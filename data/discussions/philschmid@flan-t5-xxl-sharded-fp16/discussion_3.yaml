!!python/object:huggingface_hub.community.DiscussionWithDetails
author: deathcrush
conflicting_files: null
created_at: 2023-03-03 12:22:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae0ebefe67d2cdd3c1f26bf3da5f5094.svg
      fullname: Alexandru Coca
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: deathcrush
      type: user
    createdAt: '2023-03-03T12:22:19.000Z'
    data:
      edited: false
      editors:
      - deathcrush
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae0ebefe67d2cdd3c1f26bf3da5f5094.svg
          fullname: Alexandru Coca
          isHf: false
          isPro: false
          name: deathcrush
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;philschmid&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/philschmid\"\
          >@<span class=\"underline\">philschmid</span></a></span>\n\n\t</span></span>,</p>\n\
          <p>I experimented with this <a href=\"https://huggingface.co/spaces/osanseviero/i-like-flan/tree/main\"\
          >https://huggingface.co/spaces/osanseviero/i-like-flan/tree/main</a> demo\
          \ and found that I could use FLAN-T5-XXL for very interesting research.\
          \ I am looking to understand a bit more what model I was running and how\
          \ it relates to the google checkpoint from the hub. I can see you used Artifact-AI/flan-t5-xxl-sharded-fp16.\
          \ What exactly is this model? Did the authors just cast the model weights\
          \ to fp16 and then saved the model to reduce inference latency and cost?</p>\n"
        raw: "Hi @philschmid,\r\n\r\nI experimented with this https://huggingface.co/spaces/osanseviero/i-like-flan/tree/main\
          \ demo and found that I could use FLAN-T5-XXL for very interesting research.\
          \ I am looking to understand a bit more what model I was running and how\
          \ it relates to the google checkpoint from the hub. I can see you used Artifact-AI/flan-t5-xxl-sharded-fp16.\
          \ What exactly is this model? Did the authors just cast the model weights\
          \ to fp16 and then saved the model to reduce inference latency and cost?"
        updatedAt: '2023-03-03T12:22:19.623Z'
      numEdits: 0
      reactions: []
    id: 6401e67b82bbdfe4b7c28b11
    type: comment
  author: deathcrush
  content: "Hi @philschmid,\r\n\r\nI experimented with this https://huggingface.co/spaces/osanseviero/i-like-flan/tree/main\
    \ demo and found that I could use FLAN-T5-XXL for very interesting research. I\
    \ am looking to understand a bit more what model I was running and how it relates\
    \ to the google checkpoint from the hub. I can see you used Artifact-AI/flan-t5-xxl-sharded-fp16.\
    \ What exactly is this model? Did the authors just cast the model weights to fp16\
    \ and then saved the model to reduce inference latency and cost?"
  created_at: 2023-03-03 12:22:19+00:00
  edited: false
  hidden: false
  id: 6401e67b82bbdfe4b7c28b11
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: philschmid/flan-t5-xxl-sharded-fp16
repo_type: model
status: open
target_branch: null
title: Model details
