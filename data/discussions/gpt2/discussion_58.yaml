!!python/object:huggingface_hub.community.DiscussionWithDetails
author: humza-sami
conflicting_files: null
created_at: 2023-06-26 08:11:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/633d6d4f48ab6a0add2ce1a3/qTO75kR0hk1Yn1SaP7ZPb.jpeg?w=200&h=200&f=face
      fullname: Humza Sami
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: humza-sami
      type: user
    createdAt: '2023-06-26T09:11:00.000Z'
    data:
      edited: false
      editors:
      - humza-sami
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8120349645614624
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/633d6d4f48ab6a0add2ce1a3/qTO75kR0hk1Yn1SaP7ZPb.jpeg?w=200&h=200&f=face
          fullname: Humza Sami
          isHf: false
          isPro: false
          name: humza-sami
          type: user
        html: "<p>I\u2019m encountering an issue with GPU memory allocation while\
          \ training a GPT-2 model on a GPU with 24 GB of VRAM. Despite having a substantial\
          \ amount of available memory, I\u2019m receiving the following error:</p>\n\
          <p>OutOfMemoryError: CUDA out of memory. Tried to allocate 64.00 MiB (GPU\
          \ 0; 23.68 GiB total capacity; 18.17 GiB already allocated; 64.62 MiB free;\
          \ 18.60 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt;\
          \ allocated memory try setting max_split_size_mb to avoid fragmentation.\
          \ See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF.</p>\n\
          <p>Here are the specifications of my setup and the model training:</p>\n\
          <p>GPU: NVIDIA GPU with 24 GB VRAM<br>Model: GPT-2 with approximately 3\
          \ GB in size and 800 parameters of 32-bit each<br>Training Data: 36,000\
          \ training examples with vector length of 600<br>Training Configuration:\
          \ 5 epochs, batch size of 16, and fp16 enabled<br>These are my calculations:</p>\n\
          <p>Model Size:<br>GPT-2 model: ~3 GB<br>Parameters: 800 parameters of 32\
          \ bits each<br>Gradients:<br>Gradients are typically of the same size as\
          \ the model\u2019s parameters.<br>Batch Size and Training Examples:<br>Batch\
          \ Size: 16<br>Training Examples: 36,000<br>Vector Length: 600<br>Memory\
          \ Allocation per Batch:<br>Model: 3 GB (unchanged per batch)<br>Gradients:\
          \ 3 GB (unchanged per batch)<br>Input Data: 16 x 600 (vector length) x 4\
          \ bytes (assuming each value is a 32-bit float) = 37.5 KB per batch<br>Output\
          \ Data: 16 x 600 (vector length) x 4 bytes (assuming each value is a 32-bit\
          \ float) = 37.5 KB per batch<br>Based on the above calculations, the memory\
          \ allocation per batch for your scenario would be approximately:</p>\n<p>Model:\
          \ 3 GB<br>Gradients: 3 GB<br>Input and Output Data: 75 KB<br>I would appreciate\
          \ any insights or suggestions on how to resolve this issue. Thank you in\
          \ advance for your assistance!</p>\n"
        raw: "I\u2019m encountering an issue with GPU memory allocation while training\
          \ a GPT-2 model on a GPU with 24 GB of VRAM. Despite having a substantial\
          \ amount of available memory, I\u2019m receiving the following error:\r\n\
          \r\nOutOfMemoryError: CUDA out of memory. Tried to allocate 64.00 MiB (GPU\
          \ 0; 23.68 GiB total capacity; 18.17 GiB already allocated; 64.62 MiB free;\
          \ 18.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated\
          \ memory try setting max_split_size_mb to avoid fragmentation. See documentation\
          \ for Memory Management and PYTORCH_CUDA_ALLOC_CONF.\r\n\r\nHere are the\
          \ specifications of my setup and the model training:\r\n\r\nGPU: NVIDIA\
          \ GPU with 24 GB VRAM\r\nModel: GPT-2 with approximately 3 GB in size and\
          \ 800 parameters of 32-bit each\r\nTraining Data: 36,000 training examples\
          \ with vector length of 600\r\nTraining Configuration: 5 epochs, batch size\
          \ of 16, and fp16 enabled\r\nThese are my calculations:\r\n\r\nModel Size:\r\
          \nGPT-2 model: ~3 GB\r\nParameters: 800 parameters of 32 bits each\r\nGradients:\r\
          \nGradients are typically of the same size as the model\u2019s parameters.\r\
          \nBatch Size and Training Examples:\r\nBatch Size: 16\r\nTraining Examples:\
          \ 36,000\r\nVector Length: 600\r\nMemory Allocation per Batch:\r\nModel:\
          \ 3 GB (unchanged per batch)\r\nGradients: 3 GB (unchanged per batch)\r\n\
          Input Data: 16 x 600 (vector length) x 4 bytes (assuming each value is a\
          \ 32-bit float) = 37.5 KB per batch\r\nOutput Data: 16 x 600 (vector length)\
          \ x 4 bytes (assuming each value is a 32-bit float) = 37.5 KB per batch\r\
          \nBased on the above calculations, the memory allocation per batch for your\
          \ scenario would be approximately:\r\n\r\nModel: 3 GB\r\nGradients: 3 GB\r\
          \nInput and Output Data: 75 KB\r\nI would appreciate any insights or suggestions\
          \ on how to resolve this issue. Thank you in advance for your assistance!"
        updatedAt: '2023-06-26T09:11:00.412Z'
      numEdits: 0
      reactions: []
    id: 649956246fa90dfa283fa34c
    type: comment
  author: humza-sami
  content: "I\u2019m encountering an issue with GPU memory allocation while training\
    \ a GPT-2 model on a GPU with 24 GB of VRAM. Despite having a substantial amount\
    \ of available memory, I\u2019m receiving the following error:\r\n\r\nOutOfMemoryError:\
    \ CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 23.68 GiB total capacity;\
    \ 18.17 GiB already allocated; 64.62 MiB free; 18.60 GiB reserved in total by\
    \ PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb\
    \ to avoid fragmentation. See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF.\r\
    \n\r\nHere are the specifications of my setup and the model training:\r\n\r\n\
    GPU: NVIDIA GPU with 24 GB VRAM\r\nModel: GPT-2 with approximately 3 GB in size\
    \ and 800 parameters of 32-bit each\r\nTraining Data: 36,000 training examples\
    \ with vector length of 600\r\nTraining Configuration: 5 epochs, batch size of\
    \ 16, and fp16 enabled\r\nThese are my calculations:\r\n\r\nModel Size:\r\nGPT-2\
    \ model: ~3 GB\r\nParameters: 800 parameters of 32 bits each\r\nGradients:\r\n\
    Gradients are typically of the same size as the model\u2019s parameters.\r\nBatch\
    \ Size and Training Examples:\r\nBatch Size: 16\r\nTraining Examples: 36,000\r\
    \nVector Length: 600\r\nMemory Allocation per Batch:\r\nModel: 3 GB (unchanged\
    \ per batch)\r\nGradients: 3 GB (unchanged per batch)\r\nInput Data: 16 x 600\
    \ (vector length) x 4 bytes (assuming each value is a 32-bit float) = 37.5 KB\
    \ per batch\r\nOutput Data: 16 x 600 (vector length) x 4 bytes (assuming each\
    \ value is a 32-bit float) = 37.5 KB per batch\r\nBased on the above calculations,\
    \ the memory allocation per batch for your scenario would be approximately:\r\n\
    \r\nModel: 3 GB\r\nGradients: 3 GB\r\nInput and Output Data: 75 KB\r\nI would\
    \ appreciate any insights or suggestions on how to resolve this issue. Thank you\
    \ in advance for your assistance!"
  created_at: 2023-06-26 08:11:00+00:00
  edited: false
  hidden: false
  id: 649956246fa90dfa283fa34c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 58
repo_id: gpt2
repo_type: model
status: open
target_branch: null
title: 'OutOfMemoryError: CUDA out of memory despite available GPU memory'
