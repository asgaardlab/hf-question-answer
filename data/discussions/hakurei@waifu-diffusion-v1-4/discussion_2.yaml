!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Nilaier
conflicting_files: null
created_at: 2022-10-17 02:20:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674077813762-61e284a0a1b71bd0dc4a4e7d.png?w=200&h=200&f=face
      fullname: Nilaier
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nilaier
      type: user
    createdAt: '2022-10-17T03:20:36.000Z'
    data:
      edited: false
      editors:
      - Nilaier
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674077813762-61e284a0a1b71bd0dc4a4e7d.png?w=200&h=200&f=face
          fullname: Nilaier
          isHf: false
          isPro: false
          name: Nilaier
          type: user
        html: '<p>Just asking. Can''t use ckpt, don''t know how to convert. Big dummy
          me</p>

          '
        raw: Just asking. Can't use ckpt, don't know how to convert. Big dummy me
        updatedAt: '2022-10-17T03:20:36.584Z'
      numEdits: 0
      reactions: []
    id: 634cca0488c6b621d357cbfa
    type: comment
  author: Nilaier
  content: Just asking. Can't use ckpt, don't know how to convert. Big dummy me
  created_at: 2022-10-17 02:20:36+00:00
  edited: false
  hidden: false
  id: 634cca0488c6b621d357cbfa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666058209742-631822c449af4d408c36dfec.jpeg?w=200&h=200&f=face
      fullname: Dan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HexagonSun
      type: user
    createdAt: '2022-10-18T01:55:23.000Z'
    data:
      edited: true
      editors:
      - HexagonSun
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666058209742-631822c449af4d408c36dfec.jpeg?w=200&h=200&f=face
          fullname: Dan
          isHf: false
          isPro: false
          name: HexagonSun
          type: user
        html: '<p>You should just rename the .ckpt file of the VAE to the name of
          the model you''re using and change the extension to ".vae.pt", I think the
          config and the pruner should also be there but I''m not sure.</p>

          <p>So, if you''re using the "wd-v1-3-float16.ckpt" model file, you should
          rename the VAE into "wd-v1-3-float16.vae.pt". Both should be present in
          the "/models/stable-diffusion" folder.<br>When you select the WD model,
          the console should say: "Loading VAE weights from: ...\stable-diffusion-webui\models\Stable-diffusion\wd-v1-3-float16.vae.pt"</p>

          '
        raw: 'You should just rename the .ckpt file of the VAE to the name of the
          model you''re using and change the extension to ".vae.pt", I think the config
          and the pruner should also be there but I''m not sure.


          So, if you''re using the "wd-v1-3-float16.ckpt" model file, you should rename
          the VAE into "wd-v1-3-float16.vae.pt". Both should be present in the "/models/stable-diffusion"
          folder.

          When you select the WD model, the console should say: "Loading VAE weights
          from: ...\stable-diffusion-webui\models\Stable-diffusion\wd-v1-3-float16.vae.pt"'
        updatedAt: '2022-10-18T01:58:19.859Z'
      numEdits: 3
      reactions: []
    id: 634e078b418913d584671b7a
    type: comment
  author: HexagonSun
  content: 'You should just rename the .ckpt file of the VAE to the name of the model
    you''re using and change the extension to ".vae.pt", I think the config and the
    pruner should also be there but I''m not sure.


    So, if you''re using the "wd-v1-3-float16.ckpt" model file, you should rename
    the VAE into "wd-v1-3-float16.vae.pt". Both should be present in the "/models/stable-diffusion"
    folder.

    When you select the WD model, the console should say: "Loading VAE weights from:
    ...\stable-diffusion-webui\models\Stable-diffusion\wd-v1-3-float16.vae.pt"'
  created_at: 2022-10-18 00:55:23+00:00
  edited: true
  hidden: false
  id: 634e078b418913d584671b7a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674077813762-61e284a0a1b71bd0dc4a4e7d.png?w=200&h=200&f=face
      fullname: Nilaier
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nilaier
      type: user
    createdAt: '2022-10-18T01:59:20.000Z'
    data:
      edited: false
      editors:
      - Nilaier
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674077813762-61e284a0a1b71bd0dc4a4e7d.png?w=200&h=200&f=face
          fullname: Nilaier
          isHf: false
          isPro: false
          name: Nilaier
          type: user
        html: '<blockquote>

          <p>You should just rename the file .ckpt file of the VAE to the name of
          the model you''re using and change the extension to ".vae.pt"</p>

          <p>So, if you''re using the "wd-v1-3-float16.ckpt" model file, you should
          rename the VAE into "wd-v1-3-float16.vae.pt". Both should be present in
          the "/models/stable-diffusion" folder.<br>When you select the WD model,
          the console should say: "Loading VAE weights from: ...\stable-diffusion-webui\models\Stable-diffusion\wd-v1-3-float16.vae.pt"</p>

          </blockquote>

          <p>Cool, but can I merge VAE with the model so they''ll be solid? I don''t
          think you can use them separately in dreambooth.</p>

          '
        raw: "> You should just rename the file .ckpt file of the VAE to the name\
          \ of the model you're using and change the extension to \".vae.pt\"\n> \n\
          > So, if you're using the \"wd-v1-3-float16.ckpt\" model file, you should\
          \ rename the VAE into \"wd-v1-3-float16.vae.pt\". Both should be present\
          \ in the \"/models/stable-diffusion\" folder.\n> When you select the WD\
          \ model, the console should say: \"Loading VAE weights from: ...\\stable-diffusion-webui\\\
          models\\Stable-diffusion\\wd-v1-3-float16.vae.pt\"\n\nCool, but can I merge\
          \ VAE with the model so they'll be solid? I don't think you can use them\
          \ separately in dreambooth."
        updatedAt: '2022-10-18T01:59:20.437Z'
      numEdits: 0
      reactions: []
    id: 634e0878a00c472888739464
    type: comment
  author: Nilaier
  content: "> You should just rename the file .ckpt file of the VAE to the name of\
    \ the model you're using and change the extension to \".vae.pt\"\n> \n> So, if\
    \ you're using the \"wd-v1-3-float16.ckpt\" model file, you should rename the\
    \ VAE into \"wd-v1-3-float16.vae.pt\". Both should be present in the \"/models/stable-diffusion\"\
    \ folder.\n> When you select the WD model, the console should say: \"Loading VAE\
    \ weights from: ...\\stable-diffusion-webui\\models\\Stable-diffusion\\wd-v1-3-float16.vae.pt\"\
    \n\nCool, but can I merge VAE with the model so they'll be solid? I don't think\
    \ you can use them separately in dreambooth."
  created_at: 2022-10-18 00:59:20+00:00
  edited: false
  hidden: false
  id: 634e0878a00c472888739464
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666058209742-631822c449af4d408c36dfec.jpeg?w=200&h=200&f=face
      fullname: Dan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HexagonSun
      type: user
    createdAt: '2022-10-18T04:08:47.000Z'
    data:
      edited: true
      editors:
      - HexagonSun
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666058209742-631822c449af4d408c36dfec.jpeg?w=200&h=200&f=face
          fullname: Dan
          isHf: false
          isPro: false
          name: HexagonSun
          type: user
        html: '<blockquote>

          <p>Cool, but can I merge VAE with the model so they''ll be solid? I don''t
          think you can use them separately in dreambooth.</p>

          </blockquote>

          <p>I think so, yes. I have merged both successfully in the past, but now
          that I think of it, I can''t be sure if it actually worked lol<br>Try merging
          them as they are and update here with the results for others.</p>

          '
        raw: '> Cool, but can I merge VAE with the model so they''ll be solid? I don''t
          think you can use them separately in dreambooth.


          I think so, yes. I have merged both successfully in the past, but now that
          I think of it, I can''t be sure if it actually worked lol

          Try merging them as they are and update here with the results for others.'
        updatedAt: '2022-10-18T04:08:55.114Z'
      numEdits: 1
      reactions: []
    id: 634e26cfe2d037c12803ae60
    type: comment
  author: HexagonSun
  content: '> Cool, but can I merge VAE with the model so they''ll be solid? I don''t
    think you can use them separately in dreambooth.


    I think so, yes. I have merged both successfully in the past, but now that I think
    of it, I can''t be sure if it actually worked lol

    Try merging them as they are and update here with the results for others.'
  created_at: 2022-10-18 03:08:47+00:00
  edited: true
  hidden: false
  id: 634e26cfe2d037c12803ae60
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/db0ae4bcf7e1b08c7240687d607571c3.svg
      fullname: Joao Oliveira
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jspsoli
      type: user
    createdAt: '2022-10-18T14:40:29.000Z'
    data:
      edited: true
      editors:
      - jspsoli
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/db0ae4bcf7e1b08c7240687d607571c3.svg
          fullname: Joao Oliveira
          isHf: false
          isPro: false
          name: jspsoli
          type: user
        html: '<blockquote>

          <p>Cool, but can I merge VAE with the model so they''ll be solid? I don''t
          think you can use them separately in dreambooth.</p>

          </blockquote>

          <p>Not with the Automatic1111''s merge option - as far as I know.<br>But
          you can do this with diffusers (github) - they have a script to convert
          a normal SD checkpoint to diffusers and another that does the reverse.<br>Since
          the first script splits the checkpoint into parts you can just set it to
          load the custom VAE instead of the one built in the .ckpt and then use the
          second script to convert it back to .ckpt (which will integrate the custom
          VAE into the checkpoint itself). To do this though you need to  manually
          edit the first conversion script to load the external VAE.<br>First load
          it like this:<br>external_vae_path = "Your-Vae-Path"<br>vae_ckpt = torch.load(external_vae_path,
          map_location="cpu")["state_dict"]<br>Then replace:<br>converted_vae_checkpoint
          = convert_ldm_vae_checkpoint(checkpoint, vae_config)<br>with:<br>converted_vae_checkpoint
          = convert_ldm_vae_checkpoint(vae_ckpt, vae_config)</p>

          <p>EDIT:<br>Just to be even more clear, you can do this with any model including
          a dreambooth. You could also do a conversion using a dummy model just to
          get the diffusers-based custom VAE then use the first script (unedited)
          to convert any model you want to diffusers and just copy paste and replace
          the VAE part with the custom one before converting it back to .ckpt.</p>

          '
        raw: "> Cool, but can I merge VAE with the model so they'll be solid? I don't\
          \ think you can use them separately in dreambooth.\n\nNot with the Automatic1111's\
          \ merge option - as far as I know.\nBut you can do this with diffusers (github)\
          \ - they have a script to convert a normal SD checkpoint to diffusers and\
          \ another that does the reverse. \nSince the first script splits the checkpoint\
          \ into parts you can just set it to load the custom VAE instead of the one\
          \ built in the .ckpt and then use the second script to convert it back to\
          \ .ckpt (which will integrate the custom VAE into the checkpoint itself).\
          \ To do this though you need to  manually edit the first conversion script\
          \ to load the external VAE.\nFirst load it like this:\nexternal_vae_path\
          \ = \"Your-Vae-Path\"\nvae_ckpt = torch.load(external_vae_path, map_location=\"\
          cpu\")[\"state_dict\"]\nThen replace:\nconverted_vae_checkpoint = convert_ldm_vae_checkpoint(checkpoint,\
          \ vae_config)\nwith:\nconverted_vae_checkpoint = convert_ldm_vae_checkpoint(vae_ckpt,\
          \ vae_config)\n\nEDIT:\nJust to be even more clear, you can do this with\
          \ any model including a dreambooth. You could also do a conversion using\
          \ a dummy model just to get the diffusers-based custom VAE then use the\
          \ first script (unedited) to convert any model you want to diffusers and\
          \ just copy paste and replace the VAE part with the custom one before converting\
          \ it back to .ckpt."
        updatedAt: '2022-10-18T14:45:02.919Z'
      numEdits: 4
      reactions: []
    id: 634ebadda51d5df8c2dcea3f
    type: comment
  author: jspsoli
  content: "> Cool, but can I merge VAE with the model so they'll be solid? I don't\
    \ think you can use them separately in dreambooth.\n\nNot with the Automatic1111's\
    \ merge option - as far as I know.\nBut you can do this with diffusers (github)\
    \ - they have a script to convert a normal SD checkpoint to diffusers and another\
    \ that does the reverse. \nSince the first script splits the checkpoint into parts\
    \ you can just set it to load the custom VAE instead of the one built in the .ckpt\
    \ and then use the second script to convert it back to .ckpt (which will integrate\
    \ the custom VAE into the checkpoint itself). To do this though you need to  manually\
    \ edit the first conversion script to load the external VAE.\nFirst load it like\
    \ this:\nexternal_vae_path = \"Your-Vae-Path\"\nvae_ckpt = torch.load(external_vae_path,\
    \ map_location=\"cpu\")[\"state_dict\"]\nThen replace:\nconverted_vae_checkpoint\
    \ = convert_ldm_vae_checkpoint(checkpoint, vae_config)\nwith:\nconverted_vae_checkpoint\
    \ = convert_ldm_vae_checkpoint(vae_ckpt, vae_config)\n\nEDIT:\nJust to be even\
    \ more clear, you can do this with any model including a dreambooth. You could\
    \ also do a conversion using a dummy model just to get the diffusers-based custom\
    \ VAE then use the first script (unedited) to convert any model you want to diffusers\
    \ and just copy paste and replace the VAE part with the custom one before converting\
    \ it back to .ckpt."
  created_at: 2022-10-18 13:40:29+00:00
  edited: true
  hidden: false
  id: 634ebadda51d5df8c2dcea3f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674077813762-61e284a0a1b71bd0dc4a4e7d.png?w=200&h=200&f=face
      fullname: Nilaier
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nilaier
      type: user
    createdAt: '2022-10-19T04:07:23.000Z'
    data:
      edited: false
      editors:
      - Nilaier
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674077813762-61e284a0a1b71bd0dc4a4e7d.png?w=200&h=200&f=face
          fullname: Nilaier
          isHf: false
          isPro: false
          name: Nilaier
          type: user
        html: '<blockquote>

          <blockquote>

          <p>Cool, but can I merge VAE with the model so they''ll be solid? I don''t
          think you can use them separately in dreambooth.</p>

          </blockquote>

          <p>Not with the Automatic1111''s merge option - as far as I know.<br>But
          you can do this with diffusers (github) - they have a script to convert
          a normal SD checkpoint to diffusers and another that does the reverse.<br>Since
          the first script splits the checkpoint into parts you can just set it to
          load the custom VAE instead of the one built in the .ckpt and then use the
          second script to convert it back to .ckpt (which will integrate the custom
          VAE into the checkpoint itself). To do this though you need to  manually
          edit the first conversion script to load the external VAE.<br>First load
          it like this:<br>external_vae_path = "Your-Vae-Path"<br>vae_ckpt = torch.load(external_vae_path,
          map_location="cpu")["state_dict"]<br>Then replace:<br>converted_vae_checkpoint
          = convert_ldm_vae_checkpoint(checkpoint, vae_config)<br>with:<br>converted_vae_checkpoint
          = convert_ldm_vae_checkpoint(vae_ckpt, vae_config)</p>

          <p>EDIT:<br>Just to be even more clear, you can do this with any model including
          a dreambooth. You could also do a conversion using a dummy model just to
          get the diffusers-based custom VAE then use the first script (unedited)
          to convert any model you want to diffusers and just copy paste and replace
          the VAE part with the custom one before converting it back to .ckpt.</p>

          </blockquote>

          <p>No, i don''t think that works. Usually it throws an error exactly on
          &gt; converted_vae_checkpoint = convert_ldm_vae_checkpoint(vae_ckpt, vae_config)</p>

          <p>Either: omegaconf.errors.ConfigAttributeError: Missing key timesteps<br>    full_key:
          model.params.timesteps<br>    object_type=dict<br>If provided a config from
          the vae''s folder too</p>

          <p>Or:     new_checkpoint["encoder.conv_in.weight"] = vae_state_dict["encoder.conv_in.weight"]<br>KeyError:
          ''encoder.conv_in.weight''<br>Without it</p>

          '
        raw: "> > Cool, but can I merge VAE with the model so they'll be solid? I\
          \ don't think you can use them separately in dreambooth.\n> \n> Not with\
          \ the Automatic1111's merge option - as far as I know.\n> But you can do\
          \ this with diffusers (github) - they have a script to convert a normal\
          \ SD checkpoint to diffusers and another that does the reverse. \n> Since\
          \ the first script splits the checkpoint into parts you can just set it\
          \ to load the custom VAE instead of the one built in the .ckpt and then\
          \ use the second script to convert it back to .ckpt (which will integrate\
          \ the custom VAE into the checkpoint itself). To do this though you need\
          \ to  manually edit the first conversion script to load the external VAE.\n\
          > First load it like this:\n> external_vae_path = \"Your-Vae-Path\"\n> vae_ckpt\
          \ = torch.load(external_vae_path, map_location=\"cpu\")[\"state_dict\"]\n\
          > Then replace:\n> converted_vae_checkpoint = convert_ldm_vae_checkpoint(checkpoint,\
          \ vae_config)\n> with:\n> converted_vae_checkpoint = convert_ldm_vae_checkpoint(vae_ckpt,\
          \ vae_config)\n> \n> EDIT:\n> Just to be even more clear, you can do this\
          \ with any model including a dreambooth. You could also do a conversion\
          \ using a dummy model just to get the diffusers-based custom VAE then use\
          \ the first script (unedited) to convert any model you want to diffusers\
          \ and just copy paste and replace the VAE part with the custom one before\
          \ converting it back to .ckpt.\n\nNo, i don't think that works. Usually\
          \ it throws an error exactly on > converted_vae_checkpoint = convert_ldm_vae_checkpoint(vae_ckpt,\
          \ vae_config)\n\nEither: omegaconf.errors.ConfigAttributeError: Missing\
          \ key timesteps\n    full_key: model.params.timesteps\n    object_type=dict\n\
          If provided a config from the vae's folder too\n\nOr:     new_checkpoint[\"\
          encoder.conv_in.weight\"] = vae_state_dict[\"encoder.conv_in.weight\"]\n\
          KeyError: 'encoder.conv_in.weight'\nWithout it"
        updatedAt: '2022-10-19T04:07:23.072Z'
      numEdits: 0
      reactions: []
    id: 634f77fb23788038c5f368e1
    type: comment
  author: Nilaier
  content: "> > Cool, but can I merge VAE with the model so they'll be solid? I don't\
    \ think you can use them separately in dreambooth.\n> \n> Not with the Automatic1111's\
    \ merge option - as far as I know.\n> But you can do this with diffusers (github)\
    \ - they have a script to convert a normal SD checkpoint to diffusers and another\
    \ that does the reverse. \n> Since the first script splits the checkpoint into\
    \ parts you can just set it to load the custom VAE instead of the one built in\
    \ the .ckpt and then use the second script to convert it back to .ckpt (which\
    \ will integrate the custom VAE into the checkpoint itself). To do this though\
    \ you need to  manually edit the first conversion script to load the external\
    \ VAE.\n> First load it like this:\n> external_vae_path = \"Your-Vae-Path\"\n\
    > vae_ckpt = torch.load(external_vae_path, map_location=\"cpu\")[\"state_dict\"\
    ]\n> Then replace:\n> converted_vae_checkpoint = convert_ldm_vae_checkpoint(checkpoint,\
    \ vae_config)\n> with:\n> converted_vae_checkpoint = convert_ldm_vae_checkpoint(vae_ckpt,\
    \ vae_config)\n> \n> EDIT:\n> Just to be even more clear, you can do this with\
    \ any model including a dreambooth. You could also do a conversion using a dummy\
    \ model just to get the diffusers-based custom VAE then use the first script (unedited)\
    \ to convert any model you want to diffusers and just copy paste and replace the\
    \ VAE part with the custom one before converting it back to .ckpt.\n\nNo, i don't\
    \ think that works. Usually it throws an error exactly on > converted_vae_checkpoint\
    \ = convert_ldm_vae_checkpoint(vae_ckpt, vae_config)\n\nEither: omegaconf.errors.ConfigAttributeError:\
    \ Missing key timesteps\n    full_key: model.params.timesteps\n    object_type=dict\n\
    If provided a config from the vae's folder too\n\nOr:     new_checkpoint[\"encoder.conv_in.weight\"\
    ] = vae_state_dict[\"encoder.conv_in.weight\"]\nKeyError: 'encoder.conv_in.weight'\n\
    Without it"
  created_at: 2022-10-19 03:07:23+00:00
  edited: false
  hidden: false
  id: 634f77fb23788038c5f368e1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/db0ae4bcf7e1b08c7240687d607571c3.svg
      fullname: Joao Oliveira
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jspsoli
      type: user
    createdAt: '2022-10-19T20:48:39.000Z'
    data:
      edited: false
      editors:
      - jspsoli
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/db0ae4bcf7e1b08c7240687d607571c3.svg
          fullname: Joao Oliveira
          isHf: false
          isPro: false
          name: jspsoli
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Nilaier&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Nilaier\">@<span class=\"\
          underline\">Nilaier</span></a></span>\n\n\t</span></span><br>My bad - I\
          \ didn't actually tested it out. Turns out the keys are a bit different\
          \ which is why you got errors even without trying to load the included config.yaml.<br>You\
          \ can get it working by not using that config file and replacing the following\
          \ line:</p>\n<blockquote>\n<p>if key.startswith(vae_key):</p>\n</blockquote>\n\
          <p>with:</p>\n<blockquote>\n<p>if key[0:4] != \"loss\":</p>\n</blockquote>\n\
          <p>However this will not add the 'loss' keys which have some configuration\
          \ within the given VAE config.yaml - those keys and those config settings\
          \ do not exist in the original v1-inference.yaml - and so since I'm no dev\
          \ this is as far as I can go.<br>The config settings - aside from the 'loss'\
          \ keys settings -  are exactly the same as the original SD so you could\
          \ just try to ignore those but I don't think the end results will be 100%\
          \ the same.</p>\n"
        raw: "@Nilaier \nMy bad - I didn't actually tested it out. Turns out the keys\
          \ are a bit different which is why you got errors even without trying to\
          \ load the included config.yaml.\nYou can get it working by not using that\
          \ config file and replacing the following line:\n>if key.startswith(vae_key):\n\
          \nwith:\n>if key[0:4] != \"loss\":\n\nHowever this will not add the 'loss'\
          \ keys which have some configuration within the given VAE config.yaml -\
          \ those keys and those config settings do not exist in the original v1-inference.yaml\
          \ - and so since I'm no dev this is as far as I can go.\nThe config settings\
          \ - aside from the 'loss' keys settings -  are exactly the same as the original\
          \ SD so you could just try to ignore those but I don't think the end results\
          \ will be 100% the same."
        updatedAt: '2022-10-19T20:48:39.255Z'
      numEdits: 0
      reactions: []
    id: 635062a759bfa9a85d40a45d
    type: comment
  author: jspsoli
  content: "@Nilaier \nMy bad - I didn't actually tested it out. Turns out the keys\
    \ are a bit different which is why you got errors even without trying to load\
    \ the included config.yaml.\nYou can get it working by not using that config file\
    \ and replacing the following line:\n>if key.startswith(vae_key):\n\nwith:\n>if\
    \ key[0:4] != \"loss\":\n\nHowever this will not add the 'loss' keys which have\
    \ some configuration within the given VAE config.yaml - those keys and those config\
    \ settings do not exist in the original v1-inference.yaml - and so since I'm no\
    \ dev this is as far as I can go.\nThe config settings - aside from the 'loss'\
    \ keys settings -  are exactly the same as the original SD so you could just try\
    \ to ignore those but I don't think the end results will be 100% the same."
  created_at: 2022-10-19 19:48:39+00:00
  edited: false
  hidden: false
  id: 635062a759bfa9a85d40a45d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674077813762-61e284a0a1b71bd0dc4a4e7d.png?w=200&h=200&f=face
      fullname: Nilaier
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nilaier
      type: user
    createdAt: '2022-10-19T21:14:02.000Z'
    data:
      edited: false
      editors:
      - Nilaier
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674077813762-61e284a0a1b71bd0dc4a4e7d.png?w=200&h=200&f=face
          fullname: Nilaier
          isHf: false
          isPro: false
          name: Nilaier
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;Nilaier&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Nilaier\"\
          >@<span class=\"underline\">Nilaier</span></a></span>\n\n\t</span></span><br>My\
          \ bad - I didn't actually tested it out. Turns out the keys are a bit different\
          \ which is why you got errors even without trying to load the included config.yaml.<br>You\
          \ can get it working by not using that config file and replacing the following\
          \ line:</p>\n<blockquote>\n<p>if key.startswith(vae_key):</p>\n</blockquote>\n\
          <p>with:</p>\n<blockquote>\n<p>if key[0:4] != \"loss\":</p>\n</blockquote>\n\
          <p>However this will not add the 'loss' keys which have some configuration\
          \ within the given VAE config.yaml - those keys and those config settings\
          \ do not exist in the original v1-inference.yaml - and so since I'm no dev\
          \ this is as far as I can go.<br>The config settings - aside from the 'loss'\
          \ keys settings -  are exactly the same as the original SD so you could\
          \ just try to ignore those but I don't think the end results will be 100%\
          \ the same.</p>\n</blockquote>\n<p>Okay, if that's what we can do, then\
          \ i'm going to try. Let's cross our fingers and dive right into it!</p>\n"
        raw: "> @Nilaier \n> My bad - I didn't actually tested it out. Turns out the\
          \ keys are a bit different which is why you got errors even without trying\
          \ to load the included config.yaml.\n> You can get it working by not using\
          \ that config file and replacing the following line:\n> >if key.startswith(vae_key):\n\
          > \n> with:\n> >if key[0:4] != \"loss\":\n> \n> However this will not add\
          \ the 'loss' keys which have some configuration within the given VAE config.yaml\
          \ - those keys and those config settings do not exist in the original v1-inference.yaml\
          \ - and so since I'm no dev this is as far as I can go.\n> The config settings\
          \ - aside from the 'loss' keys settings -  are exactly the same as the original\
          \ SD so you could just try to ignore those but I don't think the end results\
          \ will be 100% the same.\n\nOkay, if that's what we can do, then i'm going\
          \ to try. Let's cross our fingers and dive right into it!"
        updatedAt: '2022-10-19T21:14:02.187Z'
      numEdits: 0
      reactions: []
    id: 6350689a1edb9d240f65fd62
    type: comment
  author: Nilaier
  content: "> @Nilaier \n> My bad - I didn't actually tested it out. Turns out the\
    \ keys are a bit different which is why you got errors even without trying to\
    \ load the included config.yaml.\n> You can get it working by not using that config\
    \ file and replacing the following line:\n> >if key.startswith(vae_key):\n> \n\
    > with:\n> >if key[0:4] != \"loss\":\n> \n> However this will not add the 'loss'\
    \ keys which have some configuration within the given VAE config.yaml - those\
    \ keys and those config settings do not exist in the original v1-inference.yaml\
    \ - and so since I'm no dev this is as far as I can go.\n> The config settings\
    \ - aside from the 'loss' keys settings -  are exactly the same as the original\
    \ SD so you could just try to ignore those but I don't think the end results will\
    \ be 100% the same.\n\nOkay, if that's what we can do, then i'm going to try.\
    \ Let's cross our fingers and dive right into it!"
  created_at: 2022-10-19 20:14:02+00:00
  edited: false
  hidden: false
  id: 6350689a1edb9d240f65fd62
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674077813762-61e284a0a1b71bd0dc4a4e7d.png?w=200&h=200&f=face
      fullname: Nilaier
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nilaier
      type: user
    createdAt: '2022-10-20T01:28:44.000Z'
    data:
      edited: false
      editors:
      - Nilaier
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674077813762-61e284a0a1b71bd0dc4a4e7d.png?w=200&h=200&f=face
          fullname: Nilaier
          isHf: false
          isPro: false
          name: Nilaier
          type: user
        html: '<p>Oh, ok, i guess it did actually worked! It doesn''t have such amazing
          results as it was shown for us on Haru''s twitter, but, admitedly, i''ve
          used float 16 checkpoint, so i think it would be even better on something
          like float 32 or full ema.<br>New VAE:<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1666229285456-61e284a0a1b71bd0dc4a4e7d.png"><img
          alt="00009-4260133673-1girl, solo,____.png" src="https://cdn-uploads.huggingface.co/production/uploads/1666229285456-61e284a0a1b71bd0dc4a4e7d.png"></a><br>Original:<br><a
          rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1666229285562-61e284a0a1b71bd0dc4a4e7d.png"><img
          alt="00008-4260133673-1girl, solo,____.png" src="https://cdn-uploads.huggingface.co/production/uploads/1666229285562-61e284a0a1b71bd0dc4a4e7d.png"></a></p>

          '
        raw: 'Oh, ok, i guess it did actually worked! It doesn''t have such amazing
          results as it was shown for us on Haru''s twitter, but, admitedly, i''ve
          used float 16 checkpoint, so i think it would be even better on something
          like float 32 or full ema.

          New VAE:

          ![00009-4260133673-1girl, solo,____.png](https://cdn-uploads.huggingface.co/production/uploads/1666229285456-61e284a0a1b71bd0dc4a4e7d.png)

          Original:

          ![00008-4260133673-1girl, solo,____.png](https://cdn-uploads.huggingface.co/production/uploads/1666229285562-61e284a0a1b71bd0dc4a4e7d.png)'
        updatedAt: '2022-10-20T01:28:44.065Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - jspsoli
        - Nilaier
    id: 6350a44caaee2ec378df40a1
    type: comment
  author: Nilaier
  content: 'Oh, ok, i guess it did actually worked! It doesn''t have such amazing
    results as it was shown for us on Haru''s twitter, but, admitedly, i''ve used
    float 16 checkpoint, so i think it would be even better on something like float
    32 or full ema.

    New VAE:

    ![00009-4260133673-1girl, solo,____.png](https://cdn-uploads.huggingface.co/production/uploads/1666229285456-61e284a0a1b71bd0dc4a4e7d.png)

    Original:

    ![00008-4260133673-1girl, solo,____.png](https://cdn-uploads.huggingface.co/production/uploads/1666229285562-61e284a0a1b71bd0dc4a4e7d.png)'
  created_at: 2022-10-20 00:28:44+00:00
  edited: false
  hidden: false
  id: 6350a44caaee2ec378df40a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/db0ae4bcf7e1b08c7240687d607571c3.svg
      fullname: Joao Oliveira
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jspsoli
      type: user
    createdAt: '2022-10-20T03:42:49.000Z'
    data:
      edited: false
      editors:
      - jspsoli
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/db0ae4bcf7e1b08c7240687d607571c3.svg
          fullname: Joao Oliveira
          isHf: false
          isPro: false
          name: jspsoli
          type: user
        html: '<p>"Supposedly improves reconstruction of eyes and fingers." - From
          the rentry.org site.<br>It would be difficult to improve on that art style
          and yet there''s definitely some improvement in the eyes there.<br>This
          will probably fare much better with more ''realistic''/modern anime style.
          Also when it comes to conversions and merges its always a good idea to experiment
          with the different schedulers/methods a bit.<br>Will def give this a try
          myself when v1.4 gets out.</p>

          '
        raw: '"Supposedly improves reconstruction of eyes and fingers." - From the
          rentry.org site.

          It would be difficult to improve on that art style and yet there''s definitely
          some improvement in the eyes there.

          This will probably fare much better with more ''realistic''/modern anime
          style. Also when it comes to conversions and merges its always a good idea
          to experiment with the different schedulers/methods a bit.

          Will def give this a try myself when v1.4 gets out.'
        updatedAt: '2022-10-20T03:42:49.773Z'
      numEdits: 0
      reactions: []
    id: 6350c3b9229624a4d4a74115
    type: comment
  author: jspsoli
  content: '"Supposedly improves reconstruction of eyes and fingers." - From the rentry.org
    site.

    It would be difficult to improve on that art style and yet there''s definitely
    some improvement in the eyes there.

    This will probably fare much better with more ''realistic''/modern anime style.
    Also when it comes to conversions and merges its always a good idea to experiment
    with the different schedulers/methods a bit.

    Will def give this a try myself when v1.4 gets out.'
  created_at: 2022-10-20 02:42:49+00:00
  edited: false
  hidden: false
  id: 6350c3b9229624a4d4a74115
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666058209742-631822c449af4d408c36dfec.jpeg?w=200&h=200&f=face
      fullname: Dan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HexagonSun
      type: user
    createdAt: '2022-10-20T16:17:51.000Z'
    data:
      edited: false
      editors:
      - HexagonSun
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666058209742-631822c449af4d408c36dfec.jpeg?w=200&h=200&f=face
          fullname: Dan
          isHf: false
          isPro: false
          name: HexagonSun
          type: user
        html: '<blockquote>

          <p>admitedly, i''ve used float 16 checkpoint, so i think it would be even
          better on something like float 32 or full ema.</p>

          </blockquote>

          <p>I thought this shouldn''t have any effect on final result, and is used
          only when you start training?</p>

          '
        raw: '> admitedly, i''ve used float 16 checkpoint, so i think it would be
          even better on something like float 32 or full ema.


          I thought this shouldn''t have any effect on final result, and is used only
          when you start training?'
        updatedAt: '2022-10-20T16:17:51.071Z'
      numEdits: 0
      reactions: []
    id: 635174af4cecef71a4192f5f
    type: comment
  author: HexagonSun
  content: '> admitedly, i''ve used float 16 checkpoint, so i think it would be even
    better on something like float 32 or full ema.


    I thought this shouldn''t have any effect on final result, and is used only when
    you start training?'
  created_at: 2022-10-20 15:17:51+00:00
  edited: false
  hidden: false
  id: 635174af4cecef71a4192f5f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/db0ae4bcf7e1b08c7240687d607571c3.svg
      fullname: Joao Oliveira
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jspsoli
      type: user
    createdAt: '2022-10-20T19:00:53.000Z'
    data:
      edited: true
      editors:
      - jspsoli
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/db0ae4bcf7e1b08c7240687d607571c3.svg
          fullname: Joao Oliveira
          isHf: false
          isPro: false
          name: jspsoli
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;HexagonSun&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/HexagonSun\">@<span class=\"\
          underline\">HexagonSun</span></a></span>\n\n\t</span></span><br>It will\
          \ obviously affect the final result but not by much. The way I understand\
          \ it is float 32 is a decimal number which supports double the number of\
          \ digits than fp16 does. So when converting to fp16 you are basically 'rounding'\
          \ the weights - the end result is VERY close to the original but never the\
          \ same. You can see this by directly comparing 2 images generated with a\
          \ fp16 and its fp32 equivalent model.<br>When it comes to this VAE - since\
          \ its meant to affect minor details - using fp16 might have a noticeable\
          \ negative impact.</p>\n"
        raw: '@HexagonSun

          It will obviously affect the final result but not by much. The way I understand
          it is float 32 is a decimal number which supports double the number of digits
          than fp16 does. So when converting to fp16 you are basically ''rounding''
          the weights - the end result is VERY close to the original but never the
          same. You can see this by directly comparing 2 images generated with a fp16
          and its fp32 equivalent model.

          When it comes to this VAE - since its meant to affect minor details - using
          fp16 might have a noticeable negative impact.'
        updatedAt: '2022-10-20T19:02:12.607Z'
      numEdits: 1
      reactions: []
    id: 63519ae5d748e43563c58d9a
    type: comment
  author: jspsoli
  content: '@HexagonSun

    It will obviously affect the final result but not by much. The way I understand
    it is float 32 is a decimal number which supports double the number of digits
    than fp16 does. So when converting to fp16 you are basically ''rounding'' the
    weights - the end result is VERY close to the original but never the same. You
    can see this by directly comparing 2 images generated with a fp16 and its fp32
    equivalent model.

    When it comes to this VAE - since its meant to affect minor details - using fp16
    might have a noticeable negative impact.'
  created_at: 2022-10-20 18:00:53+00:00
  edited: true
  hidden: false
  id: 63519ae5d748e43563c58d9a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666058209742-631822c449af4d408c36dfec.jpeg?w=200&h=200&f=face
      fullname: Dan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HexagonSun
      type: user
    createdAt: '2022-10-20T21:19:26.000Z'
    data:
      edited: false
      editors:
      - HexagonSun
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666058209742-631822c449af4d408c36dfec.jpeg?w=200&h=200&f=face
          fullname: Dan
          isHf: false
          isPro: false
          name: HexagonSun
          type: user
        html: '<blockquote>

          <p>When it comes to this VAE - since its meant to affect minor details -
          using fp16 might have a noticeable negative impact.</p>

          </blockquote>

          <p>This is new to me. Do you perhaps have a link or anything to see a comparison
          of the 16/32/full models with a VAE? I wasn''t aware of this at all.</p>

          '
        raw: '> When it comes to this VAE - since its meant to affect minor details
          - using fp16 might have a noticeable negative impact.


          This is new to me. Do you perhaps have a link or anything to see a comparison
          of the 16/32/full models with a VAE? I wasn''t aware of this at all.'
        updatedAt: '2022-10-20T21:19:26.652Z'
      numEdits: 0
      reactions: []
    id: 6351bb5e21c37db00cbb08c5
    type: comment
  author: HexagonSun
  content: '> When it comes to this VAE - since its meant to affect minor details
    - using fp16 might have a noticeable negative impact.


    This is new to me. Do you perhaps have a link or anything to see a comparison
    of the 16/32/full models with a VAE? I wasn''t aware of this at all.'
  created_at: 2022-10-20 20:19:26+00:00
  edited: false
  hidden: false
  id: 6351bb5e21c37db00cbb08c5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: hakurei/waifu-diffusion-v1-4
repo_type: model
status: open
target_branch: null
title: Why VAE is in .ckpt instead of .bin?
