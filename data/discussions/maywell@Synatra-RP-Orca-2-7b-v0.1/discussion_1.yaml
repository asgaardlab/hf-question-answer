!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jintopark
conflicting_files: null
created_at: 2023-11-22 00:04:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9b76cb63baf4276c8d935ebe24eddb31.svg
      fullname: jaykwonpark
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jintopark
      type: user
    createdAt: '2023-11-22T00:04:44.000Z'
    data:
      edited: false
      editors:
      - jintopark
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5792582035064697
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9b76cb63baf4276c8d935ebe24eddb31.svg
          fullname: jaykwonpark
          isHf: false
          isPro: false
          name: jintopark
          type: user
        html: "<p>How can I load this model?</p>\n<p>With this code</p>\n<pre><code>model\
          \ = AutoModelForCausalLM.from_pretrained(\n        model_id,\n        device_map=\"\
          auto\",\n        use_flash_attention_2=True,\n        torch_dtype=torch.bfloat16,\n\
          )\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ngen_cfg = GenerationConfig.from_model_config(model.config)\n\
          gen_cfg.pad_token_id = tokenizer.eos_token_id\n</code></pre>\n<p>I got error\
          \ on loading tokenizer </p>\n<pre><code>ValueError: Couldn't instantiate\
          \ the backend tokenizer from one of: \n(1) a `tokenizers` library serialization\
          \ file, \n(2) a slow tokenizer instance to convert or \n(3) an equivalent\
          \ slow tokenizer class to instantiate and convert. \nYou need to have sentencepiece\
          \ installed to convert a slow tokenizer to a fast one.\n</code></pre>\n"
        raw: "How can I load this model?\r\n\r\n\r\nWith this code\r\n```\r\nmodel\
          \ = AutoModelForCausalLM.from_pretrained(\r\n        model_id,\r\n     \
          \   device_map=\"auto\",\r\n        use_flash_attention_2=True,\r\n    \
          \    torch_dtype=torch.bfloat16,\r\n)\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model_id)\r\
          \ngen_cfg = GenerationConfig.from_model_config(model.config)\r\ngen_cfg.pad_token_id\
          \ = tokenizer.eos_token_id\r\n```\r\n\r\n\r\nI got error on loading tokenizer\
          \ \r\n```\r\nValueError: Couldn't instantiate the backend tokenizer from\
          \ one of: \r\n(1) a `tokenizers` library serialization file, \r\n(2) a slow\
          \ tokenizer instance to convert or \r\n(3) an equivalent slow tokenizer\
          \ class to instantiate and convert. \r\nYou need to have sentencepiece installed\
          \ to convert a slow tokenizer to a fast one.\r\n```"
        updatedAt: '2023-11-22T00:04:44.294Z'
      numEdits: 0
      reactions: []
    id: 655d459c82afda0fc45b564e
    type: comment
  author: jintopark
  content: "How can I load this model?\r\n\r\n\r\nWith this code\r\n```\r\nmodel =\
    \ AutoModelForCausalLM.from_pretrained(\r\n        model_id,\r\n        device_map=\"\
    auto\",\r\n        use_flash_attention_2=True,\r\n        torch_dtype=torch.bfloat16,\r\
    \n)\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model_id)\r\ngen_cfg = GenerationConfig.from_model_config(model.config)\r\
    \ngen_cfg.pad_token_id = tokenizer.eos_token_id\r\n```\r\n\r\n\r\nI got error\
    \ on loading tokenizer \r\n```\r\nValueError: Couldn't instantiate the backend\
    \ tokenizer from one of: \r\n(1) a `tokenizers` library serialization file, \r\
    \n(2) a slow tokenizer instance to convert or \r\n(3) an equivalent slow tokenizer\
    \ class to instantiate and convert. \r\nYou need to have sentencepiece installed\
    \ to convert a slow tokenizer to a fast one.\r\n```"
  created_at: 2023-11-22 00:04:44+00:00
  edited: false
  hidden: false
  id: 655d459c82afda0fc45b564e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6439f43a1514b7ee7fb616a1/aFhmyAoicv3zcWKYZ27Z_.png?w=200&h=200&f=face
      fullname: Jeonghwan Park
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: maywell
      type: user
    createdAt: '2023-11-22T00:08:32.000Z'
    data:
      edited: false
      editors:
      - maywell
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.985529899597168
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6439f43a1514b7ee7fb616a1/aFhmyAoicv3zcWKYZ27Z_.png?w=200&h=200&f=face
          fullname: Jeonghwan Park
          isHf: false
          isPro: false
          name: maywell
          type: user
        html: '<p>install sentencepiece as it says</p>

          '
        raw: install sentencepiece as it says
        updatedAt: '2023-11-22T00:08:32.548Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jintopark
    id: 655d4680be545cd24554c631
    type: comment
  author: maywell
  content: install sentencepiece as it says
  created_at: 2023-11-22 00:08:32+00:00
  edited: false
  hidden: false
  id: 655d4680be545cd24554c631
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6439f43a1514b7ee7fb616a1/aFhmyAoicv3zcWKYZ27Z_.png?w=200&h=200&f=face
      fullname: Jeonghwan Park
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: maywell
      type: user
    createdAt: '2023-11-22T09:07:27.000Z'
    data:
      status: closed
    id: 655dc4cf6a37ab8e1c6c4555
    type: status-change
  author: maywell
  created_at: 2023-11-22 09:07:27+00:00
  id: 655dc4cf6a37ab8e1c6c4555
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: maywell/Synatra-RP-Orca-2-7b-v0.1
repo_type: model
status: closed
target_branch: null
title: How can I load tokenizer?
