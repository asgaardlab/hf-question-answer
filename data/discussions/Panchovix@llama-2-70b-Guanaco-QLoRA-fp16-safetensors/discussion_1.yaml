!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MB7977
conflicting_files: null
created_at: 2023-10-10 14:37:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d8b1419f999f31ce3fdcb8ad994b5351.svg
      fullname: MB
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: MB7977
      type: user
    createdAt: '2023-10-10T15:37:18.000Z'
    data:
      edited: false
      editors:
      - MB7977
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9579840898513794
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d8b1419f999f31ce3fdcb8ad994b5351.svg
          fullname: MB
          isHf: false
          isPro: true
          name: MB7977
          type: user
        html: '<p>Thank you for this. I''m curious to see if an exl2 version might
          cure some of the issues I''ve had with other quants of it. Just a heads
          up that you''re missing the config.json. I used the one from The Bloke''s
          repo but needed to fix the max_position_embeddings as it''s incorrectly
          set to 2048. When quanting, exllamav2 threw up an illegal memory access/shaping
          error before I changed it to 4096 (I am quantizing with that sequence length).
          </p>

          '
        raw: 'Thank you for this. I''m curious to see if an exl2 version might cure
          some of the issues I''ve had with other quants of it. Just a heads up that
          you''re missing the config.json. I used the one from The Bloke''s repo but
          needed to fix the max_position_embeddings as it''s incorrectly set to 2048.
          When quanting, exllamav2 threw up an illegal memory access/shaping error
          before I changed it to 4096 (I am quantizing with that sequence length). '
        updatedAt: '2023-10-10T15:37:18.401Z'
      numEdits: 0
      reactions: []
    id: 65256fae904f30580f332b9f
    type: comment
  author: MB7977
  content: 'Thank you for this. I''m curious to see if an exl2 version might cure
    some of the issues I''ve had with other quants of it. Just a heads up that you''re
    missing the config.json. I used the one from The Bloke''s repo but needed to fix
    the max_position_embeddings as it''s incorrectly set to 2048. When quanting, exllamav2
    threw up an illegal memory access/shaping error before I changed it to 4096 (I
    am quantizing with that sequence length). '
  created_at: 2023-10-10 14:37:18+00:00
  edited: false
  hidden: false
  id: 65256fae904f30580f332b9f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f52a8d866ed36aba5000ac8d0ef5bc96.svg
      fullname: Francisco
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Panchovix
      type: user
    createdAt: '2023-10-10T16:14:14.000Z'
    data:
      edited: false
      editors:
      - Panchovix
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9934670329093933
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f52a8d866ed36aba5000ac8d0ef5bc96.svg
          fullname: Francisco
          isHf: false
          isPro: false
          name: Panchovix
          type: user
        html: '<p>Thanks! I didn''t upload it since I was doing the same test and
          it failed me on 2048 ctx. Just uploaded the correct config.json.</p>

          '
        raw: Thanks! I didn't upload it since I was doing the same test and it failed
          me on 2048 ctx. Just uploaded the correct config.json.
        updatedAt: '2023-10-10T16:14:14.048Z'
      numEdits: 0
      reactions: []
    id: 65257856f8db96cffc966142
    type: comment
  author: Panchovix
  content: Thanks! I didn't upload it since I was doing the same test and it failed
    me on 2048 ctx. Just uploaded the correct config.json.
  created_at: 2023-10-10 15:14:14+00:00
  edited: false
  hidden: false
  id: 65257856f8db96cffc966142
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Panchovix/llama-2-70b-Guanaco-QLoRA-fp16-safetensors
repo_type: model
status: open
target_branch: null
title: Thanks
