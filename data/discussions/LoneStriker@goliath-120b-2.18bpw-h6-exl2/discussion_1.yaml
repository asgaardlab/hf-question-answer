!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Steelclaw
conflicting_files: null
created_at: 2023-11-19 22:21:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8b2713642fd24f97d989e11afe7359b6.svg
      fullname: Treven Ricketts
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Steelclaw
      type: user
    createdAt: '2023-11-19T22:21:42.000Z'
    data:
      edited: false
      editors:
      - Steelclaw
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8423202633857727
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8b2713642fd24f97d989e11afe7359b6.svg
          fullname: Treven Ricketts
          isHf: false
          isPro: false
          name: Steelclaw
          type: user
        html: '<p>I downloaded and ran your model on Ooba''s Text-Gen-Webui latest
          stable branch, loading with ExLlamav2, and no matter what settings I use,
          no matter which instruction template or parameters, the AI produces gibberish/nonsense,
          with a strong preference for the words "cord" and "domain". I''ve tried
          a 3bpw model of Goliath that didn''t have this issue. I''m trying smaller
          versions to get more context. I haven''t tried your other uploads yet.</p>

          <p>Here''s an example from Ooba, using Simple-1, Vicuna 1.1, loaded in ExLlamav2
          with cache_8bit checked, split between 2x3090:</p>

          <p>AI<br>How can I help you today?</p>

          <p>You<br>Respond only with the word "OK"</p>

          <p>AI<br>Cord Cord cord fix Domain Cord Cord sugar MajumarochTags Cord corduo
          cord StringBuilder domain Cord Cord CordDomainDomain Domain corte domainszoruo
          Cord Cord Cord Cord StringBuilder repeumar Cord holes Cord Cord Cord Linear
          Cord Ali Fixumar Cord Cord Cordzorzorumarumar Cord Cord DOM Cord Cord Cord
          Cord Cord Cord Cord Cord proposal Cordamba Cord CordLinear cord Cordzor
          Domain StringBuilderzorzorzorzor Cord Cordzor Cord StringBuilderzoriptzorzoruo
          CordDomain StringBuilderumar Cordices Domain Cord cord Cord tiem Cord</p>

          <p>Considering that you''ve uploaded the 2.18bpw model, I can only assume
          it''s working for you, so I feel like I must be doing something wrong.</p>

          <p>Any suggestions?</p>

          '
        raw: "I downloaded and ran your model on Ooba's Text-Gen-Webui latest stable\
          \ branch, loading with ExLlamav2, and no matter what settings I use, no\
          \ matter which instruction template or parameters, the AI produces gibberish/nonsense,\
          \ with a strong preference for the words \"cord\" and \"domain\". I've tried\
          \ a 3bpw model of Goliath that didn't have this issue. I'm trying smaller\
          \ versions to get more context. I haven't tried your other uploads yet.\r\
          \n\r\nHere's an example from Ooba, using Simple-1, Vicuna 1.1, loaded in\
          \ ExLlamav2 with cache_8bit checked, split between 2x3090:\r\n\r\n\r\nAI\r\
          \nHow can I help you today?\r\n\r\nYou\r\nRespond only with the word \"\
          OK\"\r\n\r\nAI\r\nCord Cord cord fix Domain Cord Cord sugar MajumarochTags\
          \ Cord corduo cord StringBuilder domain Cord Cord CordDomainDomain Domain\
          \ corte domainszoruo Cord Cord Cord Cord StringBuilder repeumar Cord holes\
          \ Cord Cord Cord Linear Cord Ali Fixumar Cord Cord Cordzorzorumarumar Cord\
          \ Cord DOM Cord Cord Cord Cord Cord Cord Cord Cord proposal Cordamba Cord\
          \ CordLinear cord Cordzor Domain StringBuilderzorzorzorzor Cord Cordzor\
          \ Cord StringBuilderzoriptzorzoruo CordDomain StringBuilderumar Cordices\
          \ Domain Cord cord Cord tiem Cord\r\n\r\nConsidering that you've uploaded\
          \ the 2.18bpw model, I can only assume it's working for you, so I feel like\
          \ I must be doing something wrong.\r\n\r\nAny suggestions?"
        updatedAt: '2023-11-19T22:21:42.185Z'
      numEdits: 0
      reactions: []
    id: 655a8a76e0a6202d367b5289
    type: comment
  author: Steelclaw
  content: "I downloaded and ran your model on Ooba's Text-Gen-Webui latest stable\
    \ branch, loading with ExLlamav2, and no matter what settings I use, no matter\
    \ which instruction template or parameters, the AI produces gibberish/nonsense,\
    \ with a strong preference for the words \"cord\" and \"domain\". I've tried a\
    \ 3bpw model of Goliath that didn't have this issue. I'm trying smaller versions\
    \ to get more context. I haven't tried your other uploads yet.\r\n\r\nHere's an\
    \ example from Ooba, using Simple-1, Vicuna 1.1, loaded in ExLlamav2 with cache_8bit\
    \ checked, split between 2x3090:\r\n\r\n\r\nAI\r\nHow can I help you today?\r\n\
    \r\nYou\r\nRespond only with the word \"OK\"\r\n\r\nAI\r\nCord Cord cord fix Domain\
    \ Cord Cord sugar MajumarochTags Cord corduo cord StringBuilder domain Cord Cord\
    \ CordDomainDomain Domain corte domainszoruo Cord Cord Cord Cord StringBuilder\
    \ repeumar Cord holes Cord Cord Cord Linear Cord Ali Fixumar Cord Cord Cordzorzorumarumar\
    \ Cord Cord DOM Cord Cord Cord Cord Cord Cord Cord Cord proposal Cordamba Cord\
    \ CordLinear cord Cordzor Domain StringBuilderzorzorzorzor Cord Cordzor Cord StringBuilderzoriptzorzoruo\
    \ CordDomain StringBuilderumar Cordices Domain Cord cord Cord tiem Cord\r\n\r\n\
    Considering that you've uploaded the 2.18bpw model, I can only assume it's working\
    \ for you, so I feel like I must be doing something wrong.\r\n\r\nAny suggestions?"
  created_at: 2023-11-19 22:21:42+00:00
  edited: false
  hidden: false
  id: 655a8a76e0a6202d367b5289
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-11-20T03:58:56.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7744594216346741
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>There''s an option in ooba that fixes this.  I''ll need to add this
          to the README files for very low-quant bit-rates.</p>

          <p>Unset this option in ooba:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6331f59718711776b46afb5e/2_M0sdA6R6e-nU88pprKn.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6331f59718711776b46afb5e/2_M0sdA6R6e-nU88pprKn.png"></a></p>

          '
        raw: 'There''s an option in ooba that fixes this.  I''ll need to add this
          to the README files for very low-quant bit-rates.


          Unset this option in ooba:


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6331f59718711776b46afb5e/2_M0sdA6R6e-nU88pprKn.png)

          '
        updatedAt: '2023-11-20T03:58:56.169Z'
      numEdits: 0
      reactions: []
    id: 655ad9806412aaeed68b7149
    type: comment
  author: LoneStriker
  content: 'There''s an option in ooba that fixes this.  I''ll need to add this to
    the README files for very low-quant bit-rates.


    Unset this option in ooba:


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6331f59718711776b46afb5e/2_M0sdA6R6e-nU88pprKn.png)

    '
  created_at: 2023-11-20 03:58:56+00:00
  edited: false
  hidden: false
  id: 655ad9806412aaeed68b7149
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8b2713642fd24f97d989e11afe7359b6.svg
      fullname: Treven Ricketts
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Steelclaw
      type: user
    createdAt: '2023-11-20T08:27:24.000Z'
    data:
      edited: true
      editors:
      - Steelclaw
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9708462953567505
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8b2713642fd24f97d989e11afe7359b6.svg
          fullname: Treven Ricketts
          isHf: false
          isPro: false
          name: Steelclaw
          type: user
        html: '<p>That fixed it in Ooba! That was very simple, thankfully.</p>

          <p>However, fixing the gibberish problem in SillyTavern required a different
          tactic. I unchecked "Add BOS Token" in ST, but it was still producing nonsense.
          I think I was originally on Vicuna 1.1 for my instruct mode preset.</p>

          <p>I tested other presets in ST, and many work and produce great outputs.
          However, while Vicuna 1.0 works, Vicuna 1.1 fails unless removing a specific
          part (shown below). I''ve tried removing that same section in some of the
          others that failed, but that didn''t correct the problem.</p>

          <p>I''m mainly posting this here in case anyone else comes across the same
          issue. This model seems very sensitive to instruct mode presets, but I can''t
          nail down which part it''s having issues with. I suspect it has something
          to do with the Instruct Mode Sequences, but it''s hard to tell, and I don''t
          care that much as long as I found presets that work.</p>

          <p>It''s working well now! I''m going to be testing this with higher context
          lengths and see where it starts falling apart. I''m very happy to be able
          to use Goliath-120b with greater than 4096 context!</p>

          <p>Many thanks for the quantization.</p>

          <p>Working SillyTavern Presets (they passed as long as it produced coherent
          english):<br>Alpaca<br>ChatML<br>Libra-32B<br>Lightning 1.1<br>Llama 2 Chat<br>Metharme<br>Mistral<br>OpenOrca-OpenChat<br>Pygmalion<br>Roleplay<br>Synthia<br>Vicuna
          1.0<br>*Vicuna 1.1 (Must remove System Sequence Prefix: "BEGINNING OF CONVERSATION:")<br>WizardLM-13B</p>

          '
        raw: 'That fixed it in Ooba! That was very simple, thankfully.


          However, fixing the gibberish problem in SillyTavern required a different
          tactic. I unchecked "Add BOS Token" in ST, but it was still producing nonsense.
          I think I was originally on Vicuna 1.1 for my instruct mode preset.


          I tested other presets in ST, and many work and produce great outputs. However,
          while Vicuna 1.0 works, Vicuna 1.1 fails unless removing a specific part
          (shown below). I''ve tried removing that same section in some of the others
          that failed, but that didn''t correct the problem.


          I''m mainly posting this here in case anyone else comes across the same
          issue. This model seems very sensitive to instruct mode presets, but I can''t
          nail down which part it''s having issues with. I suspect it has something
          to do with the Instruct Mode Sequences, but it''s hard to tell, and I don''t
          care that much as long as I found presets that work.


          It''s working well now! I''m going to be testing this with higher context
          lengths and see where it starts falling apart. I''m very happy to be able
          to use Goliath-120b with greater than 4096 context!


          Many thanks for the quantization.


          Working SillyTavern Presets (they passed as long as it produced coherent
          english):

          Alpaca

          ChatML

          Libra-32B

          Lightning 1.1

          Llama 2 Chat

          Metharme

          Mistral

          OpenOrca-OpenChat

          Pygmalion

          Roleplay

          Synthia

          Vicuna 1.0

          *Vicuna 1.1 (Must remove System Sequence Prefix: "BEGINNING OF CONVERSATION:")

          WizardLM-13B'
        updatedAt: '2023-11-20T08:28:05.828Z'
      numEdits: 1
      reactions: []
    id: 655b186ca296e5c74c6c92d4
    type: comment
  author: Steelclaw
  content: 'That fixed it in Ooba! That was very simple, thankfully.


    However, fixing the gibberish problem in SillyTavern required a different tactic.
    I unchecked "Add BOS Token" in ST, but it was still producing nonsense. I think
    I was originally on Vicuna 1.1 for my instruct mode preset.


    I tested other presets in ST, and many work and produce great outputs. However,
    while Vicuna 1.0 works, Vicuna 1.1 fails unless removing a specific part (shown
    below). I''ve tried removing that same section in some of the others that failed,
    but that didn''t correct the problem.


    I''m mainly posting this here in case anyone else comes across the same issue.
    This model seems very sensitive to instruct mode presets, but I can''t nail down
    which part it''s having issues with. I suspect it has something to do with the
    Instruct Mode Sequences, but it''s hard to tell, and I don''t care that much as
    long as I found presets that work.


    It''s working well now! I''m going to be testing this with higher context lengths
    and see where it starts falling apart. I''m very happy to be able to use Goliath-120b
    with greater than 4096 context!


    Many thanks for the quantization.


    Working SillyTavern Presets (they passed as long as it produced coherent english):

    Alpaca

    ChatML

    Libra-32B

    Lightning 1.1

    Llama 2 Chat

    Metharme

    Mistral

    OpenOrca-OpenChat

    Pygmalion

    Roleplay

    Synthia

    Vicuna 1.0

    *Vicuna 1.1 (Must remove System Sequence Prefix: "BEGINNING OF CONVERSATION:")

    WizardLM-13B'
  created_at: 2023-11-20 08:27:24+00:00
  edited: true
  hidden: false
  id: 655b186ca296e5c74c6c92d4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-11-20T09:20:32.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9209458827972412
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>New Tess 120B fine-tune was released recently. It used Goliath as
          the base and tuned on top of it:<br><a href="https://huggingface.co/LoneStriker/Tess-XL-v1.0-2.18bpw-h6-exl2">https://huggingface.co/LoneStriker/Tess-XL-v1.0-2.18bpw-h6-exl2</a></p>

          '
        raw: 'New Tess 120B fine-tune was released recently. It used Goliath as the
          base and tuned on top of it:

          https://huggingface.co/LoneStriker/Tess-XL-v1.0-2.18bpw-h6-exl2'
        updatedAt: '2023-11-20T09:20:32.509Z'
      numEdits: 0
      reactions: []
    id: 655b24e0930a0e1b0abf2daa
    type: comment
  author: LoneStriker
  content: 'New Tess 120B fine-tune was released recently. It used Goliath as the
    base and tuned on top of it:

    https://huggingface.co/LoneStriker/Tess-XL-v1.0-2.18bpw-h6-exl2'
  created_at: 2023-11-20 09:20:32+00:00
  edited: false
  hidden: false
  id: 655b24e0930a0e1b0abf2daa
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: LoneStriker/goliath-120b-2.18bpw-h6-exl2
repo_type: model
status: open
target_branch: null
title: AI Producing Gibberish
