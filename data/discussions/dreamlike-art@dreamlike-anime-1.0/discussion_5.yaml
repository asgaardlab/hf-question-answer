!!python/object:huggingface_hub.community.DiscussionWithDetails
author: HaNope
conflicting_files: null
created_at: 2023-05-15 13:50:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1a3543056a0a6abc27645cb3a3c18946.svg
      fullname: Nope
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HaNope
      type: user
    createdAt: '2023-05-15T14:50:36.000Z'
    data:
      edited: false
      editors:
      - HaNope
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1a3543056a0a6abc27645cb3a3c18946.svg
          fullname: Nope
          isHf: false
          isPro: false
          name: HaNope
          type: user
        html: "<p>The error I keep seeing with torch is the following:</p>\n<pre><code>venv/lib/python3.9/site-packages/torch\
          \ \u2502\n\u2502 /cuda/__init__.py:239 in _lazy_init                   \
          \                       \u2502\n\u2502                                 \
          \                                             \u2502\n\u2502    236 \u2502\
          \   \u2502   \u2502   \u2502   \"Cannot re-initialize CUDA in forked subprocess.\
          \ To u \u2502\n\u2502    237 \u2502   \u2502   \u2502   \u2502   \"multiprocessing,\
          \ you must use the 'spawn' start meth \u2502\n\u2502    238 \u2502   \u2502\
          \   if not hasattr(torch._C, '_cuda_getDeviceCount'):             \u2502\
          \n\u2502 \u2771  239 \u2502   \u2502   \u2502   raise AssertionError(\"\
          Torch not compiled with CUDA enable \u2502\n\u2502    240 \u2502   \u2502\
          \   if _cudart is None:                                           \u2502\
          \n\u2502    241 \u2502   \u2502   \u2502   raise AssertionError(       \
          \                              \u2502\n\u2502    242 \u2502   \u2502   \u2502\
          \   \u2502   \"libcudart functions unavailable. It looks like you h \n</code></pre>\n\
          <p>AssertionError: Torch not compiled with CUDA enabled</p>\n<p>I'm running\
          \ a Mac M2 and not sure how to get torch and CUDA working.</p>\n"
        raw: "The error I keep seeing with torch is the following:\r\n\r\n```\r\n\
          venv/lib/python3.9/site-packages/torch \u2502\r\n\u2502 /cuda/__init__.py:239\
          \ in _lazy_init                                          \u2502\r\n\u2502\
          \                                                                      \
          \        \u2502\r\n\u2502    236 \u2502   \u2502   \u2502   \u2502   \"\
          Cannot re-initialize CUDA in forked subprocess. To u \u2502\r\n\u2502  \
          \  237 \u2502   \u2502   \u2502   \u2502   \"multiprocessing, you must use\
          \ the 'spawn' start meth \u2502\r\n\u2502    238 \u2502   \u2502   if not\
          \ hasattr(torch._C, '_cuda_getDeviceCount'):             \u2502\r\n\u2502\
          \ \u2771  239 \u2502   \u2502   \u2502   raise AssertionError(\"Torch not\
          \ compiled with CUDA enable \u2502\r\n\u2502    240 \u2502   \u2502   if\
          \ _cudart is None:                                           \u2502\r\n\u2502\
          \    241 \u2502   \u2502   \u2502   raise AssertionError(              \
          \                       \u2502\r\n\u2502    242 \u2502   \u2502   \u2502\
          \   \u2502   \"libcudart functions unavailable. It looks like you h \r\n\
          ```\r\nAssertionError: Torch not compiled with CUDA enabled\r\n\r\nI'm running\
          \ a Mac M2 and not sure how to get torch and CUDA working.\r\n"
        updatedAt: '2023-05-15T14:50:36.317Z'
      numEdits: 0
      reactions: []
    id: 646246bc514ee1645bcfedbc
    type: comment
  author: HaNope
  content: "The error I keep seeing with torch is the following:\r\n\r\n```\r\nvenv/lib/python3.9/site-packages/torch\
    \ \u2502\r\n\u2502 /cuda/__init__.py:239 in _lazy_init                       \
    \                   \u2502\r\n\u2502                                         \
    \                                     \u2502\r\n\u2502    236 \u2502   \u2502\
    \   \u2502   \u2502   \"Cannot re-initialize CUDA in forked subprocess. To u \u2502\
    \r\n\u2502    237 \u2502   \u2502   \u2502   \u2502   \"multiprocessing, you must\
    \ use the 'spawn' start meth \u2502\r\n\u2502    238 \u2502   \u2502   if not\
    \ hasattr(torch._C, '_cuda_getDeviceCount'):             \u2502\r\n\u2502 \u2771\
    \  239 \u2502   \u2502   \u2502   raise AssertionError(\"Torch not compiled with\
    \ CUDA enable \u2502\r\n\u2502    240 \u2502   \u2502   if _cudart is None:  \
    \                                         \u2502\r\n\u2502    241 \u2502   \u2502\
    \   \u2502   raise AssertionError(                                     \u2502\r\
    \n\u2502    242 \u2502   \u2502   \u2502   \u2502   \"libcudart functions unavailable.\
    \ It looks like you h \r\n```\r\nAssertionError: Torch not compiled with CUDA\
    \ enabled\r\n\r\nI'm running a Mac M2 and not sure how to get torch and CUDA working.\r\
    \n"
  created_at: 2023-05-15 13:50:36+00:00
  edited: false
  hidden: false
  id: 646246bc514ee1645bcfedbc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: dreamlike-art/dreamlike-anime-1.0
repo_type: model
status: open
target_branch: null
title: Is there a way to use this w/o torch
