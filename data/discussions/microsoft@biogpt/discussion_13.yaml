!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Seantaud
conflicting_files: null
created_at: 2023-03-07 01:58:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5995d0219ace325805e601c3aea467de.svg
      fullname: Xiaotao Wang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Seantaud
      type: user
    createdAt: '2023-03-07T01:58:29.000Z'
    data:
      edited: false
      editors:
      - Seantaud
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5995d0219ace325805e601c3aea467de.svg
          fullname: Xiaotao Wang
          isHf: false
          isPro: false
          name: Seantaud
          type: user
        html: '<p> I would like to construct a fast tokenizer class based on the BioGptTokenizer,
          so that I could use the offsets_mapping to know from which words the tokens
          do origin. But unfortunately,  it failed.</p>

          '
        raw: ' I would like to construct a fast tokenizer class based on the BioGptTokenizer,
          so that I could use the offsets_mapping to know from which words the tokens
          do origin. But unfortunately,  it failed.'
        updatedAt: '2023-03-07T01:58:29.715Z'
      numEdits: 0
      reactions: []
    id: 64069a45c3ab325efa9b74e3
    type: comment
  author: Seantaud
  content: ' I would like to construct a fast tokenizer class based on the BioGptTokenizer,
    so that I could use the offsets_mapping to know from which words the tokens do
    origin. But unfortunately,  it failed.'
  created_at: 2023-03-07 01:58:29+00:00
  edited: false
  hidden: false
  id: 64069a45c3ab325efa9b74e3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5995d0219ace325805e601c3aea467de.svg
      fullname: Xiaotao Wang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Seantaud
      type: user
    createdAt: '2023-03-07T02:06:22.000Z'
    data:
      edited: false
      editors:
      - Seantaud
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5995d0219ace325805e601c3aea467de.svg
          fullname: Xiaotao Wang
          isHf: false
          isPro: false
          name: Seantaud
          type: user
        html: '<p><code>System Info</code><br>I was trying to use BioGpt model in
          my code for fine-tuning. I would like to construct a fast tokenizer class
          based on the BioGptTokenizer, so that I could use the offsets_mapping to
          know from which words the tokens do origin. But unfortunately, when creating
          a BiogptTokenizerFast from the PreTrainedTokenizerFast by <code>convert_slow_tokenizer</code>,
          following error occurs: <code>Error while initializing BPE: Token -@&lt;/w&gt;
          out of vocabulary.</code></p>

          <p><code>Reproduction</code><br>I copy the code related to colab.This is
          the link : <a rel="nofollow" href="https://colab.research.google.com/drive/1IMhiDz45GiarBLgXG9B2rA_u0ZOmmjJS?usp=sharing">https://colab.research.google.com/drive/1IMhiDz45GiarBLgXG9B2rA_u0ZOmmjJS?usp=sharing</a></p>

          <p><code>Expected behavior</code><br>According to this issue <a rel="nofollow"
          href="https://github.com/huggingface/transformers/issues/9290">https://github.com/huggingface/transformers/issues/9290</a>,
          this problem might be caused by some missing tokens in vocab.json or merge.txt.
          Could you please check it? Thank you very much!</p>

          '
        raw: '`System Info`

          I was trying to use BioGpt model in my code for fine-tuning. I would like
          to construct a fast tokenizer class based on the BioGptTokenizer, so that
          I could use the offsets_mapping to know from which words the tokens do origin.
          But unfortunately, when creating a BiogptTokenizerFast from the PreTrainedTokenizerFast
          by `convert_slow_tokenizer`, following error occurs: `Error while initializing
          BPE: Token -@</w> out of vocabulary.`


          `Reproduction`

          I copy the code related to colab.This is the link : https://colab.research.google.com/drive/1IMhiDz45GiarBLgXG9B2rA_u0ZOmmjJS?usp=sharing


          `Expected behavior`

          According to this issue https://github.com/huggingface/transformers/issues/9290,
          this problem might be caused by some missing tokens in vocab.json or merge.txt.
          Could you please check it? Thank you very much!'
        updatedAt: '2023-03-07T02:06:22.012Z'
      numEdits: 0
      reactions: []
    id: 64069c1e31ddcb90bdc02662
    type: comment
  author: Seantaud
  content: '`System Info`

    I was trying to use BioGpt model in my code for fine-tuning. I would like to construct
    a fast tokenizer class based on the BioGptTokenizer, so that I could use the offsets_mapping
    to know from which words the tokens do origin. But unfortunately, when creating
    a BiogptTokenizerFast from the PreTrainedTokenizerFast by `convert_slow_tokenizer`,
    following error occurs: `Error while initializing BPE: Token -@</w> out of vocabulary.`


    `Reproduction`

    I copy the code related to colab.This is the link : https://colab.research.google.com/drive/1IMhiDz45GiarBLgXG9B2rA_u0ZOmmjJS?usp=sharing


    `Expected behavior`

    According to this issue https://github.com/huggingface/transformers/issues/9290,
    this problem might be caused by some missing tokens in vocab.json or merge.txt.
    Could you please check it? Thank you very much!'
  created_at: 2023-03-07 02:06:22+00:00
  edited: false
  hidden: false
  id: 64069c1e31ddcb90bdc02662
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/43bfffe27fc1eaea014120eeabc77e34.svg
      fullname: Tekeshwar Hirwani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tekeshwarhirwani
      type: user
    createdAt: '2023-06-14T15:54:23.000Z'
    data:
      edited: false
      editors:
      - tekeshwarhirwani
      hidden: false
      identifiedLanguage:
        language: fr
        probability: 0.19406883418560028
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/43bfffe27fc1eaea014120eeabc77e34.svg
          fullname: Tekeshwar Hirwani
          isHf: false
          isPro: false
          name: tekeshwarhirwani
          type: user
        html: '<p>Dude any update ?</p>

          '
        raw: Dude any update ?
        updatedAt: '2023-06-14T15:54:23.541Z'
      numEdits: 0
      reactions: []
    id: 6489e2af0420f039c5945b17
    type: comment
  author: tekeshwarhirwani
  content: Dude any update ?
  created_at: 2023-06-14 14:54:23+00:00
  edited: false
  hidden: false
  id: 6489e2af0420f039c5945b17
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: microsoft/biogpt
repo_type: model
status: open
target_branch: null
title: 'Unable to convert BioGpt slow tokenizer to fast: token out of vocabulary'
