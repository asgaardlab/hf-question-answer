!!python/object:huggingface_hub.community.DiscussionWithDetails
author: howard-hou
conflicting_files: null
created_at: 2023-11-07 12:32:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64414d0a66a62c605c94d14d/KGjlf9tRwslr7Q503YLnJ.jpeg?w=200&h=200&f=face
      fullname: howard-hou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: howard-hou
      type: user
    createdAt: '2023-11-07T12:32:07.000Z'
    data:
      edited: false
      editors:
      - howard-hou
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.31242886185646057
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64414d0a66a62c605c94d14d/KGjlf9tRwslr7Q503YLnJ.jpeg?w=200&h=200&f=face
          fullname: howard-hou
          isHf: false
          isPro: false
          name: howard-hou
          type: user
        html: '<p>I try to make the input batch_size =2 by<br>inputs = tokenizer([prompt,
          prompt], return_tensors="pt")<br>output = model.generate(inputs["input_ids"],
          max_new_tokens=256)<br>and it raise a runtime error:</p>

          <pre><code>175     # https://github.com/BlinkDL/ChatRWKV/blob/main/rwkv_pip_package/src/rwkv/model.py#L693

          </code></pre>

          <p>--&gt; 176     key = self.key(key).to(torch.float32).view(T, H, S).transpose(0,
          1).transpose(-2, -1)<br>    177     value = self.value(value).to(torch.float32).view(T,
          H, S).transpose(0, 1)<br>    178     receptance = self.receptance(receptance).to(torch.float32).view(T,
          H, S).transpose(0, 1)</p>

          <p>RuntimeError: shape ''[47, 32, 64]'' is invalid for input of size 192512</p>

          '
        raw: "I try to make the input batch_size =2 by \r\ninputs = tokenizer([prompt,\
          \ prompt], return_tensors=\"pt\")\r\noutput = model.generate(inputs[\"input_ids\"\
          ], max_new_tokens=256)\r\nand it raise a runtime error:\r\n\r\n    175 \
          \    # https://github.com/BlinkDL/ChatRWKV/blob/main/rwkv_pip_package/src/rwkv/model.py#L693\r\
          \n--> 176     key = self.key(key).to(torch.float32).view(T, H, S).transpose(0,\
          \ 1).transpose(-2, -1)\r\n    177     value = self.value(value).to(torch.float32).view(T,\
          \ H, S).transpose(0, 1)\r\n    178     receptance = self.receptance(receptance).to(torch.float32).view(T,\
          \ H, S).transpose(0, 1)\r\n\r\nRuntimeError: shape '[47, 32, 64]' is invalid\
          \ for input of size 192512"
        updatedAt: '2023-11-07T12:32:07.645Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - CyberDancer
    id: 654a2e472d2fcd6bf27321b3
    type: comment
  author: howard-hou
  content: "I try to make the input batch_size =2 by \r\ninputs = tokenizer([prompt,\
    \ prompt], return_tensors=\"pt\")\r\noutput = model.generate(inputs[\"input_ids\"\
    ], max_new_tokens=256)\r\nand it raise a runtime error:\r\n\r\n    175     # https://github.com/BlinkDL/ChatRWKV/blob/main/rwkv_pip_package/src/rwkv/model.py#L693\r\
    \n--> 176     key = self.key(key).to(torch.float32).view(T, H, S).transpose(0,\
    \ 1).transpose(-2, -1)\r\n    177     value = self.value(value).to(torch.float32).view(T,\
    \ H, S).transpose(0, 1)\r\n    178     receptance = self.receptance(receptance).to(torch.float32).view(T,\
    \ H, S).transpose(0, 1)\r\n\r\nRuntimeError: shape '[47, 32, 64]' is invalid for\
    \ input of size 192512"
  created_at: 2023-11-07 12:32:07+00:00
  edited: false
  hidden: false
  id: 654a2e472d2fcd6bf27321b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/910ace29b232523159f1c6bbd6e7e8ad.svg
      fullname: Rong Shan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CyberDancer
      type: user
    createdAt: '2023-11-30T03:28:25.000Z'
    data:
      edited: false
      editors:
      - CyberDancer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7979327440261841
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/910ace29b232523159f1c6bbd6e7e8ad.svg
          fullname: Rong Shan
          isHf: false
          isPro: false
          name: CyberDancer
          type: user
        html: '<p>Same problem encountered.</p>

          '
        raw: Same problem encountered.
        updatedAt: '2023-11-30T03:28:25.717Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - CyberDancer
        - howard-hou
    id: 6568015988bfbc261a399401
    type: comment
  author: CyberDancer
  content: Same problem encountered.
  created_at: 2023-11-30 03:28:25+00:00
  edited: false
  hidden: false
  id: 6568015988bfbc261a399401
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: RWKV/rwkv-5-world-1b5
repo_type: model
status: open
target_branch: null
title: It seems that this project can only support a batch_size of 1 during inference?
