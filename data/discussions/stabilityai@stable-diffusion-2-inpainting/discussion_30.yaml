!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lakshman111
conflicting_files: null
created_at: 2023-05-25 00:24:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667717604360-noauth.png?w=200&h=200&f=face
      fullname: Lakshman Mody
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lakshman111
      type: user
    createdAt: '2023-05-25T01:24:34.000Z'
    data:
      edited: false
      editors:
      - lakshman111
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667717604360-noauth.png?w=200&h=200&f=face
          fullname: Lakshman Mody
          isHf: false
          isPro: false
          name: lakshman111
          type: user
        html: '<p>Hi!  I have a prompt that has a length of 127.  I''m getting the
          following message when running SD2:</p>

          <p>"Token indices sequence length is longer than the specified maximum sequence
          length for this model (127 &gt; 77). Running this sequence through the model
          will result in indexing errors<br>The following part of your input was truncated
          because CLIP can only handle sequences up to 77 tokens: [...]"</p>

          <p>Looking at the CLIP documentation: <a href="https://huggingface.co/docs/transformers/model_doc/clip">https://huggingface.co/docs/transformers/model_doc/clip</a>,
          it looks like max_position_embeddings is set to 77 by default.  I''m wondering
          - is there a way to adjust this length for the SD2 inpainting model?</p>

          '
        raw: "Hi!  I have a prompt that has a length of 127.  I'm getting the following\
          \ message when running SD2:\r\n\r\n\"Token indices sequence length is longer\
          \ than the specified maximum sequence length for this model (127 > 77).\
          \ Running this sequence through the model will result in indexing errors\r\
          \nThe following part of your input was truncated because CLIP can only handle\
          \ sequences up to 77 tokens: [...]\"\r\n\r\nLooking at the CLIP documentation:\
          \ https://huggingface.co/docs/transformers/model_doc/clip, it looks like\
          \ max_position_embeddings is set to 77 by default.  I'm wondering - is there\
          \ a way to adjust this length for the SD2 inpainting model?"
        updatedAt: '2023-05-25T01:24:34.486Z'
      numEdits: 0
      reactions: []
    id: 646eb8d298e8f749fc60ac59
    type: comment
  author: lakshman111
  content: "Hi!  I have a prompt that has a length of 127.  I'm getting the following\
    \ message when running SD2:\r\n\r\n\"Token indices sequence length is longer than\
    \ the specified maximum sequence length for this model (127 > 77). Running this\
    \ sequence through the model will result in indexing errors\r\nThe following part\
    \ of your input was truncated because CLIP can only handle sequences up to 77\
    \ tokens: [...]\"\r\n\r\nLooking at the CLIP documentation: https://huggingface.co/docs/transformers/model_doc/clip,\
    \ it looks like max_position_embeddings is set to 77 by default.  I'm wondering\
    \ - is there a way to adjust this length for the SD2 inpainting model?"
  created_at: 2023-05-25 00:24:34+00:00
  edited: false
  hidden: false
  id: 646eb8d298e8f749fc60ac59
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 30
repo_id: stabilityai/stable-diffusion-2-inpainting
repo_type: model
status: open
target_branch: null
title: Expanding the maximum sequence length of CLIP past 77?
