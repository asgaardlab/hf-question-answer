!!python/object:huggingface_hub.community.DiscussionWithDetails
author: StableDiffusion69
conflicting_files: null
created_at: 2023-06-19 18:16:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d21e05e5e616f57b17b43244d561411c.svg
      fullname: Diffusion
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: StableDiffusion69
      type: user
    createdAt: '2023-06-19T19:16:48.000Z'
    data:
      edited: true
      editors:
      - StableDiffusion69
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.956664502620697
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d21e05e5e616f57b17b43244d561411c.svg
          fullname: Diffusion
          isHf: false
          isPro: false
          name: StableDiffusion69
          type: user
        html: "<p>Since the last update of oobabooga, the model stopped loading. It\
          \ just stays on Loading checkpoint shards 0%<br>Any new settings needed\
          \ to run this again (currently used Transformers)?<br>I would really like\
          \ to use this model again with my 8GB card. It is wonderful.<br>Thanks!</p>\n\
          <p>Update:<br>In the meantime, I noticed, that it didn't sopped loading,\
          \ it loads incredible slow. Normally, it takes about 1 to 2 minutes to load.\
          \ But often now, it takes about 30 minutes. And that is not wen the model\
          \ is changed, but right after loading oobabooga<br>Any idea why it takes\
          \ so long sometimes? \U0001F914<br>I really love this model, it's great.</p>\n\
          <p>2023-06-21 18:15:24 INFO:Loading Imablank_P1GM4L10N-7B-MERGED_WEIGHTS...<br>2023-06-21\
          \ 18:15:24 WARNING:Using the following 4-bit params: {'load_in_4bit': True,\
          \ 'bnb_4bit_compute_dtype': torch.float16, 'bnb_4bit_quant_type': 'nf4',\
          \ 'bnb_4bit_use_double_quant': False}<br>2023-06-21 18:15:26 WARNING:The\
          \ model weights are not tied. Please use the <code>tie_weights</code> method\
          \ before using the <code>infer_auto_device</code> function.<br>Loading checkpoint\
          \ shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [29:41&lt;00:00,\
          \ 890.88s/it]<br>2023-06-21 18:45:09 INFO:Loaded the model in 1784.14 seconds.</p>\n"
        raw: "Since the last update of oobabooga, the model stopped loading. It just\
          \ stays on Loading checkpoint shards 0%\nAny new settings needed to run\
          \ this again (currently used Transformers)?\nI would really like to use\
          \ this model again with my 8GB card. It is wonderful.\nThanks!\n\nUpdate:\n\
          In the meantime, I noticed, that it didn't sopped loading, it loads incredible\
          \ slow. Normally, it takes about 1 to 2 minutes to load. But often now,\
          \ it takes about 30 minutes. And that is not wen the model is changed, but\
          \ right after loading oobabooga\nAny idea why it takes so long sometimes?\
          \ \U0001F914\nI really love this model, it's great.\n\n2023-06-21 18:15:24\
          \ INFO:Loading Imablank_P1GM4L10N-7B-MERGED_WEIGHTS...\n2023-06-21 18:15:24\
          \ WARNING:Using the following 4-bit params: {'load_in_4bit': True, 'bnb_4bit_compute_dtype':\
          \ torch.float16, 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant':\
          \ False}\n2023-06-21 18:15:26 WARNING:The model weights are not tied. Please\
          \ use the `tie_weights` method before using the `infer_auto_device` function.\n\
          Loading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588| 2/2 [29:41<00:00, 890.88s/it]\n2023-06-21 18:45:09 INFO:Loaded the\
          \ model in 1784.14 seconds."
        updatedAt: '2023-06-21T17:49:40.624Z'
      numEdits: 1
      reactions: []
    id: 6490a9a0a0c93fb1a0eef639
    type: comment
  author: StableDiffusion69
  content: "Since the last update of oobabooga, the model stopped loading. It just\
    \ stays on Loading checkpoint shards 0%\nAny new settings needed to run this again\
    \ (currently used Transformers)?\nI would really like to use this model again\
    \ with my 8GB card. It is wonderful.\nThanks!\n\nUpdate:\nIn the meantime, I noticed,\
    \ that it didn't sopped loading, it loads incredible slow. Normally, it takes\
    \ about 1 to 2 minutes to load. But often now, it takes about 30 minutes. And\
    \ that is not wen the model is changed, but right after loading oobabooga\nAny\
    \ idea why it takes so long sometimes? \U0001F914\nI really love this model, it's\
    \ great.\n\n2023-06-21 18:15:24 INFO:Loading Imablank_P1GM4L10N-7B-MERGED_WEIGHTS...\n\
    2023-06-21 18:15:24 WARNING:Using the following 4-bit params: {'load_in_4bit':\
    \ True, 'bnb_4bit_compute_dtype': torch.float16, 'bnb_4bit_quant_type': 'nf4',\
    \ 'bnb_4bit_use_double_quant': False}\n2023-06-21 18:15:26 WARNING:The model weights\
    \ are not tied. Please use the `tie_weights` method before using the `infer_auto_device`\
    \ function.\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [29:41<00:00,\
    \ 890.88s/it]\n2023-06-21 18:45:09 INFO:Loaded the model in 1784.14 seconds."
  created_at: 2023-06-19 18:16:48+00:00
  edited: true
  hidden: false
  id: 6490a9a0a0c93fb1a0eef639
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Imablank/P1GM4L10N-7B-MERGED_WEIGHTS
repo_type: model
status: open
target_branch: null
title: Stopped loading
