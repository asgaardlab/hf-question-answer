!!python/object:huggingface_hub.community.DiscussionWithDetails
author: luxfx
conflicting_files: null
created_at: 2024-01-04 22:35:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a3ac80d516a148d88e8372826697338c.svg
      fullname: David Woods
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luxfx
      type: user
    createdAt: '2024-01-04T22:35:05.000Z'
    data:
      edited: false
      editors:
      - luxfx
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.920811653137207
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a3ac80d516a148d88e8372826697338c.svg
          fullname: David Woods
          isHf: false
          isPro: false
          name: luxfx
          type: user
        html: '<p>I am trying to run this is Ooba, but it will not work. I believe
          the problem is that the model.safetensors.index.json file is from the original
          set (it mentions ''00001 of 00008'' etc) and does not reflect the quantized
          safetensors (e.g. ''00001 of 00003'').</p>

          '
        raw: I am trying to run this is Ooba, but it will not work. I believe the
          problem is that the model.safetensors.index.json file is from the original
          set (it mentions '00001 of 00008' etc) and does not reflect the quantized
          safetensors (e.g. '00001 of 00003').
        updatedAt: '2024-01-04T22:35:05.769Z'
      numEdits: 0
      reactions: []
    id: 65973299fd17ceb1d4bb87bd
    type: comment
  author: luxfx
  content: I am trying to run this is Ooba, but it will not work. I believe the problem
    is that the model.safetensors.index.json file is from the original set (it mentions
    '00001 of 00008' etc) and does not reflect the quantized safetensors (e.g. '00001
    of 00003').
  created_at: 2024-01-04 22:35:05+00:00
  edited: false
  hidden: false
  id: 65973299fd17ceb1d4bb87bd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/abb894e4acb53d10f446aecb1efd7c9e.svg
      fullname: Sam Meyer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: cravepig
      type: user
    createdAt: '2024-01-11T04:20:54.000Z'
    data:
      edited: false
      editors:
      - cravepig
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9933268427848816
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/abb894e4acb53d10f446aecb1efd7c9e.svg
          fullname: Sam Meyer
          isHf: false
          isPro: true
          name: cravepig
          type: user
        html: '<p>I''m having the same issue.</p>

          '
        raw: I'm having the same issue.
        updatedAt: '2024-01-11T04:20:54.027Z'
      numEdits: 0
      reactions: []
    id: 659f6ca6d8a112a4b99bf239
    type: comment
  author: cravepig
  content: I'm having the same issue.
  created_at: 2024-01-11 04:20:54+00:00
  edited: false
  hidden: false
  id: 659f6ca6d8a112a4b99bf239
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2024-01-11T18:38:53.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8381370306015015
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>I''m able to load the model just fine in ooba. Please make sure
          you''ve got the latest ooba code and update the packages as well using the
          <code>update_linux.sh</code> or <code>update_windows.cmd</code> scripts.</p>

          '
        raw: I'm able to load the model just fine in ooba. Please make sure you've
          got the latest ooba code and update the packages as well using the `update_linux.sh`
          or `update_windows.cmd` scripts.
        updatedAt: '2024-01-11T18:38:53.453Z'
      numEdits: 0
      reactions: []
    id: 65a035bddb5d37ad5e65be99
    type: comment
  author: LoneStriker
  content: I'm able to load the model just fine in ooba. Please make sure you've got
    the latest ooba code and update the packages as well using the `update_linux.sh`
    or `update_windows.cmd` scripts.
  created_at: 2024-01-11 18:38:53+00:00
  edited: false
  hidden: false
  id: 65a035bddb5d37ad5e65be99
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a3ac80d516a148d88e8372826697338c.svg
      fullname: David Woods
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luxfx
      type: user
    createdAt: '2024-01-11T19:11:57.000Z'
    data:
      edited: true
      editors:
      - luxfx
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5210481882095337
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a3ac80d516a148d88e8372826697338c.svg
          fullname: David Woods
          isHf: false
          isPro: false
          name: luxfx
          type: user
        html: "<p>After updating I am still seeing this when attempting to load via\
          \ ExLlamav2_HF:</p>\n<pre><code>13:58:56-953203 INFO     Loading CodeBooga-34B-v0.1-4.0bpw-h6-exl2\n\
          13:58:57-408714 ERROR    Failed to load the model.\nTraceback (most recent\
          \ call last):\n  File \"C:\\oobabooga\\text-generation-webui\\modules\\\
          ui_model_menu.py\", line 213, in load_model_wrapper\n    shared.model, shared.tokenizer\
          \ = load_model(selected_model, loader)\n                               \
          \      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\oobabooga\\text-generation-webui\\\
          modules\\models.py\", line 87, in load_model\n    output = load_func_map[loader](model_name)\n\
          \             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\oobabooga\\\
          text-generation-webui\\modules\\models.py\", line 389, in ExLlamav2_HF_loader\n\
          \    return Exllamav2HF.from_pretrained(model_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"C:\\oobabooga\\text-generation-webui\\modules\\exllamav2_hf.py\"\
          , line 162, in from_pretrained\n    config.prepare()\n  File \"C:\\oobabooga\\\
          text-generation-webui\\installer_files\\env\\Lib\\site-packages\\exllamav2\\\
          config.py\", line 188, in prepare\n    with safe_open(st_file, framework\
          \ = \"pt\", device = \"cpu\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n\
          </code></pre>\n<p>Just to experiment I tried other model loaders (they all\
          \ fail), and Transformers ends with this:</p>\n<pre><code>FileNotFoundError:\
          \ No such file or directory: \"models\\\\CodeBooga-34B-v0.1-4.0bpw-h6-exl2\\\
          \\model-00001-of-00008.safetensors\"\n</code></pre>\n<p>Looking into the\
          \ index I can see the references to model-00008.safetensors, but other EXL2\
          \ quantized models I've looked at appear to reference non-existant files\
          \ as well, so I suppose that's not it.</p>\n<p>Any other ideas? I'm on Windows\
          \ 11 with a 3090.</p>\n"
        raw: "After updating I am still seeing this when attempting to load via ExLlamav2_HF:\n\
          \n```\n13:58:56-953203 INFO     Loading CodeBooga-34B-v0.1-4.0bpw-h6-exl2\n\
          13:58:57-408714 ERROR    Failed to load the model.\nTraceback (most recent\
          \ call last):\n  File \"C:\\oobabooga\\text-generation-webui\\modules\\\
          ui_model_menu.py\", line 213, in load_model_wrapper\n    shared.model, shared.tokenizer\
          \ = load_model(selected_model, loader)\n                               \
          \      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\oobabooga\\text-generation-webui\\\
          modules\\models.py\", line 87, in load_model\n    output = load_func_map[loader](model_name)\n\
          \             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\oobabooga\\\
          text-generation-webui\\modules\\models.py\", line 389, in ExLlamav2_HF_loader\n\
          \    return Exllamav2HF.from_pretrained(model_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"C:\\oobabooga\\text-generation-webui\\modules\\exllamav2_hf.py\"\
          , line 162, in from_pretrained\n    config.prepare()\n  File \"C:\\oobabooga\\\
          text-generation-webui\\installer_files\\env\\Lib\\site-packages\\exllamav2\\\
          config.py\", line 188, in prepare\n    with safe_open(st_file, framework\
          \ = \"pt\", device = \"cpu\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n\
          \n```\n\nJust to experiment I tried other model loaders (they all fail),\
          \ and Transformers ends with this:\n\n```\nFileNotFoundError: No such file\
          \ or directory: \"models\\\\CodeBooga-34B-v0.1-4.0bpw-h6-exl2\\\\model-00001-of-00008.safetensors\"\
          \n```\n\nLooking into the index I can see the references to model-00008.safetensors,\
          \ but other EXL2 quantized models I've looked at appear to reference non-existant\
          \ files as well, so I suppose that's not it.\n\nAny other ideas? I'm on\
          \ Windows 11 with a 3090.\n"
        updatedAt: '2024-01-11T19:12:13.070Z'
      numEdits: 1
      reactions: []
    id: 65a03d7dfbad78ab68db6feb
    type: comment
  author: luxfx
  content: "After updating I am still seeing this when attempting to load via ExLlamav2_HF:\n\
    \n```\n13:58:56-953203 INFO     Loading CodeBooga-34B-v0.1-4.0bpw-h6-exl2\n13:58:57-408714\
    \ ERROR    Failed to load the model.\nTraceback (most recent call last):\n  File\
    \ \"C:\\oobabooga\\text-generation-webui\\modules\\ui_model_menu.py\", line 213,\
    \ in load_model_wrapper\n    shared.model, shared.tokenizer = load_model(selected_model,\
    \ loader)\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
    \  File \"C:\\oobabooga\\text-generation-webui\\modules\\models.py\", line 87,\
    \ in load_model\n    output = load_func_map[loader](model_name)\n            \
    \ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\oobabooga\\text-generation-webui\\\
    modules\\models.py\", line 389, in ExLlamav2_HF_loader\n    return Exllamav2HF.from_pretrained(model_name)\n\
    \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\oobabooga\\\
    text-generation-webui\\modules\\exllamav2_hf.py\", line 162, in from_pretrained\n\
    \    config.prepare()\n  File \"C:\\oobabooga\\text-generation-webui\\installer_files\\\
    env\\Lib\\site-packages\\exllamav2\\config.py\", line 188, in prepare\n    with\
    \ safe_open(st_file, framework = \"pt\", device = \"cpu\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
    safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer\n\
    \n```\n\nJust to experiment I tried other model loaders (they all fail), and Transformers\
    \ ends with this:\n\n```\nFileNotFoundError: No such file or directory: \"models\\\
    \\CodeBooga-34B-v0.1-4.0bpw-h6-exl2\\\\model-00001-of-00008.safetensors\"\n```\n\
    \nLooking into the index I can see the references to model-00008.safetensors,\
    \ but other EXL2 quantized models I've looked at appear to reference non-existant\
    \ files as well, so I suppose that's not it.\n\nAny other ideas? I'm on Windows\
    \ 11 with a 3090.\n"
  created_at: 2024-01-11 19:11:57+00:00
  edited: true
  hidden: false
  id: 65a03d7dfbad78ab68db6feb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2024-01-11T19:15:37.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7296515703201294
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>Try the exllamav2 loader and not the _HF version? Not sure as it
          works for me under Linux with the updated ooba plus latest packages:</p>

          <pre><code>$ ./cmd_linux.sh

          $ pip list | grep exllamav2

          exllamav2                         0.0.11+cu121

          </code></pre>

          '
        raw: 'Try the exllamav2 loader and not the _HF version? Not sure as it works
          for me under Linux with the updated ooba plus latest packages:

          ```

          $ ./cmd_linux.sh

          $ pip list | grep exllamav2

          exllamav2                         0.0.11+cu121

          ```'
        updatedAt: '2024-01-11T19:15:37.893Z'
      numEdits: 0
      reactions: []
    id: 65a03e59e0b49a84d2fa75bf
    type: comment
  author: LoneStriker
  content: 'Try the exllamav2 loader and not the _HF version? Not sure as it works
    for me under Linux with the updated ooba plus latest packages:

    ```

    $ ./cmd_linux.sh

    $ pip list | grep exllamav2

    exllamav2                         0.0.11+cu121

    ```'
  created_at: 2024-01-11 19:15:37+00:00
  edited: false
  hidden: false
  id: 65a03e59e0b49a84d2fa75bf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a3ac80d516a148d88e8372826697338c.svg
      fullname: David Woods
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luxfx
      type: user
    createdAt: '2024-01-11T19:55:12.000Z'
    data:
      edited: false
      editors:
      - luxfx
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9627347588539124
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a3ac80d516a148d88e8372826697338c.svg
          fullname: David Woods
          isHf: false
          isPro: false
          name: luxfx
          type: user
        html: '<p>I tried nuking my model download and downloading it again -- and
          that worked! Must have just been a bad download. Thanks for your help, and
          thanks for the model!</p>

          '
        raw: I tried nuking my model download and downloading it again -- and that
          worked! Must have just been a bad download. Thanks for your help, and thanks
          for the model!
        updatedAt: '2024-01-11T19:55:12.015Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - LoneStriker
      relatedEventId: 65a047a0db5d37ad5e6ab371
    id: 65a047a0db5d37ad5e6ab36d
    type: comment
  author: luxfx
  content: I tried nuking my model download and downloading it again -- and that worked!
    Must have just been a bad download. Thanks for your help, and thanks for the model!
  created_at: 2024-01-11 19:55:12+00:00
  edited: false
  hidden: false
  id: 65a047a0db5d37ad5e6ab36d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/a3ac80d516a148d88e8372826697338c.svg
      fullname: David Woods
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luxfx
      type: user
    createdAt: '2024-01-11T19:55:12.000Z'
    data:
      status: closed
    id: 65a047a0db5d37ad5e6ab371
    type: status-change
  author: luxfx
  created_at: 2024-01-11 19:55:12+00:00
  id: 65a047a0db5d37ad5e6ab371
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: LoneStriker/CodeBooga-34B-v0.1-4.0bpw-h6-exl2
repo_type: model
status: closed
target_branch: null
title: Bad index?
