!!python/object:huggingface_hub.community.DiscussionWithDetails
author: klotz
conflicting_files: null
created_at: 2023-12-30 02:55:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5b304332ba7d9eb0f25d72dd50a1fea9.svg
      fullname: Leigh Klotz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: klotz
      type: user
    createdAt: '2023-12-30T02:55:00.000Z'
    data:
      edited: false
      editors:
      - klotz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.760719895362854
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5b304332ba7d9eb0f25d72dd50a1fea9.svg
          fullname: Leigh Klotz
          isHf: false
          isPro: false
          name: klotz
          type: user
        html: '<p><a href="https://huggingface.co/cognitivecomputations/dolphin-2.6.1-mixtral-8x7b">https://huggingface.co/cognitivecomputations/dolphin-2.6.1-mixtral-8x7b</a>
          gets 404.<br>Nothing with dolphin-2.6.1* seems nearby.</p>

          '
        raw: "https://huggingface.co/cognitivecomputations/dolphin-2.6.1-mixtral-8x7b\
          \ gets 404.\r\nNothing with dolphin-2.6.1* seems nearby."
        updatedAt: '2023-12-30T02:55:00.020Z'
      numEdits: 0
      reactions: []
    id: 658f8684a41c3cbad563929e
    type: comment
  author: klotz
  content: "https://huggingface.co/cognitivecomputations/dolphin-2.6.1-mixtral-8x7b\
    \ gets 404.\r\nNothing with dolphin-2.6.1* seems nearby."
  created_at: 2023-12-30 02:55:00+00:00
  edited: false
  hidden: false
  id: 658f8684a41c3cbad563929e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6435718aaaef013d1aec3b8b/XKf-8MA47tjVAM6SCX0MP.jpeg?w=200&h=200&f=face
      fullname: Bartowski
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: bartowski
      type: user
    createdAt: '2023-12-30T03:01:24.000Z'
    data:
      edited: false
      editors:
      - bartowski
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9793933033943176
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6435718aaaef013d1aec3b8b/XKf-8MA47tjVAM6SCX0MP.jpeg?w=200&h=200&f=face
          fullname: Bartowski
          isHf: false
          isPro: false
          name: bartowski
          type: user
        html: '<p>Yeah I was about to add a change, Eric saw the performance decreased
          with 2.6.1 so pulled it, I''ll leave mine up for anyone who wants but he''s
          working on retraining</p>

          <p>The leading theory is that Axolotl''s transformers build doesn''t properly
          train the MoE router, and so it''s being "naive in backpropagation", and
          so 2.7 or whatever he ends up calling it will be properly training the routing
          and have likely much higher performance</p>

          '
        raw: 'Yeah I was about to add a change, Eric saw the performance decreased
          with 2.6.1 so pulled it, I''ll leave mine up for anyone who wants but he''s
          working on retraining


          The leading theory is that Axolotl''s transformers build doesn''t properly
          train the MoE router, and so it''s being "naive in backpropagation", and
          so 2.7 or whatever he ends up calling it will be properly training the routing
          and have likely much higher performance'
        updatedAt: '2023-12-30T03:01:24.507Z'
      numEdits: 0
      reactions: []
    id: 658f8804674349122c11a970
    type: comment
  author: bartowski
  content: 'Yeah I was about to add a change, Eric saw the performance decreased with
    2.6.1 so pulled it, I''ll leave mine up for anyone who wants but he''s working
    on retraining


    The leading theory is that Axolotl''s transformers build doesn''t properly train
    the MoE router, and so it''s being "naive in backpropagation", and so 2.7 or whatever
    he ends up calling it will be properly training the routing and have likely much
    higher performance'
  created_at: 2023-12-30 03:01:24+00:00
  edited: false
  hidden: false
  id: 658f8804674349122c11a970
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5b304332ba7d9eb0f25d72dd50a1fea9.svg
      fullname: Leigh Klotz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: klotz
      type: user
    createdAt: '2023-12-30T04:01:51.000Z'
    data:
      edited: false
      editors:
      - klotz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8260924816131592
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5b304332ba7d9eb0f25d72dd50a1fea9.svg
          fullname: Leigh Klotz
          isHf: false
          isPro: false
          name: klotz
          type: user
        html: '<p>Thank you for the status and the great repo!</p>

          '
        raw: Thank you for the status and the great repo!
        updatedAt: '2023-12-30T04:01:51.513Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - bartowski
    id: 658f962f4a24a38778d40839
    type: comment
  author: klotz
  content: Thank you for the status and the great repo!
  created_at: 2023-12-30 04:01:51+00:00
  edited: false
  hidden: false
  id: 658f962f4a24a38778d40839
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: bartowski/dolphin-2.6.1-mixtral-8x7b-exl2
repo_type: model
status: open
target_branch: null
title: Original model link is 404
