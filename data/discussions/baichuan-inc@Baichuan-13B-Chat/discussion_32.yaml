!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Desjajja
conflicting_files: null
created_at: 2023-08-21 08:33:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/746cb764f9edc6488ead8758a76f5687.svg
      fullname: "\u9093\u7FD4\u5B87"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Desjajja
      type: user
    createdAt: '2023-08-21T09:33:12.000Z'
    data:
      edited: false
      editors:
      - Desjajja
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8984407782554626
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/746cb764f9edc6488ead8758a76f5687.svg
          fullname: "\u9093\u7FD4\u5B87"
          isHf: false
          isPro: false
          name: Desjajja
          type: user
        html: '<p>Is there any pipeline to export this model to ONNX (using torch.onnx/optimum,
          etc)? I intend to do further acceleration in inference and ONNX file is
          a must. However, none of the frameworks above support baichuan yet.</p>

          '
        raw: Is there any pipeline to export this model to ONNX (using torch.onnx/optimum,
          etc)? I intend to do further acceleration in inference and ONNX file is
          a must. However, none of the frameworks above support baichuan yet.
        updatedAt: '2023-08-21T09:33:12.904Z'
      numEdits: 0
      reactions: []
    id: 64e32f58618cd90997d4d8f8
    type: comment
  author: Desjajja
  content: Is there any pipeline to export this model to ONNX (using torch.onnx/optimum,
    etc)? I intend to do further acceleration in inference and ONNX file is a must.
    However, none of the frameworks above support baichuan yet.
  created_at: 2023-08-21 08:33:12+00:00
  edited: false
  hidden: false
  id: 64e32f58618cd90997d4d8f8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cd9725a883f4cc4ae64a3f35697e6533.svg
      fullname: wuzhiying2023
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: wuzhiying2023
      type: user
    createdAt: '2023-08-22T02:22:40.000Z'
    data:
      edited: false
      editors:
      - wuzhiying2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8012655973434448
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cd9725a883f4cc4ae64a3f35697e6533.svg
          fullname: wuzhiying2023
          isHf: false
          isPro: false
          name: wuzhiying2023
          type: user
        html: '<p>I have no idea.Is there any framework  supports llama?</p>

          '
        raw: I have no idea.Is there any framework  supports llama?
        updatedAt: '2023-08-22T02:22:40.044Z'
      numEdits: 0
      reactions: []
    id: 64e41bf098b7b68a1c1e6110
    type: comment
  author: wuzhiying2023
  content: I have no idea.Is there any framework  supports llama?
  created_at: 2023-08-22 01:22:40+00:00
  edited: false
  hidden: false
  id: 64e41bf098b7b68a1c1e6110
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/746cb764f9edc6488ead8758a76f5687.svg
      fullname: "\u9093\u7FD4\u5B87"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Desjajja
      type: user
    createdAt: '2023-08-22T02:47:25.000Z'
    data:
      edited: false
      editors:
      - Desjajja
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8509843349456787
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/746cb764f9edc6488ead8758a76f5687.svg
          fullname: "\u9093\u7FD4\u5B87"
          isHf: false
          isPro: false
          name: Desjajja
          type: user
        html: '<p>Yes, HF <a href="https://huggingface.co/docs/optimum/exporters/onnx/overview">optimum
          </a>supports llama, but baichuan is not even in their plan LOL</p>

          '
        raw: Yes, HF [optimum ](https://huggingface.co/docs/optimum/exporters/onnx/overview)supports
          llama, but baichuan is not even in their plan LOL
        updatedAt: '2023-08-22T02:47:25.495Z'
      numEdits: 0
      reactions: []
    id: 64e421bdcf8c236f3044a65d
    type: comment
  author: Desjajja
  content: Yes, HF [optimum ](https://huggingface.co/docs/optimum/exporters/onnx/overview)supports
    llama, but baichuan is not even in their plan LOL
  created_at: 2023-08-22 01:47:25+00:00
  edited: false
  hidden: false
  id: 64e421bdcf8c236f3044a65d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 32
repo_id: baichuan-inc/Baichuan-13B-Chat
repo_type: model
status: open
target_branch: null
title: Model Export to ONNX format
