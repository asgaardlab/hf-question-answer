!!python/object:huggingface_hub.community.DiscussionWithDetails
author: frankxyy
conflicting_files: null
created_at: 2023-09-22 05:34:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4ac36ffc22dabf02569a2cab65295ff9.svg
      fullname: yangyang xu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: frankxyy
      type: user
    createdAt: '2023-09-22T06:34:56.000Z'
    data:
      edited: false
      editors:
      - frankxyy
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.99729984998703
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4ac36ffc22dabf02569a2cab65295ff9.svg
          fullname: yangyang xu
          isHf: false
          isPro: false
          name: frankxyy
          type: user
        html: "<p>\u5982\u9898</p>\n"
        raw: "\u5982\u9898"
        updatedAt: '2023-09-22T06:34:56.157Z'
      numEdits: 0
      reactions: []
    id: 650d35907074abb29fd6b0a3
    type: comment
  author: frankxyy
  content: "\u5982\u9898"
  created_at: 2023-09-22 05:34:56+00:00
  edited: false
  hidden: false
  id: 650d35907074abb29fd6b0a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ead5336301fd88ef9cd71e3b4aef413.svg
      fullname: d ck
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: player123187
      type: user
    createdAt: '2023-12-07T03:09:59.000Z'
    data:
      edited: false
      editors:
      - player123187
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.39238226413726807
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ead5336301fd88ef9cd71e3b4aef413.svg
          fullname: d ck
          isHf: false
          isPro: false
          name: player123187
          type: user
        html: "<p>Baichuan-13B \u652F\u6301 int8 \u548C int4 \u91CF\u5316\uFF0C\u7528\
          \u6237\u53EA\u9700\u5728\u63A8\u7406\u4EE3\u7801\u4E2D\u7B80\u5355\u4FEE\
          \u6539\u4E24\u884C\u5373\u53EF\u5B9E\u73B0\u3002\u8BF7\u6CE8\u610F\uFF0C\
          \u5982\u679C\u662F\u4E3A\u4E86\u8282\u7701\u663E\u5B58\u800C\u8FDB\u884C\
          \u91CF\u5316\uFF0C\u5E94\u52A0\u8F7D\u539F\u59CB\u7CBE\u5EA6\u6A21\u578B\
          \u5230 CPU \u540E\u518D\u5F00\u59CB\u91CF\u5316\uFF1B\u907F\u514D\u5728\
          \ from_pretrained \u65F6\u6DFB\u52A0 device_map='auto' \u6216\u8005\u5176\
          \u5B83\u4F1A\u5BFC\u81F4\u628A\u539F\u59CB\u7CBE\u5EA6\u6A21\u578B\u76F4\
          \u63A5\u52A0\u8F7D\u5230 GPU \u7684\u884C\u4E3A\u7684\u53C2\u6570\u3002\
          </p>\n<p>\u4F7F\u7528 int8 \u91CF\u5316 (To use int8 quantization):</p>\n\
          <p>model = AutoModelForCausalLM.from_pretrained(\"baichuan-inc/Baichuan-13B-Chat\"\
          , torch_dtype=torch.float16, trust_remote_code=True)<br>model = model.quantize(8).cuda()\
          \ </p>\n<p>\u540C\u6837\u7684\uFF0C\u5982\u9700\u4F7F\u7528 int4 \u91CF\u5316\
          \ (Similarly, to use int4 quantization):</p>\n<p>model = AutoModelForCausalLM.from_pretrained(\"\
          baichuan-inc/Baichuan-13B-Chat\", torch_dtype=torch.float16, trust_remote_code=True)<br>model\
          \ = model.quantize(4).cuda()</p>\n"
        raw: "Baichuan-13B \u652F\u6301 int8 \u548C int4 \u91CF\u5316\uFF0C\u7528\u6237\
          \u53EA\u9700\u5728\u63A8\u7406\u4EE3\u7801\u4E2D\u7B80\u5355\u4FEE\u6539\
          \u4E24\u884C\u5373\u53EF\u5B9E\u73B0\u3002\u8BF7\u6CE8\u610F\uFF0C\u5982\
          \u679C\u662F\u4E3A\u4E86\u8282\u7701\u663E\u5B58\u800C\u8FDB\u884C\u91CF\
          \u5316\uFF0C\u5E94\u52A0\u8F7D\u539F\u59CB\u7CBE\u5EA6\u6A21\u578B\u5230\
          \ CPU \u540E\u518D\u5F00\u59CB\u91CF\u5316\uFF1B\u907F\u514D\u5728 from_pretrained\
          \ \u65F6\u6DFB\u52A0 device_map='auto' \u6216\u8005\u5176\u5B83\u4F1A\u5BFC\
          \u81F4\u628A\u539F\u59CB\u7CBE\u5EA6\u6A21\u578B\u76F4\u63A5\u52A0\u8F7D\
          \u5230 GPU \u7684\u884C\u4E3A\u7684\u53C2\u6570\u3002\n\n\u4F7F\u7528 int8\
          \ \u91CF\u5316 (To use int8 quantization):\n\nmodel = AutoModelForCausalLM.from_pretrained(\"\
          baichuan-inc/Baichuan-13B-Chat\", torch_dtype=torch.float16, trust_remote_code=True)\n\
          model = model.quantize(8).cuda() \n\n\u540C\u6837\u7684\uFF0C\u5982\u9700\
          \u4F7F\u7528 int4 \u91CF\u5316 (Similarly, to use int4 quantization):\n\n\
          model = AutoModelForCausalLM.from_pretrained(\"baichuan-inc/Baichuan-13B-Chat\"\
          , torch_dtype=torch.float16, trust_remote_code=True)\nmodel = model.quantize(4).cuda()"
        updatedAt: '2023-12-07T03:09:59.324Z'
      numEdits: 0
      reactions: []
    id: 65713787c8018fe6408e55ee
    type: comment
  author: player123187
  content: "Baichuan-13B \u652F\u6301 int8 \u548C int4 \u91CF\u5316\uFF0C\u7528\u6237\
    \u53EA\u9700\u5728\u63A8\u7406\u4EE3\u7801\u4E2D\u7B80\u5355\u4FEE\u6539\u4E24\
    \u884C\u5373\u53EF\u5B9E\u73B0\u3002\u8BF7\u6CE8\u610F\uFF0C\u5982\u679C\u662F\
    \u4E3A\u4E86\u8282\u7701\u663E\u5B58\u800C\u8FDB\u884C\u91CF\u5316\uFF0C\u5E94\
    \u52A0\u8F7D\u539F\u59CB\u7CBE\u5EA6\u6A21\u578B\u5230 CPU \u540E\u518D\u5F00\u59CB\
    \u91CF\u5316\uFF1B\u907F\u514D\u5728 from_pretrained \u65F6\u6DFB\u52A0 device_map='auto'\
    \ \u6216\u8005\u5176\u5B83\u4F1A\u5BFC\u81F4\u628A\u539F\u59CB\u7CBE\u5EA6\u6A21\
    \u578B\u76F4\u63A5\u52A0\u8F7D\u5230 GPU \u7684\u884C\u4E3A\u7684\u53C2\u6570\u3002\
    \n\n\u4F7F\u7528 int8 \u91CF\u5316 (To use int8 quantization):\n\nmodel = AutoModelForCausalLM.from_pretrained(\"\
    baichuan-inc/Baichuan-13B-Chat\", torch_dtype=torch.float16, trust_remote_code=True)\n\
    model = model.quantize(8).cuda() \n\n\u540C\u6837\u7684\uFF0C\u5982\u9700\u4F7F\
    \u7528 int4 \u91CF\u5316 (Similarly, to use int4 quantization):\n\nmodel = AutoModelForCausalLM.from_pretrained(\"\
    baichuan-inc/Baichuan-13B-Chat\", torch_dtype=torch.float16, trust_remote_code=True)\n\
    model = model.quantize(4).cuda()"
  created_at: 2023-12-07 03:09:59+00:00
  edited: false
  hidden: false
  id: 65713787c8018fe6408e55ee
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 39
repo_id: baichuan-inc/Baichuan-13B-Chat
repo_type: model
status: open
target_branch: null
title: "\u8BF7\u95EEint8 \u548C int4 \u7528\u7684\u91CF\u5316\u65B9\u6CD5\u662F\u4EC0\
  \u4E48\u554A\uFF1F"
