!!python/object:huggingface_hub.community.DiscussionWithDetails
author: diagaiwei
conflicting_files: null
created_at: 2023-07-18 08:02:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b32d2fdb42f0b885810c0d112d45d11d.svg
      fullname: ouwei
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: diagaiwei
      type: user
    createdAt: '2023-07-18T09:02:33.000Z'
    data:
      edited: false
      editors:
      - diagaiwei
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.47219082713127136
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b32d2fdb42f0b885810c0d112d45d11d.svg
          fullname: ouwei
          isHf: false
          isPro: false
          name: diagaiwei
          type: user
        html: "<p>Hi I adapted the llama.cpp to run Baichuan13B. Now you can run it\
          \ smoothly on machines with around 12GB RAM without GPU. <a rel=\"nofollow\"\
          \ href=\"https://github.com/ouwei2013/baichuan13b.cpp.git\">https://github.com/ouwei2013/baichuan13b.cpp.git</a>\
          \ The usage is basically the same as llama.cpp. </p>\n<p>\u6211\u6539\u4E86\
          \u4E0Bllama.cpp\u7684\u4EE3\u7801\uFF0C\u73B0\u5728\u5728\u6CA1\u6709gpu\u7684\
          \u673A\u5668\u4E0A\u4E5F\u80FD\u8DD1\u8FD9\u4E2A\u6A21\u578B\u4E86\uFF0C\
          \u53EA\u8981\u673A\u5668\u5185\u5B58\u5927\u4E8E12G\u5E94\u8BE5\u662F\u53EF\
          \u4EE5\u8DD1\u8D77\u6765\u7684\u3002</p>\n"
        raw: "Hi I adapted the llama.cpp to run Baichuan13B. Now you can run it smoothly\
          \ on machines with around 12GB RAM without GPU. https://github.com/ouwei2013/baichuan13b.cpp.git\
          \ The usage is basically the same as llama.cpp. \r\n\r\n\u6211\u6539\u4E86\
          \u4E0Bllama.cpp\u7684\u4EE3\u7801\uFF0C\u73B0\u5728\u5728\u6CA1\u6709gpu\u7684\
          \u673A\u5668\u4E0A\u4E5F\u80FD\u8DD1\u8FD9\u4E2A\u6A21\u578B\u4E86\uFF0C\
          \u53EA\u8981\u673A\u5668\u5185\u5B58\u5927\u4E8E12G\u5E94\u8BE5\u662F\u53EF\
          \u4EE5\u8DD1\u8D77\u6765\u7684\u3002\r\n\r\n"
        updatedAt: '2023-07-18T09:02:33.706Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - williamHL
        - GradientGuru
        - chengfy
    id: 64b655290d4992edf1a0a516
    type: comment
  author: diagaiwei
  content: "Hi I adapted the llama.cpp to run Baichuan13B. Now you can run it smoothly\
    \ on machines with around 12GB RAM without GPU. https://github.com/ouwei2013/baichuan13b.cpp.git\
    \ The usage is basically the same as llama.cpp. \r\n\r\n\u6211\u6539\u4E86\u4E0B\
    llama.cpp\u7684\u4EE3\u7801\uFF0C\u73B0\u5728\u5728\u6CA1\u6709gpu\u7684\u673A\
    \u5668\u4E0A\u4E5F\u80FD\u8DD1\u8FD9\u4E2A\u6A21\u578B\u4E86\uFF0C\u53EA\u8981\
    \u673A\u5668\u5185\u5B58\u5927\u4E8E12G\u5E94\u8BE5\u662F\u53EF\u4EE5\u8DD1\u8D77\
    \u6765\u7684\u3002\r\n\r\n"
  created_at: 2023-07-18 08:02:33+00:00
  edited: false
  hidden: false
  id: 64b655290d4992edf1a0a516
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641414045189abde8cbbd088/P9ChZODyI5f2climsCvZv.png?w=200&h=200&f=face
      fullname: Gradient Guru
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GradientGuru
      type: user
    createdAt: '2023-07-18T13:01:02.000Z'
    data:
      status: closed
    id: 64b68d0e2687500c183ad880
    type: status-change
  author: GradientGuru
  created_at: 2023-07-18 12:01:02+00:00
  id: 64b68d0e2687500c183ad880
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1dc828c0e175b67e92c17b9f2d8064f0.svg
      fullname: lanrenxu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lanrenxu
      type: user
    createdAt: '2023-08-02T07:47:15.000Z'
    data:
      edited: false
      editors:
      - lanrenxu
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.8516524434089661
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1dc828c0e175b67e92c17b9f2d8064f0.svg
          fullname: lanrenxu
          isHf: false
          isPro: false
          name: lanrenxu
          type: user
        html: "<p>llama.cpp\u8DD1\u8FD9\u4E2A\u6A21\u578B\u52A0\u901F\u6BD4\u6709\u591A\
          \u5C11\uFF0C\u6709\u6CA1\u6709\u8BD5\u8FC7fastllm\uFF1F</p>\n"
        raw: "llama.cpp\u8DD1\u8FD9\u4E2A\u6A21\u578B\u52A0\u901F\u6BD4\u6709\u591A\
          \u5C11\uFF0C\u6709\u6CA1\u6709\u8BD5\u8FC7fastllm\uFF1F"
        updatedAt: '2023-08-02T07:47:15.035Z'
      numEdits: 0
      reactions: []
    id: 64ca0a035b62ca163f0e73f8
    type: comment
  author: lanrenxu
  content: "llama.cpp\u8DD1\u8FD9\u4E2A\u6A21\u578B\u52A0\u901F\u6BD4\u6709\u591A\u5C11\
    \uFF0C\u6709\u6CA1\u6709\u8BD5\u8FC7fastllm\uFF1F"
  created_at: 2023-08-02 06:47:15+00:00
  edited: false
  hidden: false
  id: 64ca0a035b62ca163f0e73f8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 19
repo_id: baichuan-inc/Baichuan-13B-Chat
repo_type: model
status: closed
target_branch: null
title: "run the model on a windows machine without GPU / \u5728CPU\u4E0A\u8DD113B "
