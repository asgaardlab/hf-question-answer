!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Tonight223
conflicting_files: null
created_at: 2023-04-18 02:59:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/637f083e2438d7485b8eb942/gO1NL5pquqQS-uGVQ4Sjc.png?w=200&h=200&f=face
      fullname: T-ML
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tonight223
      type: user
    createdAt: '2023-04-18T03:59:11.000Z'
    data:
      edited: false
      editors:
      - Tonight223
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/637f083e2438d7485b8eb942/gO1NL5pquqQS-uGVQ4Sjc.png?w=200&h=200&f=face
          fullname: T-ML
          isHf: false
          isPro: false
          name: Tonight223
          type: user
        html: "<p>This is the content in start-webui-vicuna-gpu.bat file.</p>\n<pre><code><span\
          \ data-props=\"{&quot;user&quot;:&quot;echo&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/echo\">@<span class=\"underline\">echo</span></a></span>\n\
          \n\t</span></span> off\n\n<span data-props=\"{&quot;user&quot;:&quot;echo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/echo\"\
          >@<span class=\"underline\">echo</span></a></span>\n\n\t</span></span> Starting\
          \ the web UI...\n\ncd /D \"%~dp0\"\n\nset MAMBA_ROOT_PREFIX=%cd%\\installer_files\\\
          mamba\nset INSTALL_ENV_DIR=%cd%\\installer_files\\env\n\nif not exist \"\
          %MAMBA_ROOT_PREFIX%\\condabin\\micromamba.bat\" (\n  call \"%MAMBA_ROOT_PREFIX%\\\
          micromamba.exe\" shell hook &gt;nul 2&gt;&amp;1\n)\ncall \"%MAMBA_ROOT_PREFIX%\\\
          condabin\\micromamba.bat\" activate \"%INSTALL_ENV_DIR%\" || ( echo MicroMamba\
          \ hook not found. &amp;&amp; goto end )\ncd text-generation-webui\n\ncall\
          \ python server.py --auto-devices --chat --model gpt4-alpaca-lora-30B-GPTQ-4bit-128g\
          \ --wbits 4 --groupsize 128 --model_type Llama\n\n:end\npause\n</code></pre>\n\
          <p>And it only replys same repeating Russian word again and again, can anyone\
          \ help me to fix it?</p>\n"
        raw: "This is the content in start-webui-vicuna-gpu.bat file.\r\n```\r\n@echo\
          \ off\r\n\r\n@echo Starting the web UI...\r\n\r\ncd /D \"%~dp0\"\r\n\r\n\
          set MAMBA_ROOT_PREFIX=%cd%\\installer_files\\mamba\r\nset INSTALL_ENV_DIR=%cd%\\\
          installer_files\\env\r\n\r\nif not exist \"%MAMBA_ROOT_PREFIX%\\condabin\\\
          micromamba.bat\" (\r\n  call \"%MAMBA_ROOT_PREFIX%\\micromamba.exe\" shell\
          \ hook >nul 2>&1\r\n)\r\ncall \"%MAMBA_ROOT_PREFIX%\\condabin\\micromamba.bat\"\
          \ activate \"%INSTALL_ENV_DIR%\" || ( echo MicroMamba hook not found. &&\
          \ goto end )\r\ncd text-generation-webui\r\n\r\ncall python server.py --auto-devices\
          \ --chat --model gpt4-alpaca-lora-30B-GPTQ-4bit-128g --wbits 4 --groupsize\
          \ 128 --model_type Llama\r\n\r\n:end\r\npause\r\n```\r\nAnd it only replys\
          \ same repeating Russian word again and again, can anyone help me to fix\
          \ it?"
        updatedAt: '2023-04-18T03:59:11.753Z'
      numEdits: 0
      reactions: []
    id: 643e158f7cd64d872cbac144
    type: comment
  author: Tonight223
  content: "This is the content in start-webui-vicuna-gpu.bat file.\r\n```\r\n@echo\
    \ off\r\n\r\n@echo Starting the web UI...\r\n\r\ncd /D \"%~dp0\"\r\n\r\nset MAMBA_ROOT_PREFIX=%cd%\\\
    installer_files\\mamba\r\nset INSTALL_ENV_DIR=%cd%\\installer_files\\env\r\n\r\
    \nif not exist \"%MAMBA_ROOT_PREFIX%\\condabin\\micromamba.bat\" (\r\n  call \"\
    %MAMBA_ROOT_PREFIX%\\micromamba.exe\" shell hook >nul 2>&1\r\n)\r\ncall \"%MAMBA_ROOT_PREFIX%\\\
    condabin\\micromamba.bat\" activate \"%INSTALL_ENV_DIR%\" || ( echo MicroMamba\
    \ hook not found. && goto end )\r\ncd text-generation-webui\r\n\r\ncall python\
    \ server.py --auto-devices --chat --model gpt4-alpaca-lora-30B-GPTQ-4bit-128g\
    \ --wbits 4 --groupsize 128 --model_type Llama\r\n\r\n:end\r\npause\r\n```\r\n\
    And it only replys same repeating Russian word again and again, can anyone help\
    \ me to fix it?"
  created_at: 2023-04-18 02:59:11+00:00
  edited: false
  hidden: false
  id: 643e158f7cd64d872cbac144
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-18T07:31:21.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I didn''t get around to producing a GPTQ file that doesn''t use
          <code>--act-order</code>. Therefore you can''t use the file without updating
          to a more recent version of the GPTQ-for-LLaMa code.  And this code won''t
          run on Windows unless you use WSL2.  </p>

          <p>Try using this file instead, from MetalX''s repository: <a href="https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors">https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors</a></p>

          '
        raw: "I didn't get around to producing a GPTQ file that doesn't use `--act-order`.\
          \ Therefore you can't use the file without updating to a more recent version\
          \ of the GPTQ-for-LLaMa code.  And this code won't run on Windows unless\
          \ you use WSL2.  \n\nTry using this file instead, from MetalX's repository:\
          \ https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors"
        updatedAt: '2023-04-18T07:31:44.117Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Tonight223
    id: 643e47495daab569ee616983
    type: comment
  author: TheBloke
  content: "I didn't get around to producing a GPTQ file that doesn't use `--act-order`.\
    \ Therefore you can't use the file without updating to a more recent version of\
    \ the GPTQ-for-LLaMa code.  And this code won't run on Windows unless you use\
    \ WSL2.  \n\nTry using this file instead, from MetalX's repository: https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors"
  created_at: 2023-04-18 06:31:21+00:00
  edited: true
  hidden: false
  id: 643e47495daab569ee616983
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/58cc1be947c2c84cab25f1dad1146146.svg
      fullname: Theo Miao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KongfuAi
      type: user
    createdAt: '2023-04-22T06:17:29.000Z'
    data:
      edited: false
      editors:
      - KongfuAi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/58cc1be947c2c84cab25f1dad1146146.svg
          fullname: Theo Miao
          isHf: false
          isPro: false
          name: KongfuAi
          type: user
        html: "<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/6434bc3bd55dea2d0ec6b782/wyMPUt9g_o0DbqN3GKxhg.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6434bc3bd55dea2d0ec6b782/wyMPUt9g_o0DbqN3GKxhg.png\"\
          ></a><br>I have the similar problem\uFF0Cshoud i solve it by using the \
          \ MetalX's model(<a href=\"https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors\"\
          >https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors</a>)?</p>\n"
        raw: "![image.png](https://cdn-uploads.huggingface.co/production/uploads/6434bc3bd55dea2d0ec6b782/wyMPUt9g_o0DbqN3GKxhg.png)\n\
          I have the similar problem\uFF0Cshoud i solve it by using the  MetalX's\
          \ model(https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors)?"
        updatedAt: '2023-04-22T06:17:29.646Z'
      numEdits: 0
      reactions: []
    id: 64437bf95298d19c9cf74269
    type: comment
  author: KongfuAi
  content: "![image.png](https://cdn-uploads.huggingface.co/production/uploads/6434bc3bd55dea2d0ec6b782/wyMPUt9g_o0DbqN3GKxhg.png)\n\
    I have the similar problem\uFF0Cshoud i solve it by using the  MetalX's model(https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors)?"
  created_at: 2023-04-22 05:17:29+00:00
  edited: false
  hidden: false
  id: 64437bf95298d19c9cf74269
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-22T06:58:05.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yeah try this file : <a href="https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors">https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors</a></p>

          '
        raw: 'Yeah try this file : https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors'
        updatedAt: '2023-04-22T06:58:05.115Z'
      numEdits: 0
      reactions: []
    id: 6443857d8f795c936df946f6
    type: comment
  author: TheBloke
  content: 'Yeah try this file : https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors'
  created_at: 2023-04-22 05:58:05+00:00
  edited: false
  hidden: false
  id: 6443857d8f795c936df946f6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62fb3c84ce54be18b0949888/AQrrK8Ooh2xKQDGhRyRI3.jpeg?w=200&h=200&f=face
      fullname: Om
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: asach
      type: user
    createdAt: '2023-06-04T14:32:21.000Z'
    data:
      edited: false
      editors:
      - asach
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8302146792411804
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62fb3c84ce54be18b0949888/AQrrK8Ooh2xKQDGhRyRI3.jpeg?w=200&h=200&f=face
          fullname: Om
          isHf: false
          isPro: false
          name: asach
          type: user
        html: '<blockquote>

          <p>I didn''t get around to producing a GPTQ file that doesn''t use <code>--act-order</code>.
          Therefore you can''t use the file without updating to a more recent version
          of the GPTQ-for-LLaMa code.  And this code won''t run on Windows unless
          you use WSL2.  </p>

          <p>Try using this file instead, from MetalX''s repository: <a href="https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors">https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors</a></p>

          </blockquote>

          <p>This worked thanks!</p>

          '
        raw: "> I didn't get around to producing a GPTQ file that doesn't use `--act-order`.\
          \ Therefore you can't use the file without updating to a more recent version\
          \ of the GPTQ-for-LLaMa code.  And this code won't run on Windows unless\
          \ you use WSL2.  \n> \n> Try using this file instead, from MetalX's repository:\
          \ https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors\n\
          \nThis worked thanks!"
        updatedAt: '2023-06-04T14:32:21.032Z'
      numEdits: 0
      reactions: []
    id: 647ca0751c0644de8d2827dd
    type: comment
  author: asach
  content: "> I didn't get around to producing a GPTQ file that doesn't use `--act-order`.\
    \ Therefore you can't use the file without updating to a more recent version of\
    \ the GPTQ-for-LLaMa code.  And this code won't run on Windows unless you use\
    \ WSL2.  \n> \n> Try using this file instead, from MetalX's repository: https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-Int4/blob/main/gpt4-x-alpaca-30b-128g-4bit.safetensors\n\
    \nThis worked thanks!"
  created_at: 2023-06-04 13:32:21+00:00
  edited: false
  hidden: false
  id: 647ca0751c0644de8d2827dd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: TheBloke/gpt4-alpaca-lora-30B-GPTQ
repo_type: model
status: open
target_branch: null
title: gpt4-alpaca-lora-30B-GPTQ-4bit-128g only generate same Russian words
