!!python/object:huggingface_hub.community.DiscussionWithDetails
author: andysalerno
conflicting_files: null
created_at: 2023-04-17 01:56:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bf22d0ded3407be69886f53de96d3f46.svg
      fullname: andy s
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andysalerno
      type: user
    createdAt: '2023-04-17T02:56:52.000Z'
    data:
      edited: false
      editors:
      - andysalerno
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bf22d0ded3407be69886f53de96d3f46.svg
          fullname: andy s
          isHf: false
          isPro: false
          name: andysalerno
          type: user
        html: '<p>Hi, first of all, thank you for the many models you have generated
          and shared!</p>

          <p>Are there any plans to perform the same quantizing for the 13b lora released
          by chansung? I mean this one of these two:</p>

          <p><a href="https://huggingface.co/chansung/gpt4-alpaca-lora-13b">https://huggingface.co/chansung/gpt4-alpaca-lora-13b</a><br><a
          href="https://huggingface.co/chansung/gpt4-alpaca-lora-13b-decapoda-1024">https://huggingface.co/chansung/gpt4-alpaca-lora-13b-decapoda-1024</a></p>

          <p>I''m asking because this model (TheBloke/gpt4-alpaca-lora-30B-GPTQ-4bit-128g)
          is the best one I have used so far, and I''ve used many :D But unfortunately
          it only fits on an A5000 instance I am renting, while a 13b version should
          fit on my 3080 12GB.</p>

          <p>Normally I hate when internet strangers make a request like "please do
          this thing for me for free!" but you seem to have the resources, so just
          figured I''d ask if this is something you''re planning.</p>

          '
        raw: "Hi, first of all, thank you for the many models you have generated and\
          \ shared!\r\n\r\nAre there any plans to perform the same quantizing for\
          \ the 13b lora released by chansung? I mean this one of these two:\r\n\r\
          \nhttps://huggingface.co/chansung/gpt4-alpaca-lora-13b\r\nhttps://huggingface.co/chansung/gpt4-alpaca-lora-13b-decapoda-1024\r\
          \n\r\nI'm asking because this model (TheBloke/gpt4-alpaca-lora-30B-GPTQ-4bit-128g)\
          \ is the best one I have used so far, and I've used many :D But unfortunately\
          \ it only fits on an A5000 instance I am renting, while a 13b version should\
          \ fit on my 3080 12GB.\r\n\r\nNormally I hate when internet strangers make\
          \ a request like \"please do this thing for me for free!\" but you seem\
          \ to have the resources, so just figured I'd ask if this is something you're\
          \ planning."
        updatedAt: '2023-04-17T02:56:52.909Z'
      numEdits: 0
      reactions: []
    id: 643cb574ae8d93dc39533a2b
    type: comment
  author: andysalerno
  content: "Hi, first of all, thank you for the many models you have generated and\
    \ shared!\r\n\r\nAre there any plans to perform the same quantizing for the 13b\
    \ lora released by chansung? I mean this one of these two:\r\n\r\nhttps://huggingface.co/chansung/gpt4-alpaca-lora-13b\r\
    \nhttps://huggingface.co/chansung/gpt4-alpaca-lora-13b-decapoda-1024\r\n\r\nI'm\
    \ asking because this model (TheBloke/gpt4-alpaca-lora-30B-GPTQ-4bit-128g) is\
    \ the best one I have used so far, and I've used many :D But unfortunately it\
    \ only fits on an A5000 instance I am renting, while a 13b version should fit\
    \ on my 3080 12GB.\r\n\r\nNormally I hate when internet strangers make a request\
    \ like \"please do this thing for me for free!\" but you seem to have the resources,\
    \ so just figured I'd ask if this is something you're planning."
  created_at: 2023-04-17 01:56:52+00:00
  edited: false
  hidden: false
  id: 643cb574ae8d93dc39533a2b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-17T10:28:22.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Hi there. You''re welcome, glad they''ve been helpful.</p>

          <p>I''d be glad to do GPTQs of those. To be honest I hadn''t noticed they''d
          been put up at the same time.</p>

          <p>It will be interesting to see how they compare to the current leaders
          in the 13B field, Vicuna 1.1 and Koala.</p>

          <p>I''ll try to get them up by later today.</p>

          '
        raw: 'Hi there. You''re welcome, glad they''ve been helpful.


          I''d be glad to do GPTQs of those. To be honest I hadn''t noticed they''d
          been put up at the same time.


          It will be interesting to see how they compare to the current leaders in
          the 13B field, Vicuna 1.1 and Koala.


          I''ll try to get them up by later today.'
        updatedAt: '2023-04-17T10:28:22.375Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - andysalerno
    id: 643d1f46af3fe078a398a556
    type: comment
  author: TheBloke
  content: 'Hi there. You''re welcome, glad they''ve been helpful.


    I''d be glad to do GPTQs of those. To be honest I hadn''t noticed they''d been
    put up at the same time.


    It will be interesting to see how they compare to the current leaders in the 13B
    field, Vicuna 1.1 and Koala.


    I''ll try to get them up by later today.'
  created_at: 2023-04-17 09:28:22+00:00
  edited: false
  hidden: false
  id: 643d1f46af3fe078a398a556
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-17T23:09:50.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Here you go! <a href="https://huggingface.co/TheBloke/gpt4-alpaca-lora-13B-GPTQ-4bit-128g">https://huggingface.co/TheBloke/gpt4-alpaca-lora-13B-GPTQ-4bit-128g</a></p>

          '
        raw: Here you go! https://huggingface.co/TheBloke/gpt4-alpaca-lora-13B-GPTQ-4bit-128g
        updatedAt: '2023-04-17T23:09:50.958Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - andysalerno
    id: 643dd1be8249c7c8d10d96b8
    type: comment
  author: TheBloke
  content: Here you go! https://huggingface.co/TheBloke/gpt4-alpaca-lora-13B-GPTQ-4bit-128g
  created_at: 2023-04-17 22:09:50+00:00
  edited: false
  hidden: false
  id: 643dd1be8249c7c8d10d96b8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bf22d0ded3407be69886f53de96d3f46.svg
      fullname: andy s
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andysalerno
      type: user
    createdAt: '2023-04-18T21:25:44.000Z'
    data:
      edited: false
      editors:
      - andysalerno
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bf22d0ded3407be69886f53de96d3f46.svg
          fullname: andy s
          isHf: false
          isPro: false
          name: andysalerno
          type: user
        html: '<p>Thanks, it''s much appreciated :)</p>

          '
        raw: Thanks, it's much appreciated :)
        updatedAt: '2023-04-18T21:25:44.161Z'
      numEdits: 0
      reactions: []
    id: 643f0ad846c418c9c68363c7
    type: comment
  author: andysalerno
  content: Thanks, it's much appreciated :)
  created_at: 2023-04-18 20:25:44+00:00
  edited: false
  hidden: false
  id: 643f0ad846c418c9c68363c7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/bf22d0ded3407be69886f53de96d3f46.svg
      fullname: andy s
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andysalerno
      type: user
    createdAt: '2023-05-03T22:19:39.000Z'
    data:
      status: closed
    id: 6452ddfb3a794b2d9b18bf1e
    type: status-change
  author: andysalerno
  created_at: 2023-05-03 21:19:39+00:00
  id: 6452ddfb3a794b2d9b18bf1e
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TheBloke/gpt4-alpaca-lora-30B-GPTQ
repo_type: model
status: closed
target_branch: null
title: Possibility of 13b weights?
