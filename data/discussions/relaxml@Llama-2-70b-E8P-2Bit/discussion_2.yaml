!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dmiche
conflicting_files: null
created_at: 2023-12-13 20:31:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673387999037-noauth.jpeg?w=200&h=200&f=face
      fullname: Dmitry Chernyak
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dmiche
      type: user
    createdAt: '2023-12-13T20:31:17.000Z'
    data:
      edited: false
      editors:
      - dmiche
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8136047720909119
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673387999037-noauth.jpeg?w=200&h=200&f=face
          fullname: Dmitry Chernyak
          isHf: false
          isPro: false
          name: dmiche
          type: user
        html: '<p>Hi!<br>The model files itself are small and should fit in 24Gb of
          GPU.<br>But if I try the suggested pipeline:</p>

          <p>pipe = pipeline("text-generation", model="relaxml/Llama-2-70b-E8P-2Bit")</p>

          <p>it start to grow the CPU memory till 128Gb and then be killed on OOM.<br>Can
          I avoid this memory allocation?</p>

          '
        raw: "Hi!\r\nThe model files itself are small and should fit in 24Gb of GPU.\r\
          \nBut if I try the suggested pipeline:\r\n\r\npipe = pipeline(\"text-generation\"\
          , model=\"relaxml/Llama-2-70b-E8P-2Bit\")\r\n\r\nit start to grow the CPU\
          \ memory till 128Gb and then be killed on OOM.\r\nCan I avoid this memory\
          \ allocation?"
        updatedAt: '2023-12-13T20:31:17.677Z'
      numEdits: 0
      reactions: []
    id: 657a1495ff53f5227d114e75
    type: comment
  author: dmiche
  content: "Hi!\r\nThe model files itself are small and should fit in 24Gb of GPU.\r\
    \nBut if I try the suggested pipeline:\r\n\r\npipe = pipeline(\"text-generation\"\
    , model=\"relaxml/Llama-2-70b-E8P-2Bit\")\r\n\r\nit start to grow the CPU memory\
    \ till 128Gb and then be killed on OOM.\r\nCan I avoid this memory allocation?"
  created_at: 2023-12-13 20:31:17+00:00
  edited: false
  hidden: false
  id: 657a1495ff53f5227d114e75
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/35298884b7633c67a9bcff0a32d31211.svg
      fullname: Albert
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: at676
      type: user
    createdAt: '2023-12-13T22:34:00.000Z'
    data:
      edited: false
      editors:
      - at676
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9750640392303467
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/35298884b7633c67a9bcff0a32d31211.svg
          fullname: Albert
          isHf: false
          isPro: false
          name: at676
          type: user
        html: '<p>I''m confused, what is this suggested pipeline? I don''t think we
          have any code in our codebase that uses a <code>pipeline()</code> call.
          </p>

          '
        raw: 'I''m confused, what is this suggested pipeline? I don''t think we have
          any code in our codebase that uses a `pipeline()` call. '
        updatedAt: '2023-12-13T22:34:00.249Z'
      numEdits: 0
      reactions: []
    id: 657a31587115d9f26486398c
    type: comment
  author: at676
  content: 'I''m confused, what is this suggested pipeline? I don''t think we have
    any code in our codebase that uses a `pipeline()` call. '
  created_at: 2023-12-13 22:34:00+00:00
  edited: false
  hidden: false
  id: 657a31587115d9f26486398c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673387999037-noauth.jpeg?w=200&h=200&f=face
      fullname: Dmitry Chernyak
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dmiche
      type: user
    createdAt: '2023-12-13T22:39:03.000Z'
    data:
      edited: false
      editors:
      - dmiche
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7034303545951843
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673387999037-noauth.jpeg?w=200&h=200&f=face
          fullname: Dmitry Chernyak
          isHf: false
          isPro: false
          name: dmiche
          type: user
        html: '<p>Hm... "Model card" tab, most right button above "Downloads" chart
          "Use in Transformers" :)</p>

          <p>Do you offer a working example of code?</p>

          '
        raw: 'Hm... "Model card" tab, most right button above "Downloads" chart "Use
          in Transformers" :)


          Do you offer a working example of code?'
        updatedAt: '2023-12-13T22:39:03.655Z'
      numEdits: 0
      reactions: []
    id: 657a3287a5ebdfee3c1fadb2
    type: comment
  author: dmiche
  content: 'Hm... "Model card" tab, most right button above "Downloads" chart "Use
    in Transformers" :)


    Do you offer a working example of code?'
  created_at: 2023-12-13 22:39:03+00:00
  edited: false
  hidden: false
  id: 657a3287a5ebdfee3c1fadb2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/35298884b7633c67a9bcff0a32d31211.svg
      fullname: Albert
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: at676
      type: user
    createdAt: '2023-12-13T22:41:15.000Z'
    data:
      edited: false
      editors:
      - at676
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8201267123222351
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/35298884b7633c67a9bcff0a32d31211.svg
          fullname: Albert
          isHf: false
          isPro: false
          name: at676
          type: user
        html: '<p>Yes, in our github repo <a rel="nofollow" href="https://github.com/Cornell-RelaxML/quip-sharp">https://github.com/Cornell-RelaxML/quip-sharp</a>.
          We use a modified version of the modeling_llama.py file to handle our quantized
          linear layers, which is why calling the default "pipeline" command without
          using our repo will not work.</p>

          '
        raw: Yes, in our github repo https://github.com/Cornell-RelaxML/quip-sharp.
          We use a modified version of the modeling_llama.py file to handle our quantized
          linear layers, which is why calling the default "pipeline" command without
          using our repo will not work.
        updatedAt: '2023-12-13T22:41:15.885Z'
      numEdits: 0
      reactions: []
    id: 657a330b857f942849a92491
    type: comment
  author: at676
  content: Yes, in our github repo https://github.com/Cornell-RelaxML/quip-sharp.
    We use a modified version of the modeling_llama.py file to handle our quantized
    linear layers, which is why calling the default "pipeline" command without using
    our repo will not work.
  created_at: 2023-12-13 22:41:15+00:00
  edited: false
  hidden: false
  id: 657a330b857f942849a92491
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673387999037-noauth.jpeg?w=200&h=200&f=face
      fullname: Dmitry Chernyak
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dmiche
      type: user
    createdAt: '2023-12-13T23:35:15.000Z'
    data:
      edited: false
      editors:
      - dmiche
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.1014813780784607
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673387999037-noauth.jpeg?w=200&h=200&f=face
          fullname: Dmitry Chernyak
          isHf: false
          isPro: false
          name: dmiche
          type: user
        html: '<p>Thank You!</p>

          '
        raw: Thank You!
        updatedAt: '2023-12-13T23:35:15.968Z'
      numEdits: 0
      reactions: []
      relatedEventId: 657a3fb423a7e36930e61320
    id: 657a3fb323a7e36930e61315
    type: comment
  author: dmiche
  content: Thank You!
  created_at: 2023-12-13 23:35:15+00:00
  edited: false
  hidden: false
  id: 657a3fb323a7e36930e61315
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673387999037-noauth.jpeg?w=200&h=200&f=face
      fullname: Dmitry Chernyak
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dmiche
      type: user
    createdAt: '2023-12-13T23:35:16.000Z'
    data:
      status: closed
    id: 657a3fb423a7e36930e61320
    type: status-change
  author: dmiche
  created_at: 2023-12-13 23:35:16+00:00
  id: 657a3fb423a7e36930e61320
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fdfaeb01aedd0e86014de9/UliF1du7InfuCs7RHLiA5.png?w=200&h=200&f=face
      fullname: Ahmed Morsi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eramax
      type: user
    createdAt: '2023-12-15T12:01:36.000Z'
    data:
      edited: false
      editors:
      - eramax
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8798056840896606
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fdfaeb01aedd0e86014de9/UliF1du7InfuCs7RHLiA5.png?w=200&h=200&f=face
          fullname: Ahmed Morsi
          isHf: false
          isPro: false
          name: eramax
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;at676&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/at676\">@<span class=\"\
          underline\">at676</span></a></span>\n\n\t</span></span> , I would appriate\
          \ if you provide us with a colab link for QUIP inference</p>\n"
        raw: '@at676 , I would appriate if you provide us with a colab link for QUIP
          inference'
        updatedAt: '2023-12-15T12:01:36.658Z'
      numEdits: 0
      reactions: []
    id: 657c4020688f1a0f7ed514a0
    type: comment
  author: eramax
  content: '@at676 , I would appriate if you provide us with a colab link for QUIP
    inference'
  created_at: 2023-12-15 12:01:36+00:00
  edited: false
  hidden: false
  id: 657c4020688f1a0f7ed514a0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: relaxml/Llama-2-70b-E8P-2Bit
repo_type: model
status: closed
target_branch: null
title: Out of CPU memory in pipeline
