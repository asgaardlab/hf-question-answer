!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nikokks
conflicting_files: null
created_at: 2022-07-27 09:32:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/644fed911b1db5c497061344a778c881.svg
      fullname: nicolas playe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nikokks
      type: user
    createdAt: '2022-07-27T10:32:09.000Z'
    data:
      edited: false
      editors:
      - nikokks
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/644fed911b1db5c497061344a778c881.svg
          fullname: nicolas playe
          isHf: false
          isPro: false
          name: nikokks
          type: user
        html: '<p>Hello! </p>

          <p>In view of the results which are very impressive, I am a little surprised
          that the best wav2vec2 reference model trained 6 months ago on the CV7.0
          has results comparable to its CER for your WER. is it the WER or the CER
          on your test? I don''t have time to check it myself. </p>

          <p>Have a nice day ! </p>

          <p>see by yourself with these 2 links<br><a rel="nofollow" href="https://paperswithcode.com/sota/speech-recognition-on-common-voice-7-0-german-1">https://paperswithcode.com/sota/speech-recognition-on-common-voice-7-0-german-1</a><br><a
          rel="nofollow" href="https://paperswithcode.com/sota/speech-recognition-on-common-voice-7-0-german?metric=Test%20WER">https://paperswithcode.com/sota/speech-recognition-on-common-voice-7-0-german?metric=Test%20WER</a></p>

          '
        raw: "Hello! \r\n\r\nIn view of the results which are very impressive, I am\
          \ a little surprised that the best wav2vec2 reference model trained 6 months\
          \ ago on the CV7.0 has results comparable to its CER for your WER. is it\
          \ the WER or the CER on your test? I don't have time to check it myself.\
          \ \r\n\r\nHave a nice day ! \r\n\r\nsee by yourself with these 2 links\r\
          \nhttps://paperswithcode.com/sota/speech-recognition-on-common-voice-7-0-german-1\r\
          \nhttps://paperswithcode.com/sota/speech-recognition-on-common-voice-7-0-german?metric=Test%20WER"
        updatedAt: '2022-07-27T10:32:09.018Z'
      numEdits: 0
      reactions: []
    id: 62e11429579bc85f8c1960b1
    type: comment
  author: nikokks
  content: "Hello! \r\n\r\nIn view of the results which are very impressive, I am\
    \ a little surprised that the best wav2vec2 reference model trained 6 months ago\
    \ on the CV7.0 has results comparable to its CER for your WER. is it the WER or\
    \ the CER on your test? I don't have time to check it myself. \r\n\r\nHave a nice\
    \ day ! \r\n\r\nsee by yourself with these 2 links\r\nhttps://paperswithcode.com/sota/speech-recognition-on-common-voice-7-0-german-1\r\
    \nhttps://paperswithcode.com/sota/speech-recognition-on-common-voice-7-0-german?metric=Test%20WER"
  created_at: 2022-07-27 09:32:09+00:00
  edited: false
  hidden: false
  id: 62e11429579bc85f8c1960b1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1649899774659-6254f8e5d21e4cc386b881ad.jpeg?w=200&h=200&f=face
      fullname: Somshubra Majumdar
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: smajumdar94
      type: user
    createdAt: '2022-07-27T17:36:37.000Z'
    data:
      edited: true
      editors:
      - smajumdar94
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1649899774659-6254f8e5d21e4cc386b881ad.jpeg?w=200&h=200&f=face
          fullname: Somshubra Majumdar
          isHf: false
          isPro: false
          name: smajumdar94
          type: user
        html: '<p>The links you provided are for German, though this is the French
          model card. I assume you are asking the question for french - <a rel="nofollow"
          href="https://paperswithcode.com/sota/automatic-speech-recognition-on-mcv-7-0">https://paperswithcode.com/sota/automatic-speech-recognition-on-mcv-7-0</a>
          </p>

          <p>Yes, the results calculated here are WER, not CER. We normally do not
          publish CER scores for languages where WER can be computed. </p>

          <p>There are a few reasons for this - </p>

          <ol>

          <li>This is a Conformer Transducer - Transducer models are much more accurate
          than CTC models in general. Conformer CTC is also more accurate than Wav2Vec
          CTC in nearly all cases.</li>

          <li>These models are jointly trained - note that they train via both MCV
          + MLS French, so it is expected that their overall score on MCV alone is
          superior to a model that was trained on just MCV.</li>

          </ol>

          '
        raw: "The links you provided are for German, though this is the French model\
          \ card. I assume you are asking the question for french - https://paperswithcode.com/sota/automatic-speech-recognition-on-mcv-7-0\
          \ \n\nYes, the results calculated here are WER, not CER. We normally do\
          \ not publish CER scores for languages where WER can be computed. \n\nThere\
          \ are a few reasons for this - \n1) This is a Conformer Transducer - Transducer\
          \ models are much more accurate than CTC models in general. Conformer CTC\
          \ is also more accurate than Wav2Vec CTC in nearly all cases.\n2) These\
          \ models are jointly trained - note that they train via both MCV + MLS French,\
          \ so it is expected that their overall score on MCV alone is superior to\
          \ a model that was trained on just MCV."
        updatedAt: '2022-07-27T18:03:08.412Z'
      numEdits: 4
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - bofenghuang
    id: 62e177a591d6d37b6bfa9b71
    type: comment
  author: smajumdar94
  content: "The links you provided are for German, though this is the French model\
    \ card. I assume you are asking the question for french - https://paperswithcode.com/sota/automatic-speech-recognition-on-mcv-7-0\
    \ \n\nYes, the results calculated here are WER, not CER. We normally do not publish\
    \ CER scores for languages where WER can be computed. \n\nThere are a few reasons\
    \ for this - \n1) This is a Conformer Transducer - Transducer models are much\
    \ more accurate than CTC models in general. Conformer CTC is also more accurate\
    \ than Wav2Vec CTC in nearly all cases.\n2) These models are jointly trained -\
    \ note that they train via both MCV + MLS French, so it is expected that their\
    \ overall score on MCV alone is superior to a model that was trained on just MCV."
  created_at: 2022-07-27 16:36:37+00:00
  edited: true
  hidden: false
  id: 62e177a591d6d37b6bfa9b71
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: nvidia/stt_fr_conformer_transducer_large
repo_type: model
status: open
target_branch: null
title: Would there be confusion between CER and WER on test metrics ?
