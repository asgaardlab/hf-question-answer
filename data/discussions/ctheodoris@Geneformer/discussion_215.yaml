!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nwt
conflicting_files: null
created_at: 2023-08-12 12:06:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64d1b501e9cac0020bdc6eec/2Ay0dhA4JZSMi_p5gWiVV.jpeg?w=200&h=200&f=face
      fullname: wtni-gidle
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nwt
      type: user
    createdAt: '2023-08-12T13:06:04.000Z'
    data:
      edited: false
      editors:
      - nwt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8236340284347534
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64d1b501e9cac0020bdc6eec/2Ay0dhA4JZSMi_p5gWiVV.jpeg?w=200&h=200&f=face
          fullname: wtni-gidle
          isHf: false
          isPro: false
          name: nwt
          type: user
        html: "<p>Thank you for your great work!<br>I am following <a href=\"https://huggingface.co/ctheodoris/Geneformer/blob/main/examples/cell_classification.ipynb\"\
          >https://huggingface.co/ctheodoris/Geneformer/blob/main/examples/cell_classification.ipynb</a>\
          \ for cell classification task, and load the pretrained model according\
          \ to the following code, where the path is replaced by <code>\"Geneformer/\"\
          </code> (the main directory of this repository) :</p>\n<pre><code># reload\
          \ pretrained model\nmodel = BertForSequenceClassification.from_pretrained(\"\
          /path/to/pretrained_model/\", \n                         num_labels=len(organ_label_dict.keys()),\n\
          \                         output_attentions = False,\n                 \
          \        output_hidden_states = False).to(\"cuda\")\n</code></pre>\n<p>As\
          \ far as I know, <code>BertForSequenceClassification</code> uses a linear\
          \ layer on top of the pooling layer. And the pooling layer just takes the\
          \ first token which is the highest ranked gene in this scene. So, the classification\
          \ model defined in this way doesn't use mean pooling of the gene embeddings.\
          \ Is there something wrong with my understanding?<br>Thanks!</p>\n"
        raw: "Thank you for your great work!\r\nI am following https://huggingface.co/ctheodoris/Geneformer/blob/main/examples/cell_classification.ipynb\
          \ for cell classification task, and load the pretrained model according\
          \ to the following code, where the path is replaced by `\"Geneformer/\"\
          ` (the main directory of this repository) :\r\n```\r\n# reload pretrained\
          \ model\r\nmodel = BertForSequenceClassification.from_pretrained(\"/path/to/pretrained_model/\"\
          , \r\n                         num_labels=len(organ_label_dict.keys()),\r\
          \n                         output_attentions = False,\r\n              \
          \           output_hidden_states = False).to(\"cuda\")\r\n```\r\nAs far\
          \ as I know, `BertForSequenceClassification` uses a linear layer on top\
          \ of the pooling layer. And the pooling layer just takes the first token\
          \ which is the highest ranked gene in this scene. So, the classification\
          \ model defined in this way doesn't use mean pooling of the gene embeddings.\
          \ Is there something wrong with my understanding?\r\nThanks!"
        updatedAt: '2023-08-12T13:06:04.626Z'
      numEdits: 0
      reactions: []
    id: 64d783bc763279bb4dcca89e
    type: comment
  author: nwt
  content: "Thank you for your great work!\r\nI am following https://huggingface.co/ctheodoris/Geneformer/blob/main/examples/cell_classification.ipynb\
    \ for cell classification task, and load the pretrained model according to the\
    \ following code, where the path is replaced by `\"Geneformer/\"` (the main directory\
    \ of this repository) :\r\n```\r\n# reload pretrained model\r\nmodel = BertForSequenceClassification.from_pretrained(\"\
    /path/to/pretrained_model/\", \r\n                         num_labels=len(organ_label_dict.keys()),\r\
    \n                         output_attentions = False,\r\n                    \
    \     output_hidden_states = False).to(\"cuda\")\r\n```\r\nAs far as I know, `BertForSequenceClassification`\
    \ uses a linear layer on top of the pooling layer. And the pooling layer just\
    \ takes the first token which is the highest ranked gene in this scene. So, the\
    \ classification model defined in this way doesn't use mean pooling of the gene\
    \ embeddings. Is there something wrong with my understanding?\r\nThanks!"
  created_at: 2023-08-12 12:06:04+00:00
  edited: false
  hidden: false
  id: 64d783bc763279bb4dcca89e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-08-13T23:55:41.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8580108284950256
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>Thank you for your interest in Geneformer! Please refer to the Huggingface
          transformers code for how the sequence (cell) classification works with
          their function in terms of training the classifier and using it for predicting
          the classes in new data. To extract/plot cell embeddings and to perform
          in silico perturbation with the tools in this repository, we use mean pooling
          of the embedding layer specified by the user, averaging the embeddings for
          all the genes in the cell to generate the cell embedding. We use the same
          process whether the model is the pretrained one or a fine-tuned model for
          gene or cell classification. If you prefer, you can use a different method
          for training the cell classifier and then load the fine-tuned model for
          extracting/plotting embeddings or performing in silico perturbation with
          the tools provided in this repository.</p>

          '
        raw: Thank you for your interest in Geneformer! Please refer to the Huggingface
          transformers code for how the sequence (cell) classification works with
          their function in terms of training the classifier and using it for predicting
          the classes in new data. To extract/plot cell embeddings and to perform
          in silico perturbation with the tools in this repository, we use mean pooling
          of the embedding layer specified by the user, averaging the embeddings for
          all the genes in the cell to generate the cell embedding. We use the same
          process whether the model is the pretrained one or a fine-tuned model for
          gene or cell classification. If you prefer, you can use a different method
          for training the cell classifier and then load the fine-tuned model for
          extracting/plotting embeddings or performing in silico perturbation with
          the tools provided in this repository.
        updatedAt: '2023-08-13T23:55:41.870Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64d96d7d620c17bfa0b14a40
    id: 64d96d7d620c17bfa0b14a3f
    type: comment
  author: ctheodoris
  content: Thank you for your interest in Geneformer! Please refer to the Huggingface
    transformers code for how the sequence (cell) classification works with their
    function in terms of training the classifier and using it for predicting the classes
    in new data. To extract/plot cell embeddings and to perform in silico perturbation
    with the tools in this repository, we use mean pooling of the embedding layer
    specified by the user, averaging the embeddings for all the genes in the cell
    to generate the cell embedding. We use the same process whether the model is the
    pretrained one or a fine-tuned model for gene or cell classification. If you prefer,
    you can use a different method for training the cell classifier and then load
    the fine-tuned model for extracting/plotting embeddings or performing in silico
    perturbation with the tools provided in this repository.
  created_at: 2023-08-13 22:55:41+00:00
  edited: false
  hidden: false
  id: 64d96d7d620c17bfa0b14a3f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-08-13T23:55:41.000Z'
    data:
      status: closed
    id: 64d96d7d620c17bfa0b14a40
    type: status-change
  author: ctheodoris
  created_at: 2023-08-13 22:55:41+00:00
  id: 64d96d7d620c17bfa0b14a40
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 215
repo_id: ctheodoris/Geneformer
repo_type: model
status: closed
target_branch: null
title: Questions about the classification model
