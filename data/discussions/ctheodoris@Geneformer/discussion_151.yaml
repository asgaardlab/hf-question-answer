!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lqql
conflicting_files: null
created_at: 2023-08-01 08:24:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ff25cb3c410ff5ef554efdd24f731f5c.svg
      fullname: lu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lqql
      type: user
    createdAt: '2023-08-01T09:24:56.000Z'
    data:
      edited: false
      editors:
      - lqql
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7732394933700562
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ff25cb3c410ff5ef554efdd24f731f5c.svg
          fullname: lu
          isHf: false
          isPro: false
          name: lqql
          type: user
        html: '<p>Dear sir:<br>I am very confused with the code in this section of
          In_silico_perturber:<br>After you have the initial embedding and disease-specific
          embedding and the embedding of the knockout cell, when you calculate the
          embedding shift after the knockout, The cos_sim_values are calculated using
          the average of all embedding values of each batch_size on which a specific
          gene has been knocked out and the embedding of a cell with a specific disease
          state, rather than the embedding of a single gene knocked out cell. Therefore,
          when batch_size=400, this would cause a very obvious logical error. Obviously
          batch_size=1 is correct.<br>I really want to know the detailed parameters
          of perturbation of the code running when executing In_silico_perturbation
          task in the article, please tell me, thank you</p>

          <p>raw code:<br>def cos_sim_shift(original_emb, minibatch_emb, alt_emb,
          perturb_group):<br>    cos = torch.nn.CosineSimilarity(dim=2)<br>    original_emb
          = torch.mean(original_emb,dim=0,keepdim=True)<br>    if perturb_group ==
          False:<br>        original_emb = original_emb[None, :]<br>    origin_v_end
          = cos(original_emb,alt_emb)<br>    perturb_emb = torch.mean(minibatch_emb,dim=1,keepdim=True)   &lt;&lt;&lt;&lt;&lt;<br>    perturb_v_end
          = cos(perturb_emb,alt_emb)<br>    return [(perturb_v_end-origin_v_end).to("cpu")]</p>

          '
        raw: "Dear sir:\r\nI am very confused with the code in this section of In_silico_perturber:\r\
          \nAfter you have the initial embedding and disease-specific embedding and\
          \ the embedding of the knockout cell, when you calculate the embedding shift\
          \ after the knockout, The cos_sim_values are calculated using the average\
          \ of all embedding values of each batch_size on which a specific gene has\
          \ been knocked out and the embedding of a cell with a specific disease state,\
          \ rather than the embedding of a single gene knocked out cell. Therefore,\
          \ when batch_size=400, this would cause a very obvious logical error. Obviously\
          \ batch_size=1 is correct.\r\nI really want to know the detailed parameters\
          \ of perturbation of the code running when executing In_silico_perturbation\
          \ task in the article, please tell me, thank you\r\n\r\nraw code:\r\ndef\
          \ cos_sim_shift(original_emb, minibatch_emb, alt_emb, perturb_group):\r\n\
          \    cos = torch.nn.CosineSimilarity(dim=2)\r\n    original_emb = torch.mean(original_emb,dim=0,keepdim=True)\r\
          \n    if perturb_group == False:\r\n        original_emb = original_emb[None,\
          \ :]\r\n    origin_v_end = cos(original_emb,alt_emb)\r\n    perturb_emb\
          \ = torch.mean(minibatch_emb,dim=1,keepdim=True)   <<<<<\r\n    perturb_v_end\
          \ = cos(perturb_emb,alt_emb)\r\n    return [(perturb_v_end-origin_v_end).to(\"\
          cpu\")]"
        updatedAt: '2023-08-01T09:24:56.414Z'
      numEdits: 0
      reactions: []
    id: 64c8cf68120a85440bfa2b0c
    type: comment
  author: lqql
  content: "Dear sir:\r\nI am very confused with the code in this section of In_silico_perturber:\r\
    \nAfter you have the initial embedding and disease-specific embedding and the\
    \ embedding of the knockout cell, when you calculate the embedding shift after\
    \ the knockout, The cos_sim_values are calculated using the average of all embedding\
    \ values of each batch_size on which a specific gene has been knocked out and\
    \ the embedding of a cell with a specific disease state, rather than the embedding\
    \ of a single gene knocked out cell. Therefore, when batch_size=400, this would\
    \ cause a very obvious logical error. Obviously batch_size=1 is correct.\r\nI\
    \ really want to know the detailed parameters of perturbation of the code running\
    \ when executing In_silico_perturbation task in the article, please tell me, thank\
    \ you\r\n\r\nraw code:\r\ndef cos_sim_shift(original_emb, minibatch_emb, alt_emb,\
    \ perturb_group):\r\n    cos = torch.nn.CosineSimilarity(dim=2)\r\n    original_emb\
    \ = torch.mean(original_emb,dim=0,keepdim=True)\r\n    if perturb_group == False:\r\
    \n        original_emb = original_emb[None, :]\r\n    origin_v_end = cos(original_emb,alt_emb)\r\
    \n    perturb_emb = torch.mean(minibatch_emb,dim=1,keepdim=True)   <<<<<\r\n \
    \   perturb_v_end = cos(perturb_emb,alt_emb)\r\n    return [(perturb_v_end-origin_v_end).to(\"\
    cpu\")]"
  created_at: 2023-08-01 08:24:56+00:00
  edited: false
  hidden: false
  id: 64c8cf68120a85440bfa2b0c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-08-02T09:45:15.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9374024271965027
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>Thank you for your question! We have made some changes to this function
          since you posted this discussion. Please look over the updated code and
          if there is still confusion please feel free re-open this discussion.</p>

          '
        raw: Thank you for your question! We have made some changes to this function
          since you posted this discussion. Please look over the updated code and
          if there is still confusion please feel free re-open this discussion.
        updatedAt: '2023-08-02T09:45:15.922Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64ca25abc58bea735b3f8b35
    id: 64ca25abc58bea735b3f8b34
    type: comment
  author: ctheodoris
  content: Thank you for your question! We have made some changes to this function
    since you posted this discussion. Please look over the updated code and if there
    is still confusion please feel free re-open this discussion.
  created_at: 2023-08-02 08:45:15+00:00
  edited: false
  hidden: false
  id: 64ca25abc58bea735b3f8b34
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-08-02T09:45:15.000Z'
    data:
      status: closed
    id: 64ca25abc58bea735b3f8b35
    type: status-change
  author: ctheodoris
  created_at: 2023-08-02 08:45:15+00:00
  id: 64ca25abc58bea735b3f8b35
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ff25cb3c410ff5ef554efdd24f731f5c.svg
      fullname: lu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lqql
      type: user
    createdAt: '2023-08-03T06:41:51.000Z'
    data:
      edited: false
      editors:
      - lqql
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7931949496269226
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ff25cb3c410ff5ef554efdd24f731f5c.svg
          fullname: lu
          isHf: false
          isPro: false
          name: lqql
          type: user
        html: "<p>Dear sir,<br>You guys are doing a great job.Thank you very much\
          \ for your reply.<br>Some adjustments have been made to the code, but the\
          \ previous problems still exist, perhaps because I did not explain them\
          \ in detail, so I will write down the detailed problems:<br>I'm going to\
          \ use some variables in your code to explain, original_emb refers to the\
          \ average embedding of the initial cell state. minibatch_emb is the batch\
          \ size embedding with one gene perturbed. state_embs_dict[state] is the\
          \ embedding of each disease state. After obtaining the above data, Then\
          \ you calculate \uFF1A<br>A=cos_sim_shift(state_embs_dict[state], original_emb)<br>B=cos_sim_shift(minibatch_emb,state_embs_dict[state])<br>cos_sims_vs_alt_dict=B-A<br>The\
          \ problem appears in B:<br>When training minibatch_emb, the default size\
          \ of the batch size is 400, so the minibatch_emb you obtain contains a dictionary\
          \ set of embedding after perturbing 400 genes in turn. It is not the same\
          \ as a single embedding dictionary after perturbing a gene. However, when\
          \ calculating the value of B, you average a dictionary set of embedding\
          \ values obtained after perturbing 400 genes, as the corresponding single\
          \ embedding value after perturbing a single gene, your code is here:</p>\n\
          <p>def cos_sim_shift(.........\uFF09<br>        ........</p>\n<pre><code>\
          \    if original_minibatch_lengths is not None:\n        original_emb =\
          \ mean_nonpadding_embs(original_emb, original_minibatch_lengths)\n    #\
          \ else:\n    #     original_emb = torch.mean(original_emb,dim=1,keepdim=True)\n\
          \n    end_emb = torch.unsqueeze(end_emb, 1)\n    origin_v_end = cos(original_emb,\
          \ end_emb)\n    origin_v_end = torch.squeeze(origin_v_end)\nif minibatch_lengths\
          \ is not None:\n    perturb_emb = mean_nonpadding_embs(minibatch_emb, minibatch_lengths)\n\
          else:\n    perturb_emb = torch.mean(minibatch_emb,dim=1,keepdim=True)#&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;please,\
          \ here\n\nperturb_v_end = cos(perturb_emb, end_emb)\nperturb_v_end = torch.squeeze(perturb_v_end)\n\
          return [(perturb_v_end-origin_v_end).to(\"cpu\")]\n</code></pre>\n<p>That\
          \ is to say, your code uses the average of 400 different embedding after\
          \ perturbing a gene as the embedding of a gene, and then use this value\
          \ to calculate the cos_sims_vs_alt_dict after a single perturbed gene.This\
          \ logic only works when the batch size is equal to 1</p>\n<p>In addition,\
          \ I have another question: Is the result of in silico perturbation in the\
          \ paper implemented using this code?I used the same code and data set, but\
          \ the results were very different from those in the article</p>\n"
        raw: "Dear sir,\nYou guys are doing a great job.Thank you very much for your\
          \ reply.\nSome adjustments have been made to the code, but the previous\
          \ problems still exist, perhaps because I did not explain them in detail,\
          \ so I will write down the detailed problems:\nI'm going to use some variables\
          \ in your code to explain, original_emb refers to the average embedding\
          \ of the initial cell state. minibatch_emb is the batch size embedding with\
          \ one gene perturbed. state_embs_dict[state] is the embedding of each disease\
          \ state. After obtaining the above data, Then you calculate \uFF1A\nA=cos_sim_shift(state_embs_dict[state],\
          \ original_emb)\nB=cos_sim_shift(minibatch_emb,state_embs_dict[state])\n\
          cos_sims_vs_alt_dict=B-A\nThe problem appears in B:\nWhen training minibatch_emb,\
          \ the default size of the batch size is 400, so the minibatch_emb you obtain\
          \ contains a dictionary set of embedding after perturbing 400 genes in turn.\
          \ It is not the same as a single embedding dictionary after perturbing a\
          \ gene. However, when calculating the value of B, you average a dictionary\
          \ set of embedding values obtained after perturbing 400 genes, as the corresponding\
          \ single embedding value after perturbing a single gene, your code is here:\n\
          \ndef cos_sim_shift(.........\uFF09\n        ........\n\n        if original_minibatch_lengths\
          \ is not None:\n            original_emb = mean_nonpadding_embs(original_emb,\
          \ original_minibatch_lengths)\n        # else:\n        #     original_emb\
          \ = torch.mean(original_emb,dim=1,keepdim=True)\n\n        end_emb = torch.unsqueeze(end_emb,\
          \ 1)\n        origin_v_end = cos(original_emb, end_emb)\n        origin_v_end\
          \ = torch.squeeze(origin_v_end)\n    if minibatch_lengths is not None:\n\
          \        perturb_emb = mean_nonpadding_embs(minibatch_emb, minibatch_lengths)\n\
          \    else:\n        perturb_emb = torch.mean(minibatch_emb,dim=1,keepdim=True)#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<please,\
          \ here\n\n    perturb_v_end = cos(perturb_emb, end_emb)\n    perturb_v_end\
          \ = torch.squeeze(perturb_v_end)\n    return [(perturb_v_end-origin_v_end).to(\"\
          cpu\")]\n\nThat is to say, your code uses the average of 400 different embedding\
          \ after perturbing a gene as the embedding of a gene, and then use this\
          \ value to calculate the cos_sims_vs_alt_dict after a single perturbed gene.This\
          \ logic only works when the batch size is equal to 1\n\nIn addition, I have\
          \ another question: Is the result of in silico perturbation in the paper\
          \ implemented using this code?I used the same code and data set, but the\
          \ results were very different from those in the article"
        updatedAt: '2023-08-03T06:41:51.271Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64cb4c2f5dd611556276a34e
    id: 64cb4c2f5dd611556276a34d
    type: comment
  author: lqql
  content: "Dear sir,\nYou guys are doing a great job.Thank you very much for your\
    \ reply.\nSome adjustments have been made to the code, but the previous problems\
    \ still exist, perhaps because I did not explain them in detail, so I will write\
    \ down the detailed problems:\nI'm going to use some variables in your code to\
    \ explain, original_emb refers to the average embedding of the initial cell state.\
    \ minibatch_emb is the batch size embedding with one gene perturbed. state_embs_dict[state]\
    \ is the embedding of each disease state. After obtaining the above data, Then\
    \ you calculate \uFF1A\nA=cos_sim_shift(state_embs_dict[state], original_emb)\n\
    B=cos_sim_shift(minibatch_emb,state_embs_dict[state])\ncos_sims_vs_alt_dict=B-A\n\
    The problem appears in B:\nWhen training minibatch_emb, the default size of the\
    \ batch size is 400, so the minibatch_emb you obtain contains a dictionary set\
    \ of embedding after perturbing 400 genes in turn. It is not the same as a single\
    \ embedding dictionary after perturbing a gene. However, when calculating the\
    \ value of B, you average a dictionary set of embedding values obtained after\
    \ perturbing 400 genes, as the corresponding single embedding value after perturbing\
    \ a single gene, your code is here:\n\ndef cos_sim_shift(.........\uFF09\n   \
    \     ........\n\n        if original_minibatch_lengths is not None:\n       \
    \     original_emb = mean_nonpadding_embs(original_emb, original_minibatch_lengths)\n\
    \        # else:\n        #     original_emb = torch.mean(original_emb,dim=1,keepdim=True)\n\
    \n        end_emb = torch.unsqueeze(end_emb, 1)\n        origin_v_end = cos(original_emb,\
    \ end_emb)\n        origin_v_end = torch.squeeze(origin_v_end)\n    if minibatch_lengths\
    \ is not None:\n        perturb_emb = mean_nonpadding_embs(minibatch_emb, minibatch_lengths)\n\
    \    else:\n        perturb_emb = torch.mean(minibatch_emb,dim=1,keepdim=True)#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<please,\
    \ here\n\n    perturb_v_end = cos(perturb_emb, end_emb)\n    perturb_v_end = torch.squeeze(perturb_v_end)\n\
    \    return [(perturb_v_end-origin_v_end).to(\"cpu\")]\n\nThat is to say, your\
    \ code uses the average of 400 different embedding after perturbing a gene as\
    \ the embedding of a gene, and then use this value to calculate the cos_sims_vs_alt_dict\
    \ after a single perturbed gene.This logic only works when the batch size is equal\
    \ to 1\n\nIn addition, I have another question: Is the result of in silico perturbation\
    \ in the paper implemented using this code?I used the same code and data set,\
    \ but the results were very different from those in the article"
  created_at: 2023-08-03 05:41:51+00:00
  edited: false
  hidden: false
  id: 64cb4c2f5dd611556276a34d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/ff25cb3c410ff5ef554efdd24f731f5c.svg
      fullname: lu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lqql
      type: user
    createdAt: '2023-08-03T06:41:51.000Z'
    data:
      status: open
    id: 64cb4c2f5dd611556276a34e
    type: status-change
  author: lqql
  created_at: 2023-08-03 05:41:51+00:00
  id: 64cb4c2f5dd611556276a34e
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-08-03T15:21:33.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9111920595169067
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: "<p>Thank you for following up!</p>\n<p>For the line you are asking\
          \ about:<br>perturb_emb = torch.mean(minibatch_emb,dim=1,keepdim=True)</p>\n\
          <p>This line averages the embedding in the 1st dimension (the gene dimension)\
          \ to result in a tensor of dimensions (batch_size, 1, number_embedding_dimensions).\
          \ So, it\u2019s not averaging in the batch dimension. You can try adding\
          \ print statements to print the size of the tensor minibatch_emb before\
          \ this line and perturb_emb after this line to help you visualize the dimensions.</p>\n\
          <p>Regarding your other question, we did not have the code packaged into\
          \ modules like this when running the initial analyses in the manuscript\
          \ but directly converted the initial code to the modules here so that it\
          \ would be easier for others to use. In order to help you troubleshoot,\
          \ we would need to know the specific analysis you are trying to run and\
          \ the specific arguments you used to set it up. Please let us know so we\
          \ can help pinpoint if it is being set up in a way that is the same or different\
          \ from the analysis you are trying to repeat from the manuscript.</p>\n"
        raw: "Thank you for following up!\n\nFor the line you are asking about:\n\
          perturb_emb = torch.mean(minibatch_emb,dim=1,keepdim=True)\n\nThis line\
          \ averages the embedding in the 1st dimension (the gene dimension) to result\
          \ in a tensor of dimensions (batch_size, 1, number_embedding_dimensions).\
          \ So, it\u2019s not averaging in the batch dimension. You can try adding\
          \ print statements to print the size of the tensor minibatch_emb before\
          \ this line and perturb_emb after this line to help you visualize the dimensions.\n\
          \nRegarding your other question, we did not have the code packaged into\
          \ modules like this when running the initial analyses in the manuscript\
          \ but directly converted the initial code to the modules here so that it\
          \ would be easier for others to use. In order to help you troubleshoot,\
          \ we would need to know the specific analysis you are trying to run and\
          \ the specific arguments you used to set it up. Please let us know so we\
          \ can help pinpoint if it is being set up in a way that is the same or different\
          \ from the analysis you are trying to repeat from the manuscript."
        updatedAt: '2023-08-03T15:21:33.449Z'
      numEdits: 0
      reactions: []
    id: 64cbc5fd4dcdaead7a119715
    type: comment
  author: ctheodoris
  content: "Thank you for following up!\n\nFor the line you are asking about:\nperturb_emb\
    \ = torch.mean(minibatch_emb,dim=1,keepdim=True)\n\nThis line averages the embedding\
    \ in the 1st dimension (the gene dimension) to result in a tensor of dimensions\
    \ (batch_size, 1, number_embedding_dimensions). So, it\u2019s not averaging in\
    \ the batch dimension. You can try adding print statements to print the size of\
    \ the tensor minibatch_emb before this line and perturb_emb after this line to\
    \ help you visualize the dimensions.\n\nRegarding your other question, we did\
    \ not have the code packaged into modules like this when running the initial analyses\
    \ in the manuscript but directly converted the initial code to the modules here\
    \ so that it would be easier for others to use. In order to help you troubleshoot,\
    \ we would need to know the specific analysis you are trying to run and the specific\
    \ arguments you used to set it up. Please let us know so we can help pinpoint\
    \ if it is being set up in a way that is the same or different from the analysis\
    \ you are trying to repeat from the manuscript."
  created_at: 2023-08-03 14:21:33+00:00
  edited: false
  hidden: false
  id: 64cbc5fd4dcdaead7a119715
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ff25cb3c410ff5ef554efdd24f731f5c.svg
      fullname: lu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lqql
      type: user
    createdAt: '2023-08-09T03:43:11.000Z'
    data:
      edited: false
      editors:
      - lqql
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9798493385314941
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ff25cb3c410ff5ef554efdd24f731f5c.svg
          fullname: lu
          isHf: false
          isPro: false
          name: lqql
          type: user
        html: '<p>Thank you very much for your patient reply. I recently worked on
          replicating your work( in-silico-pertubation) several times, using the pre-trained
          model you uploaded, the human_dcm_hcm_nf dataset, and the newly uploaded
          in-silico-pertubation code. However, there is a big difference between the
          results I obtained and the bias value after gene perturbed in the article.
          I would like to know the reason. I will send the results to your email,
          thank you.</p>

          '
        raw: Thank you very much for your patient reply. I recently worked on replicating
          your work( in-silico-pertubation) several times, using the pre-trained model
          you uploaded, the human_dcm_hcm_nf dataset, and the newly uploaded in-silico-pertubation
          code. However, there is a big difference between the results I obtained
          and the bias value after gene perturbed in the article. I would like to
          know the reason. I will send the results to your email, thank you.
        updatedAt: '2023-08-09T03:43:11.850Z'
      numEdits: 0
      reactions: []
    id: 64d30b4f6975d681476e5682
    type: comment
  author: lqql
  content: Thank you very much for your patient reply. I recently worked on replicating
    your work( in-silico-pertubation) several times, using the pre-trained model you
    uploaded, the human_dcm_hcm_nf dataset, and the newly uploaded in-silico-pertubation
    code. However, there is a big difference between the results I obtained and the
    bias value after gene perturbed in the article. I would like to know the reason.
    I will send the results to your email, thank you.
  created_at: 2023-08-09 02:43:11+00:00
  edited: false
  hidden: false
  id: 64d30b4f6975d681476e5682
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-08-09T05:02:28.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9706231951713562
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>Thank you for following up! As mentioned previously, in order to
          help you troubleshoot, we would need to know the specific analysis you are
          trying to run and the specific arguments you used to set it up. In your
          last comment, you mentioned you used the pretrained model for your analysis.
          We used a fine-tuned model for cardiomyopathy to perform the analyses relevant
          to the dataset you mentioned, so this would be one important difference.
          There could be others, but we would need to know the specifics of what you
          are trying to do and how you are trying to do it to help you troubleshoot.
          </p>

          '
        raw: 'Thank you for following up! As mentioned previously, in order to help
          you troubleshoot, we would need to know the specific analysis you are trying
          to run and the specific arguments you used to set it up. In your last comment,
          you mentioned you used the pretrained model for your analysis. We used a
          fine-tuned model for cardiomyopathy to perform the analyses relevant to
          the dataset you mentioned, so this would be one important difference. There
          could be others, but we would need to know the specifics of what you are
          trying to do and how you are trying to do it to help you troubleshoot. '
        updatedAt: '2023-08-09T05:02:28.514Z'
      numEdits: 0
      reactions: []
    id: 64d31de41940119cff2aec38
    type: comment
  author: ctheodoris
  content: 'Thank you for following up! As mentioned previously, in order to help
    you troubleshoot, we would need to know the specific analysis you are trying to
    run and the specific arguments you used to set it up. In your last comment, you
    mentioned you used the pretrained model for your analysis. We used a fine-tuned
    model for cardiomyopathy to perform the analyses relevant to the dataset you mentioned,
    so this would be one important difference. There could be others, but we would
    need to know the specifics of what you are trying to do and how you are trying
    to do it to help you troubleshoot. '
  created_at: 2023-08-09 04:02:28+00:00
  edited: false
  hidden: false
  id: 64d31de41940119cff2aec38
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-09-18T07:30:10.000Z'
    data:
      status: closed
    id: 6507fc823fc966d1bbb802c5
    type: status-change
  author: ctheodoris
  created_at: 2023-09-18 06:30:10+00:00
  id: 6507fc823fc966d1bbb802c5
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 151
repo_id: ctheodoris/Geneformer
repo_type: model
status: closed
target_branch: null
title: I am very confused with the code in this section of In_silico_perturber
