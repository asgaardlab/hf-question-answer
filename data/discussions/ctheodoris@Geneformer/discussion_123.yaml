!!python/object:huggingface_hub.community.DiscussionWithDetails
author: abayegan
conflicting_files: null
created_at: 2023-07-17 19:15:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4447541e01b9f8594991e40972ba08ac.svg
      fullname: Amir Bayegan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abayegan
      type: user
    createdAt: '2023-07-17T20:15:52.000Z'
    data:
      edited: false
      editors:
      - abayegan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9401365518569946
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4447541e01b9f8594991e40972ba08ac.svg
          fullname: Amir Bayegan
          isHf: false
          isPro: false
          name: abayegan
          type: user
        html: '<p>Thanks for the valuable work and prompt responses in the discussion!<br>I
          was wondering if you have any suggestions for fine-tuning the model on real
          perturbation data? Is the current architecture suitable for simultaneous
          training on control and perturbed? or alternatively do you suggest computing
          features from each condition separately and build a model on top of that?
          or maybe any other ideas?</p>

          '
        raw: "Thanks for the valuable work and prompt responses in the discussion!\
          \ \r\nI was wondering if you have any suggestions for fine-tuning the model\
          \ on real perturbation data? Is the current architecture suitable for simultaneous\
          \ training on control and perturbed? or alternatively do you suggest computing\
          \ features from each condition separately and build a model on top of that?\
          \ or maybe any other ideas?"
        updatedAt: '2023-07-17T20:15:52.264Z'
      numEdits: 0
      reactions: []
    id: 64b5a178afa7fff6134fc8b6
    type: comment
  author: abayegan
  content: "Thanks for the valuable work and prompt responses in the discussion! \r\
    \nI was wondering if you have any suggestions for fine-tuning the model on real\
    \ perturbation data? Is the current architecture suitable for simultaneous training\
    \ on control and perturbed? or alternatively do you suggest computing features\
    \ from each condition separately and build a model on top of that? or maybe any\
    \ other ideas?"
  created_at: 2023-07-17 19:15:52+00:00
  edited: false
  hidden: false
  id: 64b5a178afa7fff6134fc8b6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-07-18T08:22:59.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9478074312210083
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>Thank you for your interest in Geneformer! You can definitely train
          on multiple cell states. It depends on your scientific question but one
          way to approach it would be to fine-tune the model to distinguish between
          the control and perturbed states and then perform in silico perturbations
          to identify genes that are predicted to move genes from one state to the
          other.</p>

          '
        raw: Thank you for your interest in Geneformer! You can definitely train on
          multiple cell states. It depends on your scientific question but one way
          to approach it would be to fine-tune the model to distinguish between the
          control and perturbed states and then perform in silico perturbations to
          identify genes that are predicted to move genes from one state to the other.
        updatedAt: '2023-07-18T08:22:59.349Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64b64be3c6238180931e4e7c
    id: 64b64be3c6238180931e4e79
    type: comment
  author: ctheodoris
  content: Thank you for your interest in Geneformer! You can definitely train on
    multiple cell states. It depends on your scientific question but one way to approach
    it would be to fine-tune the model to distinguish between the control and perturbed
    states and then perform in silico perturbations to identify genes that are predicted
    to move genes from one state to the other.
  created_at: 2023-07-18 07:22:59+00:00
  edited: false
  hidden: false
  id: 64b64be3c6238180931e4e79
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-07-18T08:22:59.000Z'
    data:
      status: closed
    id: 64b64be3c6238180931e4e7c
    type: status-change
  author: ctheodoris
  created_at: 2023-07-18 07:22:59+00:00
  id: 64b64be3c6238180931e4e7c
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4447541e01b9f8594991e40972ba08ac.svg
      fullname: Amir Bayegan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abayegan
      type: user
    createdAt: '2023-07-18T13:39:14.000Z'
    data:
      edited: false
      editors:
      - abayegan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9697293639183044
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4447541e01b9f8594991e40972ba08ac.svg
          fullname: Amir Bayegan
          isHf: false
          isPro: false
          name: abayegan
          type: user
        html: '<p>Thanks, training on multiple states is a great Suggestion and fits
          my purpose! Do you already have tutorial for training on different cell
          states? How do you suggest approaching that?</p>

          '
        raw: Thanks, training on multiple states is a great Suggestion and fits my
          purpose! Do you already have tutorial for training on different cell states?
          How do you suggest approaching that?
        updatedAt: '2023-07-18T13:39:14.597Z'
      numEdits: 0
      reactions: []
    id: 64b69602ce95149b1205befe
    type: comment
  author: abayegan
  content: Thanks, training on multiple states is a great Suggestion and fits my purpose!
    Do you already have tutorial for training on different cell states? How do you
    suggest approaching that?
  created_at: 2023-07-18 12:39:14+00:00
  edited: false
  hidden: false
  id: 64b69602ce95149b1205befe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-07-18T13:47:27.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8928310871124268
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>We strongly recommend hyperparameter tuning for fine-tuning, so
          the best example to follow would be the one for disease classification,
          but substituting the normal vs. disease states with your cell states of
          interest.</p>

          '
        raw: We strongly recommend hyperparameter tuning for fine-tuning, so the best
          example to follow would be the one for disease classification, but substituting
          the normal vs. disease states with your cell states of interest.
        updatedAt: '2023-07-18T13:47:27.456Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - abayegan
    id: 64b697effa499026d33b8501
    type: comment
  author: ctheodoris
  content: We strongly recommend hyperparameter tuning for fine-tuning, so the best
    example to follow would be the one for disease classification, but substituting
    the normal vs. disease states with your cell states of interest.
  created_at: 2023-07-18 12:47:27+00:00
  edited: false
  hidden: false
  id: 64b697effa499026d33b8501
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 123
repo_id: ctheodoris/Geneformer
repo_type: model
status: closed
target_branch: null
title: Fine-tuning on actual perturbation data
