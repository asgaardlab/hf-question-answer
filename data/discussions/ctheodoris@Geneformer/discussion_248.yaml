!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mehrdadorm
conflicting_files: null
created_at: 2023-09-18 15:12:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/80930b2404acdd7366cda7b1d10a2a9d.svg
      fullname: Mehrab Bari
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mehrdadorm
      type: user
    createdAt: '2023-09-18T16:12:51.000Z'
    data:
      edited: false
      editors:
      - mehrdadorm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7314066886901855
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/80930b2404acdd7366cda7b1d10a2a9d.svg
          fullname: Mehrab Bari
          isHf: false
          isPro: false
          name: mehrdadorm
          type: user
        html: '<p>Hello,</p>

          <p>I have GPUs with 40 GB of memory; however, running the codes shows me
          out of memory error after using 28 out of 40 GB of GPU memory. Any thoughts?
          </p>

          <p> <code>isp.perturb_data("/Geneformer/fine_tuned_models/geneformer-6L-30M_CellClassifier_cardiomyopathies_220224",                  "/Geneformer/Genecorpus-30M/example_input_files/cell_classification/disease_classification/human_dcm_hcm_nf.dataset",                  "/Geneformer/Results/example_input_file/cell_classification/test_silico_all",                  "test_perturbation")</code></p>

          <p><code>OutOfMemoryError: CUDA out of memory. Tried to allocate 25.00 GiB
          (GPU 0; 39.56 GiB total capacity; 28.19 GiB already allocated; 10.81 GiB
          free; 28.20 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt;
          allocated memory try setting max_split_size_mb to avoid fragmentation.  See
          documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF </code></p>

          '
        raw: "Hello,\r\n\r\nI have GPUs with 40 GB of memory; however, running the\
          \ codes shows me out of memory error after using 28 out of 40 GB of GPU\
          \ memory. Any thoughts? \r\n\r\n `isp.perturb_data(\"/Geneformer/fine_tuned_models/geneformer-6L-30M_CellClassifier_cardiomyopathies_220224\"\
          ,\r\n                 \"/Geneformer/Genecorpus-30M/example_input_files/cell_classification/disease_classification/human_dcm_hcm_nf.dataset\"\
          ,\r\n                 \"/Geneformer/Results/example_input_file/cell_classification/test_silico_all\"\
          ,\r\n                 \"test_perturbation\")`\r\n\r\n`OutOfMemoryError:\
          \ CUDA out of memory. Tried to allocate 25.00 GiB (GPU 0; 39.56 GiB total\
          \ capacity; 28.19 GiB already allocated; 10.81 GiB free; 28.20 GiB reserved\
          \ in total by PyTorch) If reserved memory is >> allocated memory try setting\
          \ max_split_size_mb to avoid fragmentation.  See documentation for Memory\
          \ Management and PYTORCH_CUDA_ALLOC_CONF\r\n`\r\n"
        updatedAt: '2023-09-18T16:12:51.672Z'
      numEdits: 0
      reactions: []
    id: 65087703c9aa376f7697e533
    type: comment
  author: mehrdadorm
  content: "Hello,\r\n\r\nI have GPUs with 40 GB of memory; however, running the codes\
    \ shows me out of memory error after using 28 out of 40 GB of GPU memory. Any\
    \ thoughts? \r\n\r\n `isp.perturb_data(\"/Geneformer/fine_tuned_models/geneformer-6L-30M_CellClassifier_cardiomyopathies_220224\"\
    ,\r\n                 \"/Geneformer/Genecorpus-30M/example_input_files/cell_classification/disease_classification/human_dcm_hcm_nf.dataset\"\
    ,\r\n                 \"/Geneformer/Results/example_input_file/cell_classification/test_silico_all\"\
    ,\r\n                 \"test_perturbation\")`\r\n\r\n`OutOfMemoryError: CUDA out\
    \ of memory. Tried to allocate 25.00 GiB (GPU 0; 39.56 GiB total capacity; 28.19\
    \ GiB already allocated; 10.81 GiB free; 28.20 GiB reserved in total by PyTorch)\
    \ If reserved memory is >> allocated memory try setting max_split_size_mb to avoid\
    \ fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\r\
    \n`\r\n"
  created_at: 2023-09-18 15:12:51+00:00
  edited: false
  hidden: false
  id: 65087703c9aa376f7697e533
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-09-18T18:13:04.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8369372487068176
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>Thank you for your interest in Geneformer! If encountering memory
          limitations, you should successively reduce the batch size until the analysis
          fits on the GPU so you choose the largest one possible without encountering
          memory limitations. The data is sorted to encounter memory constraints earlier
          so the batch size you determine should work for the remainder of the analysis.
          Of note, you should completely reset the analysis (e.g. restart kernel if
          using notebook) if you ever encounter an error to ensure the GPU is fully
          emptied and the code is not loading the model onto the GPU multiple times.</p>

          '
        raw: Thank you for your interest in Geneformer! If encountering memory limitations,
          you should successively reduce the batch size until the analysis fits on
          the GPU so you choose the largest one possible without encountering memory
          limitations. The data is sorted to encounter memory constraints earlier
          so the batch size you determine should work for the remainder of the analysis.
          Of note, you should completely reset the analysis (e.g. restart kernel if
          using notebook) if you ever encounter an error to ensure the GPU is fully
          emptied and the code is not loading the model onto the GPU multiple times.
        updatedAt: '2023-09-18T18:13:04.789Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65089330d95f30b9dcb609c1
    id: 65089330d95f30b9dcb609c0
    type: comment
  author: ctheodoris
  content: Thank you for your interest in Geneformer! If encountering memory limitations,
    you should successively reduce the batch size until the analysis fits on the GPU
    so you choose the largest one possible without encountering memory limitations.
    The data is sorted to encounter memory constraints earlier so the batch size you
    determine should work for the remainder of the analysis. Of note, you should completely
    reset the analysis (e.g. restart kernel if using notebook) if you ever encounter
    an error to ensure the GPU is fully emptied and the code is not loading the model
    onto the GPU multiple times.
  created_at: 2023-09-18 17:13:04+00:00
  edited: false
  hidden: false
  id: 65089330d95f30b9dcb609c0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-09-18T18:13:04.000Z'
    data:
      status: closed
    id: 65089330d95f30b9dcb609c1
    type: status-change
  author: ctheodoris
  created_at: 2023-09-18 17:13:04+00:00
  id: 65089330d95f30b9dcb609c1
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 248
repo_id: ctheodoris/Geneformer
repo_type: model
status: closed
target_branch: null
title: 'OutOfMemoryError: CUDA out of memory. Tried to allocate'
