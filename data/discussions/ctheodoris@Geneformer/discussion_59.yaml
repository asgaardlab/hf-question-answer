!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jingzhuu
conflicting_files: null
created_at: 2023-06-23 18:18:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/93e6288aac5e30f9e667e2e9cab59b94.svg
      fullname: Jing Zhu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jingzhuu
      type: user
    createdAt: '2023-06-23T19:18:35.000Z'
    data:
      edited: true
      editors:
      - jingzhuu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5892319083213806
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/93e6288aac5e30f9e667e2e9cab59b94.svg
          fullname: Jing Zhu
          isHf: false
          isPro: false
          name: jingzhuu
          type: user
        html: '<p>Here is what I do, but I am not really sure if this is correct since
          there is one last decoder layer that transformers the hidden embedding to
          each genes'' predictions. (decoder): Linear(in_features=256, out_features=25426,
          bias=True)</p>

          <pre><code>model = AutoModelForMaskedLM.from_pretrained("ctheodoris/Geneformer")

          model.cls.predictions.decoder = DummyLayer()

          input_ids = torch.Tensor(targets).unsqueeze(1).long()

          attention_mask = torch.ones(input_ids.shape).unsqueeze(1).long()

          label =  torch.ones(input_ids.shape).unsqueeze(1).long()

          pred = model(input_ids=input_ids, attention_mask=attention_mask, labels=label)

          </code></pre>

          <p>I wonder if this is correct.</p>

          '
        raw: 'Here is what I do, but I am not really sure if this is correct since
          there is one last decoder layer that transformers the hidden embedding to
          each genes'' predictions. (decoder): Linear(in_features=256, out_features=25426,
          bias=True)

          ```

          model = AutoModelForMaskedLM.from_pretrained("ctheodoris/Geneformer")

          model.cls.predictions.decoder = DummyLayer()

          input_ids = torch.Tensor(targets).unsqueeze(1).long()

          attention_mask = torch.ones(input_ids.shape).unsqueeze(1).long()

          label =  torch.ones(input_ids.shape).unsqueeze(1).long()

          pred = model(input_ids=input_ids, attention_mask=attention_mask, labels=label)

          ```

          I wonder if this is correct.

          '
        updatedAt: '2023-06-23T19:52:52.852Z'
      numEdits: 1
      reactions: []
    id: 6495f00b8ae472866106f7f3
    type: comment
  author: jingzhuu
  content: 'Here is what I do, but I am not really sure if this is correct since there
    is one last decoder layer that transformers the hidden embedding to each genes''
    predictions. (decoder): Linear(in_features=256, out_features=25426, bias=True)

    ```

    model = AutoModelForMaskedLM.from_pretrained("ctheodoris/Geneformer")

    model.cls.predictions.decoder = DummyLayer()

    input_ids = torch.Tensor(targets).unsqueeze(1).long()

    attention_mask = torch.ones(input_ids.shape).unsqueeze(1).long()

    label =  torch.ones(input_ids.shape).unsqueeze(1).long()

    pred = model(input_ids=input_ids, attention_mask=attention_mask, labels=label)

    ```

    I wonder if this is correct.

    '
  created_at: 2023-06-23 18:18:35+00:00
  edited: true
  hidden: false
  id: 6495f00b8ae472866106f7f3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-06-23T22:59:41.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8235058188438416
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>Thank you for your interest in Geneformer! I am not completely certain
          what you are trying to do, but Huggingface has helpful and comprehensive
          documentation regarding how to interact with model outputs (e.g. <a href="https://huggingface.co/docs/transformers/main_classes/output">https://huggingface.co/docs/transformers/main_classes/output</a>)</p>

          <p>You could also check the code in this repository in the example notebooks
          for classification, which output model predictions, and in the in silico
          perturber module, which extracts gene embeddings. For example, extracting
          gene embeddings could be accomplished with something along the lines of:</p>

          <p>model = BertForMaskedLM.from_pretrained(/path/to/Geneformer, output_hidden_states=True,
          output_attentions=False)</p>

          <p>with torch.no_grad():<br>    outputs = model(input_ids = input_data.to("cuda"))</p>

          <p>embeddings = outputs.hidden_states[embedding_layer_to_extract]</p>

          '
        raw: "Thank you for your interest in Geneformer! I am not completely certain\
          \ what you are trying to do, but Huggingface has helpful and comprehensive\
          \ documentation regarding how to interact with model outputs (e.g. https://huggingface.co/docs/transformers/main_classes/output)\n\
          \nYou could also check the code in this repository in the example notebooks\
          \ for classification, which output model predictions, and in the in silico\
          \ perturber module, which extracts gene embeddings. For example, extracting\
          \ gene embeddings could be accomplished with something along the lines of:\n\
          \nmodel = BertForMaskedLM.from_pretrained(/path/to/Geneformer, output_hidden_states=True,\
          \ output_attentions=False)\n\nwith torch.no_grad():\n\toutputs = model(input_ids\
          \ = input_data.to(\"cuda\"))\n            \nembeddings = outputs.hidden_states[embedding_layer_to_extract]"
        updatedAt: '2023-06-23T22:59:41.810Z'
      numEdits: 0
      reactions: []
      relatedEventId: 649623dd8092031386906471
    id: 649623dd809203138690646e
    type: comment
  author: ctheodoris
  content: "Thank you for your interest in Geneformer! I am not completely certain\
    \ what you are trying to do, but Huggingface has helpful and comprehensive documentation\
    \ regarding how to interact with model outputs (e.g. https://huggingface.co/docs/transformers/main_classes/output)\n\
    \nYou could also check the code in this repository in the example notebooks for\
    \ classification, which output model predictions, and in the in silico perturber\
    \ module, which extracts gene embeddings. For example, extracting gene embeddings\
    \ could be accomplished with something along the lines of:\n\nmodel = BertForMaskedLM.from_pretrained(/path/to/Geneformer,\
    \ output_hidden_states=True, output_attentions=False)\n\nwith torch.no_grad():\n\
    \toutputs = model(input_ids = input_data.to(\"cuda\"))\n            \nembeddings\
    \ = outputs.hidden_states[embedding_layer_to_extract]"
  created_at: 2023-06-23 21:59:41+00:00
  edited: false
  hidden: false
  id: 649623dd809203138690646e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-06-23T22:59:41.000Z'
    data:
      status: closed
    id: 649623dd8092031386906471
    type: status-change
  author: ctheodoris
  created_at: 2023-06-23 21:59:41+00:00
  id: 649623dd8092031386906471
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 59
repo_id: ctheodoris/Geneformer
repo_type: model
status: closed
target_branch: null
title: How to obtain the embeddings for each gene?
