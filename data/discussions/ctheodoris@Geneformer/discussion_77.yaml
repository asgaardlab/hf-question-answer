!!python/object:huggingface_hub.community.DiscussionWithDetails
author: DYXDAVE
conflicting_files: null
created_at: 2023-07-01 01:50:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/58015c33c4c76a3882ea428ae3c3d399.svg
      fullname: Yuxuan Du
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DYXDAVE
      type: user
    createdAt: '2023-07-01T02:50:58.000Z'
    data:
      edited: false
      editors:
      - DYXDAVE
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8849290013313293
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/58015c33c4c76a3882ea428ae3c3d399.svg
          fullname: Yuxuan Du
          isHf: false
          isPro: false
          name: DYXDAVE
          type: user
        html: '<p>Hi, thank you for your model.<br>I''m currently looking the code
          for the cell classification. I''m not sure whether the test dataset was
          used in the code for cell classification. Since the code provided only did
          8:2 cross validation. The variable "eval_dataset=load_from_disk("/path/to/cell_type_test_data.dataset")"
          seems not used in cell classification notebook, it was changed to organ_evalset(which
          is a subset of the training dataset) in the trainer part. So should we use
          the cell_type_test_data.dataset to test the fine-tuned model? </p>

          '
        raw: "Hi, thank you for your model. \r\nI'm currently looking the code for\
          \ the cell classification. I'm not sure whether the test dataset was used\
          \ in the code for cell classification. Since the code provided only did\
          \ 8:2 cross validation. The variable \"eval_dataset=load_from_disk(\"/path/to/cell_type_test_data.dataset\"\
          )\" seems not used in cell classification notebook, it was changed to organ_evalset(which\
          \ is a subset of the training dataset) in the trainer part. So should we\
          \ use the cell_type_test_data.dataset to test the fine-tuned model? "
        updatedAt: '2023-07-01T02:50:58.695Z'
      numEdits: 0
      reactions: []
    id: 649f94929b6e48cd6b46811c
    type: comment
  author: DYXDAVE
  content: "Hi, thank you for your model. \r\nI'm currently looking the code for the\
    \ cell classification. I'm not sure whether the test dataset was used in the code\
    \ for cell classification. Since the code provided only did 8:2 cross validation.\
    \ The variable \"eval_dataset=load_from_disk(\"/path/to/cell_type_test_data.dataset\"\
    )\" seems not used in cell classification notebook, it was changed to organ_evalset(which\
    \ is a subset of the training dataset) in the trainer part. So should we use the\
    \ cell_type_test_data.dataset to test the fine-tuned model? "
  created_at: 2023-07-01 01:50:58+00:00
  edited: false
  hidden: false
  id: 649f94929b6e48cd6b46811c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-07-01T04:18:02.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8838904500007629
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>Thank you for pointing out the unused variable. I updated the notebook
          to remove the unused variable to avoid confusion. The 20% held out data
          was used for evaluating the fine-tuned model for both Geneformer and the
          alternative models. Because we did not optimize hyperparameters for Geneformer
          or the alternative models for this application, we did not require a third
          held out dataset. If you optimize hyperparameters or in any way change the
          training process in response to evaluation results from a validation dataset,
          you must then evaluate the model performance on a third held out test dataset.
          Of note, we strongly recommend optimizing hyperparameters for any new downstream
          application or dataset - we didn''t do so in this case only in order to
          maintain an equivalent comparison between the models.</p>

          '
        raw: Thank you for pointing out the unused variable. I updated the notebook
          to remove the unused variable to avoid confusion. The 20% held out data
          was used for evaluating the fine-tuned model for both Geneformer and the
          alternative models. Because we did not optimize hyperparameters for Geneformer
          or the alternative models for this application, we did not require a third
          held out dataset. If you optimize hyperparameters or in any way change the
          training process in response to evaluation results from a validation dataset,
          you must then evaluate the model performance on a third held out test dataset.
          Of note, we strongly recommend optimizing hyperparameters for any new downstream
          application or dataset - we didn't do so in this case only in order to maintain
          an equivalent comparison between the models.
        updatedAt: '2023-07-01T04:18:02.504Z'
      numEdits: 0
      reactions: []
      relatedEventId: 649fa8fab248aaaa2d1b9256
    id: 649fa8fab248aaaa2d1b9253
    type: comment
  author: ctheodoris
  content: Thank you for pointing out the unused variable. I updated the notebook
    to remove the unused variable to avoid confusion. The 20% held out data was used
    for evaluating the fine-tuned model for both Geneformer and the alternative models.
    Because we did not optimize hyperparameters for Geneformer or the alternative
    models for this application, we did not require a third held out dataset. If you
    optimize hyperparameters or in any way change the training process in response
    to evaluation results from a validation dataset, you must then evaluate the model
    performance on a third held out test dataset. Of note, we strongly recommend optimizing
    hyperparameters for any new downstream application or dataset - we didn't do so
    in this case only in order to maintain an equivalent comparison between the models.
  created_at: 2023-07-01 03:18:02+00:00
  edited: false
  hidden: false
  id: 649fa8fab248aaaa2d1b9253
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-07-01T04:18:02.000Z'
    data:
      status: closed
    id: 649fa8fab248aaaa2d1b9256
    type: status-change
  author: ctheodoris
  created_at: 2023-07-01 03:18:02+00:00
  id: 649fa8fab248aaaa2d1b9256
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/58015c33c4c76a3882ea428ae3c3d399.svg
      fullname: Yuxuan Du
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DYXDAVE
      type: user
    createdAt: '2023-07-03T04:15:18.000Z'
    data:
      edited: false
      editors:
      - DYXDAVE
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9703301787376404
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/58015c33c4c76a3882ea428ae3c3d399.svg
          fullname: Yuxuan Du
          isHf: false
          isPro: false
          name: DYXDAVE
          type: user
        html: '<p>I''m not sure my code was right or not. I fine-tuned my model based
          on train set''s lung cells and use test set to test the model. (I only select
          lung cells that are included in the cell type dict) and found the classification
          isn''t that good. Did you tested the model using the test set? Are the test
          set includes same kinds of lung cells compare with train set? Thanks!</p>

          '
        raw: I'm not sure my code was right or not. I fine-tuned my model based on
          train set's lung cells and use test set to test the model. (I only select
          lung cells that are included in the cell type dict) and found the classification
          isn't that good. Did you tested the model using the test set? Are the test
          set includes same kinds of lung cells compare with train set? Thanks!
        updatedAt: '2023-07-03T04:15:18.221Z'
      numEdits: 0
      reactions: []
    id: 64a24b568f953945fa4e6510
    type: comment
  author: DYXDAVE
  content: I'm not sure my code was right or not. I fine-tuned my model based on train
    set's lung cells and use test set to test the model. (I only select lung cells
    that are included in the cell type dict) and found the classification isn't that
    good. Did you tested the model using the test set? Are the test set includes same
    kinds of lung cells compare with train set? Thanks!
  created_at: 2023-07-03 03:15:18+00:00
  edited: false
  hidden: false
  id: 64a24b568f953945fa4e6510
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-07-03T04:32:24.000Z'
    data:
      edited: true
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9672893285751343
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: "<p>Thank you for letting us know - as discussed above, the test set\
          \ used for evaluating our model as well as the alternative approaches was\
          \ the held out 20%. We did not optimize hyperparameters or otherwise change\
          \ the training in response to the results so these cells remained held out\
          \ and separate from the training process for all models. The test set is\
          \ from a separate dataset that may or may not have cells annotated in the\
          \ same way as the first dataset. We did not test our model or others on\
          \ this dataset. </p>\n<p>We performed this cell annotation analysis solely\
          \ as a point of comparison between approaches as it was not a major focus\
          \ for us. If we were to fine-tune an optimal model to annotate lung cells,\
          \ we would use multiple datasets for the training to ensure generalizability,\
          \ optimize hyperparameters to ensure optimal learning, and then evaluate\
          \ on multiple held out datasets. That would ensure the most effective training\
          \ and most robust predictive potential. We would recommend taking that approach\
          \ if you\u2019d like to fine-tune the model for that task. </p>\n"
        raw: "Thank you for letting us know - as discussed above, the test set used\
          \ for evaluating our model as well as the alternative approaches was the\
          \ held out 20%. We did not optimize hyperparameters or otherwise change\
          \ the training in response to the results so these cells remained held out\
          \ and separate from the training process for all models. The test set is\
          \ from a separate dataset that may or may not have cells annotated in the\
          \ same way as the first dataset. We did not test our model or others on\
          \ this dataset. \n\nWe performed this cell annotation analysis solely as\
          \ a point of comparison between approaches as it was not a major focus for\
          \ us. If we were to fine-tune an optimal model to annotate lung cells, we\
          \ would use multiple datasets for the training to ensure generalizability,\
          \ optimize hyperparameters to ensure optimal learning, and then evaluate\
          \ on multiple held out datasets. That would ensure the most effective training\
          \ and most robust predictive potential. We would recommend taking that approach\
          \ if you\u2019d like to fine-tune the model for that task. "
        updatedAt: '2023-07-03T04:33:03.584Z'
      numEdits: 1
      reactions: []
    id: 64a24f58914f0b62e3eef74e
    type: comment
  author: ctheodoris
  content: "Thank you for letting us know - as discussed above, the test set used\
    \ for evaluating our model as well as the alternative approaches was the held\
    \ out 20%. We did not optimize hyperparameters or otherwise change the training\
    \ in response to the results so these cells remained held out and separate from\
    \ the training process for all models. The test set is from a separate dataset\
    \ that may or may not have cells annotated in the same way as the first dataset.\
    \ We did not test our model or others on this dataset. \n\nWe performed this cell\
    \ annotation analysis solely as a point of comparison between approaches as it\
    \ was not a major focus for us. If we were to fine-tune an optimal model to annotate\
    \ lung cells, we would use multiple datasets for the training to ensure generalizability,\
    \ optimize hyperparameters to ensure optimal learning, and then evaluate on multiple\
    \ held out datasets. That would ensure the most effective training and most robust\
    \ predictive potential. We would recommend taking that approach if you\u2019d\
    \ like to fine-tune the model for that task. "
  created_at: 2023-07-03 03:32:24+00:00
  edited: true
  hidden: false
  id: 64a24f58914f0b62e3eef74e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 77
repo_id: ctheodoris/Geneformer
repo_type: model
status: closed
target_branch: null
title: Question about test dataset
