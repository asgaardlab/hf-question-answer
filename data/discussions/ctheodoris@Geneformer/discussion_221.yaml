!!python/object:huggingface_hub.community.DiscussionWithDetails
author: katarinayuan
conflicting_files: null
created_at: 2023-08-16 12:56:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b9e52676a080f9887cff45bfa36dbe70.svg
      fullname: Xinyu Yuan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: katarinayuan
      type: user
    createdAt: '2023-08-16T13:56:11.000Z'
    data:
      edited: false
      editors:
      - katarinayuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9511964321136475
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b9e52676a080f9887cff45bfa36dbe70.svg
          fullname: Xinyu Yuan
          isHf: false
          isPro: false
          name: katarinayuan
          type: user
        html: '<p>Hi, could you please release the data and code for attention weight
          analysis, so that people can reproduce it?</p>

          '
        raw: Hi, could you please release the data and code for attention weight analysis,
          so that people can reproduce it?
        updatedAt: '2023-08-16T13:56:11.627Z'
      numEdits: 0
      reactions: []
    id: 64dcd57b3d9f3fffb590b22e
    type: comment
  author: katarinayuan
  content: Hi, could you please release the data and code for attention weight analysis,
    so that people can reproduce it?
  created_at: 2023-08-16 12:56:11+00:00
  edited: false
  hidden: false
  id: 64dcd57b3d9f3fffb590b22e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-08-23T17:33:57.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8077444434165955
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: "<p>Thank you for your interest in Geneformer! To extract attention\
          \ weights, you can load the model with the function \"load_model\" in the\
          \ in silico perturber with changing output_attentions to True (and also\
          \ you can change output_hidden_states to False to save memory if you are\
          \ not interested in extracting embeddings). For example:</p>\n<pre><code>\
          \    model = BertForMaskedLM.from_pretrained(model_directory, \n       \
          \                                     output_hidden_states=False, \n   \
          \                                         output_attentions=True)\n</code></pre>\n\
          <p>Then, you can extract the attention weights from the output of \"forward_pass_single_cell\"\
          \ in the in silico perturber. </p>\n<p>The data is publicly available -\
          \ please see the reference in the manuscript.</p>\n"
        raw: "Thank you for your interest in Geneformer! To extract attention weights,\
          \ you can load the model with the function \"load_model\" in the in silico\
          \ perturber with changing output_attentions to True (and also you can change\
          \ output_hidden_states to False to save memory if you are not interested\
          \ in extracting embeddings). For example:\n\n        model = BertForMaskedLM.from_pretrained(model_directory,\
          \ \n                                                output_hidden_states=False,\
          \ \n                                                output_attentions=True)\n\
          \nThen, you can extract the attention weights from the output of \"forward_pass_single_cell\"\
          \ in the in silico perturber. \n\nThe data is publicly available - please\
          \ see the reference in the manuscript."
        updatedAt: '2023-08-23T17:33:57.935Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64e64306fb3add2b04d8f4d7
    id: 64e64305fb3add2b04d8f4d4
    type: comment
  author: ctheodoris
  content: "Thank you for your interest in Geneformer! To extract attention weights,\
    \ you can load the model with the function \"load_model\" in the in silico perturber\
    \ with changing output_attentions to True (and also you can change output_hidden_states\
    \ to False to save memory if you are not interested in extracting embeddings).\
    \ For example:\n\n        model = BertForMaskedLM.from_pretrained(model_directory,\
    \ \n                                                output_hidden_states=False,\
    \ \n                                                output_attentions=True)\n\n\
    Then, you can extract the attention weights from the output of \"forward_pass_single_cell\"\
    \ in the in silico perturber. \n\nThe data is publicly available - please see\
    \ the reference in the manuscript."
  created_at: 2023-08-23 16:33:57+00:00
  edited: false
  hidden: false
  id: 64e64305fb3add2b04d8f4d4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-08-23T17:33:58.000Z'
    data:
      status: closed
    id: 64e64306fb3add2b04d8f4d7
    type: status-change
  author: ctheodoris
  created_at: 2023-08-23 16:33:58+00:00
  id: 64e64306fb3add2b04d8f4d7
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 221
repo_id: ctheodoris/Geneformer
repo_type: model
status: closed
target_branch: null
title: Release of Data and Code for Attention Map Analysis
