!!python/object:huggingface_hub.community.DiscussionWithDetails
author: iLOVE2D
conflicting_files: null
created_at: 2023-06-13 02:48:46+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
      fullname: Tianyu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iLOVE2D
      type: user
    createdAt: '2023-06-13T03:48:46.000Z'
    data:
      edited: false
      editors:
      - iLOVE2D
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6050652265548706
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
          fullname: Tianyu
          isHf: false
          isPro: false
          name: iLOVE2D
          type: user
        html: '<p>Hi, I meet an error when using the gene prediction example jupyter
          notebook.</p>

          <p>ValueError: --load_best_model_at_end requires the save and eval strategy
          to match, but found</p>

          <ul>

          <li>Evaluation strategy: no</li>

          <li>Save strategy: steps</li>

          </ul>

          <p>It comes from:<br>Cell In[20], line 110, in cross_validate(data, targets,
          labels, nsplits, subsample_size, training_args, freeze_layers, output_dir,
          num_proc)<br>    108 # add output directory to training args and initiate<br>    109
          training_args["output_dir"] = ksplit_output_dir<br>--&gt; 110 training_args_init
          = TrainingArguments(**training_args)<br>    112 # create the trainer<br>    113
          trainer = Trainer(<br>    114     model=model,<br>    115     args=training_args_init,<br>   (...)<br>    118     eval_dataset=evalset_train_labeled<br>    119
          )</p>

          <p>It seems that the argument is not correct. Could you please address it?
          Thanks a lot.</p>

          '
        raw: "Hi, I meet an error when using the gene prediction example jupyter notebook.\r\
          \n\r\nValueError: --load_best_model_at_end requires the save and eval strategy\
          \ to match, but found\r\n- Evaluation strategy: no\r\n- Save strategy: steps\r\
          \n\r\n\r\nIt comes from:\r\nCell In[20], line 110, in cross_validate(data,\
          \ targets, labels, nsplits, subsample_size, training_args, freeze_layers,\
          \ output_dir, num_proc)\r\n    108 # add output directory to training args\
          \ and initiate\r\n    109 training_args[\"output_dir\"] = ksplit_output_dir\r\
          \n--> 110 training_args_init = TrainingArguments(**training_args)\r\n  \
          \  112 # create the trainer\r\n    113 trainer = Trainer(\r\n    114   \
          \  model=model,\r\n    115     args=training_args_init,\r\n   (...)\r\n\
          \    118     eval_dataset=evalset_train_labeled\r\n    119 )\r\n\r\nIt seems\
          \ that the argument is not correct. Could you please address it? Thanks\
          \ a lot."
        updatedAt: '2023-06-13T03:48:46.779Z'
      numEdits: 0
      reactions: []
    id: 6487e71e61199f7331630016
    type: comment
  author: iLOVE2D
  content: "Hi, I meet an error when using the gene prediction example jupyter notebook.\r\
    \n\r\nValueError: --load_best_model_at_end requires the save and eval strategy\
    \ to match, but found\r\n- Evaluation strategy: no\r\n- Save strategy: steps\r\
    \n\r\n\r\nIt comes from:\r\nCell In[20], line 110, in cross_validate(data, targets,\
    \ labels, nsplits, subsample_size, training_args, freeze_layers, output_dir, num_proc)\r\
    \n    108 # add output directory to training args and initiate\r\n    109 training_args[\"\
    output_dir\"] = ksplit_output_dir\r\n--> 110 training_args_init = TrainingArguments(**training_args)\r\
    \n    112 # create the trainer\r\n    113 trainer = Trainer(\r\n    114     model=model,\r\
    \n    115     args=training_args_init,\r\n   (...)\r\n    118     eval_dataset=evalset_train_labeled\r\
    \n    119 )\r\n\r\nIt seems that the argument is not correct. Could you please\
    \ address it? Thanks a lot."
  created_at: 2023-06-13 02:48:46+00:00
  edited: false
  hidden: false
  id: 6487e71e61199f7331630016
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-06-13T04:34:46.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8905000686645508
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>Can you please tell me what TrainingArguments you are using? Are
          they the same as the ones in the current example notebook? The save strategy
          and evaluation strategy need to match when you set it to load the best model
          in the end. The current example notebook arguments should not have this
          error, but please confirm which ones you are using. Please also see the
          relevant discussion here: <a rel="nofollow" href="https://discuss.huggingface.co/t/save-only-best-model-in-trainer/8442/4">https://discuss.huggingface.co/t/save-only-best-model-in-trainer/8442/4</a></p>

          '
        raw: 'Can you please tell me what TrainingArguments you are using? Are they
          the same as the ones in the current example notebook? The save strategy
          and evaluation strategy need to match when you set it to load the best model
          in the end. The current example notebook arguments should not have this
          error, but please confirm which ones you are using. Please also see the
          relevant discussion here: https://discuss.huggingface.co/t/save-only-best-model-in-trainer/8442/4'
        updatedAt: '2023-06-13T04:34:46.714Z'
      numEdits: 0
      reactions: []
    id: 6487f1e6d50b6328ee3a0489
    type: comment
  author: ctheodoris
  content: 'Can you please tell me what TrainingArguments you are using? Are they
    the same as the ones in the current example notebook? The save strategy and evaluation
    strategy need to match when you set it to load the best model in the end. The
    current example notebook arguments should not have this error, but please confirm
    which ones you are using. Please also see the relevant discussion here: https://discuss.huggingface.co/t/save-only-best-model-in-trainer/8442/4'
  created_at: 2023-06-13 03:34:46+00:00
  edited: false
  hidden: false
  id: 6487f1e6d50b6328ee3a0489
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
      fullname: Tianyu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iLOVE2D
      type: user
    createdAt: '2023-06-13T12:13:25.000Z'
    data:
      edited: true
      editors:
      - iLOVE2D
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6826821565628052
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
          fullname: Tianyu
          isHf: false
          isPro: false
          name: iLOVE2D
          type: user
        html: "<p>Hi, I use same parameters mentioned in: <a href=\"https://huggingface.co/ctheodoris/Geneformer/blob/main/examples/gene_classification.ipynb\"\
          >https://huggingface.co/ctheodoris/Geneformer/blob/main/examples/gene_classification.ipynb</a></p>\n\
          <pre><code># set model parameters\n# max input size\nmax_input_size = 2\
          \ ** 11  # 2048\n\n\n\n# set training parameters\n# max learning rate\n\
          max_lr = 5e-5\n# how many pretrained layers to freeze\nfreeze_layers = 4\n\
          # number gpus\nnum_gpus = 1\n# number cpu cores\nnum_proc = 24\n# batch\
          \ size for training and eval\ngeneformer_batch_size = 12\n# learning schedule\n\
          lr_schedule_fn = \"linear\"\n# warmup steps\nwarmup_steps = 500\n# number\
          \ of epochs\nepochs = 1\n# optimizer\noptimizer = \"adamw\"\n\n# set training\
          \ arguments\nsubsample_size = 10_000\ntraining_args = {\n    \"learning_rate\"\
          : max_lr,\n    \"do_train\": True,\n    \"evaluation_strategy\": \"no\"\
          ,\n    \"logging_steps\": 100,\n    \"group_by_length\": True,\n    \"length_column_name\"\
          : \"length\",\n    \"disable_tqdm\": False,\n    \"lr_scheduler_type\":\
          \ lr_schedule_fn,\n    \"warmup_steps\": warmup_steps,\n    \"weight_decay\"\
          : 0.001,\n    \"per_device_train_batch_size\": geneformer_batch_size,\n\
          \    \"per_device_eval_batch_size\": geneformer_batch_size,\n    \"num_train_epochs\"\
          : epochs,\n    \"load_best_model_at_end\": True,\n}\n</code></pre>\n<p>But\
          \ I still receive this error. Moreover, I do not believe that every notebook\
          \ can run successfully. For example, in this notebook, there is a variable\
          \ which is not defined in ahead but directly used:</p>\n<p>max_sequence_length</p>\n"
        raw: "Hi, I use same parameters mentioned in: https://huggingface.co/ctheodoris/Geneformer/blob/main/examples/gene_classification.ipynb\n\
          \n```\n# set model parameters\n# max input size\nmax_input_size = 2 ** 11\
          \  # 2048\n\n\n\n# set training parameters\n# max learning rate\nmax_lr\
          \ = 5e-5\n# how many pretrained layers to freeze\nfreeze_layers = 4\n# number\
          \ gpus\nnum_gpus = 1\n# number cpu cores\nnum_proc = 24\n# batch size for\
          \ training and eval\ngeneformer_batch_size = 12\n# learning schedule\nlr_schedule_fn\
          \ = \"linear\"\n# warmup steps\nwarmup_steps = 500\n# number of epochs\n\
          epochs = 1\n# optimizer\noptimizer = \"adamw\"\n\n# set training arguments\n\
          subsample_size = 10_000\ntraining_args = {\n    \"learning_rate\": max_lr,\n\
          \    \"do_train\": True,\n    \"evaluation_strategy\": \"no\",\n    \"logging_steps\"\
          : 100,\n    \"group_by_length\": True,\n    \"length_column_name\": \"length\"\
          ,\n    \"disable_tqdm\": False,\n    \"lr_scheduler_type\": lr_schedule_fn,\n\
          \    \"warmup_steps\": warmup_steps,\n    \"weight_decay\": 0.001,\n   \
          \ \"per_device_train_batch_size\": geneformer_batch_size,\n    \"per_device_eval_batch_size\"\
          : geneformer_batch_size,\n    \"num_train_epochs\": epochs,\n    \"load_best_model_at_end\"\
          : True,\n}\n```\nBut I still receive this error. Moreover, I do not believe\
          \ that every notebook can run successfully. For example, in this notebook,\
          \ there is a variable which is not defined in ahead but directly used:\n\
          \nmax_sequence_length"
        updatedAt: '2023-06-13T12:14:23.510Z'
      numEdits: 1
      reactions: []
    id: 64885d65c00cc27be8425eb8
    type: comment
  author: iLOVE2D
  content: "Hi, I use same parameters mentioned in: https://huggingface.co/ctheodoris/Geneformer/blob/main/examples/gene_classification.ipynb\n\
    \n```\n# set model parameters\n# max input size\nmax_input_size = 2 ** 11  # 2048\n\
    \n\n\n# set training parameters\n# max learning rate\nmax_lr = 5e-5\n# how many\
    \ pretrained layers to freeze\nfreeze_layers = 4\n# number gpus\nnum_gpus = 1\n\
    # number cpu cores\nnum_proc = 24\n# batch size for training and eval\ngeneformer_batch_size\
    \ = 12\n# learning schedule\nlr_schedule_fn = \"linear\"\n# warmup steps\nwarmup_steps\
    \ = 500\n# number of epochs\nepochs = 1\n# optimizer\noptimizer = \"adamw\"\n\n\
    # set training arguments\nsubsample_size = 10_000\ntraining_args = {\n    \"learning_rate\"\
    : max_lr,\n    \"do_train\": True,\n    \"evaluation_strategy\": \"no\",\n   \
    \ \"logging_steps\": 100,\n    \"group_by_length\": True,\n    \"length_column_name\"\
    : \"length\",\n    \"disable_tqdm\": False,\n    \"lr_scheduler_type\": lr_schedule_fn,\n\
    \    \"warmup_steps\": warmup_steps,\n    \"weight_decay\": 0.001,\n    \"per_device_train_batch_size\"\
    : geneformer_batch_size,\n    \"per_device_eval_batch_size\": geneformer_batch_size,\n\
    \    \"num_train_epochs\": epochs,\n    \"load_best_model_at_end\": True,\n}\n\
    ```\nBut I still receive this error. Moreover, I do not believe that every notebook\
    \ can run successfully. For example, in this notebook, there is a variable which\
    \ is not defined in ahead but directly used:\n\nmax_sequence_length"
  created_at: 2023-06-13 11:13:25+00:00
  edited: true
  hidden: false
  id: 64885d65c00cc27be8425eb8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-06-13T13:58:22.000Z'
    data:
      edited: true
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8538293838500977
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>Thank you for providing the arguments you are using. The current
          notebook has different training arguments than what you are using. (See
          below and at the link in your comment). Specifically, the current notebook
          does not have it set to load the best model at the end, which is what is
          causing the conflict with the earlier arguments regarding evaluation and
          save strategy. You may be using an outdated version. That is why I had suggested
          you check whether your arguments are the same as the current notebook. We
          suggest you pull the current notebook and try again. Please open a new issue
          if there is any different error in the updated notebook, but this error
          with training arguments should be resolved.</p>

          <p>training_args = {<br>    "learning_rate": max_lr,<br>    "do_train":
          True,<br>    "evaluation_strategy": "no",<br>    "save_strategy": "epoch",<br>    "logging_steps":
          100,<br>    "group_by_length": True,<br>    "length_column_name": "length",<br>    "disable_tqdm":
          False,<br>    "lr_scheduler_type": lr_schedule_fn,<br>    "warmup_steps":
          warmup_steps,<br>    "weight_decay": 0.001,<br>    "per_device_train_batch_size":
          geneformer_batch_size,<br>    "per_device_eval_batch_size": geneformer_batch_size,<br>    "num_train_epochs":
          epochs,<br>}</p>

          '
        raw: "Thank you for providing the arguments you are using. The current notebook\
          \ has different training arguments than what you are using. (See below and\
          \ at the link in your comment). Specifically, the current notebook does\
          \ not have it set to load the best model at the end, which is what is causing\
          \ the conflict with the earlier arguments regarding evaluation and save\
          \ strategy. You may be using an outdated version. That is why I had suggested\
          \ you check whether your arguments are the same as the current notebook.\
          \ We suggest you pull the current notebook and try again. Please open a\
          \ new issue if there is any different error in the updated notebook, but\
          \ this error with training arguments should be resolved.\n\ntraining_args\
          \ = {\n    \"learning_rate\": max_lr,\n    \"do_train\": True,\n    \"evaluation_strategy\"\
          : \"no\",\n    \"save_strategy\": \"epoch\",\n    \"logging_steps\": 100,\n\
          \    \"group_by_length\": True,\n    \"length_column_name\": \"length\"\
          ,\n    \"disable_tqdm\": False,\n    \"lr_scheduler_type\": lr_schedule_fn,\n\
          \    \"warmup_steps\": warmup_steps,\n    \"weight_decay\": 0.001,\n   \
          \ \"per_device_train_batch_size\": geneformer_batch_size,\n    \"per_device_eval_batch_size\"\
          : geneformer_batch_size,\n    \"num_train_epochs\": epochs,\n}"
        updatedAt: '2023-06-13T13:59:06.255Z'
      numEdits: 1
      reactions: []
      relatedEventId: 648875fef8bc52c0efcb6f53
    id: 648875fef8bc52c0efcb6f52
    type: comment
  author: ctheodoris
  content: "Thank you for providing the arguments you are using. The current notebook\
    \ has different training arguments than what you are using. (See below and at\
    \ the link in your comment). Specifically, the current notebook does not have\
    \ it set to load the best model at the end, which is what is causing the conflict\
    \ with the earlier arguments regarding evaluation and save strategy. You may be\
    \ using an outdated version. That is why I had suggested you check whether your\
    \ arguments are the same as the current notebook. We suggest you pull the current\
    \ notebook and try again. Please open a new issue if there is any different error\
    \ in the updated notebook, but this error with training arguments should be resolved.\n\
    \ntraining_args = {\n    \"learning_rate\": max_lr,\n    \"do_train\": True,\n\
    \    \"evaluation_strategy\": \"no\",\n    \"save_strategy\": \"epoch\",\n   \
    \ \"logging_steps\": 100,\n    \"group_by_length\": True,\n    \"length_column_name\"\
    : \"length\",\n    \"disable_tqdm\": False,\n    \"lr_scheduler_type\": lr_schedule_fn,\n\
    \    \"warmup_steps\": warmup_steps,\n    \"weight_decay\": 0.001,\n    \"per_device_train_batch_size\"\
    : geneformer_batch_size,\n    \"per_device_eval_batch_size\": geneformer_batch_size,\n\
    \    \"num_train_epochs\": epochs,\n}"
  created_at: 2023-06-13 12:58:22+00:00
  edited: true
  hidden: false
  id: 648875fef8bc52c0efcb6f52
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-06-13T13:58:22.000Z'
    data:
      status: closed
    id: 648875fef8bc52c0efcb6f53
    type: status-change
  author: ctheodoris
  created_at: 2023-06-13 12:58:22+00:00
  id: 648875fef8bc52c0efcb6f53
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
      fullname: Tianyu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iLOVE2D
      type: user
    createdAt: '2023-06-13T21:54:59.000Z'
    data:
      edited: false
      editors:
      - iLOVE2D
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.43164363503456116
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
          fullname: Tianyu
          isHf: false
          isPro: false
          name: iLOVE2D
          type: user
        html: '<p>Hi, I meet a new error after using new version. Prior this error,
          I run pip install --upgraed accelecrate</p>

          <p>110 training_args_init = TrainingArguments(**training_args)<br>    112
          # create the trainer<br>    113 trainer = Trainer(<br>    114     model=model,<br>    115     args=training_args_init,<br>--&gt;
          116     data_collator=DataCollatorForGeneClassification(),<br>    117     train_dataset=trainset_labeled,<br>    118     eval_dataset=evalset_train_labeled<br>    119
          )<br>    121 # train the gene classifier<br>    122 trainer.train()</p>

          <p>TypeError: <strong>init</strong>() missing 1 required positional argument:
          ''tokenizer''</p>

          <p>Are there any problems? Thanks a lot.</p>

          '
        raw: "Hi, I meet a new error after using new version. Prior this error, I\
          \ run pip install --upgraed accelecrate\n\n110 training_args_init = TrainingArguments(**training_args)\n\
          \    112 # create the trainer\n    113 trainer = Trainer(\n    114     model=model,\n\
          \    115     args=training_args_init,\n--> 116     data_collator=DataCollatorForGeneClassification(),\n\
          \    117     train_dataset=trainset_labeled,\n    118     eval_dataset=evalset_train_labeled\n\
          \    119 )\n    121 # train the gene classifier\n    122 trainer.train()\n\
          \nTypeError: __init__() missing 1 required positional argument: 'tokenizer'\n\
          \nAre there any problems? Thanks a lot."
        updatedAt: '2023-06-13T21:54:59.200Z'
      numEdits: 0
      reactions: []
    id: 6488e5b38c1c52a94299b52d
    type: comment
  author: iLOVE2D
  content: "Hi, I meet a new error after using new version. Prior this error, I run\
    \ pip install --upgraed accelecrate\n\n110 training_args_init = TrainingArguments(**training_args)\n\
    \    112 # create the trainer\n    113 trainer = Trainer(\n    114     model=model,\n\
    \    115     args=training_args_init,\n--> 116     data_collator=DataCollatorForGeneClassification(),\n\
    \    117     train_dataset=trainset_labeled,\n    118     eval_dataset=evalset_train_labeled\n\
    \    119 )\n    121 # train the gene classifier\n    122 trainer.train()\n\nTypeError:\
    \ __init__() missing 1 required positional argument: 'tokenizer'\n\nAre there\
    \ any problems? Thanks a lot."
  created_at: 2023-06-13 20:54:59+00:00
  edited: false
  hidden: false
  id: 6488e5b38c1c52a94299b52d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-06-13T22:16:12.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9571446180343628
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>Thank you for following up. Did you git pull the Huggingface Geneformer
          repository or just replace the gene classification notebook? If you did
          not pull the current repository, please do so as you may be using an outdated
          version.</p>

          <p>This code was developed over 2 years ago and the manuscript was submitted
          over 1 year ago so there were some changes in Huggingface transformers since
          then that caused this error. However, we already updated the collator to
          resolve this issue - the current version was tested for transformers 4.28.0.
          Please open a new issue if you pulled the current repository and are encountering
          a different error though.</p>

          '
        raw: 'Thank you for following up. Did you git pull the Huggingface Geneformer
          repository or just replace the gene classification notebook? If you did
          not pull the current repository, please do so as you may be using an outdated
          version.


          This code was developed over 2 years ago and the manuscript was submitted
          over 1 year ago so there were some changes in Huggingface transformers since
          then that caused this error. However, we already updated the collator to
          resolve this issue - the current version was tested for transformers 4.28.0.
          Please open a new issue if you pulled the current repository and are encountering
          a different error though.'
        updatedAt: '2023-06-13T22:16:12.285Z'
      numEdits: 0
      reactions: []
    id: 6488eaacbe5b91214edc77e7
    type: comment
  author: ctheodoris
  content: 'Thank you for following up. Did you git pull the Huggingface Geneformer
    repository or just replace the gene classification notebook? If you did not pull
    the current repository, please do so as you may be using an outdated version.


    This code was developed over 2 years ago and the manuscript was submitted over
    1 year ago so there were some changes in Huggingface transformers since then that
    caused this error. However, we already updated the collator to resolve this issue
    - the current version was tested for transformers 4.28.0. Please open a new issue
    if you pulled the current repository and are encountering a different error though.'
  created_at: 2023-06-13 21:16:12+00:00
  edited: false
  hidden: false
  id: 6488eaacbe5b91214edc77e7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
      fullname: Tianyu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iLOVE2D
      type: user
    createdAt: '2023-06-13T22:18:07.000Z'
    data:
      edited: false
      editors:
      - iLOVE2D
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.735580563545227
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
          fullname: Tianyu
          isHf: false
          isPro: false
          name: iLOVE2D
          type: user
        html: '<p>Hi, thanks for your quick following up. I pull the new version and
          use pip install .again. I can show you the log:</p>

          <p>git clone <a href="https://huggingface.co/ctheodoris/Geneformer">https://huggingface.co/ctheodoris/Geneformer</a><br>Cloning
          into ''Geneformer''...<br>remote: Enumerating objects: 204, done.<br>remote:
          Counting objects: 100% (189/189), done.<br>remote: Compressing objects:
          100% (165/165), done.<br>remote: Total 204 (delta 97), reused 55 (delta
          23), pack-reused 15<br>Receiving objects: 100% (204/204), 1.63 MiB | 10.44
          MiB/s, done.<br>Resolving deltas: 100% (100/100), done.</p>

          <p>pip install .<br>Processing /gpfs/gibbs/pi/zhao/tl688/Geneformer/Geneformer<br>  Preparing
          metadata (setup.py) ... done<br>Requirement already satisfied: datasets
          in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from geneformer==0.0.1) (2.12.0)<br>Requirement already satisfied: loompy
          in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from geneformer==0.0.1) (3.0.7)<br>Requirement already satisfied: numpy
          in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from geneformer==0.0.1) (1.24.3)<br>Requirement already satisfied: transformers
          in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from geneformer==0.0.1) (4.29.2)<br>Requirement already satisfied: pyarrow&gt;=8.0.0
          in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from datasets-&gt;geneformer==0.0.1) (12.0.0)<br>Requirement already satisfied:
          dill&lt;0.3.7,&gt;=0.3.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from datasets-&gt;geneformer==0.0.1) (0.3.6)<br>Requirement already satisfied:
          pandas in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from datasets-&gt;geneformer==0.0.1) (2.0.2)<br>Requirement already satisfied:
          requests&gt;=2.19.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from datasets-&gt;geneformer==0.0.1) (2.31.0)<br>Requirement already satisfied:
          tqdm&gt;=4.62.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from datasets-&gt;geneformer==0.0.1) (4.65.0)<br>Requirement already satisfied:
          xxhash in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from datasets-&gt;geneformer==0.0.1) (3.2.0)<br>Requirement already satisfied:
          multiprocess in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from datasets-&gt;geneformer==0.0.1) (0.70.14)<br>Requirement already satisfied:
          fsspec[http]&gt;=2021.11.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from datasets-&gt;geneformer==0.0.1) (2023.5.0)<br>Requirement already
          satisfied: aiohttp in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from datasets-&gt;geneformer==0.0.1) (3.8.4)<br>Requirement already satisfied:
          huggingface-hub&lt;1.0.0,&gt;=0.11.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from datasets-&gt;geneformer==0.0.1) (0.15.1)<br>Requirement already satisfied:
          packaging in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from datasets-&gt;geneformer==0.0.1) (23.1)<br>Requirement already satisfied:
          responses&lt;0.19 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from datasets-&gt;geneformer==0.0.1) (0.18.0)<br>Requirement already satisfied:
          pyyaml&gt;=5.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from datasets-&gt;geneformer==0.0.1) (6.0)<br>Requirement already satisfied:
          h5py in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from loompy-&gt;geneformer==0.0.1) (3.8.0)<br>Requirement already satisfied:
          scipy in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from loompy-&gt;geneformer==0.0.1) (1.10.1)<br>Requirement already satisfied:
          setuptools in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from loompy-&gt;geneformer==0.0.1) (67.7.2)<br>Requirement already satisfied:
          numba in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from loompy-&gt;geneformer==0.0.1) (0.57.0)<br>Requirement already satisfied:
          click in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from loompy-&gt;geneformer==0.0.1) (8.1.3)<br>Requirement already satisfied:
          numpy-groupies in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from loompy-&gt;geneformer==0.0.1) (0.9.22)<br>Requirement already satisfied:
          filelock in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from transformers-&gt;geneformer==0.0.1) (3.12.0)<br>Requirement already
          satisfied: regex!=2019.12.17 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from transformers-&gt;geneformer==0.0.1) (2023.6.3)<br>Requirement already
          satisfied: tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from transformers-&gt;geneformer==0.0.1) (0.13.3)<br>Requirement already
          satisfied: attrs&gt;=17.3.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from aiohttp-&gt;datasets-&gt;geneformer==0.0.1) (23.1.0)<br>Requirement
          already satisfied: charset-normalizer&lt;4.0,&gt;=2.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from aiohttp-&gt;datasets-&gt;geneformer==0.0.1) (3.1.0)<br>Requirement
          already satisfied: multidict&lt;7.0,&gt;=4.5 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from aiohttp-&gt;datasets-&gt;geneformer==0.0.1) (6.0.4)<br>Requirement
          already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from aiohttp-&gt;datasets-&gt;geneformer==0.0.1) (4.0.2)<br>Requirement
          already satisfied: yarl&lt;2.0,&gt;=1.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from aiohttp-&gt;datasets-&gt;geneformer==0.0.1) (1.9.2)<br>Requirement
          already satisfied: frozenlist&gt;=1.1.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from aiohttp-&gt;datasets-&gt;geneformer==0.0.1) (1.3.3)<br>Requirement
          already satisfied: aiosignal&gt;=1.1.2 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from aiohttp-&gt;datasets-&gt;geneformer==0.0.1) (1.3.1)<br>Requirement
          already satisfied: typing-extensions&gt;=3.7.4.3 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from huggingface-hub&lt;1.0.0,&gt;=0.11.0-&gt;datasets-&gt;geneformer==0.0.1)
          (4.6.3)<br>Requirement already satisfied: idna&lt;4,&gt;=2.5 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from requests&gt;=2.19.0-&gt;datasets-&gt;geneformer==0.0.1) (3.4)<br>Requirement
          already satisfied: urllib3&lt;3,&gt;=1.21.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from requests&gt;=2.19.0-&gt;datasets-&gt;geneformer==0.0.1) (2.0.2)<br>Requirement
          already satisfied: certifi&gt;=2017.4.17 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from requests&gt;=2.19.0-&gt;datasets-&gt;geneformer==0.0.1) (2023.5.7)<br>Requirement
          already satisfied: llvmlite&lt;0.41,&gt;=0.40.0dev0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from numba-&gt;loompy-&gt;geneformer==0.0.1) (0.40.0)<br>Requirement already
          satisfied: importlib-metadata in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from numba-&gt;loompy-&gt;geneformer==0.0.1) (6.6.0)<br>Requirement already
          satisfied: python-dateutil&gt;=2.8.2 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from pandas-&gt;datasets-&gt;geneformer==0.0.1) (2.8.2)<br>Requirement
          already satisfied: pytz&gt;=2020.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from pandas-&gt;datasets-&gt;geneformer==0.0.1) (2023.3)<br>Requirement
          already satisfied: tzdata&gt;=2022.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from pandas-&gt;datasets-&gt;geneformer==0.0.1) (2023.3)<br>Requirement
          already satisfied: six&gt;=1.5 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;datasets-&gt;geneformer==0.0.1)
          (1.16.0)<br>Requirement already satisfied: zipp&gt;=0.5 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages
          (from importlib-metadata-&gt;numba-&gt;loompy-&gt;geneformer==0.0.1) (3.15.0)<br>Building
          wheels for collected packages: geneformer<br>  Building wheel for geneformer
          (setup.py) ... done<br>  Created wheel for geneformer: filename=geneformer-0.0.1-py3-none-any.whl
          size=788358 sha256=93f6c8c7a7cea8fc7e896bf156a98966d15d38ddcfc9e89d31bb8c31cd30ef1e<br>  Stored
          in directory: /tmp/pip-ephem-wheel-cache-11tw161c/wheels/dc/cd/84/cbcf18cccec91328987bffbd0de23ad637bf97827956af428c<br>Successfully
          built geneformer<br>Installing collected packages: geneformer<br>  Attempting
          uninstall: geneformer<br>    Found existing installation: geneformer 0.0.1<br>    Uninstalling
          geneformer-0.0.1:<br>      Successfully uninstalled geneformer-0.0.1<br>Successfully
          installed geneformer-0.0.1</p>

          '
        raw: "Hi, thanks for your quick following up. I pull the new version and use\
          \ pip install .again. I can show you the log:\n\ngit clone https://huggingface.co/ctheodoris/Geneformer\n\
          Cloning into 'Geneformer'...\nremote: Enumerating objects: 204, done.\n\
          remote: Counting objects: 100% (189/189), done.\nremote: Compressing objects:\
          \ 100% (165/165), done.\nremote: Total 204 (delta 97), reused 55 (delta\
          \ 23), pack-reused 15\nReceiving objects: 100% (204/204), 1.63 MiB | 10.44\
          \ MiB/s, done.\nResolving deltas: 100% (100/100), done.\n\npip install .\n\
          Processing /gpfs/gibbs/pi/zhao/tl688/Geneformer/Geneformer\n  Preparing\
          \ metadata (setup.py) ... done\nRequirement already satisfied: datasets\
          \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from geneformer==0.0.1) (2.12.0)\nRequirement already satisfied: loompy\
          \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from geneformer==0.0.1) (3.0.7)\nRequirement already satisfied: numpy\
          \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from geneformer==0.0.1) (1.24.3)\nRequirement already satisfied: transformers\
          \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from geneformer==0.0.1) (4.29.2)\nRequirement already satisfied: pyarrow>=8.0.0\
          \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from datasets->geneformer==0.0.1) (12.0.0)\nRequirement already satisfied:\
          \ dill<0.3.7,>=0.3.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from datasets->geneformer==0.0.1) (0.3.6)\nRequirement already satisfied:\
          \ pandas in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from datasets->geneformer==0.0.1) (2.0.2)\nRequirement already satisfied:\
          \ requests>=2.19.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from datasets->geneformer==0.0.1) (2.31.0)\nRequirement already satisfied:\
          \ tqdm>=4.62.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from datasets->geneformer==0.0.1) (4.65.0)\nRequirement already satisfied:\
          \ xxhash in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from datasets->geneformer==0.0.1) (3.2.0)\nRequirement already satisfied:\
          \ multiprocess in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from datasets->geneformer==0.0.1) (0.70.14)\nRequirement already satisfied:\
          \ fsspec[http]>=2021.11.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from datasets->geneformer==0.0.1) (2023.5.0)\nRequirement already satisfied:\
          \ aiohttp in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from datasets->geneformer==0.0.1) (3.8.4)\nRequirement already satisfied:\
          \ huggingface-hub<1.0.0,>=0.11.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from datasets->geneformer==0.0.1) (0.15.1)\nRequirement already satisfied:\
          \ packaging in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from datasets->geneformer==0.0.1) (23.1)\nRequirement already satisfied:\
          \ responses<0.19 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from datasets->geneformer==0.0.1) (0.18.0)\nRequirement already satisfied:\
          \ pyyaml>=5.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from datasets->geneformer==0.0.1) (6.0)\nRequirement already satisfied:\
          \ h5py in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from loompy->geneformer==0.0.1) (3.8.0)\nRequirement already satisfied:\
          \ scipy in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from loompy->geneformer==0.0.1) (1.10.1)\nRequirement already satisfied:\
          \ setuptools in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from loompy->geneformer==0.0.1) (67.7.2)\nRequirement already satisfied:\
          \ numba in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from loompy->geneformer==0.0.1) (0.57.0)\nRequirement already satisfied:\
          \ click in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from loompy->geneformer==0.0.1) (8.1.3)\nRequirement already satisfied:\
          \ numpy-groupies in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from loompy->geneformer==0.0.1) (0.9.22)\nRequirement already satisfied:\
          \ filelock in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from transformers->geneformer==0.0.1) (3.12.0)\nRequirement already satisfied:\
          \ regex!=2019.12.17 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from transformers->geneformer==0.0.1) (2023.6.3)\nRequirement already\
          \ satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from transformers->geneformer==0.0.1) (0.13.3)\nRequirement already satisfied:\
          \ attrs>=17.3.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from aiohttp->datasets->geneformer==0.0.1) (23.1.0)\nRequirement already\
          \ satisfied: charset-normalizer<4.0,>=2.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from aiohttp->datasets->geneformer==0.0.1) (3.1.0)\nRequirement already\
          \ satisfied: multidict<7.0,>=4.5 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from aiohttp->datasets->geneformer==0.0.1) (6.0.4)\nRequirement already\
          \ satisfied: async-timeout<5.0,>=4.0.0a3 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from aiohttp->datasets->geneformer==0.0.1) (4.0.2)\nRequirement already\
          \ satisfied: yarl<2.0,>=1.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from aiohttp->datasets->geneformer==0.0.1) (1.9.2)\nRequirement already\
          \ satisfied: frozenlist>=1.1.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from aiohttp->datasets->geneformer==0.0.1) (1.3.3)\nRequirement already\
          \ satisfied: aiosignal>=1.1.2 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from aiohttp->datasets->geneformer==0.0.1) (1.3.1)\nRequirement already\
          \ satisfied: typing-extensions>=3.7.4.3 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from huggingface-hub<1.0.0,>=0.11.0->datasets->geneformer==0.0.1) (4.6.3)\n\
          Requirement already satisfied: idna<4,>=2.5 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from requests>=2.19.0->datasets->geneformer==0.0.1) (3.4)\nRequirement\
          \ already satisfied: urllib3<3,>=1.21.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from requests>=2.19.0->datasets->geneformer==0.0.1) (2.0.2)\nRequirement\
          \ already satisfied: certifi>=2017.4.17 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from requests>=2.19.0->datasets->geneformer==0.0.1) (2023.5.7)\nRequirement\
          \ already satisfied: llvmlite<0.41,>=0.40.0dev0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from numba->loompy->geneformer==0.0.1) (0.40.0)\nRequirement already\
          \ satisfied: importlib-metadata in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from numba->loompy->geneformer==0.0.1) (6.6.0)\nRequirement already satisfied:\
          \ python-dateutil>=2.8.2 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from pandas->datasets->geneformer==0.0.1) (2.8.2)\nRequirement already\
          \ satisfied: pytz>=2020.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from pandas->datasets->geneformer==0.0.1) (2023.3)\nRequirement already\
          \ satisfied: tzdata>=2022.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from pandas->datasets->geneformer==0.0.1) (2023.3)\nRequirement already\
          \ satisfied: six>=1.5 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from python-dateutil>=2.8.2->pandas->datasets->geneformer==0.0.1) (1.16.0)\n\
          Requirement already satisfied: zipp>=0.5 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
          \ (from importlib-metadata->numba->loompy->geneformer==0.0.1) (3.15.0)\n\
          Building wheels for collected packages: geneformer\n  Building wheel for\
          \ geneformer (setup.py) ... done\n  Created wheel for geneformer: filename=geneformer-0.0.1-py3-none-any.whl\
          \ size=788358 sha256=93f6c8c7a7cea8fc7e896bf156a98966d15d38ddcfc9e89d31bb8c31cd30ef1e\n\
          \  Stored in directory: /tmp/pip-ephem-wheel-cache-11tw161c/wheels/dc/cd/84/cbcf18cccec91328987bffbd0de23ad637bf97827956af428c\n\
          Successfully built geneformer\nInstalling collected packages: geneformer\n\
          \  Attempting uninstall: geneformer\n    Found existing installation: geneformer\
          \ 0.0.1\n    Uninstalling geneformer-0.0.1:\n      Successfully uninstalled\
          \ geneformer-0.0.1\nSuccessfully installed geneformer-0.0.1\n"
        updatedAt: '2023-06-13T22:18:07.411Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6488eb2112e3757c086cdc1c
    id: 6488eb1f12e3757c086cdb24
    type: comment
  author: iLOVE2D
  content: "Hi, thanks for your quick following up. I pull the new version and use\
    \ pip install .again. I can show you the log:\n\ngit clone https://huggingface.co/ctheodoris/Geneformer\n\
    Cloning into 'Geneformer'...\nremote: Enumerating objects: 204, done.\nremote:\
    \ Counting objects: 100% (189/189), done.\nremote: Compressing objects: 100% (165/165),\
    \ done.\nremote: Total 204 (delta 97), reused 55 (delta 23), pack-reused 15\n\
    Receiving objects: 100% (204/204), 1.63 MiB | 10.44 MiB/s, done.\nResolving deltas:\
    \ 100% (100/100), done.\n\npip install .\nProcessing /gpfs/gibbs/pi/zhao/tl688/Geneformer/Geneformer\n\
    \  Preparing metadata (setup.py) ... done\nRequirement already satisfied: datasets\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from geneformer==0.0.1) (2.12.0)\nRequirement already satisfied: loompy in\
    \ /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from geneformer==0.0.1) (3.0.7)\nRequirement already satisfied: numpy in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from geneformer==0.0.1) (1.24.3)\nRequirement already satisfied: transformers\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from geneformer==0.0.1) (4.29.2)\nRequirement already satisfied: pyarrow>=8.0.0\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from datasets->geneformer==0.0.1) (12.0.0)\nRequirement already satisfied:\
    \ dill<0.3.7,>=0.3.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from datasets->geneformer==0.0.1) (0.3.6)\nRequirement already satisfied: pandas\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from datasets->geneformer==0.0.1) (2.0.2)\nRequirement already satisfied: requests>=2.19.0\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from datasets->geneformer==0.0.1) (2.31.0)\nRequirement already satisfied:\
    \ tqdm>=4.62.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from datasets->geneformer==0.0.1) (4.65.0)\nRequirement already satisfied:\
    \ xxhash in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from datasets->geneformer==0.0.1) (3.2.0)\nRequirement already satisfied: multiprocess\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from datasets->geneformer==0.0.1) (0.70.14)\nRequirement already satisfied:\
    \ fsspec[http]>=2021.11.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from datasets->geneformer==0.0.1) (2023.5.0)\nRequirement already satisfied:\
    \ aiohttp in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from datasets->geneformer==0.0.1) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from datasets->geneformer==0.0.1) (0.15.1)\nRequirement already satisfied:\
    \ packaging in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from datasets->geneformer==0.0.1) (23.1)\nRequirement already satisfied: responses<0.19\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from datasets->geneformer==0.0.1) (0.18.0)\nRequirement already satisfied:\
    \ pyyaml>=5.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from datasets->geneformer==0.0.1) (6.0)\nRequirement already satisfied: h5py\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from loompy->geneformer==0.0.1) (3.8.0)\nRequirement already satisfied: scipy\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from loompy->geneformer==0.0.1) (1.10.1)\nRequirement already satisfied: setuptools\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from loompy->geneformer==0.0.1) (67.7.2)\nRequirement already satisfied: numba\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from loompy->geneformer==0.0.1) (0.57.0)\nRequirement already satisfied: click\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from loompy->geneformer==0.0.1) (8.1.3)\nRequirement already satisfied: numpy-groupies\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from loompy->geneformer==0.0.1) (0.9.22)\nRequirement already satisfied: filelock\
    \ in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from transformers->geneformer==0.0.1) (3.12.0)\nRequirement already satisfied:\
    \ regex!=2019.12.17 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from transformers->geneformer==0.0.1) (2023.6.3)\nRequirement already satisfied:\
    \ tokenizers!=0.11.3,<0.14,>=0.11.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from transformers->geneformer==0.0.1) (0.13.3)\nRequirement already satisfied:\
    \ attrs>=17.3.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from aiohttp->datasets->geneformer==0.0.1) (23.1.0)\nRequirement already satisfied:\
    \ charset-normalizer<4.0,>=2.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from aiohttp->datasets->geneformer==0.0.1) (3.1.0)\nRequirement already satisfied:\
    \ multidict<7.0,>=4.5 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from aiohttp->datasets->geneformer==0.0.1) (6.0.4)\nRequirement already satisfied:\
    \ async-timeout<5.0,>=4.0.0a3 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from aiohttp->datasets->geneformer==0.0.1) (4.0.2)\nRequirement already satisfied:\
    \ yarl<2.0,>=1.0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from aiohttp->datasets->geneformer==0.0.1) (1.9.2)\nRequirement already satisfied:\
    \ frozenlist>=1.1.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from aiohttp->datasets->geneformer==0.0.1) (1.3.3)\nRequirement already satisfied:\
    \ aiosignal>=1.1.2 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from aiohttp->datasets->geneformer==0.0.1) (1.3.1)\nRequirement already satisfied:\
    \ typing-extensions>=3.7.4.3 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from huggingface-hub<1.0.0,>=0.11.0->datasets->geneformer==0.0.1) (4.6.3)\n\
    Requirement already satisfied: idna<4,>=2.5 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from requests>=2.19.0->datasets->geneformer==0.0.1) (3.4)\nRequirement already\
    \ satisfied: urllib3<3,>=1.21.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from requests>=2.19.0->datasets->geneformer==0.0.1) (2.0.2)\nRequirement already\
    \ satisfied: certifi>=2017.4.17 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from requests>=2.19.0->datasets->geneformer==0.0.1) (2023.5.7)\nRequirement\
    \ already satisfied: llvmlite<0.41,>=0.40.0dev0 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from numba->loompy->geneformer==0.0.1) (0.40.0)\nRequirement already satisfied:\
    \ importlib-metadata in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from numba->loompy->geneformer==0.0.1) (6.6.0)\nRequirement already satisfied:\
    \ python-dateutil>=2.8.2 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from pandas->datasets->geneformer==0.0.1) (2.8.2)\nRequirement already satisfied:\
    \ pytz>=2020.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from pandas->datasets->geneformer==0.0.1) (2023.3)\nRequirement already satisfied:\
    \ tzdata>=2022.1 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from pandas->datasets->geneformer==0.0.1) (2023.3)\nRequirement already satisfied:\
    \ six>=1.5 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from python-dateutil>=2.8.2->pandas->datasets->geneformer==0.0.1) (1.16.0)\n\
    Requirement already satisfied: zipp>=0.5 in /gpfs/gibbs/project/zhao/tl688/conda_envs/geneformer/lib/python3.8/site-packages\
    \ (from importlib-metadata->numba->loompy->geneformer==0.0.1) (3.15.0)\nBuilding\
    \ wheels for collected packages: geneformer\n  Building wheel for geneformer (setup.py)\
    \ ... done\n  Created wheel for geneformer: filename=geneformer-0.0.1-py3-none-any.whl\
    \ size=788358 sha256=93f6c8c7a7cea8fc7e896bf156a98966d15d38ddcfc9e89d31bb8c31cd30ef1e\n\
    \  Stored in directory: /tmp/pip-ephem-wheel-cache-11tw161c/wheels/dc/cd/84/cbcf18cccec91328987bffbd0de23ad637bf97827956af428c\n\
    Successfully built geneformer\nInstalling collected packages: geneformer\n  Attempting\
    \ uninstall: geneformer\n    Found existing installation: geneformer 0.0.1\n \
    \   Uninstalling geneformer-0.0.1:\n      Successfully uninstalled geneformer-0.0.1\n\
    Successfully installed geneformer-0.0.1\n"
  created_at: 2023-06-13 21:18:07+00:00
  edited: false
  hidden: false
  id: 6488eb1f12e3757c086cdb24
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
      fullname: Tianyu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iLOVE2D
      type: user
    createdAt: '2023-06-13T22:18:09.000Z'
    data:
      status: open
    id: 6488eb2112e3757c086cdc1c
    type: status-change
  author: iLOVE2D
  created_at: 2023-06-13 21:18:09+00:00
  id: 6488eb2112e3757c086cdc1c
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-06-13T23:55:47.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9278439879417419
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>Thank you for confirming that. Unfortunately, I am not able to reproduce
          your error. When I run the gene classification fine-tuning, there is no
          error encountered. Could you compare a diff of your local version with the
          current repository geneformer/collator_for_classification.py to ensure they
          are the same? If they are, please let me know which version of Huggingface
          transformers you are using. We have tested the updated code with 4.28.0.</p>

          '
        raw: Thank you for confirming that. Unfortunately, I am not able to reproduce
          your error. When I run the gene classification fine-tuning, there is no
          error encountered. Could you compare a diff of your local version with the
          current repository geneformer/collator_for_classification.py to ensure they
          are the same? If they are, please let me know which version of Huggingface
          transformers you are using. We have tested the updated code with 4.28.0.
        updatedAt: '2023-06-13T23:55:47.356Z'
      numEdits: 0
      reactions: []
    id: 6489020391e7862adcc157a4
    type: comment
  author: ctheodoris
  content: Thank you for confirming that. Unfortunately, I am not able to reproduce
    your error. When I run the gene classification fine-tuning, there is no error
    encountered. Could you compare a diff of your local version with the current repository
    geneformer/collator_for_classification.py to ensure they are the same? If they
    are, please let me know which version of Huggingface transformers you are using.
    We have tested the updated code with 4.28.0.
  created_at: 2023-06-13 22:55:47+00:00
  edited: false
  hidden: false
  id: 6489020391e7862adcc157a4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
      fullname: Tianyu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iLOVE2D
      type: user
    createdAt: '2023-06-14T19:45:42.000Z'
    data:
      edited: true
      editors:
      - iLOVE2D
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6668339371681213
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
          fullname: Tianyu
          isHf: false
          isPro: false
          name: iLOVE2D
          type: user
        html: "<p>Hi, many thanks for your help again. It is my version problem. That\
          \ is because under my current use folder, there is also a geneformer folder\
          \ and my model will prefer loading that folder.</p>\n<p>I meet another new\
          \ problem:</p>\n<pre><code>    126 trainer.save_model(ksplit_model_dir)\n\
          \    128 # evaluate model\n--&gt; 129 fpr, tpr, interp_tpr, conf_mat = classifier_predict(trainer.model,\
          \ evalset_oos_labeled, geneformer_batch_size, mean_fpr)\n    131 # append\
          \ to tpr and roc lists\n    132 confusion = confusion + conf_mat\n\nCell\
          \ In[10], line 38, in classifier_predict(model, evalset, forward_batch_size,\
          \ mean_fpr)\n     35         predict_logits += [torch.squeeze(outputs.logits.to(\"\
          cpu\"))]\n     36         predict_labels += [torch.squeeze(label_batch.to(\"\
          cpu\"))]\n---&gt; 38 logits_by_cell = torch.cat(predict_logits)\n     39\
          \ all_logits = logits_by_cell.reshape(-1, logits_by_cell.shape[2])\n   \
          \  40 labels_by_cell = torch.cat(predict_labels)\n\nRuntimeError: Sizes\
          \ of tensors must match except in dimension 0. Expected size 797 but got\
          \ size 636 for tensor number 1 in the list.\n</code></pre>\n"
        raw: "Hi, many thanks for your help again. It is my version problem. That\
          \ is because under my current use folder, there is also a geneformer folder\
          \ and my model will prefer loading that folder.\n\nI meet another new problem:\n\
          \n```\n    126 trainer.save_model(ksplit_model_dir)\n    128 # evaluate\
          \ model\n--> 129 fpr, tpr, interp_tpr, conf_mat = classifier_predict(trainer.model,\
          \ evalset_oos_labeled, geneformer_batch_size, mean_fpr)\n    131 # append\
          \ to tpr and roc lists\n    132 confusion = confusion + conf_mat\n\nCell\
          \ In[10], line 38, in classifier_predict(model, evalset, forward_batch_size,\
          \ mean_fpr)\n     35         predict_logits += [torch.squeeze(outputs.logits.to(\"\
          cpu\"))]\n     36         predict_labels += [torch.squeeze(label_batch.to(\"\
          cpu\"))]\n---> 38 logits_by_cell = torch.cat(predict_logits)\n     39 all_logits\
          \ = logits_by_cell.reshape(-1, logits_by_cell.shape[2])\n     40 labels_by_cell\
          \ = torch.cat(predict_labels)\n\nRuntimeError: Sizes of tensors must match\
          \ except in dimension 0. Expected size 797 but got size 636 for tensor number\
          \ 1 in the list.\n```"
        updatedAt: '2023-06-14T19:46:01.542Z'
      numEdits: 1
      reactions: []
      relatedEventId: 648a18e67de18d75a2353530
    id: 648a18e67de18d75a235352d
    type: comment
  author: iLOVE2D
  content: "Hi, many thanks for your help again. It is my version problem. That is\
    \ because under my current use folder, there is also a geneformer folder and my\
    \ model will prefer loading that folder.\n\nI meet another new problem:\n\n```\n\
    \    126 trainer.save_model(ksplit_model_dir)\n    128 # evaluate model\n--> 129\
    \ fpr, tpr, interp_tpr, conf_mat = classifier_predict(trainer.model, evalset_oos_labeled,\
    \ geneformer_batch_size, mean_fpr)\n    131 # append to tpr and roc lists\n  \
    \  132 confusion = confusion + conf_mat\n\nCell In[10], line 38, in classifier_predict(model,\
    \ evalset, forward_batch_size, mean_fpr)\n     35         predict_logits += [torch.squeeze(outputs.logits.to(\"\
    cpu\"))]\n     36         predict_labels += [torch.squeeze(label_batch.to(\"cpu\"\
    ))]\n---> 38 logits_by_cell = torch.cat(predict_logits)\n     39 all_logits =\
    \ logits_by_cell.reshape(-1, logits_by_cell.shape[2])\n     40 labels_by_cell\
    \ = torch.cat(predict_labels)\n\nRuntimeError: Sizes of tensors must match except\
    \ in dimension 0. Expected size 797 but got size 636 for tensor number 1 in the\
    \ list.\n```"
  created_at: 2023-06-14 18:45:42+00:00
  edited: true
  hidden: false
  id: 648a18e67de18d75a235352d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
      fullname: Tianyu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iLOVE2D
      type: user
    createdAt: '2023-06-14T19:45:42.000Z'
    data:
      status: closed
    id: 648a18e67de18d75a2353530
    type: status-change
  author: iLOVE2D
  created_at: 2023-06-14 18:45:42+00:00
  id: 648a18e67de18d75a2353530
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
      fullname: Tianyu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iLOVE2D
      type: user
    createdAt: '2023-06-14T21:20:48.000Z'
    data:
      edited: false
      editors:
      - iLOVE2D
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5950418710708618
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
          fullname: Tianyu
          isHf: false
          isPro: false
          name: iLOVE2D
          type: user
        html: '<p>I think it is caused by the dimension mismatching in gene prediction
          step:</p>

          <p>torch.Size([12, 797, 2])<br>torch.Size([12, 636, 2])<br>torch.Size([12,
          631, 2])<br>torch.Size([12, 953, 2])<br>torch.Size([12, 536, 2])<br>torch.Size([12,
          972, 2])<br>torch.Size([12, 560, 2])<br>torch.Size([12, 710, 2])<br>torch.Size([12,
          486, 2])<br>torch.Size([12, 843, 2])<br>torch.Size([12, 570, 2])<br>torch.Size([12,
          634, 2])<br>torch.Size([12, 712, 2])<br>torch.Size([12, 754, 2])<br>torch.Size([12,
          740, 2])</p>

          <p>Thanks a lot.</p>

          '
        raw: 'I think it is caused by the dimension mismatching in gene prediction
          step:


          torch.Size([12, 797, 2])

          torch.Size([12, 636, 2])

          torch.Size([12, 631, 2])

          torch.Size([12, 953, 2])

          torch.Size([12, 536, 2])

          torch.Size([12, 972, 2])

          torch.Size([12, 560, 2])

          torch.Size([12, 710, 2])

          torch.Size([12, 486, 2])

          torch.Size([12, 843, 2])

          torch.Size([12, 570, 2])

          torch.Size([12, 634, 2])

          torch.Size([12, 712, 2])

          torch.Size([12, 754, 2])

          torch.Size([12, 740, 2])


          Thanks a lot.'
        updatedAt: '2023-06-14T21:20:48.978Z'
      numEdits: 0
      reactions: []
      relatedEventId: 648a2f31fe11ebd748a1592b
    id: 648a2f30fe11ebd748a15924
    type: comment
  author: iLOVE2D
  content: 'I think it is caused by the dimension mismatching in gene prediction step:


    torch.Size([12, 797, 2])

    torch.Size([12, 636, 2])

    torch.Size([12, 631, 2])

    torch.Size([12, 953, 2])

    torch.Size([12, 536, 2])

    torch.Size([12, 972, 2])

    torch.Size([12, 560, 2])

    torch.Size([12, 710, 2])

    torch.Size([12, 486, 2])

    torch.Size([12, 843, 2])

    torch.Size([12, 570, 2])

    torch.Size([12, 634, 2])

    torch.Size([12, 712, 2])

    torch.Size([12, 754, 2])

    torch.Size([12, 740, 2])


    Thanks a lot.'
  created_at: 2023-06-14 20:20:48+00:00
  edited: false
  hidden: false
  id: 648a2f30fe11ebd748a15924
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/b2daf2bde31edab85e3d1bc0c0afbb5a.svg
      fullname: Tianyu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iLOVE2D
      type: user
    createdAt: '2023-06-14T21:20:49.000Z'
    data:
      status: open
    id: 648a2f31fe11ebd748a1592b
    type: status-change
  author: iLOVE2D
  created_at: 2023-06-14 20:20:49+00:00
  id: 648a2f31fe11ebd748a1592b
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-06-15T01:00:15.000Z'
    data:
      edited: true
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9097902774810791
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>Thank you for the information. torch.cat() requires that the tensors
          be of the same size in all dimensions except 0 in order to be concatenated.
          The first tensor has a dimension 1 of 797 so it expects the remainder to
          have that same size in that dimension. However, these should be outputs
          that are prediction results so should be of the same size there. Unfortunately,
          I am not able to reproduce your error because when I run the gene classification
          fine-tuning, there is no error encountered. Could you provide more information
          on your input data and how many classes there are so that I can try to reproduce
          the error?</p>

          '
        raw: Thank you for the information. torch.cat() requires that the tensors
          be of the same size in all dimensions except 0 in order to be concatenated.
          The first tensor has a dimension 1 of 797 so it expects the remainder to
          have that same size in that dimension. However, these should be outputs
          that are prediction results so should be of the same size there. Unfortunately,
          I am not able to reproduce your error because when I run the gene classification
          fine-tuning, there is no error encountered. Could you provide more information
          on your input data and how many classes there are so that I can try to reproduce
          the error?
        updatedAt: '2023-06-15T01:01:38.413Z'
      numEdits: 4
      reactions: []
    id: 648a629fff0f4d8a545c3411
    type: comment
  author: ctheodoris
  content: Thank you for the information. torch.cat() requires that the tensors be
    of the same size in all dimensions except 0 in order to be concatenated. The first
    tensor has a dimension 1 of 797 so it expects the remainder to have that same
    size in that dimension. However, these should be outputs that are prediction results
    so should be of the same size there. Unfortunately, I am not able to reproduce
    your error because when I run the gene classification fine-tuning, there is no
    error encountered. Could you provide more information on your input data and how
    many classes there are so that I can try to reproduce the error?
  created_at: 2023-06-15 00:00:15+00:00
  edited: true
  hidden: false
  id: 648a629fff0f4d8a545c3411
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-06-22T20:28:18.000Z'
    data:
      edited: false
      editors:
      - ctheodoris
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9223620295524597
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
          fullname: Christina Theodoris
          isHf: false
          isPro: false
          name: ctheodoris
          type: user
        html: '<p>I pushed a fix to the notebook to resolve this issue by padding
          the evaluation data so that the prediction outputs are of equal size in
          the 2nd dimension. Please pull the new one and retry.</p>

          '
        raw: I pushed a fix to the notebook to resolve this issue by padding the evaluation
          data so that the prediction outputs are of equal size in the 2nd dimension.
          Please pull the new one and retry.
        updatedAt: '2023-06-22T20:28:18.284Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6494aee22aa2d5e37ded7cac
    id: 6494aee22aa2d5e37ded7ca8
    type: comment
  author: ctheodoris
  content: I pushed a fix to the notebook to resolve this issue by padding the evaluation
    data so that the prediction outputs are of equal size in the 2nd dimension. Please
    pull the new one and retry.
  created_at: 2023-06-22 19:28:18+00:00
  edited: false
  hidden: false
  id: 6494aee22aa2d5e37ded7ca8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671502872617-622d085c8d04fd29a9ccf169.png?w=200&h=200&f=face
      fullname: Christina Theodoris
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ctheodoris
      type: user
    createdAt: '2023-06-22T20:28:18.000Z'
    data:
      status: closed
    id: 6494aee22aa2d5e37ded7cac
    type: status-change
  author: ctheodoris
  created_at: 2023-06-22 19:28:18+00:00
  id: 6494aee22aa2d5e37ded7cac
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 31
repo_id: ctheodoris/Geneformer
repo_type: model
status: closed
target_branch: null
title: Error in using gene prediction
