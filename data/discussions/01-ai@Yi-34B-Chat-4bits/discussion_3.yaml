!!python/object:huggingface_hub.community.DiscussionWithDetails
author: angeligareta
conflicting_files: null
created_at: 2023-11-27 17:42:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b35649453e4383a8df92af0c05148f4d.svg
      fullname: Angel Igareta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: angeligareta
      type: user
    createdAt: '2023-11-27T17:42:21.000Z'
    data:
      edited: false
      editors:
      - angeligareta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8289284706115723
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b35649453e4383a8df92af0c05148f4d.svg
          fullname: Angel Igareta
          isHf: false
          isPro: false
          name: angeligareta
          type: user
        html: '<p>Has someone made this instance work using a HuggingFace Model and
          deploying it to SageMaker? I am not able to deploy it, any help on which
          configuration to use would be welcome. I have tried<br><code>config = {     "HF_MODEL_ID":
          "01-ai/Yi-34B-Chat-4bits" }</code><br>and<br><code>config = {     "HF_MODEL_ID":
          "01-ai/Yi-34B-Chat-4bits",     ''QUANTIZE'': ''awq'' } </code></p>

          '
        raw: "Has someone made this instance work using a HuggingFace Model and deploying\
          \ it to SageMaker? I am not able to deploy it, any help on which configuration\
          \ to use would be welcome. I have tried\r\n`config = {\r\n    \"HF_MODEL_ID\"\
          : \"01-ai/Yi-34B-Chat-4bits\"\r\n}`\r\nand\r\n`config = {\r\n    \"HF_MODEL_ID\"\
          : \"01-ai/Yi-34B-Chat-4bits\",\r\n    'QUANTIZE': 'awq'\r\n}\r\n`"
        updatedAt: '2023-11-27T17:42:21.442Z'
      numEdits: 0
      reactions: []
    id: 6564d4fdedae9c33b76ff1f4
    type: comment
  author: angeligareta
  content: "Has someone made this instance work using a HuggingFace Model and deploying\
    \ it to SageMaker? I am not able to deploy it, any help on which configuration\
    \ to use would be welcome. I have tried\r\n`config = {\r\n    \"HF_MODEL_ID\"\
    : \"01-ai/Yi-34B-Chat-4bits\"\r\n}`\r\nand\r\n`config = {\r\n    \"HF_MODEL_ID\"\
    : \"01-ai/Yi-34B-Chat-4bits\",\r\n    'QUANTIZE': 'awq'\r\n}\r\n`"
  created_at: 2023-11-27 17:42:21+00:00
  edited: false
  hidden: false
  id: 6564d4fdedae9c33b76ff1f4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b35649453e4383a8df92af0c05148f4d.svg
      fullname: Angel Igareta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: angeligareta
      type: user
    createdAt: '2023-11-28T14:19:57.000Z'
    data:
      edited: false
      editors:
      - angeligareta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7183865308761597
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b35649453e4383a8df92af0c05148f4d.svg
          fullname: Angel Igareta
          isHf: false
          isPro: false
          name: angeligareta
          type: user
        html: "<p>This was an error from Sagemaker. A workaround is to generate your\
          \ own dockerfile with TGI</p>\n<pre><code>FROM ghcr.io/huggingface/text-generation-inference:1.1.0\n\
          \nCOPY sagemaker-entrypoint.sh entrypoint.sh\nRUN chmod +x entrypoint.sh\n\
          \nENTRYPOINT [\"./entrypoint.sh\"]\n</code></pre>\n<p>Then build it and\
          \ upload it to ECR and then input that image_uri to the HuggingFaceModel\
          \ </p>\n<pre><code>huggingface_model = HuggingFaceModel(\n    image_uri=custom_image_uri,\n\
          \    env=hub,\n    role=role, \n)\n</code></pre>\n"
        raw: "This was an error from Sagemaker. A workaround is to generate your own\
          \ dockerfile with TGI\n```\nFROM ghcr.io/huggingface/text-generation-inference:1.1.0\n\
          \nCOPY sagemaker-entrypoint.sh entrypoint.sh\nRUN chmod +x entrypoint.sh\n\
          \nENTRYPOINT [\"./entrypoint.sh\"]\n```\n\nThen build it and upload it to\
          \ ECR and then input that image_uri to the HuggingFaceModel \n```\nhuggingface_model\
          \ = HuggingFaceModel(\n\timage_uri=custom_image_uri,\n\tenv=hub,\n\trole=role,\
          \ \n)\n```"
        updatedAt: '2023-11-28T14:19:57.831Z'
      numEdits: 0
      reactions: []
    id: 6565f70de7be83d4993c2eb5
    type: comment
  author: angeligareta
  content: "This was an error from Sagemaker. A workaround is to generate your own\
    \ dockerfile with TGI\n```\nFROM ghcr.io/huggingface/text-generation-inference:1.1.0\n\
    \nCOPY sagemaker-entrypoint.sh entrypoint.sh\nRUN chmod +x entrypoint.sh\n\nENTRYPOINT\
    \ [\"./entrypoint.sh\"]\n```\n\nThen build it and upload it to ECR and then input\
    \ that image_uri to the HuggingFaceModel \n```\nhuggingface_model = HuggingFaceModel(\n\
    \timage_uri=custom_image_uri,\n\tenv=hub,\n\trole=role, \n)\n```"
  created_at: 2023-11-28 14:19:57+00:00
  edited: false
  hidden: false
  id: 6565f70de7be83d4993c2eb5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/b35649453e4383a8df92af0c05148f4d.svg
      fullname: Angel Igareta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: angeligareta
      type: user
    createdAt: '2023-11-28T14:20:25.000Z'
    data:
      status: closed
    id: 6565f729dee7d2c57a74baa9
    type: status-change
  author: angeligareta
  created_at: 2023-11-28 14:20:25+00:00
  id: 6565f729dee7d2c57a74baa9
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: 01-ai/Yi-34B-Chat-4bits
repo_type: model
status: closed
target_branch: null
title: Not working in TGI
