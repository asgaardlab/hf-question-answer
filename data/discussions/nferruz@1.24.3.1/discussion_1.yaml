!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ShanGao
conflicting_files: null
created_at: 2023-11-13 14:45:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6fef1b4597d3f0bf8d019efaf75e0174.svg
      fullname: Yuanji Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShanGao
      type: user
    createdAt: '2023-11-13T14:45:55.000Z'
    data:
      edited: false
      editors:
      - ShanGao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8646621704101562
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6fef1b4597d3f0bf8d019efaf75e0174.svg
          fullname: Yuanji Zhang
          isHf: false
          isPro: false
          name: ShanGao
          type: user
        html: '<p>Dear Authors,</p>

          <p>Thanks for sharing the model. I read your manuscript and it looks a very
          interesting model. So I played a little bit but didn''t get expected results.
          I tried several different enzymes, and each time the generated sequences
          are very different from the prompt enzyme, but similar to GFP regardless
          which enzymes I tried to generate.</p>

          <p>Here is how I called:</p>

          <p>model = AutoModelForCausalLM.from_pretrained("nferruz/1.24.3.1").to(device)<br>tokenizer
          = AutoTokenizer.from_pretrained("nferruz/1.24.3.1")<br>my_pipe = pipeline(''text-generation'',
          model=model, tokenizer=tokenizer, device=device)<br>prompt = "2.3.1.4"    #
          example prompt value. Also tried others<br>sequences = my_pipe(prompt,  repetition_penalty=1.2,
          top_k=9, top_p=1.0, temperature=1.0, ...)</p>

          <p>Please advice.</p>

          <p>Thanks!</p>

          '
        raw: "Dear Authors,\r\n\r\nThanks for sharing the model. I read your manuscript\
          \ and it looks a very interesting model. So I played a little bit but didn't\
          \ get expected results. I tried several different enzymes, and each time\
          \ the generated sequences are very different from the prompt enzyme, but\
          \ similar to GFP regardless which enzymes I tried to generate.\r\n\r\nHere\
          \ is how I called:\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(\"\
          nferruz/1.24.3.1\").to(device)\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
          nferruz/1.24.3.1\")\r\nmy_pipe = pipeline('text-generation', model=model,\
          \ tokenizer=tokenizer, device=device)\r\nprompt = \"2.3.1.4\"    # example\
          \ prompt value. Also tried others\r\nsequences = my_pipe(prompt,  repetition_penalty=1.2,\
          \ top_k=9, top_p=1.0, temperature=1.0, ...)\r\n   \r\nPlease advice.\r\n\
          \r\nThanks!\r\n\r\n"
        updatedAt: '2023-11-13T14:45:55.986Z'
      numEdits: 0
      reactions: []
    id: 655236a39c444f80ee5f9d25
    type: comment
  author: ShanGao
  content: "Dear Authors,\r\n\r\nThanks for sharing the model. I read your manuscript\
    \ and it looks a very interesting model. So I played a little bit but didn't get\
    \ expected results. I tried several different enzymes, and each time the generated\
    \ sequences are very different from the prompt enzyme, but similar to GFP regardless\
    \ which enzymes I tried to generate.\r\n\r\nHere is how I called:\r\n\r\nmodel\
    \ = AutoModelForCausalLM.from_pretrained(\"nferruz/1.24.3.1\").to(device)\r\n\
    tokenizer = AutoTokenizer.from_pretrained(\"nferruz/1.24.3.1\")\r\nmy_pipe = pipeline('text-generation',\
    \ model=model, tokenizer=tokenizer, device=device)\r\nprompt = \"2.3.1.4\"   \
    \ # example prompt value. Also tried others\r\nsequences = my_pipe(prompt,  repetition_penalty=1.2,\
    \ top_k=9, top_p=1.0, temperature=1.0, ...)\r\n   \r\nPlease advice.\r\n\r\nThanks!\r\
    \n\r\n"
  created_at: 2023-11-13 14:45:55+00:00
  edited: false
  hidden: false
  id: 655236a39c444f80ee5f9d25
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
      fullname: Noelia Ferruz
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nferruz
      type: user
    createdAt: '2023-11-13T14:52:20.000Z'
    data:
      edited: false
      editors:
      - nferruz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8738682866096497
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
          fullname: Noelia Ferruz
          isHf: false
          isPro: false
          name: nferruz
          type: user
        html: '<p>Hi, this is a fine-tuned model on the 1.24.3.1 class. So it will
          only output sequences from that class. If you''d like to generate from a
          different enzyme, please use Zymctrl: <a href="https://huggingface.co/AI4PD/ZymCTRL">https://huggingface.co/AI4PD/ZymCTRL</a></p>

          <p>Best<br>Noelia</p>

          '
        raw: 'Hi, this is a fine-tuned model on the 1.24.3.1 class. So it will only
          output sequences from that class. If you''d like to generate from a different
          enzyme, please use Zymctrl: https://huggingface.co/AI4PD/ZymCTRL


          Best

          Noelia'
        updatedAt: '2023-11-13T14:52:20.419Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6552382446569cb3b4451bc3
    id: 6552382446569cb3b4451bbd
    type: comment
  author: nferruz
  content: 'Hi, this is a fine-tuned model on the 1.24.3.1 class. So it will only
    output sequences from that class. If you''d like to generate from a different
    enzyme, please use Zymctrl: https://huggingface.co/AI4PD/ZymCTRL


    Best

    Noelia'
  created_at: 2023-11-13 14:52:20+00:00
  edited: false
  hidden: false
  id: 6552382446569cb3b4451bbd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
      fullname: Noelia Ferruz
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nferruz
      type: user
    createdAt: '2023-11-13T14:52:20.000Z'
    data:
      status: closed
    id: 6552382446569cb3b4451bc3
    type: status-change
  author: nferruz
  created_at: 2023-11-13 14:52:20+00:00
  id: 6552382446569cb3b4451bc3
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: nferruz/1.24.3.1
repo_type: model
status: closed
target_branch: null
title: How to provide the prompt
