!!python/object:huggingface_hub.community.DiscussionWithDetails
author: CamiloMM
conflicting_files: null
created_at: 2023-12-13 22:08:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/14570e9514625800a440f40fec36ed6e.svg
      fullname: Camilo Martin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CamiloMM
      type: user
    createdAt: '2023-12-13T22:08:53.000Z'
    data:
      edited: false
      editors:
      - CamiloMM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9065455198287964
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/14570e9514625800a440f40fec36ed6e.svg
          fullname: Camilo Martin
          isHf: false
          isPro: false
          name: CamiloMM
          type: user
        html: "<p>Was gonna finally learn how to do it but hey if you're already doing\
          \ it \U0001F4A6</p>\n<p>Much thanks \U0001F64F fantastic model, honestly\
          \ quite impressive in the GGUF.</p>\n"
        raw: "Was gonna finally learn how to do it but hey if you're already doing\
          \ it \U0001F4A6\r\n\r\nMuch thanks \U0001F64F fantastic model, honestly\
          \ quite impressive in the GGUF."
        updatedAt: '2023-12-13T22:08:53.449Z'
      numEdits: 0
      reactions: []
    id: 657a2b7580141bab5dce6cc7
    type: comment
  author: CamiloMM
  content: "Was gonna finally learn how to do it but hey if you're already doing it\
    \ \U0001F4A6\r\n\r\nMuch thanks \U0001F64F fantastic model, honestly quite impressive\
    \ in the GGUF."
  created_at: 2023-12-13 22:08:53+00:00
  edited: false
  hidden: false
  id: 657a2b7580141bab5dce6cc7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/633a809fa4a8f33508dce32c/m3tP8ibrZK0qOla00g2rq.png?w=200&h=200&f=face
      fullname: Raven
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: athirdpath
      type: user
    createdAt: '2023-12-13T22:34:02.000Z'
    data:
      edited: false
      editors:
      - athirdpath
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9828018546104431
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/633a809fa4a8f33508dce32c/m3tP8ibrZK0qOla00g2rq.png?w=200&h=200&f=face
          fullname: Raven
          isHf: false
          isPro: false
          name: athirdpath
          type: user
        html: '<p>I''m going to guess that''s ~5.5 to 6 bpw? If so, sure!</p>

          '
        raw: I'm going to guess that's ~5.5 to 6 bpw? If so, sure!
        updatedAt: '2023-12-13T22:34:02.070Z'
      numEdits: 0
      reactions: []
    id: 657a315a9ad6bcff7e517edf
    type: comment
  author: athirdpath
  content: I'm going to guess that's ~5.5 to 6 bpw? If so, sure!
  created_at: 2023-12-13 22:34:02+00:00
  edited: false
  hidden: false
  id: 657a315a9ad6bcff7e517edf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/14570e9514625800a440f40fec36ed6e.svg
      fullname: Camilo Martin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CamiloMM
      type: user
    createdAt: '2023-12-14T17:08:02.000Z'
    data:
      edited: false
      editors:
      - CamiloMM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9742738604545593
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/14570e9514625800a440f40fec36ed6e.svg
          fullname: Camilo Martin
          isHf: false
          isPro: false
          name: CamiloMM
          type: user
        html: '<p>Yes please!</p>

          <p>(...I actually have no idea, I imagine ~5.5 to 6 bpw is fine since 24GB
          runs 70b at 2.3bpw fine, which... would mean even 8bpw is fine for a 20b?
          (not sure if it''s as simple as parameters * bpw * x = VRAM)<br>Though that''s
          probably pushing it and even 5bpw is already diminishing returns, I imagine.
          I''d make it 6bpw.)</p>

          '
        raw: 'Yes please!


          (...I actually have no idea, I imagine ~5.5 to 6 bpw is fine since 24GB
          runs 70b at 2.3bpw fine, which... would mean even 8bpw is fine for a 20b?
          (not sure if it''s as simple as parameters * bpw * x = VRAM)

          Though that''s probably pushing it and even 5bpw is already diminishing
          returns, I imagine. I''d make it 6bpw.)'
        updatedAt: '2023-12-14T17:08:02.231Z'
      numEdits: 0
      reactions: []
    id: 657b36722cbb7f6382355049
    type: comment
  author: CamiloMM
  content: 'Yes please!


    (...I actually have no idea, I imagine ~5.5 to 6 bpw is fine since 24GB runs 70b
    at 2.3bpw fine, which... would mean even 8bpw is fine for a 20b? (not sure if
    it''s as simple as parameters * bpw * x = VRAM)

    Though that''s probably pushing it and even 5bpw is already diminishing returns,
    I imagine. I''d make it 6bpw.)'
  created_at: 2023-12-14 17:08:02+00:00
  edited: false
  hidden: false
  id: 657b36722cbb7f6382355049
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: athirdpath/Iambe-RP-v3-20b-EXL2-3bpw
repo_type: model
status: open
target_branch: null
title: Can you quantize one for 24GB cards too?
