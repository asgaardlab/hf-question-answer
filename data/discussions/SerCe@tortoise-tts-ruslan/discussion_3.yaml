!!python/object:huggingface_hub.community.DiscussionWithDetails
author: yeserumo11
conflicting_files: null
created_at: 2023-08-31 06:59:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/71d0767201d329ae659ed3bc9500a0af.svg
      fullname: songjiaxuan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yeserumo11
      type: user
    createdAt: '2023-08-31T07:59:31.000Z'
    data:
      edited: false
      editors:
      - yeserumo11
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6367504596710205
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/71d0767201d329ae659ed3bc9500a0af.svg
          fullname: songjiaxuan
          isHf: false
          isPro: false
          name: yeserumo11
          type: user
        html: '<p>hey bro, what the tokenizer you use for rus, Is it the default tokeniser
          provided by mrq?</p>

          '
        raw: hey bro, what the tokenizer you use for rus, Is it the default tokeniser
          provided by mrq?
        updatedAt: '2023-08-31T07:59:31.377Z'
      numEdits: 0
      reactions: []
    id: 64f04863440d8697101779d4
    type: comment
  author: yeserumo11
  content: hey bro, what the tokenizer you use for rus, Is it the default tokeniser
    provided by mrq?
  created_at: 2023-08-31 06:59:31+00:00
  edited: false
  hidden: false
  id: 64f04863440d8697101779d4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/648057418c6a3b8f11f76dab/Zj4GIeq-DYoMLBwdfH2Hf.jpeg?w=200&h=200&f=face
      fullname: Sergey Tselovalnikov
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: SerCe
      type: user
    createdAt: '2023-08-31T11:14:21.000Z'
    data:
      edited: false
      editors:
      - SerCe
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9433324337005615
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/648057418c6a3b8f11f76dab/Zj4GIeq-DYoMLBwdfH2Hf.jpeg?w=200&h=200&f=face
          fullname: Sergey Tselovalnikov
          isHf: false
          isPro: false
          name: SerCe
          type: user
        html: "<p>Hi, <span data-props=\"{&quot;user&quot;:&quot;yeserumo11&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/yeserumo11\"\
          >@<span class=\"underline\">yeserumo11</span></a></span>\n\n\t</span></span>!\
          \ Yes, I didn't do any changes to the tokeniser. My understanding is that\
          \ fine-tuning wouldn't really be possible if I changed the tokeniser. The\
          \ original can already produce results in Russian, though with a strong\
          \ accent. </p>\n"
        raw: 'Hi, @yeserumo11! Yes, I didn''t do any changes to the tokeniser. My
          understanding is that fine-tuning wouldn''t really be possible if I changed
          the tokeniser. The original can already produce results in Russian, though
          with a strong accent. '
        updatedAt: '2023-08-31T11:14:21.370Z'
      numEdits: 0
      reactions: []
    id: 64f0760d100e59529d4624f2
    type: comment
  author: SerCe
  content: 'Hi, @yeserumo11! Yes, I didn''t do any changes to the tokeniser. My understanding
    is that fine-tuning wouldn''t really be possible if I changed the tokeniser. The
    original can already produce results in Russian, though with a strong accent. '
  created_at: 2023-08-31 10:14:21+00:00
  edited: false
  hidden: false
  id: 64f0760d100e59529d4624f2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/71d0767201d329ae659ed3bc9500a0af.svg
      fullname: songjiaxuan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yeserumo11
      type: user
    createdAt: '2023-09-01T07:20:43.000Z'
    data:
      edited: true
      editors:
      - yeserumo11
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.909928560256958
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/71d0767201d329ae659ed3bc9500a0af.svg
          fullname: songjiaxuan
          isHf: false
          isPro: false
          name: yeserumo11
          type: user
        html: '<p>thank you, one more question, im not sure if im understandling this
          correctly, the training audio is single-speaker audio clip, so when generate
          with the trained model, it can generate the voice like the guy and speak
          textual content that has not appeared in the training data. But it may performace
          bad if i want to generate another person''s voice using this model, is that
          right? So i should train a model for every single speaker.</p>

          '
        raw: thank you, one more question, im not sure if im understandling this correctly,
          the training audio is single-speaker audio clip, so when generate with the
          trained model, it can generate the voice like the guy and speak textual
          content that has not appeared in the training data. But it may performace
          bad if i want to generate another person's voice using this model, is that
          right? So i should train a model for every single speaker.
        updatedAt: '2023-09-01T07:21:49.380Z'
      numEdits: 2
      reactions: []
    id: 64f190cb5566e017e8723386
    type: comment
  author: yeserumo11
  content: thank you, one more question, im not sure if im understandling this correctly,
    the training audio is single-speaker audio clip, so when generate with the trained
    model, it can generate the voice like the guy and speak textual content that has
    not appeared in the training data. But it may performace bad if i want to generate
    another person's voice using this model, is that right? So i should train a model
    for every single speaker.
  created_at: 2023-09-01 06:20:43+00:00
  edited: true
  hidden: false
  id: 64f190cb5566e017e8723386
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/71d0767201d329ae659ed3bc9500a0af.svg
      fullname: songjiaxuan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yeserumo11
      type: user
    createdAt: '2023-09-01T07:21:59.000Z'
    data:
      edited: false
      editors:
      - yeserumo11
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9000289440155029
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/71d0767201d329ae659ed3bc9500a0af.svg
          fullname: songjiaxuan
          isHf: false
          isPro: false
          name: yeserumo11
          type: user
        html: '<blockquote>

          <p>thank you, one more question, im not sure if im understandling this correctly,
          the training audio is single-speaker audio clip, so when generate with the
          trained model, it can generate the voice like the guy and speak textual
          content that has not appeared in the training data. But it may performace
          bad if i want to generate another person''s voice using this model, is that
          right? So i should train a model for every single speaker.</p>

          </blockquote>

          '
        raw: '> thank you, one more question, im not sure if im understandling this
          correctly, the training audio is single-speaker audio clip, so when generate
          with the trained model, it can generate the voice like the guy and speak
          textual content that has not appeared in the training data. But it may performace
          bad if i want to generate another person''s voice using this model, is that
          right? So i should train a model for every single speaker.


          '
        updatedAt: '2023-09-01T07:21:59.642Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64f19117a111bc63b87a2128
    id: 64f19117a111bc63b87a2126
    type: comment
  author: yeserumo11
  content: '> thank you, one more question, im not sure if im understandling this
    correctly, the training audio is single-speaker audio clip, so when generate with
    the trained model, it can generate the voice like the guy and speak textual content
    that has not appeared in the training data. But it may performace bad if i want
    to generate another person''s voice using this model, is that right? So i should
    train a model for every single speaker.


    '
  created_at: 2023-09-01 06:21:59+00:00
  edited: false
  hidden: false
  id: 64f19117a111bc63b87a2126
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/71d0767201d329ae659ed3bc9500a0af.svg
      fullname: songjiaxuan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yeserumo11
      type: user
    createdAt: '2023-09-01T07:21:59.000Z'
    data:
      status: closed
    id: 64f19117a111bc63b87a2128
    type: status-change
  author: yeserumo11
  created_at: 2023-09-01 06:21:59+00:00
  id: 64f19117a111bc63b87a2128
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/71d0767201d329ae659ed3bc9500a0af.svg
      fullname: songjiaxuan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yeserumo11
      type: user
    createdAt: '2023-09-01T07:22:08.000Z'
    data:
      status: open
    id: 64f19120a111bc63b87a2299
    type: status-change
  author: yeserumo11
  created_at: 2023-09-01 06:22:08+00:00
  id: 64f19120a111bc63b87a2299
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/f9Up4tnICZJBDxkxTQGKD.jpeg?w=200&h=200&f=face
      fullname: GuenKainto
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: GuenKainto
      type: user
    createdAt: '2023-12-27T02:29:48.000Z'
    data:
      edited: false
      editors:
      - GuenKainto
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.913684070110321
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/f9Up4tnICZJBDxkxTQGKD.jpeg?w=200&h=200&f=face
          fullname: GuenKainto
          isHf: false
          isPro: false
          name: GuenKainto
          type: user
        html: '<blockquote>

          <p>thank you, one more question, im not sure if im understandling this correctly,
          the training audio is single-speaker audio clip, so when generate with the
          trained model, it can generate the voice like the guy and speak textual
          content that has not appeared in the training data. But it may performace
          bad if i want to generate another person''s voice using this model, is that
          right? So i should train a model for every single speaker.</p>

          </blockquote>

          <p>no , because<br>"Tortoise is a text-to-speech program built with the
          following priorities:</p>

          <ul>

          <li>Strong multi-voice capabilities.</li>

          <li>Highly realistic prosody and intonation.<br>This repo contains all the
          code needed to run Tortoise TTS in inference mode."<br><a rel="nofollow"
          href="https://github.com/neonbjb/tortoise-tts">https://github.com/neonbjb/tortoise-tts</a></li>

          </ul>

          <p>you can see it support strong multi-voice speaker<br>In case your model
          run wrong, can''t clone another voice, maybe you training model wrong way
          </p>

          '
        raw: "> thank you, one more question, im not sure if im understandling this\
          \ correctly, the training audio is single-speaker audio clip, so when generate\
          \ with the trained model, it can generate the voice like the guy and speak\
          \ textual content that has not appeared in the training data. But it may\
          \ performace bad if i want to generate another person's voice using this\
          \ model, is that right? So i should train a model for every single speaker.\n\
          \nno , because \n\"Tortoise is a text-to-speech program built with the following\
          \ priorities:\n  - Strong multi-voice capabilities.\n - Highly realistic\
          \ prosody and intonation.\nThis repo contains all the code needed to run\
          \ Tortoise TTS in inference mode.\"\nhttps://github.com/neonbjb/tortoise-tts\n\
          \nyou can see it support strong multi-voice speaker\nIn case your model\
          \ run wrong, can't clone another voice, maybe you training model wrong way "
        updatedAt: '2023-12-27T02:29:48.422Z'
      numEdits: 0
      reactions: []
    id: 658b8c1c2e1f5bf05c24ec33
    type: comment
  author: GuenKainto
  content: "> thank you, one more question, im not sure if im understandling this\
    \ correctly, the training audio is single-speaker audio clip, so when generate\
    \ with the trained model, it can generate the voice like the guy and speak textual\
    \ content that has not appeared in the training data. But it may performace bad\
    \ if i want to generate another person's voice using this model, is that right?\
    \ So i should train a model for every single speaker.\n\nno , because \n\"Tortoise\
    \ is a text-to-speech program built with the following priorities:\n  - Strong\
    \ multi-voice capabilities.\n - Highly realistic prosody and intonation.\nThis\
    \ repo contains all the code needed to run Tortoise TTS in inference mode.\"\n\
    https://github.com/neonbjb/tortoise-tts\n\nyou can see it support strong multi-voice\
    \ speaker\nIn case your model run wrong, can't clone another voice, maybe you\
    \ training model wrong way "
  created_at: 2023-12-27 02:29:48+00:00
  edited: false
  hidden: false
  id: 658b8c1c2e1f5bf05c24ec33
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: SerCe/tortoise-tts-ruslan
repo_type: model
status: open
target_branch: null
title: tokenizer
