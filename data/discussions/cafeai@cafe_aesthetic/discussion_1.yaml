!!python/object:huggingface_hub.community.DiscussionWithDetails
author: teknium
conflicting_files: null
created_at: 2023-01-06 05:22:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-01-06T05:22:32.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>I want to run it from a python script to judge image gens automatically.
          Possible? Any guide to run these?</p>

          '
        raw: I want to run it from a python script to judge image gens automatically.
          Possible? Any guide to run these?
        updatedAt: '2023-01-06T05:22:32.181Z'
      numEdits: 0
      reactions: []
    id: 63b7b018ca2f378e71035923
    type: comment
  author: teknium
  content: I want to run it from a python script to judge image gens automatically.
    Possible? Any guide to run these?
  created_at: 2023-01-06 05:22:32+00:00
  edited: false
  hidden: false
  id: 63b7b018ca2f378e71035923
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/91306552fe5a1ef55a9928df3dfa2627.svg
      fullname: "Josef J\xEDlek"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JosefJilek
      type: user
    createdAt: '2023-02-03T15:45:57.000Z'
    data:
      edited: false
      editors:
      - JosefJilek
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/91306552fe5a1ef55a9928df3dfa2627.svg
          fullname: "Josef J\xEDlek"
          isHf: false
          isPro: false
          name: JosefJilek
          type: user
        html: '<p>One thing you can do is mirror this <a href="https://huggingface.co/spaces/cafeai/cafe_aesthetic_demo/tree/main">https://huggingface.co/spaces/cafeai/cafe_aesthetic_demo/tree/main</a>
          and then use web api from your own python script like this<br>for files
          in os.listdir(directory):<br>    with open(directory + ''/'' + files, "rb")
          as image_file:<br>        encoded_string = base64.b64encode(image_file.read())<br>    response
          = requests.post("<a rel="nofollow" href="http://127.0.0.1:7861/run/predict&quot;">http://127.0.0.1:7861/run/predict"</a>,
          json={<br>        "data": [<br>            "data:image/" + pathlib.Path(files).suffix
          + ";base64," + encoded_string.decode(ENCODING),<br>    ]}).json()<br>    print(response)</p>

          '
        raw: "One thing you can do is mirror this https://huggingface.co/spaces/cafeai/cafe_aesthetic_demo/tree/main\
          \ and then use web api from your own python script like this\nfor files\
          \ in os.listdir(directory):\n\twith open(directory + '/' + files, \"rb\"\
          ) as image_file:\n\t\tencoded_string = base64.b64encode(image_file.read())\n\
          \tresponse = requests.post(\"http://127.0.0.1:7861/run/predict\", json={\n\
          \t\t\"data\": [\n\t\t\t\"data:image/\" + pathlib.Path(files).suffix + \"\
          ;base64,\" + encoded_string.decode(ENCODING),\n\t]}).json()\n\tprint(response)"
        updatedAt: '2023-02-03T15:45:57.778Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - lj1995
        - Vigilence
    id: 63dd2c35ecc0c6cc5f244178
    type: comment
  author: JosefJilek
  content: "One thing you can do is mirror this https://huggingface.co/spaces/cafeai/cafe_aesthetic_demo/tree/main\
    \ and then use web api from your own python script like this\nfor files in os.listdir(directory):\n\
    \twith open(directory + '/' + files, \"rb\") as image_file:\n\t\tencoded_string\
    \ = base64.b64encode(image_file.read())\n\tresponse = requests.post(\"http://127.0.0.1:7861/run/predict\"\
    , json={\n\t\t\"data\": [\n\t\t\t\"data:image/\" + pathlib.Path(files).suffix\
    \ + \";base64,\" + encoded_string.decode(ENCODING),\n\t]}).json()\n\tprint(response)"
  created_at: 2023-02-03 15:45:57+00:00
  edited: false
  hidden: false
  id: 63dd2c35ecc0c6cc5f244178
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9a0c7b0c22845e94c36448109c313787.svg
      fullname: Wuke
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zyddnys
      type: user
    createdAt: '2023-03-05T02:24:13.000Z'
    data:
      edited: false
      editors:
      - zyddnys
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9a0c7b0c22845e94c36448109c313787.svg
          fullname: Wuke
          isHf: false
          isPro: false
          name: zyddnys
          type: user
        html: "<p>sample code</p>\n<pre><code class=\"language-python\"><span class=\"\
          hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span>\
          \ AutoFeatureExtractor, AutoModelForImageClassification\n\nextractor = AutoFeatureExtractor.from_pretrained(<span\
          \ class=\"hljs-string\">\"cafeai/cafe_aesthetic\"</span>)\n\nmodel = AutoModelForImageClassification.from_pretrained(<span\
          \ class=\"hljs-string\">\"cafeai/cafe_aesthetic\"</span>)\n\nfiles = []\n\
          <span class=\"hljs-keyword\">import</span> glob\n<span class=\"hljs-keyword\"\
          >for</span> ext <span class=\"hljs-keyword\">in</span> [<span class=\"hljs-string\"\
          >'.png'</span>, <span class=\"hljs-string\">'.jpg'</span>] :\n    files.extend(glob.glob(<span\
          \ class=\"hljs-string\">'./*'</span> + ext))\n\n<span class=\"hljs-keyword\"\
          >import</span> torch\n<span class=\"hljs-keyword\">import</span> einops\n\
          <span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\"\
          >as</span> np\n<span class=\"hljs-keyword\">from</span> PIL <span class=\"\
          hljs-keyword\">import</span> Image\n<span class=\"hljs-keyword\">with</span>\
          \ torch.no_grad() :\n    <span class=\"hljs-keyword\">for</span> f <span\
          \ class=\"hljs-keyword\">in</span> files :\n        im = Image.<span class=\"\
          hljs-built_in\">open</span>(f).convert(<span class=\"hljs-string\">'RGB'</span>)\n\
          \        im = einops.rearrange(extractor(im).data[<span class=\"hljs-string\"\
          >'pixel_values'</span>][<span class=\"hljs-number\">0</span>], <span class=\"\
          hljs-string\">'c h w-&gt;1 c h w'</span>)\n        score = model(torch.from_numpy(im)).logits.softmax(dim\
          \ = -<span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">0</span>][-<span\
          \ class=\"hljs-number\">1</span>].item()\n        <span class=\"hljs-built_in\"\
          >print</span>(f, score)\n\n</code></pre>\n"
        raw: "sample code\n```python\nfrom transformers import AutoFeatureExtractor,\
          \ AutoModelForImageClassification\n\nextractor = AutoFeatureExtractor.from_pretrained(\"\
          cafeai/cafe_aesthetic\")\n\nmodel = AutoModelForImageClassification.from_pretrained(\"\
          cafeai/cafe_aesthetic\")\n\nfiles = []\nimport glob\nfor ext in ['.png',\
          \ '.jpg'] :\n    files.extend(glob.glob('./*' + ext))\n\nimport torch\n\
          import einops\nimport numpy as np\nfrom PIL import Image\nwith torch.no_grad()\
          \ :\n    for f in files :\n        im = Image.open(f).convert('RGB')\n \
          \       im = einops.rearrange(extractor(im).data['pixel_values'][0], 'c\
          \ h w->1 c h w')\n        score = model(torch.from_numpy(im)).logits.softmax(dim\
          \ = -1)[0][-1].item()\n        print(f, score)\n\n\n```"
        updatedAt: '2023-03-05T02:24:13.264Z'
      numEdits: 0
      reactions: []
    id: 6403fd4d66f4a994f149cef8
    type: comment
  author: zyddnys
  content: "sample code\n```python\nfrom transformers import AutoFeatureExtractor,\
    \ AutoModelForImageClassification\n\nextractor = AutoFeatureExtractor.from_pretrained(\"\
    cafeai/cafe_aesthetic\")\n\nmodel = AutoModelForImageClassification.from_pretrained(\"\
    cafeai/cafe_aesthetic\")\n\nfiles = []\nimport glob\nfor ext in ['.png', '.jpg']\
    \ :\n    files.extend(glob.glob('./*' + ext))\n\nimport torch\nimport einops\n\
    import numpy as np\nfrom PIL import Image\nwith torch.no_grad() :\n    for f in\
    \ files :\n        im = Image.open(f).convert('RGB')\n        im = einops.rearrange(extractor(im).data['pixel_values'][0],\
    \ 'c h w->1 c h w')\n        score = model(torch.from_numpy(im)).logits.softmax(dim\
    \ = -1)[0][-1].item()\n        print(f, score)\n\n\n```"
  created_at: 2023-03-05 02:24:13+00:00
  edited: false
  hidden: false
  id: 6403fd4d66f4a994f149cef8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: cafeai/cafe_aesthetic
repo_type: model
status: open
target_branch: null
title: Hi is there any guide to run on my own PC?
