!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SimoDR
conflicting_files: null
created_at: 2023-06-10 07:43:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ff22b45710703a8fb6c777dbae0de075.svg
      fullname: Simone De Renzis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SimoDR
      type: user
    createdAt: '2023-06-10T08:43:25.000Z'
    data:
      edited: false
      editors:
      - SimoDR
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8710655570030212
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ff22b45710703a8fb6c777dbae0de075.svg
          fullname: Simone De Renzis
          isHf: false
          isPro: false
          name: SimoDR
          type: user
        html: '<p>Hi, thank you for the model, this works great, any chance you could
          provide also the 4bit quantized version for the 13b model as in <a href="https://huggingface.co/openlm-research/open_llama_13b_600bt">https://huggingface.co/openlm-research/open_llama_13b_600bt</a>?</p>

          '
        raw: Hi, thank you for the model, this works great, any chance you could provide
          also the 4bit quantized version for the 13b model as in https://huggingface.co/openlm-research/open_llama_13b_600bt?
        updatedAt: '2023-06-10T08:43:25.408Z'
      numEdits: 0
      reactions: []
    id: 648437adc631d81a7959d457
    type: comment
  author: SimoDR
  content: Hi, thank you for the model, this works great, any chance you could provide
    also the 4bit quantized version for the 13b model as in https://huggingface.co/openlm-research/open_llama_13b_600bt?
  created_at: 2023-06-10 07:43:25+00:00
  edited: false
  hidden: false
  id: 648437adc631d81a7959d457
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-10T08:55:14.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9663733839988708
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I''ve been holding off because a) it''s not finished training, and
          b) there are no instruction tuned versions of it yet (that I know of)</p>

          <p>This 7B model has been Alpaca instruction fine tuned, so it''s pretty
          good at answering questions and following instructions.</p>

          <p>If I train that base Open Llama 13B model, it will be like Llama 13B
          in that it will generate text but not be very good at answering questions.  But
          it''ll actually be worse than that, because so far it''s only been trained
          on 600B tokens, compared to the 1T tokens in Llama 13B.</p>

          <p>So TBH I think it''ll be pretty bad :(</p>

          '
        raw: 'I''ve been holding off because a) it''s not finished training, and b)
          there are no instruction tuned versions of it yet (that I know of)


          This 7B model has been Alpaca instruction fine tuned, so it''s pretty good
          at answering questions and following instructions.


          If I train that base Open Llama 13B model, it will be like Llama 13B in
          that it will generate text but not be very good at answering questions.  But
          it''ll actually be worse than that, because so far it''s only been trained
          on 600B tokens, compared to the 1T tokens in Llama 13B.


          So TBH I think it''ll be pretty bad :('
        updatedAt: '2023-06-10T08:55:43.026Z'
      numEdits: 1
      reactions: []
    id: 64843a728bfaf80dd4db8a3c
    type: comment
  author: TheBloke
  content: 'I''ve been holding off because a) it''s not finished training, and b)
    there are no instruction tuned versions of it yet (that I know of)


    This 7B model has been Alpaca instruction fine tuned, so it''s pretty good at
    answering questions and following instructions.


    If I train that base Open Llama 13B model, it will be like Llama 13B in that it
    will generate text but not be very good at answering questions.  But it''ll actually
    be worse than that, because so far it''s only been trained on 600B tokens, compared
    to the 1T tokens in Llama 13B.


    So TBH I think it''ll be pretty bad :('
  created_at: 2023-06-10 07:55:14+00:00
  edited: true
  hidden: false
  id: 64843a728bfaf80dd4db8a3c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ff22b45710703a8fb6c777dbae0de075.svg
      fullname: Simone De Renzis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SimoDR
      type: user
    createdAt: '2023-06-10T09:01:32.000Z'
    data:
      edited: false
      editors:
      - SimoDR
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9475406408309937
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ff22b45710703a8fb6c777dbae0de075.svg
          fullname: Simone De Renzis
          isHf: false
          isPro: false
          name: SimoDR
          type: user
        html: '<p>Alright, let''s hope they''ll release it soon then! Thanks again
          for your work</p>

          '
        raw: Alright, let's hope they'll release it soon then! Thanks again for your
          work
        updatedAt: '2023-06-10T09:01:32.806Z'
      numEdits: 0
      reactions: []
    id: 64843becbe9419bb3743521a
    type: comment
  author: SimoDR
  content: Alright, let's hope they'll release it soon then! Thanks again for your
    work
  created_at: 2023-06-10 08:01:32+00:00
  edited: false
  hidden: false
  id: 64843becbe9419bb3743521a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/open-llama-7b-open-instruct-GPTQ
repo_type: model
status: open
target_branch: null
title: Any chance for the 13b model?
