!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Thireus
conflicting_files: null
created_at: 2023-12-12 21:17:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af1201cb8f07eba487669586f75a4b32.svg
      fullname: None
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Thireus
      type: user
    createdAt: '2023-12-12T21:17:35.000Z'
    data:
      edited: false
      editors:
      - Thireus
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9393867254257202
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af1201cb8f07eba487669586f75a4b32.svg
          fullname: None
          isHf: false
          isPro: false
          name: Thireus
          type: user
        html: '<p>Would you be able to issue a exl2-2 version of this 6.0bpw model
          please? :)</p>

          '
        raw: Would you be able to issue a exl2-2 version of this 6.0bpw model please?
          :)
        updatedAt: '2023-12-12T21:17:35.943Z'
      numEdits: 0
      reactions: []
    id: 6578cdef23b2859ba25f10f7
    type: comment
  author: Thireus
  content: Would you be able to issue a exl2-2 version of this 6.0bpw model please?
    :)
  created_at: 2023-12-12 21:17:35+00:00
  edited: false
  hidden: false
  id: 6578cdef23b2859ba25f10f7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-12-13T10:05:02.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9773396253585815
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>I''ll put it no my list. I''m not sure how much improvements we''ll
          see for the 6bpw model. For the lower bpw models, things are definitely
          better.</p>

          '
        raw: I'll put it no my list. I'm not sure how much improvements we'll see
          for the 6bpw model. For the lower bpw models, things are definitely better.
        updatedAt: '2023-12-13T10:05:02.500Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Thireus
        - eramax
    id: 657981cedd2996f01a2ce6c6
    type: comment
  author: LoneStriker
  content: I'll put it no my list. I'm not sure how much improvements we'll see for
    the 6bpw model. For the lower bpw models, things are definitely better.
  created_at: 2023-12-13 10:05:02+00:00
  edited: false
  hidden: false
  id: 657981cedd2996f01a2ce6c6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af1201cb8f07eba487669586f75a4b32.svg
      fullname: None
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Thireus
      type: user
    createdAt: '2023-12-13T17:18:54.000Z'
    data:
      edited: false
      editors:
      - Thireus
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9888244867324829
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af1201cb8f07eba487669586f75a4b32.svg
          fullname: None
          isHf: false
          isPro: false
          name: Thireus
          type: user
        html: '<p>Indeed, I don''t expect much improvements either but very curious
          to see the results. Thank you.</p>

          '
        raw: Indeed, I don't expect much improvements either but very curious to see
          the results. Thank you.
        updatedAt: '2023-12-13T17:18:54.155Z'
      numEdits: 0
      reactions: []
    id: 6579e77eb2ad12b875be3d07
    type: comment
  author: Thireus
  content: Indeed, I don't expect much improvements either but very curious to see
    the results. Thank you.
  created_at: 2023-12-13 17:18:54+00:00
  edited: false
  hidden: false
  id: 6579e77eb2ad12b875be3d07
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-12-13T20:34:48.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9090235233306885
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>It''s up, but with a caveat: the quant enhancements have not been
          finalized, so there''s a chance we may have to redo the quants.  Worth a
          test though to compare:<br><a href="https://huggingface.co/LoneStriker/dolphin-2.2-70b-6.0bpw-h6-exl2-2">https://huggingface.co/LoneStriker/dolphin-2.2-70b-6.0bpw-h6-exl2-2</a></p>

          '
        raw: 'It''s up, but with a caveat: the quant enhancements have not been finalized,
          so there''s a chance we may have to redo the quants.  Worth a test though
          to compare:

          https://huggingface.co/LoneStriker/dolphin-2.2-70b-6.0bpw-h6-exl2-2'
        updatedAt: '2023-12-13T20:34:48.545Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Thireus
    id: 657a1568ff53f5227d117786
    type: comment
  author: LoneStriker
  content: 'It''s up, but with a caveat: the quant enhancements have not been finalized,
    so there''s a chance we may have to redo the quants.  Worth a test though to compare:

    https://huggingface.co/LoneStriker/dolphin-2.2-70b-6.0bpw-h6-exl2-2'
  created_at: 2023-12-13 20:34:48+00:00
  edited: false
  hidden: false
  id: 657a1568ff53f5227d117786
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af1201cb8f07eba487669586f75a4b32.svg
      fullname: None
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Thireus
      type: user
    createdAt: '2023-12-14T13:47:23.000Z'
    data:
      edited: true
      editors:
      - Thireus
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.35443153977394104
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af1201cb8f07eba487669586f75a4b32.svg
          fullname: None
          isHf: false
          isPro: false
          name: Thireus
          type: user
        html: '<p>Some improvement on wikitext ppl:</p>

          <ul>

          <li>dolphin-2.2-70b-6.0bpw-h6-exl2: 3.9869189262390137</li>

          <li>dolphin-2.2-70b-6.0bpw-h6-exl2-2: 3.9655632972717285</li>

          </ul>

          '
        raw: 'Some improvement on wikitext ppl:

          - dolphin-2.2-70b-6.0bpw-h6-exl2: 3.9869189262390137

          - dolphin-2.2-70b-6.0bpw-h6-exl2-2: 3.9655632972717285'
        updatedAt: '2023-12-14T15:12:07.998Z'
      numEdits: 1
      reactions: []
    id: 657b076b504b90a3c57b7704
    type: comment
  author: Thireus
  content: 'Some improvement on wikitext ppl:

    - dolphin-2.2-70b-6.0bpw-h6-exl2: 3.9869189262390137

    - dolphin-2.2-70b-6.0bpw-h6-exl2-2: 3.9655632972717285'
  created_at: 2023-12-14 13:47:23+00:00
  edited: true
  hidden: false
  id: 657b076b504b90a3c57b7704
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af1201cb8f07eba487669586f75a4b32.svg
      fullname: None
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Thireus
      type: user
    createdAt: '2023-12-14T13:54:50.000Z'
    data:
      edited: false
      editors:
      - Thireus
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9121143817901611
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af1201cb8f07eba487669586f75a4b32.svg
          fullname: None
          isHf: false
          isPro: false
          name: Thireus
          type: user
        html: '<p>When you say the quant enhancements have not been finalized, which
          step of the conversion process do you mean? Measuring quantization impact...?
          Would it be worth redoing the quants?</p>

          '
        raw: When you say the quant enhancements have not been finalized, which step
          of the conversion process do you mean? Measuring quantization impact...?
          Would it be worth redoing the quants?
        updatedAt: '2023-12-14T13:54:50.431Z'
      numEdits: 0
      reactions: []
    id: 657b092a7ecacd7e1c6f675e
    type: comment
  author: Thireus
  content: When you say the quant enhancements have not been finalized, which step
    of the conversion process do you mean? Measuring quantization impact...? Would
    it be worth redoing the quants?
  created_at: 2023-12-14 13:54:50+00:00
  edited: false
  hidden: false
  id: 657b092a7ecacd7e1c6f675e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-12-15T19:36:34.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9535426497459412
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<blockquote>

          <p>When you say the quant enhancements have not been finalized, which step
          of the conversion process do you mean? Measuring quantization impact...?
          Would it be worth redoing the quants?</p>

          </blockquote>

          <p>Turboderp was still finalizing the quantization enhancements. Initially,
          the new quants showed improvements but had certain instabilities at certain
          model sizes (like 13B.) He''s gone back to using measurements, but faster.
          Both methods improve perplexity substantially, particularly at lower bpw.  At
          this point, ~5bpw is nearly indistinguishable from fp16. I believe that
          the quants I''ve re-done should be good. Going forward, I''ll be using his
          latest measurement method. It should be merged into main shortly (if it
          hasn''t already).</p>

          '
        raw: '> When you say the quant enhancements have not been finalized, which
          step of the conversion process do you mean? Measuring quantization impact...?
          Would it be worth redoing the quants?


          Turboderp was still finalizing the quantization enhancements. Initially,
          the new quants showed improvements but had certain instabilities at certain
          model sizes (like 13B.) He''s gone back to using measurements, but faster.
          Both methods improve perplexity substantially, particularly at lower bpw.  At
          this point, ~5bpw is nearly indistinguishable from fp16. I believe that
          the quants I''ve re-done should be good. Going forward, I''ll be using his
          latest measurement method. It should be merged into main shortly (if it
          hasn''t already).'
        updatedAt: '2023-12-15T19:36:34.646Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Thireus
    id: 657caac2416635415fc934b0
    type: comment
  author: LoneStriker
  content: '> When you say the quant enhancements have not been finalized, which step
    of the conversion process do you mean? Measuring quantization impact...? Would
    it be worth redoing the quants?


    Turboderp was still finalizing the quantization enhancements. Initially, the new
    quants showed improvements but had certain instabilities at certain model sizes
    (like 13B.) He''s gone back to using measurements, but faster. Both methods improve
    perplexity substantially, particularly at lower bpw.  At this point, ~5bpw is
    nearly indistinguishable from fp16. I believe that the quants I''ve re-done should
    be good. Going forward, I''ll be using his latest measurement method. It should
    be merged into main shortly (if it hasn''t already).'
  created_at: 2023-12-15 19:36:34+00:00
  edited: false
  hidden: false
  id: 657caac2416635415fc934b0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12f9b5342345b9d5407828e0139fd7a1.svg
      fullname: cgus
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cgus
      type: user
    createdAt: '2023-12-17T12:33:46.000Z'
    data:
      edited: false
      editors:
      - cgus
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9158928394317627
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12f9b5342345b9d5407828e0139fd7a1.svg
          fullname: cgus
          isHf: false
          isPro: false
          name: cgus
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;LoneStriker&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/LoneStriker\"\
          >@<span class=\"underline\">LoneStriker</span></a></span>\n\n\t</span></span>\
          \ do I understand it correctly that the new quantization method should be\
          \ in newly released 0.0.11 (since dev branch completely merged into it)?<br>And\
          \ that it's enabled when you don't specify a callibration dataset?</p>\n"
        raw: '@LoneStriker do I understand it correctly that the new quantization
          method should be in newly released 0.0.11 (since dev branch completely merged
          into it)?

          And that it''s enabled when you don''t specify a callibration dataset?'
        updatedAt: '2023-12-17T12:33:46.495Z'
      numEdits: 0
      reactions: []
    id: 657eeaaa3687559a67867ebb
    type: comment
  author: cgus
  content: '@LoneStriker do I understand it correctly that the new quantization method
    should be in newly released 0.0.11 (since dev branch completely merged into it)?

    And that it''s enabled when you don''t specify a callibration dataset?'
  created_at: 2023-12-17 12:33:46+00:00
  edited: false
  hidden: false
  id: 657eeaaa3687559a67867ebb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-12-17T12:49:51.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9133318066596985
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>Yes, that''s correct. You will use the default calibration dataset
          that is constructed from a diverse set of different texts. You can still
          specify the calibration dataset if you wish, if for example your model uses
          a language not covered by the built-in one. But, Turbo tried to include
          lots of different text types, so this is almost never needed.</p>

          '
        raw: Yes, that's correct. You will use the default calibration dataset that
          is constructed from a diverse set of different texts. You can still specify
          the calibration dataset if you wish, if for example your model uses a language
          not covered by the built-in one. But, Turbo tried to include lots of different
          text types, so this is almost never needed.
        updatedAt: '2023-12-17T12:49:51.644Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - cgus
    id: 657eee6fefc0f84bcb929780
    type: comment
  author: LoneStriker
  content: Yes, that's correct. You will use the default calibration dataset that
    is constructed from a diverse set of different texts. You can still specify the
    calibration dataset if you wish, if for example your model uses a language not
    covered by the built-in one. But, Turbo tried to include lots of different text
    types, so this is almost never needed.
  created_at: 2023-12-17 12:49:51+00:00
  edited: false
  hidden: false
  id: 657eee6fefc0f84bcb929780
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: LoneStriker/dolphin-2.2-70b-6.0bpw-h6-exl2
repo_type: model
status: open
target_branch: null
title: exl2-2 please?
