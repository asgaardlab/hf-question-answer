!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BoshiAI
conflicting_files: null
created_at: 2023-12-13 09:39:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12ab90a4764939e91ec49b62cb911d70.svg
      fullname: Boshi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BoshiAI
      type: user
    createdAt: '2023-12-13T09:39:56.000Z'
    data:
      edited: true
      editors:
      - BoshiAI
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9707726836204529
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12ab90a4764939e91ec49b62cb911d70.svg
          fullname: Boshi
          isHf: false
          isPro: false
          name: BoshiAI
          type: user
        html: '<p>Hey there!</p>

          <p>I can''t believe you''ve quantized a version of Mythalion with Kimiko
          v2 which supports a 8K context and nobody''s noticed it!?</p>

          <p>For that matter I''m surprised nobody noticed there was a Mythalion Kimiko
          v2 out at all!</p>

          <p>Given that Kimiko is routinely rolled in with MythoMax to improve it
          (so common to see people pushing MythoMax Kimiko over the original), and
          Mythalion is considered a step up from MythoMax too, i''m surprised nobody
          noticed a Mythalion blended with Kimiko!</p>

          <p>How was a 8K context acheved with this? I thought MythoMax only supported
          4K? Or was it capable of more all along? Is it the addition of Kimiko that
          makes a difference here or did you do something else to come up with the
          8K GGUF? Have you actively used this model yourself and how did you find
          it against MythoMax, Mythalion and other models around at the time / since?</p>

          <p>I''ve been using the 8K GGUF of this and it''s working great under Faraday
          for me so far! It seems more soulful/warm in SFW and a little spicier in
          NSFW.    Would love to hear from you on this model, and surprised it hasn''t
          received more attention!</p>

          '
        raw: 'Hey there!


          I can''t believe you''ve quantized a version of Mythalion with Kimiko v2
          which supports a 8K context and nobody''s noticed it!?


          For that matter I''m surprised nobody noticed there was a Mythalion Kimiko
          v2 out at all!


          Given that Kimiko is routinely rolled in with MythoMax to improve it (so
          common to see people pushing MythoMax Kimiko over the original), and Mythalion
          is considered a step up from MythoMax too, i''m surprised nobody noticed
          a Mythalion blended with Kimiko!


          How was a 8K context acheved with this? I thought MythoMax only supported
          4K? Or was it capable of more all along? Is it the addition of Kimiko that
          makes a difference here or did you do something else to come up with the
          8K GGUF? Have you actively used this model yourself and how did you find
          it against MythoMax, Mythalion and other models around at the time / since?


          I''ve been using the 8K GGUF of this and it''s working great under Faraday
          for me so far! It seems more soulful/warm in SFW and a little spicier in
          NSFW.    Would love to hear from you on this model, and surprised it hasn''t
          received more attention!'
        updatedAt: '2023-12-13T11:45:52.795Z'
      numEdits: 3
      reactions: []
    id: 65797bec02233b8d83d7e42c
    type: comment
  author: BoshiAI
  content: 'Hey there!


    I can''t believe you''ve quantized a version of Mythalion with Kimiko v2 which
    supports a 8K context and nobody''s noticed it!?


    For that matter I''m surprised nobody noticed there was a Mythalion Kimiko v2
    out at all!


    Given that Kimiko is routinely rolled in with MythoMax to improve it (so common
    to see people pushing MythoMax Kimiko over the original), and Mythalion is considered
    a step up from MythoMax too, i''m surprised nobody noticed a Mythalion blended
    with Kimiko!


    How was a 8K context acheved with this? I thought MythoMax only supported 4K?
    Or was it capable of more all along? Is it the addition of Kimiko that makes a
    difference here or did you do something else to come up with the 8K GGUF? Have
    you actively used this model yourself and how did you find it against MythoMax,
    Mythalion and other models around at the time / since?


    I''ve been using the 8K GGUF of this and it''s working great under Faraday for
    me so far! It seems more soulful/warm in SFW and a little spicier in NSFW.    Would
    love to hear from you on this model, and surprised it hasn''t received more attention!'
  created_at: 2023-12-13 09:39:56+00:00
  edited: true
  hidden: false
  id: 65797bec02233b8d83d7e42c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12ab90a4764939e91ec49b62cb911d70.svg
      fullname: Boshi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BoshiAI
      type: user
    createdAt: '2023-12-13T11:45:37.000Z'
    data:
      edited: false
      editors:
      - BoshiAI
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9555403590202332
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12ab90a4764939e91ec49b62cb911d70.svg
          fullname: Boshi
          isHf: false
          isPro: false
          name: BoshiAI
          type: user
        html: '<p>Okay this is now OFFICIALLY my favourite model! It''s warmer and
          more creative in SFW, spicer and more creative in NSFW, compared to MythoMax.
          It seems to track character card data better, too. Plus I can use 8K context?
          What''s not to like!? I''m off to tell others about this model now lol.</p>

          '
        raw: Okay this is now OFFICIALLY my favourite model! It's warmer and more
          creative in SFW, spicer and more creative in NSFW, compared to MythoMax.
          It seems to track character card data better, too. Plus I can use 8K context?
          What's not to like!? I'm off to tell others about this model now lol.
        updatedAt: '2023-12-13T11:45:37.279Z'
      numEdits: 0
      reactions: []
    id: 65799961ca3375d36d126dd2
    type: comment
  author: BoshiAI
  content: Okay this is now OFFICIALLY my favourite model! It's warmer and more creative
    in SFW, spicer and more creative in NSFW, compared to MythoMax. It seems to track
    character card data better, too. Plus I can use 8K context? What's not to like!?
    I'm off to tell others about this model now lol.
  created_at: 2023-12-13 11:45:37+00:00
  edited: false
  hidden: false
  id: 65799961ca3375d36d126dd2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/128e142c99913a014009c21fc7b4cdbb.svg
      fullname: GIGAMETTO
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: GIGAMETTO
      type: user
    createdAt: '2023-12-13T14:40:11.000Z'
    data:
      edited: false
      editors:
      - GIGAMETTO
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.915457546710968
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/128e142c99913a014009c21fc7b4cdbb.svg
          fullname: GIGAMETTO
          isHf: false
          isPro: false
          name: GIGAMETTO
          type: user
        html: '<p>Alright, I am going to try this model out, If I remember I will
          give it a casual review ;)</p>

          '
        raw: Alright, I am going to try this model out, If I remember I will give
          it a casual review ;)
        updatedAt: '2023-12-13T14:40:11.427Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - BoshiAI
    id: 6579c24b95e559712cc51180
    type: comment
  author: GIGAMETTO
  content: Alright, I am going to try this model out, If I remember I will give it
    a casual review ;)
  created_at: 2023-12-13 14:40:11+00:00
  edited: false
  hidden: false
  id: 6579c24b95e559712cc51180
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12ab90a4764939e91ec49b62cb911d70.svg
      fullname: Boshi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BoshiAI
      type: user
    createdAt: '2023-12-13T15:29:27.000Z'
    data:
      edited: false
      editors:
      - BoshiAI
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9551464319229126
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12ab90a4764939e91ec49b62cb911d70.svg
          fullname: Boshi
          isHf: false
          isPro: false
          name: BoshiAI
          type: user
        html: '<p>I look forward to reading it!<br>For me, it''s a definite step up
          from MythoMax, with the. combination of Pygmalion and Kimiko together undoubtedly
          helping.  SFW felt warmer and more creative, NSFW felt spicier and more
          creative too.  I''ve read that Pygmalion increases creativity, Kimiko improves
          NSFW and intelligence (inc things like tracking a character card better)
          and makes a model behave more like an RP model.<br>For me, it''s a great
          combo, especially with the 8K context in the 8K GGUF quant actionpace has
          created (though i''d still like to know how that 8k comes about from a tech
          pov.)</p>

          '
        raw: 'I look forward to reading it!

          For me, it''s a definite step up from MythoMax, with the. combination of
          Pygmalion and Kimiko together undoubtedly helping.  SFW felt warmer and
          more creative, NSFW felt spicier and more creative too.  I''ve read that
          Pygmalion increases creativity, Kimiko improves NSFW and intelligence (inc
          things like tracking a character card better) and makes a model behave more
          like an RP model.

          For me, it''s a great combo, especially with the 8K context in the 8K GGUF
          quant actionpace has created (though i''d still like to know how that 8k
          comes about from a tech pov.)'
        updatedAt: '2023-12-13T15:29:27.491Z'
      numEdits: 0
      reactions: []
    id: 6579cdd75dbfcf78e4cf1772
    type: comment
  author: BoshiAI
  content: 'I look forward to reading it!

    For me, it''s a definite step up from MythoMax, with the. combination of Pygmalion
    and Kimiko together undoubtedly helping.  SFW felt warmer and more creative, NSFW
    felt spicier and more creative too.  I''ve read that Pygmalion increases creativity,
    Kimiko improves NSFW and intelligence (inc things like tracking a character card
    better) and makes a model behave more like an RP model.

    For me, it''s a great combo, especially with the 8K context in the 8K GGUF quant
    actionpace has created (though i''d still like to know how that 8k comes about
    from a tech pov.)'
  created_at: 2023-12-13 15:29:27+00:00
  edited: false
  hidden: false
  id: 6579cdd75dbfcf78e4cf1772
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: actionpace/Mythalion-Kimiko-v2
repo_type: model
status: open
target_branch: null
title: How come nobody noticed this!?
