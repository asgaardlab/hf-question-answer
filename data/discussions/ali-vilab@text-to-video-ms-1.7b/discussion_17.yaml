!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Qwart376
conflicting_files: null
created_at: 2023-04-28 15:46:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2807c5930665649f6898a085a9d27b5d.svg
      fullname: Qwart376
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Qwart376
      type: user
    createdAt: '2023-04-28T16:46:27.000Z'
    data:
      edited: true
      editors:
      - Qwart376
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2807c5930665649f6898a085a9d27b5d.svg
          fullname: Qwart376
          isHf: false
          isPro: false
          name: Qwart376
          type: user
        html: '<p>Here are code blocks with small tweaks that will allow you to use
          the model without any problems.</p>

          <p>IMPORTANT NOTE: Keep <code>Setup</code> and <code>Generation</code> in
          separate blocks, and run <code>Setup</code> only once. Otherwise Google
          Colab will load model with each run and crash the instance after two-three
          times.</p>

          <hr>

          <ul>

          <li>First example from documentation, only generates videos up to 2 seconds</li>

          </ul>

          <p>[1] Setup </p>

          <pre><code>!pip install diffusers transformers accelerate


          import torch

          from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler

          from diffusers.utils import export_to_video


          pipe = DiffusionPipeline.from_pretrained("damo-vilab/text-to-video-ms-1.7b",
          torch_dtype=torch.float16, variant="fp16")

          pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)

          pipe.enable_model_cpu_offload()

          </code></pre>

          <p>[2] Generation</p>

          <pre><code>prompt = "Spiderman is surfing"

          video_frames = pipe(prompt, num_inference_steps=25).frames

          video_path = export_to_video(video_frames)

          video_name = video_path.replace(''/tmp/'', '''')

          print(''Name:'', video_name)

          torch.cuda.empty_cache()

          </code></pre>

          <hr>

          <ul>

          <li>Second example, generates videos with custom length</li>

          </ul>

          <p>[1] Setup</p>

          <pre><code>!pip install diffusers transformers accelerate


          import torch

          from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler

          from diffusers.utils import export_to_video


          # load pipeline

          pipe = DiffusionPipeline.from_pretrained("damo-vilab/text-to-video-ms-1.7b",
          torch_dtype=torch.float16, variant="fp16")

          pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)


          # optimize for GPU memory

          pipe.enable_model_cpu_offload()

          pipe.enable_vae_slicing()

          </code></pre>

          <p>[2] Generation</p>

          <pre><code>prompt = "Spiderman is surfing. Darth Vader is also surfing and
          following Spiderman"

          video_frames = pipe(prompt, num_inference_steps=25, num_frames=200).frames

          video_path = export_to_video(video_frames)

          video_name = video_path.replace(''/tmp/'', '''')

          print(''Name:'', video_name)

          torch.cuda.empty_cache()

          </code></pre>

          <p><code>num_frames</code> is variable responsible for video length (1 =
          0.123 second)</p>

          <hr>

          <p>How to access generated videos: </p>

          <ul>

          <li>Select folder icon on left pane (4th icon)</li>

          <li>Double click on two dots above <code>sample_data</code> folder</li>

          <li>Find <code>tmp</code> folder and expand it, this is where the videos
          are saved by default<br>All video file names start with <code>tmp</code>
          and appear on the bottom of file list. Just right click and download or
          refresh if you don''t see it (folder with refresh icon above the file view)</li>

          </ul>

          <p>Tweaks I''ve added on top of code from documentation:</p>

          <ul>

          <li>Printing out the name in clean way<br><code>video_name = video_path.replace(''/tmp/'',
          '''')</code><br><code>print(''Name:'', video_name)</code></li>

          <li>Flushing CUDA cache to prevent it from clogging after couple of uses<br><code>torch.cuda.empty_cache()</code></li>

          </ul>

          '
        raw: "Here are code blocks with small tweaks that will allow you to use the\
          \ model without any problems.\n\nIMPORTANT NOTE: Keep `Setup` and `Generation`\
          \ in separate blocks, and run `Setup` only once. Otherwise Google Colab\
          \ will load model with each run and crash the instance after two-three times.\n\
          \n---\n- First example from documentation, only generates videos up to 2\
          \ seconds\n\n[1] Setup \n```\n!pip install diffusers transformers accelerate\n\
          \nimport torch\nfrom diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n\
          from diffusers.utils import export_to_video\n\npipe = DiffusionPipeline.from_pretrained(\"\
          damo-vilab/text-to-video-ms-1.7b\", torch_dtype=torch.float16, variant=\"\
          fp16\")\npipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n\
          pipe.enable_model_cpu_offload()\n```\n[2] Generation\n```\nprompt = \"Spiderman\
          \ is surfing\"\nvideo_frames = pipe(prompt, num_inference_steps=25).frames\n\
          video_path = export_to_video(video_frames)\nvideo_name = video_path.replace('/tmp/',\
          \ '')\nprint('Name:', video_name)\ntorch.cuda.empty_cache()\n```\n\n---\n\
          \n- Second example, generates videos with custom length\n\n[1] Setup\n```\n\
          !pip install diffusers transformers accelerate\n\nimport torch\nfrom diffusers\
          \ import DiffusionPipeline, DPMSolverMultistepScheduler\nfrom diffusers.utils\
          \ import export_to_video\n\n# load pipeline\npipe = DiffusionPipeline.from_pretrained(\"\
          damo-vilab/text-to-video-ms-1.7b\", torch_dtype=torch.float16, variant=\"\
          fp16\")\npipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n\
          \n# optimize for GPU memory\npipe.enable_model_cpu_offload()\npipe.enable_vae_slicing()\n\
          ```\n\n[2] Generation\n```\nprompt = \"Spiderman is surfing. Darth Vader\
          \ is also surfing and following Spiderman\"\nvideo_frames = pipe(prompt,\
          \ num_inference_steps=25, num_frames=200).frames\nvideo_path = export_to_video(video_frames)\n\
          video_name = video_path.replace('/tmp/', '')\nprint('Name:', video_name)\n\
          torch.cuda.empty_cache()\n```\n`num_frames` is variable responsible for\
          \ video length (1 = 0.123 second)\n\n---\n\nHow to access generated videos:\
          \ \n- Select folder icon on left pane (4th icon)\n- Double click on two\
          \ dots above `sample_data` folder\n- Find `tmp` folder and expand it, this\
          \ is where the videos are saved by default\nAll video file names start with\
          \ `tmp` and appear on the bottom of file list. Just right click and download\
          \ or refresh if you don't see it (folder with refresh icon above the file\
          \ view)\n\nTweaks I've added on top of code from documentation:\n- Printing\
          \ out the name in clean way\n`video_name = video_path.replace('/tmp/', '')`\n\
          `print('Name:', video_name)`\n- Flushing CUDA cache to prevent it from clogging\
          \ after couple of uses\n`torch.cuda.empty_cache()`"
        updatedAt: '2023-04-28T17:04:44.868Z'
      numEdits: 2
      reactions: []
    id: 644bf86322d211df6444b904
    type: comment
  author: Qwart376
  content: "Here are code blocks with small tweaks that will allow you to use the\
    \ model without any problems.\n\nIMPORTANT NOTE: Keep `Setup` and `Generation`\
    \ in separate blocks, and run `Setup` only once. Otherwise Google Colab will load\
    \ model with each run and crash the instance after two-three times.\n\n---\n-\
    \ First example from documentation, only generates videos up to 2 seconds\n\n\
    [1] Setup \n```\n!pip install diffusers transformers accelerate\n\nimport torch\n\
    from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\nfrom diffusers.utils\
    \ import export_to_video\n\npipe = DiffusionPipeline.from_pretrained(\"damo-vilab/text-to-video-ms-1.7b\"\
    , torch_dtype=torch.float16, variant=\"fp16\")\npipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n\
    pipe.enable_model_cpu_offload()\n```\n[2] Generation\n```\nprompt = \"Spiderman\
    \ is surfing\"\nvideo_frames = pipe(prompt, num_inference_steps=25).frames\nvideo_path\
    \ = export_to_video(video_frames)\nvideo_name = video_path.replace('/tmp/', '')\n\
    print('Name:', video_name)\ntorch.cuda.empty_cache()\n```\n\n---\n\n- Second example,\
    \ generates videos with custom length\n\n[1] Setup\n```\n!pip install diffusers\
    \ transformers accelerate\n\nimport torch\nfrom diffusers import DiffusionPipeline,\
    \ DPMSolverMultistepScheduler\nfrom diffusers.utils import export_to_video\n\n\
    # load pipeline\npipe = DiffusionPipeline.from_pretrained(\"damo-vilab/text-to-video-ms-1.7b\"\
    , torch_dtype=torch.float16, variant=\"fp16\")\npipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n\
    \n# optimize for GPU memory\npipe.enable_model_cpu_offload()\npipe.enable_vae_slicing()\n\
    ```\n\n[2] Generation\n```\nprompt = \"Spiderman is surfing. Darth Vader is also\
    \ surfing and following Spiderman\"\nvideo_frames = pipe(prompt, num_inference_steps=25,\
    \ num_frames=200).frames\nvideo_path = export_to_video(video_frames)\nvideo_name\
    \ = video_path.replace('/tmp/', '')\nprint('Name:', video_name)\ntorch.cuda.empty_cache()\n\
    ```\n`num_frames` is variable responsible for video length (1 = 0.123 second)\n\
    \n---\n\nHow to access generated videos: \n- Select folder icon on left pane (4th\
    \ icon)\n- Double click on two dots above `sample_data` folder\n- Find `tmp` folder\
    \ and expand it, this is where the videos are saved by default\nAll video file\
    \ names start with `tmp` and appear on the bottom of file list. Just right click\
    \ and download or refresh if you don't see it (folder with refresh icon above\
    \ the file view)\n\nTweaks I've added on top of code from documentation:\n- Printing\
    \ out the name in clean way\n`video_name = video_path.replace('/tmp/', '')`\n\
    `print('Name:', video_name)`\n- Flushing CUDA cache to prevent it from clogging\
    \ after couple of uses\n`torch.cuda.empty_cache()`"
  created_at: 2023-04-28 15:46:27+00:00
  edited: true
  hidden: false
  id: 644bf86322d211df6444b904
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 17
repo_id: ali-vilab/text-to-video-ms-1.7b
repo_type: model
status: open
target_branch: null
title: Google Colab full setup with tweaks
