!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dsmithcentric
conflicting_files: null
created_at: 2023-09-27 08:41:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3397df4b9a4062aac9aaf89838a67b96.svg
      fullname: Daniel Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dsmithcentric
      type: user
    createdAt: '2023-09-27T09:41:40.000Z'
    data:
      edited: true
      editors:
      - dsmithcentric
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.970090925693512
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3397df4b9a4062aac9aaf89838a67b96.svg
          fullname: Daniel Smith
          isHf: false
          isPro: false
          name: dsmithcentric
          type: user
        html: '<p>Hey guys, I''m having a bit of an issue logically constraining MPT-30B''s
          responses. A simple scenario is given a question and a context, if the answer
          is not contained within the context, ask for the question to be rephrased.
          Smaller and simpler models can do this without issue, but MPT fairly consistently
          answers when the context does not contain the answer, rather than following
          the instruction. Even if I include that "all previous knowledge should be
          forgotten" it doesn''t seem to keep the model on task. Is there a trick
          to prompting in this way with MPT? I''d like to progress further and use
          the model to do more complicated deductions but I haven''t had a lot of
          luck with this first hurdle yet.<br>Cheers</p>

          '
        raw: 'Hey guys, I''m having a bit of an issue logically constraining MPT-30B''s
          responses. A simple scenario is given a question and a context, if the answer
          is not contained within the context, ask for the question to be rephrased.
          Smaller and simpler models can do this without issue, but MPT fairly consistently
          answers when the context does not contain the answer, rather than following
          the instruction. Even if I include that "all previous knowledge should be
          forgotten" it doesn''t seem to keep the model on task. Is there a trick
          to prompting in this way with MPT? I''d like to progress further and use
          the model to do more complicated deductions but I haven''t had a lot of
          luck with this first hurdle yet.

          Cheers'
        updatedAt: '2023-09-27T11:37:58.904Z'
      numEdits: 1
      reactions: []
    id: 6513f8d43c912b5622fe2e4e
    type: comment
  author: dsmithcentric
  content: 'Hey guys, I''m having a bit of an issue logically constraining MPT-30B''s
    responses. A simple scenario is given a question and a context, if the answer
    is not contained within the context, ask for the question to be rephrased. Smaller
    and simpler models can do this without issue, but MPT fairly consistently answers
    when the context does not contain the answer, rather than following the instruction.
    Even if I include that "all previous knowledge should be forgotten" it doesn''t
    seem to keep the model on task. Is there a trick to prompting in this way with
    MPT? I''d like to progress further and use the model to do more complicated deductions
    but I haven''t had a lot of luck with this first hurdle yet.

    Cheers'
  created_at: 2023-09-27 08:41:40+00:00
  edited: true
  hidden: false
  id: 6513f8d43c912b5622fe2e4e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a2ed59283e2e835858e103910d348a9f.svg
      fullname: Sam Havens
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: samhavens
      type: user
    createdAt: '2023-09-27T15:25:33.000Z'
    data:
      edited: false
      editors:
      - samhavens
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.983600914478302
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a2ed59283e2e835858e103910d348a9f.svg
          fullname: Sam Havens
          isHf: false
          isPro: false
          name: samhavens
          type: user
        html: '<p>What prompts work with other modela that aren''t working here?</p>

          '
        raw: What prompts work with other modela that aren't working here?
        updatedAt: '2023-09-27T15:25:33.336Z'
      numEdits: 0
      reactions: []
    id: 6514496da73ce94bf5e4e26a
    type: comment
  author: samhavens
  content: What prompts work with other modela that aren't working here?
  created_at: 2023-09-27 14:25:33+00:00
  edited: false
  hidden: false
  id: 6514496da73ce94bf5e4e26a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3397df4b9a4062aac9aaf89838a67b96.svg
      fullname: Daniel Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dsmithcentric
      type: user
    createdAt: '2023-09-28T01:28:52.000Z'
    data:
      edited: true
      editors:
      - dsmithcentric
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.942212700843811
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3397df4b9a4062aac9aaf89838a67b96.svg
          fullname: Daniel Smith
          isHf: false
          isPro: false
          name: dsmithcentric
          type: user
        html: '<p>Here''s a prompt which works in the huggingface MPT-30B-Chat demo,
          but doesn''t work locally with MPT-30B-Instruct (template included here):<br>Below
          is an instruction that describes a task. Write a response that appropriately
          completes the request.\n\n###Instruction\nThoroughly answer as much of the
          question as truthfully as possible using only information from the provided
          context below. Forget everything you knew about the world. The answer MUST
          ONLY include information contained within the context below. You MUST NOT
          provide any information unless it is in the context below. If the context
          below does not include any information to answer the question you must apologize
          and inform the user that the context does not contain enough relevant information.\n\nContext:\nThe
          sky is blue. The grass is green. Fire is like water but hotter.\n\nQuestion:\nWhat
          is glue?\n\nAnswer:\n\n### Response\n<br>I''m using a topP value of 1, topK
          value of -1 and temperature set to 0, but adjusting them doesn''t seem to
          change much. MPT-30B-Instruct consistently tells me what glue is.</p>

          '
        raw: 'Here''s a prompt which works in the huggingface MPT-30B-Chat demo, but
          doesn''t work locally with MPT-30B-Instruct (template included here):

          Below is an instruction that describes a task. Write a response that appropriately
          completes the request.\n\n###Instruction\nThoroughly answer as much of the
          question as truthfully as possible using only information from the provided
          context below. Forget everything you knew about the world. The answer MUST
          ONLY include information contained within the context below. You MUST NOT
          provide any information unless it is in the context below. If the context
          below does not include any information to answer the question you must apologize
          and inform the user that the context does not contain enough relevant information.\n\nContext:\nThe
          sky is blue. The grass is green. Fire is like water but hotter.\n\nQuestion:\nWhat
          is glue?\n\nAnswer:\n\n### Response\n

          I''m using a topP value of 1, topK value of -1 and temperature set to 0,
          but adjusting them doesn''t seem to change much. MPT-30B-Instruct consistently
          tells me what glue is.'
        updatedAt: '2023-09-28T01:29:33.987Z'
      numEdits: 1
      reactions: []
    id: 6514d6d4d1005268b0c337ac
    type: comment
  author: dsmithcentric
  content: 'Here''s a prompt which works in the huggingface MPT-30B-Chat demo, but
    doesn''t work locally with MPT-30B-Instruct (template included here):

    Below is an instruction that describes a task. Write a response that appropriately
    completes the request.\n\n###Instruction\nThoroughly answer as much of the question
    as truthfully as possible using only information from the provided context below.
    Forget everything you knew about the world. The answer MUST ONLY include information
    contained within the context below. You MUST NOT provide any information unless
    it is in the context below. If the context below does not include any information
    to answer the question you must apologize and inform the user that the context
    does not contain enough relevant information.\n\nContext:\nThe sky is blue. The
    grass is green. Fire is like water but hotter.\n\nQuestion:\nWhat is glue?\n\nAnswer:\n\n###
    Response\n

    I''m using a topP value of 1, topK value of -1 and temperature set to 0, but adjusting
    them doesn''t seem to change much. MPT-30B-Instruct consistently tells me what
    glue is.'
  created_at: 2023-09-28 00:28:52+00:00
  edited: true
  hidden: false
  id: 6514d6d4d1005268b0c337ac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3397df4b9a4062aac9aaf89838a67b96.svg
      fullname: Daniel Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dsmithcentric
      type: user
    createdAt: '2023-09-28T03:07:19.000Z'
    data:
      edited: false
      editors:
      - dsmithcentric
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.984283447265625
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3397df4b9a4062aac9aaf89838a67b96.svg
          fullname: Daniel Smith
          isHf: false
          isPro: false
          name: dsmithcentric
          type: user
        html: '<p>I think I found the problem, "inform the user" isn''t a clear enough
          instruction. Being more specific there has helped solve the issue.</p>

          '
        raw: I think I found the problem, "inform the user" isn't a clear enough instruction.
          Being more specific there has helped solve the issue.
        updatedAt: '2023-09-28T03:07:19.802Z'
      numEdits: 0
      reactions: []
    id: 6514ede75aef9f39138d3ced
    type: comment
  author: dsmithcentric
  content: I think I found the problem, "inform the user" isn't a clear enough instruction.
    Being more specific there has helped solve the issue.
  created_at: 2023-09-28 02:07:19+00:00
  edited: false
  hidden: false
  id: 6514ede75aef9f39138d3ced
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/3397df4b9a4062aac9aaf89838a67b96.svg
      fullname: Daniel Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dsmithcentric
      type: user
    createdAt: '2023-09-28T04:14:55.000Z'
    data:
      status: closed
    id: 6514fdbf921b7d68490540d0
    type: status-change
  author: dsmithcentric
  created_at: 2023-09-28 03:14:55+00:00
  id: 6514fdbf921b7d68490540d0
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3397df4b9a4062aac9aaf89838a67b96.svg
      fullname: Daniel Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dsmithcentric
      type: user
    createdAt: '2023-09-28T05:39:48.000Z'
    data:
      edited: false
      editors:
      - dsmithcentric
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9882938265800476
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3397df4b9a4062aac9aaf89838a67b96.svg
          fullname: Daniel Smith
          isHf: false
          isPro: false
          name: dsmithcentric
          type: user
        html: '<p>I have noticed that once the prompt starts to get more complex the
          answers do return though, which Chat doesn''t seem as inclined to do. I''ll
          keep experimenting</p>

          '
        raw: I have noticed that once the prompt starts to get more complex the answers
          do return though, which Chat doesn't seem as inclined to do. I'll keep experimenting
        updatedAt: '2023-09-28T05:39:48.118Z'
      numEdits: 0
      reactions: []
    id: 651511a4a990e6c56c687f10
    type: comment
  author: dsmithcentric
  content: I have noticed that once the prompt starts to get more complex the answers
    do return though, which Chat doesn't seem as inclined to do. I'll keep experimenting
  created_at: 2023-09-28 04:39:48+00:00
  edited: false
  hidden: false
  id: 651511a4a990e6c56c687f10
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/3397df4b9a4062aac9aaf89838a67b96.svg
      fullname: Daniel Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dsmithcentric
      type: user
    createdAt: '2023-09-28T06:09:29.000Z'
    data:
      status: open
    id: 65151899fc2301d62d812aad
    type: status-change
  author: dsmithcentric
  created_at: 2023-09-28 05:09:29+00:00
  id: 65151899fc2301d62d812aad
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3397df4b9a4062aac9aaf89838a67b96.svg
      fullname: Daniel Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dsmithcentric
      type: user
    createdAt: '2023-09-28T06:14:37.000Z'
    data:
      edited: false
      editors:
      - dsmithcentric
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9396676421165466
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3397df4b9a4062aac9aaf89838a67b96.svg
          fullname: Daniel Smith
          isHf: false
          isPro: false
          name: dsmithcentric
          type: user
        html: '<p>Here''s another example, very similar to the last one, but slightly
          improved. It seems like any little tweak can easily break the attempted
          constraint on limiting output. I feel like I''m misunderstanding how to
          fundamentally instruct the model because Chat seemingly always follows the
          instructions, and Instruct seems to always just want to answer the question.</p>

          <p>Below is an instruction that describes a task. Write a response that
          appropriately completes the request.\n\n###Instruction\nUsing only information
          provided in the context below thoroughly answer as much of the question
          as possible. The answer MUST ONLY include information contained within the
          context below. You MUST NOT provide any information unless it is in the
          context below. If the context below does not include any information to
          answer the question you must answer by stating that the context does not
          contain enough information to answer the question.\n\nContext:\nThe sky
          is blue. The grass is green. Fire is like water but hotter.\n\nQuestion:\nWhat
          is the sun?\n\nAnswer:\n\n### Response\n</p>

          '
        raw: 'Here''s another example, very similar to the last one, but slightly
          improved. It seems like any little tweak can easily break the attempted
          constraint on limiting output. I feel like I''m misunderstanding how to
          fundamentally instruct the model because Chat seemingly always follows the
          instructions, and Instruct seems to always just want to answer the question.


          Below is an instruction that describes a task. Write a response that appropriately
          completes the request.\n\n###Instruction\nUsing only information provided
          in the context below thoroughly answer as much of the question as possible.
          The answer MUST ONLY include information contained within the context below.
          You MUST NOT provide any information unless it is in the context below.
          If the context below does not include any information to answer the question
          you must answer by stating that the context does not contain enough information
          to answer the question.\n\nContext:\nThe sky is blue. The grass is green.
          Fire is like water but hotter.\n\nQuestion:\nWhat is the sun?\n\nAnswer:\n\n###
          Response\n'
        updatedAt: '2023-09-28T06:14:37.942Z'
      numEdits: 0
      reactions: []
    id: 651519cda1b6d19bd16c5e62
    type: comment
  author: dsmithcentric
  content: 'Here''s another example, very similar to the last one, but slightly improved.
    It seems like any little tweak can easily break the attempted constraint on limiting
    output. I feel like I''m misunderstanding how to fundamentally instruct the model
    because Chat seemingly always follows the instructions, and Instruct seems to
    always just want to answer the question.


    Below is an instruction that describes a task. Write a response that appropriately
    completes the request.\n\n###Instruction\nUsing only information provided in the
    context below thoroughly answer as much of the question as possible. The answer
    MUST ONLY include information contained within the context below. You MUST NOT
    provide any information unless it is in the context below. If the context below
    does not include any information to answer the question you must answer by stating
    that the context does not contain enough information to answer the question.\n\nContext:\nThe
    sky is blue. The grass is green. Fire is like water but hotter.\n\nQuestion:\nWhat
    is the sun?\n\nAnswer:\n\n### Response\n'
  created_at: 2023-09-28 05:14:37+00:00
  edited: false
  hidden: false
  id: 651519cda1b6d19bd16c5e62
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a2ed59283e2e835858e103910d348a9f.svg
      fullname: Sam Havens
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: samhavens
      type: user
    createdAt: '2023-09-29T23:02:47.000Z'
    data:
      edited: true
      editors:
      - samhavens
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9281855225563049
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a2ed59283e2e835858e103910d348a9f.svg
          fullname: Sam Havens
          isHf: false
          isPro: false
          name: samhavens
          type: user
        html: '<p>The Chat model saw many more samples, and they were higher quality
          as well. It is not licensed for commercial use though, because of OpenAI''s
          terms of service wrt how data from their models is used. It is entirely
          possible that Chat saw examples of this task (refusal when the retrieved
          data in the prompt doesn''t support answering the question) and Instruct
          did not.</p>

          <p>If fine tuning isn''t an option, try few-shot (give it multiple examples),
          with some of the examples being refusals:</p>

          <pre><code>Below is an instruction that describes a task. Write a response
          that appropriately completes the request.\n\n###Instruction\nUsing only
          information provided in the context below thoroughly answer as much of the
          question as possible. The answer MUST ONLY include information contained
          within the context below. You MUST NOT provide any information unless it
          is in the context below. If the context below does not include any information
          to answer the question you must answer by stating that the context does
          not contain enough information to answer the question.\n\nContext:\nThe
          sky is blue. The grass is green. Fire is like water but hotter.\n\nQuestion:\nWhat
          is the sun?\n\nAnswer:\nThe context does not contain enough information
          to answer the question.\n\nContext:\nSOME OTHER CONTEXT.\n\nQuestion:\ANOTHER
          EXAMPLE QUESTION?\n\nAnswer:\nTHIS ANSWER SHOULD BE SUPPORTED BY THE CONTEXT.\n\nContext:\{Context}.\n\nQuestion:\{Question}\n\nAnswer:\n\n###
          Response\n

          </code></pre>

          <p>So that is a 2-shot prompt. If you have the space, doing 2-4 should help
          a lot.</p>

          '
        raw: 'The Chat model saw many more samples, and they were higher quality as
          well. It is not licensed for commercial use though, because of OpenAI''s
          terms of service wrt how data from their models is used. It is entirely
          possible that Chat saw examples of this task (refusal when the retrieved
          data in the prompt doesn''t support answering the question) and Instruct
          did not.


          If fine tuning isn''t an option, try few-shot (give it multiple examples),
          with some of the examples being refusals:


          ```

          Below is an instruction that describes a task. Write a response that appropriately
          completes the request.\n\n###Instruction\nUsing only information provided
          in the context below thoroughly answer as much of the question as possible.
          The answer MUST ONLY include information contained within the context below.
          You MUST NOT provide any information unless it is in the context below.
          If the context below does not include any information to answer the question
          you must answer by stating that the context does not contain enough information
          to answer the question.\n\nContext:\nThe sky is blue. The grass is green.
          Fire is like water but hotter.\n\nQuestion:\nWhat is the sun?\n\nAnswer:\nThe
          context does not contain enough information to answer the question.\n\nContext:\nSOME
          OTHER CONTEXT.\n\nQuestion:\ANOTHER EXAMPLE QUESTION?\n\nAnswer:\nTHIS ANSWER
          SHOULD BE SUPPORTED BY THE CONTEXT.\n\nContext:\{Context}.\n\nQuestion:\{Question}\n\nAnswer:\n\n###
          Response\n

          ```

          So that is a 2-shot prompt. If you have the space, doing 2-4 should help
          a lot.'
        updatedAt: '2023-09-29T23:03:00.611Z'
      numEdits: 1
      reactions: []
    id: 65175797ed0bef1df0cbdb74
    type: comment
  author: samhavens
  content: 'The Chat model saw many more samples, and they were higher quality as
    well. It is not licensed for commercial use though, because of OpenAI''s terms
    of service wrt how data from their models is used. It is entirely possible that
    Chat saw examples of this task (refusal when the retrieved data in the prompt
    doesn''t support answering the question) and Instruct did not.


    If fine tuning isn''t an option, try few-shot (give it multiple examples), with
    some of the examples being refusals:


    ```

    Below is an instruction that describes a task. Write a response that appropriately
    completes the request.\n\n###Instruction\nUsing only information provided in the
    context below thoroughly answer as much of the question as possible. The answer
    MUST ONLY include information contained within the context below. You MUST NOT
    provide any information unless it is in the context below. If the context below
    does not include any information to answer the question you must answer by stating
    that the context does not contain enough information to answer the question.\n\nContext:\nThe
    sky is blue. The grass is green. Fire is like water but hotter.\n\nQuestion:\nWhat
    is the sun?\n\nAnswer:\nThe context does not contain enough information to answer
    the question.\n\nContext:\nSOME OTHER CONTEXT.\n\nQuestion:\ANOTHER EXAMPLE QUESTION?\n\nAnswer:\nTHIS
    ANSWER SHOULD BE SUPPORTED BY THE CONTEXT.\n\nContext:\{Context}.\n\nQuestion:\{Question}\n\nAnswer:\n\n###
    Response\n

    ```

    So that is a 2-shot prompt. If you have the space, doing 2-4 should help a lot.'
  created_at: 2023-09-29 22:02:47+00:00
  edited: true
  hidden: false
  id: 65175797ed0bef1df0cbdb74
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: mosaicml/mpt-30b-instruct
repo_type: model
status: open
target_branch: null
title: Issues instructing MPT to answer specifically when given a condition
