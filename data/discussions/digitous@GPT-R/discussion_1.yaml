!!python/object:huggingface_hub.community.DiscussionWithDetails
author: brianflakes
conflicting_files: null
created_at: 2023-02-20 05:54:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acfb40667c185def9204c76b7b748446.svg
      fullname: Brian Semrau
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: brianflakes
      type: user
    createdAt: '2023-02-20T05:54:04.000Z'
    data:
      edited: false
      editors:
      - brianflakes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acfb40667c185def9204c76b7b748446.svg
          fullname: Brian Semrau
          isHf: false
          isPro: false
          name: brianflakes
          type: user
        html: "<p>In the space of stable diffusion models, model merging seems to\
          \ be super common. There are two techniques that I've seen:</p>\n<ol>\n\
          <li>Weighted average (given A and B are two models with identical shapes)<br><code>output\
          \ = (1-\u03B1)A + \u03B1B</code></li>\n<li>Added diff (given A, B are models\
          \ finetuned from C)<br><code>output = A + \u03B1(B - C)</code></li>\n</ol>\n\
          <p>The intuition I've gathered is that weighted average is akin to mixing\
          \ the datasets, while added diff is more like additional finetuning. I'm\
          \ not sure if there's any research out there that takes a properly analysis,\
          \ but this is what I've heard and understood. Obviously both methods raise\
          \ eyebrows, but it's cool that they can sometimes work.</p>\n<p>The second\
          \ technique has, with mixed results, enabled the transfer of inpainting\
          \ capabilities to other models without forgetting.</p>\n<p>I'm assuming\
          \ that ppo_hh_gpt-j was finetuned on GPT-J. Since the two models you've\
          \ averaged are finetuned off of the same baseline, have you considered the\
          \ second formula above?</p>\n<p>Let me know what you think, or if there's\
          \ any research you know of that I could study up on.</p>\n"
        raw: "In the space of stable diffusion models, model merging seems to be super\
          \ common. There are two techniques that I've seen:\r\n1. Weighted average\
          \ (given A and B are two models with identical shapes)\r\n`output = (1-\u03B1\
          )A + \u03B1B`\r\n2. Added diff (given A, B are models finetuned from C)\r\
          \n`output = A + \u03B1(B - C)`\r\n\r\nThe intuition I've gathered is that\
          \ weighted average is akin to mixing the datasets, while added diff is more\
          \ like additional finetuning. I'm not sure if there's any research out there\
          \ that takes a properly analysis, but this is what I've heard and understood.\
          \ Obviously both methods raise eyebrows, but it's cool that they can sometimes\
          \ work.\r\n\r\nThe second technique has, with mixed results, enabled the\
          \ transfer of inpainting capabilities to other models without forgetting.\r\
          \n\r\nI'm assuming that ppo_hh_gpt-j was finetuned on GPT-J. Since the two\
          \ models you've averaged are finetuned off of the same baseline, have you\
          \ considered the second formula above?\r\n\r\nLet me know what you think,\
          \ or if there's any research you know of that I could study up on."
        updatedAt: '2023-02-20T05:54:04.679Z'
      numEdits: 0
      reactions: []
    id: 63f30afcbe95ed4c9aa1c048
    type: comment
  author: brianflakes
  content: "In the space of stable diffusion models, model merging seems to be super\
    \ common. There are two techniques that I've seen:\r\n1. Weighted average (given\
    \ A and B are two models with identical shapes)\r\n`output = (1-\u03B1)A + \u03B1\
    B`\r\n2. Added diff (given A, B are models finetuned from C)\r\n`output = A +\
    \ \u03B1(B - C)`\r\n\r\nThe intuition I've gathered is that weighted average is\
    \ akin to mixing the datasets, while added diff is more like additional finetuning.\
    \ I'm not sure if there's any research out there that takes a properly analysis,\
    \ but this is what I've heard and understood. Obviously both methods raise eyebrows,\
    \ but it's cool that they can sometimes work.\r\n\r\nThe second technique has,\
    \ with mixed results, enabled the transfer of inpainting capabilities to other\
    \ models without forgetting.\r\n\r\nI'm assuming that ppo_hh_gpt-j was finetuned\
    \ on GPT-J. Since the two models you've averaged are finetuned off of the same\
    \ baseline, have you considered the second formula above?\r\n\r\nLet me know what\
    \ you think, or if there's any research you know of that I could study up on."
  created_at: 2023-02-20 05:54:04+00:00
  edited: false
  hidden: false
  id: 63f30afcbe95ed4c9aa1c048
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
      fullname: Erik
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: digitous
      type: user
    createdAt: '2023-02-21T02:38:16.000Z'
    data:
      edited: false
      editors:
      - digitous
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
          fullname: Erik
          isHf: false
          isPro: false
          name: digitous
          type: user
        html: '<p>I''ve been curious as well if difference merge is possible with
          language models. Frankly I''m floored weight merging is possible in this
          space. I''m excited to find out what else is possible. I may eyeball Automatic1111''s
          difference merge script and see what might be possible to retrofit into
          the merge script I used to make this model.</p>

          <p>Caveat, I''m new to Python, capable of augmenting or heavily modifying
          the work of others but at the moment I''m babby. I''m not the original author
          of the weight average script, although I have converted it to a Colab environment
          and plan to officially release it in a week or two. The KoboldAI Discord
          has the original .py under the model merging channel.</p>

          <p>The author of the merge script I used is the work of Concedo: <a href="https://huggingface.co/concedo">https://huggingface.co/concedo</a></p>

          '
        raw: 'I''ve been curious as well if difference merge is possible with language
          models. Frankly I''m floored weight merging is possible in this space. I''m
          excited to find out what else is possible. I may eyeball Automatic1111''s
          difference merge script and see what might be possible to retrofit into
          the merge script I used to make this model.


          Caveat, I''m new to Python, capable of augmenting or heavily modifying the
          work of others but at the moment I''m babby. I''m not the original author
          of the weight average script, although I have converted it to a Colab environment
          and plan to officially release it in a week or two. The KoboldAI Discord
          has the original .py under the model merging channel.


          The author of the merge script I used is the work of Concedo: https://huggingface.co/concedo'
        updatedAt: '2023-02-21T02:38:16.708Z'
      numEdits: 0
      reactions: []
    id: 63f42e98230a01e7d05338e3
    type: comment
  author: digitous
  content: 'I''ve been curious as well if difference merge is possible with language
    models. Frankly I''m floored weight merging is possible in this space. I''m excited
    to find out what else is possible. I may eyeball Automatic1111''s difference merge
    script and see what might be possible to retrofit into the merge script I used
    to make this model.


    Caveat, I''m new to Python, capable of augmenting or heavily modifying the work
    of others but at the moment I''m babby. I''m not the original author of the weight
    average script, although I have converted it to a Colab environment and plan to
    officially release it in a week or two. The KoboldAI Discord has the original
    .py under the model merging channel.


    The author of the merge script I used is the work of Concedo: https://huggingface.co/concedo'
  created_at: 2023-02-21 02:38:16+00:00
  edited: false
  hidden: false
  id: 63f42e98230a01e7d05338e3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acfb40667c185def9204c76b7b748446.svg
      fullname: Brian Semrau
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: brianflakes
      type: user
    createdAt: '2023-02-21T04:41:25.000Z'
    data:
      edited: false
      editors:
      - brianflakes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acfb40667c185def9204c76b7b748446.svg
          fullname: Brian Semrau
          isHf: false
          isPro: false
          name: brianflakes
          type: user
        html: '<p>Thanks for the info. I''ll work on modifying that <code>merge.py</code>
          script to support difference merge. Here''s hoping it works.</p>

          '
        raw: Thanks for the info. I'll work on modifying that `merge.py` script to
          support difference merge. Here's hoping it works.
        updatedAt: '2023-02-21T04:41:25.786Z'
      numEdits: 0
      reactions: []
    id: 63f44b75e13a558a4d71213d
    type: comment
  author: brianflakes
  content: Thanks for the info. I'll work on modifying that `merge.py` script to support
    difference merge. Here's hoping it works.
  created_at: 2023-02-21 04:41:25+00:00
  edited: false
  hidden: false
  id: 63f44b75e13a558a4d71213d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acfb40667c185def9204c76b7b748446.svg
      fullname: Brian Semrau
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: brianflakes
      type: user
    createdAt: '2023-02-21T06:35:57.000Z'
    data:
      edited: false
      editors:
      - brianflakes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acfb40667c185def9204c76b7b748446.svg
          fullname: Brian Semrau
          isHf: false
          isPro: false
          name: brianflakes
          type: user
        html: '<p>for anyone who comes across this discussion:<br><a rel="nofollow"
          href="https://gist.github.com/briansemrau/c68835edc88a0dea79b092bce4e1ee17">https://gist.github.com/briansemrau/c68835edc88a0dea79b092bce4e1ee17</a></p>

          '
        raw: 'for anyone who comes across this discussion:

          https://gist.github.com/briansemrau/c68835edc88a0dea79b092bce4e1ee17'
        updatedAt: '2023-02-21T06:35:57.311Z'
      numEdits: 0
      reactions: []
    id: 63f4664de13a558a4d730030
    type: comment
  author: brianflakes
  content: 'for anyone who comes across this discussion:

    https://gist.github.com/briansemrau/c68835edc88a0dea79b092bce4e1ee17'
  created_at: 2023-02-21 06:35:57+00:00
  edited: false
  hidden: false
  id: 63f4664de13a558a4d730030
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
      fullname: Erik
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: digitous
      type: user
    createdAt: '2023-02-21T21:49:11.000Z'
    data:
      edited: true
      editors:
      - digitous
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
          fullname: Erik
          isHf: false
          isPro: false
          name: digitous
          type: user
        html: '<p>Absolutely awesome, this opens even more doors for interesting tests
          with learned information transfer. I''m tinkering with a colab conversion
          right now. Will add you to the credits at the top.</p>

          '
        raw: Absolutely awesome, this opens even more doors for interesting tests
          with learned information transfer. I'm tinkering with a colab conversion
          right now. Will add you to the credits at the top.
        updatedAt: '2023-02-21T21:49:40.217Z'
      numEdits: 1
      reactions: []
    id: 63f53c573b9744a2f31debe1
    type: comment
  author: digitous
  content: Absolutely awesome, this opens even more doors for interesting tests with
    learned information transfer. I'm tinkering with a colab conversion right now.
    Will add you to the credits at the top.
  created_at: 2023-02-21 21:49:11+00:00
  edited: true
  hidden: false
  id: 63f53c573b9744a2f31debe1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: digitous/GPT-R
repo_type: model
status: open
target_branch: null
title: Model merging techniques
