!!python/object:huggingface_hub.community.DiscussionWithDetails
author: robkirk
conflicting_files: null
created_at: 2022-08-31 09:41:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660732304230-noauth.jpeg?w=200&h=200&f=face
      fullname: Robert Kirk
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: robkirk
      type: user
    createdAt: '2022-08-31T10:41:52.000Z'
    data:
      edited: true
      editors:
      - robkirk
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660732304230-noauth.jpeg?w=200&h=200&f=face
          fullname: Robert Kirk
          isHf: false
          isPro: false
          name: robkirk
          type: user
        html: '<p>In the model configuration for this (and other opt models) the vocab_size
          is 50272, but the tokenizer has vocab size 50265, which matches the original
          vocabulary <a rel="nofollow" href="https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/assets/gpt2-vocab.json">here</a>.
          and the one on huggingface <a href="https://huggingface.co/patrickvonplaten/opt-30b/tree/main">here</a>.
          Could this be updated somehow (although I realise that could mess with checkpoints
          etc.)?</p>

          <p>There''s <a rel="nofollow" href="https://github.com/huggingface/transformers/issues/18268">this</a>
          issue on the transformers github referencing the samething.</p>

          '
        raw: 'In the model configuration for this (and other opt models) the vocab_size
          is 50272, but the tokenizer has vocab size 50265, which matches the original
          vocabulary [here](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/assets/gpt2-vocab.json).
          and the one on huggingface [here](https://huggingface.co/patrickvonplaten/opt-30b/tree/main).
          Could this be updated somehow (although I realise that could mess with checkpoints
          etc.)?


          There''s [this](https://github.com/huggingface/transformers/issues/18268)
          issue on the transformers github referencing the samething.'
        updatedAt: '2022-08-31T12:38:21.101Z'
      numEdits: 1
      reactions: []
    id: 630f3af0dd31b2a8dbdfffa8
    type: comment
  author: robkirk
  content: 'In the model configuration for this (and other opt models) the vocab_size
    is 50272, but the tokenizer has vocab size 50265, which matches the original vocabulary
    [here](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/assets/gpt2-vocab.json).
    and the one on huggingface [here](https://huggingface.co/patrickvonplaten/opt-30b/tree/main).
    Could this be updated somehow (although I realise that could mess with checkpoints
    etc.)?


    There''s [this](https://github.com/huggingface/transformers/issues/18268) issue
    on the transformers github referencing the samething.'
  created_at: 2022-08-31 09:41:52+00:00
  edited: true
  hidden: false
  id: 630f3af0dd31b2a8dbdfffa8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2022-08-31T19:16:12.000Z'
    data:
      edited: false
      editors:
      - patrickvonplaten
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
          fullname: Patrick von Platen
          isHf: true
          isPro: false
          name: patrickvonplaten
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;robkirk&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/robkirk\"\
          >@<span class=\"underline\">robkirk</span></a></span>\n\n\t</span></span>\
          \ ,</p>\n<p>Good question! I think you can find the answer here: <a rel=\"\
          nofollow\" href=\"https://github.com/huggingface/transformers/issues/17431#issuecomment-1224231170\"\
          >https://github.com/huggingface/transformers/issues/17431#issuecomment-1224231170</a>\
          \ (it was on another GitHub issue)</p>\n"
        raw: 'Hey @robkirk ,


          Good question! I think you can find the answer here: https://github.com/huggingface/transformers/issues/17431#issuecomment-1224231170
          (it was on another GitHub issue)'
        updatedAt: '2022-08-31T19:16:12.904Z'
      numEdits: 0
      reactions: []
    id: 630fb37c236215d0b70d8185
    type: comment
  author: patrickvonplaten
  content: 'Hey @robkirk ,


    Good question! I think you can find the answer here: https://github.com/huggingface/transformers/issues/17431#issuecomment-1224231170
    (it was on another GitHub issue)'
  created_at: 2022-08-31 18:16:12+00:00
  edited: false
  hidden: false
  id: 630fb37c236215d0b70d8185
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: facebook/opt-125m
repo_type: model
status: open
target_branch: null
title: Vocab_size of the model configuration is incorrect
