!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ndurkee
conflicting_files: null
created_at: 2024-01-18 17:55:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/53fe807d9ffaf2c23ac8a13756a2486b.svg
      fullname: Nick Durkee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ndurkee
      type: user
    createdAt: '2024-01-18T17:55:38.000Z'
    data:
      edited: false
      editors:
      - ndurkee
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8660712242126465
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/53fe807d9ffaf2c23ac8a13756a2486b.svg
          fullname: Nick Durkee
          isHf: false
          isPro: false
          name: ndurkee
          type: user
        html: '<p>I''m trying to use this model to follow instructions and give single
          word responses. Here is an example prompt</p>

          <pre><code>A chat between a curious user and an artificial intelligence
          assistant. The assistant gives helpful, detailed, and polite answers to
          the user''s questions.

          ### Instruction:

          Is this a valid sentence?

          "Biology1544-91731545-7885Public Library of Science San Francisco,"

          Answer yes or no and nothing else.

          ### Response:

          </code></pre>

          <p>The response I''m getting is</p>

          <pre><code>[Answer to the question]


          [Answer]

          No

          </code></pre>

          <p>Occasionally I''ll get </p>

          <pre><code>[Answer] No

          </code></pre>

          <p>or</p>

          <pre><code>[Question edited for clarity: "Is this a valid sentence? ''Biology
          1544-9173 1545-7885 Public Library of Science San Francisco,''"]

          Answer: No

          </code></pre>

          <p>Model: bagel-dpo-34b-v0.2<br>Precision: 16-bit bfloat<br>Engine: VLLM
          api server<br>Settings:</p>

          <pre><code>{"prompt": '''',

          "stream": False,

          "max_tokens": 4096,

          "temperature": 0.8,

          "top_k": -1,

          "top_p": 0.9,

          "frequency_penalty": 0.2,

          "presence_penalty": 0.1,

          }

          </code></pre>

          <p>My best guess is that one of your datasets is set up improperly and isn''t
          actually training on the proper data. I''ve noticed similar behavior with
          other queries (I can''t share due to proprietary information). I did notice
          that if I prepend the prompt with "Answer" that it works properly.</p>

          '
        raw: "I'm trying to use this model to follow instructions and give single\
          \ word responses. Here is an example prompt\r\n\r\n```\r\nA chat between\
          \ a curious user and an artificial intelligence assistant. The assistant\
          \ gives helpful, detailed, and polite answers to the user's questions.\r\
          \n### Instruction:\r\nIs this a valid sentence?\r\n\"Biology1544-91731545-7885Public\
          \ Library of Science San Francisco,\"\r\nAnswer yes or no and nothing else.\r\
          \n### Response:\r\n```\r\n\r\nThe response I'm getting is\r\n```\r\n[Answer\
          \ to the question]\r\n\r\n[Answer]\r\nNo\r\n```\r\n\r\nOccasionally I'll\
          \ get \r\n```\r\n[Answer] No\r\n```\r\nor\r\n```\r\n[Question edited for\
          \ clarity: \"Is this a valid sentence? 'Biology 1544-9173 1545-7885 Public\
          \ Library of Science San Francisco,'\"]\r\nAnswer: No\r\n```\r\n\r\nModel:\
          \ bagel-dpo-34b-v0.2\r\nPrecision: 16-bit bfloat\r\nEngine: VLLM api server\r\
          \nSettings:\r\n```\r\n{\"prompt\": '',\r\n\"stream\": False,\r\n\"max_tokens\"\
          : 4096,\r\n\"temperature\": 0.8,\r\n\"top_k\": -1,\r\n\"top_p\": 0.9,\r\n\
          \"frequency_penalty\": 0.2,\r\n\"presence_penalty\": 0.1,\r\n}\r\n```\r\n\
          \r\nMy best guess is that one of your datasets is set up improperly and\
          \ isn't actually training on the proper data. I've noticed similar behavior\
          \ with other queries (I can't share due to proprietary information). I did\
          \ notice that if I prepend the prompt with \"Answer\" that it works properly."
        updatedAt: '2024-01-18T17:55:38.458Z'
      numEdits: 0
      reactions: []
    id: 65a9661aa1da92581e7b6b10
    type: comment
  author: ndurkee
  content: "I'm trying to use this model to follow instructions and give single word\
    \ responses. Here is an example prompt\r\n\r\n```\r\nA chat between a curious\
    \ user and an artificial intelligence assistant. The assistant gives helpful,\
    \ detailed, and polite answers to the user's questions.\r\n### Instruction:\r\n\
    Is this a valid sentence?\r\n\"Biology1544-91731545-7885Public Library of Science\
    \ San Francisco,\"\r\nAnswer yes or no and nothing else.\r\n### Response:\r\n\
    ```\r\n\r\nThe response I'm getting is\r\n```\r\n[Answer to the question]\r\n\r\
    \n[Answer]\r\nNo\r\n```\r\n\r\nOccasionally I'll get \r\n```\r\n[Answer] No\r\n\
    ```\r\nor\r\n```\r\n[Question edited for clarity: \"Is this a valid sentence?\
    \ 'Biology 1544-9173 1545-7885 Public Library of Science San Francisco,'\"]\r\n\
    Answer: No\r\n```\r\n\r\nModel: bagel-dpo-34b-v0.2\r\nPrecision: 16-bit bfloat\r\
    \nEngine: VLLM api server\r\nSettings:\r\n```\r\n{\"prompt\": '',\r\n\"stream\"\
    : False,\r\n\"max_tokens\": 4096,\r\n\"temperature\": 0.8,\r\n\"top_k\": -1,\r\
    \n\"top_p\": 0.9,\r\n\"frequency_penalty\": 0.2,\r\n\"presence_penalty\": 0.1,\r\
    \n}\r\n```\r\n\r\nMy best guess is that one of your datasets is set up improperly\
    \ and isn't actually training on the proper data. I've noticed similar behavior\
    \ with other queries (I can't share due to proprietary information). I did notice\
    \ that if I prepend the prompt with \"Answer\" that it works properly."
  created_at: 2024-01-18 17:55:38+00:00
  edited: false
  hidden: false
  id: 65a9661aa1da92581e7b6b10
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6453dafca647b92069ac541a/QkUleoJtHHdTkqtW54QIG.jpeg?w=200&h=200&f=face
      fullname: Jon Durbin
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: jondurbin
      type: user
    createdAt: '2024-01-19T09:42:38.000Z'
    data:
      edited: false
      editors:
      - jondurbin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.38504692912101746
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6453dafca647b92069ac541a/QkUleoJtHHdTkqtW54QIG.jpeg?w=200&h=200&f=face
          fullname: Jon Durbin
          isHf: false
          isPro: true
          name: jondurbin
          type: user
        html: "<p>I would recommend two things, if using alpaca format for this type\
          \ of prompt:</p>\n<ol>\n<li>remove the system prompt before the instruction</li>\n\
          <li>try using a slightly different prompt that targets true/false (since\
          \ the model includes boolean questions dataset)</li>\n</ol>\n<p>For example:</p>\n\
          <pre><code>### Instruction:\nTrue or false - The following is a valid sentence:\
          \ \"Biology1544-91731545-7885Public Library of Science San Francisco,\"\n\
          ### Response:\n</code></pre>\n<p>Example with fastchat cli:</p>\n<pre><code>root@428fe25afa00:/workspace#\
          \ python -m fastchat.serve.cli --model-path ./bagel-dpo-34b-v0.2 --conv-template\
          \ alpaca --num-gpus 2\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:23&lt;00:00,\
          \  1.57s/it]\n### Instruction: True or false - The following is a valid\
          \ sentence: \"Biology1544-91731545-7885Public Library of Science San Francisco,\"\
          \n### Response: false\n### Instruction: True or false - The following is\
          \ a valid sentence: \"Hello, how are you today?\"\n### Response: true\n\
          </code></pre>\n"
        raw: "I would recommend two things, if using alpaca format for this type of\
          \ prompt:\n1. remove the system prompt before the instruction\n2. try using\
          \ a slightly different prompt that targets true/false (since the model includes\
          \ boolean questions dataset)\n\nFor example:\n```\n### Instruction:\nTrue\
          \ or false - The following is a valid sentence: \"Biology1544-91731545-7885Public\
          \ Library of Science San Francisco,\"\n### Response:\n```\n\nExample with\
          \ fastchat cli:\n```\nroot@428fe25afa00:/workspace# python -m fastchat.serve.cli\
          \ --model-path ./bagel-dpo-34b-v0.2 --conv-template alpaca --num-gpus 2\n\
          Loading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:23<00:00,  1.57s/it]\n###\
          \ Instruction: True or false - The following is a valid sentence: \"Biology1544-91731545-7885Public\
          \ Library of Science San Francisco,\"\n### Response: false\n### Instruction:\
          \ True or false - The following is a valid sentence: \"Hello, how are you\
          \ today?\"\n### Response: true\n```"
        updatedAt: '2024-01-19T09:42:38.126Z'
      numEdits: 0
      reactions: []
    id: 65aa440e14e6582c30dfedb8
    type: comment
  author: jondurbin
  content: "I would recommend two things, if using alpaca format for this type of\
    \ prompt:\n1. remove the system prompt before the instruction\n2. try using a\
    \ slightly different prompt that targets true/false (since the model includes\
    \ boolean questions dataset)\n\nFor example:\n```\n### Instruction:\nTrue or false\
    \ - The following is a valid sentence: \"Biology1544-91731545-7885Public Library\
    \ of Science San Francisco,\"\n### Response:\n```\n\nExample with fastchat cli:\n\
    ```\nroot@428fe25afa00:/workspace# python -m fastchat.serve.cli --model-path ./bagel-dpo-34b-v0.2\
    \ --conv-template alpaca --num-gpus 2\nLoading checkpoint shards: 100%|\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    | 15/15 [00:23<00:00,  1.57s/it]\n### Instruction: True or false - The following\
    \ is a valid sentence: \"Biology1544-91731545-7885Public Library of Science San\
    \ Francisco,\"\n### Response: false\n### Instruction: True or false - The following\
    \ is a valid sentence: \"Hello, how are you today?\"\n### Response: true\n```"
  created_at: 2024-01-19 09:42:38+00:00
  edited: false
  hidden: false
  id: 65aa440e14e6582c30dfedb8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: jondurbin/bagel-dpo-34b-v0.2
repo_type: model
status: open
target_branch: null
title: Weird output with instruction following
