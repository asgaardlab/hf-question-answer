!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Henk717
conflicting_files: null
created_at: 2024-01-02 16:31:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640356718818-61c47e9c71a107e9d80e33e3.jpeg?w=200&h=200&f=face
      fullname: Henky!!
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Henk717
      type: user
    createdAt: '2024-01-02T16:31:50.000Z'
    data:
      edited: false
      editors:
      - Henk717
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9689469933509827
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640356718818-61c47e9c71a107e9d80e33e3.jpeg?w=200&h=200&f=face
          fullname: Henky!!
          isHf: false
          isPro: false
          name: Henk717
          type: user
        html: '<p>When using the model to generate stories the model very rapidly
          derails from story writing or refuses to do so and merely claims it is story
          writing.<br>Considering that Gutenberg is in here that is highly undesirable
          behavior that directly seems to come from the fact DPO was used to bias
          towards an instruct dataset. The original Bagel without DPO performs these
          tasks well.</p>

          '
        raw: "When using the model to generate stories the model very rapidly derails\
          \ from story writing or refuses to do so and merely claims it is story writing.\r\
          \nConsidering that Gutenberg is in here that is highly undesirable behavior\
          \ that directly seems to come from the fact DPO was used to bias towards\
          \ an instruct dataset. The original Bagel without DPO performs these tasks\
          \ well."
        updatedAt: '2024-01-02T16:31:50.629Z'
      numEdits: 0
      reactions: []
    id: 65943a7689f1ff04630ddb23
    type: comment
  author: Henk717
  content: "When using the model to generate stories the model very rapidly derails\
    \ from story writing or refuses to do so and merely claims it is story writing.\r\
    \nConsidering that Gutenberg is in here that is highly undesirable behavior that\
    \ directly seems to come from the fact DPO was used to bias towards an instruct\
    \ dataset. The original Bagel without DPO performs these tasks well."
  created_at: 2024-01-02 16:31:50+00:00
  edited: false
  hidden: false
  id: 65943a7689f1ff04630ddb23
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6453dafca647b92069ac541a/QkUleoJtHHdTkqtW54QIG.jpeg?w=200&h=200&f=face
      fullname: Jon Durbin
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: jondurbin
      type: user
    createdAt: '2024-01-06T09:38:01.000Z'
    data:
      edited: false
      editors:
      - jondurbin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9723968505859375
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6453dafca647b92069ac541a/QkUleoJtHHdTkqtW54QIG.jpeg?w=200&h=200&f=face
          fullname: Jon Durbin
          isHf: false
          isPro: true
          name: jondurbin
          type: user
        html: "<p>Thanks for the feedback <span data-props=\"{&quot;user&quot;:&quot;Henk717&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Henk717\"\
          >@<span class=\"underline\">Henk717</span></a></span>\n\n\t</span></span>,\
          \ the DPO process for yi-34b with qlora is still a bit of trial-and-error.\
          \  I think, perhaps, the learning rate was too high (even though it was\
          \ orders of magnitude lower than the SFT phase, and I stopped it early at\
          \ 1/3 of the way through).</p>\n<p>Will work on improving the process over\
          \ time.</p>\n"
        raw: 'Thanks for the feedback @Henk717, the DPO process for yi-34b with qlora
          is still a bit of trial-and-error.  I think, perhaps, the learning rate
          was too high (even though it was orders of magnitude lower than the SFT
          phase, and I stopped it early at 1/3 of the way through).


          Will work on improving the process over time.'
        updatedAt: '2024-01-06T09:38:01.627Z'
      numEdits: 0
      reactions: []
    id: 65991f7917edd1f0533e211a
    type: comment
  author: jondurbin
  content: 'Thanks for the feedback @Henk717, the DPO process for yi-34b with qlora
    is still a bit of trial-and-error.  I think, perhaps, the learning rate was too
    high (even though it was orders of magnitude lower than the SFT phase, and I stopped
    it early at 1/3 of the way through).


    Will work on improving the process over time.'
  created_at: 2024-01-06 09:38:01+00:00
  edited: false
  hidden: false
  id: 65991f7917edd1f0533e211a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: jondurbin/bagel-dpo-34b-v0.2
repo_type: model
status: open
target_branch: null
title: DPO ruined Bagel's versitility
