!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Stilgar
conflicting_files: null
created_at: 2023-11-20 21:44:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f5bcb4d417d1db7eb1d0450e9c715d88.svg
      fullname: Choraly
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Stilgar
      type: user
    createdAt: '2023-11-20T21:44:58.000Z'
    data:
      edited: false
      editors:
      - Stilgar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6533365845680237
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f5bcb4d417d1db7eb1d0450e9c715d88.svg
          fullname: Choraly
          isHf: false
          isPro: false
          name: Stilgar
          type: user
        html: '<p>Got the following error with oobagooba and trust_remote_code enabled
          :</p>

          <p>OSError: models\LoneStrikerdolphin-2.2-yi-34b-4.0bpw-h6-exl2 does not
          appear to have a file named tokenization_yi.py. Checkout ''<a href="https://huggingface.co/models%5CLoneStrikerdolphin-2.2-yi-34b-4.0bpw-h6-exl2/None''">https://huggingface.co/models\LoneStrikerdolphin-2.2-yi-34b-4.0bpw-h6-exl2/None''</a>
          for available files.</p>

          '
        raw: "Got the following error with oobagooba and trust_remote_code enabled\
          \ :\r\n\r\nOSError: models\\LoneStrikerdolphin-2.2-yi-34b-4.0bpw-h6-exl2\
          \ does not appear to have a file named tokenization_yi.py. Checkout 'https://huggingface.co/models\\\
          LoneStrikerdolphin-2.2-yi-34b-4.0bpw-h6-exl2/None' for available files."
        updatedAt: '2023-11-20T21:44:58.795Z'
      numEdits: 0
      reactions: []
    id: 655bd35a31c4978366b8a144
    type: comment
  author: Stilgar
  content: "Got the following error with oobagooba and trust_remote_code enabled :\r\
    \n\r\nOSError: models\\LoneStrikerdolphin-2.2-yi-34b-4.0bpw-h6-exl2 does not appear\
    \ to have a file named tokenization_yi.py. Checkout 'https://huggingface.co/models\\\
    LoneStrikerdolphin-2.2-yi-34b-4.0bpw-h6-exl2/None' for available files."
  created_at: 2023-11-20 21:44:58+00:00
  edited: false
  hidden: false
  id: 655bd35a31c4978366b8a144
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-11-21T05:29:37.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9871641993522644
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>Looks like the model was missing the file.  Fixed.</p>

          '
        raw: Looks like the model was missing the file.  Fixed.
        updatedAt: '2023-11-21T05:29:37.836Z'
      numEdits: 0
      reactions: []
    id: 655c404176e4fad552bf9b1c
    type: comment
  author: LoneStriker
  content: Looks like the model was missing the file.  Fixed.
  created_at: 2023-11-21 05:29:37+00:00
  edited: false
  hidden: false
  id: 655c404176e4fad552bf9b1c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f5bcb4d417d1db7eb1d0450e9c715d88.svg
      fullname: Choraly
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Stilgar
      type: user
    createdAt: '2023-11-21T17:40:58.000Z'
    data:
      edited: true
      editors:
      - Stilgar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8981245756149292
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f5bcb4d417d1db7eb1d0450e9c715d88.svg
          fullname: Choraly
          isHf: false
          isPro: false
          name: Stilgar
          type: user
        html: '<p>Thank you the error is gone,</p>

          <p>But now I get another one but probably because my transformers are not
          the latest :</p>

          <p>ValueError: Tokenizer class YiTokenizer does not exist or is not currently
          imported.</p>

          <p>Edit : After trying to import the missing YiTokenizer, I get the following
          error : </p>

          <p>ModuleNotFoundError: No module named ''transformers_modules.LoneStrikerdolphin-2''</p>

          <p>Maybe another file is missing...</p>

          '
        raw: "Thank you the error is gone,\n\nBut now I get another one but probably\
          \ because my transformers are not the latest :\n\nValueError: Tokenizer\
          \ class YiTokenizer does not exist or is not currently imported.\n\nEdit\
          \ : After trying to import the missing YiTokenizer, I get the following\
          \ error : \n\nModuleNotFoundError: No module named 'transformers_modules.LoneStrikerdolphin-2'\n\
          \nMaybe another file is missing..."
        updatedAt: '2023-11-21T17:52:14.202Z'
      numEdits: 1
      reactions: []
      relatedEventId: 655cebaab5da99edaf1c628c
    id: 655cebaab5da99edaf1c628a
    type: comment
  author: Stilgar
  content: "Thank you the error is gone,\n\nBut now I get another one but probably\
    \ because my transformers are not the latest :\n\nValueError: Tokenizer class\
    \ YiTokenizer does not exist or is not currently imported.\n\nEdit : After trying\
    \ to import the missing YiTokenizer, I get the following error : \n\nModuleNotFoundError:\
    \ No module named 'transformers_modules.LoneStrikerdolphin-2'\n\nMaybe another\
    \ file is missing..."
  created_at: 2023-11-21 17:40:58+00:00
  edited: true
  hidden: false
  id: 655cebaab5da99edaf1c628a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/f5bcb4d417d1db7eb1d0450e9c715d88.svg
      fullname: Choraly
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Stilgar
      type: user
    createdAt: '2023-11-21T17:40:58.000Z'
    data:
      status: closed
    id: 655cebaab5da99edaf1c628c
    type: status-change
  author: Stilgar
  created_at: 2023-11-21 17:40:58+00:00
  id: 655cebaab5da99edaf1c628c
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af1201cb8f07eba487669586f75a4b32.svg
      fullname: None
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Thireus
      type: user
    createdAt: '2023-11-25T15:24:34.000Z'
    data:
      edited: false
      editors:
      - Thireus
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8636484146118164
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af1201cb8f07eba487669586f75a4b32.svg
          fullname: None
          isHf: false
          isPro: false
          name: Thireus
          type: user
        html: '<p>Using <code>--loader exllamav2</code> instead of <code>--loader
          exllamav2_hf</code> resolves this issue.</p>

          '
        raw: Using `--loader exllamav2` instead of `--loader exllamav2_hf` resolves
          this issue.
        updatedAt: '2023-11-25T15:24:34.371Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - LoneStriker
    id: 656211b2280cd6b710a7d45e
    type: comment
  author: Thireus
  content: Using `--loader exllamav2` instead of `--loader exllamav2_hf` resolves
    this issue.
  created_at: 2023-11-25 15:24:34+00:00
  edited: false
  hidden: false
  id: 656211b2280cd6b710a7d45e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f5bcb4d417d1db7eb1d0450e9c715d88.svg
      fullname: Choraly
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Stilgar
      type: user
    createdAt: '2023-11-25T17:40:25.000Z'
    data:
      edited: true
      editors:
      - Stilgar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9615557789802551
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f5bcb4d417d1db7eb1d0450e9c715d88.svg
          fullname: Choraly
          isHf: false
          isPro: false
          name: Stilgar
          type: user
        html: '<p>Yes your right it''s work with exllamav2.<br>The model is using
          23.5Go Vram and is really fast on a 4090 (+/- 34 token /s)<br>BUT :<br>he
          hallucinates a lot and does not answer the questions asked.<br>Ultimately
          the result is worse than a Mistral 7b.<br>Unfortunately exl2 is known to
          favor speed to the detriment of accuracy.</p>

          '
        raw: "Yes your right it's work with exllamav2.\nThe model is using 23.5Go\
          \ Vram and is really fast on a 4090 (+/- 34 token /s)\nBUT : \nhe hallucinates\
          \ a lot and does not answer the questions asked. \nUltimately the result\
          \ is worse than a Mistral 7b. \nUnfortunately exl2 is known to favor speed\
          \ to the detriment of accuracy."
        updatedAt: '2023-11-25T17:40:46.127Z'
      numEdits: 1
      reactions: []
    id: 65623189d5e3c35c790fceb7
    type: comment
  author: Stilgar
  content: "Yes your right it's work with exllamav2.\nThe model is using 23.5Go Vram\
    \ and is really fast on a 4090 (+/- 34 token /s)\nBUT : \nhe hallucinates a lot\
    \ and does not answer the questions asked. \nUltimately the result is worse than\
    \ a Mistral 7b. \nUnfortunately exl2 is known to favor speed to the detriment\
    \ of accuracy."
  created_at: 2023-11-25 17:40:25+00:00
  edited: true
  hidden: false
  id: 65623189d5e3c35c790fceb7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-11-25T19:15:32.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9722145795822144
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>I don''t believe that''s a true statement. exl2 is as accurate as
          other quantization methods as well as being fast.  It also lets you pick
          exactly the bitrate you want, so you can fit models into specific GPUs (70B
          at ~2.4bpw fits on a single 3090 or 4090).  The Yi models themselves seem
          to be much more fragile and more prone to go off the rails.  Try setting
          your repetition penalty lower (like 1.0 or close to it.)  At lower bit rates,
          exl2 models need to turn off inserting the bos tokens in ooba.  You can
          try turning that off here as well.</p>

          '
        raw: I don't believe that's a true statement. exl2 is as accurate as other
          quantization methods as well as being fast.  It also lets you pick exactly
          the bitrate you want, so you can fit models into specific GPUs (70B at ~2.4bpw
          fits on a single 3090 or 4090).  The Yi models themselves seem to be much
          more fragile and more prone to go off the rails.  Try setting your repetition
          penalty lower (like 1.0 or close to it.)  At lower bit rates, exl2 models
          need to turn off inserting the bos tokens in ooba.  You can try turning
          that off here as well.
        updatedAt: '2023-11-25T19:15:32.286Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Thireus
        - waldie
    id: 656247d42bdaccfcd5e37fbe
    type: comment
  author: LoneStriker
  content: I don't believe that's a true statement. exl2 is as accurate as other quantization
    methods as well as being fast.  It also lets you pick exactly the bitrate you
    want, so you can fit models into specific GPUs (70B at ~2.4bpw fits on a single
    3090 or 4090).  The Yi models themselves seem to be much more fragile and more
    prone to go off the rails.  Try setting your repetition penalty lower (like 1.0
    or close to it.)  At lower bit rates, exl2 models need to turn off inserting the
    bos tokens in ooba.  You can try turning that off here as well.
  created_at: 2023-11-25 19:15:32+00:00
  edited: false
  hidden: false
  id: 656247d42bdaccfcd5e37fbe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f5bcb4d417d1db7eb1d0450e9c715d88.svg
      fullname: Choraly
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Stilgar
      type: user
    createdAt: '2023-11-25T20:18:31.000Z'
    data:
      edited: true
      editors:
      - Stilgar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9529539346694946
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f5bcb4d417d1db7eb1d0450e9c715d88.svg
          fullname: Choraly
          isHf: false
          isPro: false
          name: Stilgar
          type: user
        html: "<p>Setting the repetition rate to 1 seems to be better, temperature\
          \ parameters does not change a lot.</p>\n<p>The thing I notice:<br>If I\
          \ ask the model in French I get some big mistakes:</p>\n<p>By example, I\
          \ ask about atom constitution and is doing a mix between neutron and neutrino\
          \ then affect a null charge to electron.<br>Asking in English (with same\
          \ parameters) I got different sentences and good result.</p>\n<p>Again,\
          \ I ask in French about a character from a well-known book and the reply\
          \ is the character does not exist\u2026<br>In English, the character is\
          \ found and story has some errors but at least the reply is not too bad\
          \ and is coherent.</p>\n<p>I did not notice this with other model, generaaly\
          \ french and english sentences are very close (only time to time some word\
          \ not fully translated)</p>\n<p>In any case thank you for your job, I\u2019\
          ll try more exl2 models because it\u2019s clear the speed and Vram used\
          \ are very efficient.</p>\n"
        raw: "Setting the repetition rate to 1 seems to be better, temperature parameters\
          \ does not change a lot.\n\nThe thing I notice:\nIf I ask the model in French\
          \ I get some big mistakes:\n\nBy example, I ask about atom constitution\
          \ and is doing a mix between neutron and neutrino then affect a null charge\
          \ to electron.\nAsking in English (with same parameters) I got different\
          \ sentences and good result.\n\nAgain, I ask in French about a character\
          \ from a well-known book and the reply is the character does not exist\u2026\
          \nIn English, the character is found and story has some errors but at least\
          \ the reply is not too bad and is coherent.\n\nI did not notice this with\
          \ other model, generaaly french and english sentences are very close (only\
          \ time to time some word not fully translated)\n\nIn any case thank you\
          \ for your job, I\u2019ll try more exl2 models because it\u2019s clear the\
          \ speed and Vram used are very efficient.\n"
        updatedAt: '2023-11-25T20:19:30.400Z'
      numEdits: 3
      reactions: []
    id: 65625697620c177ae08ddf04
    type: comment
  author: Stilgar
  content: "Setting the repetition rate to 1 seems to be better, temperature parameters\
    \ does not change a lot.\n\nThe thing I notice:\nIf I ask the model in French\
    \ I get some big mistakes:\n\nBy example, I ask about atom constitution and is\
    \ doing a mix between neutron and neutrino then affect a null charge to electron.\n\
    Asking in English (with same parameters) I got different sentences and good result.\n\
    \nAgain, I ask in French about a character from a well-known book and the reply\
    \ is the character does not exist\u2026\nIn English, the character is found and\
    \ story has some errors but at least the reply is not too bad and is coherent.\n\
    \nI did not notice this with other model, generaaly french and english sentences\
    \ are very close (only time to time some word not fully translated)\n\nIn any\
    \ case thank you for your job, I\u2019ll try more exl2 models because it\u2019\
    s clear the speed and Vram used are very efficient.\n"
  created_at: 2023-11-25 20:18:31+00:00
  edited: true
  hidden: false
  id: 65625697620c177ae08ddf04
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: LoneStriker/dolphin-2.2-yi-34b-4.0bpw-h6-exl2
repo_type: model
status: closed
target_branch: null
title: tokenization_yi.py
