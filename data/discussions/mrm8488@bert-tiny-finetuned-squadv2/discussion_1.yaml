!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mweiss
conflicting_files: null
created_at: 2022-07-15 08:13:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dc55659964dbd6fbd48c057ff50c3f20.svg
      fullname: Michael Weiss
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mweiss
      type: user
    createdAt: '2022-07-15T09:13:33.000Z'
    data:
      edited: true
      editors:
      - mweiss
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dc55659964dbd6fbd48c057ff50c3f20.svg
          fullname: Michael Weiss
          isHf: false
          isPro: false
          name: mweiss
          type: user
        html: '<p>Context: </p>

          <blockquote>

          <p>The Norman dynasty had a major political, cultural and military impact
          on medieval Europe and even the Near East. The Normans were famed for their
          martial spirit and eventually for their Christian piety, becoming exponents
          of the Catholic orthodoxy into which they assimilated. They adopted the
          Gallo-Romance language of the Frankish land they settled, their dialect
          becoming known as Norman, Normaund or Norman French, an important literary
          language. The Duchy of Normandy, which they formed by treaty with the French
          crown, was a great fief of medieval France, and under Richard I of Normandy
          was forged into a cohesive and formidable principality in feudal tenure.
          The Normans are noted both for their culture, such as their unique Romanesque
          architecture and musical traditions, and for their significant military
          accomplishments and innovations. Norman adventurers founded the Kingdom
          of Sicily under Roger II after conquering southern Italy on the Saracens
          and Byzantines, and an expedition on behalf of their duke, William the Conqueror,
          led to the Norman conquest of England at the Battle of Hastings in 1066.
          Norman cultural and military influence spread from these new European centres
          to the Crusader states of the Near East, where their prince Bohemond I founded
          the Principality of Antioch in the Levant, to Scotland and Wales in Great
          Britain, to Ireland, and to the coasts of north Africa and the Canary Islands.</p>

          </blockquote>

          <p>Question:</p>

          <blockquote>

          <p>''Who ruled the duchy of Normandy''</p>

          </blockquote>

          <p>Stack Trace:</p>

          <blockquote>

          <p>thread '''' panicked at ''assertion failed: stride &lt; max_len'', /__w/tokenizers/tokenizers/tokenizers/src/tokenizer/encoding.rs:311:9<br>note:
          run with <code>RUST_BACKTRACE=1</code> environment variable to display a
          backtrace<br>Traceback (most recent call last):<br>  File "/snap/pycharm-professional/290/plugins/python/helpers/pydev/pydevd.py",
          line 1491, in _exec<br>    pydev_imports.execfile(file, globals, locals)  #
          execute the script<br>  File "/snap/pycharm-professional/290/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py",
          line 18, in execfile<br>    exec(compile(contents+"\n", file, ''exec''),
          glob, loc)<br>  File "/case_studies/squadv2.py", line 134, in <br>    SQuADv2().collect_local_predictions()<br>  File
          "/case_studies/squadv2.py", line 104, in collect_local_predictions<br>    pred
          = qa_pipeline(inp.context, inp.context)<br>  File "/venv38/lib/python3.8/site-packages/transformers/pipelines/question_answering.py",
          line 250, in <strong>call</strong><br>    return super().<strong>call</strong>(examples[0],
          **kwargs)<br>  File "/venv38/lib/python3.8/site-packages/transformers/pipelines/base.py",
          line 1043, in <strong>call</strong><br>    return self.run_single(inputs,
          preprocess_params, forward_params, postprocess_params)<br>  File "/venv38/lib/python3.8/site-packages/transformers/pipelines/base.py",
          line 1064, in run_single<br>    for model_inputs in self.preprocess(inputs,
          **preprocess_params):<br>  File "/venv38/lib/python3.8/site-packages/transformers/pipelines/question_answering.py",
          line 275, in preprocess<br>    encoded_inputs = self.tokenizer(<br>  File
          "/venv38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py",
          line 2515, in <strong>call</strong><br>    return self.encode_plus(<br>  File
          "/venv38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py",
          line 2588, in encode_plus<br>    return self._encode_plus(<br>  File "/venv38/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py",
          line 499, in _encode_plus<br>    batched_output = self._batch_encode_plus(<br>  File
          "/venv38/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py",
          line 426, in _batch_encode_plus<br>    encodings = self._tokenizer.encode_batch(<br>pyo3_runtime.PanicException:
          assertion failed: stride &lt; max_len</p>

          </blockquote>

          <p>Reducing the length of the context to 100chars confirms that the error
          is caused by the long context. Clearly, however, this is not a workaround.
          </p>

          <p>Versions:<br><code>torch==1.12.0</code><br><code>python 3.8</code><br><code>transformers==4.20.1</code><br><code>tensorflow==2.8.0</code></p>

          '
        raw: "Context: \n> The Norman dynasty had a major political, cultural and\
          \ military impact on medieval Europe and even the Near East. The Normans\
          \ were famed for their martial spirit and eventually for their Christian\
          \ piety, becoming exponents of the Catholic orthodoxy into which they assimilated.\
          \ They adopted the Gallo-Romance language of the Frankish land they settled,\
          \ their dialect becoming known as Norman, Normaund or Norman French, an\
          \ important literary language. The Duchy of Normandy, which they formed\
          \ by treaty with the French crown, was a great fief of medieval France,\
          \ and under Richard I of Normandy was forged into a cohesive and formidable\
          \ principality in feudal tenure. The Normans are noted both for their culture,\
          \ such as their unique Romanesque architecture and musical traditions, and\
          \ for their significant military accomplishments and innovations. Norman\
          \ adventurers founded the Kingdom of Sicily under Roger II after conquering\
          \ southern Italy on the Saracens and Byzantines, and an expedition on behalf\
          \ of their duke, William the Conqueror, led to the Norman conquest of England\
          \ at the Battle of Hastings in 1066. Norman cultural and military influence\
          \ spread from these new European centres to the Crusader states of the Near\
          \ East, where their prince Bohemond I founded the Principality of Antioch\
          \ in the Levant, to Scotland and Wales in Great Britain, to Ireland, and\
          \ to the coasts of north Africa and the Canary Islands.\n\nQuestion:\n>\
          \ 'Who ruled the duchy of Normandy'\n\nStack Trace:\n> thread '<unnamed>'\
          \ panicked at 'assertion failed: stride < max_len', /__w/tokenizers/tokenizers/tokenizers/src/tokenizer/encoding.rs:311:9\n\
          note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n\
          Traceback (most recent call last):\n  File \"/snap/pycharm-professional/290/plugins/python/helpers/pydev/pydevd.py\"\
          , line 1491, in _exec\n    pydev_imports.execfile(file, globals, locals)\
          \  # execute the script\n  File \"/snap/pycharm-professional/290/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py\"\
          , line 18, in execfile\n    exec(compile(contents+\"\\n\", file, 'exec'),\
          \ glob, loc)\n  File \"<project-path>/case_studies/squadv2.py\", line 134,\
          \ in <module>\n    SQuADv2().collect_local_predictions()\n  File \"<project-path>/case_studies/squadv2.py\"\
          , line 104, in collect_local_predictions\n    pred = qa_pipeline(inp.context,\
          \ inp.context)\n  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/pipelines/question_answering.py\"\
          , line 250, in __call__\n    return super().__call__(examples[0], **kwargs)\n\
          \  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/pipelines/base.py\"\
          , line 1043, in __call__\n    return self.run_single(inputs, preprocess_params,\
          \ forward_params, postprocess_params)\n  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/pipelines/base.py\"\
          , line 1064, in run_single\n    for model_inputs in self.preprocess(inputs,\
          \ **preprocess_params):\n  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/pipelines/question_answering.py\"\
          , line 275, in preprocess\n    encoded_inputs = self.tokenizer(\n  File\
          \ \"<project-path>/venv38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2515, in __call__\n    return self.encode_plus(\n  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2588, in encode_plus\n    return self._encode_plus(\n  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\"\
          , line 499, in _encode_plus\n    batched_output = self._batch_encode_plus(\n\
          \  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\"\
          , line 426, in _batch_encode_plus\n    encodings = self._tokenizer.encode_batch(\n\
          pyo3_runtime.PanicException: assertion failed: stride < max_len\n\nReducing\
          \ the length of the context to 100chars confirms that the error is caused\
          \ by the long context. Clearly, however, this is not a workaround. \n\n\
          Versions:\n`torch==1.12.0`\n`python 3.8`\n`transformers==4.20.1`\n`tensorflow==2.8.0`"
        updatedAt: '2022-07-15T09:16:33.285Z'
      numEdits: 1
      reactions: []
    id: 62d12fbd11c2dbcf27e8749e
    type: comment
  author: mweiss
  content: "Context: \n> The Norman dynasty had a major political, cultural and military\
    \ impact on medieval Europe and even the Near East. The Normans were famed for\
    \ their martial spirit and eventually for their Christian piety, becoming exponents\
    \ of the Catholic orthodoxy into which they assimilated. They adopted the Gallo-Romance\
    \ language of the Frankish land they settled, their dialect becoming known as\
    \ Norman, Normaund or Norman French, an important literary language. The Duchy\
    \ of Normandy, which they formed by treaty with the French crown, was a great\
    \ fief of medieval France, and under Richard I of Normandy was forged into a cohesive\
    \ and formidable principality in feudal tenure. The Normans are noted both for\
    \ their culture, such as their unique Romanesque architecture and musical traditions,\
    \ and for their significant military accomplishments and innovations. Norman adventurers\
    \ founded the Kingdom of Sicily under Roger II after conquering southern Italy\
    \ on the Saracens and Byzantines, and an expedition on behalf of their duke, William\
    \ the Conqueror, led to the Norman conquest of England at the Battle of Hastings\
    \ in 1066. Norman cultural and military influence spread from these new European\
    \ centres to the Crusader states of the Near East, where their prince Bohemond\
    \ I founded the Principality of Antioch in the Levant, to Scotland and Wales in\
    \ Great Britain, to Ireland, and to the coasts of north Africa and the Canary\
    \ Islands.\n\nQuestion:\n> 'Who ruled the duchy of Normandy'\n\nStack Trace:\n\
    > thread '<unnamed>' panicked at 'assertion failed: stride < max_len', /__w/tokenizers/tokenizers/tokenizers/src/tokenizer/encoding.rs:311:9\n\
    note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n\
    Traceback (most recent call last):\n  File \"/snap/pycharm-professional/290/plugins/python/helpers/pydev/pydevd.py\"\
    , line 1491, in _exec\n    pydev_imports.execfile(file, globals, locals)  # execute\
    \ the script\n  File \"/snap/pycharm-professional/290/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py\"\
    , line 18, in execfile\n    exec(compile(contents+\"\\n\", file, 'exec'), glob,\
    \ loc)\n  File \"<project-path>/case_studies/squadv2.py\", line 134, in <module>\n\
    \    SQuADv2().collect_local_predictions()\n  File \"<project-path>/case_studies/squadv2.py\"\
    , line 104, in collect_local_predictions\n    pred = qa_pipeline(inp.context,\
    \ inp.context)\n  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/pipelines/question_answering.py\"\
    , line 250, in __call__\n    return super().__call__(examples[0], **kwargs)\n\
    \  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/pipelines/base.py\"\
    , line 1043, in __call__\n    return self.run_single(inputs, preprocess_params,\
    \ forward_params, postprocess_params)\n  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/pipelines/base.py\"\
    , line 1064, in run_single\n    for model_inputs in self.preprocess(inputs, **preprocess_params):\n\
    \  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/pipelines/question_answering.py\"\
    , line 275, in preprocess\n    encoded_inputs = self.tokenizer(\n  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\"\
    , line 2515, in __call__\n    return self.encode_plus(\n  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\"\
    , line 2588, in encode_plus\n    return self._encode_plus(\n  File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\"\
    , line 499, in _encode_plus\n    batched_output = self._batch_encode_plus(\n \
    \ File \"<project-path>/venv38/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\"\
    , line 426, in _batch_encode_plus\n    encodings = self._tokenizer.encode_batch(\n\
    pyo3_runtime.PanicException: assertion failed: stride < max_len\n\nReducing the\
    \ length of the context to 100chars confirms that the error is caused by the long\
    \ context. Clearly, however, this is not a workaround. \n\nVersions:\n`torch==1.12.0`\n\
    `python 3.8`\n`transformers==4.20.1`\n`tensorflow==2.8.0`"
  created_at: 2022-07-15 08:13:33+00:00
  edited: true
  hidden: false
  id: 62d12fbd11c2dbcf27e8749e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dc55659964dbd6fbd48c057ff50c3f20.svg
      fullname: Michael Weiss
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mweiss
      type: user
    createdAt: '2022-07-15T09:47:07.000Z'
    data:
      edited: false
      editors:
      - mweiss
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dc55659964dbd6fbd48c057ff50c3f20.svg
          fullname: Michael Weiss
          isHf: false
          isPro: false
          name: mweiss
          type: user
        html: '<p>Turns out problem was sitting in front of the keyboard ;-)</p>

          '
        raw: Turns out problem was sitting in front of the keyboard ;-)
        updatedAt: '2022-07-15T09:47:07.763Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mrm8488
    id: 62d1379beaedad82706ab6c0
    type: comment
  author: mweiss
  content: Turns out problem was sitting in front of the keyboard ;-)
  created_at: 2022-07-15 08:47:07+00:00
  edited: false
  hidden: false
  id: 62d1379beaedad82706ab6c0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/dc55659964dbd6fbd48c057ff50c3f20.svg
      fullname: Michael Weiss
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mweiss
      type: user
    createdAt: '2022-07-15T09:47:07.000Z'
    data:
      status: closed
    id: 62d1379beaedad82706ab6c1
    type: status-change
  author: mweiss
  created_at: 2022-07-15 08:47:07+00:00
  id: 62d1379beaedad82706ab6c1
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: mrm8488/bert-tiny-finetuned-squadv2
repo_type: model
status: closed
target_branch: null
title: Running example provided in readme on squadv2 leads to error
