!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ilnurshams
conflicting_files: null
created_at: 2023-06-03 21:51:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/aeb28ba60e2961c979bf0787bc90e40c.svg
      fullname: ilnurshams
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ilnurshams
      type: user
    createdAt: '2023-06-03T22:51:43.000Z'
    data:
      edited: false
      editors:
      - ilnurshams
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9691449999809265
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/aeb28ba60e2961c979bf0787bc90e40c.svg
          fullname: ilnurshams
          isHf: false
          isPro: false
          name: ilnurshams
          type: user
        html: '<p>I am running it with Windows 11, RTX4090, 65GB RAM, i7 13700KF.<br>And
          it gives me 0.16 t/s. My graphic card is loading up to 20gb+- out of 24gb
          ( it means that there is nothing wrong with 128g, it has some space ). I
          have no clue what''s wrong with it. All other models work just fine.<br>Did
          anyone managed to fix that problem?</p>

          '
        raw: "I am running it with Windows 11, RTX4090, 65GB RAM, i7 13700KF.\r\n\
          And it gives me 0.16 t/s. My graphic card is loading up to 20gb+- out of\
          \ 24gb ( it means that there is nothing wrong with 128g, it has some space\
          \ ). I have no clue what's wrong with it. All other models work just fine.\r\
          \nDid anyone managed to fix that problem?"
        updatedAt: '2023-06-03T22:51:43.996Z'
      numEdits: 0
      reactions: []
    id: 647bc3ff42b0647cd744bb54
    type: comment
  author: ilnurshams
  content: "I am running it with Windows 11, RTX4090, 65GB RAM, i7 13700KF.\r\nAnd\
    \ it gives me 0.16 t/s. My graphic card is loading up to 20gb+- out of 24gb (\
    \ it means that there is nothing wrong with 128g, it has some space ). I have\
    \ no clue what's wrong with it. All other models work just fine.\r\nDid anyone\
    \ managed to fix that problem?"
  created_at: 2023-06-03 21:51:43+00:00
  edited: false
  hidden: false
  id: 647bc3ff42b0647cd744bb54
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1f437f318770edea28ec92d7cb14bd73.svg
      fullname: Brett S
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cleverest
      type: user
    createdAt: '2023-06-27T23:42:35.000Z'
    data:
      edited: false
      editors:
      - cleverest
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9974105358123779
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1f437f318770edea28ec92d7cb14bd73.svg
          fullname: Brett S
          isHf: false
          isPro: false
          name: cleverest
          type: user
        html: '<p>Sadly they don''t seem to care; this model is broken sadly.</p>

          '
        raw: Sadly they don't seem to care; this model is broken sadly.
        updatedAt: '2023-06-27T23:42:35.224Z'
      numEdits: 0
      reactions: []
    id: 649b73eb1ac1830dc89854a5
    type: comment
  author: cleverest
  content: Sadly they don't seem to care; this model is broken sadly.
  created_at: 2023-06-27 22:42:35+00:00
  edited: false
  hidden: false
  id: 649b73eb1ac1830dc89854a5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: Zicara/OPT-30B-Erebus-4bit-128g
repo_type: model
status: open
target_branch: null
title: Did anyone manage to run it with oobabooga? It's very slow
