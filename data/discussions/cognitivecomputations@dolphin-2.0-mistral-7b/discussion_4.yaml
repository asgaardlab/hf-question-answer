!!python/object:huggingface_hub.community.DiscussionWithDetails
author: danihend
conflicting_files: null
created_at: 2023-10-13 18:53:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/da80ae3d8370e8a379c5fc3530b62b22.svg
      fullname: Daniel Henderson
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: danihend
      type: user
    createdAt: '2023-10-13T19:53:01.000Z'
    data:
      edited: false
      editors:
      - danihend
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.819908082485199
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/da80ae3d8370e8a379c5fc3530b62b22.svg
          fullname: Daniel Henderson
          isHf: false
          isPro: false
          name: danihend
          type: user
        html: "<p>I have tried loading the model with Transformers and ExLlama but\
          \ neither of them work. With ExLlama_HF it  give the error about the   \"\
          pad_token_id\" which I fixed by adding it to the config.json file as   \"\
          pad_token_id\": 2,. </p>\n<p>Then it gives me this error:<br>File \u201C\
          /home/Me/miniconda3/envs/textgen/lib/python3.10/site-packages/exllama/model.py\u201D\
          , line 732, in init</p>\n<p>with safe_open(self.config.model_path, framework\
          \ = \"pt\", device = \"cpu\") as f:<br>safetensors_rust.SafetensorError:\
          \ Error while deserializing header: HeaderTooLarge</p>\n<p>Does this mean\
          \ it is expecting the safetensors file format?</p>\n"
        raw: "I have tried loading the model with Transformers and ExLlama but neither\
          \ of them work. With ExLlama_HF it  give the error about the   \"pad_token_id\"\
          \ which I fixed by adding it to the config.json file as   \"pad_token_id\"\
          : 2,. \r\n\r\nThen it gives me this error: \r\nFile \u201C/home/Me/miniconda3/envs/textgen/lib/python3.10/site-packages/exllama/model.py\u201D\
          , line 732, in init\r\n\r\nwith safe_open(self.config.model_path, framework\
          \ = \"pt\", device = \"cpu\") as f:\r\nsafetensors_rust.SafetensorError:\
          \ Error while deserializing header: HeaderTooLarge\r\n\r\nDoes this mean\
          \ it is expecting the safetensors file format?"
        updatedAt: '2023-10-13T19:53:01.548Z'
      numEdits: 0
      reactions: []
    id: 6529a01db355406e2dadb6fc
    type: comment
  author: danihend
  content: "I have tried loading the model with Transformers and ExLlama but neither\
    \ of them work. With ExLlama_HF it  give the error about the   \"pad_token_id\"\
    \ which I fixed by adding it to the config.json file as   \"pad_token_id\": 2,.\
    \ \r\n\r\nThen it gives me this error: \r\nFile \u201C/home/Me/miniconda3/envs/textgen/lib/python3.10/site-packages/exllama/model.py\u201D\
    , line 732, in init\r\n\r\nwith safe_open(self.config.model_path, framework =\
    \ \"pt\", device = \"cpu\") as f:\r\nsafetensors_rust.SafetensorError: Error while\
    \ deserializing header: HeaderTooLarge\r\n\r\nDoes this mean it is expecting the\
    \ safetensors file format?"
  created_at: 2023-10-13 18:53:01+00:00
  edited: false
  hidden: false
  id: 6529a01db355406e2dadb6fc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b664c5ff3f049bb5f07badee175a9eac.svg
      fullname: CHRISTOPHER TIERNEY
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sennetor
      type: user
    createdAt: '2023-10-13T20:50:30.000Z'
    data:
      edited: false
      editors:
      - sennetor
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7504287958145142
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b664c5ff3f049bb5f07badee175a9eac.svg
          fullname: CHRISTOPHER TIERNEY
          isHf: false
          isPro: false
          name: sennetor
          type: user
        html: '<p>This line in your tokenizer_config.json file was causing me issues.
          I removed it and I loaded your model just fine:</p>

          <p>  "tokenizer_file": "/workspace/.cache/hf/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/d635d39671aaceec5ef84b745bc21625b324b7f8/tokenizer.json",</p>

          '
        raw: "This line in your tokenizer_config.json file was causing me issues.\
          \ I removed it and I loaded your model just fine:\n\n  \"tokenizer_file\"\
          : \"/workspace/.cache/hf/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/d635d39671aaceec5ef84b745bc21625b324b7f8/tokenizer.json\"\
          ,"
        updatedAt: '2023-10-13T20:50:30.175Z'
      numEdits: 0
      reactions: []
    id: 6529ad96b355406e2daf77a7
    type: comment
  author: sennetor
  content: "This line in your tokenizer_config.json file was causing me issues. I\
    \ removed it and I loaded your model just fine:\n\n  \"tokenizer_file\": \"/workspace/.cache/hf/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/d635d39671aaceec5ef84b745bc21625b324b7f8/tokenizer.json\"\
    ,"
  created_at: 2023-10-13 19:50:30+00:00
  edited: false
  hidden: false
  id: 6529ad96b355406e2daf77a7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/da80ae3d8370e8a379c5fc3530b62b22.svg
      fullname: Daniel Henderson
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: danihend
      type: user
    createdAt: '2023-10-13T20:59:00.000Z'
    data:
      edited: true
      editors:
      - danihend
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9421733021736145
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/da80ae3d8370e8a379c5fc3530b62b22.svg
          fullname: Daniel Henderson
          isHf: false
          isPro: false
          name: danihend
          type: user
        html: '<blockquote>

          <p>This line in your tokenizer_config.json file was causing me issues. I
          removed it and I loaded your model just fine:</p>

          <p>  "tokenizer_file": "/workspace/.cache/hf/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/d635d39671aaceec5ef84b745bc21625b324b7f8/tokenizer.json",</p>

          </blockquote>

          <p>was this a response to my post? That issue was already fixed an doesn''t
          have anything to do with this one.</p>

          '
        raw: "> This line in your tokenizer_config.json file was causing me issues.\
          \ I removed it and I loaded your model just fine:\n> \n>   \"tokenizer_file\"\
          : \"/workspace/.cache/hf/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/d635d39671aaceec5ef84b745bc21625b324b7f8/tokenizer.json\"\
          ,\n\nwas this a response to my post? That issue was already fixed an doesn't\
          \ have anything to do with this one."
        updatedAt: '2023-10-13T20:59:16.605Z'
      numEdits: 1
      reactions: []
    id: 6529af94aba3aefb7d920570
    type: comment
  author: danihend
  content: "> This line in your tokenizer_config.json file was causing me issues.\
    \ I removed it and I loaded your model just fine:\n> \n>   \"tokenizer_file\"\
    : \"/workspace/.cache/hf/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/d635d39671aaceec5ef84b745bc21625b324b7f8/tokenizer.json\"\
    ,\n\nwas this a response to my post? That issue was already fixed an doesn't have\
    \ anything to do with this one."
  created_at: 2023-10-13 19:59:00+00:00
  edited: true
  hidden: false
  id: 6529af94aba3aefb7d920570
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643d30a54816d7cb420a4808/LTrBbPAGLM6yqih7Wq6R7.jpeg?w=200&h=200&f=face
      fullname: Ashley Kleynhans
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ashleykleynhans
      type: user
    createdAt: '2023-10-16T07:55:02.000Z'
    data:
      edited: false
      editors:
      - ashleykleynhans
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9445953369140625
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643d30a54816d7cb420a4808/LTrBbPAGLM6yqih7Wq6R7.jpeg?w=200&h=200&f=face
          fullname: Ashley Kleynhans
          isHf: false
          isPro: false
          name: ashleykleynhans
          type: user
        html: '<p>This seems to be an issue with the latest version of the oobabooga
          Text Generation Web UI.<br>I was also unable to load the model using any
          of the model loaders.<br>I noticed that Matthew Berman was able to successfully
          load the model using the <strong>Transformers</strong> model loader in <a
          rel="nofollow" href="https://www.youtube.com/watch?v=tK1Pivdcl3U">this YouTube
          video</a>.</p>

          <p>There have been a number of updates to oobabooga recently which have
          broken various different things in a spectacular fashion, so they clearly
          need to add some unit tests to the project.</p>

          <p>Until such time as oobabooga is in a working state again, this is the
          commit that is working for me:<br>cb26163a209d6272ed14da83782f71bae4681d75</p>

          '
        raw: 'This seems to be an issue with the latest version of the oobabooga Text
          Generation Web UI.

          I was also unable to load the model using any of the model loaders.

          I noticed that Matthew Berman was able to successfully load the model using
          the **Transformers** model loader in [this YouTube video](https://www.youtube.com/watch?v=tK1Pivdcl3U).


          There have been a number of updates to oobabooga recently which have broken
          various different things in a spectacular fashion, so they clearly need
          to add some unit tests to the project.


          Until such time as oobabooga is in a working state again, this is the commit
          that is working for me:

          cb26163a209d6272ed14da83782f71bae4681d75'
        updatedAt: '2023-10-16T07:55:02.308Z'
      numEdits: 0
      reactions: []
    id: 652cec5666313ebb61cd82ec
    type: comment
  author: ashleykleynhans
  content: 'This seems to be an issue with the latest version of the oobabooga Text
    Generation Web UI.

    I was also unable to load the model using any of the model loaders.

    I noticed that Matthew Berman was able to successfully load the model using the
    **Transformers** model loader in [this YouTube video](https://www.youtube.com/watch?v=tK1Pivdcl3U).


    There have been a number of updates to oobabooga recently which have broken various
    different things in a spectacular fashion, so they clearly need to add some unit
    tests to the project.


    Until such time as oobabooga is in a working state again, this is the commit that
    is working for me:

    cb26163a209d6272ed14da83782f71bae4681d75'
  created_at: 2023-10-16 06:55:02+00:00
  edited: false
  hidden: false
  id: 652cec5666313ebb61cd82ec
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: cognitivecomputations/dolphin-2.0-mistral-7b
repo_type: model
status: open
target_branch: null
title: Can't load the model
