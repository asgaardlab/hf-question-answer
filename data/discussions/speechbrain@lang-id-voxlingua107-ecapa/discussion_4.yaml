!!python/object:huggingface_hub.community.DiscussionWithDetails
author: esurface
conflicting_files: null
created_at: 2023-02-13 15:48:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6290d2de7b735ef6986a5920290ba081.svg
      fullname: Erik Surface
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: esurface
      type: user
    createdAt: '2023-02-13T15:48:47.000Z'
    data:
      edited: false
      editors:
      - esurface
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6290d2de7b735ef6986a5920290ba081.svg
          fullname: Erik Surface
          isHf: false
          isPro: false
          name: esurface
          type: user
        html: '<p>Hey! I am looking for some advice. My goal is to reuse this model
          (or recipe) to produce language identification either diarized or per-utterance.
          Is there an easy way to configure this to produce those outputs? </p>

          <p>I set up the code and dug into the classification function: <code>language_id.classify_batch(signal)</code>.
          Seems  like it classifies the entire audio file through the NN model instead
          of looking at chunks. </p>

          <p>As a non-ML trained programmer, my instinct is to simply chunk the audio
          file into utterances and loop through passing them into <code>classify_batch</code>.
          Looking at the other models and code in Speechbrain, it looks like the more
          ML-friendly way to do this would be to update this recipe either by using
          parts of the Speechbrain''s <code>diarization.py</code> class or chunking
          from <code>ECAPA_TDNN.py</code> or the <code>VAD</code> recipe in Speechbrain.</p>

          <p>Am I on the right track or is this not how these things work?</p>

          <p>Much Appreciated!</p>

          '
        raw: "Hey! I am looking for some advice. My goal is to reuse this model (or\
          \ recipe) to produce language identification either diarized or per-utterance.\
          \ Is there an easy way to configure this to produce those outputs? \r\n\r\
          \nI set up the code and dug into the classification function: `language_id.classify_batch(signal)`.\
          \ Seems  like it classifies the entire audio file through the NN model instead\
          \ of looking at chunks. \r\n\r\nAs a non-ML trained programmer, my instinct\
          \ is to simply chunk the audio file into utterances and loop through passing\
          \ them into `classify_batch`. Looking at the other models and code in Speechbrain,\
          \ it looks like the more ML-friendly way to do this would be to update this\
          \ recipe either by using parts of the Speechbrain's `diarization.py` class\
          \ or chunking from `ECAPA_TDNN.py` or the `VAD` recipe in Speechbrain.\r\
          \n\r\nAm I on the right track or is this not how these things work?\r\n\r\
          \nMuch Appreciated!"
        updatedAt: '2023-02-13T15:48:47.652Z'
      numEdits: 0
      reactions: []
    id: 63ea5bdfe7f148f46015dcb7
    type: comment
  author: esurface
  content: "Hey! I am looking for some advice. My goal is to reuse this model (or\
    \ recipe) to produce language identification either diarized or per-utterance.\
    \ Is there an easy way to configure this to produce those outputs? \r\n\r\nI set\
    \ up the code and dug into the classification function: `language_id.classify_batch(signal)`.\
    \ Seems  like it classifies the entire audio file through the NN model instead\
    \ of looking at chunks. \r\n\r\nAs a non-ML trained programmer, my instinct is\
    \ to simply chunk the audio file into utterances and loop through passing them\
    \ into `classify_batch`. Looking at the other models and code in Speechbrain,\
    \ it looks like the more ML-friendly way to do this would be to update this recipe\
    \ either by using parts of the Speechbrain's `diarization.py` class or chunking\
    \ from `ECAPA_TDNN.py` or the `VAD` recipe in Speechbrain.\r\n\r\nAm I on the\
    \ right track or is this not how these things work?\r\n\r\nMuch Appreciated!"
  created_at: 2023-02-13 15:48:47+00:00
  edited: false
  hidden: false
  id: 63ea5bdfe7f148f46015dcb7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: speechbrain/lang-id-voxlingua107-ecapa
repo_type: model
status: open
target_branch: null
title: Recipe for Diarized/Utterance Language ID Model
