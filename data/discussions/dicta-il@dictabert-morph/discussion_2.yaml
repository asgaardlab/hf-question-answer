!!python/object:huggingface_hub.community.DiscussionWithDetails
author: msperka
conflicting_files: null
created_at: 2023-09-10 07:48:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8c5e073439b95ab1cf670aa08cd0bbfb.svg
      fullname: Menachem Sperka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: msperka
      type: user
    createdAt: '2023-09-10T08:48:45.000Z'
    data:
      edited: false
      editors:
      - msperka
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.49146804213523865
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8c5e073439b95ab1cf670aa08cd0bbfb.svg
          fullname: Menachem Sperka
          isHf: false
          isPro: false
          name: msperka
          type: user
        html: '<p>using the following code:</p>

          <p>''''''<br>tokenizer = AutoTokenizer.from_pretrained(''dicta-il/dictabert-morph'',
          cache_dir = r"F:\nlp_project\py\dictabert-morph")<br>    model = AutoModel.from_pretrained(''dicta-il/dictabert-morph'',  trust_remote_code=True,  cache_dir
          = r"F:\nlp_project\py\dictabert-morph")</p>

          <p>res = model.predict([txt], tokenizer)</p>

          <p>''''''</p>

          <p>the result only tokenizes and processes the first few tokens of the text
          </p>

          <p>cant attach here JSON or txt file so pasting full output in comments
          </p>

          '
        raw: "using the following code:\r\n\r\n'''\r\ntokenizer = AutoTokenizer.from_pretrained('dicta-il/dictabert-morph',\
          \ cache_dir = r\"F:\\nlp_project\\py\\dictabert-morph\")\r\n    model =\
          \ AutoModel.from_pretrained('dicta-il/dictabert-morph',  trust_remote_code=True,\
          \  cache_dir = r\"F:\\nlp_project\\py\\dictabert-morph\")\r\n\r\nres = model.predict([txt],\
          \ tokenizer)\r\n\r\n'''\r\n\r\nthe result only tokenizes and processes the\
          \ first few tokens of the text \r\n\r\ncant attach here JSON or txt file\
          \ so pasting full output in comments "
        updatedAt: '2023-09-10T08:48:45.446Z'
      numEdits: 0
      reactions: []
    id: 64fd82eddb183db86fdab234
    type: comment
  author: msperka
  content: "using the following code:\r\n\r\n'''\r\ntokenizer = AutoTokenizer.from_pretrained('dicta-il/dictabert-morph',\
    \ cache_dir = r\"F:\\nlp_project\\py\\dictabert-morph\")\r\n    model = AutoModel.from_pretrained('dicta-il/dictabert-morph',\
    \  trust_remote_code=True,  cache_dir = r\"F:\\nlp_project\\py\\dictabert-morph\"\
    )\r\n\r\nres = model.predict([txt], tokenizer)\r\n\r\n'''\r\n\r\nthe result only\
    \ tokenizes and processes the first few tokens of the text \r\n\r\ncant attach\
    \ here JSON or txt file so pasting full output in comments "
  created_at: 2023-09-10 07:48:45+00:00
  edited: false
  hidden: false
  id: 64fd82eddb183db86fdab234
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8c5e073439b95ab1cf670aa08cd0bbfb.svg
      fullname: Menachem Sperka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: msperka
      type: user
    createdAt: '2023-09-10T08:49:25.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/8c5e073439b95ab1cf670aa08cd0bbfb.svg
          fullname: Menachem Sperka
          isHf: false
          isPro: false
          name: msperka
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-11-05T16:07:26.506Z'
      numEdits: 0
      reactions: []
    id: 64fd831584bf01577e9aa08b
    type: comment
  author: msperka
  content: This comment has been hidden
  created_at: 2023-09-10 07:49:25+00:00
  edited: true
  hidden: true
  id: 64fd831584bf01577e9aa08b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/668dfce780e1681234f9116822592119.svg
      fullname: Shmidman
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Shaltiel
      type: user
    createdAt: '2023-09-10T10:04:30.000Z'
    data:
      edited: true
      editors:
      - Shaltiel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9386531710624695
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/668dfce780e1681234f9116822592119.svg
          fullname: Shmidman
          isHf: false
          isPro: false
          name: Shaltiel
          type: user
        html: '<p>The model <code>dictabert</code> was pretrained with a window of
          512 tokens, and when you input a longer sentence the <code>predict</code>
          function truncates it to the maximum length.<br>The model <code>dictabert-morph</code>
          was finetuned on sentence units (of lengths &lt;512). </p>

          <p>Therefore, the model can''t handle inputs of longer than 512 tokens and
          probably is not ideal for handling multiple concatenated sentences.</p>

          <p>I''d recommend splitting your input into a list of sentence units and
          then sending the list of sentences to the <code>predict</code> function.
          (note: sending multiple sentences will results in them being run through
          the model as a single batch, so if resources are limited it''s probably
          best to send them one at a time). </p>

          '
        raw: "The model `dictabert` was pretrained with a window of 512 tokens, and\
          \ when you input a longer sentence the `predict` function truncates it to\
          \ the maximum length. \nThe model `dictabert-morph` was finetuned on sentence\
          \ units (of lengths <512). \n\nTherefore, the model can't handle inputs\
          \ of longer than 512 tokens and probably is not ideal for handling multiple\
          \ concatenated sentences.\n\nI'd recommend splitting your input into a list\
          \ of sentence units and then sending the list of sentences to the `predict`\
          \ function. (note: sending multiple sentences will results in them being\
          \ run through the model as a single batch, so if resources are limited it's\
          \ probably best to send them one at a time). "
        updatedAt: '2023-09-10T10:05:01.285Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - msperka
    id: 64fd94aefa64465422adfe88
    type: comment
  author: Shaltiel
  content: "The model `dictabert` was pretrained with a window of 512 tokens, and\
    \ when you input a longer sentence the `predict` function truncates it to the\
    \ maximum length. \nThe model `dictabert-morph` was finetuned on sentence units\
    \ (of lengths <512). \n\nTherefore, the model can't handle inputs of longer than\
    \ 512 tokens and probably is not ideal for handling multiple concatenated sentences.\n\
    \nI'd recommend splitting your input into a list of sentence units and then sending\
    \ the list of sentences to the `predict` function. (note: sending multiple sentences\
    \ will results in them being run through the model as a single batch, so if resources\
    \ are limited it's probably best to send them one at a time). "
  created_at: 2023-09-10 09:04:30+00:00
  edited: true
  hidden: false
  id: 64fd94aefa64465422adfe88
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8c5e073439b95ab1cf670aa08cd0bbfb.svg
      fullname: Menachem Sperka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: msperka
      type: user
    createdAt: '2023-09-10T10:55:48.000Z'
    data:
      edited: false
      editors:
      - msperka
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6461685299873352
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8c5e073439b95ab1cf670aa08cd0bbfb.svg
          fullname: Menachem Sperka
          isHf: false
          isPro: false
          name: msperka
          type: user
        html: '<p>Thank you</p>

          '
        raw: Thank you
        updatedAt: '2023-09-10T10:55:48.416Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64fda0b499123d7698caf1fe
    id: 64fda0b499123d7698caf1fd
    type: comment
  author: msperka
  content: Thank you
  created_at: 2023-09-10 09:55:48+00:00
  edited: false
  hidden: false
  id: 64fda0b499123d7698caf1fd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/8c5e073439b95ab1cf670aa08cd0bbfb.svg
      fullname: Menachem Sperka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: msperka
      type: user
    createdAt: '2023-09-10T10:55:48.000Z'
    data:
      status: closed
    id: 64fda0b499123d7698caf1fe
    type: status-change
  author: msperka
  created_at: 2023-09-10 09:55:48+00:00
  id: 64fda0b499123d7698caf1fe
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: dicta-il/dictabert-morph
repo_type: model
status: closed
target_branch: null
title: 'any limit to the input text length? '
