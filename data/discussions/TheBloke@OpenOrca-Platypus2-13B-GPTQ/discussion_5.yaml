!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bikalnetomi
conflicting_files: null
created_at: 2023-09-06 20:05:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/214be746a5f6c72bed1faa584496c821.svg
      fullname: Bikal Basnet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bikalnetomi
      type: user
    createdAt: '2023-09-06T21:05:15.000Z'
    data:
      edited: true
      editors:
      - bikalnetomi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5288310647010803
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/214be746a5f6c72bed1faa584496c821.svg
          fullname: Bikal Basnet
          isHf: false
          isPro: false
          name: bikalnetomi
          type: user
        html: '<p>I am trying to run the model using the Text Generation Inference.
          Getting the following error. </p>

          <p>I used the Sagemaker Jumpstart code<br> Hub Model configuration. <a href="https://huggingface.co/models">https://huggingface.co/models</a><br>hub
          = {<br>    ''HF_MODEL_ID'':''TheBloke/OpenOrca-Platypus2-13B-GPTQ'',<br>    ''SM_NUM_GPUS'':
          json.dumps(1)<br>}</p>

          <h1 id="create-hugging-face-model-class">create Hugging Face Model Class</h1>

          <p>huggingface_model = HuggingFaceModel(<br>    image_uri=get_huggingface_llm_image_uri("huggingface",version="0.9.3"),<br>    env=hub,<br>    role=role,<br>)</p>

          <h1 id="deploy-model-to-sagemaker-inference">deploy model to SageMaker Inference</h1>

          <p>predictor = huggingface_model.deploy(<br>    initial_instance_count=1,<br>    instance_type="ml.g5.8xlarge",<br>    container_startup_health_check_timeout=300,<br>  )
          </p>

          <p>Any help to  resolve the  following error.</p>

          <blockquote>

          <p>File "/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py",
          line 142, in serve_inner<br>    model = get_model(<br>  File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/<strong>init</strong>.py",
          line 185, in get_model<br>    return FlashLlama(<br>  File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/flash_llama.py",
          line 65, in <strong>init</strong><br>    model = FlashLlamaForCausalLM(config,
          weights)<br>  File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 452, in <strong>init</strong><br>    self.model = FlashLlamaModel(config,
          weights)<br>  File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 390, in <strong>init</strong><br>    [<br>  File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 391, in <br>    FlashLlamaLayer(<br>  File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 326, in <strong>init</strong><br>    self.self_attn = FlashLlamaAttention(<br>  File
          "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 183, in <strong>init</strong><br>    self.rotary_emb = PositionRotaryEmbedding.load(<br>  File
          "/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/layers.py",
          line 395, in load<br>    inv_freq = weights.get_tensor(f"{prefix}.inv_freq")<br>  File
          "/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/weights.py",
          line 62, in get_tensor<br>    filename, tensor_name = self.get_filename(tensor_name)<br>  File
          "/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/weights.py",
          line 49, in get_filename<br>    raise RuntimeError(f"weight {tensor_name}
          does not exist")<br>RuntimeError: weight model.layers.0.self_attn.rotary_emb.inv_freq
          does not exist</p>

          </blockquote>

          '
        raw: "I am trying to run the model using the Text Generation Inference. Getting\
          \ the following error. \n\nI used the Sagemaker Jumpstart code \n Hub Model\
          \ configuration. https://huggingface.co/models\nhub = {\n\t'HF_MODEL_ID':'TheBloke/OpenOrca-Platypus2-13B-GPTQ',\n\
          \t'SM_NUM_GPUS': json.dumps(1)\n}\n\n\n\n# create Hugging Face Model Class\n\
          huggingface_model = HuggingFaceModel(\n\timage_uri=get_huggingface_llm_image_uri(\"\
          huggingface\",version=\"0.9.3\"),\n\tenv=hub,\n\trole=role, \n)\n\n# deploy\
          \ model to SageMaker Inference\npredictor = huggingface_model.deploy(\n\t\
          initial_instance_count=1,\n\tinstance_type=\"ml.g5.8xlarge\", \n\tcontainer_startup_health_check_timeout=300,\n\
          \  ) \n\nAny help to  resolve the  following error.\n\n> File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 142, in serve_inner\n    model = get_model(\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
          , line 185, in get_model\n    return FlashLlama(\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/flash_llama.py\"\
          , line 65, in __init__\n    model = FlashLlamaForCausalLM(config, weights)\n\
          \  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py\"\
          , line 452, in __init__\n    self.model = FlashLlamaModel(config, weights)\n\
          \  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py\"\
          , line 390, in __init__\n    [\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py\"\
          , line 391, in <listcomp>\n    FlashLlamaLayer(\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py\"\
          , line 326, in __init__\n    self.self_attn = FlashLlamaAttention(\n  File\
          \ \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py\"\
          , line 183, in __init__\n    self.rotary_emb = PositionRotaryEmbedding.load(\n\
          \  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/layers.py\"\
          , line 395, in load\n    inv_freq = weights.get_tensor(f\"{prefix}.inv_freq\"\
          )\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/weights.py\"\
          , line 62, in get_tensor\n    filename, tensor_name = self.get_filename(tensor_name)\n\
          \  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/weights.py\"\
          , line 49, in get_filename\n    raise RuntimeError(f\"weight {tensor_name}\
          \ does not exist\")\nRuntimeError: weight model.layers.0.self_attn.rotary_emb.inv_freq\
          \ does not exist"
        updatedAt: '2023-09-06T21:07:19.066Z'
      numEdits: 1
      reactions: []
    id: 64f8e98b6a71cea1c7002fe1
    type: comment
  author: bikalnetomi
  content: "I am trying to run the model using the Text Generation Inference. Getting\
    \ the following error. \n\nI used the Sagemaker Jumpstart code \n Hub Model configuration.\
    \ https://huggingface.co/models\nhub = {\n\t'HF_MODEL_ID':'TheBloke/OpenOrca-Platypus2-13B-GPTQ',\n\
    \t'SM_NUM_GPUS': json.dumps(1)\n}\n\n\n\n# create Hugging Face Model Class\nhuggingface_model\
    \ = HuggingFaceModel(\n\timage_uri=get_huggingface_llm_image_uri(\"huggingface\"\
    ,version=\"0.9.3\"),\n\tenv=hub,\n\trole=role, \n)\n\n# deploy model to SageMaker\
    \ Inference\npredictor = huggingface_model.deploy(\n\tinitial_instance_count=1,\n\
    \tinstance_type=\"ml.g5.8xlarge\", \n\tcontainer_startup_health_check_timeout=300,\n\
    \  ) \n\nAny help to  resolve the  following error.\n\n> File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
    , line 142, in serve_inner\n    model = get_model(\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
    , line 185, in get_model\n    return FlashLlama(\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/flash_llama.py\"\
    , line 65, in __init__\n    model = FlashLlamaForCausalLM(config, weights)\n \
    \ File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py\"\
    , line 452, in __init__\n    self.model = FlashLlamaModel(config, weights)\n \
    \ File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py\"\
    , line 390, in __init__\n    [\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py\"\
    , line 391, in <listcomp>\n    FlashLlamaLayer(\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py\"\
    , line 326, in __init__\n    self.self_attn = FlashLlamaAttention(\n  File \"\
    /opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py\"\
    , line 183, in __init__\n    self.rotary_emb = PositionRotaryEmbedding.load(\n\
    \  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/layers.py\"\
    , line 395, in load\n    inv_freq = weights.get_tensor(f\"{prefix}.inv_freq\"\
    )\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/weights.py\"\
    , line 62, in get_tensor\n    filename, tensor_name = self.get_filename(tensor_name)\n\
    \  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/weights.py\"\
    , line 49, in get_filename\n    raise RuntimeError(f\"weight {tensor_name} does\
    \ not exist\")\nRuntimeError: weight model.layers.0.self_attn.rotary_emb.inv_freq\
    \ does not exist"
  created_at: 2023-09-06 20:05:15+00:00
  edited: true
  hidden: false
  id: 64f8e98b6a71cea1c7002fe1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: TheBloke/OpenOrca-Platypus2-13B-GPTQ
repo_type: model
status: open
target_branch: null
title: 'Error running with Sagemaker Jumpstart + Text Generation Inference  : weight
  model.layers.0.self_attn.rotary_emb.inv_freq does not exist'
