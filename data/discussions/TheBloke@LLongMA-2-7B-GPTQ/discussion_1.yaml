!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rjmehta
conflicting_files: null
created_at: 2023-07-20 16:27:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
      fullname: Raj Mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rjmehta
      type: user
    createdAt: '2023-07-20T17:27:12.000Z'
    data:
      edited: false
      editors:
      - rjmehta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9269133806228638
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
          fullname: Raj Mehta
          isHf: false
          isPro: false
          name: rjmehta
          type: user
        html: '<p>Thanks, Bloke for getting the SuperHot 8K with Llama 2 out so quickly.
          Appreciate all the efforts.</p>

          '
        raw: Thanks, Bloke for getting the SuperHot 8K with Llama 2 out so quickly.
          Appreciate all the efforts.
        updatedAt: '2023-07-20T17:27:12.581Z'
      numEdits: 0
      reactions: []
    id: 64b96e70b7d190d775c81b97
    type: comment
  author: rjmehta
  content: Thanks, Bloke for getting the SuperHot 8K with Llama 2 out so quickly.
    Appreciate all the efforts.
  created_at: 2023-07-20 16:27:12+00:00
  edited: false
  hidden: false
  id: 64b96e70b7d190d775c81b97
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
      fullname: Raj Mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rjmehta
      type: user
    createdAt: '2023-07-20T17:27:41.000Z'
    data:
      edited: false
      editors:
      - rjmehta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.955794632434845
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
          fullname: Raj Mehta
          isHf: false
          isPro: false
          name: rjmehta
          type: user
        html: '<p>Waiting on you to upload the quantized file to this repo.</p>

          '
        raw: Waiting on you to upload the quantized file to this repo.
        updatedAt: '2023-07-20T17:27:41.887Z'
      numEdits: 0
      reactions: []
    id: 64b96e8d88d2d826747fb897
    type: comment
  author: rjmehta
  content: Waiting on you to upload the quantized file to this repo.
  created_at: 2023-07-20 16:27:41+00:00
  edited: false
  hidden: false
  id: 64b96e8d88d2d826747fb897
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-20T17:28:38.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9742557406425476
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>They''re coming. I''m running on a 1x GPU machine at the moment
          so the multiple quants have to be done one at a time, so it will be a few
          hours until they''re all here.  But the first quant should appear in main
          in about 10 minutes</p>

          '
        raw: They're coming. I'm running on a 1x GPU machine at the moment so the
          multiple quants have to be done one at a time, so it will be a few hours
          until they're all here.  But the first quant should appear in main in about
          10 minutes
        updatedAt: '2023-07-20T17:28:38.416Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Nurb432
    id: 64b96ec6857bcccfc9541693
    type: comment
  author: TheBloke
  content: They're coming. I'm running on a 1x GPU machine at the moment so the multiple
    quants have to be done one at a time, so it will be a few hours until they're
    all here.  But the first quant should appear in main in about 10 minutes
  created_at: 2023-07-20 16:28:38+00:00
  edited: false
  hidden: false
  id: 64b96ec6857bcccfc9541693
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
      fullname: Raj Mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rjmehta
      type: user
    createdAt: '2023-07-20T17:30:02.000Z'
    data:
      edited: false
      editors:
      - rjmehta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8168537020683289
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
          fullname: Raj Mehta
          isHf: false
          isPro: false
          name: rjmehta
          type: user
        html: '<p>Perfect. Thanks.</p>

          '
        raw: Perfect. Thanks.
        updatedAt: '2023-07-20T17:30:02.214Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64b96f1aea67d88ebec12ffb
    id: 64b96f1aea67d88ebec12ffa
    type: comment
  author: rjmehta
  content: Perfect. Thanks.
  created_at: 2023-07-20 16:30:02+00:00
  edited: false
  hidden: false
  id: 64b96f1aea67d88ebec12ffa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
      fullname: Raj Mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rjmehta
      type: user
    createdAt: '2023-07-20T17:30:02.000Z'
    data:
      status: closed
    id: 64b96f1aea67d88ebec12ffb
    type: status-change
  author: rjmehta
  created_at: 2023-07-20 16:30:02+00:00
  id: 64b96f1aea67d88ebec12ffb
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-07-20T20:16:58.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.872938871383667
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> While many dont\
          \ say it and only complain, ask questions or demand.... Many of us here\
          \ appreciate your work. </p>\n"
        raw: '@TheBloke While many dont say it and only complain, ask questions or
          demand.... Many of us here appreciate your work. '
        updatedAt: '2023-07-20T20:16:58.164Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - TheBloke
    id: 64b9963aad5725d2d3a37e9e
    type: comment
  author: Nurb432
  content: '@TheBloke While many dont say it and only complain, ask questions or demand....
    Many of us here appreciate your work. '
  created_at: 2023-07-20 19:16:58+00:00
  edited: false
  hidden: false
  id: 64b9963aad5725d2d3a37e9e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-20T20:56:35.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9836279153823853
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Sorry for the delay with GPTQs. Ran into lots of problems due to
          the 8k context length.  In the end I had to quantise them using 4K context
          length dataset.  Note: this doesn''t mean the models won''t work at 8K.
          It just means the quantisation samples were 4K.  The first one is uploaded
          now, second is processing</p>

          '
        raw: 'Sorry for the delay with GPTQs. Ran into lots of problems due to the
          8k context length.  In the end I had to quantise them using 4K context length
          dataset.  Note: this doesn''t mean the models won''t work at 8K. It just
          means the quantisation samples were 4K.  The first one is uploaded now,
          second is processing'
        updatedAt: '2023-07-20T20:56:35.820Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - rjmehta
    id: 64b99f830f381e26c3701f74
    type: comment
  author: TheBloke
  content: 'Sorry for the delay with GPTQs. Ran into lots of problems due to the 8k
    context length.  In the end I had to quantise them using 4K context length dataset.  Note:
    this doesn''t mean the models won''t work at 8K. It just means the quantisation
    samples were 4K.  The first one is uploaded now, second is processing'
  created_at: 2023-07-20 19:56:35+00:00
  edited: false
  hidden: false
  id: 64b99f830f381e26c3701f74
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
      fullname: Raj Mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rjmehta
      type: user
    createdAt: '2023-07-21T14:52:16.000Z'
    data:
      status: open
    id: 64ba9ba090dfdda6ab805400
    type: status-change
  author: rjmehta
  created_at: 2023-07-21 13:52:16+00:00
  id: 64ba9ba090dfdda6ab805400
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
      fullname: Raj Mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rjmehta
      type: user
    createdAt: '2023-07-21T14:57:39.000Z'
    data:
      edited: false
      editors:
      - rjmehta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8784069418907166
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
          fullname: Raj Mehta
          isHf: false
          isPro: false
          name: rjmehta
          type: user
        html: "<h2 id=\"hey-thebloke-a-quick-question-on-the-output-of-this-model-looks-like-the-model-is-hallucinating-quite-a-lot-i-used-this-prompt-and-the-answer-model-generated\"\
          >Hey <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span>, A quick question\
          \ on the output of this model. Looks like the model is hallucinating quite\
          \ a lot. I used this prompt. And the answer model generated.</h2>\n<p>How\
          \ much is the difference in the allocation between AIM Aerospace and Dunlop\
          \ Aircraft in the text below?</p>\n<p>{\"Dunlop Aircraft Tyres Limited \"\
          : {\"Total Fund \": \"-\", \"Your Allocation\": \"491,792\"}, \"Accurus\
          \ Aerospace Corporation \": {\"Total Fund \": \"-\", \"Your Allocation\"\
          : \"431,596\"}, \"Bromford Industries \": {\"Total Fund \": \"-\", \"Your\
          \ Allocation\": \"408,708\"}, \"AIM Aerospace Holdings, LLC \": {\"Total\
          \ Fund \": \"-\", \"Your Allocation\": \"163,483\"}, \"Working Capital \"\
          : {\"Total Fund \": \"-\", \"Your Allocation\": \"48,227\"}, \"Total Capital\
          \ Contribution due to Subsequent Closin \": {\"Total Fund \": \"-\", \"\
          Your Allocation\": \"1,543,806\"}, \"Investment in AIM Aerospace Holdings,\
          \ LLC \": {\"Total Fund \": \"30,447,144\", \"Your Allocation\": \"497,759\"\
          }, \"Total Capital Contributions \": {\"Total Fund \": \"30,447,144\", \"\
          Your Allocation\": \"497,759\"}, \"Extra Amount \": {\"Total Fund \": \"\
          -\", \"Your Allocation\": \"127,701\"}, \"Total Contribution Amount to be\
          \ Wired \": {\"Total Fund \": \"30,447,144\", \"Your Allocation\": \"2,169,266\"\
          }}</p>\n<p>Output -1 :<br>The above table shows that the total amount of\
          \ capital contribution by the investors was $ 30,447,144 (US$), but only\
          \ $ 2,169,266 (US$) were wired to the account of AIM Aerospace Holdings,\
          \ LLC. The remaining $ 28,277,878 (US) are still unpaid.<br>This means that\
          \ the investor's money has been used for other purposes than what they have\
          \ agreed upon with the company. This is a clear violation of the law.<br>What\
          \ happened next?<br>After receiving this information from me, Mr. Zhang\
          \ immediately contacted his lawyer who then sent an email to the CEO of\
          \ AIM Aerospace Holdings, LLC on August 1st, 2018. In this letter, he demanded\
          \ that all funds be returned within seven days or else legal action would\
          \ be taken against them.<br>However, instead of returning our money back\
          \ as promised, they started threatening us with legal actions if we did\
          \ not stop asking questions about where our money went! They even threatened\
          \ to sue us if we continued pursuing them legally!<br>We decided it was\
          \ time to take matters into our own hands so we filed a complaint with FINRA\
          \ (Financial Industry Regulatory Authority). We also hired attorney Michael\
          \ J. Kane who specializes in securities fraud cases like these ones involving\
          \ Ponzi schemes such as those run by Bernie Madoff or Allen Stanford etcetera...<br>How\
          \ can I get my money back?</p>\n<p>Output -2 :<br>I'm not sure if this is\
          \ a bug or I am doing something wrong but it seems that the amount of money\
          \ allocated to me is incorrect. </p>\n<hr>\n<p>But when I asked the same\
          \ question in Llama 2 7B - chat playground demo, it answers correctly.</p>\n\
          <p>Thank you for providing the text. I can see that the allocation for AIM\
          \ Aerospace is $163,483, and the allocation for Dunlop Aircraft is $491,792.<br>So,\
          \ the difference in allocation between AIM Aerospace and Dunlop Aircraft\
          \ is:<br>$491,792 - $163,483 = $328,309<br>I hope this helps! Let me know\
          \ if you have any other questions.</p>\n"
        raw: "Hey @TheBloke, A quick question on the output of this model. Looks like\
          \ the model is hallucinating quite a lot. I used this prompt. And the answer\
          \ model generated.\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\
          How much is the difference in the allocation between AIM Aerospace and Dunlop\
          \ Aircraft in the text below?\n\n{\"Dunlop Aircraft Tyres Limited \": {\"\
          Total Fund \": \"-\", \"Your Allocation\": \"491,792\"}, \"Accurus Aerospace\
          \ Corporation \": {\"Total Fund \": \"-\", \"Your Allocation\": \"431,596\"\
          }, \"Bromford Industries \": {\"Total Fund \": \"-\", \"Your Allocation\"\
          : \"408,708\"}, \"AIM Aerospace Holdings, LLC \": {\"Total Fund \": \"-\"\
          , \"Your Allocation\": \"163,483\"}, \"Working Capital \": {\"Total Fund\
          \ \": \"-\", \"Your Allocation\": \"48,227\"}, \"Total Capital Contribution\
          \ due to Subsequent Closin \": {\"Total Fund \": \"-\", \"Your Allocation\"\
          : \"1,543,806\"}, \"Investment in AIM Aerospace Holdings, LLC \": {\"Total\
          \ Fund \": \"30,447,144\", \"Your Allocation\": \"497,759\"}, \"Total Capital\
          \ Contributions \": {\"Total Fund \": \"30,447,144\", \"Your Allocation\"\
          : \"497,759\"}, \"Extra Amount \": {\"Total Fund \": \"-\", \"Your Allocation\"\
          : \"127,701\"}, \"Total Contribution Amount to be Wired \": {\"Total Fund\
          \ \": \"30,447,144\", \"Your Allocation\": \"2,169,266\"}}\n\nOutput -1\
          \ : \nThe above table shows that the total amount of capital contribution\
          \ by the investors was $ 30,447,144 (US$), but only $ 2,169,266 (US$) were\
          \ wired to the account of AIM Aerospace Holdings, LLC. The remaining $ 28,277,878\
          \ (US) are still unpaid.\nThis means that the investor's money has been\
          \ used for other purposes than what they have agreed upon with the company.\
          \ This is a clear violation of the law.\nWhat happened next?\nAfter receiving\
          \ this information from me, Mr. Zhang immediately contacted his lawyer who\
          \ then sent an email to the CEO of AIM Aerospace Holdings, LLC on August\
          \ 1st, 2018. In this letter, he demanded that all funds be returned within\
          \ seven days or else legal action would be taken against them.\nHowever,\
          \ instead of returning our money back as promised, they started threatening\
          \ us with legal actions if we did not stop asking questions about where\
          \ our money went! They even threatened to sue us if we continued pursuing\
          \ them legally!\nWe decided it was time to take matters into our own hands\
          \ so we filed a complaint with FINRA (Financial Industry Regulatory Authority).\
          \ We also hired attorney Michael J. Kane who specializes in securities fraud\
          \ cases like these ones involving Ponzi schemes such as those run by Bernie\
          \ Madoff or Allen Stanford etcetera...\nHow can I get my money back?\n\n\
          Output -2 :\nI'm not sure if this is a bug or I am doing something wrong\
          \ but it seems that the amount of money allocated to me is incorrect. \n\
          \n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\
          \nBut when I asked the same question in Llama 2 7B - chat playground demo,\
          \ it answers correctly.\n\nThank you for providing the text. I can see that\
          \ the allocation for AIM Aerospace is $163,483, and the allocation for Dunlop\
          \ Aircraft is $491,792.\nSo, the difference in allocation between AIM Aerospace\
          \ and Dunlop Aircraft is:\n$491,792 - $163,483 = $328,309\nI hope this helps!\
          \ Let me know if you have any other questions."
        updatedAt: '2023-07-21T14:57:39.604Z'
      numEdits: 0
      reactions: []
    id: 64ba9ce3710f5e54768be569
    type: comment
  author: rjmehta
  content: "Hey @TheBloke, A quick question on the output of this model. Looks like\
    \ the model is hallucinating quite a lot. I used this prompt. And the answer model\
    \ generated.\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\
    How much is the difference in the allocation between AIM Aerospace and Dunlop\
    \ Aircraft in the text below?\n\n{\"Dunlop Aircraft Tyres Limited \": {\"Total\
    \ Fund \": \"-\", \"Your Allocation\": \"491,792\"}, \"Accurus Aerospace Corporation\
    \ \": {\"Total Fund \": \"-\", \"Your Allocation\": \"431,596\"}, \"Bromford Industries\
    \ \": {\"Total Fund \": \"-\", \"Your Allocation\": \"408,708\"}, \"AIM Aerospace\
    \ Holdings, LLC \": {\"Total Fund \": \"-\", \"Your Allocation\": \"163,483\"\
    }, \"Working Capital \": {\"Total Fund \": \"-\", \"Your Allocation\": \"48,227\"\
    }, \"Total Capital Contribution due to Subsequent Closin \": {\"Total Fund \"\
    : \"-\", \"Your Allocation\": \"1,543,806\"}, \"Investment in AIM Aerospace Holdings,\
    \ LLC \": {\"Total Fund \": \"30,447,144\", \"Your Allocation\": \"497,759\"},\
    \ \"Total Capital Contributions \": {\"Total Fund \": \"30,447,144\", \"Your Allocation\"\
    : \"497,759\"}, \"Extra Amount \": {\"Total Fund \": \"-\", \"Your Allocation\"\
    : \"127,701\"}, \"Total Contribution Amount to be Wired \": {\"Total Fund \":\
    \ \"30,447,144\", \"Your Allocation\": \"2,169,266\"}}\n\nOutput -1 : \nThe above\
    \ table shows that the total amount of capital contribution by the investors was\
    \ $ 30,447,144 (US$), but only $ 2,169,266 (US$) were wired to the account of\
    \ AIM Aerospace Holdings, LLC. The remaining $ 28,277,878 (US) are still unpaid.\n\
    This means that the investor's money has been used for other purposes than what\
    \ they have agreed upon with the company. This is a clear violation of the law.\n\
    What happened next?\nAfter receiving this information from me, Mr. Zhang immediately\
    \ contacted his lawyer who then sent an email to the CEO of AIM Aerospace Holdings,\
    \ LLC on August 1st, 2018. In this letter, he demanded that all funds be returned\
    \ within seven days or else legal action would be taken against them.\nHowever,\
    \ instead of returning our money back as promised, they started threatening us\
    \ with legal actions if we did not stop asking questions about where our money\
    \ went! They even threatened to sue us if we continued pursuing them legally!\n\
    We decided it was time to take matters into our own hands so we filed a complaint\
    \ with FINRA (Financial Industry Regulatory Authority). We also hired attorney\
    \ Michael J. Kane who specializes in securities fraud cases like these ones involving\
    \ Ponzi schemes such as those run by Bernie Madoff or Allen Stanford etcetera...\n\
    How can I get my money back?\n\nOutput -2 :\nI'm not sure if this is a bug or\
    \ I am doing something wrong but it seems that the amount of money allocated to\
    \ me is incorrect. \n\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\
    \nBut when I asked the same question in Llama 2 7B - chat playground demo, it\
    \ answers correctly.\n\nThank you for providing the text. I can see that the allocation\
    \ for AIM Aerospace is $163,483, and the allocation for Dunlop Aircraft is $491,792.\n\
    So, the difference in allocation between AIM Aerospace and Dunlop Aircraft is:\n\
    $491,792 - $163,483 = $328,309\nI hope this helps! Let me know if you have any\
    \ other questions."
  created_at: 2023-07-21 13:57:39+00:00
  edited: false
  hidden: false
  id: 64ba9ce3710f5e54768be569
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-21T15:47:03.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9692001342773438
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Are you definitely comparing this to Llama 2 7B, and not Llama 2
          7B Chat?</p>

          <p>Because remember that this is not a fine tuned model, it''s a base model.
          It''s not expected to be good at answering questions or summarising text.  You
          can sometimes get questions answered, but it''s not been trained to do that
          so it''s very hit and miss. Especially with the small models like 7B.</p>

          '
        raw: 'Are you definitely comparing this to Llama 2 7B, and not Llama 2 7B
          Chat?


          Because remember that this is not a fine tuned model, it''s a base model.
          It''s not expected to be good at answering questions or summarising text.  You
          can sometimes get questions answered, but it''s not been trained to do that
          so it''s very hit and miss. Especially with the small models like 7B.'
        updatedAt: '2023-07-21T15:47:03.746Z'
      numEdits: 0
      reactions: []
    id: 64baa877c6e77d66f4519753
    type: comment
  author: TheBloke
  content: 'Are you definitely comparing this to Llama 2 7B, and not Llama 2 7B Chat?


    Because remember that this is not a fine tuned model, it''s a base model. It''s
    not expected to be good at answering questions or summarising text.  You can sometimes
    get questions answered, but it''s not been trained to do that so it''s very hit
    and miss. Especially with the small models like 7B.'
  created_at: 2023-07-21 14:47:03+00:00
  edited: false
  hidden: false
  id: 64baa877c6e77d66f4519753
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
      fullname: Raj Mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rjmehta
      type: user
    createdAt: '2023-07-21T17:21:17.000Z'
    data:
      edited: true
      editors:
      - rjmehta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9846370220184326
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
          fullname: Raj Mehta
          isHf: false
          isPro: false
          name: rjmehta
          type: user
        html: '<p>Ohh yes, I read it wrong. I was using Llama 7b - chat which must
          be fine-tuned. This is the base model. Make sense now. I will try the chat
          GPTQ model. I think the Llongma  chat GPTQ is still in the works. Will wait
          until that is quantized. </p>

          '
        raw: "Ohh yes, I read it wrong. I was using Llama 7b - chat which must be\
          \ fine-tuned. This is the base model. Make sense now. I will try the chat\
          \ GPTQ model. I think the Llongma  chat GPTQ is still in the works. Will\
          \ wait until that is quantized. \n"
        updatedAt: '2023-07-21T17:23:10.539Z'
      numEdits: 1
      reactions: []
    id: 64babe8d01f1983a862d07a0
    type: comment
  author: rjmehta
  content: "Ohh yes, I read it wrong. I was using Llama 7b - chat which must be fine-tuned.\
    \ This is the base model. Make sense now. I will try the chat GPTQ model. I think\
    \ the Llongma  chat GPTQ is still in the works. Will wait until that is quantized.\
    \ \n"
  created_at: 2023-07-21 16:21:17+00:00
  edited: true
  hidden: false
  id: 64babe8d01f1983a862d07a0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/LLongMA-2-7B-GPTQ
repo_type: model
status: open
target_branch: null
title: Long awaited! Finally out!
