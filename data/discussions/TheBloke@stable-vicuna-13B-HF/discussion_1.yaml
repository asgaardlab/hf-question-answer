!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Kernel
conflicting_files: null
created_at: 2023-04-29 04:10:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/624ae13993d46cf4a0928032/kaIXTCGMbkuxuT59p0NAO.jpeg?w=200&h=200&f=face
      fullname: Panic
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kernel
      type: user
    createdAt: '2023-04-29T05:10:25.000Z'
    data:
      edited: false
      editors:
      - Kernel
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/624ae13993d46cf4a0928032/kaIXTCGMbkuxuT59p0NAO.jpeg?w=200&h=200&f=face
          fullname: Panic
          isHf: false
          isPro: false
          name: Kernel
          type: user
        html: '<p>I tried to run the model on a A6000 GPU using official FastChat
          repo. I could not get a single coherent response, model throws a garbage
          and stats hallucinating. Any advise on how to run the model? </p>

          '
        raw: 'I tried to run the model on a A6000 GPU using official FastChat repo.
          I could not get a single coherent response, model throws a garbage and stats
          hallucinating. Any advise on how to run the model? '
        updatedAt: '2023-04-29T05:10:25.667Z'
      numEdits: 0
      reactions: []
    id: 644ca6c1a25a81b66a7e52c1
    type: comment
  author: Kernel
  content: 'I tried to run the model on a A6000 GPU using official FastChat repo.
    I could not get a single coherent response, model throws a garbage and stats hallucinating.
    Any advise on how to run the model? '
  created_at: 2023-04-29 04:10:25+00:00
  edited: false
  hidden: false
  id: 644ca6c1a25a81b66a7e52c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-29T07:25:28.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I forgot to put the prompt template in the README for this repo:</p>

          <pre><code>### Human: prompt goes here

          ### Assistant:

          </code></pre>

          <p>This model really needs the right template else it might return nothing,
          or not a good response.  Try again with the above</p>

          '
        raw: 'I forgot to put the prompt template in the README for this repo:


          ```

          ### Human: prompt goes here

          ### Assistant:

          ```


          This model really needs the right template else it might return nothing,
          or not a good response.  Try again with the above'
        updatedAt: '2023-04-29T07:25:36.702Z'
      numEdits: 1
      reactions: []
    id: 644cc668fa94e93b0eb9d8d9
    type: comment
  author: TheBloke
  content: 'I forgot to put the prompt template in the README for this repo:


    ```

    ### Human: prompt goes here

    ### Assistant:

    ```


    This model really needs the right template else it might return nothing, or not
    a good response.  Try again with the above'
  created_at: 2023-04-29 06:25:28+00:00
  edited: true
  hidden: false
  id: 644cc668fa94e93b0eb9d8d9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/096cf8b6cd70bf11ce2c13d4e2e14d6c.svg
      fullname: Jamon Terrell
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jamont
      type: user
    createdAt: '2023-04-30T18:14:41.000Z'
    data:
      edited: false
      editors:
      - jamont
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/096cf8b6cd70bf11ce2c13d4e2e14d6c.svg
          fullname: Jamon Terrell
          isHf: false
          isPro: false
          name: jamont
          type: user
        html: '<p>Even with the prompt, the answers are completely random for me as
          well.  I''m running it through text-generation-webui, if you think that
          might be making a difference.</p>

          '
        raw: Even with the prompt, the answers are completely random for me as well.  I'm
          running it through text-generation-webui, if you think that might be making
          a difference.
        updatedAt: '2023-04-30T18:14:41.864Z'
      numEdits: 0
      reactions: []
    id: 644eb011ddf20748b05c86ca
    type: comment
  author: jamont
  content: Even with the prompt, the answers are completely random for me as well.  I'm
    running it through text-generation-webui, if you think that might be making a
    difference.
  created_at: 2023-04-30 17:14:41+00:00
  edited: false
  hidden: false
  id: 644eb011ddf20748b05c86ca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/096cf8b6cd70bf11ce2c13d4e2e14d6c.svg
      fullname: Jamon Terrell
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jamont
      type: user
    createdAt: '2023-04-30T18:25:41.000Z'
    data:
      edited: false
      editors:
      - jamont
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/096cf8b6cd70bf11ce2c13d4e2e14d6c.svg
          fullname: Jamon Terrell
          isHf: false
          isPro: false
          name: jamont
          type: user
        html: '<p>I updated text-generation-webui to the latest version, set the model
          type to llama, and set it to load in 8bits, and now it''s working!  Sharing
          here in case others are having similar issues.</p>

          '
        raw: I updated text-generation-webui to the latest version, set the model
          type to llama, and set it to load in 8bits, and now it's working!  Sharing
          here in case others are having similar issues.
        updatedAt: '2023-04-30T18:25:41.424Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TheBloke
    id: 644eb2a5ddf20748b05cbb8c
    type: comment
  author: jamont
  content: I updated text-generation-webui to the latest version, set the model type
    to llama, and set it to load in 8bits, and now it's working!  Sharing here in
    case others are having similar issues.
  created_at: 2023-04-30 17:25:41+00:00
  edited: false
  hidden: false
  id: 644eb2a5ddf20748b05cbb8c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/stable-vicuna-13B-HF
repo_type: model
status: open
target_branch: null
title: Models answers incoherent.
