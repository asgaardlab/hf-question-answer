!!python/object:huggingface_hub.community.DiscussionWithDetails
author: 6san
conflicting_files: null
created_at: 2023-07-30 07:05:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e9953eed7426ce5ea7f8c580cfc62ddb.svg
      fullname: sanz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 6san
      type: user
    createdAt: '2023-07-30T08:05:26.000Z'
    data:
      edited: false
      editors:
      - 6san
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8813798427581787
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e9953eed7426ce5ea7f8c580cfc62ddb.svg
          fullname: sanz
          isHf: false
          isPro: false
          name: 6san
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64c60e3411354a0eca116607/DhmePMK7RDM_Oy4ROQSl-.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64c60e3411354a0eca116607/DhmePMK7RDM_Oy4ROQSl-.png"></a><br>Also
          tried your [stable-vicuna-13B-GPTQ] including both the MAIN and LATEST quantised
          models. Got similar results, except that the word repetition was higher.<br>Also
          verified that it''s not a WebUI display issue!</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64c60e3411354a0eca116607/xwphBj1yncIG8zNLBr8A7.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64c60e3411354a0eca116607/xwphBj1yncIG8zNLBr8A7.png"></a></p>

          <p>transformers=4.31.0<br>peft=0.5.0.dev0<br>cuda 11.8</p>

          <p>The text-generation-webui for the same environment, my own merged LLaMA-&gt;Alpaca
          model, is able to generate text properly.<br>Now it is no longer clear if
          there is something wrong with the model or if there is something I am doing
          that is causing this. Also after searching the web, tried various parameters
          in text-generation-webui that correspond to stable vicuna. But the results
          did not change.</p>

          <p>*As you can see in the screenshot above, the added_tokens.json for this
          model has "[PAD]": 32000<br>where the [PAD] part appears in the generated
          text with high frequency. I don''t know what the principle is.</p>

          '
        raw: "\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64c60e3411354a0eca116607/DhmePMK7RDM_Oy4ROQSl-.png)\r\
          \nAlso tried your [stable-vicuna-13B-GPTQ] including both the MAIN and LATEST\
          \ quantised models. Got similar results, except that the word repetition\
          \ was higher.\r\nAlso verified that it's not a WebUI display issue!\r\n\r\
          \n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64c60e3411354a0eca116607/xwphBj1yncIG8zNLBr8A7.png)\r\
          \n\r\ntransformers=4.31.0\r\npeft=0.5.0.dev0\r\ncuda 11.8\r\n\r\nThe text-generation-webui\
          \ for the same environment, my own merged LLaMA->Alpaca model, is able to\
          \ generate text properly.\r\nNow it is no longer clear if there is something\
          \ wrong with the model or if there is something I am doing that is causing\
          \ this. Also after searching the web, tried various parameters in text-generation-webui\
          \ that correspond to stable vicuna. But the results did not change.\r\n\r\
          \n*As you can see in the screenshot above, the added_tokens.json for this\
          \ model has \"[PAD]\": 32000\r\nwhere the [PAD] part appears in the generated\
          \ text with high frequency. I don't know what the principle is."
        updatedAt: '2023-07-30T08:05:26.650Z'
      numEdits: 0
      reactions: []
    id: 64c619c65e43ae1ab60f3aea
    type: comment
  author: 6san
  content: "\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64c60e3411354a0eca116607/DhmePMK7RDM_Oy4ROQSl-.png)\r\
    \nAlso tried your [stable-vicuna-13B-GPTQ] including both the MAIN and LATEST\
    \ quantised models. Got similar results, except that the word repetition was higher.\r\
    \nAlso verified that it's not a WebUI display issue!\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64c60e3411354a0eca116607/xwphBj1yncIG8zNLBr8A7.png)\r\
    \n\r\ntransformers=4.31.0\r\npeft=0.5.0.dev0\r\ncuda 11.8\r\n\r\nThe text-generation-webui\
    \ for the same environment, my own merged LLaMA->Alpaca model, is able to generate\
    \ text properly.\r\nNow it is no longer clear if there is something wrong with\
    \ the model or if there is something I am doing that is causing this. Also after\
    \ searching the web, tried various parameters in text-generation-webui that correspond\
    \ to stable vicuna. But the results did not change.\r\n\r\n*As you can see in\
    \ the screenshot above, the added_tokens.json for this model has \"[PAD]\": 32000\r\
    \nwhere the [PAD] part appears in the generated text with high frequency. I don't\
    \ know what the principle is."
  created_at: 2023-07-30 07:05:26+00:00
  edited: false
  hidden: false
  id: 64c619c65e43ae1ab60f3aea
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 14
repo_id: TheBloke/stable-vicuna-13B-HF
repo_type: model
status: open
target_branch: null
title: Using this model in text-generation-webui just results in a string of meaningless
  characters.
