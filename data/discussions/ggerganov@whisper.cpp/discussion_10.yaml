!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Maojung
conflicting_files: null
created_at: 2023-09-08 06:05:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/840e0e7cb06c18ac94a323b56c9d0f62.svg
      fullname: Hsu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Maojung
      type: user
    createdAt: '2023-09-08T07:05:31.000Z'
    data:
      edited: false
      editors:
      - Maojung
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8777451515197754
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/840e0e7cb06c18ac94a323b56c9d0f62.svg
          fullname: Hsu
          isHf: false
          isPro: false
          name: Maojung
          type: user
        html: '<p>Thanks for the .cpp version. It speeds up my transcoding by 2X to
          3X compared to the original OpenAI version. I found a Whisper v2 fine-tuned
          version for Chinese on <a href="https://huggingface.co/jonatasgrosman/whisper-large-zh-cv11">https://huggingface.co/jonatasgrosman/whisper-large-zh-cv11</a>,
          which can provide much better accuracy. After a little tweaking of the ggml
          conversion Python, I managed to get the new model without errors. However,
          the model does not work as expected at all. It generates garbage after all.
          If I switch back to the repository version, it works perfectly. There is
          no error message during my ggml conversion. I have no idea how to fix it.
          I can''t upload my .bin file here because it''s around 3GB. Please help.
          Here is my tweak of the conversion routine. </p>

          <p>Here are the specific changes I made:</p>

          <p>git clone <a rel="nofollow" href="https://github.com/openai/whisper">https://github.com/openai/whisper</a><br>git
          clone <a rel="nofollow" href="https://github.com/ggerganov/whisper.cpp">https://github.com/ggerganov/whisper.cpp</a></p>

          <h1 id="clone-hf-fine-tuned-model-this-is-just-an-example">clone HF fine-tuned
          model (this is just an example)</h1>

          <p>git clone <a rel="nofollow" href="mailto:git@hf.co">git@hf.co</a>:jonatasgrosman/whisper-large-zh-cv11</p>

          <h1 id="convert-the-model-to-ggml">convert the model to ggml</h1>

          <p>python ./whisper.cpp/models/convert-h5-to-ggml.py ./whisper-large-zh-cv11/
          ./whisper .</p>

          '
        raw: "Thanks for the .cpp version. It speeds up my transcoding by 2X to 3X\
          \ compared to the original OpenAI version. I found a Whisper v2 fine-tuned\
          \ version for Chinese on https://huggingface.co/jonatasgrosman/whisper-large-zh-cv11,\
          \ which can provide much better accuracy. After a little tweaking of the\
          \ ggml conversion Python, I managed to get the new model without errors.\
          \ However, the model does not work as expected at all. It generates garbage\
          \ after all. If I switch back to the repository version, it works perfectly.\
          \ There is no error message during my ggml conversion. I have no idea how\
          \ to fix it. I can't upload my .bin file here because it's around 3GB. Please\
          \ help. Here is my tweak of the conversion routine. \r\n\r\nHere are the\
          \ specific changes I made:\r\n\r\ngit clone https://github.com/openai/whisper\r\
          \ngit clone https://github.com/ggerganov/whisper.cpp\r\n\r\n# clone HF fine-tuned\
          \ model (this is just an example)\r\ngit clone git@hf.co:jonatasgrosman/whisper-large-zh-cv11\r\
          \n\r\n# convert the model to ggml\r\npython ./whisper.cpp/models/convert-h5-to-ggml.py\
          \ ./whisper-large-zh-cv11/ ./whisper ."
        updatedAt: '2023-09-08T07:05:31.620Z'
      numEdits: 0
      reactions: []
    id: 64fac7bb48411fc7896297e9
    type: comment
  author: Maojung
  content: "Thanks for the .cpp version. It speeds up my transcoding by 2X to 3X compared\
    \ to the original OpenAI version. I found a Whisper v2 fine-tuned version for\
    \ Chinese on https://huggingface.co/jonatasgrosman/whisper-large-zh-cv11, which\
    \ can provide much better accuracy. After a little tweaking of the ggml conversion\
    \ Python, I managed to get the new model without errors. However, the model does\
    \ not work as expected at all. It generates garbage after all. If I switch back\
    \ to the repository version, it works perfectly. There is no error message during\
    \ my ggml conversion. I have no idea how to fix it. I can't upload my .bin file\
    \ here because it's around 3GB. Please help. Here is my tweak of the conversion\
    \ routine. \r\n\r\nHere are the specific changes I made:\r\n\r\ngit clone https://github.com/openai/whisper\r\
    \ngit clone https://github.com/ggerganov/whisper.cpp\r\n\r\n# clone HF fine-tuned\
    \ model (this is just an example)\r\ngit clone git@hf.co:jonatasgrosman/whisper-large-zh-cv11\r\
    \n\r\n# convert the model to ggml\r\npython ./whisper.cpp/models/convert-h5-to-ggml.py\
    \ ./whisper-large-zh-cv11/ ./whisper ."
  created_at: 2023-09-08 06:05:31+00:00
  edited: false
  hidden: false
  id: 64fac7bb48411fc7896297e9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/840e0e7cb06c18ac94a323b56c9d0f62.svg
      fullname: Hsu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Maojung
      type: user
    createdAt: '2023-09-08T10:32:07.000Z'
    data:
      edited: false
      editors:
      - Maojung
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8699867725372314
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/840e0e7cb06c18ac94a323b56c9d0f62.svg
          fullname: Hsu
          isHf: false
          isPro: false
          name: Maojung
          type: user
        html: '<p>The pytorch_model.bin file in <a href="https://huggingface.co/jonatasgrosman/whisper-large-zh-cv11">https://huggingface.co/jonatasgrosman/whisper-large-zh-cv11</a>
          is 6.17 GB, which is almost double the size of the ggml version in <a rel="nofollow"
          href="https://github.com/ggerganov/whisper.cpp">https://github.com/ggerganov/whisper.cpp</a>.
          Could this be because of the quantization of bits? I am just curious.</p>

          '
        raw: The pytorch_model.bin file in https://huggingface.co/jonatasgrosman/whisper-large-zh-cv11
          is 6.17 GB, which is almost double the size of the ggml version in https://github.com/ggerganov/whisper.cpp.
          Could this be because of the quantization of bits? I am just curious.
        updatedAt: '2023-09-08T10:32:07.485Z'
      numEdits: 0
      reactions: []
    id: 64faf82748411fc78969de4c
    type: comment
  author: Maojung
  content: The pytorch_model.bin file in https://huggingface.co/jonatasgrosman/whisper-large-zh-cv11
    is 6.17 GB, which is almost double the size of the ggml version in https://github.com/ggerganov/whisper.cpp.
    Could this be because of the quantization of bits? I am just curious.
  created_at: 2023-09-08 09:32:07+00:00
  edited: false
  hidden: false
  id: 64faf82748411fc78969de4c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: ggerganov/whisper.cpp
repo_type: model
status: open
target_branch: null
title: My conversion of a fine-tuned Whisper model to GGML failed
