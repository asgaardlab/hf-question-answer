!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MaziyarPanahi
conflicting_files: null
created_at: 2024-01-17 20:38:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5fd5e18a90b6dc4633f6d292/gZXHW5dd9R86AV9LMZ--y.png?w=200&h=200&f=face
      fullname: Maziyar Panahi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MaziyarPanahi
      type: user
    createdAt: '2024-01-17T20:38:03.000Z'
    data:
      edited: false
      editors:
      - MaziyarPanahi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9529537558555603
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5fd5e18a90b6dc4633f6d292/gZXHW5dd9R86AV9LMZ--y.png?w=200&h=200&f=face
          fullname: Maziyar Panahi
          isHf: false
          isPro: false
          name: MaziyarPanahi
          type: user
        html: '<p>Thanks for sharing this model with the community! </p>

          <p>What is the maximum input length? If it''s based on Llama-2 it should
          be 4096 unless some scaling happened during the fine-tuning. Would you mine
          sharing the max context length this model can support? (looking at the config,
          it seems 8192 or more)</p>

          <p>Many thanks</p>

          '
        raw: "Thanks for sharing this model with the community! \r\n\r\nWhat is the\
          \ maximum input length? If it's based on Llama-2 it should be 4096 unless\
          \ some scaling happened during the fine-tuning. Would you mine sharing the\
          \ max context length this model can support? (looking at the config, it\
          \ seems 8192 or more)\r\n\r\nMany thanks"
        updatedAt: '2024-01-17T20:38:03.990Z'
      numEdits: 0
      reactions: []
    id: 65a83aabb33c64c60e8b52ae
    type: comment
  author: MaziyarPanahi
  content: "Thanks for sharing this model with the community! \r\n\r\nWhat is the\
    \ maximum input length? If it's based on Llama-2 it should be 4096 unless some\
    \ scaling happened during the fine-tuning. Would you mine sharing the max context\
    \ length this model can support? (looking at the config, it seems 8192 or more)\r\
    \n\r\nMany thanks"
  created_at: 2024-01-17 20:38:03+00:00
  edited: false
  hidden: false
  id: 65a83aabb33c64c60e8b52ae
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0cdc05d0f7ed0015c5c425a1d392d9f.svg
      fullname: xldistance
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xldistance
      type: user
    createdAt: '2024-01-18T01:04:44.000Z'
    data:
      edited: false
      editors:
      - xldistance
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8021681308746338
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0cdc05d0f7ed0015c5c425a1d392d9f.svg
          fullname: xldistance
          isHf: false
          isPro: false
          name: xldistance
          type: user
        html: '<p>Maximum contextual dialog is 32K</p>

          '
        raw: Maximum contextual dialog is 32K
        updatedAt: '2024-01-18T01:04:44.246Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - MaziyarPanahi
    id: 65a8792c0237119dc502826a
    type: comment
  author: xldistance
  content: Maximum contextual dialog is 32K
  created_at: 2024-01-18 01:04:44+00:00
  edited: false
  hidden: false
  id: 65a8792c0237119dc502826a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5fd5e18a90b6dc4633f6d292/gZXHW5dd9R86AV9LMZ--y.png?w=200&h=200&f=face
      fullname: Maziyar Panahi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MaziyarPanahi
      type: user
    createdAt: '2024-01-18T10:10:03.000Z'
    data:
      edited: false
      editors:
      - MaziyarPanahi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9906075596809387
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5fd5e18a90b6dc4633f6d292/gZXHW5dd9R86AV9LMZ--y.png?w=200&h=200&f=face
          fullname: Maziyar Panahi
          isHf: false
          isPro: false
          name: MaziyarPanahi
          type: user
        html: '<p>many thanks!</p>

          '
        raw: many thanks!
        updatedAt: '2024-01-18T10:10:03.027Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65a8f8fbbdfe6bc8fdc5dce8
    id: 65a8f8fbbdfe6bc8fdc5dce2
    type: comment
  author: MaziyarPanahi
  content: many thanks!
  created_at: 2024-01-18 10:10:03+00:00
  edited: false
  hidden: false
  id: 65a8f8fbbdfe6bc8fdc5dce2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5fd5e18a90b6dc4633f6d292/gZXHW5dd9R86AV9LMZ--y.png?w=200&h=200&f=face
      fullname: Maziyar Panahi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MaziyarPanahi
      type: user
    createdAt: '2024-01-18T10:10:03.000Z'
    data:
      status: closed
    id: 65a8f8fbbdfe6bc8fdc5dce8
    type: status-change
  author: MaziyarPanahi
  created_at: 2024-01-18 10:10:03+00:00
  id: 65a8f8fbbdfe6bc8fdc5dce8
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: moreh/MoMo-72B-lora-1.8.6-DPO
repo_type: model
status: closed
target_branch: null
title: maximum context length
