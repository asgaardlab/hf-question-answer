!!python/object:huggingface_hub.community.DiscussionWithDetails
author: keminglu
conflicting_files: null
created_at: 2024-01-18 11:29:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e8c9025ef24cec958c87a1008bb54fd7.svg
      fullname: Keming Lu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: keminglu
      type: user
    createdAt: '2024-01-18T11:29:02.000Z'
    data:
      edited: false
      editors:
      - keminglu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9538245797157288
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e8c9025ef24cec958c87a1008bb54fd7.svg
          fullname: Keming Lu
          isHf: false
          isPro: false
          name: keminglu
          type: user
        html: '<p>Great works! it looks like Qwen-72B is a very strong base model.
          Could you kindly share how you reassign the weights for leaderboard submission?</p>

          '
        raw: Great works! it looks like Qwen-72B is a very strong base model. Could
          you kindly share how you reassign the weights for leaderboard submission?
        updatedAt: '2024-01-18T11:29:02.601Z'
      numEdits: 0
      reactions: []
    id: 65a90b7e9bd7d5189de9ad85
    type: comment
  author: keminglu
  content: Great works! it looks like Qwen-72B is a very strong base model. Could
    you kindly share how you reassign the weights for leaderboard submission?
  created_at: 2024-01-18 11:29:02+00:00
  edited: false
  hidden: false
  id: 65a90b7e9bd7d5189de9ad85
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c61ec65cb0cf142506b042135be408b5.svg
      fullname: leejunhyeok
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: leejunhyeok
      type: user
    createdAt: '2024-01-19T07:05:54.000Z'
    data:
      edited: false
      editors:
      - leejunhyeok
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8300642967224121
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c61ec65cb0cf142506b042135be408b5.svg
          fullname: leejunhyeok
          isHf: false
          isPro: false
          name: leejunhyeok
          type: user
        html: '<p>hi. we are happy to share how we converted qwen weight to llama<br>please
          refer to <a rel="nofollow" href="https://drive.google.com/drive/folders/15by5pCBf431rg44urVnoJw7TuFkgTkWD?usp=sharing">link</a></p>

          <ul>

          <li>./llamafy_resource folder in script contains tokenizer and target configuration
          file for llama. <ul>

          <li>place tokenizer of this repository(moreh/MoMo-70B-lora-1.8.6-DPO), and
          config_llama.json file to the folder</li>

          </ul>

          </li>

          <li>run by <code>python llamafy_qwen.py</code></li>

          <li>in input path, we expect directory of lora weight files.</li>

          </ul>

          <p>this script is highly experimental, and cannot assure 100% functionality
          for every settings of qwen weights.<br>if you have other questions, feel
          free to ask</p>

          '
        raw: "hi. we are happy to share how we converted qwen weight to llama\nplease\
          \ refer to [link](https://drive.google.com/drive/folders/15by5pCBf431rg44urVnoJw7TuFkgTkWD?usp=sharing)\n\
          - ./llamafy_resource folder in script contains tokenizer and target configuration\
          \ file for llama. \n    - place tokenizer of this repository(moreh/MoMo-70B-lora-1.8.6-DPO),\
          \ and config_llama.json file to the folder\n- run by ```python llamafy_qwen.py```\n\
          - in input path, we expect directory of lora weight files. \n\nthis script\
          \ is highly experimental, and cannot assure 100% functionality for every\
          \ settings of qwen weights.  \nif you have other questions, feel free to\
          \ ask"
        updatedAt: '2024-01-19T07:05:54.309Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - MaziyarPanahi
    id: 65aa1f52ad7763e1d36b834f
    type: comment
  author: leejunhyeok
  content: "hi. we are happy to share how we converted qwen weight to llama\nplease\
    \ refer to [link](https://drive.google.com/drive/folders/15by5pCBf431rg44urVnoJw7TuFkgTkWD?usp=sharing)\n\
    - ./llamafy_resource folder in script contains tokenizer and target configuration\
    \ file for llama. \n    - place tokenizer of this repository(moreh/MoMo-70B-lora-1.8.6-DPO),\
    \ and config_llama.json file to the folder\n- run by ```python llamafy_qwen.py```\n\
    - in input path, we expect directory of lora weight files. \n\nthis script is\
    \ highly experimental, and cannot assure 100% functionality for every settings\
    \ of qwen weights.  \nif you have other questions, feel free to ask"
  created_at: 2024-01-19 07:05:54+00:00
  edited: false
  hidden: false
  id: 65aa1f52ad7763e1d36b834f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c61ec65cb0cf142506b042135be408b5.svg
      fullname: leejunhyeok
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: leejunhyeok
      type: user
    createdAt: '2024-01-22T04:34:41.000Z'
    data:
      edited: false
      editors:
      - leejunhyeok
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9556829929351807
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c61ec65cb0cf142506b042135be408b5.svg
          fullname: leejunhyeok
          isHf: false
          isPro: false
          name: leejunhyeok
          type: user
        html: '<p>if you have further questions, feel free to re-open this discussion</p>

          '
        raw: if you have further questions, feel free to re-open this discussion
        updatedAt: '2024-01-22T04:34:41.548Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65adf0610b2bfdf81fcfa455
    id: 65adf0610b2bfdf81fcfa451
    type: comment
  author: leejunhyeok
  content: if you have further questions, feel free to re-open this discussion
  created_at: 2024-01-22 04:34:41+00:00
  edited: false
  hidden: false
  id: 65adf0610b2bfdf81fcfa451
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/c61ec65cb0cf142506b042135be408b5.svg
      fullname: leejunhyeok
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: leejunhyeok
      type: user
    createdAt: '2024-01-22T04:34:41.000Z'
    data:
      status: closed
    id: 65adf0610b2bfdf81fcfa455
    type: status-change
  author: leejunhyeok
  created_at: 2024-01-22 04:34:41+00:00
  id: 65adf0610b2bfdf81fcfa455
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: moreh/MoMo-72B-lora-1.8.6-DPO
repo_type: model
status: closed
target_branch: null
title: Qwen compabilitiy
