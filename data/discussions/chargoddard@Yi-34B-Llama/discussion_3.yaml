!!python/object:huggingface_hub.community.DiscussionWithDetails
author: KnutJaegersberg
conflicting_files: null
created_at: 2023-11-08 07:11:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-08T07:11:17.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9947009682655334
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>I played with your model a bit but I have not been able to quantize
          a fine tune based on it with awq, gptq, gguf. </p>

          '
        raw: 'I played with your model a bit but I have not been able to quantize
          a fine tune based on it with awq, gptq, gguf. '
        updatedAt: '2023-11-08T07:11:17.681Z'
      numEdits: 0
      reactions: []
    id: 654b3495f8ebcec54531ea4e
    type: comment
  author: KnutJaegersberg
  content: 'I played with your model a bit but I have not been able to quantize a
    fine tune based on it with awq, gptq, gguf. '
  created_at: 2023-11-08 07:11:17+00:00
  edited: false
  hidden: false
  id: 654b3495f8ebcec54531ea4e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9d8683646248f2e3856c4b396945d440.svg
      fullname: Anon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lmg-anon
      type: user
    createdAt: '2023-11-08T17:01:58.000Z'
    data:
      edited: false
      editors:
      - lmg-anon
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.996127188205719
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9d8683646248f2e3856c4b396945d440.svg
          fullname: Anon
          isHf: false
          isPro: false
          name: lmg-anon
          type: user
        html: '<p>What was the problem you got? I managed to quantize a gguf just
          fine with it.</p>

          '
        raw: What was the problem you got? I managed to quantize a gguf just fine
          with it.
        updatedAt: '2023-11-08T17:01:58.754Z'
      numEdits: 0
      reactions: []
    id: 654bbf0617d83697c73df6b2
    type: comment
  author: lmg-anon
  content: What was the problem you got? I managed to quantize a gguf just fine with
    it.
  created_at: 2023-11-08 17:01:58+00:00
  edited: false
  hidden: false
  id: 654bbf0617d83697c73df6b2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-08T19:44:10.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9574434161186218
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>Hmm... I fine tuned a model, merged that and tried to quantize that.<br>For
          awq / gptq it added an lm.head or something weight layer.<br>The output
          of the quantized model was rubbish.<br>I could not even make the 16fp model
          file for gguf, it failed at the first step also because it seemed to not
          get some layers or something...<br>Have you tried that with a qlora fine
          tune?<br>You can also try mine:<br><a href="https://huggingface.co/KnutJaegersberg/Deacon-34B-qlora">https://huggingface.co/KnutJaegersberg/Deacon-34B-qlora</a></p>

          <p>It''s a great model, generating good output. </p>

          '
        raw: "Hmm... I fine tuned a model, merged that and tried to quantize that.\
          \ \nFor awq / gptq it added an lm.head or something weight layer. \nThe\
          \ output of the quantized model was rubbish. \nI could not even make the\
          \ 16fp model file for gguf, it failed at the first step also because it\
          \ seemed to not get some layers or something... \nHave you tried that with\
          \ a qlora fine tune? \nYou can also try mine: \nhttps://huggingface.co/KnutJaegersberg/Deacon-34B-qlora\n\
          \nIt's a great model, generating good output. "
        updatedAt: '2023-11-08T19:44:10.476Z'
      numEdits: 0
      reactions: []
    id: 654be50ae06d25def57e5b05
    type: comment
  author: KnutJaegersberg
  content: "Hmm... I fine tuned a model, merged that and tried to quantize that. \n\
    For awq / gptq it added an lm.head or something weight layer. \nThe output of\
    \ the quantized model was rubbish. \nI could not even make the 16fp model file\
    \ for gguf, it failed at the first step also because it seemed to not get some\
    \ layers or something... \nHave you tried that with a qlora fine tune? \nYou can\
    \ also try mine: \nhttps://huggingface.co/KnutJaegersberg/Deacon-34B-qlora\n\n\
    It's a great model, generating good output. "
  created_at: 2023-11-08 19:44:10+00:00
  edited: false
  hidden: false
  id: 654be50ae06d25def57e5b05
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9d8683646248f2e3856c4b396945d440.svg
      fullname: Anon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lmg-anon
      type: user
    createdAt: '2023-11-09T15:50:31.000Z'
    data:
      edited: false
      editors:
      - lmg-anon
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8029277324676514
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9d8683646248f2e3856c4b396945d440.svg
          fullname: Anon
          isHf: false
          isPro: false
          name: lmg-anon
          type: user
        html: '<blockquote>

          <p>Have you tried that with a qlora fine tune?</p>

          </blockquote>

          <p>The one I used was: <a href="https://huggingface.co/Doctor-Shotgun/limarpv3-yi-llama-34b-lora">https://huggingface.co/Doctor-Shotgun/limarpv3-yi-llama-34b-lora</a></p>

          <blockquote>

          <p><a href="https://huggingface.co/KnutJaegersberg/Deacon-34B-qlora">https://huggingface.co/KnutJaegersberg/Deacon-34B-qlora</a></p>

          </blockquote>

          <p>The merge script failed to merge your qlora, probably because I tried
          to merge it with "chargoddard/Yi-34B-Llama" but your qlora seems to use
          "KnutJaegersberg/Yi-34B-Llamafied".</p>

          '
        raw: '>Have you tried that with a qlora fine tune?


          The one I used was: https://huggingface.co/Doctor-Shotgun/limarpv3-yi-llama-34b-lora


          >https://huggingface.co/KnutJaegersberg/Deacon-34B-qlora


          The merge script failed to merge your qlora, probably because I tried to
          merge it with "chargoddard/Yi-34B-Llama" but your qlora seems to use "KnutJaegersberg/Yi-34B-Llamafied".

          '
        updatedAt: '2023-11-09T15:50:31.538Z'
      numEdits: 0
      reactions: []
    id: 654cffc741f0552f517eb495
    type: comment
  author: lmg-anon
  content: '>Have you tried that with a qlora fine tune?


    The one I used was: https://huggingface.co/Doctor-Shotgun/limarpv3-yi-llama-34b-lora


    >https://huggingface.co/KnutJaegersberg/Deacon-34B-qlora


    The merge script failed to merge your qlora, probably because I tried to merge
    it with "chargoddard/Yi-34B-Llama" but your qlora seems to use "KnutJaegersberg/Yi-34B-Llamafied".

    '
  created_at: 2023-11-09 15:50:31+00:00
  edited: false
  hidden: false
  id: 654cffc741f0552f517eb495
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-09T17:02:05.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9924124479293823
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>yes, I made it refer to that one. I fine tuned the model with autotrain,
          with merge adapter argument. but then a separate adapter still came out
          of it.<br>Locally I tried it with your model, or at least the adapter config
          referred to it, that worked. For consistency I refer to the files that came
          out of it. That worked locally, too.<br>I also merged it manually afterwards,
          I think with your original model, merging worked. I tried to quantize that,
          that didn''t work (well enough). </p>

          '
        raw: "yes, I made it refer to that one. I fine tuned the model with autotrain,\
          \ with merge adapter argument. but then a separate adapter still came out\
          \ of it. \nLocally I tried it with your model, or at least the adapter config\
          \ referred to it, that worked. For consistency I refer to the files that\
          \ came out of it. That worked locally, too.  \nI also merged it manually\
          \ afterwards, I think with your original model, merging worked. I tried\
          \ to quantize that, that didn't work (well enough). "
        updatedAt: '2023-11-09T17:02:05.073Z'
      numEdits: 0
      reactions: []
    id: 654d108dc06b695e130d1af4
    type: comment
  author: KnutJaegersberg
  content: "yes, I made it refer to that one. I fine tuned the model with autotrain,\
    \ with merge adapter argument. but then a separate adapter still came out of it.\
    \ \nLocally I tried it with your model, or at least the adapter config referred\
    \ to it, that worked. For consistency I refer to the files that came out of it.\
    \ That worked locally, too.  \nI also merged it manually afterwards, I think with\
    \ your original model, merging worked. I tried to quantize that, that didn't work\
    \ (well enough). "
  created_at: 2023-11-09 17:02:05+00:00
  edited: false
  hidden: false
  id: 654d108dc06b695e130d1af4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-09T17:02:47.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9931217432022095
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>I''m still fairly new to fine tuning. </p>

          '
        raw: 'I''m still fairly new to fine tuning. '
        updatedAt: '2023-11-09T17:02:47.434Z'
      numEdits: 0
      reactions: []
    id: 654d10b7956e2f124cc37c1c
    type: comment
  author: KnutJaegersberg
  content: 'I''m still fairly new to fine tuning. '
  created_at: 2023-11-09 17:02:47+00:00
  edited: false
  hidden: false
  id: 654d10b7956e2f124cc37c1c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-09T18:06:36.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.959107518196106
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>Perhaps the llamafied repo of mine is already the merged model...
          I did this earlier, manually removing the adapter, but for this model, my
          interactions in textgen webui gave me the feeling it needed it. </p>

          '
        raw: 'Perhaps the llamafied repo of mine is already the merged model... I
          did this earlier, manually removing the adapter, but for this model, my
          interactions in textgen webui gave me the feeling it needed it. '
        updatedAt: '2023-11-09T18:06:36.580Z'
      numEdits: 0
      reactions: []
    id: 654d1fac71a30c4bcafa9d57
    type: comment
  author: KnutJaegersberg
  content: 'Perhaps the llamafied repo of mine is already the merged model... I did
    this earlier, manually removing the adapter, but for this model, my interactions
    in textgen webui gave me the feeling it needed it. '
  created_at: 2023-11-09 18:06:36+00:00
  edited: false
  hidden: false
  id: 654d1fac71a30c4bcafa9d57
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-09T18:07:08.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8998770117759705
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>it''s bloody edge tech and beginners luck :) </p>

          '
        raw: 'it''s bloody edge tech and beginners luck :) '
        updatedAt: '2023-11-09T18:07:08.241Z'
      numEdits: 0
      reactions: []
    id: 654d1fccf5297ada0b84256c
    type: comment
  author: KnutJaegersberg
  content: 'it''s bloody edge tech and beginners luck :) '
  created_at: 2023-11-09 18:07:08+00:00
  edited: false
  hidden: false
  id: 654d1fccf5297ada0b84256c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: chargoddard/Yi-34B-Llama
repo_type: model
status: open
target_branch: null
title: Does quantization work?
