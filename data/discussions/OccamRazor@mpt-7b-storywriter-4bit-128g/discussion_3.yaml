!!python/object:huggingface_hub.community.DiscussionWithDetails
author: PabloTerres
conflicting_files: null
created_at: 2023-05-08 05:54:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/33645d3caee104f410f199a38a90f844.svg
      fullname: PabloTerres
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: PabloTerres
      type: user
    createdAt: '2023-05-08T06:54:45.000Z'
    data:
      edited: false
      editors:
      - PabloTerres
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/33645d3caee104f410f199a38a90f844.svg
          fullname: PabloTerres
          isHf: false
          isPro: false
          name: PabloTerres
          type: user
        html: '<p>Hello!</p>

          <p>I''m new at this sort of stuff and for the life of me, I cannot figure
          out where I set the trust_remote_code to true. I''ve downloaded it from
          the Oobagooba UI but when I try running it I''ve ran into this error.</p>

          <p>ValueError: Loading models\OccamRazor_mpt-7b-storywriter-4bit-128g requires
          you to execute the configuration file in that repo on your local machine.
          Make sure you have read the code there to avoid malicious use, then set
          the option <code>trust_remote_code=True</code> to remove this error.</p>

          <p>I had to ask chatGpt on how to fix it... which is ironic (it didn''t
          work) and gave me this answer down below </p>

          <hr>

          <p>"You can copy and paste this code into a Python file or a Python interactive
          environment, such as a Jupyter Notebook, to instantiate a pre-trained model
          and turn on trust_remote_code.</p>

          <p>Open a text editor, such as Notepad or Sublime Text, and create a new
          file.</p>

          <p>Copy the following code into the file:</p>

          <p>python<br>Copy code</p>

          <p>import transformers<br>model = transformers.AutoModelForCausalLM.from_pretrained(<br>  ''mosaicml/mpt-7b-storywriter'',<br>  trust_remote_code=True<br>)<br>Save
          the file with a .py extension, for example, my_model.py.</p>

          <p>Open a command prompt or terminal and navigate to the directory where
          the file is saved.</p>

          <p>Type python my_model.py and press Enter to run the file.</p>

          <hr>

          <p>I''ve also gone through all the files in the repository and Word searching
          for "trust_remote_code" and I didn''t find anywhere where I could change
          it to true. </p>

          <p>if anyone could explain it to me how or where to set trust_remote_code
          to true for a dummy like me would be greatly appreciated.</p>

          '
        raw: "Hello!\r\n\r\nI'm new at this sort of stuff and for the life of me,\
          \ I cannot figure out where I set the trust_remote_code to true. I've downloaded\
          \ it from the Oobagooba UI but when I try running it I've ran into this\
          \ error.\r\n\r\nValueError: Loading models\\OccamRazor_mpt-7b-storywriter-4bit-128g\
          \ requires you to execute the configuration file in that repo on your local\
          \ machine. Make sure you have read the code there to avoid malicious use,\
          \ then set the option `trust_remote_code=True` to remove this error.\r\n\
          \r\nI had to ask chatGpt on how to fix it... which is ironic (it didn't\
          \ work) and gave me this answer down below \r\n___________________________________________________________________________________________________________________________________\r\
          \n\"You can copy and paste this code into a Python file or a Python interactive\
          \ environment, such as a Jupyter Notebook, to instantiate a pre-trained\
          \ model and turn on trust_remote_code.\r\n\r\nOpen a text editor, such as\
          \ Notepad or Sublime Text, and create a new file.\r\n\r\nCopy the following\
          \ code into the file:\r\n\r\npython\r\nCopy code\r\n\r\nimport transformers\r\
          \nmodel = transformers.AutoModelForCausalLM.from_pretrained(\r\n  'mosaicml/mpt-7b-storywriter',\r\
          \n  trust_remote_code=True\r\n)\r\nSave the file with a .py extension, for\
          \ example, my_model.py.\r\n\r\nOpen a command prompt or terminal and navigate\
          \ to the directory where the file is saved.\r\n\r\nType python my_model.py\
          \ and press Enter to run the file.\r\n___________________________________________________________________________________________________________________________________\r\
          \n\r\nI've also gone through all the files in the repository and Word searching\
          \ for \"trust_remote_code\" and I didn't find anywhere where I could change\
          \ it to true. \r\n\r\nif anyone could explain it to me how or where to set\
          \ trust_remote_code to true for a dummy like me would be greatly appreciated."
        updatedAt: '2023-05-08T06:54:45.025Z'
      numEdits: 0
      reactions: []
    id: 64589cb5ab9a44f42f622ce2
    type: comment
  author: PabloTerres
  content: "Hello!\r\n\r\nI'm new at this sort of stuff and for the life of me, I\
    \ cannot figure out where I set the trust_remote_code to true. I've downloaded\
    \ it from the Oobagooba UI but when I try running it I've ran into this error.\r\
    \n\r\nValueError: Loading models\\OccamRazor_mpt-7b-storywriter-4bit-128g requires\
    \ you to execute the configuration file in that repo on your local machine. Make\
    \ sure you have read the code there to avoid malicious use, then set the option\
    \ `trust_remote_code=True` to remove this error.\r\n\r\nI had to ask chatGpt on\
    \ how to fix it... which is ironic (it didn't work) and gave me this answer down\
    \ below \r\n___________________________________________________________________________________________________________________________________\r\
    \n\"You can copy and paste this code into a Python file or a Python interactive\
    \ environment, such as a Jupyter Notebook, to instantiate a pre-trained model\
    \ and turn on trust_remote_code.\r\n\r\nOpen a text editor, such as Notepad or\
    \ Sublime Text, and create a new file.\r\n\r\nCopy the following code into the\
    \ file:\r\n\r\npython\r\nCopy code\r\n\r\nimport transformers\r\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\r\
    \n  'mosaicml/mpt-7b-storywriter',\r\n  trust_remote_code=True\r\n)\r\nSave the\
    \ file with a .py extension, for example, my_model.py.\r\n\r\nOpen a command prompt\
    \ or terminal and navigate to the directory where the file is saved.\r\n\r\nType\
    \ python my_model.py and press Enter to run the file.\r\n___________________________________________________________________________________________________________________________________\r\
    \n\r\nI've also gone through all the files in the repository and Word searching\
    \ for \"trust_remote_code\" and I didn't find anywhere where I could change it\
    \ to true. \r\n\r\nif anyone could explain it to me how or where to set trust_remote_code\
    \ to true for a dummy like me would be greatly appreciated."
  created_at: 2023-05-08 05:54:45+00:00
  edited: false
  hidden: false
  id: 64589cb5ab9a44f42f622ce2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9fd0c3e4b1af3f82ba83c61c2c971e4d.svg
      fullname: Peter Larsen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Boosh
      type: user
    createdAt: '2023-05-08T12:19:01.000Z'
    data:
      edited: true
      editors:
      - Boosh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9fd0c3e4b1af3f82ba83c61c2c971e4d.svg
          fullname: Peter Larsen
          isHf: false
          isPro: false
          name: Boosh
          type: user
        html: '<p>This method is not working for me on this model but it does on the
          og storywriter model. I''ll leave it here so you know</p>

          <p>One way of doing that is to launch it in the env In ooba so:<br> launch
          cmd_windows.bat file in you main ooba floder<br>in the command prompt type
          "cd text-generation-webui" and hit enter.<br>in that command prompt you
          can launch by typing "python server.py --model mosaicml_mpt-7b-storywriter
          --listen --trust-remote-code"</p>

          <p>That worked in the other model for me. I got it from cheshire - <a rel="nofollow"
          href="https://www.youtube.com/watch?v=QVVb6Md6huA&amp;t=1s">https://www.youtube.com/watch?v=QVVb6Md6huA&amp;t=1s</a><br>The
          other way to do it that I have found is detailed here at about 08.35 - <a
          rel="nofollow" href="https://www.youtube.com/watch?v=O9Y_ZdsuKWQ">https://www.youtube.com/watch?v=O9Y_ZdsuKWQ</a></p>

          '
        raw: "This method is not working for me on this model but it does on the og\
          \ storywriter model. I'll leave it here so you know\n\nOne way of doing\
          \ that is to launch it in the env In ooba so: \n launch cmd_windows.bat\
          \ file in you main ooba floder\nin the command prompt type \"cd text-generation-webui\"\
          \ and hit enter.\nin that command prompt you can launch by typing \"python\
          \ server.py --model mosaicml_mpt-7b-storywriter --listen --trust-remote-code\"\
          \n\nThat worked in the other model for me. I got it from cheshire - https://www.youtube.com/watch?v=QVVb6Md6huA&t=1s\n\
          The other way to do it that I have found is detailed here at about 08.35\
          \ - https://www.youtube.com/watch?v=O9Y_ZdsuKWQ"
        updatedAt: '2023-05-08T12:20:02.750Z'
      numEdits: 1
      reactions: []
    id: 6458e8b5f92601affa2e79fe
    type: comment
  author: Boosh
  content: "This method is not working for me on this model but it does on the og\
    \ storywriter model. I'll leave it here so you know\n\nOne way of doing that is\
    \ to launch it in the env In ooba so: \n launch cmd_windows.bat file in you main\
    \ ooba floder\nin the command prompt type \"cd text-generation-webui\" and hit\
    \ enter.\nin that command prompt you can launch by typing \"python server.py --model\
    \ mosaicml_mpt-7b-storywriter --listen --trust-remote-code\"\n\nThat worked in\
    \ the other model for me. I got it from cheshire - https://www.youtube.com/watch?v=QVVb6Md6huA&t=1s\n\
    The other way to do it that I have found is detailed here at about 08.35 - https://www.youtube.com/watch?v=O9Y_ZdsuKWQ"
  created_at: 2023-05-08 11:19:01+00:00
  edited: true
  hidden: false
  id: 6458e8b5f92601affa2e79fe
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: OccamRazor/mpt-7b-storywriter-4bit-128g
repo_type: model
status: open
target_branch: null
title: trust_remote_code=True
