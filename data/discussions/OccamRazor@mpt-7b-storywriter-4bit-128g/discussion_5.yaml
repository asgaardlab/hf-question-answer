!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ProPatte
conflicting_files: null
created_at: 2023-05-09 20:52:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9199feb9a773b79032636645b1180ea1.svg
      fullname: Pro Patte
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ProPatte
      type: user
    createdAt: '2023-05-09T21:52:29.000Z'
    data:
      edited: false
      editors:
      - ProPatte
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9199feb9a773b79032636645b1180ea1.svg
          fullname: Pro Patte
          isHf: false
          isPro: false
          name: ProPatte
          type: user
        html: '<p>I''m trying to use the model with oobabooga but when I start the
          webui I get the error: "Could not locate the configuration_mpt.py inside
          models\OccamRazor_mpt-7b-storywriter-4bit-128g" is it correct to use the
          configuration_mpt.py from the /mosaicml/mpt-7b-storywriter model?</p>

          '
        raw: 'I''m trying to use the model with oobabooga but when I start the webui
          I get the error: "Could not locate the configuration_mpt.py inside models\OccamRazor_mpt-7b-storywriter-4bit-128g"
          is it correct to use the configuration_mpt.py from the /mosaicml/mpt-7b-storywriter
          model?'
        updatedAt: '2023-05-09T21:52:29.842Z'
      numEdits: 0
      reactions: []
    id: 645ac09dc4acfcf664028a1c
    type: comment
  author: ProPatte
  content: 'I''m trying to use the model with oobabooga but when I start the webui
    I get the error: "Could not locate the configuration_mpt.py inside models\OccamRazor_mpt-7b-storywriter-4bit-128g"
    is it correct to use the configuration_mpt.py from the /mosaicml/mpt-7b-storywriter
    model?'
  created_at: 2023-05-09 20:52:29+00:00
  edited: false
  hidden: false
  id: 645ac09dc4acfcf664028a1c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/574d055ca3ee7ecab70385e44b8944ef.svg
      fullname: neural_worm
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: neuralworm
      type: user
    createdAt: '2023-05-13T15:41:47.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/574d055ca3ee7ecab70385e44b8944ef.svg
          fullname: neural_worm
          isHf: false
          isPro: false
          name: neuralworm
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-05-13T15:58:59.318Z'
      numEdits: 2
      reactions: []
    id: 645fafbb446a4fa46957df67
    type: comment
  author: neuralworm
  content: This comment has been hidden
  created_at: 2023-05-13 14:41:47+00:00
  edited: true
  hidden: true
  id: 645fafbb446a4fa46957df67
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9199feb9a773b79032636645b1180ea1.svg
      fullname: Pro Patte
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ProPatte
      type: user
    createdAt: '2023-05-16T09:46:35.000Z'
    data:
      edited: false
      editors:
      - ProPatte
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9199feb9a773b79032636645b1180ea1.svg
          fullname: Pro Patte
          isHf: false
          isPro: false
          name: ProPatte
          type: user
        html: '<p>Why is @bartman081523 comment hidden?</p>

          '
        raw: Why is @bartman081523 comment hidden?
        updatedAt: '2023-05-16T09:46:35.089Z'
      numEdits: 0
      reactions: []
    id: 646350fba429ec3af0a3e800
    type: comment
  author: ProPatte
  content: Why is @bartman081523 comment hidden?
  created_at: 2023-05-16 08:46:35+00:00
  edited: false
  hidden: false
  id: 646350fba429ec3af0a3e800
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a908c7a993127eb4159f7e20e8d78e17.svg
      fullname: and giggles
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tisbeforfun
      type: user
    createdAt: '2023-05-18T18:18:52.000Z'
    data:
      edited: false
      editors:
      - tisbeforfun
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a908c7a993127eb4159f7e20e8d78e17.svg
          fullname: and giggles
          isHf: false
          isPro: false
          name: tisbeforfun
          type: user
        html: '<p>It seems you need to download the files that it says is missing
          from the mosaicml model. I needed to get: adapt_tokenizer, attention, blocks,
          configuration_mpt, hf_prefixlm_converter, meta_init_context, modeling_mpt,
          norm, and param_init_fns. After putting those in the model folder (oobabooga_windows\text-generation-webui\models\OccamRazor_mpt-7b-storywriter-4bit-128g",
          it worked for me.</p>

          '
        raw: 'It seems you need to download the files that it says is missing from
          the mosaicml model. I needed to get: adapt_tokenizer, attention, blocks,
          configuration_mpt, hf_prefixlm_converter, meta_init_context, modeling_mpt,
          norm, and param_init_fns. After putting those in the model folder (oobabooga_windows\text-generation-webui\models\OccamRazor_mpt-7b-storywriter-4bit-128g",
          it worked for me.'
        updatedAt: '2023-05-18T18:18:52.010Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\U0001F44D"
        users:
        - ProPatte
        - AshraGaunt
        - NOC-314
        - Freigus
        - circool
    id: 64666c0c119ad94383d36e82
    type: comment
  author: tisbeforfun
  content: 'It seems you need to download the files that it says is missing from the
    mosaicml model. I needed to get: adapt_tokenizer, attention, blocks, configuration_mpt,
    hf_prefixlm_converter, meta_init_context, modeling_mpt, norm, and param_init_fns.
    After putting those in the model folder (oobabooga_windows\text-generation-webui\models\OccamRazor_mpt-7b-storywriter-4bit-128g",
    it worked for me.'
  created_at: 2023-05-18 17:18:52+00:00
  edited: false
  hidden: false
  id: 64666c0c119ad94383d36e82
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Q7ytqF9XHRYTYisIfHGpv.png?w=200&h=200&f=face
      fullname: Nuka Libre
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NukaLibre
      type: user
    createdAt: '2023-05-26T06:39:53.000Z'
    data:
      edited: false
      editors:
      - NukaLibre
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Q7ytqF9XHRYTYisIfHGpv.png?w=200&h=200&f=face
          fullname: Nuka Libre
          isHf: false
          isPro: false
          name: NukaLibre
          type: user
        html: '<p>Found those files here: <a href="https://huggingface.co/mosaicml/mpt-7b/tree/main">https://huggingface.co/mosaicml/mpt-7b/tree/main</a></p>

          '
        raw: 'Found those files here: https://huggingface.co/mosaicml/mpt-7b/tree/main'
        updatedAt: '2023-05-26T06:39:53.599Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Freigus
        - circool
    id: 647054391f0e7ee7fb14c6f5
    type: comment
  author: NukaLibre
  content: 'Found those files here: https://huggingface.co/mosaicml/mpt-7b/tree/main'
  created_at: 2023-05-26 05:39:53+00:00
  edited: false
  hidden: false
  id: 647054391f0e7ee7fb14c6f5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/574d055ca3ee7ecab70385e44b8944ef.svg
      fullname: neural_worm
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: neuralworm
      type: user
    createdAt: '2023-08-20T14:56:48.000Z'
    data:
      edited: false
      editors:
      - neuralworm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8435360193252563
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/574d055ca3ee7ecab70385e44b8944ef.svg
          fullname: neural_worm
          isHf: false
          isPro: false
          name: neuralworm
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ProPatte&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ProPatte\">@<span class=\"\
          underline\">ProPatte</span></a></span>\n\n\t</span></span></p>\n<blockquote>\n\
          <p>Why is @bartman081523 comment hidden?</p>\n</blockquote>\n<p>My post\
          \ was wrong info</p>\n"
        raw: '@ProPatte

          > Why is @bartman081523 comment hidden?


          My post was wrong info'
        updatedAt: '2023-08-20T14:56:48.671Z'
      numEdits: 0
      reactions: []
    id: 64e229b03209bf4194b2f9c6
    type: comment
  author: neuralworm
  content: '@ProPatte

    > Why is @bartman081523 comment hidden?


    My post was wrong info'
  created_at: 2023-08-20 13:56:48+00:00
  edited: false
  hidden: false
  id: 64e229b03209bf4194b2f9c6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/04987dfc8de4de051aee0a5d2ce51367.svg
      fullname: Clark Llarena
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: circool
      type: user
    createdAt: '2023-08-23T02:10:31.000Z'
    data:
      edited: false
      editors:
      - circool
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5008196830749512
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/04987dfc8de4de051aee0a5d2ce51367.svg
          fullname: Clark Llarena
          isHf: false
          isPro: false
          name: circool
          type: user
        html: '<p>I was facing the same issue, I''ve downloaded those files and more
          but now I get this AttributeError:</p>

          <p><code> 2023-08-23 09:45:17 INFO:Loading OccamRazor_mpt-7b-storywriter-4bit-128g...
          2023-08-23 09:45:17 ERROR:Failed to load the model. Traceback (most recent
          call last):   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\text-generation-webui\server.py",
          line 69, in load_model_wrapper     shared.model, shared.tokenizer = load_model(shared.model_name,
          loader)   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\text-generation-webui\modules\models.py",
          line 78, in load_model     output = load_func_map[loader](model_name)   File
          "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\text-generation-webui\modules\models.py",
          line 148, in huggingface_loader     model = LoaderClass.from_pretrained(Path(f"{shared.args.model_dir}/{model_name}"),
          low_cpu_mem_usage=True, torch_dtype=torch.bfloat16 if shared.args.bf16 else
          torch.float16, trust_remote_code=shared.args.trust_remote_code)   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\installer_files\env\lib\site-packages\transformers\models\auto\auto_factory.py",
          line 488, in from_pretrained     return model_class.from_pretrained(   File
          "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
          line 2629, in from_pretrained     state_dict = load_state_dict(resolved_archive_file)   File
          "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
          line 449, in load_state_dict     if metadata.get("format") not in ["pt",
          "tf", "flax"]: AttributeError: ''NoneType'' object has no attribute ''get''</code></p>

          '
        raw: "I was facing the same issue, I've downloaded those files and more but\
          \ now I get this AttributeError:\n```\n2023-08-23 09:45:17 INFO:Loading\
          \ OccamRazor_mpt-7b-storywriter-4bit-128g...\n2023-08-23 09:45:17 ERROR:Failed\
          \ to load the model.\nTraceback (most recent call last):\n  File \"D:\\\
          AI_Stuff\\oobabooga\\oobabooga-windows\\oobabooga-windows\\text-generation-webui\\\
          server.py\", line 69, in load_model_wrapper\n    shared.model, shared.tokenizer\
          \ = load_model(shared.model_name, loader)\n  File \"D:\\AI_Stuff\\oobabooga\\\
          oobabooga-windows\\oobabooga-windows\\text-generation-webui\\modules\\models.py\"\
          , line 78, in load_model\n    output = load_func_map[loader](model_name)\n\
          \  File \"D:\\AI_Stuff\\oobabooga\\oobabooga-windows\\oobabooga-windows\\\
          text-generation-webui\\modules\\models.py\", line 148, in huggingface_loader\n\
          \    model = LoaderClass.from_pretrained(Path(f\"{shared.args.model_dir}/{model_name}\"\
          ), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16 if shared.args.bf16\
          \ else torch.float16, trust_remote_code=shared.args.trust_remote_code)\n\
          \  File \"D:\\AI_Stuff\\oobabooga\\oobabooga-windows\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\"\
          , line 488, in from_pretrained\n    return model_class.from_pretrained(\n\
          \  File \"D:\\AI_Stuff\\oobabooga\\oobabooga-windows\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\modeling_utils.py\"\
          , line 2629, in from_pretrained\n    state_dict = load_state_dict(resolved_archive_file)\n\
          \  File \"D:\\AI_Stuff\\oobabooga\\oobabooga-windows\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\modeling_utils.py\"\
          , line 449, in load_state_dict\n    if metadata.get(\"format\") not in [\"\
          pt\", \"tf\", \"flax\"]:\nAttributeError: 'NoneType' object has no attribute\
          \ 'get'```"
        updatedAt: '2023-08-23T02:10:31.114Z'
      numEdits: 0
      reactions: []
    id: 64e56a97a9a5eabaa6f28619
    type: comment
  author: circool
  content: "I was facing the same issue, I've downloaded those files and more but\
    \ now I get this AttributeError:\n```\n2023-08-23 09:45:17 INFO:Loading OccamRazor_mpt-7b-storywriter-4bit-128g...\n\
    2023-08-23 09:45:17 ERROR:Failed to load the model.\nTraceback (most recent call\
    \ last):\n  File \"D:\\AI_Stuff\\oobabooga\\oobabooga-windows\\oobabooga-windows\\\
    text-generation-webui\\server.py\", line 69, in load_model_wrapper\n    shared.model,\
    \ shared.tokenizer = load_model(shared.model_name, loader)\n  File \"D:\\AI_Stuff\\\
    oobabooga\\oobabooga-windows\\oobabooga-windows\\text-generation-webui\\modules\\\
    models.py\", line 78, in load_model\n    output = load_func_map[loader](model_name)\n\
    \  File \"D:\\AI_Stuff\\oobabooga\\oobabooga-windows\\oobabooga-windows\\text-generation-webui\\\
    modules\\models.py\", line 148, in huggingface_loader\n    model = LoaderClass.from_pretrained(Path(f\"\
    {shared.args.model_dir}/{model_name}\"), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16\
    \ if shared.args.bf16 else torch.float16, trust_remote_code=shared.args.trust_remote_code)\n\
    \  File \"D:\\AI_Stuff\\oobabooga\\oobabooga-windows\\oobabooga-windows\\installer_files\\\
    env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 488,\
    \ in from_pretrained\n    return model_class.from_pretrained(\n  File \"D:\\AI_Stuff\\\
    oobabooga\\oobabooga-windows\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\modeling_utils.py\", line 2629, in from_pretrained\n    state_dict\
    \ = load_state_dict(resolved_archive_file)\n  File \"D:\\AI_Stuff\\oobabooga\\\
    oobabooga-windows\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\modeling_utils.py\", line 449, in load_state_dict\n    if metadata.get(\"\
    format\") not in [\"pt\", \"tf\", \"flax\"]:\nAttributeError: 'NoneType' object\
    \ has no attribute 'get'```"
  created_at: 2023-08-23 01:10:31+00:00
  edited: false
  hidden: false
  id: 64e56a97a9a5eabaa6f28619
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9820de6460ef50383eb76892c8eec819.svg
      fullname: Nathan Wilson
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Cryptic15262
      type: user
    createdAt: '2023-12-15T01:32:47.000Z'
    data:
      edited: false
      editors:
      - Cryptic15262
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5223898887634277
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9820de6460ef50383eb76892c8eec819.svg
          fullname: Nathan Wilson
          isHf: false
          isPro: false
          name: Cryptic15262
          type: user
        html: "<blockquote>\n<p>I was facing the same issue, I've downloaded those\
          \ files and more but now I get this AttributeError:</p>\n<pre><code>2023-08-23\
          \ 09:45:17 INFO:Loading OccamRazor_mpt-7b-storywriter-4bit-128g...\n2023-08-23\
          \ 09:45:17 ERROR:Failed to load the model.\nTraceback (most recent call\
          \ last):\n  File \"D:\\AI_Stuff\\oobabooga\\oobabooga-windows\\oobabooga-windows\\\
          text-generation-webui\\server.py\", line 69, in load_model_wrapper\n   \
          \ shared.model, shared.tokenizer = load_model(shared.model_name, loader)\n\
          \  File \"D:\\AI_Stuff\\oobabooga\\oobabooga-windows\\oobabooga-windows\\\
          text-generation-webui\\modules\\models.py\", line 78, in load_model\n  \
          \  output = load_func_map[loader](model_name)\n  File \"D:\\AI_Stuff\\oobabooga\\\
          oobabooga-windows\\oobabooga-windows\\text-generation-webui\\modules\\models.py\"\
          , line 148, in huggingface_loader\n    model = LoaderClass.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}\"), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16\
          \ if shared.args.bf16 else torch.float16, trust_remote_code=shared.args.trust_remote_code)\n\
          \  File \"D:\\AI_Stuff\\oobabooga\\oobabooga-windows\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\"\
          , line 488, in from_pretrained\n    return model_class.from_pretrained(\n\
          \  File \"D:\\AI_Stuff\\oobabooga\\oobabooga-windows\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\modeling_utils.py\"\
          , line 2629, in from_pretrained\n    state_dict = load_state_dict(resolved_archive_file)\n\
          \  File \"D:\\AI_Stuff\\oobabooga\\oobabooga-windows\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\modeling_utils.py\"\
          , line 449, in load_state_dict\n    if metadata.get(\"format\") not in [\"\
          pt\", \"tf\", \"flax\"]:\nAttributeError: 'NoneType' object has no attribute\
          \ 'get'```\n</code></pre>\n</blockquote>\n<p>Same thing I got! Did you end\
          \ up finding a solution? I really want to use this model!</p>\n"
        raw: '> I was facing the same issue, I''ve downloaded those files and more
          but now I get this AttributeError:

          > ```

          > 2023-08-23 09:45:17 INFO:Loading OccamRazor_mpt-7b-storywriter-4bit-128g...

          > 2023-08-23 09:45:17 ERROR:Failed to load the model.

          > Traceback (most recent call last):

          >   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\text-generation-webui\server.py",
          line 69, in load_model_wrapper

          >     shared.model, shared.tokenizer = load_model(shared.model_name, loader)

          >   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\text-generation-webui\modules\models.py",
          line 78, in load_model

          >     output = load_func_map[loader](model_name)

          >   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\text-generation-webui\modules\models.py",
          line 148, in huggingface_loader

          >     model = LoaderClass.from_pretrained(Path(f"{shared.args.model_dir}/{model_name}"),
          low_cpu_mem_usage=True, torch_dtype=torch.bfloat16 if shared.args.bf16 else
          torch.float16, trust_remote_code=shared.args.trust_remote_code)

          >   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\installer_files\env\lib\site-packages\transformers\models\auto\auto_factory.py",
          line 488, in from_pretrained

          >     return model_class.from_pretrained(

          >   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
          line 2629, in from_pretrained

          >     state_dict = load_state_dict(resolved_archive_file)

          >   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
          line 449, in load_state_dict

          >     if metadata.get("format") not in ["pt", "tf", "flax"]:

          > AttributeError: ''NoneType'' object has no attribute ''get''```


          Same thing I got! Did you end up finding a solution? I really want to use
          this model!'
        updatedAt: '2023-12-15T01:32:47.984Z'
      numEdits: 0
      reactions: []
    id: 657bacbf13e11aaa91d62682
    type: comment
  author: Cryptic15262
  content: '> I was facing the same issue, I''ve downloaded those files and more but
    now I get this AttributeError:

    > ```

    > 2023-08-23 09:45:17 INFO:Loading OccamRazor_mpt-7b-storywriter-4bit-128g...

    > 2023-08-23 09:45:17 ERROR:Failed to load the model.

    > Traceback (most recent call last):

    >   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\text-generation-webui\server.py",
    line 69, in load_model_wrapper

    >     shared.model, shared.tokenizer = load_model(shared.model_name, loader)

    >   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\text-generation-webui\modules\models.py",
    line 78, in load_model

    >     output = load_func_map[loader](model_name)

    >   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\text-generation-webui\modules\models.py",
    line 148, in huggingface_loader

    >     model = LoaderClass.from_pretrained(Path(f"{shared.args.model_dir}/{model_name}"),
    low_cpu_mem_usage=True, torch_dtype=torch.bfloat16 if shared.args.bf16 else torch.float16,
    trust_remote_code=shared.args.trust_remote_code)

    >   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\installer_files\env\lib\site-packages\transformers\models\auto\auto_factory.py",
    line 488, in from_pretrained

    >     return model_class.from_pretrained(

    >   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
    line 2629, in from_pretrained

    >     state_dict = load_state_dict(resolved_archive_file)

    >   File "D:\AI_Stuff\oobabooga\oobabooga-windows\oobabooga-windows\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
    line 449, in load_state_dict

    >     if metadata.get("format") not in ["pt", "tf", "flax"]:

    > AttributeError: ''NoneType'' object has no attribute ''get''```


    Same thing I got! Did you end up finding a solution? I really want to use this
    model!'
  created_at: 2023-12-15 01:32:47+00:00
  edited: false
  hidden: false
  id: 657bacbf13e11aaa91d62682
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: OccamRazor/mpt-7b-storywriter-4bit-128g
repo_type: model
status: open
target_branch: null
title: 'Oobabooga: "Could not locate the configuration_mpt.py inside models\OccamRazor_mpt-7b-storywriter-4bit-128g"'
