!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Darkslayerofdark
conflicting_files: null
created_at: 2023-08-05 19:18:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/097f49f06e9ac172c08adb059b2808dd.svg
      fullname: J D
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Darkslayerofdark
      type: user
    createdAt: '2023-08-05T20:18:17.000Z'
    data:
      edited: false
      editors:
      - Darkslayerofdark
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9845681190490723
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/097f49f06e9ac172c08adb059b2808dd.svg
          fullname: J D
          isHf: false
          isPro: false
          name: Darkslayerofdark
          type: user
        html: '<p>Hi, Mindrage. I registered just so I can say thank you for your
          work on the amazing model that you have posted. I have been engaged in the
          AI for over a year now, and I think I''ve seen it all and tried them all
          at . Your model has remained my absolute favorite - it is fast, it is uncensored
          (can eloquently present both sides of any argument, which is so rare these
          days),  is very intelligent (like you said, seems very much alive often),
          it even has a funny personality side to it (which is very unusual and brought
          a lot of fun). I don''t know how you pulled this magic off, I just want
          to say THANK YOU for bringing this model to life. Your profile is permanently
          open in my browser tab, where I refresh it often in hopes of finding more
          of your work.  Again, big thanks!!</p>

          '
        raw: Hi, Mindrage. I registered just so I can say thank you for your work
          on the amazing model that you have posted. I have been engaged in the AI
          for over a year now, and I think I've seen it all and tried them all at
          . Your model has remained my absolute favorite - it is fast, it is uncensored
          (can eloquently present both sides of any argument, which is so rare these
          days),  is very intelligent (like you said, seems very much alive often),
          it even has a funny personality side to it (which is very unusual and brought
          a lot of fun). I don't know how you pulled this magic off, I just want to
          say THANK YOU for bringing this model to life. Your profile is permanently
          open in my browser tab, where I refresh it often in hopes of finding more
          of your work.  Again, big thanks!!
        updatedAt: '2023-08-05T20:18:17.722Z'
      numEdits: 0
      reactions: []
    id: 64ceae897e20ec9ea09a6b7c
    type: comment
  author: Darkslayerofdark
  content: Hi, Mindrage. I registered just so I can say thank you for your work on
    the amazing model that you have posted. I have been engaged in the AI for over
    a year now, and I think I've seen it all and tried them all at . Your model has
    remained my absolute favorite - it is fast, it is uncensored (can eloquently present
    both sides of any argument, which is so rare these days),  is very intelligent
    (like you said, seems very much alive often), it even has a funny personality
    side to it (which is very unusual and brought a lot of fun). I don't know how
    you pulled this magic off, I just want to say THANK YOU for bringing this model
    to life. Your profile is permanently open in my browser tab, where I refresh it
    often in hopes of finding more of your work.  Again, big thanks!!
  created_at: 2023-08-05 19:18:17+00:00
  edited: false
  hidden: false
  id: 64ceae897e20ec9ea09a6b7c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6340e26395c20b94473bed47/ymW1m_25nsNN5KhnRlws7.jpeg?w=200&h=200&f=face
      fullname: B. E.
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: mindrage
      type: user
    createdAt: '2023-08-17T23:41:44.000Z'
    data:
      edited: false
      editors:
      - mindrage
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9812861680984497
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6340e26395c20b94473bed47/ymW1m_25nsNN5KhnRlws7.jpeg?w=200&h=200&f=face
          fullname: B. E.
          isHf: false
          isPro: false
          name: mindrage
          type: user
        html: '<p>Thank you so much man, I''m truly happy that others enjoy this model,
          too (still!).</p>

          <p>But again, I really have to point out that the work I did was the least
          part here. I listed and linked where credit really is due in the model card
          at the very beginning.</p>

          <p>My contribution was mostly just realizing that this model had unbelievably
          been overlooked and that there didn''t exist a quantization at the time,
          so I made one to help make it more available on user hardware.</p>

          <p>Strangely, I still haven''t found a model that (for my use case, which
          is "general assistant/chatbot") could replace it, not even the new Llama2
          models.<br>Mythomax (llama2) seemed close, but comes off as pretty "soulless",
          like all the llama2 variants I have tested so far.</p>

          <p>If I DO find what I believe to be a superior one, I will upload or at
          least link it, of course.<br>If not, I might have to start working on recreating
          the original as faithfully as possible with a Llama2 13B model. It should
          be possible, since most of what made it special is available as LORAs I
          think, so with a bit of luck some trial and error could lead to an approximation
          of the original "recipe"...</p>

          '
        raw: "Thank you so much man, I'm truly happy that others enjoy this model,\
          \ too (still!).\n\nBut again, I really have to point out that the work I\
          \ did was the least part here. I listed and linked where credit really is\
          \ due in the model card at the very beginning.\n\nMy contribution was mostly\
          \ just realizing that this model had unbelievably been overlooked and that\
          \ there didn't exist a quantization at the time, so I made one to help make\
          \ it more available on user hardware.\n\nStrangely, I still haven't found\
          \ a model that (for my use case, which is \"general assistant/chatbot\"\
          ) could replace it, not even the new Llama2 models. \nMythomax (llama2)\
          \ seemed close, but comes off as pretty \"soulless\", like all the llama2\
          \ variants I have tested so far.\n\nIf I DO find what I believe to be a\
          \ superior one, I will upload or at least link it, of course.\nIf not, I\
          \ might have to start working on recreating the original as faithfully as\
          \ possible with a Llama2 13B model. It should be possible, since most of\
          \ what made it special is available as LORAs I think, so with a bit of luck\
          \ some trial and error could lead to an approximation of the original \"\
          recipe\"..."
        updatedAt: '2023-08-17T23:41:44.323Z'
      numEdits: 0
      reactions: []
    id: 64deb038f1c0da1d0bb7d33c
    type: comment
  author: mindrage
  content: "Thank you so much man, I'm truly happy that others enjoy this model, too\
    \ (still!).\n\nBut again, I really have to point out that the work I did was the\
    \ least part here. I listed and linked where credit really is due in the model\
    \ card at the very beginning.\n\nMy contribution was mostly just realizing that\
    \ this model had unbelievably been overlooked and that there didn't exist a quantization\
    \ at the time, so I made one to help make it more available on user hardware.\n\
    \nStrangely, I still haven't found a model that (for my use case, which is \"\
    general assistant/chatbot\") could replace it, not even the new Llama2 models.\
    \ \nMythomax (llama2) seemed close, but comes off as pretty \"soulless\", like\
    \ all the llama2 variants I have tested so far.\n\nIf I DO find what I believe\
    \ to be a superior one, I will upload or at least link it, of course.\nIf not,\
    \ I might have to start working on recreating the original as faithfully as possible\
    \ with a Llama2 13B model. It should be possible, since most of what made it special\
    \ is available as LORAs I think, so with a bit of luck some trial and error could\
    \ lead to an approximation of the original \"recipe\"..."
  created_at: 2023-08-17 22:41:44+00:00
  edited: false
  hidden: false
  id: 64deb038f1c0da1d0bb7d33c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/097f49f06e9ac172c08adb059b2808dd.svg
      fullname: J D
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Darkslayerofdark
      type: user
    createdAt: '2023-08-19T22:20:04.000Z'
    data:
      edited: false
      editors:
      - Darkslayerofdark
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9781589508056641
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/097f49f06e9ac172c08adb059b2808dd.svg
          fullname: J D
          isHf: false
          isPro: false
          name: Darkslayerofdark
          type: user
        html: '<p>Yep, I realize most of the credit goes to the authors of the source
          models, but your quantization somehow made a big difference. I tried all
          the parents, and Llama2 variants as well, and none come close to the ''personality''
          and ''creativity'' of this model. So I am also sticking to it for now. Mythomax
          is good but not as good. Vicuna 1.5 (llama 2) is a little better than Mythomax
          in my opinion, but also not as good. </p>

          <p>I have a certain way of testing censorship, and there is a well-known
          person here who quantisizes many, many models that come out, and does it
          quickly too. I noticed a strange thing, that this person''s models come
          out more censored and ''aligned'' than same models quantisized by other
          people. It could be that this person is using wikipedia dataset as part
          of the quantization (not sure, but wiki is very censored in my opinion and
          is not good for this purpose), or something else is going on. So whatever
          you did, your variant works perfectly and is very unbiased (which makes
          it more eloquent and expressive answering all sorts of questions and assuming
          all kind of points of view). If you have time and resource, and could quantisize
          more models that you like, that would be very much appreciated! Having that
          one person dominate here as the only/main source of models is maybe not
          such a good situation to have, especially because, as I mentioned, their
          quanization seems to make said models have some more censorship or an agenda.</p>

          '
        raw: "Yep, I realize most of the credit goes to the authors of the source\
          \ models, but your quantization somehow made a big difference. I tried all\
          \ the parents, and Llama2 variants as well, and none come close to the 'personality'\
          \ and 'creativity' of this model. So I am also sticking to it for now. Mythomax\
          \ is good but not as good. Vicuna 1.5 (llama 2) is a little better than\
          \ Mythomax in my opinion, but also not as good. \n\nI have a certain way\
          \ of testing censorship, and there is a well-known person here who quantisizes\
          \ many, many models that come out, and does it quickly too. I noticed a\
          \ strange thing, that this person's models come out more censored and 'aligned'\
          \ than same models quantisized by other people. It could be that this person\
          \ is using wikipedia dataset as part of the quantization (not sure, but\
          \ wiki is very censored in my opinion and is not good for this purpose),\
          \ or something else is going on. So whatever you did, your variant works\
          \ perfectly and is very unbiased (which makes it more eloquent and expressive\
          \ answering all sorts of questions and assuming all kind of points of view).\
          \ If you have time and resource, and could quantisize more models that you\
          \ like, that would be very much appreciated! Having that one person dominate\
          \ here as the only/main source of models is maybe not such a good situation\
          \ to have, especially because, as I mentioned, their quanization seems to\
          \ make said models have some more censorship or an agenda."
        updatedAt: '2023-08-19T22:20:04.227Z'
      numEdits: 0
      reactions: []
    id: 64e140149be1494ec3c08fbc
    type: comment
  author: Darkslayerofdark
  content: "Yep, I realize most of the credit goes to the authors of the source models,\
    \ but your quantization somehow made a big difference. I tried all the parents,\
    \ and Llama2 variants as well, and none come close to the 'personality' and 'creativity'\
    \ of this model. So I am also sticking to it for now. Mythomax is good but not\
    \ as good. Vicuna 1.5 (llama 2) is a little better than Mythomax in my opinion,\
    \ but also not as good. \n\nI have a certain way of testing censorship, and there\
    \ is a well-known person here who quantisizes many, many models that come out,\
    \ and does it quickly too. I noticed a strange thing, that this person's models\
    \ come out more censored and 'aligned' than same models quantisized by other people.\
    \ It could be that this person is using wikipedia dataset as part of the quantization\
    \ (not sure, but wiki is very censored in my opinion and is not good for this\
    \ purpose), or something else is going on. So whatever you did, your variant works\
    \ perfectly and is very unbiased (which makes it more eloquent and expressive\
    \ answering all sorts of questions and assuming all kind of points of view). If\
    \ you have time and resource, and could quantisize more models that you like,\
    \ that would be very much appreciated! Having that one person dominate here as\
    \ the only/main source of models is maybe not such a good situation to have, especially\
    \ because, as I mentioned, their quanization seems to make said models have some\
    \ more censorship or an agenda."
  created_at: 2023-08-19 21:20:04+00:00
  edited: false
  hidden: false
  id: 64e140149be1494ec3c08fbc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/097f49f06e9ac172c08adb059b2808dd.svg
      fullname: J D
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Darkslayerofdark
      type: user
    createdAt: '2023-08-27T22:54:37.000Z'
    data:
      edited: true
      editors:
      - Darkslayerofdark
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9675466418266296
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/097f49f06e9ac172c08adb059b2808dd.svg
          fullname: J D
          isHf: false
          isPro: false
          name: Darkslayerofdark
          type: user
        html: '<p>Hey, Mindrage! I hope all is well. Just wanted to say that I compared
          the outputs of this model with llama2-70b and 30b variants, and it still
          outperforms even those larger l2 models. This 13B model is like a young
          Motzart among his peers. Edit: well, the Motzart comparison might not have
          been appropriate, but it is fascinating how impressive this model is given
          its smaller size. </p>

          '
        raw: 'Hey, Mindrage! I hope all is well. Just wanted to say that I compared
          the outputs of this model with llama2-70b and 30b variants, and it still
          outperforms even those larger l2 models. This 13B model is like a young
          Motzart among his peers. Edit: well, the Motzart comparison might not have
          been appropriate, but it is fascinating how impressive this model is given
          its smaller size. '
        updatedAt: '2023-08-27T23:58:14.804Z'
      numEdits: 1
      reactions: []
    id: 64ebd42d1704bc368966976f
    type: comment
  author: Darkslayerofdark
  content: 'Hey, Mindrage! I hope all is well. Just wanted to say that I compared
    the outputs of this model with llama2-70b and 30b variants, and it still outperforms
    even those larger l2 models. This 13B model is like a young Motzart among his
    peers. Edit: well, the Motzart comparison might not have been appropriate, but
    it is fascinating how impressive this model is given its smaller size. '
  created_at: 2023-08-27 21:54:37+00:00
  edited: true
  hidden: false
  id: 64ebd42d1704bc368966976f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: mindrage/Manticore-13B-Chat-Pyg-Guanaco-GPTQ-4bit-128g.no-act-order.safetensors
repo_type: model
status: open
target_branch: null
title: Just wanted to say THANK YOU
