!!python/object:huggingface_hub.community.DiscussionWithDetails
author: haydenhong
conflicting_files: null
created_at: 2022-12-06 07:27:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a05379ab140073de0281000e1b21f119.svg
      fullname: hhong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: haydenhong
      type: user
    createdAt: '2022-12-06T07:27:49.000Z'
    data:
      edited: false
      editors:
      - haydenhong
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a05379ab140073de0281000e1b21f119.svg
          fullname: hhong
          isHf: false
          isPro: false
          name: haydenhong
          type: user
        html: '<p>Thanks for the great work on training and releazing this model!
          Upon reading the discussion on the Bloom page related to Bloomz and mt0-xxl,
          I am excited to try out mt0-xxl web version (given that bloomz web is gone).
          I am puzzled to see simply running the default example would generate result
          that seems to be not as impressive. The screenshot shows the three issues
          I think we can easily spot.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1670311654988-6325a532ff539edeea8d6590.png"><img
          alt="edaafbeefa0ecfb467ad1b86e88721a.png" src="https://cdn-uploads.huggingface.co/production/uploads/1670311654988-6325a532ff539edeea8d6590.png"></a></p>

          <p>I also ran some of the cases from xP3 dataset for zh and noticed those
          cases with short answers tend to be good, while those with longer answers
          would show various kind of issues, including 1) words repeated immediately
          one after another sometimes, 2) grammatically incorrect sentences, 3) irrelevant
          contents, and 4) uncoherent context etc.<br>Is there something missing somewhere?</p>

          <p>BTW, do you mind sharing the "best" parameters used for calling the "model.generate()"
          in a locally deployed mt0-xxl model please?</p>

          '
        raw: "Thanks for the great work on training and releazing this model! Upon\
          \ reading the discussion on the Bloom page related to Bloomz and mt0-xxl,\
          \ I am excited to try out mt0-xxl web version (given that bloomz web is\
          \ gone). I am puzzled to see simply running the default example would generate\
          \ result that seems to be not as impressive. The screenshot shows the three\
          \ issues I think we can easily spot.\r\n\r\n![edaafbeefa0ecfb467ad1b86e88721a.png](https://cdn-uploads.huggingface.co/production/uploads/1670311654988-6325a532ff539edeea8d6590.png)\r\
          \n\r\nI also ran some of the cases from xP3 dataset for zh and noticed those\
          \ cases with short answers tend to be good, while those with longer answers\
          \ would show various kind of issues, including 1) words repeated immediately\
          \ one after another sometimes, 2) grammatically incorrect sentences, 3)\
          \ irrelevant contents, and 4) uncoherent context etc.\r\nIs there something\
          \ missing somewhere?\r\n\r\nBTW, do you mind sharing the \"best\" parameters\
          \ used for calling the \"model.generate()\" in a locally deployed mt0-xxl\
          \ model please?"
        updatedAt: '2022-12-06T07:27:49.437Z'
      numEdits: 0
      reactions: []
    id: 638eeef5f9fb22b5a073355f
    type: comment
  author: haydenhong
  content: "Thanks for the great work on training and releazing this model! Upon reading\
    \ the discussion on the Bloom page related to Bloomz and mt0-xxl, I am excited\
    \ to try out mt0-xxl web version (given that bloomz web is gone). I am puzzled\
    \ to see simply running the default example would generate result that seems to\
    \ be not as impressive. The screenshot shows the three issues I think we can easily\
    \ spot.\r\n\r\n![edaafbeefa0ecfb467ad1b86e88721a.png](https://cdn-uploads.huggingface.co/production/uploads/1670311654988-6325a532ff539edeea8d6590.png)\r\
    \n\r\nI also ran some of the cases from xP3 dataset for zh and noticed those cases\
    \ with short answers tend to be good, while those with longer answers would show\
    \ various kind of issues, including 1) words repeated immediately one after another\
    \ sometimes, 2) grammatically incorrect sentences, 3) irrelevant contents, and\
    \ 4) uncoherent context etc.\r\nIs there something missing somewhere?\r\n\r\n\
    BTW, do you mind sharing the \"best\" parameters used for calling the \"model.generate()\"\
    \ in a locally deployed mt0-xxl model please?"
  created_at: 2022-12-06 07:27:49+00:00
  edited: false
  hidden: false
  id: 638eeef5f9fb22b5a073355f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
      fullname: Thomas Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: TimeRobber
      type: user
    createdAt: '2022-12-06T20:44:54.000Z'
    data:
      edited: false
      editors:
      - TimeRobber
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
          fullname: Thomas Wang
          isHf: false
          isPro: false
          name: TimeRobber
          type: user
        html: '<p>Yeah one of the drawpacks of current models trained on P3/xP3 etc
          ... is they tend to generate shorter answer. BLOOMz is probably a better
          model if you want to have long answers. It''s an ongoing work to generate
          long consistent text.</p>

          <p>We don''t really have "best" parameters, feel free to experiment with
          other params, as well as other inference algorithms. If I''m not wrong,
          the current generation is purely greedy so probably the worst of the algorithm.</p>

          '
        raw: 'Yeah one of the drawpacks of current models trained on P3/xP3 etc ...
          is they tend to generate shorter answer. BLOOMz is probably a better model
          if you want to have long answers. It''s an ongoing work to generate long
          consistent text.


          We don''t really have "best" parameters, feel free to experiment with other
          params, as well as other inference algorithms. If I''m not wrong, the current
          generation is purely greedy so probably the worst of the algorithm.'
        updatedAt: '2022-12-06T20:44:54.719Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - yahma
    id: 638fa9c60c51c77bb8ac032d
    type: comment
  author: TimeRobber
  content: 'Yeah one of the drawpacks of current models trained on P3/xP3 etc ...
    is they tend to generate shorter answer. BLOOMz is probably a better model if
    you want to have long answers. It''s an ongoing work to generate long consistent
    text.


    We don''t really have "best" parameters, feel free to experiment with other params,
    as well as other inference algorithms. If I''m not wrong, the current generation
    is purely greedy so probably the worst of the algorithm.'
  created_at: 2022-12-06 20:44:54+00:00
  edited: false
  hidden: false
  id: 638fa9c60c51c77bb8ac032d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: bigscience/mt0-xxl
repo_type: model
status: open
target_branch: null
title: mt0-xxl web app performance issue?
