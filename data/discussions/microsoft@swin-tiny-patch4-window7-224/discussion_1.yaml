!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Bailey24
conflicting_files: null
created_at: 2022-12-10 06:26:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669816869049-6358bf50856b319a29bd6f14.jpeg?w=200&h=200&f=face
      fullname: Knight
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Bailey24
      type: user
    createdAt: '2022-12-10T06:26:23.000Z'
    data:
      edited: false
      editors:
      - Bailey24
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669816869049-6358bf50856b319a29bd6f14.jpeg?w=200&h=200&f=face
          fullname: Knight
          isHf: false
          isPro: false
          name: Bailey24
          type: user
        html: '<p>Hi, I''m a student from China.<br>     I want to use swin v2 as
          backbone to extract features. But I don''t know how to adapt the model to
          my project.<br>    First,  the input size is torch.size((1, 5, 224, 224)),
          but the pretrained swin v2 see only support torch.size((3, 224,224)).<br>    Second,
          I want to extract the feature, in other words,  the output size from swin
          v2 is torch.size((1,1024,20,20)).<br>How do I fix the two questions above?</p>

          <p>Thanks in advance.</p>

          '
        raw: "Hi, I'm a student from China.\r\n     I want to use swin v2 as backbone\
          \ to extract features. But I don't know how to adapt the model to my project.\r\
          \n    First,  the input size is torch.size((1, 5, 224, 224)), but the pretrained\
          \ swin v2 see only support torch.size((3, 224,224)).\r\n    Second, I want\
          \ to extract the feature, in other words,  the output size from swin v2\
          \ is torch.size((1,1024,20,20)).\r\nHow do I fix the two questions above?\r\
          \n\r\nThanks in advance.\r\n"
        updatedAt: '2022-12-10T06:26:23.211Z'
      numEdits: 0
      reactions: []
    id: 6394268f93b1c0acee529e14
    type: comment
  author: Bailey24
  content: "Hi, I'm a student from China.\r\n     I want to use swin v2 as backbone\
    \ to extract features. But I don't know how to adapt the model to my project.\r\
    \n    First,  the input size is torch.size((1, 5, 224, 224)), but the pretrained\
    \ swin v2 see only support torch.size((3, 224,224)).\r\n    Second, I want to\
    \ extract the feature, in other words,  the output size from swin v2 is torch.size((1,1024,20,20)).\r\
    \nHow do I fix the two questions above?\r\n\r\nThanks in advance.\r\n"
  created_at: 2022-12-10 06:26:23+00:00
  edited: false
  hidden: false
  id: 6394268f93b1c0acee529e14
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2022-12-12T11:25:04.000Z'
    data:
      edited: false
      editors:
      - nielsr
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: '<p>Hi,</p>

          <p>To use Swinv2, you can take a look at the available models: <a href="https://huggingface.co/models?other=swinv2">https://huggingface.co/models?other=swinv2</a>.</p>

          <p>This particular checkpoint is Swin v1.</p>

          <p>As for your first question, you might need to update the initial projection
          layer, however note that this will require you to train this layer from
          scratch. It''s advised to use as many pre-trained weights as possible.</p>

          <p>As for your second question, we''re currently adding support for the
          AutoBackbone API, which allows you to easily extract feature maps from vision
          backbones, like Swin and ConvNext. For now, it''s advised you run a forward
          pass with <code>output_hidden_states=True</code> to get the intermediate
          features.</p>

          '
        raw: 'Hi,


          To use Swinv2, you can take a look at the available models: https://huggingface.co/models?other=swinv2.


          This particular checkpoint is Swin v1.


          As for your first question, you might need to update the initial projection
          layer, however note that this will require you to train this layer from
          scratch. It''s advised to use as many pre-trained weights as possible.


          As for your second question, we''re currently adding support for the AutoBackbone
          API, which allows you to easily extract feature maps from vision backbones,
          like Swin and ConvNext. For now, it''s advised you run a forward pass with
          `output_hidden_states=True` to get the intermediate features.'
        updatedAt: '2022-12-12T11:25:04.528Z'
      numEdits: 0
      reactions: []
    id: 63970f90931c47be1af4096c
    type: comment
  author: nielsr
  content: 'Hi,


    To use Swinv2, you can take a look at the available models: https://huggingface.co/models?other=swinv2.


    This particular checkpoint is Swin v1.


    As for your first question, you might need to update the initial projection layer,
    however note that this will require you to train this layer from scratch. It''s
    advised to use as many pre-trained weights as possible.


    As for your second question, we''re currently adding support for the AutoBackbone
    API, which allows you to easily extract feature maps from vision backbones, like
    Swin and ConvNext. For now, it''s advised you run a forward pass with `output_hidden_states=True`
    to get the intermediate features.'
  created_at: 2022-12-12 11:25:04+00:00
  edited: false
  hidden: false
  id: 63970f90931c47be1af4096c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: microsoft/swin-tiny-patch4-window7-224
repo_type: model
status: open
target_branch: null
title: how to use swin v2?
