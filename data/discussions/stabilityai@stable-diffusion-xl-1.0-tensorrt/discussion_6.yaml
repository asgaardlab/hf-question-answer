!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tintwotin
conflicting_files: null
created_at: 2023-08-28 11:08:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1732106613b89ea94b3f189bb73349d0.svg
      fullname: tin tin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tintwotin
      type: user
    createdAt: '2023-08-28T12:08:59.000Z'
    data:
      edited: false
      editors:
      - tintwotin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9058772921562195
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1732106613b89ea94b3f189bb73349d0.svg
          fullname: tin tin
          isHf: false
          isPro: false
          name: tintwotin
          type: user
        html: '<p>What is the hardware requirements to run this locally? </p>

          <p>Is it possible on a RTX2060 with 6 GB VRAM?</p>

          '
        raw: "What is the hardware requirements to run this locally? \r\n\r\nIs it\
          \ possible on a RTX2060 with 6 GB VRAM?"
        updatedAt: '2023-08-28T12:08:59.253Z'
      numEdits: 0
      reactions: []
    id: 64ec8e5b1704bc36897dd40d
    type: comment
  author: tintwotin
  content: "What is the hardware requirements to run this locally? \r\n\r\nIs it possible\
    \ on a RTX2060 with 6 GB VRAM?"
  created_at: 2023-08-28 11:08:59+00:00
  edited: false
  hidden: false
  id: 64ec8e5b1704bc36897dd40d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/AGyEW1YOHJvVCJagoSmsv.png?w=200&h=200&f=face
      fullname: "Phan Tu\u1EA5n Anh"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: doof-ferb
      type: user
    createdAt: '2023-08-28T13:34:53.000Z'
    data:
      edited: true
      editors:
      - doof-ferb
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9594851136207581
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/AGyEW1YOHJvVCJagoSmsv.png?w=200&h=200&f=face
          fullname: "Phan Tu\u1EA5n Anh"
          isHf: false
          isPro: false
          name: doof-ferb
          type: user
        html: '<p>in my test it need 10gb vram, possible with lesser vram if ram swap
          but much slower</p>

          <p>see my attempt: <a rel="nofollow" href="https://github.com/phineas-pta/SDXL-trt-win">https://github.com/phineas-pta/SDXL-trt-win</a></p>

          '
        raw: 'in my test it need 10gb vram, possible with lesser vram if ram swap
          but much slower


          see my attempt: https://github.com/phineas-pta/SDXL-trt-win'
        updatedAt: '2023-10-16T09:13:21.849Z'
      numEdits: 1
      reactions: []
    id: 64eca27dcfa36c8ac204febd
    type: comment
  author: doof-ferb
  content: 'in my test it need 10gb vram, possible with lesser vram if ram swap but
    much slower


    see my attempt: https://github.com/phineas-pta/SDXL-trt-win'
  created_at: 2023-08-28 12:34:53+00:00
  edited: true
  hidden: false
  id: 64eca27dcfa36c8ac204febd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dcc57ba5d43bf63dfe4ba1398b5f937a.svg
      fullname: piero aldo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: costatattooz
      type: user
    createdAt: '2023-10-16T20:33:17.000Z'
    data:
      edited: false
      editors:
      - costatattooz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8752337694168091
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dcc57ba5d43bf63dfe4ba1398b5f937a.svg
          fullname: piero aldo
          isHf: false
          isPro: false
          name: costatattooz
          type: user
        html: '<p>can this be installed on automatic1111? i got an rtx3060 12gb, and
          i installed the extension for tensorrt for automatic1111. I was able to
          convert 1.5 models to .trt format . How can i convert this? i saw multiple
          files. what is about that file of 5gb? I tried downloading the model.onnx
          for both model and refiner but can''t convert them. Please help im a noob.
          BTW: im using linux mint</p>

          '
        raw: 'can this be installed on automatic1111? i got an rtx3060 12gb, and i
          installed the extension for tensorrt for automatic1111. I was able to convert
          1.5 models to .trt format . How can i convert this? i saw multiple files.
          what is about that file of 5gb? I tried downloading the model.onnx for both
          model and refiner but can''t convert them. Please help im a noob. BTW: im
          using linux mint'
        updatedAt: '2023-10-16T20:33:17.847Z'
      numEdits: 0
      reactions: []
    id: 652d9e0dd786913fc7dad9dd
    type: comment
  author: costatattooz
  content: 'can this be installed on automatic1111? i got an rtx3060 12gb, and i installed
    the extension for tensorrt for automatic1111. I was able to convert 1.5 models
    to .trt format . How can i convert this? i saw multiple files. what is about that
    file of 5gb? I tried downloading the model.onnx for both model and refiner but
    can''t convert them. Please help im a noob. BTW: im using linux mint'
  created_at: 2023-10-16 19:33:17+00:00
  edited: false
  hidden: false
  id: 652d9e0dd786913fc7dad9dd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/AGyEW1YOHJvVCJagoSmsv.png?w=200&h=200&f=face
      fullname: "Phan Tu\u1EA5n Anh"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: doof-ferb
      type: user
    createdAt: '2023-10-17T18:52:37.000Z'
    data:
      edited: false
      editors:
      - doof-ferb
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6838308572769165
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/AGyEW1YOHJvVCJagoSmsv.png?w=200&h=200&f=face
          fullname: "Phan Tu\u1EA5n Anh"
          isHf: false
          isPro: false
          name: doof-ferb
          type: user
        html: '<p>this repo doesnt seem to be beginner friendly</p>

          <p>for a1111 use the new extension: <a rel="nofollow" href="https://github.com/NVIDIA/Stable-Diffusion-WebUI-TensorRT">https://github.com/NVIDIA/Stable-Diffusion-WebUI-TensorRT</a></p>

          '
        raw: 'this repo doesnt seem to be beginner friendly


          for a1111 use the new extension: https://github.com/NVIDIA/Stable-Diffusion-WebUI-TensorRT'
        updatedAt: '2023-10-17T18:52:37.593Z'
      numEdits: 0
      reactions: []
    id: 652ed7f517d03c316f654268
    type: comment
  author: doof-ferb
  content: 'this repo doesnt seem to be beginner friendly


    for a1111 use the new extension: https://github.com/NVIDIA/Stable-Diffusion-WebUI-TensorRT'
  created_at: 2023-10-17 17:52:37+00:00
  edited: false
  hidden: false
  id: 652ed7f517d03c316f654268
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: stabilityai/stable-diffusion-xl-1.0-tensorrt
repo_type: model
status: open
target_branch: null
title: Hardware requirements?
