!!python/object:huggingface_hub.community.DiscussionWithDetails
author: gardner
conflicting_files: null
created_at: 2023-06-21 03:27:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638581711769b7c4b10f0523/v95VFXJqueQ_pp9ZURu4R.jpeg?w=200&h=200&f=face
      fullname: Gardner Bickford
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gardner
      type: user
    createdAt: '2023-06-21T04:27:26.000Z'
    data:
      edited: false
      editors:
      - gardner
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7591055035591125
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638581711769b7c4b10f0523/v95VFXJqueQ_pp9ZURu4R.jpeg?w=200&h=200&f=face
          fullname: Gardner Bickford
          isHf: false
          isPro: false
          name: gardner
          type: user
        html: "<p>Hi there,<br>  thanks for publishing all these models. I just tried\
          \ this one out with <code>llama.cpp</code>. I pulled from the repo and rebuilt\
          \ with CUBLAS enabled and run with:</p>\n<pre><code>./build/bin/main -m\
          \ /home/user/src/llama.cpp/models/WizardCoder-15B/WizardCoder-15B-1.0.ggmlv3.q4_1.bin\
          \ -p \"Please tell me a story about a robot.\"\n</code></pre>\n<p>I tried\
          \ the <code>q4_0.bin</code> file as well with the same result.</p>\n<pre><code>$\
          \ git log -1\ncommit 049aa16b8c5c6d086246e4e6b9feb18de4fbd663 (HEAD -&gt;\
          \ master, origin/master, origin/HEAD)\nAuthor: Georgi Gerganov &lt;ggerganov@gmail.com&gt;\n\
          Date:   Tue Jun 20 19:05:54 2023 +0300\n\n    readme : add link to p1\n\
          </code></pre>\n"
        raw: "Hi there,\r\n  thanks for publishing all these models. I just tried\
          \ this one out with `llama.cpp`. I pulled from the repo and rebuilt with\
          \ CUBLAS enabled and run with:\r\n\r\n```\r\n./build/bin/main -m /home/user/src/llama.cpp/models/WizardCoder-15B/WizardCoder-15B-1.0.ggmlv3.q4_1.bin\
          \ -p \"Please tell me a story about a robot.\"\r\n```\r\n\r\nI tried the\
          \ `q4_0.bin` file as well with the same result.\r\n\r\n```\r\n$ git log\
          \ -1\r\ncommit 049aa16b8c5c6d086246e4e6b9feb18de4fbd663 (HEAD -> master,\
          \ origin/master, origin/HEAD)\r\nAuthor: Georgi Gerganov <ggerganov@gmail.com>\r\
          \nDate:   Tue Jun 20 19:05:54 2023 +0300\r\n\r\n    readme : add link to\
          \ p1\r\n```"
        updatedAt: '2023-06-21T04:27:26.064Z'
      numEdits: 0
      reactions: []
    id: 64927c2e31aa83e4e531a3cb
    type: comment
  author: gardner
  content: "Hi there,\r\n  thanks for publishing all these models. I just tried this\
    \ one out with `llama.cpp`. I pulled from the repo and rebuilt with CUBLAS enabled\
    \ and run with:\r\n\r\n```\r\n./build/bin/main -m /home/user/src/llama.cpp/models/WizardCoder-15B/WizardCoder-15B-1.0.ggmlv3.q4_1.bin\
    \ -p \"Please tell me a story about a robot.\"\r\n```\r\n\r\nI tried the `q4_0.bin`\
    \ file as well with the same result.\r\n\r\n```\r\n$ git log -1\r\ncommit 049aa16b8c5c6d086246e4e6b9feb18de4fbd663\
    \ (HEAD -> master, origin/master, origin/HEAD)\r\nAuthor: Georgi Gerganov <ggerganov@gmail.com>\r\
    \nDate:   Tue Jun 20 19:05:54 2023 +0300\r\n\r\n    readme : add link to p1\r\n\
    ```"
  created_at: 2023-06-21 03:27:26+00:00
  edited: false
  hidden: false
  id: 64927c2e31aa83e4e531a3cb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-21T07:30:08.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8911498188972473
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>They''re not compatible with llama.cpp - please see the README for
          a list of software it will work with.</p>

          '
        raw: They're not compatible with llama.cpp - please see the README for a list
          of software it will work with.
        updatedAt: '2023-06-21T07:30:08.554Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - gardner
    id: 6492a700d305b1c4ee92ad61
    type: comment
  author: TheBloke
  content: They're not compatible with llama.cpp - please see the README for a list
    of software it will work with.
  created_at: 2023-06-21 06:30:08+00:00
  edited: false
  hidden: false
  id: 6492a700d305b1c4ee92ad61
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638581711769b7c4b10f0523/v95VFXJqueQ_pp9ZURu4R.jpeg?w=200&h=200&f=face
      fullname: Gardner Bickford
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gardner
      type: user
    createdAt: '2024-01-18T00:36:45.000Z'
    data:
      status: closed
    id: 65a8729d5e3029d4d5954bfa
    type: status-change
  author: gardner
  created_at: 2024-01-18 00:36:45+00:00
  id: 65a8729d5e3029d4d5954bfa
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: TheBloke/WizardCoder-15B-1.0-GGML
repo_type: model
status: closed
target_branch: null
title: '"error loading model: missing tok_embeddings.weight" with llama.cpp'
