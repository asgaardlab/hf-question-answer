!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rdp-studio
conflicting_files: null
created_at: 2022-10-11 00:51:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
      fullname: Launchpad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rdp-studio
      type: user
    createdAt: '2022-10-11T01:51:30.000Z'
    data:
      edited: false
      editors:
      - rdp-studio
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
          fullname: Launchpad
          isHf: false
          isPro: false
          name: rdp-studio
          type: user
        html: '<p>Is there an onnx version of the model?</p>

          '
        raw: Is there an onnx version of the model?
        updatedAt: '2022-10-11T01:51:30.200Z'
      numEdits: 0
      reactions: []
    id: 6344cc22ba3e1a1973d970bc
    type: comment
  author: rdp-studio
  content: Is there an onnx version of the model?
  created_at: 2022-10-11 00:51:30+00:00
  edited: false
  hidden: false
  id: 6344cc22ba3e1a1973d970bc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
      fullname: ShadowPower
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShadowPower
      type: user
    createdAt: '2022-10-11T08:03:25.000Z'
    data:
      edited: false
      editors:
      - ShadowPower
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
          fullname: ShadowPower
          isHf: false
          isPro: false
          name: ShadowPower
          type: user
        html: '<p>You can try this: <a href="https://huggingface.co/ShadowPower/waifu-diffusion-v1-3-onnx">https://huggingface.co/ShadowPower/waifu-diffusion-v1-3-onnx</a></p>

          '
        raw: 'You can try this: https://huggingface.co/ShadowPower/waifu-diffusion-v1-3-onnx'
        updatedAt: '2022-10-11T08:03:25.265Z'
      numEdits: 0
      reactions: []
    id: 6345234dfeba4bdba59d43ee
    type: comment
  author: ShadowPower
  content: 'You can try this: https://huggingface.co/ShadowPower/waifu-diffusion-v1-3-onnx'
  created_at: 2022-10-11 07:03:25+00:00
  edited: false
  hidden: false
  id: 6345234dfeba4bdba59d43ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
      fullname: Launchpad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rdp-studio
      type: user
    createdAt: '2022-10-11T08:36:13.000Z'
    data:
      edited: false
      editors:
      - rdp-studio
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
          fullname: Launchpad
          isHf: false
          isPro: false
          name: rdp-studio
          type: user
        html: '<blockquote>

          <p>You can try this: <a href="https://huggingface.co/ShadowPower/waifu-diffusion-v1-3-onnx">https://huggingface.co/ShadowPower/waifu-diffusion-v1-3-onnx</a></p>

          </blockquote>

          <p>Yes, this is good. But I want a model that is compatible with the <code>StableDiffusionOnnxPipeline</code>
          that comes with diffusers.</p>

          '
        raw: '> You can try this: https://huggingface.co/ShadowPower/waifu-diffusion-v1-3-onnx


          Yes, this is good. But I want a model that is compatible with the `StableDiffusionOnnxPipeline`
          that comes with diffusers.'
        updatedAt: '2022-10-11T08:36:13.591Z'
      numEdits: 0
      reactions: []
    id: 63452afda05b51f7ded2f2c0
    type: comment
  author: rdp-studio
  content: '> You can try this: https://huggingface.co/ShadowPower/waifu-diffusion-v1-3-onnx


    Yes, this is good. But I want a model that is compatible with the `StableDiffusionOnnxPipeline`
    that comes with diffusers.'
  created_at: 2022-10-11 07:36:13+00:00
  edited: false
  hidden: false
  id: 63452afda05b51f7ded2f2c0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
      fullname: ShadowPower
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShadowPower
      type: user
    createdAt: '2022-10-11T08:58:07.000Z'
    data:
      edited: false
      editors:
      - ShadowPower
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
          fullname: ShadowPower
          isHf: false
          isPro: false
          name: ShadowPower
          type: user
        html: '<p>I just converted to a version that might work for diffusers, here
          it is: <a href="https://huggingface.co/ShadowPower/waifu-diffusion-diffusers-onnx-v1-3">https://huggingface.co/ShadowPower/waifu-diffusion-diffusers-onnx-v1-3</a></p>

          '
        raw: 'I just converted to a version that might work for diffusers, here it
          is: https://huggingface.co/ShadowPower/waifu-diffusion-diffusers-onnx-v1-3'
        updatedAt: '2022-10-11T08:58:07.369Z'
      numEdits: 0
      reactions: []
    id: 6345301f4969a147fe24677f
    type: comment
  author: ShadowPower
  content: 'I just converted to a version that might work for diffusers, here it is:
    https://huggingface.co/ShadowPower/waifu-diffusion-diffusers-onnx-v1-3'
  created_at: 2022-10-11 07:58:07+00:00
  edited: false
  hidden: false
  id: 6345301f4969a147fe24677f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
      fullname: Launchpad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rdp-studio
      type: user
    createdAt: '2022-10-11T11:10:17.000Z'
    data:
      edited: false
      editors:
      - rdp-studio
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
          fullname: Launchpad
          isHf: false
          isPro: false
          name: rdp-studio
          type: user
        html: '<blockquote>

          <p>I just converted to a version that might work for diffusers, here it
          is: <a href="https://huggingface.co/ShadowPower/waifu-diffusion-diffusers-onnx-v1-3">https://huggingface.co/ShadowPower/waifu-diffusion-diffusers-onnx-v1-3</a></p>

          </blockquote>

          <p>Thank you. I''ll try it now.</p>

          '
        raw: '> I just converted to a version that might work for diffusers, here
          it is: https://huggingface.co/ShadowPower/waifu-diffusion-diffusers-onnx-v1-3


          Thank you. I''ll try it now.'
        updatedAt: '2022-10-11T11:10:17.877Z'
      numEdits: 0
      reactions: []
    id: 63454f193cc8a5caf9b5ff67
    type: comment
  author: rdp-studio
  content: '> I just converted to a version that might work for diffusers, here it
    is: https://huggingface.co/ShadowPower/waifu-diffusion-diffusers-onnx-v1-3


    Thank you. I''ll try it now.'
  created_at: 2022-10-11 10:10:17+00:00
  edited: false
  hidden: false
  id: 63454f193cc8a5caf9b5ff67
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
      fullname: Launchpad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rdp-studio
      type: user
    createdAt: '2022-10-11T11:27:23.000Z'
    data:
      edited: true
      editors:
      - rdp-studio
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
          fullname: Launchpad
          isHf: false
          isPro: false
          name: rdp-studio
          type: user
        html: "<blockquote>\n<p>I just converted to a version that might work for\
          \ diffusers, here it is: <a href=\"https://huggingface.co/ShadowPower/waifu-diffusion-diffusers-onnx-v1-3\"\
          >https://huggingface.co/ShadowPower/waifu-diffusion-diffusers-onnx-v1-3</a></p>\n\
          </blockquote>\n<pre><code>Traceback (most recent call last):\n  File \"\
          C:\\Data\\AI\\picgen\\server.py\", line 65, in run\n    generate(data[\"\
          prompt\"], data[\"taskid\"])\n  File \"C:\\Data\\AI\\picgen\\server.py\"\
          , line 149, in generate\n    file_like = infer(prompt)[0]\n  File \"C:\\\
          Data\\AI\\picgen\\server.py\", line 124, in infer\n    images = pipe([prompt]\
          \ * nums, height=height, width=width, num_inference_steps=steps, generator=generator,\
          \ guidance_scale=guidance_scale )[\"sample\"]\n  File \"C:\\Users\\17192\\\
          AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\diffusers\\\
          pipelines\\stable_diffusion\\pipeline_stable_diffusion_onnx.py\", line 167,\
          \ in __call__\n    noise_pred = self.unet(\n  File \"C:\\Users\\17192\\\
          AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\diffusers\\\
          onnx_utils.py\", line 46, in __call__\n    return self.model.run(None, inputs)\n\
          \  File \"C:\\Users\\17192\\AppData\\Local\\Programs\\Python\\Python310\\\
          lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\"\
          , line 200, in run\n    return self._sess.run(output_names, input_feed,\
          \ run_options)\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument:\
          \ [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type.\
          \ Actual: (tensor(int32)) , expected: (tensor(int64))\n</code></pre>\n<p>Whats\
          \ wrong?</p>\n<p>(I am using the dml provider of onnx)</p>\n"
        raw: "> I just converted to a version that might work for diffusers, here\
          \ it is: https://huggingface.co/ShadowPower/waifu-diffusion-diffusers-onnx-v1-3\n\
          \n```\nTraceback (most recent call last):\n  File \"C:\\Data\\AI\\picgen\\\
          server.py\", line 65, in run\n    generate(data[\"prompt\"], data[\"taskid\"\
          ])\n  File \"C:\\Data\\AI\\picgen\\server.py\", line 149, in generate\n\
          \    file_like = infer(prompt)[0]\n  File \"C:\\Data\\AI\\picgen\\server.py\"\
          , line 124, in infer\n    images = pipe([prompt] * nums, height=height,\
          \ width=width, num_inference_steps=steps, generator=generator, guidance_scale=guidance_scale\
          \ )[\"sample\"]\n  File \"C:\\Users\\17192\\AppData\\Local\\Programs\\Python\\\
          Python310\\lib\\site-packages\\diffusers\\pipelines\\stable_diffusion\\\
          pipeline_stable_diffusion_onnx.py\", line 167, in __call__\n    noise_pred\
          \ = self.unet(\n  File \"C:\\Users\\17192\\AppData\\Local\\Programs\\Python\\\
          Python310\\lib\\site-packages\\diffusers\\onnx_utils.py\", line 46, in __call__\n\
          \    return self.model.run(None, inputs)\n  File \"C:\\Users\\17192\\AppData\\\
          Local\\Programs\\Python\\Python310\\lib\\site-packages\\onnxruntime\\capi\\\
          onnxruntime_inference_collection.py\", line 200, in run\n    return self._sess.run(output_names,\
          \ input_feed, run_options)\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument:\
          \ [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type.\
          \ Actual: (tensor(int32)) , expected: (tensor(int64))\n```\nWhats wrong?\n\
          \n(I am using the dml provider of onnx)"
        updatedAt: '2022-10-11T11:47:13.332Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F92F"
        users:
        - rdp-studio
    id: 6345531b7393804ce0d04a64
    type: comment
  author: rdp-studio
  content: "> I just converted to a version that might work for diffusers, here it\
    \ is: https://huggingface.co/ShadowPower/waifu-diffusion-diffusers-onnx-v1-3\n\
    \n```\nTraceback (most recent call last):\n  File \"C:\\Data\\AI\\picgen\\server.py\"\
    , line 65, in run\n    generate(data[\"prompt\"], data[\"taskid\"])\n  File \"\
    C:\\Data\\AI\\picgen\\server.py\", line 149, in generate\n    file_like = infer(prompt)[0]\n\
    \  File \"C:\\Data\\AI\\picgen\\server.py\", line 124, in infer\n    images =\
    \ pipe([prompt] * nums, height=height, width=width, num_inference_steps=steps,\
    \ generator=generator, guidance_scale=guidance_scale )[\"sample\"]\n  File \"\
    C:\\Users\\17192\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\\
    diffusers\\pipelines\\stable_diffusion\\pipeline_stable_diffusion_onnx.py\", line\
    \ 167, in __call__\n    noise_pred = self.unet(\n  File \"C:\\Users\\17192\\AppData\\\
    Local\\Programs\\Python\\Python310\\lib\\site-packages\\diffusers\\onnx_utils.py\"\
    , line 46, in __call__\n    return self.model.run(None, inputs)\n  File \"C:\\\
    Users\\17192\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\\
    onnxruntime\\capi\\onnxruntime_inference_collection.py\", line 200, in run\n \
    \   return self._sess.run(output_names, input_feed, run_options)\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument:\
    \ [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type. Actual:\
    \ (tensor(int32)) , expected: (tensor(int64))\n```\nWhats wrong?\n\n(I am using\
    \ the dml provider of onnx)"
  created_at: 2022-10-11 10:27:23+00:00
  edited: true
  hidden: false
  id: 6345531b7393804ce0d04a64
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
      fullname: ShadowPower
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShadowPower
      type: user
    createdAt: '2022-10-11T12:29:58.000Z'
    data:
      edited: false
      editors:
      - ShadowPower
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
          fullname: ShadowPower
          isHf: false
          isPro: false
          name: ShadowPower
          type: user
        html: '<p>It looks like a data type mismatch error, I''ll try it myself later.</p>

          '
        raw: It looks like a data type mismatch error, I'll try it myself later.
        updatedAt: '2022-10-11T12:29:58.424Z'
      numEdits: 0
      reactions: []
    id: 634561c6547c70e4b7cbc215
    type: comment
  author: ShadowPower
  content: It looks like a data type mismatch error, I'll try it myself later.
  created_at: 2022-10-11 11:29:58+00:00
  edited: false
  hidden: false
  id: 634561c6547c70e4b7cbc215
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
      fullname: ShadowPower
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShadowPower
      type: user
    createdAt: '2022-10-11T13:17:11.000Z'
    data:
      edited: true
      editors:
      - ShadowPower
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
          fullname: ShadowPower
          isHf: false
          isPro: false
          name: ShadowPower
          type: user
        html: "<p>It seems that the scheduler will use PyTorch's tensor type by default,\
          \ which is not supported by StableDiffusionOnnxPipeline.<br>So you need\
          \ to create one manually to avoid using the default scheduler.<br>This is\
          \ an example:</p>\n<pre><code class=\"language-python\"><span class=\"hljs-keyword\"\
          >from</span> diffusers <span class=\"hljs-keyword\">import</span> StableDiffusionOnnxPipeline,\
          \ PNDMScheduler\nmodel_path = <span class=\"hljs-string\">r'ShadowPower/waifu-diffusion-diffusers-onnx-v1-3'</span>\n\
          \nscheduler = PNDMScheduler(\n    beta_start=<span class=\"hljs-number\"\
          >0.00085</span>,\n    beta_end=<span class=\"hljs-number\">0.012</span>,\n\
          \    beta_schedule=<span class=\"hljs-string\">'scaled_linear'</span>,\n\
          \    skip_prk_steps=<span class=\"hljs-literal\">True</span>,\n    tensor_format=<span\
          \ class=\"hljs-string\">'np'</span>\n)\npipe = StableDiffusionOnnxPipeline.from_pretrained(\n\
          \    model_path,\n    provider=<span class=\"hljs-string\">\"CPUExecutionProvider\"\
          </span>,\n    scheduler=scheduler\n)\n\n<span class=\"hljs-keyword\">if</span>\
          \ __name__ == <span class=\"hljs-string\">'__main__'</span>:\n    prompt\
          \ = <span class=\"hljs-string\">\"1girl,  hakurei reimu\"</span>\n    image\
          \ = pipe(prompt).images[<span class=\"hljs-number\">0</span>]\n</code></pre>\n"
        raw: "It seems that the scheduler will use PyTorch's tensor type by default,\
          \ which is not supported by StableDiffusionOnnxPipeline.\nSo you need to\
          \ create one manually to avoid using the default scheduler.\nThis is an\
          \ example:\n```python\nfrom diffusers import StableDiffusionOnnxPipeline,\
          \ PNDMScheduler\nmodel_path = r'ShadowPower/waifu-diffusion-diffusers-onnx-v1-3'\n\
          \nscheduler = PNDMScheduler(\n    beta_start=0.00085,\n    beta_end=0.012,\n\
          \    beta_schedule='scaled_linear',\n    skip_prk_steps=True,\n    tensor_format='np'\n\
          )\npipe = StableDiffusionOnnxPipeline.from_pretrained(\n    model_path,\n\
          \    provider=\"CPUExecutionProvider\",\n    scheduler=scheduler\n)\n\n\
          if __name__ == '__main__':\n    prompt = \"1girl,  hakurei reimu\"\n   \
          \ image = pipe(prompt).images[0]\n```"
        updatedAt: '2022-10-11T13:19:54.962Z'
      numEdits: 1
      reactions: []
    id: 63456cd77393804ce0d12220
    type: comment
  author: ShadowPower
  content: "It seems that the scheduler will use PyTorch's tensor type by default,\
    \ which is not supported by StableDiffusionOnnxPipeline.\nSo you need to create\
    \ one manually to avoid using the default scheduler.\nThis is an example:\n```python\n\
    from diffusers import StableDiffusionOnnxPipeline, PNDMScheduler\nmodel_path =\
    \ r'ShadowPower/waifu-diffusion-diffusers-onnx-v1-3'\n\nscheduler = PNDMScheduler(\n\
    \    beta_start=0.00085,\n    beta_end=0.012,\n    beta_schedule='scaled_linear',\n\
    \    skip_prk_steps=True,\n    tensor_format='np'\n)\npipe = StableDiffusionOnnxPipeline.from_pretrained(\n\
    \    model_path,\n    provider=\"CPUExecutionProvider\",\n    scheduler=scheduler\n\
    )\n\nif __name__ == '__main__':\n    prompt = \"1girl,  hakurei reimu\"\n    image\
    \ = pipe(prompt).images[0]\n```"
  created_at: 2022-10-11 12:17:11+00:00
  edited: true
  hidden: false
  id: 63456cd77393804ce0d12220
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
      fullname: Launchpad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rdp-studio
      type: user
    createdAt: '2022-10-11T14:04:13.000Z'
    data:
      edited: true
      editors:
      - rdp-studio
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
          fullname: Launchpad
          isHf: false
          isPro: false
          name: rdp-studio
          type: user
        html: "<blockquote>\n<p>It seems that the scheduler will use PyTorch's tensor\
          \ type by default, which is not supported by StableDiffusionOnnxPipeline.<br>So\
          \ you need to create one manually to avoid using the default scheduler.<br>This\
          \ is an example:</p>\n<pre><code class=\"language-python\"><span class=\"\
          hljs-keyword\">from</span> diffusers <span class=\"hljs-keyword\">import</span>\
          \ StableDiffusionOnnxPipeline, PNDMScheduler\nmodel_path = <span class=\"\
          hljs-string\">r'ShadowPower/waifu-diffusion-diffusers-onnx-v1-3'</span>\n\
          \nscheduler = PNDMScheduler(\n    beta_start=<span class=\"hljs-number\"\
          >0.00085</span>,\n    beta_end=<span class=\"hljs-number\">0.012</span>,\n\
          \    beta_schedule=<span class=\"hljs-string\">'scaled_linear'</span>,\n\
          \    skip_prk_steps=<span class=\"hljs-literal\">True</span>,\n    tensor_format=<span\
          \ class=\"hljs-string\">'np'</span>\n)\npipe = StableDiffusionOnnxPipeline.from_pretrained(\n\
          \    model_path,\n    provider=<span class=\"hljs-string\">\"CPUExecutionProvider\"\
          </span>,\n    scheduler=scheduler\n)\n\n<span class=\"hljs-keyword\">if</span>\
          \ __name__ == <span class=\"hljs-string\">'__main__'</span>:\n    prompt\
          \ = <span class=\"hljs-string\">\"1girl,  hakurei reimu\"</span>\n    image\
          \ = pipe(prompt).images[<span class=\"hljs-number\">0</span>]\n</code></pre>\n\
          </blockquote>\n<pre><code>022-10-11 21:58:45.5907994 [E:onnxruntime:, sequential_executor.cc:368\
          \ onnxruntime::SequentialExecutor::Execute] Non-zero status code returned\
          \ while running InstanceNormalization node. Name:'InstanceNormalization_44'\
          \ Status Message: D:\\a\\_work\\1\\s\\onnxruntime\\core\\providers\\dml\\\
          DmlExecutionProvider\\src\\MLOperatorAuthorImpl.cpp(1857)\\onnxruntime_pybind11_stat\
          \  0%|                                                                 \
          \                          | 0/51 [00:00&lt;?, ?it/s]\nWorker thread-0:\
          \ error:\nTraceback (most recent call last):\n  File \"C:\\Data\\AI\\picgen\\\
          server.py\", line 78, in run\n    generate(data[\"prompt\"], data[\"taskid\"\
          ])\n  File \"C:\\Data\\AI\\picgen\\server.py\", line 162, in generate\n\
          \    file_like = infer(prompt)[0]\n  File \"C:\\Data\\AI\\picgen\\server.py\"\
          , line 137, in infer\n    images = pipe([prompt] * nums, height=height,\
          \ width=width, num_inference_steps=steps, generator=generator, guidance_scale=guidance_scale\
          \ )[\"sample\"]\n  File \"C:\\Users\\17192\\AppData\\Local\\Programs\\Python\\\
          Python310\\lib\\site-packages\\diffusers\\pipelines\\stable_diffusion\\\
          pipeline_stable_diffusion_onnx.py\", line 167, in __call__\n    noise_pred\
          \ = self.unet(\n  File \"C:\\Users\\17192\\AppData\\Local\\Programs\\Python\\\
          Python310\\lib\\site-packages\\diffusers\\onnx_utils.py\", line 46, in __call__\n\
          \    return self.model.run(None, inputs)\n  File \"C:\\Users\\17192\\AppData\\\
          Local\\Programs\\Python\\Python310\\lib\\site-packages\\onnxruntime\\capi\\\
          onnxruntime_inference_collection.py\", line 200, in run\n    return self._sess.run(output_names,\
          \ input_feed, run_options)\nonnxruntime.capi.onnxruntime_pybind11_state.RuntimeException\n\
          </code></pre>\n<p>An error is still reported when using the <code>DmlExecutionProvider</code>\
          \ provider. <code>CPUExecutionProvider</code> running normally.</p>\n<p>Supplement:</p>\n\
          <p>When running with the CPU, it seems that a black image is returned. (No\
          \ NSFW detected)</p>\n"
        raw: "> It seems that the scheduler will use PyTorch's tensor type by default,\
          \ which is not supported by StableDiffusionOnnxPipeline.\n> So you need\
          \ to create one manually to avoid using the default scheduler.\n> This is\
          \ an example:\n> ```python\n> from diffusers import StableDiffusionOnnxPipeline,\
          \ PNDMScheduler\n> model_path = r'ShadowPower/waifu-diffusion-diffusers-onnx-v1-3'\n\
          > \n> scheduler = PNDMScheduler(\n>     beta_start=0.00085,\n>     beta_end=0.012,\n\
          >     beta_schedule='scaled_linear',\n>     skip_prk_steps=True,\n>    \
          \ tensor_format='np'\n> )\n> pipe = StableDiffusionOnnxPipeline.from_pretrained(\n\
          >     model_path,\n>     provider=\"CPUExecutionProvider\",\n>     scheduler=scheduler\n\
          > )\n> \n> if __name__ == '__main__':\n>     prompt = \"1girl,  hakurei\
          \ reimu\"\n>     image = pipe(prompt).images[0]\n> ```\n\n```\n022-10-11\
          \ 21:58:45.5907994 [E:onnxruntime:, sequential_executor.cc:368 onnxruntime::SequentialExecutor::Execute]\
          \ Non-zero status code returned while running InstanceNormalization node.\
          \ Name:'InstanceNormalization_44' Status Message: D:\\a\\_work\\1\\s\\onnxruntime\\\
          core\\providers\\dml\\DmlExecutionProvider\\src\\MLOperatorAuthorImpl.cpp(1857)\\\
          onnxruntime_pybind11_stat  0%|                                         \
          \                                                  | 0/51 [00:00<?, ?it/s]\n\
          Worker thread-0: error:\nTraceback (most recent call last):\n  File \"C:\\\
          Data\\AI\\picgen\\server.py\", line 78, in run\n    generate(data[\"prompt\"\
          ], data[\"taskid\"])\n  File \"C:\\Data\\AI\\picgen\\server.py\", line 162,\
          \ in generate\n    file_like = infer(prompt)[0]\n  File \"C:\\Data\\AI\\\
          picgen\\server.py\", line 137, in infer\n    images = pipe([prompt] * nums,\
          \ height=height, width=width, num_inference_steps=steps, generator=generator,\
          \ guidance_scale=guidance_scale )[\"sample\"]\n  File \"C:\\Users\\17192\\\
          AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\diffusers\\\
          pipelines\\stable_diffusion\\pipeline_stable_diffusion_onnx.py\", line 167,\
          \ in __call__\n    noise_pred = self.unet(\n  File \"C:\\Users\\17192\\\
          AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\diffusers\\\
          onnx_utils.py\", line 46, in __call__\n    return self.model.run(None, inputs)\n\
          \  File \"C:\\Users\\17192\\AppData\\Local\\Programs\\Python\\Python310\\\
          lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\"\
          , line 200, in run\n    return self._sess.run(output_names, input_feed,\
          \ run_options)\nonnxruntime.capi.onnxruntime_pybind11_state.RuntimeException\n\
          ```\n\nAn error is still reported when using the `DmlExecutionProvider`\
          \ provider. `CPUExecutionProvider` running normally.\n\nSupplement:\n\n\
          When running with the CPU, it seems that a black image is returned. (No\
          \ NSFW detected)"
        updatedAt: '2022-10-11T14:14:06.019Z'
      numEdits: 2
      reactions: []
    id: 634577dd43f4f2d2ed0ea00a
    type: comment
  author: rdp-studio
  content: "> It seems that the scheduler will use PyTorch's tensor type by default,\
    \ which is not supported by StableDiffusionOnnxPipeline.\n> So you need to create\
    \ one manually to avoid using the default scheduler.\n> This is an example:\n\
    > ```python\n> from diffusers import StableDiffusionOnnxPipeline, PNDMScheduler\n\
    > model_path = r'ShadowPower/waifu-diffusion-diffusers-onnx-v1-3'\n> \n> scheduler\
    \ = PNDMScheduler(\n>     beta_start=0.00085,\n>     beta_end=0.012,\n>     beta_schedule='scaled_linear',\n\
    >     skip_prk_steps=True,\n>     tensor_format='np'\n> )\n> pipe = StableDiffusionOnnxPipeline.from_pretrained(\n\
    >     model_path,\n>     provider=\"CPUExecutionProvider\",\n>     scheduler=scheduler\n\
    > )\n> \n> if __name__ == '__main__':\n>     prompt = \"1girl,  hakurei reimu\"\
    \n>     image = pipe(prompt).images[0]\n> ```\n\n```\n022-10-11 21:58:45.5907994\
    \ [E:onnxruntime:, sequential_executor.cc:368 onnxruntime::SequentialExecutor::Execute]\
    \ Non-zero status code returned while running InstanceNormalization node. Name:'InstanceNormalization_44'\
    \ Status Message: D:\\a\\_work\\1\\s\\onnxruntime\\core\\providers\\dml\\DmlExecutionProvider\\\
    src\\MLOperatorAuthorImpl.cpp(1857)\\onnxruntime_pybind11_stat  0%|          \
    \                                                                            \
    \     | 0/51 [00:00<?, ?it/s]\nWorker thread-0: error:\nTraceback (most recent\
    \ call last):\n  File \"C:\\Data\\AI\\picgen\\server.py\", line 78, in run\n \
    \   generate(data[\"prompt\"], data[\"taskid\"])\n  File \"C:\\Data\\AI\\picgen\\\
    server.py\", line 162, in generate\n    file_like = infer(prompt)[0]\n  File \"\
    C:\\Data\\AI\\picgen\\server.py\", line 137, in infer\n    images = pipe([prompt]\
    \ * nums, height=height, width=width, num_inference_steps=steps, generator=generator,\
    \ guidance_scale=guidance_scale )[\"sample\"]\n  File \"C:\\Users\\17192\\AppData\\\
    Local\\Programs\\Python\\Python310\\lib\\site-packages\\diffusers\\pipelines\\\
    stable_diffusion\\pipeline_stable_diffusion_onnx.py\", line 167, in __call__\n\
    \    noise_pred = self.unet(\n  File \"C:\\Users\\17192\\AppData\\Local\\Programs\\\
    Python\\Python310\\lib\\site-packages\\diffusers\\onnx_utils.py\", line 46, in\
    \ __call__\n    return self.model.run(None, inputs)\n  File \"C:\\Users\\17192\\\
    AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\onnxruntime\\\
    capi\\onnxruntime_inference_collection.py\", line 200, in run\n    return self._sess.run(output_names,\
    \ input_feed, run_options)\nonnxruntime.capi.onnxruntime_pybind11_state.RuntimeException\n\
    ```\n\nAn error is still reported when using the `DmlExecutionProvider` provider.\
    \ `CPUExecutionProvider` running normally.\n\nSupplement:\n\nWhen running with\
    \ the CPU, it seems that a black image is returned. (No NSFW detected)"
  created_at: 2022-10-11 13:04:13+00:00
  edited: true
  hidden: false
  id: 634577dd43f4f2d2ed0ea00a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
      fullname: ShadowPower
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShadowPower
      type: user
    createdAt: '2022-10-11T14:32:15.000Z'
    data:
      edited: true
      editors:
      - ShadowPower
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
          fullname: ShadowPower
          isHf: false
          isPro: false
          name: ShadowPower
          type: user
        html: '<p>This is a bug in onnxruntime-directml, you can try using the nightly
          build version instead.<br><a rel="nofollow" href="https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ORT-Nightly/PyPI/ort-nightly-directml">https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ORT-Nightly/PyPI/ort-nightly-directml</a><br>I''m
          not sure it works properly, just that I found it on Google.</p>

          '
        raw: 'This is a bug in onnxruntime-directml, you can try using the nightly
          build version instead.

          https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ORT-Nightly/PyPI/ort-nightly-directml

          I''m not sure it works properly, just that I found it on Google.'
        updatedAt: '2022-10-11T14:37:13.429Z'
      numEdits: 1
      reactions: []
    id: 63457e6fac1cb29fb2a69ca7
    type: comment
  author: ShadowPower
  content: 'This is a bug in onnxruntime-directml, you can try using the nightly build
    version instead.

    https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ORT-Nightly/PyPI/ort-nightly-directml

    I''m not sure it works properly, just that I found it on Google.'
  created_at: 2022-10-11 13:32:15+00:00
  edited: true
  hidden: false
  id: 63457e6fac1cb29fb2a69ca7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
      fullname: Launchpad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rdp-studio
      type: user
    createdAt: '2022-10-11T14:39:46.000Z'
    data:
      edited: true
      editors:
      - rdp-studio
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
          fullname: Launchpad
          isHf: false
          isPro: false
          name: rdp-studio
          type: user
        html: '<blockquote>

          <p>This is a bug in onnxruntime-directml, you can try using the nightly
          build version instead.<br><a rel="nofollow" href="https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ORT-Nightly/PyPI/ort-nightly-directml">https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ORT-Nightly/PyPI/ort-nightly-directml</a><br>I''m
          not sure it works properly, just that I found it on Google.</p>

          </blockquote>

          <p>It works, thanks.</p>

          <p>I''m trying to see if it outputs normally</p>

          '
        raw: '> This is a bug in onnxruntime-directml, you can try using the nightly
          build version instead.

          > https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ORT-Nightly/PyPI/ort-nightly-directml

          > I''m not sure it works properly, just that I found it on Google.


          It works, thanks.


          I''m trying to see if it outputs normally'
        updatedAt: '2022-10-11T14:49:27.826Z'
      numEdits: 2
      reactions: []
    id: 63458032952248db8936d0e8
    type: comment
  author: rdp-studio
  content: '> This is a bug in onnxruntime-directml, you can try using the nightly
    build version instead.

    > https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ORT-Nightly/PyPI/ort-nightly-directml

    > I''m not sure it works properly, just that I found it on Google.


    It works, thanks.


    I''m trying to see if it outputs normally'
  created_at: 2022-10-11 13:39:46+00:00
  edited: true
  hidden: false
  id: 63458032952248db8936d0e8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
      fullname: ShadowPower
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShadowPower
      type: user
    createdAt: '2022-10-11T14:43:58.000Z'
    data:
      edited: false
      editors:
      - ShadowPower
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
          fullname: ShadowPower
          isHf: false
          isPro: false
          name: ShadowPower
          type: user
        html: '<p>Well, maybe we''ll just have to wait for the official Microsoft
          update.</p>

          '
        raw: Well, maybe we'll just have to wait for the official Microsoft update.
        updatedAt: '2022-10-11T14:43:58.138Z'
      numEdits: 0
      reactions: []
    id: 6345812eac1cb29fb2a6b9fc
    type: comment
  author: ShadowPower
  content: Well, maybe we'll just have to wait for the official Microsoft update.
  created_at: 2022-10-11 13:43:58+00:00
  edited: false
  hidden: false
  id: 6345812eac1cb29fb2a6b9fc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
      fullname: Launchpad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rdp-studio
      type: user
    createdAt: '2022-10-11T14:58:19.000Z'
    data:
      edited: false
      editors:
      - rdp-studio
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
          fullname: Launchpad
          isHf: false
          isPro: false
          name: rdp-studio
          type: user
        html: '<blockquote>

          <p>Well, maybe we''ll just have to wait for the official Microsoft update.</p>

          </blockquote>

          <p>The returned image is still black.</p>

          '
        raw: '> Well, maybe we''ll just have to wait for the official Microsoft update.


          The returned image is still black.'
        updatedAt: '2022-10-11T14:58:19.413Z'
      numEdits: 0
      reactions: []
    id: 6345848b5efccdc07f11cdf6
    type: comment
  author: rdp-studio
  content: '> Well, maybe we''ll just have to wait for the official Microsoft update.


    The returned image is still black.'
  created_at: 2022-10-11 13:58:19+00:00
  edited: false
  hidden: false
  id: 6345848b5efccdc07f11cdf6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
      fullname: ShadowPower
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShadowPower
      type: user
    createdAt: '2022-10-11T15:36:03.000Z'
    data:
      edited: false
      editors:
      - ShadowPower
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658901427929-noauth.png?w=200&h=200&f=face
          fullname: ShadowPower
          isHf: false
          isPro: false
          name: ShadowPower
          type: user
        html: '<p>There is no problem with CPUExecutionProvider, which may be related
          to the implementation of the DirectML version or the graphics card driver.<br>I
          don''t have any good ideas.</p>

          '
        raw: 'There is no problem with CPUExecutionProvider, which may be related
          to the implementation of the DirectML version or the graphics card driver.

          I don''t have any good ideas.'
        updatedAt: '2022-10-11T15:36:03.522Z'
      numEdits: 0
      reactions: []
    id: 63458d6343f4f2d2ed0f79ec
    type: comment
  author: ShadowPower
  content: 'There is no problem with CPUExecutionProvider, which may be related to
    the implementation of the DirectML version or the graphics card driver.

    I don''t have any good ideas.'
  created_at: 2022-10-11 14:36:03+00:00
  edited: false
  hidden: false
  id: 63458d6343f4f2d2ed0f79ec
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
      fullname: Launchpad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rdp-studio
      type: user
    createdAt: '2022-10-11T23:41:54.000Z'
    data:
      edited: true
      editors:
      - rdp-studio
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
          fullname: Launchpad
          isHf: false
          isPro: false
          name: rdp-studio
          type: user
        html: '<blockquote>

          <p>There is no problem with CPUExecutionProvider, which may be related to
          the implementation of the DirectML version or the graphics card driver.<br>I
          don''t have any good ideas.</p>

          </blockquote>

          <p>No, in my environment, the "CPUExecutionProvider" returns pure black
          image too.</p>

          <p>I will try to upgrade "onnxruntime-directml".</p>

          '
        raw: '> There is no problem with CPUExecutionProvider, which may be related
          to the implementation of the DirectML version or the graphics card driver.

          > I don''t have any good ideas.


          No, in my environment, the "CPUExecutionProvider" returns pure black image
          too.


          I will try to upgrade "onnxruntime-directml".'
        updatedAt: '2022-10-11T23:42:49.620Z'
      numEdits: 2
      reactions: []
    id: 6345ff424947a01c6b072645
    type: comment
  author: rdp-studio
  content: '> There is no problem with CPUExecutionProvider, which may be related
    to the implementation of the DirectML version or the graphics card driver.

    > I don''t have any good ideas.


    No, in my environment, the "CPUExecutionProvider" returns pure black image too.


    I will try to upgrade "onnxruntime-directml".'
  created_at: 2022-10-11 22:41:54+00:00
  edited: true
  hidden: false
  id: 6345ff424947a01c6b072645
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
      fullname: Launchpad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rdp-studio
      type: user
    createdAt: '2022-10-12T00:07:39.000Z'
    data:
      edited: true
      editors:
      - rdp-studio
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
          fullname: Launchpad
          isHf: false
          isPro: false
          name: rdp-studio
          type: user
        html: '<p>"CPUExecutionProvider" works.</p>

          <p>"DmlExecutionProvider" doesn''t work.</p>

          '
        raw: '"CPUExecutionProvider" works.


          "DmlExecutionProvider" doesn''t work.'
        updatedAt: '2022-10-12T05:43:59.603Z'
      numEdits: 1
      reactions: []
    id: 6346054b7393804ce0d67ed5
    type: comment
  author: rdp-studio
  content: '"CPUExecutionProvider" works.


    "DmlExecutionProvider" doesn''t work.'
  created_at: 2022-10-11 23:07:39+00:00
  edited: true
  hidden: false
  id: 6346054b7393804ce0d67ed5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/968d152900bfd1080a94c11cd1361697.svg
      fullname: F
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fpoole98765
      type: user
    createdAt: '2022-10-12T15:15:00.000Z'
    data:
      edited: false
      editors:
      - fpoole98765
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/968d152900bfd1080a94c11cd1361697.svg
          fullname: F
          isHf: false
          isPro: false
          name: fpoole98765
          type: user
        html: '<p>I generated my onnx by replacing the from_pretrained to "hakurei/waifu-diffusion"
          in the script I had, generated with no issue<br>Yes you need to use a nightly
          ort, I used dev20220908001 I think? or 20220917005. One of them had an issue
          and wouldn''t work. The other worked fine. have not attempted to update
          since.<br>If stable diffusion generates onnx for  you via whatever guide,
          then replacing the above should work the same.</p>

          '
        raw: 'I generated my onnx by replacing the from_pretrained to "hakurei/waifu-diffusion"
          in the script I had, generated with no issue

          Yes you need to use a nightly ort, I used dev20220908001 I think? or 20220917005.
          One of them had an issue and wouldn''t work. The other worked fine. have
          not attempted to update since.

          If stable diffusion generates onnx for  you via whatever guide, then replacing
          the above should work the same.'
        updatedAt: '2022-10-12T15:15:00.124Z'
      numEdits: 0
      reactions: []
    id: 6346d9f4fa79ac99a3ae83de
    type: comment
  author: fpoole98765
  content: 'I generated my onnx by replacing the from_pretrained to "hakurei/waifu-diffusion"
    in the script I had, generated with no issue

    Yes you need to use a nightly ort, I used dev20220908001 I think? or 20220917005.
    One of them had an issue and wouldn''t work. The other worked fine. have not attempted
    to update since.

    If stable diffusion generates onnx for  you via whatever guide, then replacing
    the above should work the same.'
  created_at: 2022-10-12 14:15:00+00:00
  edited: false
  hidden: false
  id: 6346d9f4fa79ac99a3ae83de
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
      fullname: Launchpad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rdp-studio
      type: user
    createdAt: '2022-10-12T23:54:19.000Z'
    data:
      edited: false
      editors:
      - rdp-studio
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a1f90198a95c9b96224f5/jNCDekrJMCAK2UcVvNAbK.jpeg?w=200&h=200&f=face
          fullname: Launchpad
          isHf: false
          isPro: false
          name: rdp-studio
          type: user
        html: '<blockquote>

          <p>I generated my onnx by replacing the from_pretrained to "hakurei/waifu-diffusion"
          in the script I had, generated with no issue<br>Yes you need to use a nightly
          ort, I used dev20220908001 I think? or 20220917005. One of them had an issue
          and wouldn''t work. The other worked fine. have not attempted to update
          since.<br>If stable diffusion generates onnx for  you via whatever guide,
          then replacing the above should work the same.</p>

          </blockquote>

          <p>Thanks, it works now!</p>

          '
        raw: '> I generated my onnx by replacing the from_pretrained to "hakurei/waifu-diffusion"
          in the script I had, generated with no issue

          > Yes you need to use a nightly ort, I used dev20220908001 I think? or 20220917005.
          One of them had an issue and wouldn''t work. The other worked fine. have
          not attempted to update since.

          > If stable diffusion generates onnx for  you via whatever guide, then replacing
          the above should work the same.


          Thanks, it works now!'
        updatedAt: '2022-10-12T23:54:19.182Z'
      numEdits: 0
      reactions: []
    id: 634753ab0a9fa1ac49985ecb
    type: comment
  author: rdp-studio
  content: '> I generated my onnx by replacing the from_pretrained to "hakurei/waifu-diffusion"
    in the script I had, generated with no issue

    > Yes you need to use a nightly ort, I used dev20220908001 I think? or 20220917005.
    One of them had an issue and wouldn''t work. The other worked fine. have not attempted
    to update since.

    > If stable diffusion generates onnx for  you via whatever guide, then replacing
    the above should work the same.


    Thanks, it works now!'
  created_at: 2022-10-12 22:54:19+00:00
  edited: false
  hidden: false
  id: 634753ab0a9fa1ac49985ecb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1638629276018-noauth.jpeg?w=200&h=200&f=face
      fullname: Feraidoon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NightMachinery
      type: user
    createdAt: '2022-10-14T17:10:24.000Z'
    data:
      edited: false
      editors:
      - NightMachinery
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1638629276018-noauth.jpeg?w=200&h=200&f=face
          fullname: Feraidoon
          isHf: false
          isPro: false
          name: NightMachinery
          type: user
        html: '<blockquote>

          <blockquote>

          <p>I generated my onnx by replacing the from_pretrained to "hakurei/waifu-diffusion"
          in the script I had, generated with no issue<br>Yes you need to use a nightly
          ort, I used dev20220908001 I think? or 20220917005. One of them had an issue
          and wouldn''t work. The other worked fine. have not attempted to update
          since.<br>If stable diffusion generates onnx for  you via whatever guide,
          then replacing the above should work the same.</p>

          </blockquote>

          <p>Thanks, it works now!</p>

          </blockquote>

          <p>Can you share all the steps necessary and the notebook?</p>

          <p>What''s the advantage of <code>onnx</code>?</p>

          <p>Is there a TPU/Flax version of this model? That version is very fast
          with the original SD model.</p>

          '
        raw: "> > I generated my onnx by replacing the from_pretrained to \"hakurei/waifu-diffusion\"\
          \ in the script I had, generated with no issue\n> > Yes you need to use\
          \ a nightly ort, I used dev20220908001 I think? or 20220917005. One of them\
          \ had an issue and wouldn't work. The other worked fine. have not attempted\
          \ to update since.\n> > If stable diffusion generates onnx for  you via\
          \ whatever guide, then replacing the above should work the same.\n> \n>\
          \ Thanks, it works now!\n\nCan you share all the steps necessary and the\
          \ notebook?\n\nWhat's the advantage of `onnx`?\n\nIs there a TPU/Flax version\
          \ of this model? That version is very fast with the original SD model."
        updatedAt: '2022-10-14T17:10:24.584Z'
      numEdits: 0
      reactions: []
    id: 6349980097fe7cc460334ba4
    type: comment
  author: NightMachinery
  content: "> > I generated my onnx by replacing the from_pretrained to \"hakurei/waifu-diffusion\"\
    \ in the script I had, generated with no issue\n> > Yes you need to use a nightly\
    \ ort, I used dev20220908001 I think? or 20220917005. One of them had an issue\
    \ and wouldn't work. The other worked fine. have not attempted to update since.\n\
    > > If stable diffusion generates onnx for  you via whatever guide, then replacing\
    \ the above should work the same.\n> \n> Thanks, it works now!\n\nCan you share\
    \ all the steps necessary and the notebook?\n\nWhat's the advantage of `onnx`?\n\
    \nIs there a TPU/Flax version of this model? That version is very fast with the\
    \ original SD model."
  created_at: 2022-10-14 16:10:24+00:00
  edited: false
  hidden: false
  id: 6349980097fe7cc460334ba4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 24
repo_id: hakurei/waifu-diffusion
repo_type: model
status: open
target_branch: null
title: Is there an onnx version of the model?
