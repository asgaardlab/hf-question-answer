!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MonsterMMORPG
conflicting_files: null
created_at: 2023-01-01 00:15:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672531901326-6345bd89fe134dfd7a0dba40.png?w=200&h=200&f=face
      fullname: "Furkan G\xF6z\xFCkara"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MonsterMMORPG
      type: user
    createdAt: '2023-01-01T00:15:03.000Z'
    data:
      edited: false
      editors:
      - MonsterMMORPG
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672531901326-6345bd89fe134dfd7a0dba40.png?w=200&h=200&f=face
          fullname: "Furkan G\xF6z\xFCkara"
          isHf: false
          isPro: false
          name: MonsterMMORPG
          type: user
        html: "<p><strong>I hope this video gets added to the FAQ, wiki and stickies.</strong></p>\n\
          <p><strong>Appreciate very much.</strong></p>\n<p>Full Stable Diffusion\
          \ related playlist that explains both on google colab and PC by Automatic1111\
          \ Web UI :<br>\u27A1\uFE0F <a rel=\"nofollow\" href=\"https://www.youtube.com/playlist?list=PL_pbwdIyffsmclLl0O144nQRnezKlNdx3\"\
          >https://www.youtube.com/playlist?list=PL_pbwdIyffsmclLl0O144nQRnezKlNdx3</a></p>\n\
          <p>\U0001F3A6 <a rel=\"nofollow\" href=\"https://youtu.be/mfaqqL5yOO4\"\
          >https://youtu.be/mfaqqL5yOO4</a></p>\n<p><a rel=\"nofollow\" href=\"https://youtu.be/mfaqqL5yOO4\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/1672446412494-6345bd89fe134dfd7a0dba40.png\"\
          ></a></p>\n<p>content of the video</p>\n<p>0:00 Introduction speech<br>1:07\
          \ How to install the LoRA extension to the Stable Diffusion Web UI<br>2:36\
          \ Preparation of training set images by properly sized cropping<br>2:54\
          \ How to crop images using Paint .NET, an open-source image editing software<br>5:02\
          \ What is Low-Rank Adaptation (LoRA)<br>5:35 Starting preparation for training\
          \ using the DreamBooth tab - LoRA<br>6:50 Explanation of all training parameters,\
          \ settings, and options<br>8:27 How many training steps equal one epoch<br>9:09\
          \ Save checkpoints frequency<br>9:48 Save a preview of training images after\
          \ certain steps or epochs<br>10:04 What is batch size in training settings<br>11:56\
          \ Where to set LoRA training in SD Web UI<br>13:45 Explanation of Concepts\
          \ tab in training section of SD Web UI<br>14:00 How to set the path for\
          \ training images<br>14:28 Classification Dataset Directory<br>15:22 Training\
          \ prompt - how to set what to teach the model<br>15:55 What is Class and\
          \ Sample Image Prompt in SD training<br>17:57 What is Image Generation settings\
          \ and why we need classification image generation in SD training<br>19:40\
          \ Starting the training process<br>21:03 How and why to tune your Class\
          \ Prompt (generating generic training images)<br>22:39 Why we generate regularization\
          \ generic images by class prompt<br>23:27 Recap of the setting up process\
          \ for training parameters, options, and settings<br>29:23 How much GPU,\
          \ CPU, and RAM the class regularization image generation uses<br>29:57 Training\
          \ process starts after class image generation has been completed<br>30:04\
          \ Displaying the generated class regularization images folder for SD 2.1<br>30:31\
          \ The speed of the training process - how many seconds per iteration on\
          \ an RTX 3060 GPU<br>31:19 Where LoRA training checkpoints (weights) are\
          \ saved<br>32:36 Where training preview images are saved and our first training\
          \ preview image<br>33:10 When we will decide to stop training<br>34:09 How\
          \ to resume training after training has crashed or you close it down<br>36:49\
          \ Lifetime vs. session training steps<br>37:54 After 30 epochs, resembling\
          \ images start to appear in the preview folder<br>38:19 The command line\
          \ printed messages are incorrect in some cases<br>39:05 Training step speed,\
          \ a certain number of seconds per iteration (IT)<br>39:25 Results after\
          \ 5600 steps (350 epochs) - it was sufficient for SD 2.1<br>39:44 How I'm\
          \ picking a checkpoint to generate a full model .ckpt file<br>40:23 How\
          \ to generate a full model .ckpt file from a LoRA checkpoint .pt file<br>41:17\
          \ Generated/saved file name is incorrect, but it is generated from the correct\
          \ selected .pt file<br>42:01 Doing inference (generating new images) using\
          \ the text2img tab with our newly trained and generated model<br>42:47 The\
          \ results of SD 2.1 Version 768 pixel model after training with the LoRA\
          \ method and teaching a human face<br>44:38 Setting up the training parameters/options\
          \ for SD version 1.5 this time<br>48:35 Re-generating class regularization\
          \ images since SD 1.5 uses 512 pixel resolution<br>49:11 Displaying the\
          \ generated class regularization images folder for SD 1.5<br>50:16 Training\
          \ of Stable Diffusion 1.5 using the LoRA methodology and teaching a face\
          \ has been completed and the results are displayed<br>51:09 The inference\
          \ (text2img) results with SD 1.5 training<br>51:19 You have to do more inference\
          \ with LoRA since it has less precision than DreamBooth<br>51:39 How to\
          \ give more attention/emphasis to certain keywords in the SD Web UI<br>52:51\
          \ How to generate more than 100 images using the script section of the Web\
          \ UI<br>54:46 How to check PNG info to see used prompts and settings<br>55:24\
          \ How to upscale using AI models<br>56:12 Fixing face image quality, especially\
          \ eyes, with GFPGAN visibility<br>56:32 How to batch post-process<br>57:00\
          \ Where batch-generated images are saved<br>57:18 Conclusion and ending\
          \ speech</p>\n"
        raw: "**I hope this video gets added to the FAQ, wiki and stickies.**\r\n\r\
          \n**Appreciate very much.**\r\n\r\nFull Stable Diffusion related playlist\
          \ that explains both on google colab and PC by Automatic1111 Web UI : \r\
          \n\u27A1\uFE0F https://www.youtube.com/playlist?list=PL_pbwdIyffsmclLl0O144nQRnezKlNdx3\r\
          \n\r\n\U0001F3A6 https://youtu.be/mfaqqL5yOO4\r\n\r\n[![image.png](https://cdn-uploads.huggingface.co/production/uploads/1672446412494-6345bd89fe134dfd7a0dba40.png)](https://youtu.be/mfaqqL5yOO4)\r\
          \n\r\ncontent of the video\r\n\r\n0:00 Introduction speech\r\n1:07 How to\
          \ install the LoRA extension to the Stable Diffusion Web UI\r\n2:36 Preparation\
          \ of training set images by properly sized cropping\r\n2:54 How to crop\
          \ images using Paint .NET, an open-source image editing software\r\n5:02\
          \ What is Low-Rank Adaptation (LoRA)\r\n5:35 Starting preparation for training\
          \ using the DreamBooth tab - LoRA\r\n6:50 Explanation of all training parameters,\
          \ settings, and options\r\n8:27 How many training steps equal one epoch\r\
          \n9:09 Save checkpoints frequency\r\n9:48 Save a preview of training images\
          \ after certain steps or epochs\r\n10:04 What is batch size in training\
          \ settings\r\n11:56 Where to set LoRA training in SD Web UI\r\n13:45 Explanation\
          \ of Concepts tab in training section of SD Web UI\r\n14:00 How to set the\
          \ path for training images\r\n14:28 Classification Dataset Directory\r\n\
          15:22 Training prompt - how to set what to teach the model\r\n15:55 What\
          \ is Class and Sample Image Prompt in SD training\r\n17:57 What is Image\
          \ Generation settings and why we need classification image generation in\
          \ SD training\r\n19:40 Starting the training process\r\n21:03 How and why\
          \ to tune your Class Prompt (generating generic training images)\r\n22:39\
          \ Why we generate regularization generic images by class prompt\r\n23:27\
          \ Recap of the setting up process for training parameters, options, and\
          \ settings\r\n29:23 How much GPU, CPU, and RAM the class regularization\
          \ image generation uses\r\n29:57 Training process starts after class image\
          \ generation has been completed\r\n30:04 Displaying the generated class\
          \ regularization images folder for SD 2.1\r\n30:31 The speed of the training\
          \ process - how many seconds per iteration on an RTX 3060 GPU\r\n31:19 Where\
          \ LoRA training checkpoints (weights) are saved\r\n32:36 Where training\
          \ preview images are saved and our first training preview image\r\n33:10\
          \ When we will decide to stop training\r\n34:09 How to resume training after\
          \ training has crashed or you close it down\r\n36:49 Lifetime vs. session\
          \ training steps\r\n37:54 After 30 epochs, resembling images start to appear\
          \ in the preview folder\r\n38:19 The command line printed messages are incorrect\
          \ in some cases\r\n39:05 Training step speed, a certain number of seconds\
          \ per iteration (IT)\r\n39:25 Results after 5600 steps (350 epochs) - it\
          \ was sufficient for SD 2.1\r\n39:44 How I'm picking a checkpoint to generate\
          \ a full model .ckpt file\r\n40:23 How to generate a full model .ckpt file\
          \ from a LoRA checkpoint .pt file\r\n41:17 Generated/saved file name is\
          \ incorrect, but it is generated from the correct selected .pt file\r\n\
          42:01 Doing inference (generating new images) using the text2img tab with\
          \ our newly trained and generated model\r\n42:47 The results of SD 2.1 Version\
          \ 768 pixel model after training with the LoRA method and teaching a human\
          \ face\r\n44:38 Setting up the training parameters/options for SD version\
          \ 1.5 this time\r\n48:35 Re-generating class regularization images since\
          \ SD 1.5 uses 512 pixel resolution\r\n49:11 Displaying the generated class\
          \ regularization images folder for SD 1.5\r\n50:16 Training of Stable Diffusion\
          \ 1.5 using the LoRA methodology and teaching a face has been completed\
          \ and the results are displayed\r\n51:09 The inference (text2img) results\
          \ with SD 1.5 training\r\n51:19 You have to do more inference with LoRA\
          \ since it has less precision than DreamBooth\r\n51:39 How to give more\
          \ attention/emphasis to certain keywords in the SD Web UI\r\n52:51 How to\
          \ generate more than 100 images using the script section of the Web UI\r\
          \n54:46 How to check PNG info to see used prompts and settings\r\n55:24\
          \ How to upscale using AI models\r\n56:12 Fixing face image quality, especially\
          \ eyes, with GFPGAN visibility\r\n56:32 How to batch post-process\r\n57:00\
          \ Where batch-generated images are saved\r\n57:18 Conclusion and ending\
          \ speech"
        updatedAt: '2023-01-01T00:15:03.588Z'
      numEdits: 0
      reactions: []
    id: 63b0d087f2eb87a4d6947193
    type: comment
  author: MonsterMMORPG
  content: "**I hope this video gets added to the FAQ, wiki and stickies.**\r\n\r\n\
    **Appreciate very much.**\r\n\r\nFull Stable Diffusion related playlist that explains\
    \ both on google colab and PC by Automatic1111 Web UI : \r\n\u27A1\uFE0F https://www.youtube.com/playlist?list=PL_pbwdIyffsmclLl0O144nQRnezKlNdx3\r\
    \n\r\n\U0001F3A6 https://youtu.be/mfaqqL5yOO4\r\n\r\n[![image.png](https://cdn-uploads.huggingface.co/production/uploads/1672446412494-6345bd89fe134dfd7a0dba40.png)](https://youtu.be/mfaqqL5yOO4)\r\
    \n\r\ncontent of the video\r\n\r\n0:00 Introduction speech\r\n1:07 How to install\
    \ the LoRA extension to the Stable Diffusion Web UI\r\n2:36 Preparation of training\
    \ set images by properly sized cropping\r\n2:54 How to crop images using Paint\
    \ .NET, an open-source image editing software\r\n5:02 What is Low-Rank Adaptation\
    \ (LoRA)\r\n5:35 Starting preparation for training using the DreamBooth tab -\
    \ LoRA\r\n6:50 Explanation of all training parameters, settings, and options\r\
    \n8:27 How many training steps equal one epoch\r\n9:09 Save checkpoints frequency\r\
    \n9:48 Save a preview of training images after certain steps or epochs\r\n10:04\
    \ What is batch size in training settings\r\n11:56 Where to set LoRA training\
    \ in SD Web UI\r\n13:45 Explanation of Concepts tab in training section of SD\
    \ Web UI\r\n14:00 How to set the path for training images\r\n14:28 Classification\
    \ Dataset Directory\r\n15:22 Training prompt - how to set what to teach the model\r\
    \n15:55 What is Class and Sample Image Prompt in SD training\r\n17:57 What is\
    \ Image Generation settings and why we need classification image generation in\
    \ SD training\r\n19:40 Starting the training process\r\n21:03 How and why to tune\
    \ your Class Prompt (generating generic training images)\r\n22:39 Why we generate\
    \ regularization generic images by class prompt\r\n23:27 Recap of the setting\
    \ up process for training parameters, options, and settings\r\n29:23 How much\
    \ GPU, CPU, and RAM the class regularization image generation uses\r\n29:57 Training\
    \ process starts after class image generation has been completed\r\n30:04 Displaying\
    \ the generated class regularization images folder for SD 2.1\r\n30:31 The speed\
    \ of the training process - how many seconds per iteration on an RTX 3060 GPU\r\
    \n31:19 Where LoRA training checkpoints (weights) are saved\r\n32:36 Where training\
    \ preview images are saved and our first training preview image\r\n33:10 When\
    \ we will decide to stop training\r\n34:09 How to resume training after training\
    \ has crashed or you close it down\r\n36:49 Lifetime vs. session training steps\r\
    \n37:54 After 30 epochs, resembling images start to appear in the preview folder\r\
    \n38:19 The command line printed messages are incorrect in some cases\r\n39:05\
    \ Training step speed, a certain number of seconds per iteration (IT)\r\n39:25\
    \ Results after 5600 steps (350 epochs) - it was sufficient for SD 2.1\r\n39:44\
    \ How I'm picking a checkpoint to generate a full model .ckpt file\r\n40:23 How\
    \ to generate a full model .ckpt file from a LoRA checkpoint .pt file\r\n41:17\
    \ Generated/saved file name is incorrect, but it is generated from the correct\
    \ selected .pt file\r\n42:01 Doing inference (generating new images) using the\
    \ text2img tab with our newly trained and generated model\r\n42:47 The results\
    \ of SD 2.1 Version 768 pixel model after training with the LoRA method and teaching\
    \ a human face\r\n44:38 Setting up the training parameters/options for SD version\
    \ 1.5 this time\r\n48:35 Re-generating class regularization images since SD 1.5\
    \ uses 512 pixel resolution\r\n49:11 Displaying the generated class regularization\
    \ images folder for SD 1.5\r\n50:16 Training of Stable Diffusion 1.5 using the\
    \ LoRA methodology and teaching a face has been completed and the results are\
    \ displayed\r\n51:09 The inference (text2img) results with SD 1.5 training\r\n\
    51:19 You have to do more inference with LoRA since it has less precision than\
    \ DreamBooth\r\n51:39 How to give more attention/emphasis to certain keywords\
    \ in the SD Web UI\r\n52:51 How to generate more than 100 images using the script\
    \ section of the Web UI\r\n54:46 How to check PNG info to see used prompts and\
    \ settings\r\n55:24 How to upscale using AI models\r\n56:12 Fixing face image\
    \ quality, especially eyes, with GFPGAN visibility\r\n56:32 How to batch post-process\r\
    \n57:00 Where batch-generated images are saved\r\n57:18 Conclusion and ending\
    \ speech"
  created_at: 2023-01-01 00:15:03+00:00
  edited: false
  hidden: false
  id: 63b0d087f2eb87a4d6947193
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672531901326-6345bd89fe134dfd7a0dba40.png?w=200&h=200&f=face
      fullname: "Furkan G\xF6z\xFCkara"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MonsterMMORPG
      type: user
    createdAt: '2023-01-12T11:21:44.000Z'
    data:
      status: closed
    id: 63bfed48c42fb2d7f864f29a
    type: status-change
  author: MonsterMMORPG
  created_at: 2023-01-12 11:21:44+00:00
  id: 63bfed48c42fb2d7f864f29a
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 100
repo_id: hakurei/waifu-diffusion
repo_type: model
status: closed
target_branch: null
title: '[Tutorial] How To Do Stable Diffusion LORA Training By Using Web UI On Different
  Models - Tested SD 1.5, SD 2.1'
