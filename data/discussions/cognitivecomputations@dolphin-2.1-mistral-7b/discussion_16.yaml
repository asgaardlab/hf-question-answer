!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Phil337
conflicting_files: null
created_at: 2023-11-11 02:01:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-11-11T02:01:37.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9758148193359375
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>Dolphin 2.0 scored 39.5 on DROP,  while Dolphin 2.1 scored 7.6.</p>

          <p>This makes no sense to me because Dolphin 2.1 did notably better across
          the board on my testing compared to Dolphin 2.0, not to mention on all standardized
          LLM tests other than TruthfulQA, which it still did better than average
          on.</p>

          <p>There are 96k DROP questions so I''m not going to keep testing them,
          but I tested several, including many similar questions from my person test,
          and Dolphin 2.1 had no problem with any of them, as did Dolphin 2.0.</p>

          <p>Perhaps there''s certain types of questions from DROP that Dolphin 2.1
          struggles with. If so, what changed between Dolphin 2.0 and 2.1 that would
          account for such a huge drop in the DROP score (39.5 to 7.6)?</p>

          '
        raw: "Dolphin 2.0 scored 39.5 on DROP,  while Dolphin 2.1 scored 7.6.\r\n\r\
          \nThis makes no sense to me because Dolphin 2.1 did notably better across\
          \ the board on my testing compared to Dolphin 2.0, not to mention on all\
          \ standardized LLM tests other than TruthfulQA, which it still did better\
          \ than average on.\r\n\r\nThere are 96k DROP questions so I'm not going\
          \ to keep testing them, but I tested several, including many similar questions\
          \ from my person test, and Dolphin 2.1 had no problem with any of them,\
          \ as did Dolphin 2.0.\r\n\r\nPerhaps there's certain types of questions\
          \ from DROP that Dolphin 2.1 struggles with. If so, what changed between\
          \ Dolphin 2.0 and 2.1 that would account for such a huge drop in the DROP\
          \ score (39.5 to 7.6)?\r\n"
        updatedAt: '2023-11-11T02:01:37.847Z'
      numEdits: 0
      reactions: []
    id: 654ee081259ab60296e31814
    type: comment
  author: Phil337
  content: "Dolphin 2.0 scored 39.5 on DROP,  while Dolphin 2.1 scored 7.6.\r\n\r\n\
    This makes no sense to me because Dolphin 2.1 did notably better across the board\
    \ on my testing compared to Dolphin 2.0, not to mention on all standardized LLM\
    \ tests other than TruthfulQA, which it still did better than average on.\r\n\r\
    \nThere are 96k DROP questions so I'm not going to keep testing them, but I tested\
    \ several, including many similar questions from my person test, and Dolphin 2.1\
    \ had no problem with any of them, as did Dolphin 2.0.\r\n\r\nPerhaps there's\
    \ certain types of questions from DROP that Dolphin 2.1 struggles with. If so,\
    \ what changed between Dolphin 2.0 and 2.1 that would account for such a huge\
    \ drop in the DROP score (39.5 to 7.6)?\r\n"
  created_at: 2023-11-11 02:01:37+00:00
  edited: false
  hidden: false
  id: 654ee081259ab60296e31814
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-11-11T02:13:25.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6730380654335022
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>I wanna see dolphin 2.2.1 scores </p>

          '
        raw: 'I wanna see dolphin 2.2.1 scores '
        updatedAt: '2023-11-11T02:13:25.633Z'
      numEdits: 0
      reactions: []
    id: 654ee345259ab60296e393ab
    type: comment
  author: ehartford
  content: 'I wanna see dolphin 2.2.1 scores '
  created_at: 2023-11-11 02:13:25+00:00
  edited: false
  hidden: false
  id: 654ee345259ab60296e393ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-11-30T06:11:36.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9606262445449829
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>Intel''s neural chat 3.1 got a relatively high DROP score and their
          explanation as to why was "We find the metric of drop decreases during the
          training. So early stopping is needed.".</p>

          <p>There is something fundamentally wrong about the DROP test or its implementation
          because weird things are happening with it. For example, Yi-34 chat has
          a DROP score of only 8, while the Yi-34 base model has a score of 64. And
          Qwen 14b has a much higher DROP score than Falcon 180b despite being a VASTLY
          inferior LLM at everything I threw at it.</p>

          <p>Anyways, it''s kinda odd that unusually "smart" models like Dolphin 2.1/2.2.1
          and Zephyr Beta have much lower DROP scores than other "dumb" Mistrals and
          Llamas that make far more frequent and egregious logic, math, coding...
          errors.</p>

          '
        raw: 'Intel''s neural chat 3.1 got a relatively high DROP score and their
          explanation as to why was "We find the metric of drop decreases during the
          training. So early stopping is needed.".


          There is something fundamentally wrong about the DROP test or its implementation
          because weird things are happening with it. For example, Yi-34 chat has
          a DROP score of only 8, while the Yi-34 base model has a score of 64. And
          Qwen 14b has a much higher DROP score than Falcon 180b despite being a VASTLY
          inferior LLM at everything I threw at it.


          Anyways, it''s kinda odd that unusually "smart" models like Dolphin 2.1/2.2.1
          and Zephyr Beta have much lower DROP scores than other "dumb" Mistrals and
          Llamas that make far more frequent and egregious logic, math, coding...
          errors.'
        updatedAt: '2023-11-30T06:11:36.250Z'
      numEdits: 0
      reactions: []
    id: 65682798461af93fcac87295
    type: comment
  author: Phil337
  content: 'Intel''s neural chat 3.1 got a relatively high DROP score and their explanation
    as to why was "We find the metric of drop decreases during the training. So early
    stopping is needed.".


    There is something fundamentally wrong about the DROP test or its implementation
    because weird things are happening with it. For example, Yi-34 chat has a DROP
    score of only 8, while the Yi-34 base model has a score of 64. And Qwen 14b has
    a much higher DROP score than Falcon 180b despite being a VASTLY inferior LLM
    at everything I threw at it.


    Anyways, it''s kinda odd that unusually "smart" models like Dolphin 2.1/2.2.1
    and Zephyr Beta have much lower DROP scores than other "dumb" Mistrals and Llamas
    that make far more frequent and egregious logic, math, coding... errors.'
  created_at: 2023-11-30 06:11:36+00:00
  edited: false
  hidden: false
  id: 65682798461af93fcac87295
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-07T18:59:02.000Z'
    data:
      from: Why does Dolphin 2.0 do so much better on DROP?
      to: Never Mind. There Was an Issue with DROP not this LLM.
    id: 657215f6536d823668cfac00
    type: title-change
  author: Phil337
  created_at: 2023-12-07 18:59:02+00:00
  id: 657215f6536d823668cfac00
  new_title: Never Mind. There Was an Issue with DROP not this LLM.
  old_title: Why does Dolphin 2.0 do so much better on DROP?
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-07T18:59:07.000Z'
    data:
      status: closed
    id: 657215fb725d443c8b265669
    type: status-change
  author: Phil337
  created_at: 2023-12-07 18:59:07+00:00
  id: 657215fb725d443c8b265669
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: cognitivecomputations/dolphin-2.1-mistral-7b
repo_type: model
status: closed
target_branch: null
title: Never Mind. There Was an Issue with DROP not this LLM.
