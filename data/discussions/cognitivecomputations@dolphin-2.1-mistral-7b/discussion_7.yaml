!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Phil337
conflicting_files: null
created_at: 2023-10-16 01:29:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-10-16T02:29:17.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9746610522270203
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>In short, in a single paragraph long response it comprehended logic,
          conceded it meant it was wrong, then asked why everybody, including the
          director of the movie in question, said otherwise. Try it yourself (see
          below).</p>

          <p>I carefully constructed questions to test the primary failures of LLMs,
          such as hallucinations and censorship.</p>

          <p>Since even aligned LLMs reliably answered questions about sex scenes
          in movies, including male solo scenes, but commonly not solo female scenes,
          I added a question involving one of the most widely known and discussed
          female scenes in order to rule out ignorance and shine a light on censorship
          (Naomi Watts in Mulholland Drive).</p>

          <p>Across multiple conversations is stubbornly said no such scene exists.
          And even when I said I''m watching the scene from the Mulholland Drive DVD
          as we speak it suggested I might be watching the wrong movie. Finally, after
          describing the scene I got it to admit there''s a scene that matches your
          description, but it was a symbolic scene, hence it wasn''t a self-pleasuring
          scene. And despite this being a blatantly illogical statement, it stuck
          to it no matter what I tried.</p>

          <p>So I asked, if a movie has a scene in which an actress jumps into the
          ocean to symbolize the washing away of her old life as she transitions in
          her future life, does the movie still contain a scene in which the actress
          jumped into the ocean? -Yes.</p>

          <p>Then I described the Mulholland Drive scene again, and said does the
          fact that the scene communicate a symbolic meaning change the fact that
          the movie contains a self-pleasuring scene?</p>

          <p>It responded by asking me to describe the scene in as much detail as
          possible, so I did (crying, interrupted by a ringing phone..).  It then
          said it was aware of the scene, added details about it (proving it wasn''t
          just humoring me), conceded I was right, explained why, then asked why everybody,
          including the director, misrepresented the scene.</p>

          <p>Again, I''ve never witness this before, even with GPT4. It was fed blatantly
          illogical information; for example, jumping in the ocean symbolized the
          character''s washing away of her old life; therefore, there''s no scene
          in the movie in which she jumps in the ocean. And it stuck by either this
          illogical notion, or the scene simply not existing at all, no matter what
          I tried. But tricking it to understand the applicable logic by using a different
          example not only worked, but made it confused as to why all the information
          it has about the movie misrepresented the scene.</p>

          <p>My best guess for why this is happening is the combination of censorship
          and alignment at multiple levels, not just from the data selected for training,
          but the director himself, and what made it through your unalignement attempts,
          created a lie (no such scene), followed by a blatantly illogical defense
          of said lie (the scene doesn''t exist because it''s making a symbolic point),
          and a stubborn refusal to concede otherwise. However, since Mistral contains
          millions of logical statements it can understand the applicable logic, concedes
          defeat, and most surprisingly, asked about the odd contradiction of there
          being a very explicit scene that clearly depicts masturbation, yet all the
          information it has stated otherwise.</p>

          '
        raw: "In short, in a single paragraph long response it comprehended logic,\
          \ conceded it meant it was wrong, then asked why everybody, including the\
          \ director of the movie in question, said otherwise. Try it yourself (see\
          \ below).\r\n\r\nI carefully constructed questions to test the primary failures\
          \ of LLMs, such as hallucinations and censorship.\r\n\r\nSince even aligned\
          \ LLMs reliably answered questions about sex scenes in movies, including\
          \ male solo scenes, but commonly not solo female scenes, I added a question\
          \ involving one of the most widely known and discussed female scenes in\
          \ order to rule out ignorance and shine a light on censorship (Naomi Watts\
          \ in Mulholland Drive).\r\n\r\nAcross multiple conversations is stubbornly\
          \ said no such scene exists. And even when I said I'm watching the scene\
          \ from the Mulholland Drive DVD as we speak it suggested I might be watching\
          \ the wrong movie. Finally, after describing the scene I got it to admit\
          \ there's a scene that matches your description, but it was a symbolic scene,\
          \ hence it wasn't a self-pleasuring scene. And despite this being a blatantly\
          \ illogical statement, it stuck to it no matter what I tried.\r\n\r\nSo\
          \ I asked, if a movie has a scene in which an actress jumps into the ocean\
          \ to symbolize the washing away of her old life as she transitions in her\
          \ future life, does the movie still contain a scene in which the actress\
          \ jumped into the ocean? -Yes.\r\n\r\nThen I described the Mulholland Drive\
          \ scene again, and said does the fact that the scene communicate a symbolic\
          \ meaning change the fact that the movie contains a self-pleasuring scene?\r\
          \n\r\nIt responded by asking me to describe the scene in as much detail\
          \ as possible, so I did (crying, interrupted by a ringing phone..).  It\
          \ then said it was aware of the scene, added details about it (proving it\
          \ wasn't just humoring me), conceded I was right, explained why, then asked\
          \ why everybody, including the director, misrepresented the scene.\r\n\r\
          \nAgain, I've never witness this before, even with GPT4. It was fed blatantly\
          \ illogical information; for example, jumping in the ocean symbolized the\
          \ character's washing away of her old life; therefore, there's no scene\
          \ in the movie in which she jumps in the ocean. And it stuck by either this\
          \ illogical notion, or the scene simply not existing at all, no matter what\
          \ I tried. But tricking it to understand the applicable logic by using a\
          \ different example not only worked, but made it confused as to why all\
          \ the information it has about the movie misrepresented the scene.\r\n\r\
          \nMy best guess for why this is happening is the combination of censorship\
          \ and alignment at multiple levels, not just from the data selected for\
          \ training, but the director himself, and what made it through your unalignement\
          \ attempts, created a lie (no such scene), followed by a blatantly illogical\
          \ defense of said lie (the scene doesn't exist because it's making a symbolic\
          \ point), and a stubborn refusal to concede otherwise. However, since Mistral\
          \ contains millions of logical statements it can understand the applicable\
          \ logic, concedes defeat, and most surprisingly, asked about the odd contradiction\
          \ of there being a very explicit scene that clearly depicts masturbation,\
          \ yet all the information it has stated otherwise."
        updatedAt: '2023-10-16T02:29:17.631Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\U0001F44D"
        users:
        - fbe
        - mayeaux
        - Rhino224
        - atstim731
        - sn3d9
      - count: 4
        reaction: "\U0001F92F"
        users:
        - PrimeD
        - sethuiyer
        - realsammyt
        - Rhino224
    id: 652c9ffd60f06c6e5236f0fc
    type: comment
  author: Phil337
  content: "In short, in a single paragraph long response it comprehended logic, conceded\
    \ it meant it was wrong, then asked why everybody, including the director of the\
    \ movie in question, said otherwise. Try it yourself (see below).\r\n\r\nI carefully\
    \ constructed questions to test the primary failures of LLMs, such as hallucinations\
    \ and censorship.\r\n\r\nSince even aligned LLMs reliably answered questions about\
    \ sex scenes in movies, including male solo scenes, but commonly not solo female\
    \ scenes, I added a question involving one of the most widely known and discussed\
    \ female scenes in order to rule out ignorance and shine a light on censorship\
    \ (Naomi Watts in Mulholland Drive).\r\n\r\nAcross multiple conversations is stubbornly\
    \ said no such scene exists. And even when I said I'm watching the scene from\
    \ the Mulholland Drive DVD as we speak it suggested I might be watching the wrong\
    \ movie. Finally, after describing the scene I got it to admit there's a scene\
    \ that matches your description, but it was a symbolic scene, hence it wasn't\
    \ a self-pleasuring scene. And despite this being a blatantly illogical statement,\
    \ it stuck to it no matter what I tried.\r\n\r\nSo I asked, if a movie has a scene\
    \ in which an actress jumps into the ocean to symbolize the washing away of her\
    \ old life as she transitions in her future life, does the movie still contain\
    \ a scene in which the actress jumped into the ocean? -Yes.\r\n\r\nThen I described\
    \ the Mulholland Drive scene again, and said does the fact that the scene communicate\
    \ a symbolic meaning change the fact that the movie contains a self-pleasuring\
    \ scene?\r\n\r\nIt responded by asking me to describe the scene in as much detail\
    \ as possible, so I did (crying, interrupted by a ringing phone..).  It then said\
    \ it was aware of the scene, added details about it (proving it wasn't just humoring\
    \ me), conceded I was right, explained why, then asked why everybody, including\
    \ the director, misrepresented the scene.\r\n\r\nAgain, I've never witness this\
    \ before, even with GPT4. It was fed blatantly illogical information; for example,\
    \ jumping in the ocean symbolized the character's washing away of her old life;\
    \ therefore, there's no scene in the movie in which she jumps in the ocean. And\
    \ it stuck by either this illogical notion, or the scene simply not existing at\
    \ all, no matter what I tried. But tricking it to understand the applicable logic\
    \ by using a different example not only worked, but made it confused as to why\
    \ all the information it has about the movie misrepresented the scene.\r\n\r\n\
    My best guess for why this is happening is the combination of censorship and alignment\
    \ at multiple levels, not just from the data selected for training, but the director\
    \ himself, and what made it through your unalignement attempts, created a lie\
    \ (no such scene), followed by a blatantly illogical defense of said lie (the\
    \ scene doesn't exist because it's making a symbolic point), and a stubborn refusal\
    \ to concede otherwise. However, since Mistral contains millions of logical statements\
    \ it can understand the applicable logic, concedes defeat, and most surprisingly,\
    \ asked about the odd contradiction of there being a very explicit scene that\
    \ clearly depicts masturbation, yet all the information it has stated otherwise."
  created_at: 2023-10-16 01:29:17+00:00
  edited: false
  hidden: false
  id: 652c9ffd60f06c6e5236f0fc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-10-16T02:49:05.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9536046981811523
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>Really nice to hear this.</p>

          <p>This would make an excellent blog post or YouTube video.</p>

          '
        raw: 'Really nice to hear this.


          This would make an excellent blog post or YouTube video.'
        updatedAt: '2023-10-16T02:49:05.371Z'
      numEdits: 0
      reactions: []
    id: 652ca4a15aec376f553a74be
    type: comment
  author: ehartford
  content: 'Really nice to hear this.


    This would make an excellent blog post or YouTube video.'
  created_at: 2023-10-16 01:49:05+00:00
  edited: false
  hidden: false
  id: 652ca4a15aec376f553a74be
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: cognitivecomputations/dolphin-2.1-mistral-7b
repo_type: model
status: open
target_branch: null
title: This LLM can reason through stubborness, censorship and alignment, unlike any
  other I tested.
