!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Ollie
conflicting_files: null
created_at: 2022-06-27 10:48:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d7734b0618a6640db2935456cfa11904.svg
      fullname: Oliver Broadhurst
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ollie
      type: user
    createdAt: '2022-06-27T11:48:49.000Z'
    data:
      edited: false
      editors:
      - Ollie
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d7734b0618a6640db2935456cfa11904.svg
          fullname: Oliver Broadhurst
          isHf: false
          isPro: false
          name: Ollie
          type: user
        html: "<p>Thanks so much for the great model!</p>\n<p><span data-props=\"\
          {&quot;user&quot;:&quot;lorenlugosch&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/lorenlugosch\">@<span class=\"underline\"\
          >lorenlugosch</span></a></span>\n\n\t</span></span> do you know if there\
          \ are any plans to release the weights of the base model mentioned in the\
          \ paper?</p>\n<p>Thanks!</p>\n"
        raw: "Thanks so much for the great model!\r\n\r\n@lorenlugosch do you know\
          \ if there are any plans to release the weights of the base model mentioned\
          \ in the paper?\r\n\r\nThanks!"
        updatedAt: '2022-06-27T11:48:49.199Z'
      numEdits: 0
      reactions: []
    id: 62b99921397ff36bf1f0eb15
    type: comment
  author: Ollie
  content: "Thanks so much for the great model!\r\n\r\n@lorenlugosch do you know if\
    \ there are any plans to release the weights of the base model mentioned in the\
    \ paper?\r\n\r\nThanks!"
  created_at: 2022-06-27 10:48:49+00:00
  edited: false
  hidden: false
  id: 62b99921397ff36bf1f0eb15
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615683805593-604d5ef6d8a4193fd3a928f2.png?w=200&h=200&f=face
      fullname: Loren Lugosch
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lorenlugosch
      type: user
    createdAt: '2022-06-27T15:13:04.000Z'
    data:
      edited: false
      editors:
      - lorenlugosch
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615683805593-604d5ef6d8a4193fd3a928f2.png?w=200&h=200&f=face
          fullname: Loren Lugosch
          isHf: false
          isPro: false
          name: lorenlugosch
          type: user
        html: '<p>Glad it''s useful for you Ollie!</p>

          <p>We don''t plan to release the 275M-param model weights.</p>

          <p>If you need a smaller version of the model, you could try distilling
          the 1B-param model or just using a subset of the layers (I ran some experiments
          applying the output layer to intermediate hidden activations that suggest
          that this should work pretty well with a bit of finetuning).</p>

          '
        raw: 'Glad it''s useful for you Ollie!


          We don''t plan to release the 275M-param model weights.


          If you need a smaller version of the model, you could try distilling the
          1B-param model or just using a subset of the layers (I ran some experiments
          applying the output layer to intermediate hidden activations that suggest
          that this should work pretty well with a bit of finetuning).'
        updatedAt: '2022-06-27T15:13:04.012Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - Ollie
    id: 62b9c900558a1ae1a3e7be3f
    type: comment
  author: lorenlugosch
  content: 'Glad it''s useful for you Ollie!


    We don''t plan to release the 275M-param model weights.


    If you need a smaller version of the model, you could try distilling the 1B-param
    model or just using a subset of the layers (I ran some experiments applying the
    output layer to intermediate hidden activations that suggest that this should
    work pretty well with a bit of finetuning).'
  created_at: 2022-06-27 14:13:04+00:00
  edited: false
  hidden: false
  id: 62b9c900558a1ae1a3e7be3f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615683805593-604d5ef6d8a4193fd3a928f2.png?w=200&h=200&f=face
      fullname: Loren Lugosch
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lorenlugosch
      type: user
    createdAt: '2022-06-27T15:13:04.000Z'
    data:
      status: closed
    id: 62b9c900558a1ae1a3e7be40
    type: status-change
  author: lorenlugosch
  created_at: 2022-06-27 14:13:04+00:00
  id: 62b9c900558a1ae1a3e7be40
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: speechbrain/m-ctc-t-large
repo_type: model
status: closed
target_branch: null
title: Base model weights
