!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Harsh6519
conflicting_files: null
created_at: 2023-11-21 08:20:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0a800d614c8257cec84329691763e928.svg
      fullname: Harsh Vaishnav
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Harsh6519
      type: user
    createdAt: '2023-11-21T08:20:20.000Z'
    data:
      edited: false
      editors:
      - Harsh6519
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5457062721252441
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0a800d614c8257cec84329691763e928.svg
          fullname: Harsh Vaishnav
          isHf: false
          isPro: false
          name: Harsh6519
          type: user
        html: '<p>I am doing Q-A for CSV data using langchain CSV agent. </p>

          <h2 id="here-is-my-code">Here is my code:</h2>

          <p>import os<br>import pandas as pd<br>from langchain_experimental.agents.agent_toolkits
          import create_csv_agent<br>from langchain.llms import OpenAI<br>from transformers
          import AutoTokenizer, AutoModelForSeq2SeqLM<br>from transformers import
          pipeline<br>from langchain.llms import HuggingFacePipeline<br>from langchain.prompts
          import ChatPromptTemplate</p>

          <p>os.environ["OPENAI_API_KEY"] = "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"</p>

          <p>df = pd.read_csv("dataset.csv")</p>

          <p>tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-xl")<br>model
          = AutoModelForSeq2SeqLM.from_pretrained(<br>    "google/flan-t5-xl",<br>    max_length=512<br>)<br>pipe
          = pipeline(<br>    "text2text-generation",<br>    model=model,<br>    tokenizer=tokenizer,<br>    max_length=512,<br>    repetition_penalty=1.15,<br>)</p>

          <p>local_llm = HuggingFacePipeline(pipeline=pipe)<br>agent = create_csv_agent(<br>    llm=local_llm,
          path="dataset.csv", verbose=True, handle_parsing_errors=True<br>)</p>

          <p>try:<br>    result = agent.run("How many people have same height?, return
          answer in text format.")<br>    print("Result-&gt;", result)<br>    prnt("Ket",
          result.keys())<br>except Exception as e:<br>    print("e===", e)</p>

          <hr>

          <p>In here I am getting error as : Could not parse LLM output.<br>So how
          to solve this issue?<br>If anyone have any idea then please help me to solve
          it out.</p>

          '
        raw: "I am doing Q-A for CSV data using langchain CSV agent. \r\n\r\nHere\
          \ is my code:\r\n--------------------\r\nimport os\r\nimport pandas as pd\r\
          \nfrom langchain_experimental.agents.agent_toolkits import create_csv_agent\r\
          \nfrom langchain.llms import OpenAI\r\nfrom transformers import AutoTokenizer,\
          \ AutoModelForSeq2SeqLM\r\nfrom transformers import pipeline\r\nfrom langchain.llms\
          \ import HuggingFacePipeline\r\nfrom langchain.prompts import ChatPromptTemplate\r\
          \n\r\nos.environ[\"OPENAI_API_KEY\"] = \"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\"\
          \r\n\r\ndf = pd.read_csv(\"dataset.csv\")\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
          google/flan-t5-xl\")\r\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\r\
          \n    \"google/flan-t5-xl\",\r\n    max_length=512\r\n)\r\npipe = pipeline(\r\
          \n    \"text2text-generation\",\r\n    model=model,\r\n    tokenizer=tokenizer,\r\
          \n    max_length=512,\r\n    repetition_penalty=1.15,\r\n)\r\n\r\nlocal_llm\
          \ = HuggingFacePipeline(pipeline=pipe)\r\nagent = create_csv_agent(\r\n\
          \    llm=local_llm, path=\"dataset.csv\", verbose=True, handle_parsing_errors=True\r\
          \n)\r\n\r\ntry:\r\n    result = agent.run(\"How many people have same height?,\
          \ return answer in text format.\")\r\n    print(\"Result->\", result)\r\n\
          \    prnt(\"Ket\", result.keys())\r\nexcept Exception as e:\r\n    print(\"\
          e===\", e)\r\n--------------------------\r\nIn here I am getting error as\
          \ : Could not parse LLM output.\r\nSo how to solve this issue?\r\nIf anyone\
          \ have any idea then please help me to solve it out."
        updatedAt: '2023-11-21T08:20:20.833Z'
      numEdits: 0
      reactions: []
    id: 655c68446d0ea8d4e615323b
    type: comment
  author: Harsh6519
  content: "I am doing Q-A for CSV data using langchain CSV agent. \r\n\r\nHere is\
    \ my code:\r\n--------------------\r\nimport os\r\nimport pandas as pd\r\nfrom\
    \ langchain_experimental.agents.agent_toolkits import create_csv_agent\r\nfrom\
    \ langchain.llms import OpenAI\r\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\r\
    \nfrom transformers import pipeline\r\nfrom langchain.llms import HuggingFacePipeline\r\
    \nfrom langchain.prompts import ChatPromptTemplate\r\n\r\nos.environ[\"OPENAI_API_KEY\"\
    ] = \"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\"\r\n\r\ndf = pd.read_csv(\"\
    dataset.csv\")\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\"\
    )\r\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\r\n    \"google/flan-t5-xl\"\
    ,\r\n    max_length=512\r\n)\r\npipe = pipeline(\r\n    \"text2text-generation\"\
    ,\r\n    model=model,\r\n    tokenizer=tokenizer,\r\n    max_length=512,\r\n \
    \   repetition_penalty=1.15,\r\n)\r\n\r\nlocal_llm = HuggingFacePipeline(pipeline=pipe)\r\
    \nagent = create_csv_agent(\r\n    llm=local_llm, path=\"dataset.csv\", verbose=True,\
    \ handle_parsing_errors=True\r\n)\r\n\r\ntry:\r\n    result = agent.run(\"How\
    \ many people have same height?, return answer in text format.\")\r\n    print(\"\
    Result->\", result)\r\n    prnt(\"Ket\", result.keys())\r\nexcept Exception as\
    \ e:\r\n    print(\"e===\", e)\r\n--------------------------\r\nIn here I am getting\
    \ error as : Could not parse LLM output.\r\nSo how to solve this issue?\r\nIf\
    \ anyone have any idea then please help me to solve it out."
  created_at: 2023-11-21 08:20:20+00:00
  edited: false
  hidden: false
  id: 655c68446d0ea8d4e615323b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 23
repo_id: google/flan-t5-xl
repo_type: model
status: open
target_branch: null
title: Could not parse LLM output.
