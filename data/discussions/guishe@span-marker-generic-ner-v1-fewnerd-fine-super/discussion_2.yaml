!!python/object:huggingface_hub.community.DiscussionWithDetails
author: krumeto
conflicting_files: null
created_at: 2023-11-28 08:37:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e55253efd9dab60819257255e2dd959d.svg
      fullname: Krum Arnaudov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: krumeto
      type: user
    createdAt: '2023-11-28T08:37:09.000Z'
    data:
      edited: false
      editors:
      - krumeto
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9225255250930786
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e55253efd9dab60819257255e2dd959d.svg
          fullname: Krum Arnaudov
          isHf: false
          isPro: false
          name: krumeto
          type: user
        html: '<p>First of all, congrats on the great model!</p>

          <p>Do you have any recommendation on handling longer than the max token
          of the underlying model? I''ve tried document-level context, it has worked
          fine but also got the <code>WARNING:span_marker.modeling:This model was
          trained without document-level context: inference with document-level context
          may cause decreased performance.</code>.</p>

          <p>Would you know what is the basis for the potential performance decrease
          with document-level context?</p>

          '
        raw: "First of all, congrats on the great model!\r\n\r\nDo you have any recommendation\
          \ on handling longer than the max token of the underlying model? I've tried\
          \ document-level context, it has worked fine but also got the `WARNING:span_marker.modeling:This\
          \ model was trained without document-level context: inference with document-level\
          \ context may cause decreased performance.`.\r\n\r\nWould you know what\
          \ is the basis for the potential performance decrease with document-level\
          \ context?\r\n"
        updatedAt: '2023-11-28T08:37:09.383Z'
      numEdits: 0
      reactions: []
    id: 6565a6b5995cc49553f0b113
    type: comment
  author: krumeto
  content: "First of all, congrats on the great model!\r\n\r\nDo you have any recommendation\
    \ on handling longer than the max token of the underlying model? I've tried document-level\
    \ context, it has worked fine but also got the `WARNING:span_marker.modeling:This\
    \ model was trained without document-level context: inference with document-level\
    \ context may cause decreased performance.`.\r\n\r\nWould you know what is the\
    \ basis for the potential performance decrease with document-level context?\r\n"
  created_at: 2023-11-28 08:37:09+00:00
  edited: false
  hidden: false
  id: 6565a6b5995cc49553f0b113
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/5vNzCxAqt3Y-0QFIYnrAA.jpeg?w=200&h=200&f=face
      fullname: "Guille P\xE9rez-Torr\xF3"
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: guishe
      type: user
    createdAt: '2023-11-29T10:31:21.000Z'
    data:
      edited: false
      editors:
      - guishe
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9352694153785706
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/5vNzCxAqt3Y-0QFIYnrAA.jpeg?w=200&h=200&f=face
          fullname: "Guille P\xE9rez-Torr\xF3"
          isHf: false
          isPro: false
          name: guishe
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;krumeto&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/krumeto\">@<span class=\"\
          underline\">krumeto</span></a></span>\n\n\t</span></span>!</p>\n<p>Regarding\
          \ document-level context. You can check Tom's thesis, there's a <a rel=\"\
          nofollow\" href=\"https://github.com/tomaarsen/SpanMarkerNER\">link</a>\
          \ to it in the github page. Short summary, when adding adjacent context\
          \ sentences, these are added as additional text tokens but without span-marker\
          \ pairs. That means, text tokens would be able to attend each other, but\
          \ start/end markers will not attend context text tokens, only the ones from\
          \ the target sentence. In theory this setup improves performance, although\
          \ in the thesis there are only reported results comparing no-context vs\
          \ context on CONLL03. So the token distribution setup (check the figures\
          \ in the thesis, they are very insightful to understand the inner working\
          \ of the architecture), do not differ from context to no-context except\
          \ for adding more text tokens, thus, when spreading the tokens to generate\
          \ the embedding matrices to be passed to the encoder, will overflow among\
          \ more samples meaning training/inference time will increase (check this\
          \ in table 3.6 of the thesis).</p>\n<p>Now, answering your questions:</p>\n\
          <ol>\n<li>I'm dealing with long texts in my work. What I do is just split\
          \ by sentences without document-level. Each sentence is processed independently.\
          \ I group by document the entities detected after the inference.</li>\n\
          <li>That message is just preventive. The model has not been trained with\
          \ those additional adjacent context-sentences, so it is not \"prepared\"\
          \ but, as I said before, internally almost nothing changes and nothing prohibits\
          \ you to do so. It's just, this model has not been either trained or tested\
          \ in that scenario, maybe works fine as is or maybe no.</li>\n</ol>\n<p>Hopefully\
          \ this sheds a bit of light on your doubts.</p>\n<p>Cheers!</p>\n"
        raw: 'Hi @krumeto!


          Regarding document-level context. You can check Tom''s thesis, there''s
          a [link](https://github.com/tomaarsen/SpanMarkerNER) to it in the github
          page. Short summary, when adding adjacent context sentences, these are added
          as additional text tokens but without span-marker pairs. That means, text
          tokens would be able to attend each other, but start/end markers will not
          attend context text tokens, only the ones from the target sentence. In theory
          this setup improves performance, although in the thesis there are only reported
          results comparing no-context vs context on CONLL03. So the token distribution
          setup (check the figures in the thesis, they are very insightful to understand
          the inner working of the architecture), do not differ from context to no-context
          except for adding more text tokens, thus, when spreading the tokens to generate
          the embedding matrices to be passed to the encoder, will overflow among
          more samples meaning training/inference time will increase (check this in
          table 3.6 of the thesis).


          Now, answering your questions:


          1) I''m dealing with long texts in my work. What I do is just split by sentences
          without document-level. Each sentence is processed independently. I group
          by document the entities detected after the inference.

          2) That message is just preventive. The model has not been trained with
          those additional adjacent context-sentences, so it is not "prepared" but,
          as I said before, internally almost nothing changes and nothing prohibits
          you to do so. It''s just, this model has not been either trained or tested
          in that scenario, maybe works fine as is or maybe no.


          Hopefully this sheds a bit of light on your doubts.


          Cheers!'
        updatedAt: '2023-11-29T10:31:21.828Z'
      numEdits: 0
      reactions: []
    id: 656712f932a48203e7f6946a
    type: comment
  author: guishe
  content: 'Hi @krumeto!


    Regarding document-level context. You can check Tom''s thesis, there''s a [link](https://github.com/tomaarsen/SpanMarkerNER)
    to it in the github page. Short summary, when adding adjacent context sentences,
    these are added as additional text tokens but without span-marker pairs. That
    means, text tokens would be able to attend each other, but start/end markers will
    not attend context text tokens, only the ones from the target sentence. In theory
    this setup improves performance, although in the thesis there are only reported
    results comparing no-context vs context on CONLL03. So the token distribution
    setup (check the figures in the thesis, they are very insightful to understand
    the inner working of the architecture), do not differ from context to no-context
    except for adding more text tokens, thus, when spreading the tokens to generate
    the embedding matrices to be passed to the encoder, will overflow among more samples
    meaning training/inference time will increase (check this in table 3.6 of the
    thesis).


    Now, answering your questions:


    1) I''m dealing with long texts in my work. What I do is just split by sentences
    without document-level. Each sentence is processed independently. I group by document
    the entities detected after the inference.

    2) That message is just preventive. The model has not been trained with those
    additional adjacent context-sentences, so it is not "prepared" but, as I said
    before, internally almost nothing changes and nothing prohibits you to do so.
    It''s just, this model has not been either trained or tested in that scenario,
    maybe works fine as is or maybe no.


    Hopefully this sheds a bit of light on your doubts.


    Cheers!'
  created_at: 2023-11-29 10:31:21+00:00
  edited: false
  hidden: false
  id: 656712f932a48203e7f6946a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/5vNzCxAqt3Y-0QFIYnrAA.jpeg?w=200&h=200&f=face
      fullname: "Guille P\xE9rez-Torr\xF3"
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: guishe
      type: user
    createdAt: '2023-12-14T18:45:00.000Z'
    data:
      status: closed
    id: 657b4d2c2cbb7f63823a18bd
    type: status-change
  author: guishe
  created_at: 2023-12-14 18:45:00+00:00
  id: 657b4d2c2cbb7f63823a18bd
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: guishe/span-marker-generic-ner-v1-fewnerd-fine-super
repo_type: model
status: closed
target_branch: null
title: Strategies for long documents - document-level context?
