!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kurugai
conflicting_files: null
created_at: 2023-09-03 00:09:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/693615a426ae42f691ce76f8f53653a7.svg
      fullname: HyeongWon Yun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kurugai
      type: user
    createdAt: '2023-09-03T01:09:09.000Z'
    data:
      edited: false
      editors:
      - kurugai
      hidden: false
      identifiedLanguage:
        language: ko
        probability: 0.9992669820785522
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/693615a426ae42f691ce76f8f53653a7.svg
          fullname: HyeongWon Yun
          isHf: false
          isPro: false
          name: kurugai
          type: user
        html: "<p>\uC548\uB155\uD558\uC138\uC694.</p>\n<p>\uBA3C\uC800 StarFox7/Llama-2-ko-7B-chat-gguf\
          \ \uB9CC\uB4E4\uC5B4\uC8FC\uC154\uC11C \uC544\uC8FC \uC720\uC6A9\uD558\uAC8C\
          \ \uC798 \uC0AC\uC6A9\uD558\uACE0 \uC788\uC2B5\uB2C8\uB2E4.<br>\uB2E4\uB984\
          \uC774 \uC544\uB2C8\uB77C \uC81C\uAC00 lora\uB85C \uD559\uC2B5\uD55C \uBAA8\
          \uB378\uB3C4 gguf\uB97C \uB9CC\uB4E4\uACE0 \uC2F6\uC740\uB370 \uD639\uC2DC\
          \ \uC81C\uC791\uD558\uB294 \uBC29\uBC95\uC744 \uACF5\uC720\uD574\uC8FC\uC2E4\
          \uC218 \uC788\uC744\uAE4C\uC694?</p>\n<p>LLAMA.CPP\uC5D0 \uC788\uB294 convert.py\
          \ \uB97C \uC774\uC6A9\uD558\uBA74 gguf \uD30C\uC77C\uC740 \uB9CC\uB4E4\uC5B4\
          \uC9C0\uB294\uB370 load\uB97C \uD560 \uC218 \uC5C6\uC5B4\uC11C \uC774\uAC83\
          \uC800\uAC83 \uC2DC\uB3C4\uD588\uC9C0\uB9CC \uB418\uC9C0 \uC54A\uC544\uC11C\
          \uC694.<br><a rel=\"nofollow\" href=\"https://github.com/ggerganov/llama.cpp/issues/2865\"\
          >https://github.com/ggerganov/llama.cpp/issues/2865</a></p>\n<p>\uC8C4\uC1A1\
          \uD569\uB2C8\uB2E4\uB9CC, \uC54C\uB824\uC8FC\uC2DC\uBA74 github\uC5D0\uB3C4\
          \ \uAC19\uC774 \uC218\uC815\uC0AC\uD56D \uD3EC\uC778\uD2B8\uB97C \uACF5\uC720\
          \uD560 \uC218 \uC788\uC744\uAC83 \uAC19\uC2B5\uB2C8\uB2E4.<br>\uBD80\uD0C1\
          \uB4DC\uB9AC\uACA0\uC2B5\uB2C8\uB2E4.</p>\n"
        raw: "\uC548\uB155\uD558\uC138\uC694.\r\n\r\n\uBA3C\uC800 StarFox7/Llama-2-ko-7B-chat-gguf\
          \ \uB9CC\uB4E4\uC5B4\uC8FC\uC154\uC11C \uC544\uC8FC \uC720\uC6A9\uD558\uAC8C\
          \ \uC798 \uC0AC\uC6A9\uD558\uACE0 \uC788\uC2B5\uB2C8\uB2E4.\r\n\uB2E4\uB984\
          \uC774 \uC544\uB2C8\uB77C \uC81C\uAC00 lora\uB85C \uD559\uC2B5\uD55C \uBAA8\
          \uB378\uB3C4 gguf\uB97C \uB9CC\uB4E4\uACE0 \uC2F6\uC740\uB370 \uD639\uC2DC\
          \ \uC81C\uC791\uD558\uB294 \uBC29\uBC95\uC744 \uACF5\uC720\uD574\uC8FC\uC2E4\
          \uC218 \uC788\uC744\uAE4C\uC694?\r\n\r\nLLAMA.CPP\uC5D0 \uC788\uB294 convert.py\
          \ \uB97C \uC774\uC6A9\uD558\uBA74 gguf \uD30C\uC77C\uC740 \uB9CC\uB4E4\uC5B4\
          \uC9C0\uB294\uB370 load\uB97C \uD560 \uC218 \uC5C6\uC5B4\uC11C \uC774\uAC83\
          \uC800\uAC83 \uC2DC\uB3C4\uD588\uC9C0\uB9CC \uB418\uC9C0 \uC54A\uC544\uC11C\
          \uC694.\r\nhttps://github.com/ggerganov/llama.cpp/issues/2865\r\n\r\n\uC8C4\
          \uC1A1\uD569\uB2C8\uB2E4\uB9CC, \uC54C\uB824\uC8FC\uC2DC\uBA74 github\uC5D0\
          \uB3C4 \uAC19\uC774 \uC218\uC815\uC0AC\uD56D \uD3EC\uC778\uD2B8\uB97C \uACF5\
          \uC720\uD560 \uC218 \uC788\uC744\uAC83 \uAC19\uC2B5\uB2C8\uB2E4.\r\n\uBD80\
          \uD0C1\uB4DC\uB9AC\uACA0\uC2B5\uB2C8\uB2E4."
        updatedAt: '2023-09-03T01:09:09.363Z'
      numEdits: 0
      reactions: []
    id: 64f3dcb5ac4e8ab9b9f35e3d
    type: comment
  author: kurugai
  content: "\uC548\uB155\uD558\uC138\uC694.\r\n\r\n\uBA3C\uC800 StarFox7/Llama-2-ko-7B-chat-gguf\
    \ \uB9CC\uB4E4\uC5B4\uC8FC\uC154\uC11C \uC544\uC8FC \uC720\uC6A9\uD558\uAC8C \uC798\
    \ \uC0AC\uC6A9\uD558\uACE0 \uC788\uC2B5\uB2C8\uB2E4.\r\n\uB2E4\uB984\uC774 \uC544\
    \uB2C8\uB77C \uC81C\uAC00 lora\uB85C \uD559\uC2B5\uD55C \uBAA8\uB378\uB3C4 gguf\uB97C\
    \ \uB9CC\uB4E4\uACE0 \uC2F6\uC740\uB370 \uD639\uC2DC \uC81C\uC791\uD558\uB294\
    \ \uBC29\uBC95\uC744 \uACF5\uC720\uD574\uC8FC\uC2E4\uC218 \uC788\uC744\uAE4C\uC694\
    ?\r\n\r\nLLAMA.CPP\uC5D0 \uC788\uB294 convert.py \uB97C \uC774\uC6A9\uD558\uBA74\
    \ gguf \uD30C\uC77C\uC740 \uB9CC\uB4E4\uC5B4\uC9C0\uB294\uB370 load\uB97C \uD560\
    \ \uC218 \uC5C6\uC5B4\uC11C \uC774\uAC83\uC800\uAC83 \uC2DC\uB3C4\uD588\uC9C0\uB9CC\
    \ \uB418\uC9C0 \uC54A\uC544\uC11C\uC694.\r\nhttps://github.com/ggerganov/llama.cpp/issues/2865\r\
    \n\r\n\uC8C4\uC1A1\uD569\uB2C8\uB2E4\uB9CC, \uC54C\uB824\uC8FC\uC2DC\uBA74 github\uC5D0\
    \uB3C4 \uAC19\uC774 \uC218\uC815\uC0AC\uD56D \uD3EC\uC778\uD2B8\uB97C \uACF5\uC720\
    \uD560 \uC218 \uC788\uC744\uAC83 \uAC19\uC2B5\uB2C8\uB2E4.\r\n\uBD80\uD0C1\uB4DC\
    \uB9AC\uACA0\uC2B5\uB2C8\uB2E4."
  created_at: 2023-09-03 00:09:09+00:00
  edited: false
  hidden: false
  id: 64f3dcb5ac4e8ab9b9f35e3d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/646ea14898e8f749fc604358/UVVe5x4DuEAV0R54QHwYK.png?w=200&h=200&f=face
      fullname: John Youn
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: StarFox7
      type: user
    createdAt: '2023-09-04T06:17:24.000Z'
    data:
      edited: false
      editors:
      - StarFox7
      hidden: false
      identifiedLanguage:
        language: ko
        probability: 0.9997583627700806
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/646ea14898e8f749fc604358/UVVe5x4DuEAV0R54QHwYK.png?w=200&h=200&f=face
          fullname: John Youn
          isHf: false
          isPro: false
          name: StarFox7
          type: user
        html: "<p>llama cpp \uC758  \uCD5C\uC2E0 release \uB294 beta \uC774\uBA70\
          \ convert \uBC0F  inference \uC5D0 \uC0C1\uB2F9\uD55C \uC624\uB958\uAC00\
          \ \uC874\uC7AC\uD558\uACE0 \uC788\uC73C\uBA70 stable version \uAE4C\uC9C0\
          \uB294 \uC2DC\uAC04\uC774 \uB354 \uD544\uC694\uD569\uB2C8\uB2E4. \uC544\uB798\
          \ \uB300\uC548\uC744 \uCD94\uCC9C\uB4DC\uB9BD\uB2C8\uB2E4.</p>\n<ul>\n<li>ggml\
          \ \uC744 \uC9C0\uC6D0\uD558\uB294 llama cpp stable \uBC84\uC804(8\uC6D4\uCD08\
          \ \uC774\uC804) \uC744 \uC0AC\uC6A9\uD558\uC5EC \uB300\uC0C1 \uBAA8\uB378\
          \uC744 ggml \uB85C \uBCC0\uD658 \uD6C4, ggml to gguf convertor \uB97C \uD1B5\
          \uD574 gguf  \uB85C \uBCC0\uD658\uD558\uC5EC \uC0AC\uC6A9</li>\n</ul>\n"
        raw: "llama cpp \uC758  \uCD5C\uC2E0 release \uB294 beta \uC774\uBA70 convert\
          \ \uBC0F  inference \uC5D0 \uC0C1\uB2F9\uD55C \uC624\uB958\uAC00 \uC874\uC7AC\
          \uD558\uACE0 \uC788\uC73C\uBA70 stable version \uAE4C\uC9C0\uB294 \uC2DC\
          \uAC04\uC774 \uB354 \uD544\uC694\uD569\uB2C8\uB2E4. \uC544\uB798 \uB300\uC548\
          \uC744 \uCD94\uCC9C\uB4DC\uB9BD\uB2C8\uB2E4.\n- ggml \uC744 \uC9C0\uC6D0\
          \uD558\uB294 llama cpp stable \uBC84\uC804(8\uC6D4\uCD08 \uC774\uC804) \uC744\
          \ \uC0AC\uC6A9\uD558\uC5EC \uB300\uC0C1 \uBAA8\uB378\uC744 ggml \uB85C \uBCC0\
          \uD658 \uD6C4, ggml to gguf convertor \uB97C \uD1B5\uD574 gguf  \uB85C \uBCC0\
          \uD658\uD558\uC5EC \uC0AC\uC6A9"
        updatedAt: '2023-09-04T06:17:24.741Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - hursm
    id: 64f576747df8c83c9d8a37af
    type: comment
  author: StarFox7
  content: "llama cpp \uC758  \uCD5C\uC2E0 release \uB294 beta \uC774\uBA70 convert\
    \ \uBC0F  inference \uC5D0 \uC0C1\uB2F9\uD55C \uC624\uB958\uAC00 \uC874\uC7AC\uD558\
    \uACE0 \uC788\uC73C\uBA70 stable version \uAE4C\uC9C0\uB294 \uC2DC\uAC04\uC774\
    \ \uB354 \uD544\uC694\uD569\uB2C8\uB2E4. \uC544\uB798 \uB300\uC548\uC744 \uCD94\
    \uCC9C\uB4DC\uB9BD\uB2C8\uB2E4.\n- ggml \uC744 \uC9C0\uC6D0\uD558\uB294 llama\
    \ cpp stable \uBC84\uC804(8\uC6D4\uCD08 \uC774\uC804) \uC744 \uC0AC\uC6A9\uD558\
    \uC5EC \uB300\uC0C1 \uBAA8\uB378\uC744 ggml \uB85C \uBCC0\uD658 \uD6C4, ggml to\
    \ gguf convertor \uB97C \uD1B5\uD574 gguf  \uB85C \uBCC0\uD658\uD558\uC5EC \uC0AC\
    \uC6A9"
  created_at: 2023-09-04 05:17:24+00:00
  edited: false
  hidden: false
  id: 64f576747df8c83c9d8a37af
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/693615a426ae42f691ce76f8f53653a7.svg
      fullname: HyeongWon Yun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kurugai
      type: user
    createdAt: '2023-09-04T09:50:42.000Z'
    data:
      edited: false
      editors:
      - kurugai
      hidden: false
      identifiedLanguage:
        language: ko
        probability: 0.3221471607685089
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/693615a426ae42f691ce76f8f53653a7.svg
          fullname: HyeongWon Yun
          isHf: false
          isPro: false
          name: kurugai
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;StarFox7&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/StarFox7\">@<span class=\"\
          underline\">StarFox7</span></a></span>\n\n\t</span></span><br>\uC544 \uAC10\
          \uC0AC\uD569\uB2C8\uB2E4. \uC608\uC804 \uBC84\uC804 \uAC00\uC9C0\uACE0 \uC788\
          \uB294\uAC8C \uC788\uC5B4\uC11C \uB9D0\uC500\uD574\uC8FC\uC2E0\uAC83 \uCC98\
          \uB7FC \uC9C4\uD589\uC744 \uD558\uC600\uB294\uB370 <code>tokenizer.model</code>\
          \ \uD30C\uC77C\uC774 \uC5C6\uB2E4\uACE0 \uD45C\uC2DC\uB429\uB2C8\uB2E4.\
          \ \uD639\uC2DC <code>tokenizer.model</code>\uC744 \uB9CC\uB4DC\uB294 \uBC29\
          \uBC95\uC744 \uC54C\uB824\uC8FC\uC2E4\uC218 \uC788\uC744\uAE4C\uC694? \uAC70\
          \uC758 \uC77C\uC8FC\uC77C\uC9F8 \uC5EC\uAE30\uC11C \uD5E4\uB9E4\uACE0 \uC788\
          \uC2B5\uB2C8\uB2E4.\u3160\u3160<br>\uBD80\uD0C1\uB4DC\uB9AC\uACA0\uC2B5\uB2C8\
          \uB2E4.</p>\n<pre><code>C:\\AI\\old_llama.cpp&gt;python convert.py .\\models\\\
          kfkas_Llama-2-ko-7b-Chat --outtype f16\nLoading model file models\\kfkas_Llama-2-ko-7b-Chat\\\
          pytorch_model-00001-of-00002.bin\nLoading model file models\\kfkas_Llama-2-ko-7b-Chat\\\
          pytorch_model-00001-of-00002.bin\nLoading model file models\\kfkas_Llama-2-ko-7b-Chat\\\
          pytorch_model-00002-of-00002.bin\nTraceback (most recent call last):\n \
          \ File \"C:\\AI\\old_llama.cpp\\convert.py\", line 1263, in &lt;module&gt;\n\
          \    main()\n  File \"C:\\AI\\old_llama.cpp\\convert.py\", line 1251, in\
          \ main\n    vocab = load_vocab(vocab_dir)\n  File \"C:\\AI\\old_llama.cpp\\\
          convert.py\", line 1187, in load_vocab\n    raise FileNotFoundError(\nFileNotFoundError:\
          \ Could not find tokenizer.model in models\\kfkas_Llama-2-ko-7b-Chat or\
          \ its parent; if it's in another directory, pass the directory as --vocab-dir\n\
          </code></pre>\n"
        raw: "@StarFox7 \n\uC544 \uAC10\uC0AC\uD569\uB2C8\uB2E4. \uC608\uC804 \uBC84\
          \uC804 \uAC00\uC9C0\uACE0 \uC788\uB294\uAC8C \uC788\uC5B4\uC11C \uB9D0\uC500\
          \uD574\uC8FC\uC2E0\uAC83 \uCC98\uB7FC \uC9C4\uD589\uC744 \uD558\uC600\uB294\
          \uB370 `tokenizer.model` \uD30C\uC77C\uC774 \uC5C6\uB2E4\uACE0 \uD45C\uC2DC\
          \uB429\uB2C8\uB2E4. \uD639\uC2DC `tokenizer.model`\uC744 \uB9CC\uB4DC\uB294\
          \ \uBC29\uBC95\uC744 \uC54C\uB824\uC8FC\uC2E4\uC218 \uC788\uC744\uAE4C\uC694\
          ? \uAC70\uC758 \uC77C\uC8FC\uC77C\uC9F8 \uC5EC\uAE30\uC11C \uD5E4\uB9E4\uACE0\
          \ \uC788\uC2B5\uB2C8\uB2E4.\u3160\u3160\n\uBD80\uD0C1\uB4DC\uB9AC\uACA0\uC2B5\
          \uB2C8\uB2E4.\n\n```\nC:\\AI\\old_llama.cpp>python convert.py .\\models\\\
          kfkas_Llama-2-ko-7b-Chat --outtype f16\nLoading model file models\\kfkas_Llama-2-ko-7b-Chat\\\
          pytorch_model-00001-of-00002.bin\nLoading model file models\\kfkas_Llama-2-ko-7b-Chat\\\
          pytorch_model-00001-of-00002.bin\nLoading model file models\\kfkas_Llama-2-ko-7b-Chat\\\
          pytorch_model-00002-of-00002.bin\nTraceback (most recent call last):\n \
          \ File \"C:\\AI\\old_llama.cpp\\convert.py\", line 1263, in <module>\n \
          \   main()\n  File \"C:\\AI\\old_llama.cpp\\convert.py\", line 1251, in\
          \ main\n    vocab = load_vocab(vocab_dir)\n  File \"C:\\AI\\old_llama.cpp\\\
          convert.py\", line 1187, in load_vocab\n    raise FileNotFoundError(\nFileNotFoundError:\
          \ Could not find tokenizer.model in models\\kfkas_Llama-2-ko-7b-Chat or\
          \ its parent; if it's in another directory, pass the directory as --vocab-dir\n\
          ```"
        updatedAt: '2023-09-04T09:50:42.885Z'
      numEdits: 0
      reactions: []
    id: 64f5a872342c391931a70ca6
    type: comment
  author: kurugai
  content: "@StarFox7 \n\uC544 \uAC10\uC0AC\uD569\uB2C8\uB2E4. \uC608\uC804 \uBC84\
    \uC804 \uAC00\uC9C0\uACE0 \uC788\uB294\uAC8C \uC788\uC5B4\uC11C \uB9D0\uC500\uD574\
    \uC8FC\uC2E0\uAC83 \uCC98\uB7FC \uC9C4\uD589\uC744 \uD558\uC600\uB294\uB370 `tokenizer.model`\
    \ \uD30C\uC77C\uC774 \uC5C6\uB2E4\uACE0 \uD45C\uC2DC\uB429\uB2C8\uB2E4. \uD639\
    \uC2DC `tokenizer.model`\uC744 \uB9CC\uB4DC\uB294 \uBC29\uBC95\uC744 \uC54C\uB824\
    \uC8FC\uC2E4\uC218 \uC788\uC744\uAE4C\uC694? \uAC70\uC758 \uC77C\uC8FC\uC77C\uC9F8\
    \ \uC5EC\uAE30\uC11C \uD5E4\uB9E4\uACE0 \uC788\uC2B5\uB2C8\uB2E4.\u3160\u3160\n\
    \uBD80\uD0C1\uB4DC\uB9AC\uACA0\uC2B5\uB2C8\uB2E4.\n\n```\nC:\\AI\\old_llama.cpp>python\
    \ convert.py .\\models\\kfkas_Llama-2-ko-7b-Chat --outtype f16\nLoading model\
    \ file models\\kfkas_Llama-2-ko-7b-Chat\\pytorch_model-00001-of-00002.bin\nLoading\
    \ model file models\\kfkas_Llama-2-ko-7b-Chat\\pytorch_model-00001-of-00002.bin\n\
    Loading model file models\\kfkas_Llama-2-ko-7b-Chat\\pytorch_model-00002-of-00002.bin\n\
    Traceback (most recent call last):\n  File \"C:\\AI\\old_llama.cpp\\convert.py\"\
    , line 1263, in <module>\n    main()\n  File \"C:\\AI\\old_llama.cpp\\convert.py\"\
    , line 1251, in main\n    vocab = load_vocab(vocab_dir)\n  File \"C:\\AI\\old_llama.cpp\\\
    convert.py\", line 1187, in load_vocab\n    raise FileNotFoundError(\nFileNotFoundError:\
    \ Could not find tokenizer.model in models\\kfkas_Llama-2-ko-7b-Chat or its parent;\
    \ if it's in another directory, pass the directory as --vocab-dir\n```"
  created_at: 2023-09-04 08:50:42+00:00
  edited: false
  hidden: false
  id: 64f5a872342c391931a70ca6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/646ea14898e8f749fc604358/UVVe5x4DuEAV0R54QHwYK.png?w=200&h=200&f=face
      fullname: John Youn
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: StarFox7
      type: user
    createdAt: '2023-09-05T04:44:17.000Z'
    data:
      edited: false
      editors:
      - StarFox7
      hidden: false
      identifiedLanguage:
        language: ko
        probability: 0.9990414977073669
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/646ea14898e8f749fc604358/UVVe5x4DuEAV0R54QHwYK.png?w=200&h=200&f=face
          fullname: John Youn
          isHf: false
          isPro: false
          name: StarFox7
          type: user
        html: "<p>tokenizer.model \uC740 meta \uC5D0\uC11C \uACF5\uAC1C\uD55C Llama2\
          \ \uC758 tokenizer.model \uC744 \uADF8\uB300\uB85C \uC0AC\uC6A9\uD558\uC2DC\
          \uBA74 \uB429\uB2C8\uB2E4.<br>\uBCC0\uD658\uD558\uACE0\uC790 \uD558\uC2DC\
          \uB294 kfkas_Llama-2-ko-7b-Chat \uBAA8\uB378\uC740 \uD55C\uAD6D\uC5B4\uB97C\
          \ \uCD94\uAC00\uD55C tokenizer \uB97C \uC0AC\uC6A9\uD558\uACE0 \uC788\uC73C\
          \uBBC0\uB85C, \uC774\uB97C \uBC18\uC601\uD558\uAE30 \uC704\uD574 kfkas_Llama-2-ko-7b-Chat\
          \ \uC5D0\uC11C Llama2 Tokenizer \uC5D0 \uCD94\uAC00\uD55C Additional Token\
          \ \uB9CC\uC744 Json Format \uC73C\uB85C Export \uD558\uC5EC \uBCC0\uD658\
          \ \uB300\uC0C1 \uBAA8\uB378\uC758 \uC0C1\uC704 \uD3F4\uB354\uC5D0 added_tokens.json\
          \ \uD30C\uC77C\uBA85\uC73C\uB85C \uC704\uCE58 \uC2DC\uD0A4\uBA74 \uB429\uB2C8\
          \uB2E4. </p>\n"
        raw: "tokenizer.model \uC740 meta \uC5D0\uC11C \uACF5\uAC1C\uD55C Llama2 \uC758\
          \ tokenizer.model \uC744 \uADF8\uB300\uB85C \uC0AC\uC6A9\uD558\uC2DC\uBA74\
          \ \uB429\uB2C8\uB2E4.\n\uBCC0\uD658\uD558\uACE0\uC790 \uD558\uC2DC\uB294\
          \ kfkas_Llama-2-ko-7b-Chat \uBAA8\uB378\uC740 \uD55C\uAD6D\uC5B4\uB97C \uCD94\
          \uAC00\uD55C tokenizer \uB97C \uC0AC\uC6A9\uD558\uACE0 \uC788\uC73C\uBBC0\
          \uB85C, \uC774\uB97C \uBC18\uC601\uD558\uAE30 \uC704\uD574 kfkas_Llama-2-ko-7b-Chat\
          \ \uC5D0\uC11C Llama2 Tokenizer \uC5D0 \uCD94\uAC00\uD55C Additional Token\
          \ \uB9CC\uC744 Json Format \uC73C\uB85C Export \uD558\uC5EC \uBCC0\uD658\
          \ \uB300\uC0C1 \uBAA8\uB378\uC758 \uC0C1\uC704 \uD3F4\uB354\uC5D0 added_tokens.json\
          \ \uD30C\uC77C\uBA85\uC73C\uB85C \uC704\uCE58 \uC2DC\uD0A4\uBA74 \uB429\uB2C8\
          \uB2E4. "
        updatedAt: '2023-09-05T04:44:17.533Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - hursm
        - kurugai
        - jw0029
    id: 64f6b2213a14cc4dd8bc0535
    type: comment
  author: StarFox7
  content: "tokenizer.model \uC740 meta \uC5D0\uC11C \uACF5\uAC1C\uD55C Llama2 \uC758\
    \ tokenizer.model \uC744 \uADF8\uB300\uB85C \uC0AC\uC6A9\uD558\uC2DC\uBA74 \uB429\
    \uB2C8\uB2E4.\n\uBCC0\uD658\uD558\uACE0\uC790 \uD558\uC2DC\uB294 kfkas_Llama-2-ko-7b-Chat\
    \ \uBAA8\uB378\uC740 \uD55C\uAD6D\uC5B4\uB97C \uCD94\uAC00\uD55C tokenizer \uB97C\
    \ \uC0AC\uC6A9\uD558\uACE0 \uC788\uC73C\uBBC0\uB85C, \uC774\uB97C \uBC18\uC601\
    \uD558\uAE30 \uC704\uD574 kfkas_Llama-2-ko-7b-Chat \uC5D0\uC11C Llama2 Tokenizer\
    \ \uC5D0 \uCD94\uAC00\uD55C Additional Token \uB9CC\uC744 Json Format \uC73C\uB85C\
    \ Export \uD558\uC5EC \uBCC0\uD658 \uB300\uC0C1 \uBAA8\uB378\uC758 \uC0C1\uC704\
    \ \uD3F4\uB354\uC5D0 added_tokens.json \uD30C\uC77C\uBA85\uC73C\uB85C \uC704\uCE58\
    \ \uC2DC\uD0A4\uBA74 \uB429\uB2C8\uB2E4. "
  created_at: 2023-09-05 03:44:17+00:00
  edited: false
  hidden: false
  id: 64f6b2213a14cc4dd8bc0535
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/693615a426ae42f691ce76f8f53653a7.svg
      fullname: HyeongWon Yun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kurugai
      type: user
    createdAt: '2023-09-05T11:32:06.000Z'
    data:
      edited: false
      editors:
      - kurugai
      hidden: false
      identifiedLanguage:
        language: ko
        probability: 1.00006103515625
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/693615a426ae42f691ce76f8f53653a7.svg
          fullname: HyeongWon Yun
          isHf: false
          isPro: false
          name: kurugai
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;StarFox7&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/StarFox7\">@<span class=\"\
          underline\">StarFox7</span></a></span>\n\n\t</span></span><br>\uC815\uB9D0\
          \ \uAC10\uC0AC\uD569\uB2C8\uB2E4. \uC774\uB300\uB85C \uC9C4\uD589\uD574\uBCF4\
          \uACA0\uC2B5\uB2C8\uB2E4. ^^ \uC88B\uC740 \uD558\uB8E8 \uBCF4\uB0B4\uC138\
          \uC694!</p>\n"
        raw: "@StarFox7\n\uC815\uB9D0 \uAC10\uC0AC\uD569\uB2C8\uB2E4. \uC774\uB300\
          \uB85C \uC9C4\uD589\uD574\uBCF4\uACA0\uC2B5\uB2C8\uB2E4. ^^ \uC88B\uC740\
          \ \uD558\uB8E8 \uBCF4\uB0B4\uC138\uC694!"
        updatedAt: '2023-09-05T11:32:06.814Z'
      numEdits: 0
      reactions: []
    id: 64f711b682dcd34b0b5da3ef
    type: comment
  author: kurugai
  content: "@StarFox7\n\uC815\uB9D0 \uAC10\uC0AC\uD569\uB2C8\uB2E4. \uC774\uB300\uB85C\
    \ \uC9C4\uD589\uD574\uBCF4\uACA0\uC2B5\uB2C8\uB2E4. ^^ \uC88B\uC740 \uD558\uB8E8\
    \ \uBCF4\uB0B4\uC138\uC694!"
  created_at: 2023-09-05 10:32:06+00:00
  edited: false
  hidden: false
  id: 64f711b682dcd34b0b5da3ef
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: StarFox7/Llama-2-ko-7B-chat-gguf
repo_type: model
status: open
target_branch: null
title: "qquf \uC81C\uC791 \uBC29\uBC95 \uAD00\uB828"
