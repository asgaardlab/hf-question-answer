!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BlueNipples
conflicting_files: null
created_at: 2023-10-23 03:02:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
      fullname: Matthew Andrews
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BlueNipples
      type: user
    createdAt: '2023-10-23T04:02:01.000Z'
    data:
      edited: true
      editors:
      - BlueNipples
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8225451707839966
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
          fullname: Matthew Andrews
          isHf: false
          isPro: false
          name: BlueNipples
          type: user
        html: '<p>Just sayin''. Both the llama-2 version, and the Mistral version
          are fire. Genuinely great prose and comprehension for RP, especially the
          mistral version. Proper surprised me these. </p>

          <p>I did briefly test this model. Quite promising. Runs better on mobile
          dGPU than 13b models if you use the 2 bit k-quant. Prose is quite complex,
          but a little incoherent. Possible with some tuning this could be great for
          people who sit on the cusp between 7 and 13. </p>

          '
        raw: "Just sayin'. Both the llama-2 version, and the Mistral version are fire.\
          \ Genuinely great prose and comprehension for RP, especially the mistral\
          \ version. Proper surprised me these. \n\nI did briefly test this model.\
          \ Quite promising. Runs better on mobile dGPU than 13b models if you use\
          \ the 2 bit k-quant. Prose is quite complex, but a little incoherent. Possible\
          \ with some tuning this could be great for people who sit on the cusp between\
          \ 7 and 13. "
        updatedAt: '2023-10-23T04:52:28.428Z'
      numEdits: 2
      reactions: []
    id: 6535f0394ac2e2d605858d74
    type: comment
  author: BlueNipples
  content: "Just sayin'. Both the llama-2 version, and the Mistral version are fire.\
    \ Genuinely great prose and comprehension for RP, especially the mistral version.\
    \ Proper surprised me these. \n\nI did briefly test this model. Quite promising.\
    \ Runs better on mobile dGPU than 13b models if you use the 2 bit k-quant. Prose\
    \ is quite complex, but a little incoherent. Possible with some tuning this could\
    \ be great for people who sit on the cusp between 7 and 13. "
  created_at: 2023-10-23 03:02:01+00:00
  edited: true
  hidden: false
  id: 6535f0394ac2e2d605858d74
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6436279eaaef013d1af225c9/31yjIFpqfdvn_n9igumIU.png?w=200&h=200&f=face
      fullname: Alignment Lab AI
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Alignment-Lab-AI
      type: user
    createdAt: '2023-10-27T01:00:36.000Z'
    data:
      edited: false
      editors:
      - Alignment-Lab-AI
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9877496361732483
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6436279eaaef013d1af225c9/31yjIFpqfdvn_n9igumIU.png?w=200&h=200&f=face
          fullname: Alignment Lab AI
          isHf: false
          isPro: false
          name: Alignment-Lab-AI
          type: user
        html: "<p>I can confirm from first hand experience that anything <span data-props=\"\
          {&quot;user&quot;:&quot;LDJnr&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/LDJnr\">@<span class=\"underline\">LDJnr</span></a></span>\n\
          \n\t</span></span>  has on his repository is a product of meticulous design\
          \ and expertise </p>\n"
        raw: 'I can confirm from first hand experience that anything @LDJnr  has on
          his repository is a product of meticulous design and expertise '
        updatedAt: '2023-10-27T01:00:36.874Z'
      numEdits: 0
      reactions: []
    id: 653b0bb49d53a3f851541dfa
    type: comment
  author: Alignment-Lab-AI
  content: 'I can confirm from first hand experience that anything @LDJnr  has on
    his repository is a product of meticulous design and expertise '
  created_at: 2023-10-27 00:00:36+00:00
  edited: false
  hidden: false
  id: 653b0bb49d53a3f851541dfa
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Undi95/Mistral-11B-OmniMix
repo_type: model
status: open
target_branch: null
title: Don't sleep on Nous capybara
