!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lcahill
conflicting_files: null
created_at: 2023-12-17 00:12:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c387297b09e57e6f9101860f7f84cc79.svg
      fullname: Lachlan Cahill
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lcahill
      type: user
    createdAt: '2023-12-17T00:12:05.000Z'
    data:
      edited: false
      editors:
      - lcahill
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4550919532775879
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c387297b09e57e6f9101860f7f84cc79.svg
          fullname: Lachlan Cahill
          isHf: false
          isPro: false
          name: lcahill
          type: user
        html: '<p>I am getting the following warning when loading the model. Not a
          big issue since the model appears to run fine. </p>

          <pre><code>The model ''DeciLMForCausalLM'' is not supported for text-generation.
          Supported models are [''BartForCausalLM'', ''BertLMHeadModel'', ''BertGenerationDecoder'',
          ''BigBirdForCausalLM'', ''BigBirdPegasusForCausalLM'', ''BioGptForCausalLM'',
          ''BlenderbotForCausalLM'', ''BlenderbotSmallForCausalLM'', ''BloomForCausalLM'',
          ''CamembertForCausalLM'', ''LlamaForCausalLM'', ''CodeGenForCausalLM'',
          ''CpmAntForCausalLM'', ''CTRLLMHeadModel'', ''Data2VecTextForCausalLM'',
          ''ElectraForCausalLM'', ''ErnieForCausalLM'', ''FalconForCausalLM'', ''FuyuForCausalLM'',
          ''GitForCausalLM'', ''GPT2LMHeadModel'', ''GPT2LMHeadModel'', ''GPTBigCodeForCausalLM'',
          ''GPTNeoForCausalLM'', ''GPTNeoXForCausalLM'', ''GPTNeoXJapaneseForCausalLM'',
          ''GPTJForCausalLM'', ''LlamaForCausalLM'', ''MarianForCausalLM'', ''MBartForCausalLM'',
          ''MegaForCausalLM'', ''MegatronBertForCausalLM'', ''MistralForCausalLM'',
          ''MixtralForCausalLM'', ''MptForCausalLM'', ''MusicgenForCausalLM'', ''MvpForCausalLM'',
          ''OpenLlamaForCausalLM'', ''OpenAIGPTLMHeadModel'', ''OPTForCausalLM'',
          ''PegasusForCausalLM'', ''PersimmonForCausalLM'', ''PhiForCausalLM'', ''PLBartForCausalLM'',
          ''ProphetNetForCausalLM'', ''QDQBertLMHeadModel'', ''ReformerModelWithLMHead'',
          ''RemBertForCausalLM'', ''RobertaForCausalLM'', ''RobertaPreLayerNormForCausalLM'',
          ''RoCBertForCausalLM'', ''RoFormerForCausalLM'', ''RwkvForCausalLM'', ''Speech2Text2ForCausalLM'',
          ''TransfoXLLMHeadModel'', ''TrOCRForCausalLM'', ''WhisperForCausalLM'',
          ''XGLMForCausalLM'', ''XLMWithLMHeadModel'', ''XLMProphetNetForCausalLM'',
          ''XLMRobertaForCausalLM'', ''XLMRobertaXLForCausalLM'', ''XLNetLMHeadModel'',
          ''XmodForCausalLM''].

          </code></pre>

          <p>I have already upgraded transformers with <code>pip install --upgrade
          transformers</code>. Expect a change may need to be made to the transformers
          library to ensure it recognises this model class. </p>

          '
        raw: "I am getting the following warning when loading the model. Not a big\
          \ issue since the model appears to run fine. \r\n\r\n```\r\nThe model 'DeciLMForCausalLM'\
          \ is not supported for text-generation. Supported models are ['BartForCausalLM',\
          \ 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM',\
          \ 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM',\
          \ 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM',\
          \ 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM',\
          \ 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM',\
          \ 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM',\
          \ 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM',\
          \ 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM',\
          \ 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM',\
          \ 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM',\
          \ 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM',\
          \ 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel',\
          \ 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM',\
          \ 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM',\
          \ 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel',\
          \ 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel',\
          \ 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM',\
          \ 'XLNetLMHeadModel', 'XmodForCausalLM'].\r\n```\r\n\r\nI have already upgraded\
          \ transformers with `pip install --upgrade transformers`. Expect a change\
          \ may need to be made to the transformers library to ensure it recognises\
          \ this model class. "
        updatedAt: '2023-12-17T00:12:05.663Z'
      numEdits: 0
      reactions: []
    id: 657e3cd5138b7e39147fa818
    type: comment
  author: lcahill
  content: "I am getting the following warning when loading the model. Not a big issue\
    \ since the model appears to run fine. \r\n\r\n```\r\nThe model 'DeciLMForCausalLM'\
    \ is not supported for text-generation. Supported models are ['BartForCausalLM',\
    \ 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM',\
    \ 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM',\
    \ 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM',\
    \ 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM',\
    \ 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM',\
    \ 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM',\
    \ 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM',\
    \ 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM',\
    \ 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM',\
    \ 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM',\
    \ 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM',\
    \ 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM',\
    \ 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM',\
    \ 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel',\
    \ 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel',\
    \ 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM',\
    \ 'XLNetLMHeadModel', 'XmodForCausalLM'].\r\n```\r\n\r\nI have already upgraded\
    \ transformers with `pip install --upgrade transformers`. Expect a change may\
    \ need to be made to the transformers library to ensure it recognises this model\
    \ class. "
  created_at: 2023-12-17 00:12:05+00:00
  edited: false
  hidden: false
  id: 657e3cd5138b7e39147fa818
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7c056331fdc4b65505b08c2c83cc127a.svg
      fullname: Tomer Ronen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomer
      type: user
    createdAt: '2023-12-17T18:10:58.000Z'
    data:
      edited: false
      editors:
      - tomer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9622974395751953
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7c056331fdc4b65505b08c2c83cc127a.svg
          fullname: Tomer Ronen
          isHf: false
          isPro: false
          name: tomer
          type: user
        html: '<p>Should be fixed now. Thanks for the heads up!</p>

          '
        raw: Should be fixed now. Thanks for the heads up!
        updatedAt: '2023-12-17T18:10:58.982Z'
      numEdits: 0
      reactions: []
    id: 657f39b219ca6a5e92a0de0d
    type: comment
  author: tomer
  content: Should be fixed now. Thanks for the heads up!
  created_at: 2023-12-17 18:10:58+00:00
  edited: false
  hidden: false
  id: 657f39b219ca6a5e92a0de0d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: Deci/DeciLM-7B-instruct
repo_type: model
status: open
target_branch: null
title: Getting warning when model loaded.
