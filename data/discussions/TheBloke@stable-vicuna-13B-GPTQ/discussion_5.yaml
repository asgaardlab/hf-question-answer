!!python/object:huggingface_hub.community.DiscussionWithDetails
author: boricuapab
conflicting_files: null
created_at: 2023-04-30 04:18:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d70ae605c07e368f8a50543ca42e0eba.svg
      fullname: Pablito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boricuapab
      type: user
    createdAt: '2023-04-30T05:18:57.000Z'
    data:
      edited: false
      editors:
      - boricuapab
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d70ae605c07e368f8a50543ca42e0eba.svg
          fullname: Pablito
          isHf: false
          isPro: false
          name: boricuapab
          type: user
        html: '<p>Starting the web UI...<br>Gradio HTTP request redirected to localhost
          :)<br>Loading TheBloke_stable-vicuna-13B-GPTQ...<br>Found the following
          quantized model: models\TheBloke_stable-vicuna-13B-GPTQ\stable-vicuna-13B-GPTQ-4bit.compat.no-act-order.safetensors<br>Loading
          model ...<br>Traceback (most recent call last):<br>  File "C:\oobaBoo\oobabooga-windows\text-generation-webui\server.py",
          line 914, in <br>    shared.model, shared.tokenizer = load_model(shared.model_name)<br>  File
          "C:\oobaBoo\oobabooga-windows\text-generation-webui\modules\models.py",
          line 158, in load_model<br>    model = load_quantized(model_name)<br>  File
          "C:\oobaBoo\oobabooga-windows\text-generation-webui\modules\GPTQ_loader.py",
          line 173, in load_quantized<br>    model = load_quant(str(path_to_model),
          str(pt_path), shared.args.wbits, shared.args.groupsize, shared.args.pre_layer)<br>  File
          "C:\oobaBoo\oobabooga-windows\text-generation-webui\repositories\GPTQ-for-LLaMa\llama_inference_offload.py",
          line 226, in load_quant<br>    model.load_state_dict(safe_load(checkpoint))<br>  File
          "C:\oobaBoo\oobabooga-windows\installer_files\env\lib\site-packages\torch\nn\modules\module.py",
          line 2041, in load_state_dict<br>    raise RuntimeError(''Error(s) in loading
          state_dict for {}:\n\t{}''.format(<br>RuntimeError: Error(s) in loading
          state_dict for LlamaForCausalLM:<br>        Missing key(s) in state_dict:
          "model.layers.0.self_attn.k_proj.bias", "model.layers.0.self_attn.o_proj.bias",
          "model.layers.0.self_attn.q_proj.bias", "model.layers.0.self_attn.v_proj.bias",
          "model.layers.0.mlp.down_proj.bias", "model.layers.0.mlp.gate_proj.bias",
          "model.layers.0.mlp.up_proj.bias", "model.layers.1.self_attn.k_proj.bias",
          "model.layers.1.self_attn.o_proj.bias", "model.layers.1.self_attn.q_proj.bias",
          "model.layers.1.self_attn.v_proj.bias", "model.layers.1.mlp.down_proj.bias",
          "model.layers.1.mlp.gate_proj.bias", "model.layers.1.mlp.up_proj.bias",
          "model.layers.2.self_attn.k_proj.bias", "model.layers.2.self_attn.o_proj.bias",
          "model.layers.2.self_attn.q_proj.bias", "model.layers.2.self_attn.v_proj.bias",
          "model.layers.2.mlp.down_proj.bias", "model.layers.2.mlp.gate_proj.bias",
          "model.layers.2.mlp.up_proj.bias", "model.layers.3.self_attn.k_proj.bias",
          "model.layers.3.self_attn.o_proj.bias", "model.layers.3.self_attn.q_proj.bias",
          "model.layers.3.self_attn.v_proj.bias", "model.layers.3.mlp.down_proj.bias",
          "model.layers.3.mlp.gate_proj.bias", "model.layers.3.mlp.up_proj.bias",
          "model.layers.4.self_attn.k_proj.bias", "model.layers.4.self_attn.o_proj.bias",
          "model.layers.4.self_attn.q_proj.bias", "model.layers.4.self_attn.v_proj.bias",
          "model.layers.4.mlp.down_proj.bias", "model.layers.4.mlp.gate_proj.bias",
          "model.layers.4.mlp.up_proj.bias", "model.layers.5.self_attn.k_proj.bias",
          "model.layers.5.self_attn.o_proj.bias", "model.layers.5.self_attn.q_proj.bias",
          "model.layers.5.self_attn.v_proj.bias", "model.layers.5.mlp.down_proj.bias",
          "model.layers.5.mlp.gate_proj.bias", "model.layers.5.mlp.up_proj.bias",
          "model.layers.6.self_attn.k_proj.bias", "model.layers.6.self_attn.o_proj.bias",
          "model.layers.6.self_attn.q_proj.bias", "model.layers.6.self_attn.v_proj.bias",
          "model.layers.6.mlp.down_proj.bias", "model.layers.6.mlp.gate_proj.bias",
          "model.layers.6.mlp.up_proj.bias", "model.layers.7.self_attn.k_proj.bias",
          "model.layers.7.self_attn.o_proj.bias", "model.layers.7.self_attn.q_proj.bias",
          "model.layers.7.self_attn.v_proj.bias", "model.layers.7.mlp.down_proj.bias",
          "model.layers.7.mlp.gate_proj.bias", "model.layers.7.mlp.up_proj.bias",
          "model.layers.8.self_attn.k_proj.bias", "model.layers.8.self_attn.o_proj.bias",
          "model.layers.8.self_attn.q_proj.bias", "model.layers.8.self_attn.v_proj.bias",
          "model.layers.8.mlp.down_proj.bias", "model.layers.8.mlp.gate_proj.bias",
          "model.layers.8.mlp.up_proj.bias", "model.layers.9.self_attn.k_proj.bias",
          "model.layers.9.self_attn.o_proj.bias", "model.layers.9.self_attn.q_proj.bias",
          "model.layers.9.self_attn.v_proj.bias", "model.layers.9.mlp.down_proj.bias",
          "model.layers.9.mlp.gate_proj.bias", "model.layers.9.mlp.up_proj.bias",
          "model.layers.10.self_attn.k_proj.bias", "model.layers.10.self_attn.o_proj.bias",
          "model.layers.10.self_attn.q_proj.bias", "model.layers.10.self_attn.v_proj.bias",
          "model.layers.10.mlp.down_proj.bias", "model.layers.10.mlp.gate_proj.bias",
          "model.layers.10.mlp.up_proj.bias", "model.layers.11.self_attn.k_proj.bias",
          "model.layers.11.self_attn.o_proj.bias", "model.layers.11.self_attn.q_proj.bias",
          "model.layers.11.self_attn.v_proj.bias", "model.layers.11.mlp.down_proj.bias",
          "model.layers.11.mlp.gate_proj.bias", "model.layers.11.mlp.up_proj.bias",
          "model.layers.12.self_attn.k_proj.bias", "model.layers.12.self_attn.o_proj.bias",
          "model.layers.12.self_attn.q_proj.bias", "model.layers.12.self_attn.v_proj.bias",
          "model.layers.12.mlp.down_proj.bias", "model.layers.12.mlp.gate_proj.bias",
          "model.layers.12.mlp.up_proj.bias", "model.layers.13.self_attn.k_proj.bias",
          "model.layers.13.self_attn.o_proj.bias", "model.layers.13.self_attn.q_proj.bias",
          "model.layers.13.self_attn.v_proj.bias", "model.layers.13.mlp.down_proj.bias",
          "model.layers.13.mlp.gate_proj.bias", "model.layers.13.mlp.up_proj.bias",
          "model.layers.14.self_attn.k_proj.bias", "model.layers.14.self_attn.o_proj.bias",
          "model.layers.14.self_attn.q_proj.bias", "model.layers.14.self_attn.v_proj.bias",
          "model.layers.14.mlp.down_proj.bias", "model.layers.14.mlp.gate_proj.bias",
          "model.layers.14.mlp.up_proj.bias", "model.layers.15.self_attn.k_proj.bias",
          "model.layers.15.self_attn.o_proj.bias", "model.layers.15.self_attn.q_proj.bias",
          "model.layers.15.self_attn.v_proj.bias", "model.layers.15.mlp.down_proj.bias",
          "model.layers.15.mlp.gate_proj.bias", "model.layers.15.mlp.up_proj.bias",
          "model.layers.16.self_attn.k_proj.bias", "model.layers.16.self_attn.o_proj.bias",
          "model.layers.16.self_attn.q_proj.bias", "model.layers.16.self_attn.v_proj.bias",
          "model.layers.16.mlp.down_proj.bias", "model.layers.16.mlp.gate_proj.bias",
          "model.layers.16.mlp.up_proj.bias", "model.layers.17.self_attn.k_proj.bias",
          "model.layers.17.self_attn.o_proj.bias", "model.layers.17.self_attn.q_proj.bias",
          "model.layers.17.self_attn.v_proj.bias", "model.layers.17.mlp.down_proj.bias",
          "model.layers.17.mlp.gate_proj.bias", "model.layers.17.mlp.up_proj.bias",
          "model.layers.18.self_attn.k_proj.bias", "model.layers.18.self_attn.o_proj.bias",
          "model.layers.18.self_attn.q_proj.bias", "model.layers.18.self_attn.v_proj.bias",
          "model.layers.18.mlp.down_proj.bias", "model.layers.18.mlp.gate_proj.bias",
          "model.layers.18.mlp.up_proj.bias", "model.layers.19.self_attn.k_proj.bias",
          "model.layers.19.self_attn.o_proj.bias", "model.layers.19.self_attn.q_proj.bias",
          "model.layers.19.self_attn.v_proj.bias", "model.layers.19.mlp.down_proj.bias",
          "model.layers.19.mlp.gate_proj.bias", "model.layers.19.mlp.up_proj.bias",
          "model.layers.20.self_attn.k_proj.bias", "model.layers.20.self_attn.o_proj.bias",
          "model.layers.20.self_attn.q_proj.bias", "model.layers.20.self_attn.v_proj.bias",
          "model.layers.20.mlp.down_proj.bias", "model.layers.20.mlp.gate_proj.bias",
          "model.layers.20.mlp.up_proj.bias", "model.layers.21.self_attn.k_proj.bias",
          "model.layers.21.self_attn.o_proj.bias", "model.layers.21.self_attn.q_proj.bias",
          "model.layers.21.self_attn.v_proj.bias", "model.layers.21.mlp.down_proj.bias",
          "model.layers.21.mlp.gate_proj.bias", "model.layers.21.mlp.up_proj.bias",
          "model.layers.22.self_attn.k_proj.bias", "model.layers.22.self_attn.o_proj.bias",
          "model.layers.22.self_attn.q_proj.bias", "model.layers.22.self_attn.v_proj.bias",
          "model.layers.22.mlp.down_proj.bias", "model.layers.22.mlp.gate_proj.bias",
          "model.layers.22.mlp.up_proj.bias", "model.layers.23.self_attn.k_proj.bias",
          "model.layers.23.self_attn.o_proj.bias", "model.layers.23.self_attn.q_proj.bias",
          "model.layers.23.self_attn.v_proj.bias", "model.layers.23.mlp.down_proj.bias",
          "model.layers.23.mlp.gate_proj.bias", "model.layers.23.mlp.up_proj.bias",
          "model.layers.24.self_attn.k_proj.bias", "model.layers.24.self_attn.o_proj.bias",
          "model.layers.24.self_attn.q_proj.bias", "model.layers.24.self_attn.v_proj.bias",
          "model.layers.24.mlp.down_proj.bias", "model.layers.24.mlp.gate_proj.bias",
          "model.layers.24.mlp.up_proj.bias", "model.layers.25.self_attn.k_proj.bias",
          "model.layers.25.self_attn.o_proj.bias", "model.layers.25.self_attn.q_proj.bias",
          "model.layers.25.self_attn.v_proj.bias", "model.layers.25.mlp.down_proj.bias",
          "model.layers.25.mlp.gate_proj.bias", "model.layers.25.mlp.up_proj.bias",
          "model.layers.26.self_attn.k_proj.bias", "model.layers.26.self_attn.o_proj.bias",
          "model.layers.26.self_attn.q_proj.bias", "model.layers.26.self_attn.v_proj.bias",
          "model.layers.26.mlp.down_proj.bias", "model.layers.26.mlp.gate_proj.bias",
          "model.layers.26.mlp.up_proj.bias", "model.layers.27.self_attn.k_proj.bias",
          "model.layers.27.self_attn.o_proj.bias", "model.layers.27.self_attn.q_proj.bias",
          "model.layers.27.self_attn.v_proj.bias", "model.layers.27.mlp.down_proj.bias",
          "model.layers.27.mlp.gate_proj.bias", "model.layers.27.mlp.up_proj.bias",
          "model.layers.28.self_attn.k_proj.bias", "model.layers.28.self_attn.o_proj.bias",
          "model.layers.28.self_attn.q_proj.bias", "model.layers.28.self_attn.v_proj.bias",
          "model.layers.28.mlp.down_proj.bias", "model.layers.28.mlp.gate_proj.bias",
          "model.layers.28.mlp.up_proj.bias", "model.layers.29.self_attn.k_proj.bias",
          "model.layers.29.self_attn.o_proj.bias", "model.layers.29.self_attn.q_proj.bias",
          "model.layers.29.self_attn.v_proj.bias", "model.layers.29.mlp.down_proj.bias",
          "model.layers.29.mlp.gate_proj.bias", "model.layers.29.mlp.up_proj.bias",
          "model.layers.30.self_attn.k_proj.bias", "model.layers.30.self_attn.o_proj.bias",
          "model.layers.30.self_attn.q_proj.bias", "model.layers.30.self_attn.v_proj.bias",
          "model.layers.30.mlp.down_proj.bias", "model.layers.30.mlp.gate_proj.bias",
          "model.layers.30.mlp.up_proj.bias", "model.layers.31.self_attn.k_proj.bias",
          "model.layers.31.self_attn.o_proj.bias", "model.layers.31.self_attn.q_proj.bias",
          "model.layers.31.self_attn.v_proj.bias", "model.layers.31.mlp.down_proj.bias",
          "model.layers.31.mlp.gate_proj.bias", "model.layers.31.mlp.up_proj.bias",
          "model.layers.32.self_attn.k_proj.bias", "model.layers.32.self_attn.o_proj.bias",
          "model.layers.32.self_attn.q_proj.bias", "model.layers.32.self_attn.v_proj.bias",
          "model.layers.32.mlp.down_proj.bias", "model.layers.32.mlp.gate_proj.bias",
          "model.layers.32.mlp.up_proj.bias", "model.layers.33.self_attn.k_proj.bias",
          "model.layers.33.self_attn.o_proj.bias", "model.layers.33.self_attn.q_proj.bias",
          "model.layers.33.self_attn.v_proj.bias", "model.layers.33.mlp.down_proj.bias",
          "model.layers.33.mlp.gate_proj.bias", "model.layers.33.mlp.up_proj.bias",
          "model.layers.34.self_attn.k_proj.bias", "model.layers.34.self_attn.o_proj.bias",
          "model.layers.34.self_attn.q_proj.bias", "model.layers.34.self_attn.v_proj.bias",
          "model.layers.34.mlp.down_proj.bias", "model.layers.34.mlp.gate_proj.bias",
          "model.layers.34.mlp.up_proj.bias", "model.layers.35.self_attn.k_proj.bias",
          "model.layers.35.self_attn.o_proj.bias", "model.layers.35.self_attn.q_proj.bias",
          "model.layers.35.self_attn.v_proj.bias", "model.layers.35.mlp.down_proj.bias",
          "model.layers.35.mlp.gate_proj.bias", "model.layers.35.mlp.up_proj.bias",
          "model.layers.36.self_attn.k_proj.bias", "model.layers.36.self_attn.o_proj.bias",
          "model.layers.36.self_attn.q_proj.bias", "model.layers.36.self_attn.v_proj.bias",
          "model.layers.36.mlp.down_proj.bias", "model.layers.36.mlp.gate_proj.bias",
          "model.layers.36.mlp.up_proj.bias", "model.layers.37.self_attn.k_proj.bias",
          "model.layers.37.self_attn.o_proj.bias", "model.layers.37.self_attn.q_proj.bias",
          "model.layers.37.self_attn.v_proj.bias", "model.layers.37.mlp.down_proj.bias",
          "model.layers.37.mlp.gate_proj.bias", "model.layers.37.mlp.up_proj.bias",
          "model.layers.38.self_attn.k_proj.bias", "model.layers.38.self_attn.o_proj.bias",
          "model.layers.38.self_attn.q_proj.bias", "model.layers.38.self_attn.v_proj.bias",
          "model.layers.38.mlp.down_proj.bias", "model.layers.38.mlp.gate_proj.bias",
          "model.layers.38.mlp.up_proj.bias", "model.layers.39.self_attn.k_proj.bias",
          "model.layers.39.self_attn.o_proj.bias", "model.layers.39.self_attn.q_proj.bias",
          "model.layers.39.self_attn.v_proj.bias", "model.layers.39.mlp.down_proj.bias",
          "model.layers.39.mlp.gate_proj.bias", "model.layers.39.mlp.up_proj.bias".<br>        Unexpected
          key(s) in state_dict: "model.layers.0.self_attn.k_proj.g_idx", "model.layers.0.self_attn.o_proj.g_idx",
          "model.layers.0.self_attn.q_proj.g_idx", "model.layers.0.self_attn.v_proj.g_idx",
          "model.layers.0.mlp.down_proj.g_idx", "model.layers.0.mlp.gate_proj.g_idx",
          "model.layers.0.mlp.up_proj.g_idx", "model.layers.1.self_attn.k_proj.g_idx",
          "model.layers.1.self_attn.o_proj.g_idx", "model.layers.1.self_attn.q_proj.g_idx",
          "model.layers.1.self_attn.v_proj.g_idx", "model.layers.1.mlp.down_proj.g_idx",
          "model.layers.1.mlp.gate_proj.g_idx", "model.layers.1.mlp.up_proj.g_idx",
          "model.layers.2.self_attn.k_proj.g_idx", "model.layers.2.self_attn.o_proj.g_idx",
          "model.layers.2.self_attn.q_proj.g_idx", "model.layers.2.self_attn.v_proj.g_idx",
          "model.layers.2.mlp.down_proj.g_idx", "model.layers.2.mlp.gate_proj.g_idx",
          "model.layers.2.mlp.up_proj.g_idx", "model.layers.3.self_attn.k_proj.g_idx",
          "model.layers.3.self_attn.o_proj.g_idx", "model.layers.3.self_attn.q_proj.g_idx",
          "model.layers.3.self_attn.v_proj.g_idx", "model.layers.3.mlp.down_proj.g_idx",
          "model.layers.3.mlp.gate_proj.g_idx", "model.layers.3.mlp.up_proj.g_idx",
          "model.layers.4.self_attn.k_proj.g_idx", "model.layers.4.self_attn.o_proj.g_idx",
          "model.layers.4.self_attn.q_proj.g_idx", "model.layers.4.self_attn.v_proj.g_idx",
          "model.layers.4.mlp.down_proj.g_idx", "model.layers.4.mlp.gate_proj.g_idx",
          "model.layers.4.mlp.up_proj.g_idx", "model.layers.5.self_attn.k_proj.g_idx",
          "model.layers.5.self_attn.o_proj.g_idx", "model.layers.5.self_attn.q_proj.g_idx",
          "model.layers.5.self_attn.v_proj.g_idx", "model.layers.5.mlp.down_proj.g_idx",
          "model.layers.5.mlp.gate_proj.g_idx", "model.layers.5.mlp.up_proj.g_idx",
          "model.layers.6.self_attn.k_proj.g_idx", "model.layers.6.self_attn.o_proj.g_idx",
          "model.layers.6.self_attn.q_proj.g_idx", "model.layers.6.self_attn.v_proj.g_idx",
          "model.layers.6.mlp.down_proj.g_idx", "model.layers.6.mlp.gate_proj.g_idx",
          "model.layers.6.mlp.up_proj.g_idx", "model.layers.7.self_attn.k_proj.g_idx",
          "model.layers.7.self_attn.o_proj.g_idx", "model.layers.7.self_attn.q_proj.g_idx",
          "model.layers.7.self_attn.v_proj.g_idx", "model.layers.7.mlp.down_proj.g_idx",
          "model.layers.7.mlp.gate_proj.g_idx", "model.layers.7.mlp.up_proj.g_idx",
          "model.layers.8.self_attn.k_proj.g_idx", "model.layers.8.self_attn.o_proj.g_idx",
          "model.layers.8.self_attn.q_proj.g_idx", "model.layers.8.self_attn.v_proj.g_idx",
          "model.layers.8.mlp.down_proj.g_idx", "model.layers.8.mlp.gate_proj.g_idx",
          "model.layers.8.mlp.up_proj.g_idx", "model.layers.9.self_attn.k_proj.g_idx",
          "model.layers.9.self_attn.o_proj.g_idx", "model.layers.9.self_attn.q_proj.g_idx",
          "model.layers.9.self_attn.v_proj.g_idx", "model.layers.9.mlp.down_proj.g_idx",
          "model.layers.9.mlp.gate_proj.g_idx", "model.layers.9.mlp.up_proj.g_idx",
          "model.layers.10.self_attn.k_proj.g_idx", "model.layers.10.self_attn.o_proj.g_idx",
          "model.layers.10.self_attn.q_proj.g_idx", "model.layers.10.self_attn.v_proj.g_idx",
          "model.layers.10.mlp.down_proj.g_idx", "model.layers.10.mlp.gate_proj.g_idx",
          "model.layers.10.mlp.up_proj.g_idx", "model.layers.11.self_attn.k_proj.g_idx",
          "model.layers.11.self_attn.o_proj.g_idx", "model.layers.11.self_attn.q_proj.g_idx",
          "model.layers.11.self_attn.v_proj.g_idx", "model.layers.11.mlp.down_proj.g_idx",
          "model.layers.11.mlp.gate_proj.g_idx", "model.layers.11.mlp.up_proj.g_idx",
          "model.layers.12.self_attn.k_proj.g_idx", "model.layers.12.self_attn.o_proj.g_idx",
          "model.layers.12.self_attn.q_proj.g_idx", "model.layers.12.self_attn.v_proj.g_idx",
          "model.layers.12.mlp.down_proj.g_idx", "model.layers.12.mlp.gate_proj.g_idx",
          "model.layers.12.mlp.up_proj.g_idx", "model.layers.13.self_attn.k_proj.g_idx",
          "model.layers.13.self_attn.o_proj.g_idx", "model.layers.13.self_attn.q_proj.g_idx",
          "model.layers.13.self_attn.v_proj.g_idx", "model.layers.13.mlp.down_proj.g_idx",
          "model.layers.13.mlp.gate_proj.g_idx", "model.layers.13.mlp.up_proj.g_idx",
          "model.layers.14.self_attn.k_proj.g_idx", "model.layers.14.self_attn.o_proj.g_idx",
          "model.layers.14.self_attn.q_proj.g_idx", "model.layers.14.self_attn.v_proj.g_idx",
          "model.layers.14.mlp.down_proj.g_idx", "model.layers.14.mlp.gate_proj.g_idx",
          "model.layers.14.mlp.up_proj.g_idx", "model.layers.15.self_attn.k_proj.g_idx",
          "model.layers.15.self_attn.o_proj.g_idx", "model.layers.15.self_attn.q_proj.g_idx",
          "model.layers.15.self_attn.v_proj.g_idx", "model.layers.15.mlp.down_proj.g_idx",
          "model.layers.15.mlp.gate_proj.g_idx", "model.layers.15.mlp.up_proj.g_idx",
          "model.layers.16.self_attn.k_proj.g_idx", "model.layers.16.self_attn.o_proj.g_idx",
          "model.layers.16.self_attn.q_proj.g_idx", "model.layers.16.self_attn.v_proj.g_idx",
          "model.layers.16.mlp.down_proj.g_idx", "model.layers.16.mlp.gate_proj.g_idx",
          "model.layers.16.mlp.up_proj.g_idx", "model.layers.17.self_attn.k_proj.g_idx",
          "model.layers.17.self_attn.o_proj.g_idx", "model.layers.17.self_attn.q_proj.g_idx",
          "model.layers.17.self_attn.v_proj.g_idx", "model.layers.17.mlp.down_proj.g_idx",
          "model.layers.17.mlp.gate_proj.g_idx", "model.layers.17.mlp.up_proj.g_idx",
          "model.layers.18.self_attn.k_proj.g_idx", "model.layers.18.self_attn.o_proj.g_idx",
          "model.layers.18.self_attn.q_proj.g_idx", "model.layers.18.self_attn.v_proj.g_idx",
          "model.layers.18.mlp.down_proj.g_idx", "model.layers.18.mlp.gate_proj.g_idx",
          "model.layers.18.mlp.up_proj.g_idx", "model.layers.19.self_attn.k_proj.g_idx",
          "model.layers.19.self_attn.o_proj.g_idx", "model.layers.19.self_attn.q_proj.g_idx",
          "model.layers.19.self_attn.v_proj.g_idx", "model.layers.19.mlp.down_proj.g_idx",
          "model.layers.19.mlp.gate_proj.g_idx", "model.layers.19.mlp.up_proj.g_idx",
          "model.layers.20.self_attn.k_proj.g_idx", "model.layers.20.self_attn.o_proj.g_idx",
          "model.layers.20.self_attn.q_proj.g_idx", "model.layers.20.self_attn.v_proj.g_idx",
          "model.layers.20.mlp.down_proj.g_idx", "model.layers.20.mlp.gate_proj.g_idx",
          "model.layers.20.mlp.up_proj.g_idx", "model.layers.21.self_attn.k_proj.g_idx",
          "model.layers.21.self_attn.o_proj.g_idx", "model.layers.21.self_attn.q_proj.g_idx",
          "model.layers.21.self_attn.v_proj.g_idx", "model.layers.21.mlp.down_proj.g_idx",
          "model.layers.21.mlp.gate_proj.g_idx", "model.layers.21.mlp.up_proj.g_idx",
          "model.layers.22.self_attn.k_proj.g_idx", "model.layers.22.self_attn.o_proj.g_idx",
          "model.layers.22.self_attn.q_proj.g_idx", "model.layers.22.self_attn.v_proj.g_idx",
          "model.layers.22.mlp.down_proj.g_idx", "model.layers.22.mlp.gate_proj.g_idx",
          "model.layers.22.mlp.up_proj.g_idx", "model.layers.23.self_attn.k_proj.g_idx",
          "model.layers.23.self_attn.o_proj.g_idx", "model.layers.23.self_attn.q_proj.g_idx",
          "model.layers.23.self_attn.v_proj.g_idx", "model.layers.23.mlp.down_proj.g_idx",
          "model.layers.23.mlp.gate_proj.g_idx", "model.layers.23.mlp.up_proj.g_idx",
          "model.layers.24.self_attn.k_proj.g_idx", "model.layers.24.self_attn.o_proj.g_idx",
          "model.layers.24.self_attn.q_proj.g_idx", "model.layers.24.self_attn.v_proj.g_idx",
          "model.layers.24.mlp.down_proj.g_idx", "model.layers.24.mlp.gate_proj.g_idx",
          "model.layers.24.mlp.up_proj.g_idx", "model.layers.25.self_attn.k_proj.g_idx",
          "model.layers.25.self_attn.o_proj.g_idx", "model.layers.25.self_attn.q_proj.g_idx",
          "model.layers.25.self_attn.v_proj.g_idx", "model.layers.25.mlp.down_proj.g_idx",
          "model.layers.25.mlp.gate_proj.g_idx", "model.layers.25.mlp.up_proj.g_idx",
          "model.layers.26.self_attn.k_proj.g_idx", "model.layers.26.self_attn.o_proj.g_idx",
          "model.layers.26.self_attn.q_proj.g_idx", "model.layers.26.self_attn.v_proj.g_idx",
          "model.layers.26.mlp.down_proj.g_idx", "model.layers.26.mlp.gate_proj.g_idx",
          "model.layers.26.mlp.up_proj.g_idx", "model.layers.27.self_attn.k_proj.g_idx",
          "model.layers.27.self_attn.o_proj.g_idx", "model.layers.27.self_attn.q_proj.g_idx",
          "model.layers.27.self_attn.v_proj.g_idx", "model.layers.27.mlp.down_proj.g_idx",
          "model.layers.27.mlp.gate_proj.g_idx", "model.layers.27.mlp.up_proj.g_idx",
          "model.layers.28.self_attn.k_proj.g_idx", "model.layers.28.self_attn.o_proj.g_idx",
          "model.layers.28.self_attn.q_proj.g_idx", "model.layers.28.self_attn.v_proj.g_idx",
          "model.layers.28.mlp.down_proj.g_idx", "model.layers.28.mlp.gate_proj.g_idx",
          "model.layers.28.mlp.up_proj.g_idx", "model.layers.29.self_attn.k_proj.g_idx",
          "model.layers.29.self_attn.o_proj.g_idx", "model.layers.29.self_attn.q_proj.g_idx",
          "model.layers.29.self_attn.v_proj.g_idx", "model.layers.29.mlp.down_proj.g_idx",
          "model.layers.29.mlp.gate_proj.g_idx", "model.layers.29.mlp.up_proj.g_idx",
          "model.layers.30.self_attn.k_proj.g_idx", "model.layers.30.self_attn.o_proj.g_idx",
          "model.layers.30.self_attn.q_proj.g_idx", "model.layers.30.self_attn.v_proj.g_idx",
          "model.layers.30.mlp.down_proj.g_idx", "model.layers.30.mlp.gate_proj.g_idx",
          "model.layers.30.mlp.up_proj.g_idx", "model.layers.31.self_attn.k_proj.g_idx",
          "model.layers.31.self_attn.o_proj.g_idx", "model.layers.31.self_attn.q_proj.g_idx",
          "model.layers.31.self_attn.v_proj.g_idx", "model.layers.31.mlp.down_proj.g_idx",
          "model.layers.31.mlp.gate_proj.g_idx", "model.layers.31.mlp.up_proj.g_idx",
          "model.layers.32.self_attn.k_proj.g_idx", "model.layers.32.self_attn.o_proj.g_idx",
          "model.layers.32.self_attn.q_proj.g_idx", "model.layers.32.self_attn.v_proj.g_idx",
          "model.layers.32.mlp.down_proj.g_idx", "model.layers.32.mlp.gate_proj.g_idx",
          "model.layers.32.mlp.up_proj.g_idx", "model.layers.33.self_attn.k_proj.g_idx",
          "model.layers.33.self_attn.o_proj.g_idx", "model.layers.33.self_attn.q_proj.g_idx",
          "model.layers.33.self_attn.v_proj.g_idx", "model.layers.33.mlp.down_proj.g_idx",
          "model.layers.33.mlp.gate_proj.g_idx", "model.layers.33.mlp.up_proj.g_idx",
          "model.layers.34.self_attn.k_proj.g_idx", "model.layers.34.self_attn.o_proj.g_idx",
          "model.layers.34.self_attn.q_proj.g_idx", "model.layers.34.self_attn.v_proj.g_idx",
          "model.layers.34.mlp.down_proj.g_idx", "model.layers.34.mlp.gate_proj.g_idx",
          "model.layers.34.mlp.up_proj.g_idx", "model.layers.35.self_attn.k_proj.g_idx",
          "model.layers.35.self_attn.o_proj.g_idx", "model.layers.35.self_attn.q_proj.g_idx",
          "model.layers.35.self_attn.v_proj.g_idx", "model.layers.35.mlp.down_proj.g_idx",
          "model.layers.35.mlp.gate_proj.g_idx", "model.layers.35.mlp.up_proj.g_idx",
          "model.layers.36.self_attn.k_proj.g_idx", "model.layers.36.self_attn.o_proj.g_idx",
          "model.layers.36.self_attn.q_proj.g_idx", "model.layers.36.self_attn.v_proj.g_idx",
          "model.layers.36.mlp.down_proj.g_idx", "model.layers.36.mlp.gate_proj.g_idx",
          "model.layers.36.mlp.up_proj.g_idx", "model.layers.37.self_attn.k_proj.g_idx",
          "model.layers.37.self_attn.o_proj.g_idx", "model.layers.37.self_attn.q_proj.g_idx",
          "model.layers.37.self_attn.v_proj.g_idx", "model.layers.37.mlp.down_proj.g_idx",
          "model.layers.37.mlp.gate_proj.g_idx", "model.layers.37.mlp.up_proj.g_idx",
          "model.layers.38.self_attn.k_proj.g_idx", "model.layers.38.self_attn.o_proj.g_idx",
          "model.layers.38.self_attn.q_proj.g_idx", "model.layers.38.self_attn.v_proj.g_idx",
          "model.layers.38.mlp.down_proj.g_idx", "model.layers.38.mlp.gate_proj.g_idx",
          "model.layers.38.mlp.up_proj.g_idx", "model.layers.39.self_attn.k_proj.g_idx",
          "model.layers.39.self_attn.o_proj.g_idx", "model.layers.39.self_attn.q_proj.g_idx",
          "model.layers.39.self_attn.v_proj.g_idx", "model.layers.39.mlp.down_proj.g_idx",
          "model.layers.39.mlp.gate_proj.g_idx", "model.layers.39.mlp.up_proj.g_idx".<br>Press
          any key to continue . . .</p>

          '
        raw: "Starting the web UI...\r\nGradio HTTP request redirected to localhost\
          \ :)\r\nLoading TheBloke_stable-vicuna-13B-GPTQ...\r\nFound the following\
          \ quantized model: models\\TheBloke_stable-vicuna-13B-GPTQ\\stable-vicuna-13B-GPTQ-4bit.compat.no-act-order.safetensors\r\
          \nLoading model ...\r\nTraceback (most recent call last):\r\n  File \"C:\\\
          oobaBoo\\oobabooga-windows\\text-generation-webui\\server.py\", line 914,\
          \ in <module>\r\n    shared.model, shared.tokenizer = load_model(shared.model_name)\r\
          \n  File \"C:\\oobaBoo\\oobabooga-windows\\text-generation-webui\\modules\\\
          models.py\", line 158, in load_model\r\n    model = load_quantized(model_name)\r\
          \n  File \"C:\\oobaBoo\\oobabooga-windows\\text-generation-webui\\modules\\\
          GPTQ_loader.py\", line 173, in load_quantized\r\n    model = load_quant(str(path_to_model),\
          \ str(pt_path), shared.args.wbits, shared.args.groupsize, shared.args.pre_layer)\r\
          \n  File \"C:\\oobaBoo\\oobabooga-windows\\text-generation-webui\\repositories\\\
          GPTQ-for-LLaMa\\llama_inference_offload.py\", line 226, in load_quant\r\n\
          \    model.load_state_dict(safe_load(checkpoint))\r\n  File \"C:\\oobaBoo\\\
          oobabooga-windows\\installer_files\\env\\lib\\site-packages\\torch\\nn\\\
          modules\\module.py\", line 2041, in load_state_dict\r\n    raise RuntimeError('Error(s)\
          \ in loading state_dict for {}:\\n\\t{}'.format(\r\nRuntimeError: Error(s)\
          \ in loading state_dict for LlamaForCausalLM:\r\n        Missing key(s)\
          \ in state_dict: \"model.layers.0.self_attn.k_proj.bias\", \"model.layers.0.self_attn.o_proj.bias\"\
          , \"model.layers.0.self_attn.q_proj.bias\", \"model.layers.0.self_attn.v_proj.bias\"\
          , \"model.layers.0.mlp.down_proj.bias\", \"model.layers.0.mlp.gate_proj.bias\"\
          , \"model.layers.0.mlp.up_proj.bias\", \"model.layers.1.self_attn.k_proj.bias\"\
          , \"model.layers.1.self_attn.o_proj.bias\", \"model.layers.1.self_attn.q_proj.bias\"\
          , \"model.layers.1.self_attn.v_proj.bias\", \"model.layers.1.mlp.down_proj.bias\"\
          , \"model.layers.1.mlp.gate_proj.bias\", \"model.layers.1.mlp.up_proj.bias\"\
          , \"model.layers.2.self_attn.k_proj.bias\", \"model.layers.2.self_attn.o_proj.bias\"\
          , \"model.layers.2.self_attn.q_proj.bias\", \"model.layers.2.self_attn.v_proj.bias\"\
          , \"model.layers.2.mlp.down_proj.bias\", \"model.layers.2.mlp.gate_proj.bias\"\
          , \"model.layers.2.mlp.up_proj.bias\", \"model.layers.3.self_attn.k_proj.bias\"\
          , \"model.layers.3.self_attn.o_proj.bias\", \"model.layers.3.self_attn.q_proj.bias\"\
          , \"model.layers.3.self_attn.v_proj.bias\", \"model.layers.3.mlp.down_proj.bias\"\
          , \"model.layers.3.mlp.gate_proj.bias\", \"model.layers.3.mlp.up_proj.bias\"\
          , \"model.layers.4.self_attn.k_proj.bias\", \"model.layers.4.self_attn.o_proj.bias\"\
          , \"model.layers.4.self_attn.q_proj.bias\", \"model.layers.4.self_attn.v_proj.bias\"\
          , \"model.layers.4.mlp.down_proj.bias\", \"model.layers.4.mlp.gate_proj.bias\"\
          , \"model.layers.4.mlp.up_proj.bias\", \"model.layers.5.self_attn.k_proj.bias\"\
          , \"model.layers.5.self_attn.o_proj.bias\", \"model.layers.5.self_attn.q_proj.bias\"\
          , \"model.layers.5.self_attn.v_proj.bias\", \"model.layers.5.mlp.down_proj.bias\"\
          , \"model.layers.5.mlp.gate_proj.bias\", \"model.layers.5.mlp.up_proj.bias\"\
          , \"model.layers.6.self_attn.k_proj.bias\", \"model.layers.6.self_attn.o_proj.bias\"\
          , \"model.layers.6.self_attn.q_proj.bias\", \"model.layers.6.self_attn.v_proj.bias\"\
          , \"model.layers.6.mlp.down_proj.bias\", \"model.layers.6.mlp.gate_proj.bias\"\
          , \"model.layers.6.mlp.up_proj.bias\", \"model.layers.7.self_attn.k_proj.bias\"\
          , \"model.layers.7.self_attn.o_proj.bias\", \"model.layers.7.self_attn.q_proj.bias\"\
          , \"model.layers.7.self_attn.v_proj.bias\", \"model.layers.7.mlp.down_proj.bias\"\
          , \"model.layers.7.mlp.gate_proj.bias\", \"model.layers.7.mlp.up_proj.bias\"\
          , \"model.layers.8.self_attn.k_proj.bias\", \"model.layers.8.self_attn.o_proj.bias\"\
          , \"model.layers.8.self_attn.q_proj.bias\", \"model.layers.8.self_attn.v_proj.bias\"\
          , \"model.layers.8.mlp.down_proj.bias\", \"model.layers.8.mlp.gate_proj.bias\"\
          , \"model.layers.8.mlp.up_proj.bias\", \"model.layers.9.self_attn.k_proj.bias\"\
          , \"model.layers.9.self_attn.o_proj.bias\", \"model.layers.9.self_attn.q_proj.bias\"\
          , \"model.layers.9.self_attn.v_proj.bias\", \"model.layers.9.mlp.down_proj.bias\"\
          , \"model.layers.9.mlp.gate_proj.bias\", \"model.layers.9.mlp.up_proj.bias\"\
          , \"model.layers.10.self_attn.k_proj.bias\", \"model.layers.10.self_attn.o_proj.bias\"\
          , \"model.layers.10.self_attn.q_proj.bias\", \"model.layers.10.self_attn.v_proj.bias\"\
          , \"model.layers.10.mlp.down_proj.bias\", \"model.layers.10.mlp.gate_proj.bias\"\
          , \"model.layers.10.mlp.up_proj.bias\", \"model.layers.11.self_attn.k_proj.bias\"\
          , \"model.layers.11.self_attn.o_proj.bias\", \"model.layers.11.self_attn.q_proj.bias\"\
          , \"model.layers.11.self_attn.v_proj.bias\", \"model.layers.11.mlp.down_proj.bias\"\
          , \"model.layers.11.mlp.gate_proj.bias\", \"model.layers.11.mlp.up_proj.bias\"\
          , \"model.layers.12.self_attn.k_proj.bias\", \"model.layers.12.self_attn.o_proj.bias\"\
          , \"model.layers.12.self_attn.q_proj.bias\", \"model.layers.12.self_attn.v_proj.bias\"\
          , \"model.layers.12.mlp.down_proj.bias\", \"model.layers.12.mlp.gate_proj.bias\"\
          , \"model.layers.12.mlp.up_proj.bias\", \"model.layers.13.self_attn.k_proj.bias\"\
          , \"model.layers.13.self_attn.o_proj.bias\", \"model.layers.13.self_attn.q_proj.bias\"\
          , \"model.layers.13.self_attn.v_proj.bias\", \"model.layers.13.mlp.down_proj.bias\"\
          , \"model.layers.13.mlp.gate_proj.bias\", \"model.layers.13.mlp.up_proj.bias\"\
          , \"model.layers.14.self_attn.k_proj.bias\", \"model.layers.14.self_attn.o_proj.bias\"\
          , \"model.layers.14.self_attn.q_proj.bias\", \"model.layers.14.self_attn.v_proj.bias\"\
          , \"model.layers.14.mlp.down_proj.bias\", \"model.layers.14.mlp.gate_proj.bias\"\
          , \"model.layers.14.mlp.up_proj.bias\", \"model.layers.15.self_attn.k_proj.bias\"\
          , \"model.layers.15.self_attn.o_proj.bias\", \"model.layers.15.self_attn.q_proj.bias\"\
          , \"model.layers.15.self_attn.v_proj.bias\", \"model.layers.15.mlp.down_proj.bias\"\
          , \"model.layers.15.mlp.gate_proj.bias\", \"model.layers.15.mlp.up_proj.bias\"\
          , \"model.layers.16.self_attn.k_proj.bias\", \"model.layers.16.self_attn.o_proj.bias\"\
          , \"model.layers.16.self_attn.q_proj.bias\", \"model.layers.16.self_attn.v_proj.bias\"\
          , \"model.layers.16.mlp.down_proj.bias\", \"model.layers.16.mlp.gate_proj.bias\"\
          , \"model.layers.16.mlp.up_proj.bias\", \"model.layers.17.self_attn.k_proj.bias\"\
          , \"model.layers.17.self_attn.o_proj.bias\", \"model.layers.17.self_attn.q_proj.bias\"\
          , \"model.layers.17.self_attn.v_proj.bias\", \"model.layers.17.mlp.down_proj.bias\"\
          , \"model.layers.17.mlp.gate_proj.bias\", \"model.layers.17.mlp.up_proj.bias\"\
          , \"model.layers.18.self_attn.k_proj.bias\", \"model.layers.18.self_attn.o_proj.bias\"\
          , \"model.layers.18.self_attn.q_proj.bias\", \"model.layers.18.self_attn.v_proj.bias\"\
          , \"model.layers.18.mlp.down_proj.bias\", \"model.layers.18.mlp.gate_proj.bias\"\
          , \"model.layers.18.mlp.up_proj.bias\", \"model.layers.19.self_attn.k_proj.bias\"\
          , \"model.layers.19.self_attn.o_proj.bias\", \"model.layers.19.self_attn.q_proj.bias\"\
          , \"model.layers.19.self_attn.v_proj.bias\", \"model.layers.19.mlp.down_proj.bias\"\
          , \"model.layers.19.mlp.gate_proj.bias\", \"model.layers.19.mlp.up_proj.bias\"\
          , \"model.layers.20.self_attn.k_proj.bias\", \"model.layers.20.self_attn.o_proj.bias\"\
          , \"model.layers.20.self_attn.q_proj.bias\", \"model.layers.20.self_attn.v_proj.bias\"\
          , \"model.layers.20.mlp.down_proj.bias\", \"model.layers.20.mlp.gate_proj.bias\"\
          , \"model.layers.20.mlp.up_proj.bias\", \"model.layers.21.self_attn.k_proj.bias\"\
          , \"model.layers.21.self_attn.o_proj.bias\", \"model.layers.21.self_attn.q_proj.bias\"\
          , \"model.layers.21.self_attn.v_proj.bias\", \"model.layers.21.mlp.down_proj.bias\"\
          , \"model.layers.21.mlp.gate_proj.bias\", \"model.layers.21.mlp.up_proj.bias\"\
          , \"model.layers.22.self_attn.k_proj.bias\", \"model.layers.22.self_attn.o_proj.bias\"\
          , \"model.layers.22.self_attn.q_proj.bias\", \"model.layers.22.self_attn.v_proj.bias\"\
          , \"model.layers.22.mlp.down_proj.bias\", \"model.layers.22.mlp.gate_proj.bias\"\
          , \"model.layers.22.mlp.up_proj.bias\", \"model.layers.23.self_attn.k_proj.bias\"\
          , \"model.layers.23.self_attn.o_proj.bias\", \"model.layers.23.self_attn.q_proj.bias\"\
          , \"model.layers.23.self_attn.v_proj.bias\", \"model.layers.23.mlp.down_proj.bias\"\
          , \"model.layers.23.mlp.gate_proj.bias\", \"model.layers.23.mlp.up_proj.bias\"\
          , \"model.layers.24.self_attn.k_proj.bias\", \"model.layers.24.self_attn.o_proj.bias\"\
          , \"model.layers.24.self_attn.q_proj.bias\", \"model.layers.24.self_attn.v_proj.bias\"\
          , \"model.layers.24.mlp.down_proj.bias\", \"model.layers.24.mlp.gate_proj.bias\"\
          , \"model.layers.24.mlp.up_proj.bias\", \"model.layers.25.self_attn.k_proj.bias\"\
          , \"model.layers.25.self_attn.o_proj.bias\", \"model.layers.25.self_attn.q_proj.bias\"\
          , \"model.layers.25.self_attn.v_proj.bias\", \"model.layers.25.mlp.down_proj.bias\"\
          , \"model.layers.25.mlp.gate_proj.bias\", \"model.layers.25.mlp.up_proj.bias\"\
          , \"model.layers.26.self_attn.k_proj.bias\", \"model.layers.26.self_attn.o_proj.bias\"\
          , \"model.layers.26.self_attn.q_proj.bias\", \"model.layers.26.self_attn.v_proj.bias\"\
          , \"model.layers.26.mlp.down_proj.bias\", \"model.layers.26.mlp.gate_proj.bias\"\
          , \"model.layers.26.mlp.up_proj.bias\", \"model.layers.27.self_attn.k_proj.bias\"\
          , \"model.layers.27.self_attn.o_proj.bias\", \"model.layers.27.self_attn.q_proj.bias\"\
          , \"model.layers.27.self_attn.v_proj.bias\", \"model.layers.27.mlp.down_proj.bias\"\
          , \"model.layers.27.mlp.gate_proj.bias\", \"model.layers.27.mlp.up_proj.bias\"\
          , \"model.layers.28.self_attn.k_proj.bias\", \"model.layers.28.self_attn.o_proj.bias\"\
          , \"model.layers.28.self_attn.q_proj.bias\", \"model.layers.28.self_attn.v_proj.bias\"\
          , \"model.layers.28.mlp.down_proj.bias\", \"model.layers.28.mlp.gate_proj.bias\"\
          , \"model.layers.28.mlp.up_proj.bias\", \"model.layers.29.self_attn.k_proj.bias\"\
          , \"model.layers.29.self_attn.o_proj.bias\", \"model.layers.29.self_attn.q_proj.bias\"\
          , \"model.layers.29.self_attn.v_proj.bias\", \"model.layers.29.mlp.down_proj.bias\"\
          , \"model.layers.29.mlp.gate_proj.bias\", \"model.layers.29.mlp.up_proj.bias\"\
          , \"model.layers.30.self_attn.k_proj.bias\", \"model.layers.30.self_attn.o_proj.bias\"\
          , \"model.layers.30.self_attn.q_proj.bias\", \"model.layers.30.self_attn.v_proj.bias\"\
          , \"model.layers.30.mlp.down_proj.bias\", \"model.layers.30.mlp.gate_proj.bias\"\
          , \"model.layers.30.mlp.up_proj.bias\", \"model.layers.31.self_attn.k_proj.bias\"\
          , \"model.layers.31.self_attn.o_proj.bias\", \"model.layers.31.self_attn.q_proj.bias\"\
          , \"model.layers.31.self_attn.v_proj.bias\", \"model.layers.31.mlp.down_proj.bias\"\
          , \"model.layers.31.mlp.gate_proj.bias\", \"model.layers.31.mlp.up_proj.bias\"\
          , \"model.layers.32.self_attn.k_proj.bias\", \"model.layers.32.self_attn.o_proj.bias\"\
          , \"model.layers.32.self_attn.q_proj.bias\", \"model.layers.32.self_attn.v_proj.bias\"\
          , \"model.layers.32.mlp.down_proj.bias\", \"model.layers.32.mlp.gate_proj.bias\"\
          , \"model.layers.32.mlp.up_proj.bias\", \"model.layers.33.self_attn.k_proj.bias\"\
          , \"model.layers.33.self_attn.o_proj.bias\", \"model.layers.33.self_attn.q_proj.bias\"\
          , \"model.layers.33.self_attn.v_proj.bias\", \"model.layers.33.mlp.down_proj.bias\"\
          , \"model.layers.33.mlp.gate_proj.bias\", \"model.layers.33.mlp.up_proj.bias\"\
          , \"model.layers.34.self_attn.k_proj.bias\", \"model.layers.34.self_attn.o_proj.bias\"\
          , \"model.layers.34.self_attn.q_proj.bias\", \"model.layers.34.self_attn.v_proj.bias\"\
          , \"model.layers.34.mlp.down_proj.bias\", \"model.layers.34.mlp.gate_proj.bias\"\
          , \"model.layers.34.mlp.up_proj.bias\", \"model.layers.35.self_attn.k_proj.bias\"\
          , \"model.layers.35.self_attn.o_proj.bias\", \"model.layers.35.self_attn.q_proj.bias\"\
          , \"model.layers.35.self_attn.v_proj.bias\", \"model.layers.35.mlp.down_proj.bias\"\
          , \"model.layers.35.mlp.gate_proj.bias\", \"model.layers.35.mlp.up_proj.bias\"\
          , \"model.layers.36.self_attn.k_proj.bias\", \"model.layers.36.self_attn.o_proj.bias\"\
          , \"model.layers.36.self_attn.q_proj.bias\", \"model.layers.36.self_attn.v_proj.bias\"\
          , \"model.layers.36.mlp.down_proj.bias\", \"model.layers.36.mlp.gate_proj.bias\"\
          , \"model.layers.36.mlp.up_proj.bias\", \"model.layers.37.self_attn.k_proj.bias\"\
          , \"model.layers.37.self_attn.o_proj.bias\", \"model.layers.37.self_attn.q_proj.bias\"\
          , \"model.layers.37.self_attn.v_proj.bias\", \"model.layers.37.mlp.down_proj.bias\"\
          , \"model.layers.37.mlp.gate_proj.bias\", \"model.layers.37.mlp.up_proj.bias\"\
          , \"model.layers.38.self_attn.k_proj.bias\", \"model.layers.38.self_attn.o_proj.bias\"\
          , \"model.layers.38.self_attn.q_proj.bias\", \"model.layers.38.self_attn.v_proj.bias\"\
          , \"model.layers.38.mlp.down_proj.bias\", \"model.layers.38.mlp.gate_proj.bias\"\
          , \"model.layers.38.mlp.up_proj.bias\", \"model.layers.39.self_attn.k_proj.bias\"\
          , \"model.layers.39.self_attn.o_proj.bias\", \"model.layers.39.self_attn.q_proj.bias\"\
          , \"model.layers.39.self_attn.v_proj.bias\", \"model.layers.39.mlp.down_proj.bias\"\
          , \"model.layers.39.mlp.gate_proj.bias\", \"model.layers.39.mlp.up_proj.bias\"\
          .\r\n        Unexpected key(s) in state_dict: \"model.layers.0.self_attn.k_proj.g_idx\"\
          , \"model.layers.0.self_attn.o_proj.g_idx\", \"model.layers.0.self_attn.q_proj.g_idx\"\
          , \"model.layers.0.self_attn.v_proj.g_idx\", \"model.layers.0.mlp.down_proj.g_idx\"\
          , \"model.layers.0.mlp.gate_proj.g_idx\", \"model.layers.0.mlp.up_proj.g_idx\"\
          , \"model.layers.1.self_attn.k_proj.g_idx\", \"model.layers.1.self_attn.o_proj.g_idx\"\
          , \"model.layers.1.self_attn.q_proj.g_idx\", \"model.layers.1.self_attn.v_proj.g_idx\"\
          , \"model.layers.1.mlp.down_proj.g_idx\", \"model.layers.1.mlp.gate_proj.g_idx\"\
          , \"model.layers.1.mlp.up_proj.g_idx\", \"model.layers.2.self_attn.k_proj.g_idx\"\
          , \"model.layers.2.self_attn.o_proj.g_idx\", \"model.layers.2.self_attn.q_proj.g_idx\"\
          , \"model.layers.2.self_attn.v_proj.g_idx\", \"model.layers.2.mlp.down_proj.g_idx\"\
          , \"model.layers.2.mlp.gate_proj.g_idx\", \"model.layers.2.mlp.up_proj.g_idx\"\
          , \"model.layers.3.self_attn.k_proj.g_idx\", \"model.layers.3.self_attn.o_proj.g_idx\"\
          , \"model.layers.3.self_attn.q_proj.g_idx\", \"model.layers.3.self_attn.v_proj.g_idx\"\
          , \"model.layers.3.mlp.down_proj.g_idx\", \"model.layers.3.mlp.gate_proj.g_idx\"\
          , \"model.layers.3.mlp.up_proj.g_idx\", \"model.layers.4.self_attn.k_proj.g_idx\"\
          , \"model.layers.4.self_attn.o_proj.g_idx\", \"model.layers.4.self_attn.q_proj.g_idx\"\
          , \"model.layers.4.self_attn.v_proj.g_idx\", \"model.layers.4.mlp.down_proj.g_idx\"\
          , \"model.layers.4.mlp.gate_proj.g_idx\", \"model.layers.4.mlp.up_proj.g_idx\"\
          , \"model.layers.5.self_attn.k_proj.g_idx\", \"model.layers.5.self_attn.o_proj.g_idx\"\
          , \"model.layers.5.self_attn.q_proj.g_idx\", \"model.layers.5.self_attn.v_proj.g_idx\"\
          , \"model.layers.5.mlp.down_proj.g_idx\", \"model.layers.5.mlp.gate_proj.g_idx\"\
          , \"model.layers.5.mlp.up_proj.g_idx\", \"model.layers.6.self_attn.k_proj.g_idx\"\
          , \"model.layers.6.self_attn.o_proj.g_idx\", \"model.layers.6.self_attn.q_proj.g_idx\"\
          , \"model.layers.6.self_attn.v_proj.g_idx\", \"model.layers.6.mlp.down_proj.g_idx\"\
          , \"model.layers.6.mlp.gate_proj.g_idx\", \"model.layers.6.mlp.up_proj.g_idx\"\
          , \"model.layers.7.self_attn.k_proj.g_idx\", \"model.layers.7.self_attn.o_proj.g_idx\"\
          , \"model.layers.7.self_attn.q_proj.g_idx\", \"model.layers.7.self_attn.v_proj.g_idx\"\
          , \"model.layers.7.mlp.down_proj.g_idx\", \"model.layers.7.mlp.gate_proj.g_idx\"\
          , \"model.layers.7.mlp.up_proj.g_idx\", \"model.layers.8.self_attn.k_proj.g_idx\"\
          , \"model.layers.8.self_attn.o_proj.g_idx\", \"model.layers.8.self_attn.q_proj.g_idx\"\
          , \"model.layers.8.self_attn.v_proj.g_idx\", \"model.layers.8.mlp.down_proj.g_idx\"\
          , \"model.layers.8.mlp.gate_proj.g_idx\", \"model.layers.8.mlp.up_proj.g_idx\"\
          , \"model.layers.9.self_attn.k_proj.g_idx\", \"model.layers.9.self_attn.o_proj.g_idx\"\
          , \"model.layers.9.self_attn.q_proj.g_idx\", \"model.layers.9.self_attn.v_proj.g_idx\"\
          , \"model.layers.9.mlp.down_proj.g_idx\", \"model.layers.9.mlp.gate_proj.g_idx\"\
          , \"model.layers.9.mlp.up_proj.g_idx\", \"model.layers.10.self_attn.k_proj.g_idx\"\
          , \"model.layers.10.self_attn.o_proj.g_idx\", \"model.layers.10.self_attn.q_proj.g_idx\"\
          , \"model.layers.10.self_attn.v_proj.g_idx\", \"model.layers.10.mlp.down_proj.g_idx\"\
          , \"model.layers.10.mlp.gate_proj.g_idx\", \"model.layers.10.mlp.up_proj.g_idx\"\
          , \"model.layers.11.self_attn.k_proj.g_idx\", \"model.layers.11.self_attn.o_proj.g_idx\"\
          , \"model.layers.11.self_attn.q_proj.g_idx\", \"model.layers.11.self_attn.v_proj.g_idx\"\
          , \"model.layers.11.mlp.down_proj.g_idx\", \"model.layers.11.mlp.gate_proj.g_idx\"\
          , \"model.layers.11.mlp.up_proj.g_idx\", \"model.layers.12.self_attn.k_proj.g_idx\"\
          , \"model.layers.12.self_attn.o_proj.g_idx\", \"model.layers.12.self_attn.q_proj.g_idx\"\
          , \"model.layers.12.self_attn.v_proj.g_idx\", \"model.layers.12.mlp.down_proj.g_idx\"\
          , \"model.layers.12.mlp.gate_proj.g_idx\", \"model.layers.12.mlp.up_proj.g_idx\"\
          , \"model.layers.13.self_attn.k_proj.g_idx\", \"model.layers.13.self_attn.o_proj.g_idx\"\
          , \"model.layers.13.self_attn.q_proj.g_idx\", \"model.layers.13.self_attn.v_proj.g_idx\"\
          , \"model.layers.13.mlp.down_proj.g_idx\", \"model.layers.13.mlp.gate_proj.g_idx\"\
          , \"model.layers.13.mlp.up_proj.g_idx\", \"model.layers.14.self_attn.k_proj.g_idx\"\
          , \"model.layers.14.self_attn.o_proj.g_idx\", \"model.layers.14.self_attn.q_proj.g_idx\"\
          , \"model.layers.14.self_attn.v_proj.g_idx\", \"model.layers.14.mlp.down_proj.g_idx\"\
          , \"model.layers.14.mlp.gate_proj.g_idx\", \"model.layers.14.mlp.up_proj.g_idx\"\
          , \"model.layers.15.self_attn.k_proj.g_idx\", \"model.layers.15.self_attn.o_proj.g_idx\"\
          , \"model.layers.15.self_attn.q_proj.g_idx\", \"model.layers.15.self_attn.v_proj.g_idx\"\
          , \"model.layers.15.mlp.down_proj.g_idx\", \"model.layers.15.mlp.gate_proj.g_idx\"\
          , \"model.layers.15.mlp.up_proj.g_idx\", \"model.layers.16.self_attn.k_proj.g_idx\"\
          , \"model.layers.16.self_attn.o_proj.g_idx\", \"model.layers.16.self_attn.q_proj.g_idx\"\
          , \"model.layers.16.self_attn.v_proj.g_idx\", \"model.layers.16.mlp.down_proj.g_idx\"\
          , \"model.layers.16.mlp.gate_proj.g_idx\", \"model.layers.16.mlp.up_proj.g_idx\"\
          , \"model.layers.17.self_attn.k_proj.g_idx\", \"model.layers.17.self_attn.o_proj.g_idx\"\
          , \"model.layers.17.self_attn.q_proj.g_idx\", \"model.layers.17.self_attn.v_proj.g_idx\"\
          , \"model.layers.17.mlp.down_proj.g_idx\", \"model.layers.17.mlp.gate_proj.g_idx\"\
          , \"model.layers.17.mlp.up_proj.g_idx\", \"model.layers.18.self_attn.k_proj.g_idx\"\
          , \"model.layers.18.self_attn.o_proj.g_idx\", \"model.layers.18.self_attn.q_proj.g_idx\"\
          , \"model.layers.18.self_attn.v_proj.g_idx\", \"model.layers.18.mlp.down_proj.g_idx\"\
          , \"model.layers.18.mlp.gate_proj.g_idx\", \"model.layers.18.mlp.up_proj.g_idx\"\
          , \"model.layers.19.self_attn.k_proj.g_idx\", \"model.layers.19.self_attn.o_proj.g_idx\"\
          , \"model.layers.19.self_attn.q_proj.g_idx\", \"model.layers.19.self_attn.v_proj.g_idx\"\
          , \"model.layers.19.mlp.down_proj.g_idx\", \"model.layers.19.mlp.gate_proj.g_idx\"\
          , \"model.layers.19.mlp.up_proj.g_idx\", \"model.layers.20.self_attn.k_proj.g_idx\"\
          , \"model.layers.20.self_attn.o_proj.g_idx\", \"model.layers.20.self_attn.q_proj.g_idx\"\
          , \"model.layers.20.self_attn.v_proj.g_idx\", \"model.layers.20.mlp.down_proj.g_idx\"\
          , \"model.layers.20.mlp.gate_proj.g_idx\", \"model.layers.20.mlp.up_proj.g_idx\"\
          , \"model.layers.21.self_attn.k_proj.g_idx\", \"model.layers.21.self_attn.o_proj.g_idx\"\
          , \"model.layers.21.self_attn.q_proj.g_idx\", \"model.layers.21.self_attn.v_proj.g_idx\"\
          , \"model.layers.21.mlp.down_proj.g_idx\", \"model.layers.21.mlp.gate_proj.g_idx\"\
          , \"model.layers.21.mlp.up_proj.g_idx\", \"model.layers.22.self_attn.k_proj.g_idx\"\
          , \"model.layers.22.self_attn.o_proj.g_idx\", \"model.layers.22.self_attn.q_proj.g_idx\"\
          , \"model.layers.22.self_attn.v_proj.g_idx\", \"model.layers.22.mlp.down_proj.g_idx\"\
          , \"model.layers.22.mlp.gate_proj.g_idx\", \"model.layers.22.mlp.up_proj.g_idx\"\
          , \"model.layers.23.self_attn.k_proj.g_idx\", \"model.layers.23.self_attn.o_proj.g_idx\"\
          , \"model.layers.23.self_attn.q_proj.g_idx\", \"model.layers.23.self_attn.v_proj.g_idx\"\
          , \"model.layers.23.mlp.down_proj.g_idx\", \"model.layers.23.mlp.gate_proj.g_idx\"\
          , \"model.layers.23.mlp.up_proj.g_idx\", \"model.layers.24.self_attn.k_proj.g_idx\"\
          , \"model.layers.24.self_attn.o_proj.g_idx\", \"model.layers.24.self_attn.q_proj.g_idx\"\
          , \"model.layers.24.self_attn.v_proj.g_idx\", \"model.layers.24.mlp.down_proj.g_idx\"\
          , \"model.layers.24.mlp.gate_proj.g_idx\", \"model.layers.24.mlp.up_proj.g_idx\"\
          , \"model.layers.25.self_attn.k_proj.g_idx\", \"model.layers.25.self_attn.o_proj.g_idx\"\
          , \"model.layers.25.self_attn.q_proj.g_idx\", \"model.layers.25.self_attn.v_proj.g_idx\"\
          , \"model.layers.25.mlp.down_proj.g_idx\", \"model.layers.25.mlp.gate_proj.g_idx\"\
          , \"model.layers.25.mlp.up_proj.g_idx\", \"model.layers.26.self_attn.k_proj.g_idx\"\
          , \"model.layers.26.self_attn.o_proj.g_idx\", \"model.layers.26.self_attn.q_proj.g_idx\"\
          , \"model.layers.26.self_attn.v_proj.g_idx\", \"model.layers.26.mlp.down_proj.g_idx\"\
          , \"model.layers.26.mlp.gate_proj.g_idx\", \"model.layers.26.mlp.up_proj.g_idx\"\
          , \"model.layers.27.self_attn.k_proj.g_idx\", \"model.layers.27.self_attn.o_proj.g_idx\"\
          , \"model.layers.27.self_attn.q_proj.g_idx\", \"model.layers.27.self_attn.v_proj.g_idx\"\
          , \"model.layers.27.mlp.down_proj.g_idx\", \"model.layers.27.mlp.gate_proj.g_idx\"\
          , \"model.layers.27.mlp.up_proj.g_idx\", \"model.layers.28.self_attn.k_proj.g_idx\"\
          , \"model.layers.28.self_attn.o_proj.g_idx\", \"model.layers.28.self_attn.q_proj.g_idx\"\
          , \"model.layers.28.self_attn.v_proj.g_idx\", \"model.layers.28.mlp.down_proj.g_idx\"\
          , \"model.layers.28.mlp.gate_proj.g_idx\", \"model.layers.28.mlp.up_proj.g_idx\"\
          , \"model.layers.29.self_attn.k_proj.g_idx\", \"model.layers.29.self_attn.o_proj.g_idx\"\
          , \"model.layers.29.self_attn.q_proj.g_idx\", \"model.layers.29.self_attn.v_proj.g_idx\"\
          , \"model.layers.29.mlp.down_proj.g_idx\", \"model.layers.29.mlp.gate_proj.g_idx\"\
          , \"model.layers.29.mlp.up_proj.g_idx\", \"model.layers.30.self_attn.k_proj.g_idx\"\
          , \"model.layers.30.self_attn.o_proj.g_idx\", \"model.layers.30.self_attn.q_proj.g_idx\"\
          , \"model.layers.30.self_attn.v_proj.g_idx\", \"model.layers.30.mlp.down_proj.g_idx\"\
          , \"model.layers.30.mlp.gate_proj.g_idx\", \"model.layers.30.mlp.up_proj.g_idx\"\
          , \"model.layers.31.self_attn.k_proj.g_idx\", \"model.layers.31.self_attn.o_proj.g_idx\"\
          , \"model.layers.31.self_attn.q_proj.g_idx\", \"model.layers.31.self_attn.v_proj.g_idx\"\
          , \"model.layers.31.mlp.down_proj.g_idx\", \"model.layers.31.mlp.gate_proj.g_idx\"\
          , \"model.layers.31.mlp.up_proj.g_idx\", \"model.layers.32.self_attn.k_proj.g_idx\"\
          , \"model.layers.32.self_attn.o_proj.g_idx\", \"model.layers.32.self_attn.q_proj.g_idx\"\
          , \"model.layers.32.self_attn.v_proj.g_idx\", \"model.layers.32.mlp.down_proj.g_idx\"\
          , \"model.layers.32.mlp.gate_proj.g_idx\", \"model.layers.32.mlp.up_proj.g_idx\"\
          , \"model.layers.33.self_attn.k_proj.g_idx\", \"model.layers.33.self_attn.o_proj.g_idx\"\
          , \"model.layers.33.self_attn.q_proj.g_idx\", \"model.layers.33.self_attn.v_proj.g_idx\"\
          , \"model.layers.33.mlp.down_proj.g_idx\", \"model.layers.33.mlp.gate_proj.g_idx\"\
          , \"model.layers.33.mlp.up_proj.g_idx\", \"model.layers.34.self_attn.k_proj.g_idx\"\
          , \"model.layers.34.self_attn.o_proj.g_idx\", \"model.layers.34.self_attn.q_proj.g_idx\"\
          , \"model.layers.34.self_attn.v_proj.g_idx\", \"model.layers.34.mlp.down_proj.g_idx\"\
          , \"model.layers.34.mlp.gate_proj.g_idx\", \"model.layers.34.mlp.up_proj.g_idx\"\
          , \"model.layers.35.self_attn.k_proj.g_idx\", \"model.layers.35.self_attn.o_proj.g_idx\"\
          , \"model.layers.35.self_attn.q_proj.g_idx\", \"model.layers.35.self_attn.v_proj.g_idx\"\
          , \"model.layers.35.mlp.down_proj.g_idx\", \"model.layers.35.mlp.gate_proj.g_idx\"\
          , \"model.layers.35.mlp.up_proj.g_idx\", \"model.layers.36.self_attn.k_proj.g_idx\"\
          , \"model.layers.36.self_attn.o_proj.g_idx\", \"model.layers.36.self_attn.q_proj.g_idx\"\
          , \"model.layers.36.self_attn.v_proj.g_idx\", \"model.layers.36.mlp.down_proj.g_idx\"\
          , \"model.layers.36.mlp.gate_proj.g_idx\", \"model.layers.36.mlp.up_proj.g_idx\"\
          , \"model.layers.37.self_attn.k_proj.g_idx\", \"model.layers.37.self_attn.o_proj.g_idx\"\
          , \"model.layers.37.self_attn.q_proj.g_idx\", \"model.layers.37.self_attn.v_proj.g_idx\"\
          , \"model.layers.37.mlp.down_proj.g_idx\", \"model.layers.37.mlp.gate_proj.g_idx\"\
          , \"model.layers.37.mlp.up_proj.g_idx\", \"model.layers.38.self_attn.k_proj.g_idx\"\
          , \"model.layers.38.self_attn.o_proj.g_idx\", \"model.layers.38.self_attn.q_proj.g_idx\"\
          , \"model.layers.38.self_attn.v_proj.g_idx\", \"model.layers.38.mlp.down_proj.g_idx\"\
          , \"model.layers.38.mlp.gate_proj.g_idx\", \"model.layers.38.mlp.up_proj.g_idx\"\
          , \"model.layers.39.self_attn.k_proj.g_idx\", \"model.layers.39.self_attn.o_proj.g_idx\"\
          , \"model.layers.39.self_attn.q_proj.g_idx\", \"model.layers.39.self_attn.v_proj.g_idx\"\
          , \"model.layers.39.mlp.down_proj.g_idx\", \"model.layers.39.mlp.gate_proj.g_idx\"\
          , \"model.layers.39.mlp.up_proj.g_idx\".\r\nPress any key to continue .\
          \ . ."
        updatedAt: '2023-04-30T05:18:57.494Z'
      numEdits: 0
      reactions: []
    id: 644dfa415c1b4e14d0c58222
    type: comment
  author: boricuapab
  content: "Starting the web UI...\r\nGradio HTTP request redirected to localhost\
    \ :)\r\nLoading TheBloke_stable-vicuna-13B-GPTQ...\r\nFound the following quantized\
    \ model: models\\TheBloke_stable-vicuna-13B-GPTQ\\stable-vicuna-13B-GPTQ-4bit.compat.no-act-order.safetensors\r\
    \nLoading model ...\r\nTraceback (most recent call last):\r\n  File \"C:\\oobaBoo\\\
    oobabooga-windows\\text-generation-webui\\server.py\", line 914, in <module>\r\
    \n    shared.model, shared.tokenizer = load_model(shared.model_name)\r\n  File\
    \ \"C:\\oobaBoo\\oobabooga-windows\\text-generation-webui\\modules\\models.py\"\
    , line 158, in load_model\r\n    model = load_quantized(model_name)\r\n  File\
    \ \"C:\\oobaBoo\\oobabooga-windows\\text-generation-webui\\modules\\GPTQ_loader.py\"\
    , line 173, in load_quantized\r\n    model = load_quant(str(path_to_model), str(pt_path),\
    \ shared.args.wbits, shared.args.groupsize, shared.args.pre_layer)\r\n  File \"\
    C:\\oobaBoo\\oobabooga-windows\\text-generation-webui\\repositories\\GPTQ-for-LLaMa\\\
    llama_inference_offload.py\", line 226, in load_quant\r\n    model.load_state_dict(safe_load(checkpoint))\r\
    \n  File \"C:\\oobaBoo\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    torch\\nn\\modules\\module.py\", line 2041, in load_state_dict\r\n    raise RuntimeError('Error(s)\
    \ in loading state_dict for {}:\\n\\t{}'.format(\r\nRuntimeError: Error(s) in\
    \ loading state_dict for LlamaForCausalLM:\r\n        Missing key(s) in state_dict:\
    \ \"model.layers.0.self_attn.k_proj.bias\", \"model.layers.0.self_attn.o_proj.bias\"\
    , \"model.layers.0.self_attn.q_proj.bias\", \"model.layers.0.self_attn.v_proj.bias\"\
    , \"model.layers.0.mlp.down_proj.bias\", \"model.layers.0.mlp.gate_proj.bias\"\
    , \"model.layers.0.mlp.up_proj.bias\", \"model.layers.1.self_attn.k_proj.bias\"\
    , \"model.layers.1.self_attn.o_proj.bias\", \"model.layers.1.self_attn.q_proj.bias\"\
    , \"model.layers.1.self_attn.v_proj.bias\", \"model.layers.1.mlp.down_proj.bias\"\
    , \"model.layers.1.mlp.gate_proj.bias\", \"model.layers.1.mlp.up_proj.bias\",\
    \ \"model.layers.2.self_attn.k_proj.bias\", \"model.layers.2.self_attn.o_proj.bias\"\
    , \"model.layers.2.self_attn.q_proj.bias\", \"model.layers.2.self_attn.v_proj.bias\"\
    , \"model.layers.2.mlp.down_proj.bias\", \"model.layers.2.mlp.gate_proj.bias\"\
    , \"model.layers.2.mlp.up_proj.bias\", \"model.layers.3.self_attn.k_proj.bias\"\
    , \"model.layers.3.self_attn.o_proj.bias\", \"model.layers.3.self_attn.q_proj.bias\"\
    , \"model.layers.3.self_attn.v_proj.bias\", \"model.layers.3.mlp.down_proj.bias\"\
    , \"model.layers.3.mlp.gate_proj.bias\", \"model.layers.3.mlp.up_proj.bias\",\
    \ \"model.layers.4.self_attn.k_proj.bias\", \"model.layers.4.self_attn.o_proj.bias\"\
    , \"model.layers.4.self_attn.q_proj.bias\", \"model.layers.4.self_attn.v_proj.bias\"\
    , \"model.layers.4.mlp.down_proj.bias\", \"model.layers.4.mlp.gate_proj.bias\"\
    , \"model.layers.4.mlp.up_proj.bias\", \"model.layers.5.self_attn.k_proj.bias\"\
    , \"model.layers.5.self_attn.o_proj.bias\", \"model.layers.5.self_attn.q_proj.bias\"\
    , \"model.layers.5.self_attn.v_proj.bias\", \"model.layers.5.mlp.down_proj.bias\"\
    , \"model.layers.5.mlp.gate_proj.bias\", \"model.layers.5.mlp.up_proj.bias\",\
    \ \"model.layers.6.self_attn.k_proj.bias\", \"model.layers.6.self_attn.o_proj.bias\"\
    , \"model.layers.6.self_attn.q_proj.bias\", \"model.layers.6.self_attn.v_proj.bias\"\
    , \"model.layers.6.mlp.down_proj.bias\", \"model.layers.6.mlp.gate_proj.bias\"\
    , \"model.layers.6.mlp.up_proj.bias\", \"model.layers.7.self_attn.k_proj.bias\"\
    , \"model.layers.7.self_attn.o_proj.bias\", \"model.layers.7.self_attn.q_proj.bias\"\
    , \"model.layers.7.self_attn.v_proj.bias\", \"model.layers.7.mlp.down_proj.bias\"\
    , \"model.layers.7.mlp.gate_proj.bias\", \"model.layers.7.mlp.up_proj.bias\",\
    \ \"model.layers.8.self_attn.k_proj.bias\", \"model.layers.8.self_attn.o_proj.bias\"\
    , \"model.layers.8.self_attn.q_proj.bias\", \"model.layers.8.self_attn.v_proj.bias\"\
    , \"model.layers.8.mlp.down_proj.bias\", \"model.layers.8.mlp.gate_proj.bias\"\
    , \"model.layers.8.mlp.up_proj.bias\", \"model.layers.9.self_attn.k_proj.bias\"\
    , \"model.layers.9.self_attn.o_proj.bias\", \"model.layers.9.self_attn.q_proj.bias\"\
    , \"model.layers.9.self_attn.v_proj.bias\", \"model.layers.9.mlp.down_proj.bias\"\
    , \"model.layers.9.mlp.gate_proj.bias\", \"model.layers.9.mlp.up_proj.bias\",\
    \ \"model.layers.10.self_attn.k_proj.bias\", \"model.layers.10.self_attn.o_proj.bias\"\
    , \"model.layers.10.self_attn.q_proj.bias\", \"model.layers.10.self_attn.v_proj.bias\"\
    , \"model.layers.10.mlp.down_proj.bias\", \"model.layers.10.mlp.gate_proj.bias\"\
    , \"model.layers.10.mlp.up_proj.bias\", \"model.layers.11.self_attn.k_proj.bias\"\
    , \"model.layers.11.self_attn.o_proj.bias\", \"model.layers.11.self_attn.q_proj.bias\"\
    , \"model.layers.11.self_attn.v_proj.bias\", \"model.layers.11.mlp.down_proj.bias\"\
    , \"model.layers.11.mlp.gate_proj.bias\", \"model.layers.11.mlp.up_proj.bias\"\
    , \"model.layers.12.self_attn.k_proj.bias\", \"model.layers.12.self_attn.o_proj.bias\"\
    , \"model.layers.12.self_attn.q_proj.bias\", \"model.layers.12.self_attn.v_proj.bias\"\
    , \"model.layers.12.mlp.down_proj.bias\", \"model.layers.12.mlp.gate_proj.bias\"\
    , \"model.layers.12.mlp.up_proj.bias\", \"model.layers.13.self_attn.k_proj.bias\"\
    , \"model.layers.13.self_attn.o_proj.bias\", \"model.layers.13.self_attn.q_proj.bias\"\
    , \"model.layers.13.self_attn.v_proj.bias\", \"model.layers.13.mlp.down_proj.bias\"\
    , \"model.layers.13.mlp.gate_proj.bias\", \"model.layers.13.mlp.up_proj.bias\"\
    , \"model.layers.14.self_attn.k_proj.bias\", \"model.layers.14.self_attn.o_proj.bias\"\
    , \"model.layers.14.self_attn.q_proj.bias\", \"model.layers.14.self_attn.v_proj.bias\"\
    , \"model.layers.14.mlp.down_proj.bias\", \"model.layers.14.mlp.gate_proj.bias\"\
    , \"model.layers.14.mlp.up_proj.bias\", \"model.layers.15.self_attn.k_proj.bias\"\
    , \"model.layers.15.self_attn.o_proj.bias\", \"model.layers.15.self_attn.q_proj.bias\"\
    , \"model.layers.15.self_attn.v_proj.bias\", \"model.layers.15.mlp.down_proj.bias\"\
    , \"model.layers.15.mlp.gate_proj.bias\", \"model.layers.15.mlp.up_proj.bias\"\
    , \"model.layers.16.self_attn.k_proj.bias\", \"model.layers.16.self_attn.o_proj.bias\"\
    , \"model.layers.16.self_attn.q_proj.bias\", \"model.layers.16.self_attn.v_proj.bias\"\
    , \"model.layers.16.mlp.down_proj.bias\", \"model.layers.16.mlp.gate_proj.bias\"\
    , \"model.layers.16.mlp.up_proj.bias\", \"model.layers.17.self_attn.k_proj.bias\"\
    , \"model.layers.17.self_attn.o_proj.bias\", \"model.layers.17.self_attn.q_proj.bias\"\
    , \"model.layers.17.self_attn.v_proj.bias\", \"model.layers.17.mlp.down_proj.bias\"\
    , \"model.layers.17.mlp.gate_proj.bias\", \"model.layers.17.mlp.up_proj.bias\"\
    , \"model.layers.18.self_attn.k_proj.bias\", \"model.layers.18.self_attn.o_proj.bias\"\
    , \"model.layers.18.self_attn.q_proj.bias\", \"model.layers.18.self_attn.v_proj.bias\"\
    , \"model.layers.18.mlp.down_proj.bias\", \"model.layers.18.mlp.gate_proj.bias\"\
    , \"model.layers.18.mlp.up_proj.bias\", \"model.layers.19.self_attn.k_proj.bias\"\
    , \"model.layers.19.self_attn.o_proj.bias\", \"model.layers.19.self_attn.q_proj.bias\"\
    , \"model.layers.19.self_attn.v_proj.bias\", \"model.layers.19.mlp.down_proj.bias\"\
    , \"model.layers.19.mlp.gate_proj.bias\", \"model.layers.19.mlp.up_proj.bias\"\
    , \"model.layers.20.self_attn.k_proj.bias\", \"model.layers.20.self_attn.o_proj.bias\"\
    , \"model.layers.20.self_attn.q_proj.bias\", \"model.layers.20.self_attn.v_proj.bias\"\
    , \"model.layers.20.mlp.down_proj.bias\", \"model.layers.20.mlp.gate_proj.bias\"\
    , \"model.layers.20.mlp.up_proj.bias\", \"model.layers.21.self_attn.k_proj.bias\"\
    , \"model.layers.21.self_attn.o_proj.bias\", \"model.layers.21.self_attn.q_proj.bias\"\
    , \"model.layers.21.self_attn.v_proj.bias\", \"model.layers.21.mlp.down_proj.bias\"\
    , \"model.layers.21.mlp.gate_proj.bias\", \"model.layers.21.mlp.up_proj.bias\"\
    , \"model.layers.22.self_attn.k_proj.bias\", \"model.layers.22.self_attn.o_proj.bias\"\
    , \"model.layers.22.self_attn.q_proj.bias\", \"model.layers.22.self_attn.v_proj.bias\"\
    , \"model.layers.22.mlp.down_proj.bias\", \"model.layers.22.mlp.gate_proj.bias\"\
    , \"model.layers.22.mlp.up_proj.bias\", \"model.layers.23.self_attn.k_proj.bias\"\
    , \"model.layers.23.self_attn.o_proj.bias\", \"model.layers.23.self_attn.q_proj.bias\"\
    , \"model.layers.23.self_attn.v_proj.bias\", \"model.layers.23.mlp.down_proj.bias\"\
    , \"model.layers.23.mlp.gate_proj.bias\", \"model.layers.23.mlp.up_proj.bias\"\
    , \"model.layers.24.self_attn.k_proj.bias\", \"model.layers.24.self_attn.o_proj.bias\"\
    , \"model.layers.24.self_attn.q_proj.bias\", \"model.layers.24.self_attn.v_proj.bias\"\
    , \"model.layers.24.mlp.down_proj.bias\", \"model.layers.24.mlp.gate_proj.bias\"\
    , \"model.layers.24.mlp.up_proj.bias\", \"model.layers.25.self_attn.k_proj.bias\"\
    , \"model.layers.25.self_attn.o_proj.bias\", \"model.layers.25.self_attn.q_proj.bias\"\
    , \"model.layers.25.self_attn.v_proj.bias\", \"model.layers.25.mlp.down_proj.bias\"\
    , \"model.layers.25.mlp.gate_proj.bias\", \"model.layers.25.mlp.up_proj.bias\"\
    , \"model.layers.26.self_attn.k_proj.bias\", \"model.layers.26.self_attn.o_proj.bias\"\
    , \"model.layers.26.self_attn.q_proj.bias\", \"model.layers.26.self_attn.v_proj.bias\"\
    , \"model.layers.26.mlp.down_proj.bias\", \"model.layers.26.mlp.gate_proj.bias\"\
    , \"model.layers.26.mlp.up_proj.bias\", \"model.layers.27.self_attn.k_proj.bias\"\
    , \"model.layers.27.self_attn.o_proj.bias\", \"model.layers.27.self_attn.q_proj.bias\"\
    , \"model.layers.27.self_attn.v_proj.bias\", \"model.layers.27.mlp.down_proj.bias\"\
    , \"model.layers.27.mlp.gate_proj.bias\", \"model.layers.27.mlp.up_proj.bias\"\
    , \"model.layers.28.self_attn.k_proj.bias\", \"model.layers.28.self_attn.o_proj.bias\"\
    , \"model.layers.28.self_attn.q_proj.bias\", \"model.layers.28.self_attn.v_proj.bias\"\
    , \"model.layers.28.mlp.down_proj.bias\", \"model.layers.28.mlp.gate_proj.bias\"\
    , \"model.layers.28.mlp.up_proj.bias\", \"model.layers.29.self_attn.k_proj.bias\"\
    , \"model.layers.29.self_attn.o_proj.bias\", \"model.layers.29.self_attn.q_proj.bias\"\
    , \"model.layers.29.self_attn.v_proj.bias\", \"model.layers.29.mlp.down_proj.bias\"\
    , \"model.layers.29.mlp.gate_proj.bias\", \"model.layers.29.mlp.up_proj.bias\"\
    , \"model.layers.30.self_attn.k_proj.bias\", \"model.layers.30.self_attn.o_proj.bias\"\
    , \"model.layers.30.self_attn.q_proj.bias\", \"model.layers.30.self_attn.v_proj.bias\"\
    , \"model.layers.30.mlp.down_proj.bias\", \"model.layers.30.mlp.gate_proj.bias\"\
    , \"model.layers.30.mlp.up_proj.bias\", \"model.layers.31.self_attn.k_proj.bias\"\
    , \"model.layers.31.self_attn.o_proj.bias\", \"model.layers.31.self_attn.q_proj.bias\"\
    , \"model.layers.31.self_attn.v_proj.bias\", \"model.layers.31.mlp.down_proj.bias\"\
    , \"model.layers.31.mlp.gate_proj.bias\", \"model.layers.31.mlp.up_proj.bias\"\
    , \"model.layers.32.self_attn.k_proj.bias\", \"model.layers.32.self_attn.o_proj.bias\"\
    , \"model.layers.32.self_attn.q_proj.bias\", \"model.layers.32.self_attn.v_proj.bias\"\
    , \"model.layers.32.mlp.down_proj.bias\", \"model.layers.32.mlp.gate_proj.bias\"\
    , \"model.layers.32.mlp.up_proj.bias\", \"model.layers.33.self_attn.k_proj.bias\"\
    , \"model.layers.33.self_attn.o_proj.bias\", \"model.layers.33.self_attn.q_proj.bias\"\
    , \"model.layers.33.self_attn.v_proj.bias\", \"model.layers.33.mlp.down_proj.bias\"\
    , \"model.layers.33.mlp.gate_proj.bias\", \"model.layers.33.mlp.up_proj.bias\"\
    , \"model.layers.34.self_attn.k_proj.bias\", \"model.layers.34.self_attn.o_proj.bias\"\
    , \"model.layers.34.self_attn.q_proj.bias\", \"model.layers.34.self_attn.v_proj.bias\"\
    , \"model.layers.34.mlp.down_proj.bias\", \"model.layers.34.mlp.gate_proj.bias\"\
    , \"model.layers.34.mlp.up_proj.bias\", \"model.layers.35.self_attn.k_proj.bias\"\
    , \"model.layers.35.self_attn.o_proj.bias\", \"model.layers.35.self_attn.q_proj.bias\"\
    , \"model.layers.35.self_attn.v_proj.bias\", \"model.layers.35.mlp.down_proj.bias\"\
    , \"model.layers.35.mlp.gate_proj.bias\", \"model.layers.35.mlp.up_proj.bias\"\
    , \"model.layers.36.self_attn.k_proj.bias\", \"model.layers.36.self_attn.o_proj.bias\"\
    , \"model.layers.36.self_attn.q_proj.bias\", \"model.layers.36.self_attn.v_proj.bias\"\
    , \"model.layers.36.mlp.down_proj.bias\", \"model.layers.36.mlp.gate_proj.bias\"\
    , \"model.layers.36.mlp.up_proj.bias\", \"model.layers.37.self_attn.k_proj.bias\"\
    , \"model.layers.37.self_attn.o_proj.bias\", \"model.layers.37.self_attn.q_proj.bias\"\
    , \"model.layers.37.self_attn.v_proj.bias\", \"model.layers.37.mlp.down_proj.bias\"\
    , \"model.layers.37.mlp.gate_proj.bias\", \"model.layers.37.mlp.up_proj.bias\"\
    , \"model.layers.38.self_attn.k_proj.bias\", \"model.layers.38.self_attn.o_proj.bias\"\
    , \"model.layers.38.self_attn.q_proj.bias\", \"model.layers.38.self_attn.v_proj.bias\"\
    , \"model.layers.38.mlp.down_proj.bias\", \"model.layers.38.mlp.gate_proj.bias\"\
    , \"model.layers.38.mlp.up_proj.bias\", \"model.layers.39.self_attn.k_proj.bias\"\
    , \"model.layers.39.self_attn.o_proj.bias\", \"model.layers.39.self_attn.q_proj.bias\"\
    , \"model.layers.39.self_attn.v_proj.bias\", \"model.layers.39.mlp.down_proj.bias\"\
    , \"model.layers.39.mlp.gate_proj.bias\", \"model.layers.39.mlp.up_proj.bias\"\
    .\r\n        Unexpected key(s) in state_dict: \"model.layers.0.self_attn.k_proj.g_idx\"\
    , \"model.layers.0.self_attn.o_proj.g_idx\", \"model.layers.0.self_attn.q_proj.g_idx\"\
    , \"model.layers.0.self_attn.v_proj.g_idx\", \"model.layers.0.mlp.down_proj.g_idx\"\
    , \"model.layers.0.mlp.gate_proj.g_idx\", \"model.layers.0.mlp.up_proj.g_idx\"\
    , \"model.layers.1.self_attn.k_proj.g_idx\", \"model.layers.1.self_attn.o_proj.g_idx\"\
    , \"model.layers.1.self_attn.q_proj.g_idx\", \"model.layers.1.self_attn.v_proj.g_idx\"\
    , \"model.layers.1.mlp.down_proj.g_idx\", \"model.layers.1.mlp.gate_proj.g_idx\"\
    , \"model.layers.1.mlp.up_proj.g_idx\", \"model.layers.2.self_attn.k_proj.g_idx\"\
    , \"model.layers.2.self_attn.o_proj.g_idx\", \"model.layers.2.self_attn.q_proj.g_idx\"\
    , \"model.layers.2.self_attn.v_proj.g_idx\", \"model.layers.2.mlp.down_proj.g_idx\"\
    , \"model.layers.2.mlp.gate_proj.g_idx\", \"model.layers.2.mlp.up_proj.g_idx\"\
    , \"model.layers.3.self_attn.k_proj.g_idx\", \"model.layers.3.self_attn.o_proj.g_idx\"\
    , \"model.layers.3.self_attn.q_proj.g_idx\", \"model.layers.3.self_attn.v_proj.g_idx\"\
    , \"model.layers.3.mlp.down_proj.g_idx\", \"model.layers.3.mlp.gate_proj.g_idx\"\
    , \"model.layers.3.mlp.up_proj.g_idx\", \"model.layers.4.self_attn.k_proj.g_idx\"\
    , \"model.layers.4.self_attn.o_proj.g_idx\", \"model.layers.4.self_attn.q_proj.g_idx\"\
    , \"model.layers.4.self_attn.v_proj.g_idx\", \"model.layers.4.mlp.down_proj.g_idx\"\
    , \"model.layers.4.mlp.gate_proj.g_idx\", \"model.layers.4.mlp.up_proj.g_idx\"\
    , \"model.layers.5.self_attn.k_proj.g_idx\", \"model.layers.5.self_attn.o_proj.g_idx\"\
    , \"model.layers.5.self_attn.q_proj.g_idx\", \"model.layers.5.self_attn.v_proj.g_idx\"\
    , \"model.layers.5.mlp.down_proj.g_idx\", \"model.layers.5.mlp.gate_proj.g_idx\"\
    , \"model.layers.5.mlp.up_proj.g_idx\", \"model.layers.6.self_attn.k_proj.g_idx\"\
    , \"model.layers.6.self_attn.o_proj.g_idx\", \"model.layers.6.self_attn.q_proj.g_idx\"\
    , \"model.layers.6.self_attn.v_proj.g_idx\", \"model.layers.6.mlp.down_proj.g_idx\"\
    , \"model.layers.6.mlp.gate_proj.g_idx\", \"model.layers.6.mlp.up_proj.g_idx\"\
    , \"model.layers.7.self_attn.k_proj.g_idx\", \"model.layers.7.self_attn.o_proj.g_idx\"\
    , \"model.layers.7.self_attn.q_proj.g_idx\", \"model.layers.7.self_attn.v_proj.g_idx\"\
    , \"model.layers.7.mlp.down_proj.g_idx\", \"model.layers.7.mlp.gate_proj.g_idx\"\
    , \"model.layers.7.mlp.up_proj.g_idx\", \"model.layers.8.self_attn.k_proj.g_idx\"\
    , \"model.layers.8.self_attn.o_proj.g_idx\", \"model.layers.8.self_attn.q_proj.g_idx\"\
    , \"model.layers.8.self_attn.v_proj.g_idx\", \"model.layers.8.mlp.down_proj.g_idx\"\
    , \"model.layers.8.mlp.gate_proj.g_idx\", \"model.layers.8.mlp.up_proj.g_idx\"\
    , \"model.layers.9.self_attn.k_proj.g_idx\", \"model.layers.9.self_attn.o_proj.g_idx\"\
    , \"model.layers.9.self_attn.q_proj.g_idx\", \"model.layers.9.self_attn.v_proj.g_idx\"\
    , \"model.layers.9.mlp.down_proj.g_idx\", \"model.layers.9.mlp.gate_proj.g_idx\"\
    , \"model.layers.9.mlp.up_proj.g_idx\", \"model.layers.10.self_attn.k_proj.g_idx\"\
    , \"model.layers.10.self_attn.o_proj.g_idx\", \"model.layers.10.self_attn.q_proj.g_idx\"\
    , \"model.layers.10.self_attn.v_proj.g_idx\", \"model.layers.10.mlp.down_proj.g_idx\"\
    , \"model.layers.10.mlp.gate_proj.g_idx\", \"model.layers.10.mlp.up_proj.g_idx\"\
    , \"model.layers.11.self_attn.k_proj.g_idx\", \"model.layers.11.self_attn.o_proj.g_idx\"\
    , \"model.layers.11.self_attn.q_proj.g_idx\", \"model.layers.11.self_attn.v_proj.g_idx\"\
    , \"model.layers.11.mlp.down_proj.g_idx\", \"model.layers.11.mlp.gate_proj.g_idx\"\
    , \"model.layers.11.mlp.up_proj.g_idx\", \"model.layers.12.self_attn.k_proj.g_idx\"\
    , \"model.layers.12.self_attn.o_proj.g_idx\", \"model.layers.12.self_attn.q_proj.g_idx\"\
    , \"model.layers.12.self_attn.v_proj.g_idx\", \"model.layers.12.mlp.down_proj.g_idx\"\
    , \"model.layers.12.mlp.gate_proj.g_idx\", \"model.layers.12.mlp.up_proj.g_idx\"\
    , \"model.layers.13.self_attn.k_proj.g_idx\", \"model.layers.13.self_attn.o_proj.g_idx\"\
    , \"model.layers.13.self_attn.q_proj.g_idx\", \"model.layers.13.self_attn.v_proj.g_idx\"\
    , \"model.layers.13.mlp.down_proj.g_idx\", \"model.layers.13.mlp.gate_proj.g_idx\"\
    , \"model.layers.13.mlp.up_proj.g_idx\", \"model.layers.14.self_attn.k_proj.g_idx\"\
    , \"model.layers.14.self_attn.o_proj.g_idx\", \"model.layers.14.self_attn.q_proj.g_idx\"\
    , \"model.layers.14.self_attn.v_proj.g_idx\", \"model.layers.14.mlp.down_proj.g_idx\"\
    , \"model.layers.14.mlp.gate_proj.g_idx\", \"model.layers.14.mlp.up_proj.g_idx\"\
    , \"model.layers.15.self_attn.k_proj.g_idx\", \"model.layers.15.self_attn.o_proj.g_idx\"\
    , \"model.layers.15.self_attn.q_proj.g_idx\", \"model.layers.15.self_attn.v_proj.g_idx\"\
    , \"model.layers.15.mlp.down_proj.g_idx\", \"model.layers.15.mlp.gate_proj.g_idx\"\
    , \"model.layers.15.mlp.up_proj.g_idx\", \"model.layers.16.self_attn.k_proj.g_idx\"\
    , \"model.layers.16.self_attn.o_proj.g_idx\", \"model.layers.16.self_attn.q_proj.g_idx\"\
    , \"model.layers.16.self_attn.v_proj.g_idx\", \"model.layers.16.mlp.down_proj.g_idx\"\
    , \"model.layers.16.mlp.gate_proj.g_idx\", \"model.layers.16.mlp.up_proj.g_idx\"\
    , \"model.layers.17.self_attn.k_proj.g_idx\", \"model.layers.17.self_attn.o_proj.g_idx\"\
    , \"model.layers.17.self_attn.q_proj.g_idx\", \"model.layers.17.self_attn.v_proj.g_idx\"\
    , \"model.layers.17.mlp.down_proj.g_idx\", \"model.layers.17.mlp.gate_proj.g_idx\"\
    , \"model.layers.17.mlp.up_proj.g_idx\", \"model.layers.18.self_attn.k_proj.g_idx\"\
    , \"model.layers.18.self_attn.o_proj.g_idx\", \"model.layers.18.self_attn.q_proj.g_idx\"\
    , \"model.layers.18.self_attn.v_proj.g_idx\", \"model.layers.18.mlp.down_proj.g_idx\"\
    , \"model.layers.18.mlp.gate_proj.g_idx\", \"model.layers.18.mlp.up_proj.g_idx\"\
    , \"model.layers.19.self_attn.k_proj.g_idx\", \"model.layers.19.self_attn.o_proj.g_idx\"\
    , \"model.layers.19.self_attn.q_proj.g_idx\", \"model.layers.19.self_attn.v_proj.g_idx\"\
    , \"model.layers.19.mlp.down_proj.g_idx\", \"model.layers.19.mlp.gate_proj.g_idx\"\
    , \"model.layers.19.mlp.up_proj.g_idx\", \"model.layers.20.self_attn.k_proj.g_idx\"\
    , \"model.layers.20.self_attn.o_proj.g_idx\", \"model.layers.20.self_attn.q_proj.g_idx\"\
    , \"model.layers.20.self_attn.v_proj.g_idx\", \"model.layers.20.mlp.down_proj.g_idx\"\
    , \"model.layers.20.mlp.gate_proj.g_idx\", \"model.layers.20.mlp.up_proj.g_idx\"\
    , \"model.layers.21.self_attn.k_proj.g_idx\", \"model.layers.21.self_attn.o_proj.g_idx\"\
    , \"model.layers.21.self_attn.q_proj.g_idx\", \"model.layers.21.self_attn.v_proj.g_idx\"\
    , \"model.layers.21.mlp.down_proj.g_idx\", \"model.layers.21.mlp.gate_proj.g_idx\"\
    , \"model.layers.21.mlp.up_proj.g_idx\", \"model.layers.22.self_attn.k_proj.g_idx\"\
    , \"model.layers.22.self_attn.o_proj.g_idx\", \"model.layers.22.self_attn.q_proj.g_idx\"\
    , \"model.layers.22.self_attn.v_proj.g_idx\", \"model.layers.22.mlp.down_proj.g_idx\"\
    , \"model.layers.22.mlp.gate_proj.g_idx\", \"model.layers.22.mlp.up_proj.g_idx\"\
    , \"model.layers.23.self_attn.k_proj.g_idx\", \"model.layers.23.self_attn.o_proj.g_idx\"\
    , \"model.layers.23.self_attn.q_proj.g_idx\", \"model.layers.23.self_attn.v_proj.g_idx\"\
    , \"model.layers.23.mlp.down_proj.g_idx\", \"model.layers.23.mlp.gate_proj.g_idx\"\
    , \"model.layers.23.mlp.up_proj.g_idx\", \"model.layers.24.self_attn.k_proj.g_idx\"\
    , \"model.layers.24.self_attn.o_proj.g_idx\", \"model.layers.24.self_attn.q_proj.g_idx\"\
    , \"model.layers.24.self_attn.v_proj.g_idx\", \"model.layers.24.mlp.down_proj.g_idx\"\
    , \"model.layers.24.mlp.gate_proj.g_idx\", \"model.layers.24.mlp.up_proj.g_idx\"\
    , \"model.layers.25.self_attn.k_proj.g_idx\", \"model.layers.25.self_attn.o_proj.g_idx\"\
    , \"model.layers.25.self_attn.q_proj.g_idx\", \"model.layers.25.self_attn.v_proj.g_idx\"\
    , \"model.layers.25.mlp.down_proj.g_idx\", \"model.layers.25.mlp.gate_proj.g_idx\"\
    , \"model.layers.25.mlp.up_proj.g_idx\", \"model.layers.26.self_attn.k_proj.g_idx\"\
    , \"model.layers.26.self_attn.o_proj.g_idx\", \"model.layers.26.self_attn.q_proj.g_idx\"\
    , \"model.layers.26.self_attn.v_proj.g_idx\", \"model.layers.26.mlp.down_proj.g_idx\"\
    , \"model.layers.26.mlp.gate_proj.g_idx\", \"model.layers.26.mlp.up_proj.g_idx\"\
    , \"model.layers.27.self_attn.k_proj.g_idx\", \"model.layers.27.self_attn.o_proj.g_idx\"\
    , \"model.layers.27.self_attn.q_proj.g_idx\", \"model.layers.27.self_attn.v_proj.g_idx\"\
    , \"model.layers.27.mlp.down_proj.g_idx\", \"model.layers.27.mlp.gate_proj.g_idx\"\
    , \"model.layers.27.mlp.up_proj.g_idx\", \"model.layers.28.self_attn.k_proj.g_idx\"\
    , \"model.layers.28.self_attn.o_proj.g_idx\", \"model.layers.28.self_attn.q_proj.g_idx\"\
    , \"model.layers.28.self_attn.v_proj.g_idx\", \"model.layers.28.mlp.down_proj.g_idx\"\
    , \"model.layers.28.mlp.gate_proj.g_idx\", \"model.layers.28.mlp.up_proj.g_idx\"\
    , \"model.layers.29.self_attn.k_proj.g_idx\", \"model.layers.29.self_attn.o_proj.g_idx\"\
    , \"model.layers.29.self_attn.q_proj.g_idx\", \"model.layers.29.self_attn.v_proj.g_idx\"\
    , \"model.layers.29.mlp.down_proj.g_idx\", \"model.layers.29.mlp.gate_proj.g_idx\"\
    , \"model.layers.29.mlp.up_proj.g_idx\", \"model.layers.30.self_attn.k_proj.g_idx\"\
    , \"model.layers.30.self_attn.o_proj.g_idx\", \"model.layers.30.self_attn.q_proj.g_idx\"\
    , \"model.layers.30.self_attn.v_proj.g_idx\", \"model.layers.30.mlp.down_proj.g_idx\"\
    , \"model.layers.30.mlp.gate_proj.g_idx\", \"model.layers.30.mlp.up_proj.g_idx\"\
    , \"model.layers.31.self_attn.k_proj.g_idx\", \"model.layers.31.self_attn.o_proj.g_idx\"\
    , \"model.layers.31.self_attn.q_proj.g_idx\", \"model.layers.31.self_attn.v_proj.g_idx\"\
    , \"model.layers.31.mlp.down_proj.g_idx\", \"model.layers.31.mlp.gate_proj.g_idx\"\
    , \"model.layers.31.mlp.up_proj.g_idx\", \"model.layers.32.self_attn.k_proj.g_idx\"\
    , \"model.layers.32.self_attn.o_proj.g_idx\", \"model.layers.32.self_attn.q_proj.g_idx\"\
    , \"model.layers.32.self_attn.v_proj.g_idx\", \"model.layers.32.mlp.down_proj.g_idx\"\
    , \"model.layers.32.mlp.gate_proj.g_idx\", \"model.layers.32.mlp.up_proj.g_idx\"\
    , \"model.layers.33.self_attn.k_proj.g_idx\", \"model.layers.33.self_attn.o_proj.g_idx\"\
    , \"model.layers.33.self_attn.q_proj.g_idx\", \"model.layers.33.self_attn.v_proj.g_idx\"\
    , \"model.layers.33.mlp.down_proj.g_idx\", \"model.layers.33.mlp.gate_proj.g_idx\"\
    , \"model.layers.33.mlp.up_proj.g_idx\", \"model.layers.34.self_attn.k_proj.g_idx\"\
    , \"model.layers.34.self_attn.o_proj.g_idx\", \"model.layers.34.self_attn.q_proj.g_idx\"\
    , \"model.layers.34.self_attn.v_proj.g_idx\", \"model.layers.34.mlp.down_proj.g_idx\"\
    , \"model.layers.34.mlp.gate_proj.g_idx\", \"model.layers.34.mlp.up_proj.g_idx\"\
    , \"model.layers.35.self_attn.k_proj.g_idx\", \"model.layers.35.self_attn.o_proj.g_idx\"\
    , \"model.layers.35.self_attn.q_proj.g_idx\", \"model.layers.35.self_attn.v_proj.g_idx\"\
    , \"model.layers.35.mlp.down_proj.g_idx\", \"model.layers.35.mlp.gate_proj.g_idx\"\
    , \"model.layers.35.mlp.up_proj.g_idx\", \"model.layers.36.self_attn.k_proj.g_idx\"\
    , \"model.layers.36.self_attn.o_proj.g_idx\", \"model.layers.36.self_attn.q_proj.g_idx\"\
    , \"model.layers.36.self_attn.v_proj.g_idx\", \"model.layers.36.mlp.down_proj.g_idx\"\
    , \"model.layers.36.mlp.gate_proj.g_idx\", \"model.layers.36.mlp.up_proj.g_idx\"\
    , \"model.layers.37.self_attn.k_proj.g_idx\", \"model.layers.37.self_attn.o_proj.g_idx\"\
    , \"model.layers.37.self_attn.q_proj.g_idx\", \"model.layers.37.self_attn.v_proj.g_idx\"\
    , \"model.layers.37.mlp.down_proj.g_idx\", \"model.layers.37.mlp.gate_proj.g_idx\"\
    , \"model.layers.37.mlp.up_proj.g_idx\", \"model.layers.38.self_attn.k_proj.g_idx\"\
    , \"model.layers.38.self_attn.o_proj.g_idx\", \"model.layers.38.self_attn.q_proj.g_idx\"\
    , \"model.layers.38.self_attn.v_proj.g_idx\", \"model.layers.38.mlp.down_proj.g_idx\"\
    , \"model.layers.38.mlp.gate_proj.g_idx\", \"model.layers.38.mlp.up_proj.g_idx\"\
    , \"model.layers.39.self_attn.k_proj.g_idx\", \"model.layers.39.self_attn.o_proj.g_idx\"\
    , \"model.layers.39.self_attn.q_proj.g_idx\", \"model.layers.39.self_attn.v_proj.g_idx\"\
    , \"model.layers.39.mlp.down_proj.g_idx\", \"model.layers.39.mlp.gate_proj.g_idx\"\
    , \"model.layers.39.mlp.up_proj.g_idx\".\r\nPress any key to continue . . ."
  created_at: 2023-04-30 04:18:57+00:00
  edited: false
  hidden: false
  id: 644dfa415c1b4e14d0c58222
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d70ae605c07e368f8a50543ca42e0eba.svg
      fullname: Pablito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boricuapab
      type: user
    createdAt: '2023-04-30T05:19:34.000Z'
    data:
      edited: false
      editors:
      - boricuapab
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d70ae605c07e368f8a50543ca42e0eba.svg
          fullname: Pablito
          isHf: false
          isPro: false
          name: boricuapab
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6344929432ccc5ca993b0d2a/I062OJJOwhLUzwhka_Alg.png"><img
          alt="stablePreLayers30.PNG" src="https://cdn-uploads.huggingface.co/production/uploads/6344929432ccc5ca993b0d2a/I062OJJOwhLUzwhka_Alg.png"></a></p>

          '
        raw: '![stablePreLayers30.PNG](https://cdn-uploads.huggingface.co/production/uploads/6344929432ccc5ca993b0d2a/I062OJJOwhLUzwhka_Alg.png)'
        updatedAt: '2023-04-30T05:19:34.199Z'
      numEdits: 0
      reactions: []
    id: 644dfa66fa94e93b0ed61e69
    type: comment
  author: boricuapab
  content: '![stablePreLayers30.PNG](https://cdn-uploads.huggingface.co/production/uploads/6344929432ccc5ca993b0d2a/I062OJJOwhLUzwhka_Alg.png)'
  created_at: 2023-04-30 04:19:34+00:00
  edited: false
  hidden: false
  id: 644dfa66fa94e93b0ed61e69
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-30T07:38:25.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yeah I''ve had this issue reported before. It may be a bug in the
          GPTQ code or in text-gen-ui.</p>

          <p>Are there GPTQ models I''ve made that do work with pre_layer?</p>

          '
        raw: 'Yeah I''ve had this issue reported before. It may be a bug in the GPTQ
          code or in text-gen-ui.


          Are there GPTQ models I''ve made that do work with pre_layer?'
        updatedAt: '2023-04-30T07:38:25.066Z'
      numEdits: 0
      reactions: []
    id: 644e1af1ddf20748b04f7724
    type: comment
  author: TheBloke
  content: 'Yeah I''ve had this issue reported before. It may be a bug in the GPTQ
    code or in text-gen-ui.


    Are there GPTQ models I''ve made that do work with pre_layer?'
  created_at: 2023-04-30 06:38:25+00:00
  edited: false
  hidden: false
  id: 644e1af1ddf20748b04f7724
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d70ae605c07e368f8a50543ca42e0eba.svg
      fullname: Pablito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boricuapab
      type: user
    createdAt: '2023-04-30T08:32:04.000Z'
    data:
      edited: true
      editors:
      - boricuapab
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d70ae605c07e368f8a50543ca42e0eba.svg
          fullname: Pablito
          isHf: false
          isPro: false
          name: boricuapab
          type: user
        html: '<p>Tried using --pre_layer with your wizard lm models but it wouldn''t
          load in oobabooga either.  I have been able to use your stable lm ggml through
          both llamacpp and oobabooga.  Thanks for these models.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6344929432ccc5ca993b0d2a/-RbpABkj7-mWA32gzakGn.png"><img
          alt="ggmlStableVicunaWorks.PNG" src="https://cdn-uploads.huggingface.co/production/uploads/6344929432ccc5ca993b0d2a/-RbpABkj7-mWA32gzakGn.png"></a></p>

          '
        raw: 'Tried using --pre_layer with your wizard lm models but it wouldn''t
          load in oobabooga either.  I have been able to use your stable lm ggml through
          both llamacpp and oobabooga.  Thanks for these models.


          ![ggmlStableVicunaWorks.PNG](https://cdn-uploads.huggingface.co/production/uploads/6344929432ccc5ca993b0d2a/-RbpABkj7-mWA32gzakGn.png)'
        updatedAt: '2023-04-30T08:41:56.856Z'
      numEdits: 3
      reactions: []
    id: 644e2784cf72e60a5b73194c
    type: comment
  author: boricuapab
  content: 'Tried using --pre_layer with your wizard lm models but it wouldn''t load
    in oobabooga either.  I have been able to use your stable lm ggml through both
    llamacpp and oobabooga.  Thanks for these models.


    ![ggmlStableVicunaWorks.PNG](https://cdn-uploads.huggingface.co/production/uploads/6344929432ccc5ca993b0d2a/-RbpABkj7-mWA32gzakGn.png)'
  created_at: 2023-04-30 07:32:04+00:00
  edited: true
  hidden: false
  id: 644e2784cf72e60a5b73194c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d70ae605c07e368f8a50543ca42e0eba.svg
      fullname: Pablito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boricuapab
      type: user
    createdAt: '2023-05-15T20:20:05.000Z'
    data:
      edited: false
      editors:
      - boricuapab
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d70ae605c07e368f8a50543ca42e0eba.svg
          fullname: Pablito
          isHf: false
          isPro: false
          name: boricuapab
          type: user
        html: '<p>This new model you released works with the pre layer flag</p>

          <p><a href="https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ/tree/main">https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ/tree/main</a></p>

          '
        raw: 'This new model you released works with the pre layer flag


          https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ/tree/main'
        updatedAt: '2023-05-15T20:20:05.150Z'
      numEdits: 0
      reactions: []
    id: 646293f548e13890ea54ed5d
    type: comment
  author: boricuapab
  content: 'This new model you released works with the pre layer flag


    https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ/tree/main'
  created_at: 2023-05-15 19:20:05+00:00
  edited: false
  hidden: false
  id: 646293f548e13890ea54ed5d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-15T21:51:03.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yeah I went back to using the old fork of GPTQ-for-LLaMA to avoid
          these errors until such time as text-gen-ui supports AutoGPTQ, which hopefully
          will be soonish.</p>

          '
        raw: Yeah I went back to using the old fork of GPTQ-for-LLaMA to avoid these
          errors until such time as text-gen-ui supports AutoGPTQ, which hopefully
          will be soonish.
        updatedAt: '2023-05-15T21:51:03.840Z'
      numEdits: 0
      reactions: []
    id: 6462a947cce92c7d882f8026
    type: comment
  author: TheBloke
  content: Yeah I went back to using the old fork of GPTQ-for-LLaMA to avoid these
    errors until such time as text-gen-ui supports AutoGPTQ, which hopefully will
    be soonish.
  created_at: 2023-05-15 20:51:03+00:00
  edited: false
  hidden: false
  id: 6462a947cce92c7d882f8026
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: TheBloke/stable-vicuna-13B-GPTQ
repo_type: model
status: open
target_branch: null
title: Unable to load it using --pre_layer flag
