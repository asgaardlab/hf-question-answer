!!python/object:huggingface_hub.community.DiscussionWithDetails
author: yogurt111
conflicting_files: null
created_at: 2023-05-05 09:32:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/159c6638fc96c67e2222179f4c64de83.svg
      fullname: milk
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yogurt111
      type: user
    createdAt: '2023-05-05T10:32:24.000Z'
    data:
      edited: false
      editors:
      - yogurt111
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/159c6638fc96c67e2222179f4c64de83.svg
          fullname: milk
          isHf: false
          isPro: false
          name: yogurt111
          type: user
        html: "<p>Traceback (most recent call last): File \u201C/Users/dev/WebstormProjects/text-generation-webui/server.py\u201D\
          , line 103, in load_model_wrapper shared.model, shared.tokenizer = load_model(shared.model_name)\
          \ File \u201C/Users/dev/WebstormProjects/text-generation-webui/modules/models.py\u201D\
          , line 85, in load_model model = LoaderClass.from_pretrained(Path(f\"{shared.args.model_dir}/{model_name}\"\
          ), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16 if shared.args.bf16\
          \ else torch.float16, trust_remote_code=trust_remote_code) File \u201C/usr/local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\u201D\
          , line 471, in from_pretrained return model_class.from_pretrained( File\
          \ \u201C/usr/local/lib/python3.9/site-packages/transformers/modeling_utils.py\u201D\
          , line 2405, in from_pretrained raise EnvironmentError( OSError: Error no\
          \ file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
          \ found in directory models/stable-vicuna-13B-GPTQ.</p>\n"
        raw: "Traceback (most recent call last): File \u201C/Users/dev/WebstormProjects/text-generation-webui/server.py\u201D\
          , line 103, in load_model_wrapper shared.model, shared.tokenizer = load_model(shared.model_name)\
          \ File \u201C/Users/dev/WebstormProjects/text-generation-webui/modules/models.py\u201D\
          , line 85, in load_model model = LoaderClass.from_pretrained(Path(f\"{shared.args.model_dir}/{model_name}\"\
          ), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16 if shared.args.bf16\
          \ else torch.float16, trust_remote_code=trust_remote_code) File \u201C/usr/local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\u201D\
          , line 471, in from_pretrained return model_class.from_pretrained( File\
          \ \u201C/usr/local/lib/python3.9/site-packages/transformers/modeling_utils.py\u201D\
          , line 2405, in from_pretrained raise EnvironmentError( OSError: Error no\
          \ file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
          \ found in directory models/stable-vicuna-13B-GPTQ."
        updatedAt: '2023-05-05T10:32:24.923Z'
      numEdits: 0
      reactions: []
    id: 6454db381a543cf97b1bdaed
    type: comment
  author: yogurt111
  content: "Traceback (most recent call last): File \u201C/Users/dev/WebstormProjects/text-generation-webui/server.py\u201D\
    , line 103, in load_model_wrapper shared.model, shared.tokenizer = load_model(shared.model_name)\
    \ File \u201C/Users/dev/WebstormProjects/text-generation-webui/modules/models.py\u201D\
    , line 85, in load_model model = LoaderClass.from_pretrained(Path(f\"{shared.args.model_dir}/{model_name}\"\
    ), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16 if shared.args.bf16 else\
    \ torch.float16, trust_remote_code=trust_remote_code) File \u201C/usr/local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\u201D\
    , line 471, in from_pretrained return model_class.from_pretrained( File \u201C\
    /usr/local/lib/python3.9/site-packages/transformers/modeling_utils.py\u201D, line\
    \ 2405, in from_pretrained raise EnvironmentError( OSError: Error no file named\
    \ pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack found\
    \ in directory models/stable-vicuna-13B-GPTQ."
  created_at: 2023-05-05 09:32:24+00:00
  edited: false
  hidden: false
  id: 6454db381a543cf97b1bdaed
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-05T10:33:53.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Please follow the instructions in the README - you need to set the
          GPTQ parameters for the model: bits = 4, groupsize = 128, model_type = llama.  Then
          "save settings for this model" and "reload model"</p>

          '
        raw: 'Please follow the instructions in the README - you need to set the GPTQ
          parameters for the model: bits = 4, groupsize = 128, model_type = llama.  Then
          "save settings for this model" and "reload model"'
        updatedAt: '2023-05-05T10:33:53.191Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - yogurt111
    id: 6454db91d55525a4fee15f7e
    type: comment
  author: TheBloke
  content: 'Please follow the instructions in the README - you need to set the GPTQ
    parameters for the model: bits = 4, groupsize = 128, model_type = llama.  Then
    "save settings for this model" and "reload model"'
  created_at: 2023-05-05 09:33:53+00:00
  edited: false
  hidden: false
  id: 6454db91d55525a4fee15f7e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/159c6638fc96c67e2222179f4c64de83.svg
      fullname: milk
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yogurt111
      type: user
    createdAt: '2023-05-05T10:49:17.000Z'
    data:
      edited: false
      editors:
      - yogurt111
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/159c6638fc96c67e2222179f4c64de83.svg
          fullname: milk
          isHf: false
          isPro: false
          name: yogurt111
          type: user
        html: '<p>can this webui use other models?</p>

          '
        raw: can this webui use other models?
        updatedAt: '2023-05-05T10:49:17.628Z'
      numEdits: 0
      reactions: []
    id: 6454df2da473375be56b6aca
    type: comment
  author: yogurt111
  content: can this webui use other models?
  created_at: 2023-05-05 09:49:17+00:00
  edited: false
  hidden: false
  id: 6454df2da473375be56b6aca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-05T10:51:41.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yes of course - it supports most models out there. It supports unquantised
          fp16 HF models for GPU, the same models in 8bit on GPU,  these GPTQ models
          in 4bit on GPU. It supports Llama models, GPT-J, OPT, GPTNeoX, RWKV, and
          others. </p>

          <p>And it also supports loading ggml Llama GGML models for CPU inference.</p>

          <p>text-gen-ui supports more models than any other UI right now I would
          think.</p>

          '
        raw: "Yes of course - it supports most models out there. It supports unquantised\
          \ fp16 HF models for GPU, the same models in 8bit on GPU,  these GPTQ models\
          \ in 4bit on GPU. It supports Llama models, GPT-J, OPT, GPTNeoX, RWKV, and\
          \ others. \n\nAnd it also supports loading ggml Llama GGML models for CPU\
          \ inference.\n\ntext-gen-ui supports more models than any other UI right\
          \ now I would think."
        updatedAt: '2023-05-05T10:51:41.389Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - yogurt111
    id: 6454dfbdfe2f48cb4b61da9d
    type: comment
  author: TheBloke
  content: "Yes of course - it supports most models out there. It supports unquantised\
    \ fp16 HF models for GPU, the same models in 8bit on GPU,  these GPTQ models in\
    \ 4bit on GPU. It supports Llama models, GPT-J, OPT, GPTNeoX, RWKV, and others.\
    \ \n\nAnd it also supports loading ggml Llama GGML models for CPU inference.\n\
    \ntext-gen-ui supports more models than any other UI right now I would think."
  created_at: 2023-05-05 09:51:41+00:00
  edited: false
  hidden: false
  id: 6454dfbdfe2f48cb4b61da9d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/159c6638fc96c67e2222179f4c64de83.svg
      fullname: milk
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yogurt111
      type: user
    createdAt: '2023-05-05T10:55:30.000Z'
    data:
      edited: false
      editors:
      - yogurt111
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/159c6638fc96c67e2222179f4c64de83.svg
          fullname: milk
          isHf: false
          isPro: false
          name: yogurt111
          type: user
        html: '<p>Thanks</p>

          '
        raw: Thanks
        updatedAt: '2023-05-05T10:55:30.134Z'
      numEdits: 0
      reactions: []
    id: 6454e0a2d55525a4fee1c5b0
    type: comment
  author: yogurt111
  content: Thanks
  created_at: 2023-05-05 09:55:30+00:00
  edited: false
  hidden: false
  id: 6454e0a2d55525a4fee1c5b0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: TheBloke/stable-vicuna-13B-GPTQ
repo_type: model
status: open
target_branch: null
title: some errors occured when I use the webui who can tell me why?
