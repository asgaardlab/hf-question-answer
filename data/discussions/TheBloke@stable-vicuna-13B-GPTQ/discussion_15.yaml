!!python/object:huggingface_hub.community.DiscussionWithDetails
author: m0-ch4
conflicting_files: null
created_at: 2023-05-08 10:00:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/be58899147100d8dda279228d6ba5b0f.svg
      fullname: Sho
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: m0-ch4
      type: user
    createdAt: '2023-05-08T11:00:15.000Z'
    data:
      edited: true
      editors:
      - m0-ch4
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/be58899147100d8dda279228d6ba5b0f.svg
          fullname: Sho
          isHf: false
          isPro: false
          name: m0-ch4
          type: user
        html: "<p>I am able to use other models such as \"vicuna-13b-GPTQ-4bit-128g\"\
          \ and \"gpt4-x-alpaca-13b-native-4bit-128g\", but I am unable to use this\
          \ model.</p>\n<p>After reading through other discussions, I have already\
          \ changed the folder name to \"TheBloke_stable-vicuna-13B-4bit-128g-GPTQ\"\
          \ as instructed, and I have properly set the GPTQ parameters.</p>\n<p>Here\
          \ is the error when loading the model:</p>\n<p>Traceback (most recent call\
          \ last):<br>File \u201CC:\\Users\\USER\\Documents\\Programs\\oobabooga_windows\\\
          text-generation-webui\\server.py\u201D, line 60, in load_model_wrapper<br>shared.model,\
          \ shared.tokenizer = load_model(shared.model_name)<br>File \u201CC:\\Users\\\
          USER\\Documents\\Programs\\oobabooga_windows\\text-generation-webui\\modules\\\
          models.py\u201D, line 242, in load_model<br>tokenizer = LlamaTokenizer.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}/\u201C), clean_up_tokenization_spaces=True)<br>File\
          \ \u201CC:\\Users\\USER\\Documents\\Programs\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u201D\
          , line 1811, in from_pretrained<br>return cls.from_pretrained(<br>File \u201C\
          C:\\Users\\USER\\Documents\\Programs\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u201D\
          , line 1965, in from_pretrained<br>tokenizer = cls(*init_inputs, **init_kwargs)<br>File\
          \ \u201CC:\\Users\\USER\\Documents\\Programs\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\models\\llama\\tokenization_llama.py\u201D\
          , line 96, in init<br>self.sp_model.Load(vocab_file)<br>File \"C:\\Users\\\
          USER\\Documents\\Programs\\oobabooga_windows\\installer_files\\env\\lib\\\
          site-packages\\sentencepiece_init.py\", line 905, in Load<br>return self.LoadFromFile(model_file)<br>File\
          \ \"C:\\Users\\USER\\Documents\\Programs\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\sentencepiece_init.py\u201D, line 310, in LoadFromFile<br>return\
          \ _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)<br>TypeError:\
          \ not a string</p>\n"
        raw: "I am able to use other models such as \"vicuna-13b-GPTQ-4bit-128g\"\
          \ and \"gpt4-x-alpaca-13b-native-4bit-128g\", but I am unable to use this\
          \ model.\n\nAfter reading through other discussions, I have already changed\
          \ the folder name to \"TheBloke_stable-vicuna-13B-4bit-128g-GPTQ\" as instructed,\
          \ and I have properly set the GPTQ parameters.\n\nHere is the error when\
          \ loading the model:\n\nTraceback (most recent call last):\nFile \u201C\
          C:\\Users\\USER\\Documents\\Programs\\oobabooga_windows\\text-generation-webui\\\
          server.py\u201D, line 60, in load_model_wrapper\nshared.model, shared.tokenizer\
          \ = load_model(shared.model_name)\nFile \u201CC:\\Users\\USER\\Documents\\\
          Programs\\oobabooga_windows\\text-generation-webui\\modules\\models.py\u201D\
          , line 242, in load_model\ntokenizer = LlamaTokenizer.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}/\u201C), clean_up_tokenization_spaces=True)\n\
          File \u201CC:\\Users\\USER\\Documents\\Programs\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u201D\
          , line 1811, in from_pretrained\nreturn cls.from_pretrained(\nFile \u201C\
          C:\\Users\\USER\\Documents\\Programs\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u201D\
          , line 1965, in from_pretrained\ntokenizer = cls(*init_inputs, **init_kwargs)\n\
          File \u201CC:\\Users\\USER\\Documents\\Programs\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\models\\llama\\tokenization_llama.py\u201D\
          , line 96, in init\nself.sp_model.Load(vocab_file)\nFile \"C:\\Users\\USER\\\
          Documents\\Programs\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
          sentencepiece_init.py\", line 905, in Load\nreturn self.LoadFromFile(model_file)\n\
          File \"C:\\Users\\USER\\Documents\\Programs\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\sentencepiece_init.py\u201D, line 310, in LoadFromFile\n\
          return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)\nTypeError:\
          \ not a string"
        updatedAt: '2023-05-08T11:09:43.223Z'
      numEdits: 5
      reactions: []
    id: 6458d63f4b7baff9a84a2741
    type: comment
  author: m0-ch4
  content: "I am able to use other models such as \"vicuna-13b-GPTQ-4bit-128g\" and\
    \ \"gpt4-x-alpaca-13b-native-4bit-128g\", but I am unable to use this model.\n\
    \nAfter reading through other discussions, I have already changed the folder name\
    \ to \"TheBloke_stable-vicuna-13B-4bit-128g-GPTQ\" as instructed, and I have properly\
    \ set the GPTQ parameters.\n\nHere is the error when loading the model:\n\nTraceback\
    \ (most recent call last):\nFile \u201CC:\\Users\\USER\\Documents\\Programs\\\
    oobabooga_windows\\text-generation-webui\\server.py\u201D, line 60, in load_model_wrapper\n\
    shared.model, shared.tokenizer = load_model(shared.model_name)\nFile \u201CC:\\\
    Users\\USER\\Documents\\Programs\\oobabooga_windows\\text-generation-webui\\modules\\\
    models.py\u201D, line 242, in load_model\ntokenizer = LlamaTokenizer.from_pretrained(Path(f\"\
    {shared.args.model_dir}/{model_name}/\u201C), clean_up_tokenization_spaces=True)\n\
    File \u201CC:\\Users\\USER\\Documents\\Programs\\oobabooga_windows\\installer_files\\\
    env\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u201D, line\
    \ 1811, in from_pretrained\nreturn cls.from_pretrained(\nFile \u201CC:\\Users\\\
    USER\\Documents\\Programs\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\tokenization_utils_base.py\u201D, line 1965, in from_pretrained\n\
    tokenizer = cls(*init_inputs, **init_kwargs)\nFile \u201CC:\\Users\\USER\\Documents\\\
    Programs\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\transformers\\\
    models\\llama\\tokenization_llama.py\u201D, line 96, in init\nself.sp_model.Load(vocab_file)\n\
    File \"C:\\Users\\USER\\Documents\\Programs\\oobabooga_windows\\installer_files\\\
    env\\lib\\site-packages\\sentencepiece_init.py\", line 905, in Load\nreturn self.LoadFromFile(model_file)\n\
    File \"C:\\Users\\USER\\Documents\\Programs\\oobabooga_windows\\installer_files\\\
    env\\lib\\site-packages\\sentencepiece_init.py\u201D, line 310, in LoadFromFile\n\
    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)\nTypeError:\
    \ not a string"
  created_at: 2023-05-08 10:00:15+00:00
  edited: true
  hidden: false
  id: 6458d63f4b7baff9a84a2741
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-10T10:08:53.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>That''s a weird error.  Please check that all files are downloaded
          correctly. It might be that you have a bad <code>tokenizer.model</code>,
          or that file or another file is missing.</p>

          '
        raw: That's a weird error.  Please check that all files are downloaded correctly.
          It might be that you have a bad `tokenizer.model`, or that file or another
          file is missing.
        updatedAt: '2023-05-10T10:08:53.177Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Xingeqwd
    id: 645b6d358ac8cdceb387896c
    type: comment
  author: TheBloke
  content: That's a weird error.  Please check that all files are downloaded correctly.
    It might be that you have a bad `tokenizer.model`, or that file or another file
    is missing.
  created_at: 2023-05-10 09:08:53+00:00
  edited: false
  hidden: false
  id: 645b6d358ac8cdceb387896c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/be58899147100d8dda279228d6ba5b0f.svg
      fullname: Sho
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: m0-ch4
      type: user
    createdAt: '2023-05-16T15:04:40.000Z'
    data:
      edited: false
      editors:
      - m0-ch4
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/be58899147100d8dda279228d6ba5b0f.svg
          fullname: Sho
          isHf: false
          isPro: false
          name: m0-ch4
          type: user
        html: '<p>You are right, tokenizer.model was missing. Now it worked. Thank
          you!</p>

          '
        raw: You are right, tokenizer.model was missing. Now it worked. Thank you!
        updatedAt: '2023-05-16T15:04:40.487Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64639b8812814d75417b3a6a
    id: 64639b8812814d75417b3a69
    type: comment
  author: m0-ch4
  content: You are right, tokenizer.model was missing. Now it worked. Thank you!
  created_at: 2023-05-16 14:04:40+00:00
  edited: false
  hidden: false
  id: 64639b8812814d75417b3a69
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/be58899147100d8dda279228d6ba5b0f.svg
      fullname: Sho
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: m0-ch4
      type: user
    createdAt: '2023-05-16T15:04:40.000Z'
    data:
      status: closed
    id: 64639b8812814d75417b3a6a
    type: status-change
  author: m0-ch4
  created_at: 2023-05-16 14:04:40+00:00
  id: 64639b8812814d75417b3a6a
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 15
repo_id: TheBloke/stable-vicuna-13B-GPTQ
repo_type: model
status: closed
target_branch: null
title: 'TypeError: not a string'
