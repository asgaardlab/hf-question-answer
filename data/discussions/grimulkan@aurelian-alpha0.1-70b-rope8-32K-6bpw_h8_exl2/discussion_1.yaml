!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lazyDataScientist
conflicting_files: null
created_at: 2023-12-11 20:23:28+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/633a39ec8f27255b6b571101/7J_BcRm7ua0WZNIGwEzlo.png?w=200&h=200&f=face
      fullname: Cedrick Hesketh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lazyDataScientist
      type: user
    createdAt: '2023-12-11T20:23:28.000Z'
    data:
      edited: false
      editors:
      - lazyDataScientist
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9168333411216736
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/633a39ec8f27255b6b571101/7J_BcRm7ua0WZNIGwEzlo.png?w=200&h=200&f=face
          fullname: Cedrick Hesketh
          isHf: false
          isPro: false
          name: lazyDataScientist
          type: user
        html: '<p>Could you share the exact parameters that you use which the model
          returns good output. I have tried the recommended repetition_penalty  setting
          and I get <code>!?!?!?!?!?!?!?!?!?!...</code> for every prompt that that
          I gave the model.</p>

          '
        raw: Could you share the exact parameters that you use which the model returns
          good output. I have tried the recommended repetition_penalty  setting and
          I get ```!?!?!?!?!?!?!?!?!?!...``` for every prompt that that I gave the
          model.
        updatedAt: '2023-12-11T20:23:28.923Z'
      numEdits: 0
      reactions: []
    id: 65776fc0dd2996f01acfb20a
    type: comment
  author: lazyDataScientist
  content: Could you share the exact parameters that you use which the model returns
    good output. I have tried the recommended repetition_penalty  setting and I get
    ```!?!?!?!?!?!?!?!?!?!...``` for every prompt that that I gave the model.
  created_at: 2023-12-11 20:23:28+00:00
  edited: false
  hidden: false
  id: 65776fc0dd2996f01acfb20a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/636d6fceb1079bc9b2475e7e/VefNYYXAg4xfwSEF-xL1Y.png?w=200&h=200&f=face
      fullname: Grimulkan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: grimulkan
      type: user
    createdAt: '2024-01-10T23:58:03.000Z'
    data:
      edited: true
      editors:
      - grimulkan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4275791645050049
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/636d6fceb1079bc9b2475e7e/VefNYYXAg4xfwSEF-xL1Y.png?w=200&h=200&f=face
          fullname: Grimulkan
          isHf: false
          isPro: false
          name: grimulkan
          type: user
        html: "<p>Sorry, never got a notification for this comment for some reason.</p>\n\
          <p>That type of repetition looks like a different problem. Could be prompt\
          \ format (llama-chat) or rope scaling (which has to be 8)?</p>\n<p>Here\
          \ are 2 sets that work well for me in Oobabooga:</p>\n<p><strong>Standard\
          \ sampling</strong>:</p>\n<pre><code>'temperature': 0.8\n'top_p': 0.6\n\
          'min_p': 0\n'top_k': 40\n'repetition_penalty': 1.12\n'presence_penalty':\
          \ 0\n'frequency_penalty': 0\n'repetition_penalty_range': 1024\n'typical_p':\
          \ 1\n'tfs': 1\n'top_a': 0\n</code></pre>\n<p><strong>Mirostat</strong>:</p>\n\
          <pre><code>'mirostat_mode': 2\n'mirostat_tau': 2\n'mirostat_eta': 0.1\n\
          </code></pre>\n<p>with the other settings set to defaults:</p>\n<pre><code>'temperature':\
          \ 1\n'top_p': 1\n'min_p': 0\n'top_k': 0\n'repetition_penalty': 1\n'presence_penalty':\
          \ 0\n'frequency_penalty': 0\n'repetition_penalty_range': 1024\n'typical_p':\
          \ 1\n'tfs': 1\n'top_a': 0\n</code></pre>\n<p>edit: I see we actually sorted\
          \ this out in a different thread, didn\u2019t connect the names\u2026 Well\
          \ these settings can be here for others.</p>\n"
        raw: "Sorry, never got a notification for this comment for some reason.\n\n\
          That type of repetition looks like a different problem. Could be prompt\
          \ format (llama-chat) or rope scaling (which has to be 8)?\n\nHere are 2\
          \ sets that work well for me in Oobabooga:\n\n**Standard sampling**:\n```\n\
          'temperature': 0.8\n'top_p': 0.6\n'min_p': 0\n'top_k': 40\n'repetition_penalty':\
          \ 1.12\n'presence_penalty': 0\n'frequency_penalty': 0\n'repetition_penalty_range':\
          \ 1024\n'typical_p': 1\n'tfs': 1\n'top_a': 0\n```\n\n**Mirostat**:\n```\n\
          'mirostat_mode': 2\n'mirostat_tau': 2\n'mirostat_eta': 0.1\n```\nwith the\
          \ other settings set to defaults:\n```\n'temperature': 1\n'top_p': 1\n'min_p':\
          \ 0\n'top_k': 0\n'repetition_penalty': 1\n'presence_penalty': 0\n'frequency_penalty':\
          \ 0\n'repetition_penalty_range': 1024\n'typical_p': 1\n'tfs': 1\n'top_a':\
          \ 0\n```\n\nedit: I see we actually sorted this out in a different thread,\
          \ didn\u2019t connect the names\u2026 Well these settings can be here for\
          \ others."
        updatedAt: '2024-01-11T06:28:22.946Z'
      numEdits: 1
      reactions: []
    id: 659f2f0b58a49686b2891745
    type: comment
  author: grimulkan
  content: "Sorry, never got a notification for this comment for some reason.\n\n\
    That type of repetition looks like a different problem. Could be prompt format\
    \ (llama-chat) or rope scaling (which has to be 8)?\n\nHere are 2 sets that work\
    \ well for me in Oobabooga:\n\n**Standard sampling**:\n```\n'temperature': 0.8\n\
    'top_p': 0.6\n'min_p': 0\n'top_k': 40\n'repetition_penalty': 1.12\n'presence_penalty':\
    \ 0\n'frequency_penalty': 0\n'repetition_penalty_range': 1024\n'typical_p': 1\n\
    'tfs': 1\n'top_a': 0\n```\n\n**Mirostat**:\n```\n'mirostat_mode': 2\n'mirostat_tau':\
    \ 2\n'mirostat_eta': 0.1\n```\nwith the other settings set to defaults:\n```\n\
    'temperature': 1\n'top_p': 1\n'min_p': 0\n'top_k': 0\n'repetition_penalty': 1\n\
    'presence_penalty': 0\n'frequency_penalty': 0\n'repetition_penalty_range': 1024\n\
    'typical_p': 1\n'tfs': 1\n'top_a': 0\n```\n\nedit: I see we actually sorted this\
    \ out in a different thread, didn\u2019t connect the names\u2026 Well these settings\
    \ can be here for others."
  created_at: 2024-01-10 23:58:03+00:00
  edited: true
  hidden: false
  id: 659f2f0b58a49686b2891745
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: grimulkan/aurelian-alpha0.1-70b-rope8-32K-6bpw_h8_exl2
repo_type: model
status: open
target_branch: null
title: Repetition issue
