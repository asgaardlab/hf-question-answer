!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ggaabe
conflicting_files: null
created_at: 2023-05-06 02:58:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c55d9bcecf48fa62b60916e690e97d2d.svg
      fullname: Gabriel Garrett
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ggaabe
      type: user
    createdAt: '2023-05-06T03:58:08.000Z'
    data:
      edited: true
      editors:
      - ggaabe
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c55d9bcecf48fa62b60916e690e97d2d.svg
          fullname: Gabriel Garrett
          isHf: false
          isPro: false
          name: ggaabe
          type: user
        html: "<p>I'm trying to run the GPU example but with a Macbook M2 Max and\
          \ it seems trying to use <code>model.to(\"mps\")</code> simply hangs forever\
          \ without any error message:</p>\n<pre><code class=\"language-python\">tokenizer\
          \ = AutoTokenizer.from_pretrained(\n    path)\nmodel = AutoModelForCausalLM.from_pretrained(\n\
          \    path, torch_dtype=torch.float16)\n\n<span class=\"hljs-built_in\">print</span>(<span\
          \ class=\"hljs-string\">\"Device 0:\"</span>, model.device) <span class=\"\
          hljs-comment\"># prints: Device 0: cpu</span>\nmps_device = torch.device(<span\
          \ class=\"hljs-string\">\"mps\"</span>)\n<span class=\"hljs-built_in\">print</span>(<span\
          \ class=\"hljs-string\">\"Device 1:\"</span>, mps_device)  <span class=\"\
          hljs-comment\"># prints: Device 1: mps</span>\nmodel = model.to(mps_device)\n\
          <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"\
          Device 2:\"</span>, model.device) <span class=\"hljs-comment\"># ^^ The\
          \ above line hangs forever, this line is never reached.</span>\n</code></pre>\n\
          <p>Any thoughts on what I could do to get this to run with GPU inference?</p>\n\
          <p>PyTorch Version: 2.1.0.dev20230505</p>\n"
        raw: "I'm trying to run the GPU example but with a Macbook M2 Max and it seems\
          \ trying to use `model.to(\"mps\")` simply hangs forever without any error\
          \ message:\n\n```python\ntokenizer = AutoTokenizer.from_pretrained(\n  \
          \  path)\nmodel = AutoModelForCausalLM.from_pretrained(\n    path, torch_dtype=torch.float16)\n\
          \nprint(\"Device 0:\", model.device) # prints: Device 0: cpu\nmps_device\
          \ = torch.device(\"mps\")\nprint(\"Device 1:\", mps_device)  # prints: Device\
          \ 1: mps\nmodel = model.to(mps_device)\nprint(\"Device 2:\", model.device)\
          \ # ^^ The above line hangs forever, this line is never reached.\n```\n\n\
          Any thoughts on what I could do to get this to run with GPU inference?\n\
          \nPyTorch Version: 2.1.0.dev20230505"
        updatedAt: '2023-05-06T03:59:29.696Z'
      numEdits: 1
      reactions: []
    id: 6455d050639bc4172cf96d25
    type: comment
  author: ggaabe
  content: "I'm trying to run the GPU example but with a Macbook M2 Max and it seems\
    \ trying to use `model.to(\"mps\")` simply hangs forever without any error message:\n\
    \n```python\ntokenizer = AutoTokenizer.from_pretrained(\n    path)\nmodel = AutoModelForCausalLM.from_pretrained(\n\
    \    path, torch_dtype=torch.float16)\n\nprint(\"Device 0:\", model.device) #\
    \ prints: Device 0: cpu\nmps_device = torch.device(\"mps\")\nprint(\"Device 1:\"\
    , mps_device)  # prints: Device 1: mps\nmodel = model.to(mps_device)\nprint(\"\
    Device 2:\", model.device) # ^^ The above line hangs forever, this line is never\
    \ reached.\n```\n\nAny thoughts on what I could do to get this to run with GPU\
    \ inference?\n\nPyTorch Version: 2.1.0.dev20230505"
  created_at: 2023-05-06 02:58:08+00:00
  edited: true
  hidden: false
  id: 6455d050639bc4172cf96d25
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/40fb0922a1388a2d717fd6882c6f9fe2.svg
      fullname: Yucheng Lu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: EugeneLu
      type: user
    createdAt: '2023-05-08T17:10:06.000Z'
    data:
      edited: false
      editors:
      - EugeneLu
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/40fb0922a1388a2d717fd6882c6f9fe2.svg
          fullname: Yucheng Lu
          isHf: false
          isPro: false
          name: EugeneLu
          type: user
        html: '<p>What is the size of GPU memory for your M2 Max?</p>

          '
        raw: What is the size of GPU memory for your M2 Max?
        updatedAt: '2023-05-08T17:10:06.107Z'
      numEdits: 0
      reactions: []
    id: 64592ceec5d0d57ba4233fa5
    type: comment
  author: EugeneLu
  content: What is the size of GPU memory for your M2 Max?
  created_at: 2023-05-08 16:10:06+00:00
  edited: false
  hidden: false
  id: 64592ceec5d0d57ba4233fa5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c55d9bcecf48fa62b60916e690e97d2d.svg
      fullname: Gabriel Garrett
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ggaabe
      type: user
    createdAt: '2023-05-08T17:14:31.000Z'
    data:
      edited: false
      editors:
      - ggaabe
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c55d9bcecf48fa62b60916e690e97d2d.svg
          fullname: Gabriel Garrett
          isHf: false
          isPro: false
          name: ggaabe
          type: user
        html: '<p>My bad. There was something probably misconfigured with my env though
          I have no idea what. I had used pip for all the env packages; I retried
          with conda and it all worked.</p>

          '
        raw: My bad. There was something probably misconfigured with my env though
          I have no idea what. I had used pip for all the env packages; I retried
          with conda and it all worked.
        updatedAt: '2023-05-08T17:14:31.860Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - amaliak
    id: 64592df7f92601affa3450dd
    type: comment
  author: ggaabe
  content: My bad. There was something probably misconfigured with my env though I
    have no idea what. I had used pip for all the env packages; I retried with conda
    and it all worked.
  created_at: 2023-05-08 16:14:31+00:00
  edited: false
  hidden: false
  id: 64592df7f92601affa3450dd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: togethercomputer/RedPajama-INCITE-Instruct-3B-v1
repo_type: model
status: open
target_branch: null
title: Running the model on MPS backend (Macbook GPUs) hangs indefinitely
