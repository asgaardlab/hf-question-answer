!!python/object:huggingface_hub.community.DiscussionWithDetails
author: cmp-nct
conflicting_files: null
created_at: 2023-12-21 16:33:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/70bfddcf585e2f191ba24f47274c9e94.svg
      fullname: John
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cmp-nct
      type: user
    createdAt: '2023-12-21T16:33:31.000Z'
    data:
      edited: false
      editors:
      - cmp-nct
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9737316966056824
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/70bfddcf585e2f191ba24f47274c9e94.svg
          fullname: John
          isHf: false
          isPro: false
          name: cmp-nct
          type: user
        html: '<p>You provided two different fine tunes for 13B, both are very differently
          named (one pretrained vicuna, and this one)<br>The readme lists less training
          data for the vicuna upload, the configuration shows "square" as aspect ratio,
          does that mean the image is cropped to square instead of padding in this
          case ?</p>

          <p>What is the purpose of the other finetune ?<br>I''m just testing both,
          the vicuna one appears to hallucinate a tiny bit more than the previous
          7B variant and it does not follow instructions as good as I was used to.</p>

          '
        raw: "You provided two different fine tunes for 13B, both are very differently\
          \ named (one pretrained vicuna, and this one)\r\nThe readme lists less training\
          \ data for the vicuna upload, the configuration shows \"square\" as aspect\
          \ ratio, does that mean the image is cropped to square instead of padding\
          \ in this case ?\r\n\r\nWhat is the purpose of the other finetune ?\r\n\
          I'm just testing both, the vicuna one appears to hallucinate a tiny bit\
          \ more than the previous 7B variant and it does not follow instructions\
          \ as good as I was used to."
        updatedAt: '2023-12-21T16:33:31.975Z'
      numEdits: 0
      reactions: []
    id: 658468dbc2b0d67b5dc7025a
    type: comment
  author: cmp-nct
  content: "You provided two different fine tunes for 13B, both are very differently\
    \ named (one pretrained vicuna, and this one)\r\nThe readme lists less training\
    \ data for the vicuna upload, the configuration shows \"square\" as aspect ratio,\
    \ does that mean the image is cropped to square instead of padding in this case\
    \ ?\r\n\r\nWhat is the purpose of the other finetune ?\r\nI'm just testing both,\
    \ the vicuna one appears to hallucinate a tiny bit more than the previous 7B variant\
    \ and it does not follow instructions as good as I was used to."
  created_at: 2023-12-21 16:33:31+00:00
  edited: false
  hidden: false
  id: 658468dbc2b0d67b5dc7025a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b02ec0e5000ae8a572ced5/h5T5c14F-lHmx3X5K67A2.jpeg?w=200&h=200&f=face
      fullname: Lin Chen
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Lin-Chen
      type: user
    createdAt: '2023-12-21T17:13:36.000Z'
    data:
      edited: false
      editors:
      - Lin-Chen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9671795964241028
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b02ec0e5000ae8a572ced5/h5T5c14F-lHmx3X5K67A2.jpeg?w=200&h=200&f=face
          fullname: Lin Chen
          isHf: false
          isPro: false
          name: Lin-Chen
          type: user
        html: '<blockquote>

          <p>You provided two different fine tunes for 13B, both are very differently
          named (one pretrained vicuna, and this one)<br>The readme lists less training
          data for the vicuna upload, the configuration shows "square" as aspect ratio,
          does that mean the image is cropped to square instead of padding in this
          case ?</p>

          <p>What is the purpose of the other finetune ?<br>I''m just testing both,
          the vicuna one appears to hallucinate a tiny bit more than the previous
          7B variant and it does not follow instructions as good as I was used to.</p>

          </blockquote>

          <p>Sorry for the confusion. The vicuna one is LLM only after the pretain
          stage.</p>

          '
        raw: "> You provided two different fine tunes for 13B, both are very differently\
          \ named (one pretrained vicuna, and this one)\n> The readme lists less training\
          \ data for the vicuna upload, the configuration shows \"square\" as aspect\
          \ ratio, does that mean the image is cropped to square instead of padding\
          \ in this case ?\n> \n> What is the purpose of the other finetune ?\n> I'm\
          \ just testing both, the vicuna one appears to hallucinate a tiny bit more\
          \ than the previous 7B variant and it does not follow instructions as good\
          \ as I was used to.\n\nSorry for the confusion. The vicuna one is LLM only\
          \ after the pretain stage."
        updatedAt: '2023-12-21T17:13:36.138Z'
      numEdits: 0
      reactions: []
    id: 65847240c7918aa0447853e1
    type: comment
  author: Lin-Chen
  content: "> You provided two different fine tunes for 13B, both are very differently\
    \ named (one pretrained vicuna, and this one)\n> The readme lists less training\
    \ data for the vicuna upload, the configuration shows \"square\" as aspect ratio,\
    \ does that mean the image is cropped to square instead of padding in this case\
    \ ?\n> \n> What is the purpose of the other finetune ?\n> I'm just testing both,\
    \ the vicuna one appears to hallucinate a tiny bit more than the previous 7B variant\
    \ and it does not follow instructions as good as I was used to.\n\nSorry for the\
    \ confusion. The vicuna one is LLM only after the pretain stage."
  created_at: 2023-12-21 17:13:36+00:00
  edited: false
  hidden: false
  id: 65847240c7918aa0447853e1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/70bfddcf585e2f191ba24f47274c9e94.svg
      fullname: John
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cmp-nct
      type: user
    createdAt: '2023-12-21T19:02:34.000Z'
    data:
      edited: false
      editors:
      - cmp-nct
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9878136515617371
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/70bfddcf585e2f191ba24f47274c9e94.svg
          fullname: John
          isHf: false
          isPro: false
          name: cmp-nct
          type: user
        html: '<p>Thanks a lot, that explains it.<br>I tested the other one and it
          does not have the issues anymore and is better in listing fine details than
          the 7B one.<br>However - hallucinations increased also</p>

          '
        raw: 'Thanks a lot, that explains it.

          I tested the other one and it does not have the issues anymore and is better
          in listing fine details than the 7B one.

          However - hallucinations increased also'
        updatedAt: '2023-12-21T19:02:34.395Z'
      numEdits: 0
      reactions: []
    id: 65848bca92eba5ad69ba5dcc
    type: comment
  author: cmp-nct
  content: 'Thanks a lot, that explains it.

    I tested the other one and it does not have the issues anymore and is better in
    listing fine details than the 7B one.

    However - hallucinations increased also'
  created_at: 2023-12-21 19:02:34+00:00
  edited: false
  hidden: false
  id: 65848bca92eba5ad69ba5dcc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b02ec0e5000ae8a572ced5/h5T5c14F-lHmx3X5K67A2.jpeg?w=200&h=200&f=face
      fullname: Lin Chen
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Lin-Chen
      type: user
    createdAt: '2023-12-22T10:46:36.000Z'
    data:
      edited: false
      editors:
      - Lin-Chen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.977887749671936
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b02ec0e5000ae8a572ced5/h5T5c14F-lHmx3X5K67A2.jpeg?w=200&h=200&f=face
          fullname: Lin Chen
          isHf: false
          isPro: false
          name: Lin-Chen
          type: user
        html: '<blockquote>

          <p>Thanks a lot, that explains it.<br>I tested the other one and it does
          not have the issues anymore and is better in listing fine details than the
          7B one.<br>However - hallucinations increased also</p>

          </blockquote>

          <p>Thanks for your feedback! We will make some efforts to decrease the hallucinations
          in future work.</p>

          '
        raw: '> Thanks a lot, that explains it.

          > I tested the other one and it does not have the issues anymore and is
          better in listing fine details than the 7B one.

          > However - hallucinations increased also


          Thanks for your feedback! We will make some efforts to decrease the hallucinations
          in future work.'
        updatedAt: '2023-12-22T10:46:36.294Z'
      numEdits: 0
      reactions: []
    id: 6585690c35c3b05065e44b03
    type: comment
  author: Lin-Chen
  content: '> Thanks a lot, that explains it.

    > I tested the other one and it does not have the issues anymore and is better
    in listing fine details than the 7B one.

    > However - hallucinations increased also


    Thanks for your feedback! We will make some efforts to decrease the hallucinations
    in future work.'
  created_at: 2023-12-22 10:46:36+00:00
  edited: false
  hidden: false
  id: 6585690c35c3b05065e44b03
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b02ec0e5000ae8a572ced5/h5T5c14F-lHmx3X5K67A2.jpeg?w=200&h=200&f=face
      fullname: Lin Chen
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Lin-Chen
      type: user
    createdAt: '2023-12-27T18:00:42.000Z'
    data:
      status: closed
    id: 658c664a077d14ff7e6dd603
    type: status-change
  author: Lin-Chen
  created_at: 2023-12-27 18:00:42+00:00
  id: 658c664a077d14ff7e6dd603
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Lin-Chen/ShareGPT4V-13B
repo_type: model
status: closed
target_branch: null
title: Question on the two variants
