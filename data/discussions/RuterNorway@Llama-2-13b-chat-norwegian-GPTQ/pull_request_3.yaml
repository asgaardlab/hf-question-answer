!!python/object:huggingface_hub.community.DiscussionWithDetails
author: marksverdhei
conflicting_files: []
created_at: 2023-09-26 06:34:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648679572929-6204304ddec9ca07e4411eca.jpeg?w=200&h=200&f=face
      fullname: Markus Heiervang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: marksverdhei
      type: user
    createdAt: '2023-09-26T07:34:34.000Z'
    data:
      edited: true
      editors:
      - marksverdhei
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.11044929921627045
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648679572929-6204304ddec9ca07e4411eca.jpeg?w=200&h=200&f=face
          fullname: Markus Heiervang
          isHf: false
          isPro: false
          name: marksverdhei
          type: user
        html: "<p>This pull request converts the model files to make it runnable with\
          \ the <code>\U0001F917 transformers</code>library directly, by converting\
          \ the files to the same format as TheBloke models.<br>This includes: </p>\n\
          <ul>\n<li>Adding the quantization config to <code>config.json</code></li>\n\
          <li>Adding metadata to model.safetensors: <code>{\"format\": \"pt\", \"\
          quantized_by\": \"RuterNorway\"}</code></li>\n</ul>\n<p>Then, given that\
          \ the libraries<code>transformers, optimum, auto-gptq</code><br>you should\
          \ be able to load it in like this:</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-comment\"># Load model directly</span>\n<span class=\"\
          hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span>\
          \ AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(<span\
          \ class=\"hljs-string\">\"RuterNorway/Llama-2-13b-chat-norwegian-GPTQ\"\
          </span>)\nmodel = AutoModelForCausalLM.from_pretrained(<span class=\"hljs-string\"\
          >\"RuterNorway/Llama-2-13b-chat-norwegian-GPTQ\"</span>)\n</code></pre>\n"
        raw: "This pull request converts the model files to make it runnable with\
          \ the `\U0001F917 transformers`library directly, by converting the files\
          \ to the same format as TheBloke models.\nThis includes: \n- Adding the\
          \ quantization config to `config.json`\n- Adding metadata to model.safetensors:\
          \ `{\"format\": \"pt\", \"quantized_by\": \"RuterNorway\"}`\n\nThen, given\
          \ that the libraries`transformers, optimum, auto-gptq`\nyou should be able\
          \ to load it in like this:\n\n```python\n# Load model directly\nfrom transformers\
          \ import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"\
          RuterNorway/Llama-2-13b-chat-norwegian-GPTQ\")\nmodel = AutoModelForCausalLM.from_pretrained(\"\
          RuterNorway/Llama-2-13b-chat-norwegian-GPTQ\")\n```"
        updatedAt: '2023-09-26T08:37:10.507Z'
      numEdits: 1
      reactions: []
    id: 6512898a9a1484c10fb58a6a
    type: comment
  author: marksverdhei
  content: "This pull request converts the model files to make it runnable with the\
    \ `\U0001F917 transformers`library directly, by converting the files to the same\
    \ format as TheBloke models.\nThis includes: \n- Adding the quantization config\
    \ to `config.json`\n- Adding metadata to model.safetensors: `{\"format\": \"pt\"\
    , \"quantized_by\": \"RuterNorway\"}`\n\nThen, given that the libraries`transformers,\
    \ optimum, auto-gptq`\nyou should be able to load it in like this:\n\n```python\n\
    # Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\
    \ntokenizer = AutoTokenizer.from_pretrained(\"RuterNorway/Llama-2-13b-chat-norwegian-GPTQ\"\
    )\nmodel = AutoModelForCausalLM.from_pretrained(\"RuterNorway/Llama-2-13b-chat-norwegian-GPTQ\"\
    )\n```"
  created_at: 2023-09-26 06:34:34+00:00
  edited: true
  hidden: false
  id: 6512898a9a1484c10fb58a6a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648679572929-6204304ddec9ca07e4411eca.jpeg?w=200&h=200&f=face
      fullname: Markus Heiervang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: marksverdhei
      type: user
    createdAt: '2023-09-26T07:47:00.000Z'
    data:
      from: "GPTQ-loading with \U0001F917 transformers lib"
      to: "Add GPTQ-loading with \U0001F917 transformers lib"
    id: 65128c74d4556f9e6503c2a6
    type: title-change
  author: marksverdhei
  created_at: 2023-09-26 06:47:00+00:00
  id: 65128c74d4556f9e6503c2a6
  new_title: "Add GPTQ-loading with \U0001F917 transformers lib"
  old_title: "GPTQ-loading with \U0001F917 transformers lib"
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    createdAt: '2023-09-26T08:31:09.000Z'
    data:
      oid: 7baec41fdadcfdc2c18597ff60365e24414cb497
      parents:
      - ec675bd3d74c6ced95fbef3b28983cf20cd72d40
      subject: Add metadata and rename model to model.safetensors
    id: 651296cd0000000000000000
    type: commit
  author: deleted
  created_at: 2023-09-26 07:31:09+00:00
  id: 651296cd0000000000000000
  oid: 7baec41fdadcfdc2c18597ff60365e24414cb497
  summary: Add metadata and rename model to model.safetensors
  type: commit
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    createdAt: '2023-09-26T08:31:24.000Z'
    data:
      oid: 07fad6407d83ef606aa3f6f36dda2bc37224c7ed
      parents:
      - 7baec41fdadcfdc2c18597ff60365e24414cb497
      subject: Add quantization config to config.json
    id: 651296dc0000000000000000
    type: commit
  author: deleted
  created_at: 2023-09-26 07:31:24+00:00
  id: 651296dc0000000000000000
  oid: 07fad6407d83ef606aa3f6f36dda2bc37224c7ed
  summary: Add quantization config to config.json
  type: commit
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    createdAt: '2023-09-26T19:22:27.000Z'
    data:
      oid: fd7dfbf876e1949bcb0e20ac8d2b9c05a685ce13
      parents:
      - 07fad6407d83ef606aa3f6f36dda2bc37224c7ed
      subject: add quantize config
    id: 65132f730000000000000000
    type: commit
  author: deleted
  created_at: 2023-09-26 18:22:27+00:00
  id: 65132f730000000000000000
  oid: fd7dfbf876e1949bcb0e20ac8d2b9c05a685ce13
  summary: add quantize config
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64db79387f749b6e34577a61/wCo7eZHFwHn0_YfTh-HFF.png?w=200&h=200&f=face
      fullname: Ruter
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: RuterNorway
      type: user
    createdAt: '2023-09-27T08:33:55.000Z'
    data:
      edited: false
      editors:
      - RuterNorway
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9956406950950623
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64db79387f749b6e34577a61/wCo7eZHFwHn0_YfTh-HFF.png?w=200&h=200&f=face
          fullname: Ruter
          isHf: false
          isPro: false
          name: RuterNorway
          type: user
        html: '<p>Great work. Tested and works as expected. </p>

          '
        raw: 'Great work. Tested and works as expected. '
        updatedAt: '2023-09-27T08:33:55.550Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - marksverdhei
      relatedEventId: 6513e8f375940371506e1333
    id: 6513e8f375940371506e132e
    type: comment
  author: RuterNorway
  content: 'Great work. Tested and works as expected. '
  created_at: 2023-09-27 07:33:55+00:00
  edited: false
  hidden: false
  id: 6513e8f375940371506e132e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64db79387f749b6e34577a61/wCo7eZHFwHn0_YfTh-HFF.png?w=200&h=200&f=face
      fullname: Ruter
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: RuterNorway
      type: user
    createdAt: '2023-09-27T08:33:55.000Z'
    data:
      status: open
    id: 6513e8f375940371506e1333
    type: status-change
  author: RuterNorway
  created_at: 2023-09-27 07:33:55+00:00
  id: 6513e8f375940371506e1333
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64db79387f749b6e34577a61/wCo7eZHFwHn0_YfTh-HFF.png?w=200&h=200&f=face
      fullname: Ruter
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: RuterNorway
      type: user
    createdAt: '2023-09-27T08:34:02.000Z'
    data:
      status: merged
    id: 6513e8fa75940371506e13d2
    type: status-change
  author: RuterNorway
  created_at: 2023-09-27 07:34:02+00:00
  id: 6513e8fa75940371506e13d2
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 2de3c927dfe5a9cef2b667b03b80b7277c6d8d8d
num: 3
repo_id: RuterNorway/Llama-2-13b-chat-norwegian-GPTQ
repo_type: model
status: merged
target_branch: refs/heads/main
title: "Add GPTQ-loading with \U0001F917 transformers lib"
