!!python/object:huggingface_hub.community.DiscussionWithDetails
author: joelr23
conflicting_files: null
created_at: 2023-08-30 03:19:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ba0a759774f04ae915de4c94776eec7d.svg
      fullname: Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joelr23
      type: user
    createdAt: '2023-08-30T04:19:38.000Z'
    data:
      edited: false
      editors:
      - joelr23
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7565003633499146
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ba0a759774f04ae915de4c94776eec7d.svg
          fullname: Liu
          isHf: false
          isPro: false
          name: joelr23
          type: user
        html: "<p>hi\uFF0Cis there any method to generate batch image caption? </p>\n"
        raw: "hi\uFF0Cis there any method to generate batch image caption? "
        updatedAt: '2023-08-30T04:19:38.197Z'
      numEdits: 0
      reactions: []
    id: 64eec35af5027d22c2da8871
    type: comment
  author: joelr23
  content: "hi\uFF0Cis there any method to generate batch image caption? "
  created_at: 2023-08-30 03:19:38+00:00
  edited: false
  hidden: false
  id: 64eec35af5027d22c2da8871
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/ba0a759774f04ae915de4c94776eec7d.svg
      fullname: Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joelr23
      type: user
    createdAt: '2023-08-30T04:19:50.000Z'
    data:
      from: batch prompt
      to: batch image caption
    id: 64eec3666ac1fee42422674c
    type: title-change
  author: joelr23
  created_at: 2023-08-30 03:19:50+00:00
  id: 64eec3666ac1fee42422674c
  new_title: batch image caption
  old_title: batch prompt
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
      fullname: Yih-Dar SHIEH
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ydshieh
      type: user
    createdAt: '2023-08-30T06:15:18.000Z'
    data:
      edited: false
      editors:
      - ydshieh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9530934691429138
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
          fullname: Yih-Dar SHIEH
          isHf: true
          isPro: false
          name: ydshieh
          type: user
        html: '<p>Hi, you can put a list of images and a list of text (prompts), it
          should work. If there is something wrong, let me know please.</p>

          '
        raw: Hi, you can put a list of images and a list of text (prompts), it should
          work. If there is something wrong, let me know please.
        updatedAt: '2023-08-30T06:15:18.669Z'
      numEdits: 0
      reactions: []
    id: 64eede76ad1419742b934930
    type: comment
  author: ydshieh
  content: Hi, you can put a list of images and a list of text (prompts), it should
    work. If there is something wrong, let me know please.
  created_at: 2023-08-30 05:15:18+00:00
  edited: false
  hidden: false
  id: 64eede76ad1419742b934930
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ba0a759774f04ae915de4c94776eec7d.svg
      fullname: Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joelr23
      type: user
    createdAt: '2023-09-01T08:48:28.000Z'
    data:
      edited: true
      editors:
      - joelr23
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.40735429525375366
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ba0a759774f04ae915de4c94776eec7d.svg
          fullname: Liu
          isHf: false
          isPro: false
          name: joelr23
          type: user
        html: "<p>here is my code:</p>\n<pre><code>\n# func run\ndef run_example(images):\n\
          \    prompt = \"&lt;grounding&gt; Describe this image in detail:\"\n   \
          \ batch_ppt = [prompt] * len(images)\n    # inputs = processor(text=prompt,\
          \ images=image, return_tensors=\"pt\")\n    inputs = processor(text=batch_ppt,\
          \ images=images, return_tensors=\"pt\")\n    generated_ids = model.generate(\n\
          \        pixel_values=inputs[\"pixel_values\"],\n        input_ids=inputs[\"\
          input_ids\"][:, :-1],\n        attention_mask=inputs[\"attention_mask\"\
          ][:, :-1],\n        img_features=None,\n        img_attn_mask=inputs[\"\
          img_attn_mask\"][:, :-1],\n        use_cache=True,\n        max_new_tokens=128,\n\
          \    )\n    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\
          \    _processed_text = processor.post_process_generation(generated_text,\
          \ cleanup_and_extract=False)\n    processed_text, entities = processor.post_process_generation(generated_text)\n\
          \    print(processed_text)\n    # print(entities)\n    # print(_processed_text)\n\
          \nimg_path = '/prompts_data/snowman.jpg'\nimages = [Image.open(img_path)]\
          \ * 3\nrun_example(images)\n</code></pre>\n<p>then i get the following error\
          \ info:</p>\n<pre><code>Traceback (most recent call last):\n  File \"/cfs-nj-gameai/joelrliu/prompts_data/ko.py\"\
          , line 39, in &lt;module&gt;\n    generated_ids = model.generate(\n  File\
          \ \"/root/.cache/huggingface/modules/transformers_modules/kosmos-2-patch14-224/modeling_kosmos2.py\"\
          , line 1739, in generate\n    output = self.text_model.generate(\n  File\
          \ \"/usr/miniconda/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/usr/miniconda/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 1596, in generate\n    return self.greedy_search(\n  File \"/usr/miniconda/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 2444, in greedy_search\n    outputs = self(\n  File \"/usr/miniconda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/root/.cache/huggingface/modules/transformers_modules/kosmos-2-patch14-224/modeling_kosmos2.py\"\
          , line 1362, in forward\n    outputs = self.model(\n  File \"/usr/miniconda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/root/.cache/huggingface/modules/transformers_modules/kosmos-2-patch14-224/modeling_kosmos2.py\"\
          , line 1068, in forward\n    hidden_states = self.forward_embedding(\n \
          \ File \"/root/.cache/huggingface/modules/transformers_modules/kosmos-2-patch14-224/modeling_kosmos2.py\"\
          , line 1010, in forward_embedding\n    inputs_embeds[img_input_mask.to(dtype=torch.bool)]\
          \ = img_features\nRuntimeError: shape mismatch: value tensor of shape [3,\
          \ 64, 2048] cannot be broadcast to indexing result of shape [192, 2048]\n\
          </code></pre>\n<p>it seems that the shape is mismatch, so I try use the\
          \ <code>reshape</code> to fix the code as follow:</p>\n<pre><code>    inputs_embeds[img_input_mask.to(dtype=torch.bool)]\
          \ = img_features.reshape[-1, img_features.shape[-1]]\n</code></pre>\n<p>the\
          \ error has gone, however, get unexcpted prompt result...</p>\n"
        raw: "here is my code:\n```\n\n# func run\ndef run_example(images):\n    prompt\
          \ = \"<grounding> Describe this image in detail:\"\n    batch_ppt = [prompt]\
          \ * len(images)\n    # inputs = processor(text=prompt, images=image, return_tensors=\"\
          pt\")\n    inputs = processor(text=batch_ppt, images=images, return_tensors=\"\
          pt\")\n    generated_ids = model.generate(\n        pixel_values=inputs[\"\
          pixel_values\"],\n        input_ids=inputs[\"input_ids\"][:, :-1],\n   \
          \     attention_mask=inputs[\"attention_mask\"][:, :-1],\n        img_features=None,\n\
          \        img_attn_mask=inputs[\"img_attn_mask\"][:, :-1],\n        use_cache=True,\n\
          \        max_new_tokens=128,\n    )\n    generated_text = processor.batch_decode(generated_ids,\
          \ skip_special_tokens=True)[0]\n    _processed_text = processor.post_process_generation(generated_text,\
          \ cleanup_and_extract=False)\n    processed_text, entities = processor.post_process_generation(generated_text)\n\
          \    print(processed_text)\n    # print(entities)\n    # print(_processed_text)\n\
          \nimg_path = '/prompts_data/snowman.jpg'\nimages = [Image.open(img_path)]\
          \ * 3\nrun_example(images)\n```\nthen i get the following error info:\n\
          ```\nTraceback (most recent call last):\n  File \"/cfs-nj-gameai/joelrliu/prompts_data/ko.py\"\
          , line 39, in <module>\n    generated_ids = model.generate(\n  File \"/root/.cache/huggingface/modules/transformers_modules/kosmos-2-patch14-224/modeling_kosmos2.py\"\
          , line 1739, in generate\n    output = self.text_model.generate(\n  File\
          \ \"/usr/miniconda/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/usr/miniconda/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 1596, in generate\n    return self.greedy_search(\n  File \"/usr/miniconda/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 2444, in greedy_search\n    outputs = self(\n  File \"/usr/miniconda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/root/.cache/huggingface/modules/transformers_modules/kosmos-2-patch14-224/modeling_kosmos2.py\"\
          , line 1362, in forward\n    outputs = self.model(\n  File \"/usr/miniconda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/root/.cache/huggingface/modules/transformers_modules/kosmos-2-patch14-224/modeling_kosmos2.py\"\
          , line 1068, in forward\n    hidden_states = self.forward_embedding(\n \
          \ File \"/root/.cache/huggingface/modules/transformers_modules/kosmos-2-patch14-224/modeling_kosmos2.py\"\
          , line 1010, in forward_embedding\n    inputs_embeds[img_input_mask.to(dtype=torch.bool)]\
          \ = img_features\nRuntimeError: shape mismatch: value tensor of shape [3,\
          \ 64, 2048] cannot be broadcast to indexing result of shape [192, 2048]\n\
          ```\nit seems that the shape is mismatch, so I try use the `reshape` to\
          \ fix the code as follow:\n```\n    inputs_embeds[img_input_mask.to(dtype=torch.bool)]\
          \ = img_features.reshape[-1, img_features.shape[-1]]\n```\nthe error has\
          \ gone, however, get unexcpted prompt result..."
        updatedAt: '2023-09-01T08:58:49.039Z'
      numEdits: 4
      reactions: []
    id: 64f1a55c79e58d30324a6ae6
    type: comment
  author: joelr23
  content: "here is my code:\n```\n\n# func run\ndef run_example(images):\n    prompt\
    \ = \"<grounding> Describe this image in detail:\"\n    batch_ppt = [prompt] *\
    \ len(images)\n    # inputs = processor(text=prompt, images=image, return_tensors=\"\
    pt\")\n    inputs = processor(text=batch_ppt, images=images, return_tensors=\"\
    pt\")\n    generated_ids = model.generate(\n        pixel_values=inputs[\"pixel_values\"\
    ],\n        input_ids=inputs[\"input_ids\"][:, :-1],\n        attention_mask=inputs[\"\
    attention_mask\"][:, :-1],\n        img_features=None,\n        img_attn_mask=inputs[\"\
    img_attn_mask\"][:, :-1],\n        use_cache=True,\n        max_new_tokens=128,\n\
    \    )\n    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\
    \    _processed_text = processor.post_process_generation(generated_text, cleanup_and_extract=False)\n\
    \    processed_text, entities = processor.post_process_generation(generated_text)\n\
    \    print(processed_text)\n    # print(entities)\n    # print(_processed_text)\n\
    \nimg_path = '/prompts_data/snowman.jpg'\nimages = [Image.open(img_path)] * 3\n\
    run_example(images)\n```\nthen i get the following error info:\n```\nTraceback\
    \ (most recent call last):\n  File \"/cfs-nj-gameai/joelrliu/prompts_data/ko.py\"\
    , line 39, in <module>\n    generated_ids = model.generate(\n  File \"/root/.cache/huggingface/modules/transformers_modules/kosmos-2-patch14-224/modeling_kosmos2.py\"\
    , line 1739, in generate\n    output = self.text_model.generate(\n  File \"/usr/miniconda/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/usr/miniconda/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 1596, in generate\n    return self.greedy_search(\n  File \"/usr/miniconda/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 2444, in greedy_search\n    outputs = self(\n  File \"/usr/miniconda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /root/.cache/huggingface/modules/transformers_modules/kosmos-2-patch14-224/modeling_kosmos2.py\"\
    , line 1362, in forward\n    outputs = self.model(\n  File \"/usr/miniconda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /root/.cache/huggingface/modules/transformers_modules/kosmos-2-patch14-224/modeling_kosmos2.py\"\
    , line 1068, in forward\n    hidden_states = self.forward_embedding(\n  File \"\
    /root/.cache/huggingface/modules/transformers_modules/kosmos-2-patch14-224/modeling_kosmos2.py\"\
    , line 1010, in forward_embedding\n    inputs_embeds[img_input_mask.to(dtype=torch.bool)]\
    \ = img_features\nRuntimeError: shape mismatch: value tensor of shape [3, 64,\
    \ 2048] cannot be broadcast to indexing result of shape [192, 2048]\n```\nit seems\
    \ that the shape is mismatch, so I try use the `reshape` to fix the code as follow:\n\
    ```\n    inputs_embeds[img_input_mask.to(dtype=torch.bool)] = img_features.reshape[-1,\
    \ img_features.shape[-1]]\n```\nthe error has gone, however, get unexcpted prompt\
    \ result..."
  created_at: 2023-09-01 07:48:28+00:00
  edited: true
  hidden: false
  id: 64f1a55c79e58d30324a6ae6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b8425c02aea8d6b36b144cf834970fcf.svg
      fullname: Ashwath
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ashwath-Shetty
      type: user
    createdAt: '2023-09-01T13:11:52.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/b8425c02aea8d6b36b144cf834970fcf.svg
          fullname: Ashwath
          isHf: false
          isPro: false
          name: Ashwath-Shetty
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-09-01T14:03:16.655Z'
      numEdits: 0
      reactions: []
    id: 64f1e31881177823df69ad99
    type: comment
  author: Ashwath-Shetty
  content: This comment has been hidden
  created_at: 2023-09-01 12:11:52+00:00
  edited: true
  hidden: true
  id: 64f1e31881177823df69ad99
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
      fullname: Yih-Dar SHIEH
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ydshieh
      type: user
    createdAt: '2023-09-01T14:30:24.000Z'
    data:
      edited: false
      editors:
      - ydshieh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.921180248260498
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
          fullname: Yih-Dar SHIEH
          isHf: true
          isPro: false
          name: ydshieh
          type: user
        html: "<p>Thanks for opening this issue <span data-props=\"{&quot;user&quot;:&quot;joelr23&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/joelr23\"\
          >@<span class=\"underline\">joelr23</span></a></span>\n\n\t</span></span>\
          \ . There is indeed some problems when using batch. I will take a deeper\
          \ look.</p>\n"
        raw: Thanks for opening this issue @joelr23 . There is indeed some problems
          when using batch. I will take a deeper look.
        updatedAt: '2023-09-01T14:30:24.088Z'
      numEdits: 0
      reactions: []
    id: 64f1f58050a88166833a68ac
    type: comment
  author: ydshieh
  content: Thanks for opening this issue @joelr23 . There is indeed some problems
    when using batch. I will take a deeper look.
  created_at: 2023-09-01 13:30:24+00:00
  edited: false
  hidden: false
  id: 64f1f58050a88166833a68ac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
      fullname: Yih-Dar SHIEH
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ydshieh
      type: user
    createdAt: '2023-09-01T15:03:11.000Z'
    data:
      edited: true
      editors:
      - ydshieh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9131166934967041
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
          fullname: Yih-Dar SHIEH
          isHf: true
          isPro: false
          name: ydshieh
          type: user
        html: '<p>Hello again! I made a small change, and it should be able to run
          with batch examples now.</p>

          <p>[Note!] The current code snippet (the <code>[:, :-1]</code> part below)
          won''t work with batch examples if there is padding happening! But in your
          case, there is no padding, so it''s fine.</p>

          <pre><code class="language-python">inputs[<span class="hljs-string">"input_ids"</span>][:,
          :-<span class="hljs-number">1</span>]

          </code></pre>

          <p>There is an on going effort to port <code>Kosmos-2</code> directly into
          <code>transformers</code>. This repository (remote code) might need some
          more bug fixes later, including some breaking changes.</p>

          '
        raw: 'Hello again! I made a small change, and it should be able to run with
          batch examples now.


          [Note!] The current code snippet (the `[:, :-1]` part below) won''t work
          with batch examples if there is padding happening! But in your case, there
          is no padding, so it''s fine.


          ```python

          inputs["input_ids"][:, :-1]

          ```


          There is an on going effort to port `Kosmos-2` directly into `transformers`.
          This repository (remote code) might need some more bug fixes later, including
          some breaking changes.'
        updatedAt: '2023-09-02T04:30:01.699Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - joelr23
    id: 64f1fd2f3674dd208d4932fd
    type: comment
  author: ydshieh
  content: 'Hello again! I made a small change, and it should be able to run with
    batch examples now.


    [Note!] The current code snippet (the `[:, :-1]` part below) won''t work with
    batch examples if there is padding happening! But in your case, there is no padding,
    so it''s fine.


    ```python

    inputs["input_ids"][:, :-1]

    ```


    There is an on going effort to port `Kosmos-2` directly into `transformers`. This
    repository (remote code) might need some more bug fixes later, including some
    breaking changes.'
  created_at: 2023-09-01 14:03:11+00:00
  edited: true
  hidden: false
  id: 64f1fd2f3674dd208d4932fd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ba0a759774f04ae915de4c94776eec7d.svg
      fullname: Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joelr23
      type: user
    createdAt: '2023-09-04T07:57:38.000Z'
    data:
      edited: true
      editors:
      - joelr23
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9148279428482056
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ba0a759774f04ae915de4c94776eec7d.svg
          fullname: Liu
          isHf: false
          isPro: false
          name: joelr23
          type: user
        html: '<blockquote>

          <p>Hello again! I made a small change, and it should be able to run with
          batch examples now.</p>

          <p>[Note!] The current code snippet (the <code>[:, :-1]</code> part below)
          won''t work with batch examples if there is padding happening! But in your
          case, there is no padding, so it''s fine.</p>

          <pre><code class="language-python">inputs[<span class="hljs-string">"input_ids"</span>][:,
          :-<span class="hljs-number">1</span>]

          </code></pre>

          <p>There is an on going effort to port <code>Kosmos-2</code> directly into
          <code>transformers</code>. This repository (remote code) might need some
          more bug fixes later, including some breaking changes.</p>

          </blockquote>

          <p>thanks for your respone! use <code>view</code> is work~!</p>

          '
        raw: "> Hello again! I made a small change, and it should be able to run with\
          \ batch examples now.\n> \n> [Note!] The current code snippet (the `[:,\
          \ :-1]` part below) won't work with batch examples if there is padding happening!\
          \ But in your case, there is no padding, so it's fine.\n> \n> ```python\n\
          > inputs[\"input_ids\"][:, :-1]\n> ```\n> \n> There is an on going effort\
          \ to port `Kosmos-2` directly into `transformers`. This repository (remote\
          \ code) might need some more bug fixes later, including some breaking changes.\n\
          \nthanks for your respone! use `view` is work~!"
        updatedAt: '2023-09-04T07:58:54.055Z'
      numEdits: 1
      reactions: []
      relatedEventId: 64f58df2c20615897cbaf453
    id: 64f58df2c20615897cbaf452
    type: comment
  author: joelr23
  content: "> Hello again! I made a small change, and it should be able to run with\
    \ batch examples now.\n> \n> [Note!] The current code snippet (the `[:, :-1]`\
    \ part below) won't work with batch examples if there is padding happening! But\
    \ in your case, there is no padding, so it's fine.\n> \n> ```python\n> inputs[\"\
    input_ids\"][:, :-1]\n> ```\n> \n> There is an on going effort to port `Kosmos-2`\
    \ directly into `transformers`. This repository (remote code) might need some\
    \ more bug fixes later, including some breaking changes.\n\nthanks for your respone!\
    \ use `view` is work~!"
  created_at: 2023-09-04 06:57:38+00:00
  edited: true
  hidden: false
  id: 64f58df2c20615897cbaf452
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/ba0a759774f04ae915de4c94776eec7d.svg
      fullname: Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joelr23
      type: user
    createdAt: '2023-09-04T07:57:38.000Z'
    data:
      status: closed
    id: 64f58df2c20615897cbaf453
    type: status-change
  author: joelr23
  created_at: 2023-09-04 06:57:38+00:00
  id: 64f58df2c20615897cbaf453
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/ba0a759774f04ae915de4c94776eec7d.svg
      fullname: Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joelr23
      type: user
    createdAt: '2023-09-04T07:57:54.000Z'
    data:
      status: open
    id: 64f58e028b6d053c709cd6fe
    type: status-change
  author: joelr23
  created_at: 2023-09-04 06:57:54+00:00
  id: 64f58e028b6d053c709cd6fe
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/ba0a759774f04ae915de4c94776eec7d.svg
      fullname: Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joelr23
      type: user
    createdAt: '2023-09-04T07:58:57.000Z'
    data:
      status: closed
    id: 64f58e41d08cbea260394a04
    type: status-change
  author: joelr23
  created_at: 2023-09-04 06:58:57+00:00
  id: 64f58e41d08cbea260394a04
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: ydshieh/kosmos-2-patch14-224
repo_type: model
status: closed
target_branch: null
title: batch image caption
