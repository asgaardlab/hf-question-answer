!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Ashwath-Shetty
conflicting_files: null
created_at: 2023-09-01 12:12:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b8425c02aea8d6b36b144cf834970fcf.svg
      fullname: Ashwath
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ashwath-Shetty
      type: user
    createdAt: '2023-09-01T13:12:32.000Z'
    data:
      edited: false
      editors:
      - Ashwath-Shetty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.35196176171302795
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b8425c02aea8d6b36b144cf834970fcf.svg
          fullname: Ashwath
          isHf: false
          isPro: false
          name: Ashwath-Shetty
          type: user
        html: "<p>i'm getting the below error: <span data-props=\"{&quot;user&quot;:&quot;ydshieh&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ydshieh\"\
          >@<span class=\"underline\">ydshieh</span></a></span>\n\n\t</span></span><br>\"\
          \ NameError: name 'Kosmos2Tokenizer' is not defined\"</p>\n<p>system specs:</p>\n\
          <ul>\n<li>OS: AWS Sagemaker(Amazon Linux 2, Jupyter Lab 3<br>(notebook-al2-v2))</li>\n\
          <li>Python: 3.10</li>\n<li>Transformers: 4.31.0</li>\n<li>PyTorch: 2.0.1</li>\n\
          <li>CUDA (<code>python -c 'import torch; print(torch.version.cuda)'</code>):\
          \ 11.8</li>\n</ul>\n<p>code:<br>import requests</p>\n<p>from PIL import\
          \ Image<br>from transformers import AutoProcessor, AutoModelForVision2Seq<br>model\
          \ = AutoModelForVision2Seq.from_pretrained(\"ydshieh/kosmos-2-patch14-224\"\
          , trust_remote_code=True)<br>processor = AutoProcessor.from_pretrained(\"\
          ydshieh/kosmos-2-patch14-224\", trust_remote_code=True)</p>\n<p>prompt =\
          \ \"An image of\"</p>\n<h1 id=\"url--httpshuggingfacecoydshiehkosmos-2-patch14-224resolvemainsnowmanpng\"\
          >url = \"<a href=\"https://huggingface.co/ydshieh/kosmos-2-patch14-224/resolve/main/snowman.png&quot;\"\
          >https://huggingface.co/ydshieh/kosmos-2-patch14-224/resolve/main/snowman.png\"\
          </a></h1>\n<p>image = Image.open(\"images/images_sample/f01-01-9780323479912.jpg\"\
          )</p>\n<h1 id=\"the-original-kosmos-2-demo-saves-the-image-first-then-reload-it-for-some-images-this-will-give-slightly-different-image-input-and-change-the-generation-outputs\"\
          >The original Kosmos-2 demo saves the image first then reload it. For some\
          \ images, this will give slightly different image input and change the generation\
          \ outputs.</h1>\n<h1 id=\"uncomment-the-following-2-lines-if-you-want-to-match-the-original-demos-outputs\"\
          >Uncomment the following 2 lines if you want to match the original demo's\
          \ outputs.</h1>\n<h1 id=\"one-example-is-the-two_dogsjpg-from-the-demo\"\
          >(One example is the <code>two_dogs.jpg</code> from the demo)</h1>\n<h1\
          \ id=\"imagesavenew_imagejpg\">image.save(\"new_image.jpg\")</h1>\n<h1 id=\"\
          image--imageopennew_imagejpg\">image = Image.open(\"new_image.jpg\")</h1>\n\
          <p>inputs = processor(text=prompt, images=image, return_tensors=\"pt\")</p>\n\
          <h2 id=\"output\">output:</h2>\n<p>NameError                           \
          \      Traceback (most recent call last)<br>Cell In[6], line 2<br>     \
          \ 1 model = AutoModelForVision2Seq.from_pretrained(\"ydshieh/kosmos-2-patch14-224\"\
          , trust_remote_code=True)<br>----&gt; 2 processor = AutoProcessor.from_pretrained(\"\
          ydshieh/kosmos-2-patch14-224\", trust_remote_code=True)<br>      4 prompt\
          \ = \"An image of\"<br>      6 # url = \"<a href=\"https://huggingface.co/ydshieh/kosmos-2-patch14-224/resolve/main/snowman.png&quot;\"\
          >https://huggingface.co/ydshieh/kosmos-2-patch14-224/resolve/main/snowman.png\"\
          </a></p>\n<p>File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py:269,\
          \ in AutoProcessor.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)<br>\
          \    267     if os.path.isdir(pretrained_model_name_or_path):<br>    268\
          \         processor_class.register_for_auto_class()<br>--&gt; 269     return\
          \ processor_class.from_pretrained(<br>    270         pretrained_model_name_or_path,\
          \ trust_remote_code=trust_remote_code, **kwargs<br>    271     )<br>   \
          \ 272 elif processor_class is not None:<br>    273     return processor_class.from_pretrained(<br>\
          \    274         pretrained_model_name_or_path, trust_remote_code=trust_remote_code,\
          \ **kwargs<br>    275     )</p>\n<p>File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/processing_utils.py:215,\
          \ in ProcessorMixin.from_pretrained(cls, pretrained_model_name_or_path,\
          \ cache_dir, force_download, local_files_only, token, revision, **kwargs)<br>\
          \    211 if token is not None:<br>    212     # change to <code>token</code>\
          \ in a follow-up PR<br>    213     kwargs[\"use_auth_token\"] = token<br>--&gt;\
          \ 215 args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs)<br>    216 return cls(*args)</p>\n<p>File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/processing_utils.py:259,\
          \ in ProcessorMixin._get_arguments_from_pretrained(cls, pretrained_model_name_or_path,\
          \ **kwargs)<br>    256     else:<br>    257         attribute_class = getattr(transformers_module,\
          \ class_name)<br>--&gt; 259     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs))<br>    260 return args</p>\n<p>File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:685,\
          \ in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs,\
          \ **kwargs)<br>    683 else:<br>    684     class_ref = tokenizer_auto_map[0]<br>--&gt;\
          \ 685 tokenizer_class = get_class_from_dynamic_module(class_ref, pretrained_model_name_or_path,\
          \ **kwargs)<br>    686 _ = kwargs.pop(\"code_revision\", None)<br>    687\
          \ if os.path.isdir(pretrained_model_name_or_path):</p>\n<p>File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/dynamic_module_utils.py:443,\
          \ in get_class_from_dynamic_module(class_reference, pretrained_model_name_or_path,\
          \ cache_dir, force_download, resume_download, proxies, use_auth_token, revision,\
          \ local_files_only, repo_type, code_revision, **kwargs)<br>    430 # And\
          \ lastly we get the class inside our newly created module<br>    431 final_module\
          \ = get_cached_module_file(<br>    432     repo_id,<br>    433     module_file\
          \ + \".py\",<br>   (...)<br>    441     repo_type=repo_type,<br>    442\
          \ )<br>--&gt; 443 return get_class_in_module(class_name, final_module.replace(\"\
          .py\", \"\"))</p>\n<p>File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/dynamic_module_utils.py:164,\
          \ in get_class_in_module(class_name, module_path)<br>    160 \"\"\"<br>\
          \    161 Import a module on the cache directory for modules and extract\
          \ a class from it.<br>    162 \"\"\"<br>    163 module_path = module_path.replace(os.path.sep,\
          \ \".\")<br>--&gt; 164 module = importlib.import_module(module_path)<br>\
          \    165 return getattr(module, class_name)</p>\n<p>File ~/anaconda3/envs/pytorch_p310/lib/python3.10/importlib/<strong>init</strong>.py:126,\
          \ in import_module(name, package)<br>    124             break<br>    125\
          \         level += 1<br>--&gt; 126 return _bootstrap._gcd_import(name[level:],\
          \ package, level)</p>\n<p>File :1050, in _gcd_import(name, package, level)</p>\n\
          <p>File :1027, in <em>find_and_load(name, import</em>)</p>\n<p>File :1006,\
          \ in <em>find_and_load_unlocked(name, import</em>)</p>\n<p>File :688, in\
          \ _load_unlocked(spec)</p>\n<p>File :883, in exec_module(self, module)</p>\n\
          <p>File :241, in _call_with_frames_removed(f, *args, **kwds)</p>\n<p>File\
          \ ~/.cache/huggingface/modules/transformers_modules/ydshieh/kosmos-2-patch14-224/b9379a4db0f6c911ad452fb7235256ddb1ae0cea/tokenization_kosmos2_fast.py:48<br>\
          \     37 PRETRAINED_VOCAB_FILES_MAP = {<br>     38     \"vocab_file\": {<br>\
          \     39         \"microsoft/kosmos-2-patch14-224\": \"<a href=\"https://huggingface.co/microsoft/kosmos-2-patch14-224/resolve/main/sentencepiece.bpe.model&quot;\"\
          >https://huggingface.co/microsoft/kosmos-2-patch14-224/resolve/main/sentencepiece.bpe.model\"\
          </a>,<br>     40     }<br>     41 }<br>     43 PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\
          \ = {<br>     44     \"microsoft/kosmos-2-patch14-224\": 2048,<br>     45\
          \ }<br>---&gt; 48 class Kosmos2TokenizerFast(PreTrainedTokenizerFast):<br>\
          \     49     \"\"\"<br>     50     Construct a \"fast\" KOSMOS-2 tokenizer\
          \ (backed by HuggingFace's <em>tokenizers</em> library). Adapted from<br>\
          \     51     [<code>RobertaTokenizer</code>] and [<code>XLNetTokenizer</code>].\
          \ Based on<br>   (...)<br>     99             format <code>&lt;patch_index_xxxx&gt;</code>\
          \ where <code>xxxx</code> is an integer.<br>    100     \"\"\"<br>    102\
          \     vocab_files_names = VOCAB_FILES_NAMES</p>\n<p>File ~/.cache/huggingface/modules/transformers_modules/ydshieh/kosmos-2-patch14-224/b9379a4db0f6c911ad452fb7235256ddb1ae0cea/tokenization_kosmos2_fast.py:106,\
          \ in Kosmos2TokenizerFast()<br>    104 max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES<br>\
          \    105 model_input_names = [\"input_ids\", \"attention_mask\"]<br>--&gt;\
          \ 106 slow_tokenizer_class = Kosmos2Tokenizer<br>    108 def <strong>init</strong>(<br>\
          \    109     self,<br>    110     vocab_file=None,<br>   (...)<br>    122\
          \ ):<br>    123     # Mask token behave like a normal word, i.e. include\
          \ the space before it<br>    124     mask_token = AddedToken(mask_token,\
          \ lstrip=True, rstrip=False) if isinstance(mask_token, str) else mask_token</p>\n\
          <p>NameError: name 'Kosmos2Tokenizer' is not defined</p>\n"
        raw: "i'm getting the below error: @ydshieh \r\n\" NameError: name 'Kosmos2Tokenizer'\
          \ is not defined\"\r\n\r\nsystem specs:\r\n- OS: AWS Sagemaker(Amazon Linux\
          \ 2, Jupyter Lab 3\r\n(notebook-al2-v2))\r\n- Python: 3.10\r\n- Transformers:\
          \ 4.31.0\r\n- PyTorch: 2.0.1\r\n- CUDA (`python -c 'import torch; print(torch.version.cuda)'`):\
          \ 11.8\r\n\r\ncode:\r\nimport requests\r\n\r\nfrom PIL import Image\r\n\
          from transformers import AutoProcessor, AutoModelForVision2Seq\r\nmodel\
          \ = AutoModelForVision2Seq.from_pretrained(\"ydshieh/kosmos-2-patch14-224\"\
          , trust_remote_code=True)\r\nprocessor = AutoProcessor.from_pretrained(\"\
          ydshieh/kosmos-2-patch14-224\", trust_remote_code=True)\r\n\r\nprompt =\
          \ \"<grounding>An image of\"\r\n\r\n# url = \"https://huggingface.co/ydshieh/kosmos-2-patch14-224/resolve/main/snowman.png\"\
          \r\nimage = Image.open(\"images/images_sample/f01-01-9780323479912.jpg\"\
          )\r\n\r\n# The original Kosmos-2 demo saves the image first then reload\
          \ it. For some images, this will give slightly different image input and\
          \ change the generation outputs.\r\n# Uncomment the following 2 lines if\
          \ you want to match the original demo's outputs.\r\n# (One example is the\
          \ `two_dogs.jpg` from the demo)\r\n# image.save(\"new_image.jpg\")\r\n#\
          \ image = Image.open(\"new_image.jpg\")\r\n\r\ninputs = processor(text=prompt,\
          \ images=image, return_tensors=\"pt\")\r\n\r\noutput:\r\n---------------------------------------------------------------------------\r\
          \nNameError                                 Traceback (most recent call\
          \ last)\r\nCell In[6], line 2\r\n      1 model = AutoModelForVision2Seq.from_pretrained(\"\
          ydshieh/kosmos-2-patch14-224\", trust_remote_code=True)\r\n----> 2 processor\
          \ = AutoProcessor.from_pretrained(\"ydshieh/kosmos-2-patch14-224\", trust_remote_code=True)\r\
          \n      4 prompt = \"<grounding>An image of\"\r\n      6 # url = \"https://huggingface.co/ydshieh/kosmos-2-patch14-224/resolve/main/snowman.png\"\
          \r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py:269,\
          \ in AutoProcessor.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\r\
          \n    267     if os.path.isdir(pretrained_model_name_or_path):\r\n    268\
          \         processor_class.register_for_auto_class()\r\n--> 269     return\
          \ processor_class.from_pretrained(\r\n    270         pretrained_model_name_or_path,\
          \ trust_remote_code=trust_remote_code, **kwargs\r\n    271     )\r\n   \
          \ 272 elif processor_class is not None:\r\n    273     return processor_class.from_pretrained(\r\
          \n    274         pretrained_model_name_or_path, trust_remote_code=trust_remote_code,\
          \ **kwargs\r\n    275     )\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/processing_utils.py:215,\
          \ in ProcessorMixin.from_pretrained(cls, pretrained_model_name_or_path,\
          \ cache_dir, force_download, local_files_only, token, revision, **kwargs)\r\
          \n    211 if token is not None:\r\n    212     # change to `token` in a\
          \ follow-up PR\r\n    213     kwargs[\"use_auth_token\"] = token\r\n-->\
          \ 215 args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs)\r\n    216 return cls(*args)\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/processing_utils.py:259,\
          \ in ProcessorMixin._get_arguments_from_pretrained(cls, pretrained_model_name_or_path,\
          \ **kwargs)\r\n    256     else:\r\n    257         attribute_class = getattr(transformers_module,\
          \ class_name)\r\n--> 259     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs))\r\n    260 return args\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:685,\
          \ in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs,\
          \ **kwargs)\r\n    683 else:\r\n    684     class_ref = tokenizer_auto_map[0]\r\
          \n--> 685 tokenizer_class = get_class_from_dynamic_module(class_ref, pretrained_model_name_or_path,\
          \ **kwargs)\r\n    686 _ = kwargs.pop(\"code_revision\", None)\r\n    687\
          \ if os.path.isdir(pretrained_model_name_or_path):\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/dynamic_module_utils.py:443,\
          \ in get_class_from_dynamic_module(class_reference, pretrained_model_name_or_path,\
          \ cache_dir, force_download, resume_download, proxies, use_auth_token, revision,\
          \ local_files_only, repo_type, code_revision, **kwargs)\r\n    430 # And\
          \ lastly we get the class inside our newly created module\r\n    431 final_module\
          \ = get_cached_module_file(\r\n    432     repo_id,\r\n    433     module_file\
          \ + \".py\",\r\n   (...)\r\n    441     repo_type=repo_type,\r\n    442\
          \ )\r\n--> 443 return get_class_in_module(class_name, final_module.replace(\"\
          .py\", \"\"))\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/dynamic_module_utils.py:164,\
          \ in get_class_in_module(class_name, module_path)\r\n    160 \"\"\"\r\n\
          \    161 Import a module on the cache directory for modules and extract\
          \ a class from it.\r\n    162 \"\"\"\r\n    163 module_path = module_path.replace(os.path.sep,\
          \ \".\")\r\n--> 164 module = importlib.import_module(module_path)\r\n  \
          \  165 return getattr(module, class_name)\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/importlib/__init__.py:126,\
          \ in import_module(name, package)\r\n    124             break\r\n    125\
          \         level += 1\r\n--> 126 return _bootstrap._gcd_import(name[level:],\
          \ package, level)\r\n\r\nFile <frozen importlib._bootstrap>:1050, in _gcd_import(name,\
          \ package, level)\r\n\r\nFile <frozen importlib._bootstrap>:1027, in _find_and_load(name,\
          \ import_)\r\n\r\nFile <frozen importlib._bootstrap>:1006, in _find_and_load_unlocked(name,\
          \ import_)\r\n\r\nFile <frozen importlib._bootstrap>:688, in _load_unlocked(spec)\r\
          \n\r\nFile <frozen importlib._bootstrap_external>:883, in exec_module(self,\
          \ module)\r\n\r\nFile <frozen importlib._bootstrap>:241, in _call_with_frames_removed(f,\
          \ *args, **kwds)\r\n\r\nFile ~/.cache/huggingface/modules/transformers_modules/ydshieh/kosmos-2-patch14-224/b9379a4db0f6c911ad452fb7235256ddb1ae0cea/tokenization_kosmos2_fast.py:48\r\
          \n     37 PRETRAINED_VOCAB_FILES_MAP = {\r\n     38     \"vocab_file\":\
          \ {\r\n     39         \"microsoft/kosmos-2-patch14-224\": \"https://huggingface.co/microsoft/kosmos-2-patch14-224/resolve/main/sentencepiece.bpe.model\"\
          ,\r\n     40     }\r\n     41 }\r\n     43 PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\
          \ = {\r\n     44     \"microsoft/kosmos-2-patch14-224\": 2048,\r\n     45\
          \ }\r\n---> 48 class Kosmos2TokenizerFast(PreTrainedTokenizerFast):\r\n\
          \     49     \"\"\"\r\n     50     Construct a \"fast\" KOSMOS-2 tokenizer\
          \ (backed by HuggingFace's *tokenizers* library). Adapted from\r\n     51\
          \     [`RobertaTokenizer`] and [`XLNetTokenizer`]. Based on\r\n   (...)\r\
          \n     99             format `<patch_index_xxxx>` where `xxxx` is an integer.\r\
          \n    100     \"\"\"\r\n    102     vocab_files_names = VOCAB_FILES_NAMES\r\
          \n\r\nFile ~/.cache/huggingface/modules/transformers_modules/ydshieh/kosmos-2-patch14-224/b9379a4db0f6c911ad452fb7235256ddb1ae0cea/tokenization_kosmos2_fast.py:106,\
          \ in Kosmos2TokenizerFast()\r\n    104 max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\r\
          \n    105 model_input_names = [\"input_ids\", \"attention_mask\"]\r\n-->\
          \ 106 slow_tokenizer_class = Kosmos2Tokenizer\r\n    108 def __init__(\r\
          \n    109     self,\r\n    110     vocab_file=None,\r\n   (...)\r\n    122\
          \ ):\r\n    123     # Mask token behave like a normal word, i.e. include\
          \ the space before it\r\n    124     mask_token = AddedToken(mask_token,\
          \ lstrip=True, rstrip=False) if isinstance(mask_token, str) else mask_token\r\
          \n\r\nNameError: name 'Kosmos2Tokenizer' is not defined\r\n\r\n\r\n"
        updatedAt: '2023-09-01T13:12:32.773Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - kengkreingkrai
    id: 64f1e340dd92641727447099
    type: comment
  author: Ashwath-Shetty
  content: "i'm getting the below error: @ydshieh \r\n\" NameError: name 'Kosmos2Tokenizer'\
    \ is not defined\"\r\n\r\nsystem specs:\r\n- OS: AWS Sagemaker(Amazon Linux 2,\
    \ Jupyter Lab 3\r\n(notebook-al2-v2))\r\n- Python: 3.10\r\n- Transformers: 4.31.0\r\
    \n- PyTorch: 2.0.1\r\n- CUDA (`python -c 'import torch; print(torch.version.cuda)'`):\
    \ 11.8\r\n\r\ncode:\r\nimport requests\r\n\r\nfrom PIL import Image\r\nfrom transformers\
    \ import AutoProcessor, AutoModelForVision2Seq\r\nmodel = AutoModelForVision2Seq.from_pretrained(\"\
    ydshieh/kosmos-2-patch14-224\", trust_remote_code=True)\r\nprocessor = AutoProcessor.from_pretrained(\"\
    ydshieh/kosmos-2-patch14-224\", trust_remote_code=True)\r\n\r\nprompt = \"<grounding>An\
    \ image of\"\r\n\r\n# url = \"https://huggingface.co/ydshieh/kosmos-2-patch14-224/resolve/main/snowman.png\"\
    \r\nimage = Image.open(\"images/images_sample/f01-01-9780323479912.jpg\")\r\n\r\
    \n# The original Kosmos-2 demo saves the image first then reload it. For some\
    \ images, this will give slightly different image input and change the generation\
    \ outputs.\r\n# Uncomment the following 2 lines if you want to match the original\
    \ demo's outputs.\r\n# (One example is the `two_dogs.jpg` from the demo)\r\n#\
    \ image.save(\"new_image.jpg\")\r\n# image = Image.open(\"new_image.jpg\")\r\n\
    \r\ninputs = processor(text=prompt, images=image, return_tensors=\"pt\")\r\n\r\
    \noutput:\r\n---------------------------------------------------------------------------\r\
    \nNameError                                 Traceback (most recent call last)\r\
    \nCell In[6], line 2\r\n      1 model = AutoModelForVision2Seq.from_pretrained(\"\
    ydshieh/kosmos-2-patch14-224\", trust_remote_code=True)\r\n----> 2 processor =\
    \ AutoProcessor.from_pretrained(\"ydshieh/kosmos-2-patch14-224\", trust_remote_code=True)\r\
    \n      4 prompt = \"<grounding>An image of\"\r\n      6 # url = \"https://huggingface.co/ydshieh/kosmos-2-patch14-224/resolve/main/snowman.png\"\
    \r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py:269,\
    \ in AutoProcessor.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\r\
    \n    267     if os.path.isdir(pretrained_model_name_or_path):\r\n    268    \
    \     processor_class.register_for_auto_class()\r\n--> 269     return processor_class.from_pretrained(\r\
    \n    270         pretrained_model_name_or_path, trust_remote_code=trust_remote_code,\
    \ **kwargs\r\n    271     )\r\n    272 elif processor_class is not None:\r\n \
    \   273     return processor_class.from_pretrained(\r\n    274         pretrained_model_name_or_path,\
    \ trust_remote_code=trust_remote_code, **kwargs\r\n    275     )\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/processing_utils.py:215,\
    \ in ProcessorMixin.from_pretrained(cls, pretrained_model_name_or_path, cache_dir,\
    \ force_download, local_files_only, token, revision, **kwargs)\r\n    211 if token\
    \ is not None:\r\n    212     # change to `token` in a follow-up PR\r\n    213\
    \     kwargs[\"use_auth_token\"] = token\r\n--> 215 args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path,\
    \ **kwargs)\r\n    216 return cls(*args)\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/processing_utils.py:259,\
    \ in ProcessorMixin._get_arguments_from_pretrained(cls, pretrained_model_name_or_path,\
    \ **kwargs)\r\n    256     else:\r\n    257         attribute_class = getattr(transformers_module,\
    \ class_name)\r\n--> 259     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path,\
    \ **kwargs))\r\n    260 return args\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:685,\
    \ in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs,\
    \ **kwargs)\r\n    683 else:\r\n    684     class_ref = tokenizer_auto_map[0]\r\
    \n--> 685 tokenizer_class = get_class_from_dynamic_module(class_ref, pretrained_model_name_or_path,\
    \ **kwargs)\r\n    686 _ = kwargs.pop(\"code_revision\", None)\r\n    687 if os.path.isdir(pretrained_model_name_or_path):\r\
    \n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/dynamic_module_utils.py:443,\
    \ in get_class_from_dynamic_module(class_reference, pretrained_model_name_or_path,\
    \ cache_dir, force_download, resume_download, proxies, use_auth_token, revision,\
    \ local_files_only, repo_type, code_revision, **kwargs)\r\n    430 # And lastly\
    \ we get the class inside our newly created module\r\n    431 final_module = get_cached_module_file(\r\
    \n    432     repo_id,\r\n    433     module_file + \".py\",\r\n   (...)\r\n \
    \   441     repo_type=repo_type,\r\n    442 )\r\n--> 443 return get_class_in_module(class_name,\
    \ final_module.replace(\".py\", \"\"))\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/dynamic_module_utils.py:164,\
    \ in get_class_in_module(class_name, module_path)\r\n    160 \"\"\"\r\n    161\
    \ Import a module on the cache directory for modules and extract a class from\
    \ it.\r\n    162 \"\"\"\r\n    163 module_path = module_path.replace(os.path.sep,\
    \ \".\")\r\n--> 164 module = importlib.import_module(module_path)\r\n    165 return\
    \ getattr(module, class_name)\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/importlib/__init__.py:126,\
    \ in import_module(name, package)\r\n    124             break\r\n    125    \
    \     level += 1\r\n--> 126 return _bootstrap._gcd_import(name[level:], package,\
    \ level)\r\n\r\nFile <frozen importlib._bootstrap>:1050, in _gcd_import(name,\
    \ package, level)\r\n\r\nFile <frozen importlib._bootstrap>:1027, in _find_and_load(name,\
    \ import_)\r\n\r\nFile <frozen importlib._bootstrap>:1006, in _find_and_load_unlocked(name,\
    \ import_)\r\n\r\nFile <frozen importlib._bootstrap>:688, in _load_unlocked(spec)\r\
    \n\r\nFile <frozen importlib._bootstrap_external>:883, in exec_module(self, module)\r\
    \n\r\nFile <frozen importlib._bootstrap>:241, in _call_with_frames_removed(f,\
    \ *args, **kwds)\r\n\r\nFile ~/.cache/huggingface/modules/transformers_modules/ydshieh/kosmos-2-patch14-224/b9379a4db0f6c911ad452fb7235256ddb1ae0cea/tokenization_kosmos2_fast.py:48\r\
    \n     37 PRETRAINED_VOCAB_FILES_MAP = {\r\n     38     \"vocab_file\": {\r\n\
    \     39         \"microsoft/kosmos-2-patch14-224\": \"https://huggingface.co/microsoft/kosmos-2-patch14-224/resolve/main/sentencepiece.bpe.model\"\
    ,\r\n     40     }\r\n     41 }\r\n     43 PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\
    \ = {\r\n     44     \"microsoft/kosmos-2-patch14-224\": 2048,\r\n     45 }\r\n\
    ---> 48 class Kosmos2TokenizerFast(PreTrainedTokenizerFast):\r\n     49     \"\
    \"\"\r\n     50     Construct a \"fast\" KOSMOS-2 tokenizer (backed by HuggingFace's\
    \ *tokenizers* library). Adapted from\r\n     51     [`RobertaTokenizer`] and\
    \ [`XLNetTokenizer`]. Based on\r\n   (...)\r\n     99             format `<patch_index_xxxx>`\
    \ where `xxxx` is an integer.\r\n    100     \"\"\"\r\n    102     vocab_files_names\
    \ = VOCAB_FILES_NAMES\r\n\r\nFile ~/.cache/huggingface/modules/transformers_modules/ydshieh/kosmos-2-patch14-224/b9379a4db0f6c911ad452fb7235256ddb1ae0cea/tokenization_kosmos2_fast.py:106,\
    \ in Kosmos2TokenizerFast()\r\n    104 max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\r\
    \n    105 model_input_names = [\"input_ids\", \"attention_mask\"]\r\n--> 106 slow_tokenizer_class\
    \ = Kosmos2Tokenizer\r\n    108 def __init__(\r\n    109     self,\r\n    110\
    \     vocab_file=None,\r\n   (...)\r\n    122 ):\r\n    123     # Mask token behave\
    \ like a normal word, i.e. include the space before it\r\n    124     mask_token\
    \ = AddedToken(mask_token, lstrip=True, rstrip=False) if isinstance(mask_token,\
    \ str) else mask_token\r\n\r\nNameError: name 'Kosmos2Tokenizer' is not defined\r\
    \n\r\n\r\n"
  created_at: 2023-09-01 12:12:32+00:00
  edited: false
  hidden: false
  id: 64f1e340dd92641727447099
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
      fullname: Yih-Dar SHIEH
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ydshieh
      type: user
    createdAt: '2023-09-01T13:53:30.000Z'
    data:
      edited: false
      editors:
      - ydshieh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9210837483406067
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
          fullname: Yih-Dar SHIEH
          isHf: true
          isPro: false
          name: ydshieh
          type: user
        html: '<p>Hi,</p>

          <p>Do you have <code>sentencepiece</code> installed?</p>

          '
        raw: 'Hi,


          Do you have `sentencepiece` installed?'
        updatedAt: '2023-09-01T13:53:30.373Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - kengkreingkrai
    id: 64f1ecdab270f2fd4d90949d
    type: comment
  author: ydshieh
  content: 'Hi,


    Do you have `sentencepiece` installed?'
  created_at: 2023-09-01 12:53:30+00:00
  edited: false
  hidden: false
  id: 64f1ecdab270f2fd4d90949d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b8425c02aea8d6b36b144cf834970fcf.svg
      fullname: Ashwath
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ashwath-Shetty
      type: user
    createdAt: '2023-09-01T16:03:24.000Z'
    data:
      edited: false
      editors:
      - Ashwath-Shetty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9286673069000244
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b8425c02aea8d6b36b144cf834970fcf.svg
          fullname: Ashwath
          isHf: false
          isPro: false
          name: Ashwath-Shetty
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;ydshieh&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ydshieh\"\
          >@<span class=\"underline\">ydshieh</span></a></span>\n\n\t</span></span>\
          \ , that solved the issue. just an advice, may be it's a good idea to add\
          \ this to the tutorial.<br>thank you for your great work.</p>\n<p>i have\
          \ a couple of questions, i hope you don't mind.</p>\n<ol>\n<li>model is\
          \ giving very brief output. i want to get the detailed output which describes\
          \ the image(atleast 300 words). how can i achieve that?</li>\n<li>where\
          \ can i find the  list of model parameter to tune? &amp; also any tool/framework\
          \ to tune?</li>\n<li>can we finetune/train this on our own data? if yes,\
          \ how?</li>\n<li>can we do few shot prompting? if yes, how?<br>i know these\
          \ are lot of question, thanks in advance.</li>\n</ol>\n"
        raw: 'Thanks @ydshieh , that solved the issue. just an advice, may be it''s
          a good idea to add this to the tutorial.

          thank you for your great work.


          i have a couple of questions, i hope you don''t mind.

          1.  model is giving very brief output. i want to get the detailed output
          which describes the image(atleast 300 words). how can i achieve that?

          2. where can i find the  list of model parameter to tune? & also any tool/framework
          to tune?

          3. can we finetune/train this on our own data? if yes, how?

          4. can we do few shot prompting? if yes, how?

          i know these are lot of question, thanks in advance.'
        updatedAt: '2023-09-01T16:03:24.707Z'
      numEdits: 0
      reactions: []
    id: 64f20b4c3b8c02dd76b7f8e9
    type: comment
  author: Ashwath-Shetty
  content: 'Thanks @ydshieh , that solved the issue. just an advice, may be it''s
    a good idea to add this to the tutorial.

    thank you for your great work.


    i have a couple of questions, i hope you don''t mind.

    1.  model is giving very brief output. i want to get the detailed output which
    describes the image(atleast 300 words). how can i achieve that?

    2. where can i find the  list of model parameter to tune? & also any tool/framework
    to tune?

    3. can we finetune/train this on our own data? if yes, how?

    4. can we do few shot prompting? if yes, how?

    i know these are lot of question, thanks in advance.'
  created_at: 2023-09-01 15:03:24+00:00
  edited: false
  hidden: false
  id: 64f20b4c3b8c02dd76b7f8e9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
      fullname: Yih-Dar SHIEH
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ydshieh
      type: user
    createdAt: '2023-09-01T21:31:22.000Z'
    data:
      edited: true
      editors:
      - ydshieh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8837330937385559
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
          fullname: Yih-Dar SHIEH
          isHf: true
          isPro: false
          name: ydshieh
          type: user
        html: '<blockquote>

          <p>model is giving very brief output. i want to get the detailed output
          which describes the image(atleast 300 words). how can i achieve that?</p>

          </blockquote>

          <p>You can use <code>&lt;grounding&gt;Describe this image in detail:</code>
          as the prompt.</p>

          <blockquote>

          <p>where can i find the list of model parameter to tune? &amp; also any
          tool/framework to tune?</p>

          </blockquote>

          <p>It''s up to you to decide which parameters to tune. The original training
          trained the whole set of trainable parameters.</p>

          <blockquote>

          <p>can we finetune/train this on our own data? if yes, how?</p>

          </blockquote>

          <p>The original repository contains information about the used dataset:
          <a rel="nofollow" href="https://github.com/microsoft/unilm/tree/master/kosmos-2">https://github.com/microsoft/unilm/tree/master/kosmos-2</a><br>I
          haven''t tried (yet) anything related to training and the original datasets.</p>

          <blockquote>

          <p>can we do few shot prompting? if yes, how?</p>

          </blockquote>

          <p>It is, see the page 9 in their paper (you can find the link to it from
          the above line).<br>However, the current implementation done by me doesn''t
          allow  preparing easily  such input format.</p>

          '
        raw: '> model is giving very brief output. i want to get the detailed output
          which describes the image(atleast 300 words). how can i achieve that?


          You can use `<grounding>Describe this image in detail:` as the prompt.


          > where can i find the list of model parameter to tune? & also any tool/framework
          to tune?


          It''s up to you to decide which parameters to tune. The original training
          trained the whole set of trainable parameters.


          > can we finetune/train this on our own data? if yes, how?


          The original repository contains information about the used dataset: https://github.com/microsoft/unilm/tree/master/kosmos-2

          I haven''t tried (yet) anything related to training and the original datasets.


          > can we do few shot prompting? if yes, how?


          It is, see the page 9 in their paper (you can find the link to it from the
          above line).

          However, the current implementation done by me doesn''t allow  preparing
          easily  such input format.

          '
        updatedAt: '2023-09-01T21:31:39.378Z'
      numEdits: 1
      reactions: []
      relatedEventId: 64f2582a59505ae68cedcfff
    id: 64f2582a59505ae68cedcffd
    type: comment
  author: ydshieh
  content: '> model is giving very brief output. i want to get the detailed output
    which describes the image(atleast 300 words). how can i achieve that?


    You can use `<grounding>Describe this image in detail:` as the prompt.


    > where can i find the list of model parameter to tune? & also any tool/framework
    to tune?


    It''s up to you to decide which parameters to tune. The original training trained
    the whole set of trainable parameters.


    > can we finetune/train this on our own data? if yes, how?


    The original repository contains information about the used dataset: https://github.com/microsoft/unilm/tree/master/kosmos-2

    I haven''t tried (yet) anything related to training and the original datasets.


    > can we do few shot prompting? if yes, how?


    It is, see the page 9 in their paper (you can find the link to it from the above
    line).

    However, the current implementation done by me doesn''t allow  preparing easily  such
    input format.

    '
  created_at: 2023-09-01 20:31:22+00:00
  edited: true
  hidden: false
  id: 64f2582a59505ae68cedcffd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
      fullname: Yih-Dar SHIEH
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ydshieh
      type: user
    createdAt: '2023-09-01T21:31:22.000Z'
    data:
      status: closed
    id: 64f2582a59505ae68cedcfff
    type: status-change
  author: ydshieh
  created_at: 2023-09-01 20:31:22+00:00
  id: 64f2582a59505ae68cedcfff
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b8425c02aea8d6b36b144cf834970fcf.svg
      fullname: Ashwath
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ashwath-Shetty
      type: user
    createdAt: '2023-09-04T07:26:51.000Z'
    data:
      edited: false
      editors:
      - Ashwath-Shetty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8650076389312744
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b8425c02aea8d6b36b144cf834970fcf.svg
          fullname: Ashwath
          isHf: false
          isPro: false
          name: Ashwath-Shetty
          type: user
        html: "<p>thank you <span data-props=\"{&quot;user&quot;:&quot;ydshieh&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ydshieh\"\
          >@<span class=\"underline\">ydshieh</span></a></span>\n\n\t</span></span>\
          \ for patiently answering all the questions.<br>i'm still getting the same\
          \ result though for \"Describe this image in detail:\". output length is\
          \ less than 100 words.</p>\n"
        raw: 'thank you @ydshieh for patiently answering all the questions.

          i''m still getting the same result though for "<grounding>Describe this
          image in detail:". output length is less than 100 words.'
        updatedAt: '2023-09-04T07:26:51.054Z'
      numEdits: 0
      reactions: []
    id: 64f586bb6e33521713191001
    type: comment
  author: Ashwath-Shetty
  content: 'thank you @ydshieh for patiently answering all the questions.

    i''m still getting the same result though for "<grounding>Describe this image
    in detail:". output length is less than 100 words.'
  created_at: 2023-09-04 06:26:51+00:00
  edited: false
  hidden: false
  id: 64f586bb6e33521713191001
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
      fullname: Yih-Dar SHIEH
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ydshieh
      type: user
    createdAt: '2023-09-04T07:32:18.000Z'
    data:
      edited: false
      editors:
      - ydshieh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8994803428649902
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
          fullname: Yih-Dar SHIEH
          isHf: true
          isPro: false
          name: ydshieh
          type: user
        html: '<p>You can try to add <code>min_new_tokens=XXX</code> (with a value
          you prefer) and/or change <code>max_new_tokens=64</code> to something higher
          in the <code>model.generate()</code> call.<br>If the generation is still
          short (or long enough but with lower quality), it means the model is not
          really trained with long (enough) text desriptions.</p>

          '
        raw: 'You can try to add `min_new_tokens=XXX` (with a value you prefer) and/or
          change `max_new_tokens=64` to something higher in the `model.generate()`
          call.

          If the generation is still short (or long enough but with lower quality),
          it means the model is not really trained with long (enough) text desriptions.'
        updatedAt: '2023-09-04T07:32:18.145Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Ashwath-Shetty
    id: 64f58802984e32bf9b7893a5
    type: comment
  author: ydshieh
  content: 'You can try to add `min_new_tokens=XXX` (with a value you prefer) and/or
    change `max_new_tokens=64` to something higher in the `model.generate()` call.

    If the generation is still short (or long enough but with lower quality), it means
    the model is not really trained with long (enough) text desriptions.'
  created_at: 2023-09-04 06:32:18+00:00
  edited: false
  hidden: false
  id: 64f58802984e32bf9b7893a5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b8425c02aea8d6b36b144cf834970fcf.svg
      fullname: Ashwath
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ashwath-Shetty
      type: user
    createdAt: '2023-09-05T04:28:14.000Z'
    data:
      edited: false
      editors:
      - Ashwath-Shetty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4956127405166626
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b8425c02aea8d6b36b144cf834970fcf.svg
          fullname: Ashwath
          isHf: false
          isPro: false
          name: Ashwath-Shetty
          type: user
        html: "<p>ok, thanks <span data-props=\"{&quot;user&quot;:&quot;ydshieh&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ydshieh\"\
          >@<span class=\"underline\">ydshieh</span></a></span>\n\n\t</span></span>\
          \ </p>\n"
        raw: 'ok, thanks @ydshieh '
        updatedAt: '2023-09-05T04:28:14.414Z'
      numEdits: 0
      reactions: []
    id: 64f6ae5ee99f96c87cda44af
    type: comment
  author: Ashwath-Shetty
  content: 'ok, thanks @ydshieh '
  created_at: 2023-09-05 03:28:14+00:00
  edited: false
  hidden: false
  id: 64f6ae5ee99f96c87cda44af
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8f2dc93e206a2dad7dd29ab0454cc3f5.svg
      fullname: Kreingkrai Luangchaipreeda
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kengkreingkrai
      type: user
    createdAt: '2023-09-13T08:11:16.000Z'
    data:
      edited: false
      editors:
      - kengkreingkrai
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8926049470901489
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8f2dc93e206a2dad7dd29ab0454cc3f5.svg
          fullname: Kreingkrai Luangchaipreeda
          isHf: false
          isPro: false
          name: kengkreingkrai
          type: user
        html: '<blockquote>

          <p>Hi,</p>

          <p>Do you have <code>sentencepiece</code> installed?</p>

          </blockquote>

          <p>Thanks</p>

          '
        raw: "> Hi,\n> \n> Do you have `sentencepiece` installed?\n\nThanks"
        updatedAt: '2023-09-13T08:11:16.929Z'
      numEdits: 0
      reactions: []
    id: 65016ea4af1e402143a79be5
    type: comment
  author: kengkreingkrai
  content: "> Hi,\n> \n> Do you have `sentencepiece` installed?\n\nThanks"
  created_at: 2023-09-13 07:11:16+00:00
  edited: false
  hidden: false
  id: 65016ea4af1e402143a79be5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2dac8eeb72faa0a082dfd3b7e140e635.svg
      fullname: Claudiu Daniel Hromei
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cdh
      type: user
    createdAt: '2024-01-09T16:09:15.000Z'
    data:
      edited: false
      editors:
      - cdh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8924583792686462
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2dac8eeb72faa0a082dfd3b7e140e635.svg
          fullname: Claudiu Daniel Hromei
          isHf: false
          isPro: false
          name: cdh
          type: user
        html: '<p>Hello, I am interested too in fine-tuning this model on my downstream
          task data. Any news about it?</p>

          '
        raw: Hello, I am interested too in fine-tuning this model on my downstream
          task data. Any news about it?
        updatedAt: '2024-01-09T16:09:15.838Z'
      numEdits: 0
      reactions: []
    id: 659d6fab514472f673ba883a
    type: comment
  author: cdh
  content: Hello, I am interested too in fine-tuning this model on my downstream task
    data. Any news about it?
  created_at: 2024-01-09 16:09:15+00:00
  edited: false
  hidden: false
  id: 659d6fab514472f673ba883a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: ydshieh/kosmos-2-patch14-224
repo_type: model
status: closed
target_branch: null
title: 'NameError: name ''Kosmos2Tokenizer'' is not defined'
