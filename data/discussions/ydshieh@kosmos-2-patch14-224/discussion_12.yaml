!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Kernel
conflicting_files: null
created_at: 2023-09-02 06:42:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/624ae13993d46cf4a0928032/kaIXTCGMbkuxuT59p0NAO.jpeg?w=200&h=200&f=face
      fullname: Panic
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kernel
      type: user
    createdAt: '2023-09-02T07:42:25.000Z'
    data:
      edited: true
      editors:
      - Kernel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8268218040466309
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/624ae13993d46cf4a0928032/kaIXTCGMbkuxuT59p0NAO.jpeg?w=200&h=200&f=face
          fullname: Panic
          isHf: false
          isPro: false
          name: Kernel
          type: user
        html: '<p>Is there any possible way to get 8bit quantization? BTW what is
          the model size? 7B? Cant find this information</p>

          '
        raw: Is there any possible way to get 8bit quantization? BTW what is the model
          size? 7B? Cant find this information
        updatedAt: '2023-09-02T07:56:53.439Z'
      numEdits: 1
      reactions: []
    id: 64f2e7613e9d80250d158693
    type: comment
  author: Kernel
  content: Is there any possible way to get 8bit quantization? BTW what is the model
    size? 7B? Cant find this information
  created_at: 2023-09-02 06:42:25+00:00
  edited: true
  hidden: false
  id: 64f2e7613e9d80250d158693
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
      fullname: Yih-Dar SHIEH
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ydshieh
      type: user
    createdAt: '2023-09-02T09:01:35.000Z'
    data:
      edited: false
      editors:
      - ydshieh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9577650427818298
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
          fullname: Yih-Dar SHIEH
          isHf: true
          isPro: false
          name: ydshieh
          type: user
        html: '<p>Hi,</p>

          <p>There is an on going effort to port Kosmos-2 directly into transformers.
          This repository (remote code) might need some more bug fixes later, including
          breaking changes.<br>I would suggest to wait for the official support (where
          I will try to make it work with <code>quantization</code>,  but I can''t
          100% guarantee at this moment)</p>

          <p>Regarding the model size, the paper says <code>The total number of trainable
          parameters amounts to approximately 1.6B</code>, but I didn''t check it
          myself. The model file (pytorch bin file) is 6.6 GB however.</p>

          '
        raw: 'Hi,


          There is an on going effort to port Kosmos-2 directly into transformers.
          This repository (remote code) might need some more bug fixes later, including
          breaking changes.

          I would suggest to wait for the official support (where I will try to make
          it work with `quantization`,  but I can''t 100% guarantee at this moment)


          Regarding the model size, the paper says `The total number of trainable
          parameters amounts to approximately 1.6B`, but I didn''t check it myself.
          The model file (pytorch bin file) is 6.6 GB however.


          '
        updatedAt: '2023-09-02T09:01:35.611Z'
      numEdits: 0
      reactions: []
    id: 64f2f9eff1b6c235aee0e752
    type: comment
  author: ydshieh
  content: 'Hi,


    There is an on going effort to port Kosmos-2 directly into transformers. This
    repository (remote code) might need some more bug fixes later, including breaking
    changes.

    I would suggest to wait for the official support (where I will try to make it
    work with `quantization`,  but I can''t 100% guarantee at this moment)


    Regarding the model size, the paper says `The total number of trainable parameters
    amounts to approximately 1.6B`, but I didn''t check it myself. The model file
    (pytorch bin file) is 6.6 GB however.


    '
  created_at: 2023-09-02 08:01:35+00:00
  edited: false
  hidden: false
  id: 64f2f9eff1b6c235aee0e752
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
      fullname: Yih-Dar SHIEH
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ydshieh
      type: user
    createdAt: '2023-09-04T19:31:45.000Z'
    data:
      edited: false
      editors:
      - ydshieh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.944979727268219
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
          fullname: Yih-Dar SHIEH
          isHf: true
          isPro: false
          name: ydshieh
          type: user
        html: '<p>close this issue. Feel free to open once an official port is merged
          into <code>transformers</code>. Thank you.</p>

          '
        raw: close this issue. Feel free to open once an official port is merged into
          `transformers`. Thank you.
        updatedAt: '2023-09-04T19:31:45.663Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64f630a1d63b958c5213d835
    id: 64f630a1d63b958c5213d833
    type: comment
  author: ydshieh
  content: close this issue. Feel free to open once an official port is merged into
    `transformers`. Thank you.
  created_at: 2023-09-04 18:31:45+00:00
  edited: false
  hidden: false
  id: 64f630a1d63b958c5213d833
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
      fullname: Yih-Dar SHIEH
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ydshieh
      type: user
    createdAt: '2023-09-04T19:31:45.000Z'
    data:
      status: closed
    id: 64f630a1d63b958c5213d835
    type: status-change
  author: ydshieh
  created_at: 2023-09-04 18:31:45+00:00
  id: 64f630a1d63b958c5213d835
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: ydshieh/kosmos-2-patch14-224
repo_type: model
status: closed
target_branch: null
title: Quantization support
