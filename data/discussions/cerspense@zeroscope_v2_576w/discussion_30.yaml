!!python/object:huggingface_hub.community.DiscussionWithDetails
author: CosmoAI
conflicting_files: null
created_at: 2023-09-27 17:13:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/fw_VG4lnoepCgD0pOu5SM.jpeg?w=200&h=200&f=face
      fullname: Sachin Verma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CosmoAI
      type: user
    createdAt: '2023-09-27T18:13:01.000Z'
    data:
      edited: true
      editors:
      - CosmoAI
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8847305774688721
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/fw_VG4lnoepCgD0pOu5SM.jpeg?w=200&h=200&f=face
          fullname: Sachin Verma
          isHf: false
          isPro: false
          name: CosmoAI
          type: user
        html: '<p>after downloading video from google colab, the video is just a green
          screen. I used the same prompt as in example</p>

          '
        raw: after downloading video from google colab, the video is just a green
          screen. I used the same prompt as in example
        updatedAt: '2023-09-27T18:23:16.321Z'
      numEdits: 1
      reactions: []
    id: 651470ad18477eab4e6366a1
    type: comment
  author: CosmoAI
  content: after downloading video from google colab, the video is just a green screen.
    I used the same prompt as in example
  created_at: 2023-09-27 17:13:01+00:00
  edited: true
  hidden: false
  id: 651470ad18477eab4e6366a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/fw_VG4lnoepCgD0pOu5SM.jpeg?w=200&h=200&f=face
      fullname: Sachin Verma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CosmoAI
      type: user
    createdAt: '2023-09-27T18:22:37.000Z'
    data:
      from: How to view the video created in google colab?
      to: The video created is just a green screen
    id: 651472ed7cbb6ee93cce36eb
    type: title-change
  author: CosmoAI
  created_at: 2023-09-27 17:22:37+00:00
  id: 651472ed7cbb6ee93cce36eb
  new_title: The video created is just a green screen
  old_title: How to view the video created in google colab?
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/255bfd2de4d130fdc34d3dbe8274b54c.svg
      fullname: niumeng07
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: niumeng07
      type: user
    createdAt: '2023-09-28T03:08:52.000Z'
    data:
      edited: false
      editors:
      - niumeng07
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9941230416297913
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/255bfd2de4d130fdc34d3dbe8274b54c.svg
          fullname: niumeng07
          isHf: false
          isPro: false
          name: niumeng07
          type: user
        html: '<p>I have the same problem, have you solved it?</p>

          '
        raw: I have the same problem, have you solved it?
        updatedAt: '2023-09-28T03:08:52.875Z'
      numEdits: 0
      reactions: []
    id: 6514ee447f714cc391def796
    type: comment
  author: niumeng07
  content: I have the same problem, have you solved it?
  created_at: 2023-09-28 02:08:52+00:00
  edited: false
  hidden: false
  id: 6514ee447f714cc391def796
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/fw_VG4lnoepCgD0pOu5SM.jpeg?w=200&h=200&f=face
      fullname: Sachin Verma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CosmoAI
      type: user
    createdAt: '2023-09-28T06:22:02.000Z'
    data:
      edited: false
      editors:
      - CosmoAI
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.989542543888092
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/fw_VG4lnoepCgD0pOu5SM.jpeg?w=200&h=200&f=face
          fullname: Sachin Verma
          isHf: false
          isPro: false
          name: CosmoAI
          type: user
        html: '<blockquote>

          <p>I have the same problem, have you solved it?</p>

          </blockquote>

          <p>I have no idea how to fix this, need help.</p>

          '
        raw: '> I have the same problem, have you solved it?


          I have no idea how to fix this, need help.'
        updatedAt: '2023-09-28T06:22:02.275Z'
      numEdits: 0
      reactions: []
    id: 65151b8a391bec2898b92f7e
    type: comment
  author: CosmoAI
  content: '> I have the same problem, have you solved it?


    I have no idea how to fix this, need help.'
  created_at: 2023-09-28 05:22:02+00:00
  edited: false
  hidden: false
  id: 65151b8a391bec2898b92f7e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b9b298416803cb236f1b3f544584d9d3.svg
      fullname: Raphael Rozenblum
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rr694
      type: user
    createdAt: '2023-09-29T17:06:00.000Z'
    data:
      edited: false
      editors:
      - rr694
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6622389554977417
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b9b298416803cb236f1b3f544584d9d3.svg
          fullname: Raphael Rozenblum
          isHf: false
          isPro: false
          name: rr694
          type: user
        html: "<p>Replace export to video with this:</p>\n<pre><code>def export_to_video(video_frames,\
          \ output_video_path):\n    # Get the dimensions of the first frame to set\
          \ the dimensions of the video\n    first_frame = video_frames[0]\n    h,\
          \ w, layers = first_frame.shape\n    fps = 24  # frames per second\n   \
          \ \n    # Create a video writer object\n    with imageio.get_writer(output_video_path,\
          \ fps=fps) as writer:\n        for frame in video_frames:\n            #\
          \ Convert the numpy array to a PIL Image\n            #pil_img = Image.fromarray(frame)\n\
          \            # Append the image to the video\n            writer.append_data(frame)#np.array(pil_img))\n\
          </code></pre>\n"
        raw: "Replace export to video with this:\n\n```\ndef export_to_video(video_frames,\
          \ output_video_path):\n    # Get the dimensions of the first frame to set\
          \ the dimensions of the video\n    first_frame = video_frames[0]\n    h,\
          \ w, layers = first_frame.shape\n    fps = 24  # frames per second\n   \
          \ \n    # Create a video writer object\n    with imageio.get_writer(output_video_path,\
          \ fps=fps) as writer:\n        for frame in video_frames:\n            #\
          \ Convert the numpy array to a PIL Image\n            #pil_img = Image.fromarray(frame)\n\
          \            # Append the image to the video\n            writer.append_data(frame)#np.array(pil_img))\n\
          ```"
        updatedAt: '2023-09-29T17:06:00.360Z'
      numEdits: 0
      reactions: []
    id: 651703f8db386e10221162d3
    type: comment
  author: rr694
  content: "Replace export to video with this:\n\n```\ndef export_to_video(video_frames,\
    \ output_video_path):\n    # Get the dimensions of the first frame to set the\
    \ dimensions of the video\n    first_frame = video_frames[0]\n    h, w, layers\
    \ = first_frame.shape\n    fps = 24  # frames per second\n    \n    # Create a\
    \ video writer object\n    with imageio.get_writer(output_video_path, fps=fps)\
    \ as writer:\n        for frame in video_frames:\n            # Convert the numpy\
    \ array to a PIL Image\n            #pil_img = Image.fromarray(frame)\n      \
    \      # Append the image to the video\n            writer.append_data(frame)#np.array(pil_img))\n\
    ```"
  created_at: 2023-09-29 16:06:00+00:00
  edited: false
  hidden: false
  id: 651703f8db386e10221162d3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/fw_VG4lnoepCgD0pOu5SM.jpeg?w=200&h=200&f=face
      fullname: Sachin Verma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CosmoAI
      type: user
    createdAt: '2023-09-30T04:19:18.000Z'
    data:
      edited: false
      editors:
      - CosmoAI
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5381759405136108
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/fw_VG4lnoepCgD0pOu5SM.jpeg?w=200&h=200&f=face
          fullname: Sachin Verma
          isHf: false
          isPro: false
          name: CosmoAI
          type: user
        html: "<p>I tried with the code provided but got this error:</p>\n<p>import\
          \ torch<br>from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler<br>import\
          \ imageio</p>\n<h1 id=\"from-diffusersutils-import-export_to_video\">from\
          \ diffusers.utils import export_to_video</h1>\n<p>def export_to_video(video_frames,\
          \ output_video_path):<br>    # Get the dimensions of the first frame to\
          \ set the dimensions of the video<br>    first_frame = video_frames[0]<br>\
          \    h, w, layers = first_frame.shape<br>    fps = 24  # frames per second</p>\n\
          <pre><code># Create a video writer object\nwith imageio.get_writer(output_video_path,\
          \ fps=fps) as writer:\n    for frame in video_frames:\n        # Convert\
          \ the numpy array to a PIL Image\n        #pil_img = Image.fromarray(frame)\n\
          \        # Append the image to the video\n        writer.append_data(frame)#np.array(pil_img))\n\
          </code></pre>\n<p>pipe = DiffusionPipeline.from_pretrained(\"cerspense/zeroscope_v2_576w\"\
          , torch_dtype=torch.float16)<br>pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)<br>pipe.enable_model_cpu_offload()</p>\n\
          <p>prompt = \"Darth Vader is surfing on waves\"<br>video_frames = pipe(prompt,\
          \ num_inference_steps=40, height=320, width=576, num_frames=24).frames<br>video_path\
          \ = export_to_video(video_frames, \"/video\")</p>\n<h2 id=\"error\">ERROR:</h2>\n\
          <p>ValueError                                Traceback (most recent call\
          \ last)<br> in &lt;cell line: 26&gt;()<br>     24 prompt = \"Darth Vader\
          \ is surfing on waves\"<br>     25 video_frames = pipe(prompt, num_inference_steps=40,\
          \ height=320, width=576, num_frames=24).frames<br>---&gt; 26 video_path\
          \ = export_to_video(video_frames, \"/video\")<br>     27<br>     28 </p>\n\
          <p>2 frames<br> in export_to_video(video_frames, output_video_path)<br>\
          \     11<br>     12     # Create a video writer object<br>---&gt; 13   \
          \  with imageio.get_writer(output_video_path, fps=fps) as writer:<br>  \
          \   14         for frame in video_frames:<br>     15             # Convert\
          \ the numpy array to a PIL Image</p>\n<p>/usr/local/lib/python3.10/dist-packages/imageio/v2.py\
          \ in get_writer(uri, format, mode, **kwargs)<br>    322     imopen_args[\"\
          legacy_mode\"] = True<br>    323<br>--&gt; 324     image_file = imopen(uri,\
          \ \"w\" + mode, **imopen_args)<br>    325     if isinstance(image_file,\
          \ LegacyPlugin):<br>    326         return image_file.legacy_get_writer(**kwargs)</p>\n\
          <p>/usr/local/lib/python3.10/dist-packages/imageio/core/imopen.py in imopen(uri,\
          \ io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)<br>  \
          \  221             \"Specify the plugin explicitly using the <code>plugin</code>\
          \ kwarg, e.g. <code>plugin='DICOM'</code>\"<br>    222         )<br>--&gt;\
          \ 223         raise err_type(err_msg)<br>    224<br>    225     # close\
          \ the current request here and use fresh/new ones while trying each</p>\n\
          <p>ValueError: ImageIO does not generally support reading folders. Limited\
          \ support may be available via specific plugins. Specify the plugin explicitly\
          \ using the <code>plugin</code> kwarg, e.g. <code>plugin='DICOM'</code></p>\n"
        raw: "I tried with the code provided but got this error:\n\n\nimport torch\n\
          from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\nimport\
          \ imageio\n# from diffusers.utils import export_to_video\n\ndef export_to_video(video_frames,\
          \ output_video_path):\n    # Get the dimensions of the first frame to set\
          \ the dimensions of the video\n    first_frame = video_frames[0]\n    h,\
          \ w, layers = first_frame.shape\n    fps = 24  # frames per second\n   \
          \ \n    # Create a video writer object\n    with imageio.get_writer(output_video_path,\
          \ fps=fps) as writer:\n        for frame in video_frames:\n            #\
          \ Convert the numpy array to a PIL Image\n            #pil_img = Image.fromarray(frame)\n\
          \            # Append the image to the video\n            writer.append_data(frame)#np.array(pil_img))\n\
          \npipe = DiffusionPipeline.from_pretrained(\"cerspense/zeroscope_v2_576w\"\
          , torch_dtype=torch.float16)\npipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n\
          pipe.enable_model_cpu_offload()\n\nprompt = \"Darth Vader is surfing on\
          \ waves\"\nvideo_frames = pipe(prompt, num_inference_steps=40, height=320,\
          \ width=576, num_frames=24).frames\nvideo_path = export_to_video(video_frames,\
          \ \"/video\")\n\n\n\nERROR:\n------------\nValueError                  \
          \              Traceback (most recent call last)\n<ipython-input-4-b1b6e06341b2>\
          \ in <cell line: 26>()\n     24 prompt = \"Darth Vader is surfing on waves\"\
          \n     25 video_frames = pipe(prompt, num_inference_steps=40, height=320,\
          \ width=576, num_frames=24).frames\n---> 26 video_path = export_to_video(video_frames,\
          \ \"/video\")\n     27 \n     28 \n\n2 frames\n<ipython-input-4-b1b6e06341b2>\
          \ in export_to_video(video_frames, output_video_path)\n     11 \n     12\
          \     # Create a video writer object\n---> 13     with imageio.get_writer(output_video_path,\
          \ fps=fps) as writer:\n     14         for frame in video_frames:\n    \
          \ 15             # Convert the numpy array to a PIL Image\n\n/usr/local/lib/python3.10/dist-packages/imageio/v2.py\
          \ in get_writer(uri, format, mode, **kwargs)\n    322     imopen_args[\"\
          legacy_mode\"] = True\n    323 \n--> 324     image_file = imopen(uri, \"\
          w\" + mode, **imopen_args)\n    325     if isinstance(image_file, LegacyPlugin):\n\
          \    326         return image_file.legacy_get_writer(**kwargs)\n\n/usr/local/lib/python3.10/dist-packages/imageio/core/imopen.py\
          \ in imopen(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\n\
          \    221             \"Specify the plugin explicitly using the `plugin`\
          \ kwarg, e.g. `plugin='DICOM'`\"\n    222         )\n--> 223         raise\
          \ err_type(err_msg)\n    224 \n    225     # close the current request here\
          \ and use fresh/new ones while trying each\n\nValueError: ImageIO does not\
          \ generally support reading folders. Limited support may be available via\
          \ specific plugins. Specify the plugin explicitly using the `plugin` kwarg,\
          \ e.g. `plugin='DICOM'`"
        updatedAt: '2023-09-30T04:19:18.012Z'
      numEdits: 0
      reactions: []
    id: 6517a1c61ea44089e9ddb294
    type: comment
  author: CosmoAI
  content: "I tried with the code provided but got this error:\n\n\nimport torch\n\
    from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\nimport imageio\n\
    # from diffusers.utils import export_to_video\n\ndef export_to_video(video_frames,\
    \ output_video_path):\n    # Get the dimensions of the first frame to set the\
    \ dimensions of the video\n    first_frame = video_frames[0]\n    h, w, layers\
    \ = first_frame.shape\n    fps = 24  # frames per second\n    \n    # Create a\
    \ video writer object\n    with imageio.get_writer(output_video_path, fps=fps)\
    \ as writer:\n        for frame in video_frames:\n            # Convert the numpy\
    \ array to a PIL Image\n            #pil_img = Image.fromarray(frame)\n      \
    \      # Append the image to the video\n            writer.append_data(frame)#np.array(pil_img))\n\
    \npipe = DiffusionPipeline.from_pretrained(\"cerspense/zeroscope_v2_576w\", torch_dtype=torch.float16)\n\
    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n\
    pipe.enable_model_cpu_offload()\n\nprompt = \"Darth Vader is surfing on waves\"\
    \nvideo_frames = pipe(prompt, num_inference_steps=40, height=320, width=576, num_frames=24).frames\n\
    video_path = export_to_video(video_frames, \"/video\")\n\n\n\nERROR:\n------------\n\
    ValueError                                Traceback (most recent call last)\n\
    <ipython-input-4-b1b6e06341b2> in <cell line: 26>()\n     24 prompt = \"Darth\
    \ Vader is surfing on waves\"\n     25 video_frames = pipe(prompt, num_inference_steps=40,\
    \ height=320, width=576, num_frames=24).frames\n---> 26 video_path = export_to_video(video_frames,\
    \ \"/video\")\n     27 \n     28 \n\n2 frames\n<ipython-input-4-b1b6e06341b2>\
    \ in export_to_video(video_frames, output_video_path)\n     11 \n     12     #\
    \ Create a video writer object\n---> 13     with imageio.get_writer(output_video_path,\
    \ fps=fps) as writer:\n     14         for frame in video_frames:\n     15   \
    \          # Convert the numpy array to a PIL Image\n\n/usr/local/lib/python3.10/dist-packages/imageio/v2.py\
    \ in get_writer(uri, format, mode, **kwargs)\n    322     imopen_args[\"legacy_mode\"\
    ] = True\n    323 \n--> 324     image_file = imopen(uri, \"w\" + mode, **imopen_args)\n\
    \    325     if isinstance(image_file, LegacyPlugin):\n    326         return\
    \ image_file.legacy_get_writer(**kwargs)\n\n/usr/local/lib/python3.10/dist-packages/imageio/core/imopen.py\
    \ in imopen(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\n\
    \    221             \"Specify the plugin explicitly using the `plugin` kwarg,\
    \ e.g. `plugin='DICOM'`\"\n    222         )\n--> 223         raise err_type(err_msg)\n\
    \    224 \n    225     # close the current request here and use fresh/new ones\
    \ while trying each\n\nValueError: ImageIO does not generally support reading\
    \ folders. Limited support may be available via specific plugins. Specify the\
    \ plugin explicitly using the `plugin` kwarg, e.g. `plugin='DICOM'`"
  created_at: 2023-09-30 03:19:18+00:00
  edited: false
  hidden: false
  id: 6517a1c61ea44089e9ddb294
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 30
repo_id: cerspense/zeroscope_v2_576w
repo_type: model
status: open
target_branch: null
title: The video created is just a green screen
