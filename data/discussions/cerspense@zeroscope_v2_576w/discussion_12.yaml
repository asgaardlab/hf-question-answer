!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Yimikai
conflicting_files: null
created_at: 2023-07-05 09:53:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c824b0ab5736e02bcad50066d23ce770.svg
      fullname: Dongfang HU
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yimikai
      type: user
    createdAt: '2023-07-05T10:53:45.000Z'
    data:
      edited: false
      editors:
      - Yimikai
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6048145294189453
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c824b0ab5736e02bcad50066d23ce770.svg
          fullname: Dongfang HU
          isHf: false
          isPro: false
          name: Yimikai
          type: user
        html: '<p>import torch<br>from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler<br>from
          diffusers.utils import export_to_video<br>pipe = DiffusionPipeline.from_pretrained("cerspense/zeroscope_v2_576w",
          torch_dtype=torch.float16)</p>

          <p>Occur the following bug:</p>

          <p>pipe = DiffusionPipeline.from_pretrained("cerspense/zeroscope_v2_576w",
          torch_dtype=torch.float16)<br>  File "/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py",
          line 953, in from_pretrained<br>    loaded_sub_model = load_sub_model(<br>  File
          "/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py",
          line 394, in load_sub_model<br>    loaded_sub_model = load_method(os.path.join(cached_folder,
          name), **loading_kwargs)<br>  File "/opt/conda/lib/python3.9/site-packages/diffusers/models/modeling_utils.py",
          line 426, in from_pretrained<br>    allow_pickle = True<br>ValueError: Cannot
          load &lt;class ''diffusers.models.autoencoder_kl.AutoencoderKL''&gt; from
          cerspense/zeroscope_v2_576w/vae because the following keys are missing:<br>
          encoder.mid_block.attentions.0.proj_attn.weight, decoder.mid_block.attentions.0.value.bias,
          decoder.mid_block.attentions.0.key.bias, decoder.mid_block.attentions.0.query.bias,
          encoder.mid_block.attentions.0.value.weight, encoder.mid_block.attentions.0.query.weight,
          decoder.mid_block.attentions.0.proj_attn.bias, decoder.mid_block.attentions.0.proj_attn.weight,
          decoder.mid_block.attentions.0.query.weight, decoder.mid_block.attentions.0.key.weight,
          encoder.mid_block.attentions.0.key.bias, encoder.mid_block.attentions.0.value.bias,
          encoder.mid_block.attentions.0.key.weight, decoder.mid_block.attentions.0.value.weight,
          encoder.mid_block.attentions.0.proj_attn.bias, encoder.mid_block.attentions.0.query.bias.<br>
          Please make sure to pass <code>low_cpu_mem_usage=False</code> and <code>device_map=None</code>
          if you want to randomly initialize those weights or else make sure your
          checkpoint file is correct.</p>

          '
        raw: "\r\nimport torch\r\nfrom diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\r\
          \nfrom diffusers.utils import export_to_video\r\npipe = DiffusionPipeline.from_pretrained(\"\
          cerspense/zeroscope_v2_576w\", torch_dtype=torch.float16)\r\n \r\nOccur\
          \ the following bug:\r\n\r\npipe = DiffusionPipeline.from_pretrained(\"\
          cerspense/zeroscope_v2_576w\", torch_dtype=torch.float16)\r\n  File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 953, in from_pretrained\r\n    loaded_sub_model = load_sub_model(\r\
          \n  File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 394, in load_sub_model\r\n    loaded_sub_model = load_method(os.path.join(cached_folder,\
          \ name), **loading_kwargs)\r\n  File \"/opt/conda/lib/python3.9/site-packages/diffusers/models/modeling_utils.py\"\
          , line 426, in from_pretrained\r\n    allow_pickle = True\r\nValueError:\
          \ Cannot load <class 'diffusers.models.autoencoder_kl.AutoencoderKL'> from\
          \ cerspense/zeroscope_v2_576w/vae because the following keys are missing:\
          \ \r\n encoder.mid_block.attentions.0.proj_attn.weight, decoder.mid_block.attentions.0.value.bias,\
          \ decoder.mid_block.attentions.0.key.bias, decoder.mid_block.attentions.0.query.bias,\
          \ encoder.mid_block.attentions.0.value.weight, encoder.mid_block.attentions.0.query.weight,\
          \ decoder.mid_block.attentions.0.proj_attn.bias, decoder.mid_block.attentions.0.proj_attn.weight,\
          \ decoder.mid_block.attentions.0.query.weight, decoder.mid_block.attentions.0.key.weight,\
          \ encoder.mid_block.attentions.0.key.bias, encoder.mid_block.attentions.0.value.bias,\
          \ encoder.mid_block.attentions.0.key.weight, decoder.mid_block.attentions.0.value.weight,\
          \ encoder.mid_block.attentions.0.proj_attn.bias, encoder.mid_block.attentions.0.query.bias.\
          \ \r\n Please make sure to pass `low_cpu_mem_usage=False` and `device_map=None`\
          \ if you want to randomly initialize those weights or else make sure your\
          \ checkpoint file is correct."
        updatedAt: '2023-07-05T10:53:45.210Z'
      numEdits: 0
      reactions: []
    id: 64a54bb9ea3c5861302f84d7
    type: comment
  author: Yimikai
  content: "\r\nimport torch\r\nfrom diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\r\
    \nfrom diffusers.utils import export_to_video\r\npipe = DiffusionPipeline.from_pretrained(\"\
    cerspense/zeroscope_v2_576w\", torch_dtype=torch.float16)\r\n \r\nOccur the following\
    \ bug:\r\n\r\npipe = DiffusionPipeline.from_pretrained(\"cerspense/zeroscope_v2_576w\"\
    , torch_dtype=torch.float16)\r\n  File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
    , line 953, in from_pretrained\r\n    loaded_sub_model = load_sub_model(\r\n \
    \ File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
    , line 394, in load_sub_model\r\n    loaded_sub_model = load_method(os.path.join(cached_folder,\
    \ name), **loading_kwargs)\r\n  File \"/opt/conda/lib/python3.9/site-packages/diffusers/models/modeling_utils.py\"\
    , line 426, in from_pretrained\r\n    allow_pickle = True\r\nValueError: Cannot\
    \ load <class 'diffusers.models.autoencoder_kl.AutoencoderKL'> from cerspense/zeroscope_v2_576w/vae\
    \ because the following keys are missing: \r\n encoder.mid_block.attentions.0.proj_attn.weight,\
    \ decoder.mid_block.attentions.0.value.bias, decoder.mid_block.attentions.0.key.bias,\
    \ decoder.mid_block.attentions.0.query.bias, encoder.mid_block.attentions.0.value.weight,\
    \ encoder.mid_block.attentions.0.query.weight, decoder.mid_block.attentions.0.proj_attn.bias,\
    \ decoder.mid_block.attentions.0.proj_attn.weight, decoder.mid_block.attentions.0.query.weight,\
    \ decoder.mid_block.attentions.0.key.weight, encoder.mid_block.attentions.0.key.bias,\
    \ encoder.mid_block.attentions.0.value.bias, encoder.mid_block.attentions.0.key.weight,\
    \ decoder.mid_block.attentions.0.value.weight, encoder.mid_block.attentions.0.proj_attn.bias,\
    \ encoder.mid_block.attentions.0.query.bias. \r\n Please make sure to pass `low_cpu_mem_usage=False`\
    \ and `device_map=None` if you want to randomly initialize those weights or else\
    \ make sure your checkpoint file is correct."
  created_at: 2023-07-05 09:53:45+00:00
  edited: false
  hidden: false
  id: 64a54bb9ea3c5861302f84d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f4ecd3607e8efef9c82a297450131007.svg
      fullname: LouisLee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Mint2099
      type: user
    createdAt: '2023-09-13T05:10:27.000Z'
    data:
      edited: false
      editors:
      - Mint2099
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9625146985054016
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f4ecd3607e8efef9c82a297450131007.svg
          fullname: LouisLee
          isHf: false
          isPro: false
          name: Mint2099
          type: user
        html: '<p>Got the same question, the downloaded model''s size seems mismatched
          with the online posted one.</p>

          '
        raw: Got the same question, the downloaded model's size seems mismatched with
          the online posted one.
        updatedAt: '2023-09-13T05:10:27.489Z'
      numEdits: 0
      reactions: []
    id: 6501444313f1546526ca15e4
    type: comment
  author: Mint2099
  content: Got the same question, the downloaded model's size seems mismatched with
    the online posted one.
  created_at: 2023-09-13 04:10:27+00:00
  edited: false
  hidden: false
  id: 6501444313f1546526ca15e4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: cerspense/zeroscope_v2_576w
repo_type: model
status: open
target_branch: null
title: 'issue: is the vae model right?'
