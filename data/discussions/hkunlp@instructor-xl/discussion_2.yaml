!!python/object:huggingface_hub.community.DiscussionWithDetails
author: csinva
conflicting_files: null
created_at: 2023-02-27 15:44:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660330237411-62b0bee117fa24819dd0999c.jpeg?w=200&h=200&f=face
      fullname: Chandan Singh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: csinva
      type: user
    createdAt: '2023-02-27T15:44:30.000Z'
    data:
      edited: false
      editors:
      - csinva
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660330237411-62b0bee117fa24819dd0999c.jpeg?w=200&h=200&f=face
          fullname: Chandan Singh
          isHf: false
          isPro: false
          name: csinva
          type: user
        html: '<p>Thanks for sharing this wonderful model! I was wondering -- is there
          any way to use this model in half-precision (float16)?</p>

          <p>The standard model.half() does not seem to work.</p>

          '
        raw: "Thanks for sharing this wonderful model! I was wondering -- is there\
          \ any way to use this model in half-precision (float16)?\r\n\r\nThe standard\
          \ model.half() does not seem to work.\r\n\r\n"
        updatedAt: '2023-02-27T15:44:30.069Z'
      numEdits: 0
      reactions: []
    id: 63fccfde54dac27c8ba4c3d6
    type: comment
  author: csinva
  content: "Thanks for sharing this wonderful model! I was wondering -- is there any\
    \ way to use this model in half-precision (float16)?\r\n\r\nThe standard model.half()\
    \ does not seem to work.\r\n\r\n"
  created_at: 2023-02-27 15:44:30+00:00
  edited: false
  hidden: false
  id: 63fccfde54dac27c8ba4c3d6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b7d0a895e669bcd1303c4716b5401c36.svg
      fullname: Hongjin SU
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: multi-train
      type: user
    createdAt: '2023-02-28T03:22:38.000Z'
    data:
      edited: false
      editors:
      - multi-train
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b7d0a895e669bcd1303c4716b5401c36.svg
          fullname: Hongjin SU
          isHf: false
          isPro: false
          name: multi-train
          type: user
        html: '<p>Hi, Thanks a lot for your interest in the INSTRUCTOR model!</p>

          <p>You may use the INSTRUCTOR model to embed the texts with the half-precision:</p>

          <pre><code>from InstructorEmbedding import INSTRUCTOR

          sentences_a = [[''Represent the Science sentence: '',''Parton energy loss
          in QCD matter''], [''Represent the Financial statement: '',''The Federal
          Reserve on Wednesday raised its benchmark interest rate.'']]

          embeddings_a = model.encode(sentences_a,convert_to_tensor=True).half()

          </code></pre>

          <p>This should reduce the memory requirement to use the xl-model.</p>

          <p>For more detailed information, you may refer to the following two issues:<br><a
          rel="nofollow" href="https://github.com/UKPLab/sentence-transformers/issues/425">https://github.com/UKPLab/sentence-transformers/issues/425</a><br><a
          rel="nofollow" href="https://github.com/UKPLab/sentence-transformers/issues/822">https://github.com/UKPLab/sentence-transformers/issues/822</a></p>

          <p>Hope this helps! Feel free to add any further question or comment!</p>

          '
        raw: 'Hi, Thanks a lot for your interest in the INSTRUCTOR model!


          You may use the INSTRUCTOR model to embed the texts with the half-precision:

          ```

          from InstructorEmbedding import INSTRUCTOR

          sentences_a = [[''Represent the Science sentence: '',''Parton energy loss
          in QCD matter''], [''Represent the Financial statement: '',''The Federal
          Reserve on Wednesday raised its benchmark interest rate.'']]

          embeddings_a = model.encode(sentences_a,convert_to_tensor=True).half()

          ```

          This should reduce the memory requirement to use the xl-model.


          For more detailed information, you may refer to the following two issues:

          https://github.com/UKPLab/sentence-transformers/issues/425

          https://github.com/UKPLab/sentence-transformers/issues/822


          Hope this helps! Feel free to add any further question or comment!'
        updatedAt: '2023-02-28T03:22:38.177Z'
      numEdits: 0
      reactions: []
    id: 63fd737e0ac35c2dfbb2423f
    type: comment
  author: multi-train
  content: 'Hi, Thanks a lot for your interest in the INSTRUCTOR model!


    You may use the INSTRUCTOR model to embed the texts with the half-precision:

    ```

    from InstructorEmbedding import INSTRUCTOR

    sentences_a = [[''Represent the Science sentence: '',''Parton energy loss in QCD
    matter''], [''Represent the Financial statement: '',''The Federal Reserve on Wednesday
    raised its benchmark interest rate.'']]

    embeddings_a = model.encode(sentences_a,convert_to_tensor=True).half()

    ```

    This should reduce the memory requirement to use the xl-model.


    For more detailed information, you may refer to the following two issues:

    https://github.com/UKPLab/sentence-transformers/issues/425

    https://github.com/UKPLab/sentence-transformers/issues/822


    Hope this helps! Feel free to add any further question or comment!'
  created_at: 2023-02-28 03:22:38+00:00
  edited: false
  hidden: false
  id: 63fd737e0ac35c2dfbb2423f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: hkunlp/instructor-xl
repo_type: model
status: open
target_branch: null
title: Half precision?
