!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Essence888
conflicting_files: []
created_at: 2023-05-14 18:12:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3402f93a8422662fbb49a7e3dba7f384.svg
      fullname: W
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Essence888
      type: user
    createdAt: '2023-05-14T19:12:44.000Z'
    data:
      edited: false
      editors:
      - Essence888
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3402f93a8422662fbb49a7e3dba7f384.svg
          fullname: W
          isHf: false
          isPro: false
          name: Essence888
          type: user
        html: '<p>import torch<br>from transformers import AutoTokenizer, AutoModelForQuestionAnswering<br>tokenizer
          = AutoTokenizer.from_pretrained("atharvamundada99/bert-large-question-answering-finetuned-legal",cache_dir="/E/HUG_Models")<br>model
          = AutoModelForQuestionAnswering.from_pretrained("atharvamundada99/bert-large-question-answering-finetuned-legal",
          cache_dir="/E/HUG_Models")</p>

          <p>def get_answer( question, context):<br>    inputs = tokenizer(question,
          context, return_tensors="pt")<br>    with torch.no_grad():<br>        outputs
          = model(**inputs)<br>    answer_start_index = outputs.start_logits.argmax()<br>    answer_end_index
          = outputs.end_logits.argmax()</p>

          <pre><code>predict_answer_tokens = inputs.input_ids[0, answer_start_index:
          answer_end_index + 1]

          answer=tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)

          return answer

          </code></pre>

          <p>print(get_answer("What is your name","My name is JACK"))<br>#output JACK</p>

          '
        raw: "import torch\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\n\
          tokenizer = AutoTokenizer.from_pretrained(\"atharvamundada99/bert-large-question-answering-finetuned-legal\"\
          ,cache_dir=\"/E/HUG_Models\")\nmodel = AutoModelForQuestionAnswering.from_pretrained(\"\
          atharvamundada99/bert-large-question-answering-finetuned-legal\", cache_dir=\"\
          /E/HUG_Models\")\n\ndef get_answer( question, context):\n    inputs = tokenizer(question,\
          \ context, return_tensors=\"pt\")\n    with torch.no_grad():\n        outputs\
          \ = model(**inputs)\n    answer_start_index = outputs.start_logits.argmax()\n\
          \    answer_end_index = outputs.end_logits.argmax()\n\n    predict_answer_tokens\
          \ = inputs.input_ids[0, answer_start_index: answer_end_index + 1]\n    answer=tokenizer.decode(predict_answer_tokens,\
          \ skip_special_tokens=True)\n    return answer\nprint(get_answer(\"What\
          \ is your name\",\"My name is JACK\"))\n#output JACK"
        updatedAt: '2023-05-14T19:12:44.375Z'
      numEdits: 0
      reactions: []
    id: 646132ac3cc3259ce05af8ab
    type: comment
  author: Essence888
  content: "import torch\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\n\
    tokenizer = AutoTokenizer.from_pretrained(\"atharvamundada99/bert-large-question-answering-finetuned-legal\"\
    ,cache_dir=\"/E/HUG_Models\")\nmodel = AutoModelForQuestionAnswering.from_pretrained(\"\
    atharvamundada99/bert-large-question-answering-finetuned-legal\", cache_dir=\"\
    /E/HUG_Models\")\n\ndef get_answer( question, context):\n    inputs = tokenizer(question,\
    \ context, return_tensors=\"pt\")\n    with torch.no_grad():\n        outputs\
    \ = model(**inputs)\n    answer_start_index = outputs.start_logits.argmax()\n\
    \    answer_end_index = outputs.end_logits.argmax()\n\n    predict_answer_tokens\
    \ = inputs.input_ids[0, answer_start_index: answer_end_index + 1]\n    answer=tokenizer.decode(predict_answer_tokens,\
    \ skip_special_tokens=True)\n    return answer\nprint(get_answer(\"What is your\
    \ name\",\"My name is JACK\"))\n#output JACK"
  created_at: 2023-05-14 18:12:44+00:00
  edited: false
  hidden: false
  id: 646132ac3cc3259ce05af8ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/3402f93a8422662fbb49a7e3dba7f384.svg
      fullname: W
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Essence888
      type: user
    createdAt: '2023-05-14T19:12:45.000Z'
    data:
      oid: 181cf995ed4895264361b3a9214f86e0453dd22c
      parents:
      - 53337351517cd5b73acd7f0b63a7fb313ea71bd1
      subject: Create README.md
    id: 646132ad0000000000000000
    type: commit
  author: Essence888
  created_at: 2023-05-14 18:12:45+00:00
  id: 646132ad0000000000000000
  oid: 181cf995ed4895264361b3a9214f86e0453dd22c
  summary: Create README.md
  type: commit
is_pull_request: true
merge_commit_oid: null
num: 7
repo_id: atharvamundada99/bert-large-question-answering-finetuned-legal
repo_type: model
status: open
target_branch: refs/heads/main
title: Create README.md
