!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sermolin
conflicting_files: null
created_at: 2023-06-09 18:54:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8365d23265822eded42de44b10952d42.svg
      fullname: Sergey Ermolin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sermolin
      type: user
    createdAt: '2023-06-09T19:54:05.000Z'
    data:
      edited: false
      editors:
      - sermolin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.919550895690918
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8365d23265822eded42de44b10952d42.svg
          fullname: Sergey Ermolin
          isHf: false
          isPro: false
          name: sermolin
          type: user
        html: '<p>couldn''t find it in the documentation, reference notebook hardcodes
          it to 1024 mentioning the need to set int8 if the input length is &gt;1024,
          but what''s the max?<br>use-case: document summarization and text generation.
          Probably would not want to use --Instruct model for that, right?</p>

          '
        raw: "couldn't find it in the documentation, reference notebook hardcodes\
          \ it to 1024 mentioning the need to set int8 if the input length is >1024,\
          \ but what's the max? \r\nuse-case: document summarization and text generation.\
          \ Probably would not want to use --Instruct model for that, right?"
        updatedAt: '2023-06-09T19:54:05.043Z'
      numEdits: 0
      reactions:
      - count: 6
        reaction: "\U0001F44D"
        users:
        - kwonmha
        - neuland-homeland
        - pedrochem
        - lucadiliello
        - jbrandenburg
        - Theblaxkertheberry
    id: 6483835dc235ef76b63b4633
    type: comment
  author: sermolin
  content: "couldn't find it in the documentation, reference notebook hardcodes it\
    \ to 1024 mentioning the need to set int8 if the input length is >1024, but what's\
    \ the max? \r\nuse-case: document summarization and text generation. Probably\
    \ would not want to use --Instruct model for that, right?"
  created_at: 2023-06-09 18:54:05+00:00
  edited: false
  hidden: false
  id: 6483835dc235ef76b63b4633
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef12e1c4ae1cdf9a5b3309ce35988b53.svg
      fullname: Akharaz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Theblaxkertheberry
      type: user
    createdAt: '2023-06-22T10:05:07.000Z'
    data:
      edited: false
      editors:
      - Theblaxkertheberry
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8126536011695862
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef12e1c4ae1cdf9a5b3309ce35988b53.svg
          fullname: Akharaz
          isHf: false
          isPro: false
          name: Theblaxkertheberry
          type: user
        html: '<p>Someone for That one ?</p>

          '
        raw: Someone for That one ?
        updatedAt: '2023-06-22T10:05:07.339Z'
      numEdits: 0
      reactions: []
    id: 64941cd3df9fe8c6aa38f9de
    type: comment
  author: Theblaxkertheberry
  content: Someone for That one ?
  created_at: 2023-06-22 09:05:07+00:00
  edited: false
  hidden: false
  id: 64941cd3df9fe8c6aa38f9de
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1eac64edf4d12ed4fc30be3588d39b4a.svg
      fullname: M.L.
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mishaml77
      type: user
    createdAt: '2023-06-25T16:31:39.000Z'
    data:
      edited: false
      editors:
      - mishaml77
      hidden: false
      identifiedLanguage:
        language: de
        probability: 0.6758759617805481
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1eac64edf4d12ed4fc30be3588d39b4a.svg
          fullname: M.L.
          isHf: false
          isPro: false
          name: mishaml77
          type: user
        html: '<p>2048</p>

          '
        raw: '2048'
        updatedAt: '2023-06-25T16:31:39.288Z'
      numEdits: 0
      reactions: []
    id: 64986bebf436b85fddbd5c0c
    type: comment
  author: mishaml77
  content: '2048'
  created_at: 2023-06-25 15:31:39+00:00
  edited: false
  hidden: false
  id: 64986bebf436b85fddbd5c0c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/612a16dbb0e033524c184f80ee5c1bf7.svg
      fullname: Adrian Gabriel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gabriead
      type: user
    createdAt: '2023-07-12T11:01:16.000Z'
    data:
      edited: false
      editors:
      - gabriead
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9371040463447571
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/612a16dbb0e033524c184f80ee5c1bf7.svg
          fullname: Adrian Gabriel
          isHf: false
          isPro: false
          name: gabriead
          type: user
        html: '<p>Tried to increase the number of tokens in the openapi.json (cloned
          the repo and found that simply by searching for 1024) but that didn''t help.
          Created a feature request: <a rel="nofollow" href="https://github.com/huggingface/text-generation-inference/issues/593">https://github.com/huggingface/text-generation-inference/issues/593</a>.
          Please add to that if you need any adaptations.</p>

          '
        raw: 'Tried to increase the number of tokens in the openapi.json (cloned the
          repo and found that simply by searching for 1024) but that didn''t help.
          Created a feature request: https://github.com/huggingface/text-generation-inference/issues/593.
          Please add to that if you need any adaptations.'
        updatedAt: '2023-07-12T11:01:16.097Z'
      numEdits: 0
      reactions: []
    id: 64ae87fc1b0f37adbd7b5d20
    type: comment
  author: gabriead
  content: 'Tried to increase the number of tokens in the openapi.json (cloned the
    repo and found that simply by searching for 1024) but that didn''t help. Created
    a feature request: https://github.com/huggingface/text-generation-inference/issues/593.
    Please add to that if you need any adaptations.'
  created_at: 2023-07-12 10:01:16+00:00
  edited: false
  hidden: false
  id: 64ae87fc1b0f37adbd7b5d20
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 38
repo_id: tiiuae/falcon-40b-instruct
repo_type: model
status: open
target_branch: null
title: what is the input token length of Falcon-40B and -7B models?
