!!python/object:huggingface_hub.community.DiscussionWithDetails
author: zkdtckk
conflicting_files: null
created_at: 2023-06-01 23:14:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a748c1c117ac45df99f8ba950131bb67.svg
      fullname: Kai Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zkdtckk
      type: user
    createdAt: '2023-06-02T00:14:11.000Z'
    data:
      edited: false
      editors:
      - zkdtckk
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a748c1c117ac45df99f8ba950131bb67.svg
          fullname: Kai Zhang
          isHf: false
          isPro: false
          name: zkdtckk
          type: user
        html: '<p>The model performs really awesome, and I am trying to find a way
          to make it more repeatable. Any parameter to adjust like the temperature=0
          in OpenAI GPT API?</p>

          '
        raw: "The model performs really awesome, and I am trying to find a way to\
          \ make it more repeatable. Any parameter to adjust like the temperature=0\
          \ in OpenAI GPT API?\r\n"
        updatedAt: '2023-06-02T00:14:11.663Z'
      numEdits: 0
      reactions: []
    id: 647934535fa05d12dc342a4a
    type: comment
  author: zkdtckk
  content: "The model performs really awesome, and I am trying to find a way to make\
    \ it more repeatable. Any parameter to adjust like the temperature=0 in OpenAI\
    \ GPT API?\r\n"
  created_at: 2023-06-01 23:14:11+00:00
  edited: false
  hidden: false
  id: 647934535fa05d12dc342a4a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
      fullname: Falcon LLM TII UAE
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: FalconLLM
      type: user
    createdAt: '2023-06-02T05:07:48.000Z'
    data:
      edited: false
      editors:
      - FalconLLM
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
          fullname: Falcon LLM TII UAE
          isHf: false
          isPro: false
          name: FalconLLM
          type: user
        html: "<p>Yup, the options are here: <a href=\"https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig\"\
          >https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig</a><br>Eg.\
          \ the repetition penalty might be useful. </p>\n<p>You should be able to\
          \ specify them when calling  the pipeline</p>\n<pre><code>sequences = pipeline(\n\
          \   \"prompt goes here\",\n    max_length=200,\n    do_sample=True,\n  \
          \  top_k=10,\n    num_return_sequences=1,\n    eos_token_id=tokenizer.eos_token_id,\n\
          \    repetition_penalty=2.0\n)\n</code></pre>\n"
        raw: "Yup, the options are here: https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig\n\
          Eg. the repetition penalty might be useful. \n\nYou should be able to specify\
          \ them when calling  the pipeline\n\n```\nsequences = pipeline(\n   \"prompt\
          \ goes here\",\n    max_length=200,\n    do_sample=True,\n    top_k=10,\n\
          \    num_return_sequences=1,\n    eos_token_id=tokenizer.eos_token_id,\n\
          \    repetition_penalty=2.0\n)\n```"
        updatedAt: '2023-06-02T05:07:48.003Z'
      numEdits: 0
      reactions: []
    id: 64797924faa0a209531faf52
    type: comment
  author: FalconLLM
  content: "Yup, the options are here: https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig\n\
    Eg. the repetition penalty might be useful. \n\nYou should be able to specify\
    \ them when calling  the pipeline\n\n```\nsequences = pipeline(\n   \"prompt goes\
    \ here\",\n    max_length=200,\n    do_sample=True,\n    top_k=10,\n    num_return_sequences=1,\n\
    \    eos_token_id=tokenizer.eos_token_id,\n    repetition_penalty=2.0\n)\n```"
  created_at: 2023-06-02 04:07:48+00:00
  edited: false
  hidden: false
  id: 64797924faa0a209531faf52
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
      fullname: Falcon LLM TII UAE
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: FalconLLM
      type: user
    createdAt: '2023-06-09T14:51:50.000Z'
    data:
      status: closed
    id: 64833c86256509a233f29d50
    type: status-change
  author: FalconLLM
  created_at: 2023-06-09 13:51:50+00:00
  id: 64833c86256509a233f29d50
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 19
repo_id: tiiuae/falcon-40b-instruct
repo_type: model
status: closed
target_branch: null
title: Is there a way to control the temperature of the model?
