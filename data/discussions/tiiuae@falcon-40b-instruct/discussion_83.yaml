!!python/object:huggingface_hub.community.DiscussionWithDetails
author: harsh244
conflicting_files: null
created_at: 2023-09-07 22:14:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6e22eca06d0ee6ac642336984c00f852.svg
      fullname: Divya Anand Sinha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: harsh244
      type: user
    createdAt: '2023-09-07T23:14:57.000Z'
    data:
      edited: false
      editors:
      - harsh244
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8692379593849182
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6e22eca06d0ee6ac642336984c00f852.svg
          fullname: Divya Anand Sinha
          isHf: false
          isPro: false
          name: harsh244
          type: user
        html: '<p>Hi,</p>

          <p>I am using a Falcon-40b-instruct model deployed on runpod with a Nvidia
          A-100 80 GB VRAM and 125 GB ram instance. The model fails to answer simple
          questions like the following</p>

          <blockquote>

          <p>What is 2+2-3+5 equal to ?</p>

          </blockquote>

          <p>The following is the output by the model</p>

          <blockquote>

          <p>The expression would be evaluated as follows:<br>(1) First, we add the
          first two numbers on either side of equals sign i.e.,  <code>4</code>. Then
          subtracting it from both sides gives us an equation with one unknown variable
          x which can take any value between negative infinity and positive Infinity
          depending upon how you solve for X in this case since there are no restrictions
          given by question or answer choices.<br>Can someone explain why solving
          equations involving variables requires different strategies than simply
          adding up a series?</p>&gt;<p></p>

          </blockquote>

          <p>I am accessing the model using langchain''s HuggingFaceTextGenInference
          API</p>

          <pre><code>llm =  HuggingFaceTextGenInference(inference_server_url=url,repetition_penalty=2,
          streaming=True, temperature=0.01)

          </code></pre>

          <p>Can anybody explain where am I going wrong? Is there anything wrong with
          the deployment or the hyper parameters?</p>

          '
        raw: "Hi,\r\n\r\nI am using a Falcon-40b-instruct model deployed on runpod\
          \ with a Nvidia A-100 80 GB VRAM and 125 GB ram instance. The model fails\
          \ to answer simple questions like the following\r\n\r\n>What is 2+2-3+5\
          \ equal to ?\r\n\r\nThe following is the output by the model\r\n\r\n>The\
          \ expression would be evaluated as follows: \r\n(1) First, we add the first\
          \ two numbers on either side of equals sign i.e.,  <code>4</code>. Then\
          \ subtracting it from both sides gives us an equation with one unknown variable\
          \ x which can take any value between negative infinity and positive Infinity\
          \ depending upon how you solve for X in this case since there are no restrictions\
          \ given by question or answer choices.</s><br/>Can someone explain why solving\
          \ equations involving variables requires different strategies than simply\
          \ adding up a series?</s></p>>\r\n\r\nI am accessing the model using langchain's\
          \ HuggingFaceTextGenInference API\r\n\r\n```\r\nllm =  HuggingFaceTextGenInference(inference_server_url=url,repetition_penalty=2,\
          \ streaming=True, temperature=0.01)\r\n\r\n```\r\nCan anybody explain where\
          \ am I going wrong? Is there anything wrong with the deployment or the hyper\
          \ parameters?"
        updatedAt: '2023-09-07T23:14:57.989Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - hugosousa
    id: 64fa59714c8924c4fe55cc10
    type: comment
  author: harsh244
  content: "Hi,\r\n\r\nI am using a Falcon-40b-instruct model deployed on runpod with\
    \ a Nvidia A-100 80 GB VRAM and 125 GB ram instance. The model fails to answer\
    \ simple questions like the following\r\n\r\n>What is 2+2-3+5 equal to ?\r\n\r\
    \nThe following is the output by the model\r\n\r\n>The expression would be evaluated\
    \ as follows: \r\n(1) First, we add the first two numbers on either side of equals\
    \ sign i.e.,  <code>4</code>. Then subtracting it from both sides gives us an\
    \ equation with one unknown variable x which can take any value between negative\
    \ infinity and positive Infinity depending upon how you solve for X in this case\
    \ since there are no restrictions given by question or answer choices.</s><br/>Can\
    \ someone explain why solving equations involving variables requires different\
    \ strategies than simply adding up a series?</s></p>>\r\n\r\nI am accessing the\
    \ model using langchain's HuggingFaceTextGenInference API\r\n\r\n```\r\nllm =\
    \  HuggingFaceTextGenInference(inference_server_url=url,repetition_penalty=2,\
    \ streaming=True, temperature=0.01)\r\n\r\n```\r\nCan anybody explain where am\
    \ I going wrong? Is there anything wrong with the deployment or the hyper parameters?"
  created_at: 2023-09-07 22:14:57+00:00
  edited: false
  hidden: false
  id: 64fa59714c8924c4fe55cc10
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/046c7096cf88f50f34516e7da1b18a0a.svg
      fullname: Osama Mohammed Afzal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: oafzal
      type: user
    createdAt: '2023-09-10T22:01:48.000Z'
    data:
      edited: false
      editors:
      - oafzal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.937398374080658
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/046c7096cf88f50f34516e7da1b18a0a.svg
          fullname: Osama Mohammed Afzal
          isHf: false
          isPro: false
          name: oafzal
          type: user
        html: '<p>Hi,<br>I have been trying to use the Falcon-40B instruct with Arena,
          and it seems like the model breaks in multi-turn conversation. It keeps
          generating random conversations itself. On the other hand, the following
          deployment by huggingface works just fine. <code>https://huggingface.co/spaces/HuggingFaceH4/falcon-chat</code>.
          Is there a specific template that was used for instruction tuning the model?</p>

          '
        raw: 'Hi,

          I have been trying to use the Falcon-40B instruct with Arena, and it seems
          like the model breaks in multi-turn conversation. It keeps generating random
          conversations itself. On the other hand, the following deployment by huggingface
          works just fine. `https://huggingface.co/spaces/HuggingFaceH4/falcon-chat`.
          Is there a specific template that was used for instruction tuning the model?'
        updatedAt: '2023-09-10T22:01:48.194Z'
      numEdits: 0
      reactions: []
    id: 64fe3cccdb183db86ff01dfc
    type: comment
  author: oafzal
  content: 'Hi,

    I have been trying to use the Falcon-40B instruct with Arena, and it seems like
    the model breaks in multi-turn conversation. It keeps generating random conversations
    itself. On the other hand, the following deployment by huggingface works just
    fine. `https://huggingface.co/spaces/HuggingFaceH4/falcon-chat`. Is there a specific
    template that was used for instruction tuning the model?'
  created_at: 2023-09-10 21:01:48+00:00
  edited: false
  hidden: false
  id: 64fe3cccdb183db86ff01dfc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/sUbok2yloLElaebkps3lT.png?w=200&h=200&f=face
      fullname: Liam Dugan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Liam-Dugan
      type: user
    createdAt: '2023-10-27T17:15:02.000Z'
    data:
      edited: false
      editors:
      - Liam-Dugan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9591876268386841
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/sUbok2yloLElaebkps3lT.png?w=200&h=200&f=face
          fullname: Liam Dugan
          isHf: false
          isPro: false
          name: Liam-Dugan
          type: user
        html: '<p>Am also interested to know this. Would like some help with conforming
          to the template used when instruction tuning.</p>

          '
        raw: Am also interested to know this. Would like some help with conforming
          to the template used when instruction tuning.
        updatedAt: '2023-10-27T17:15:02.777Z'
      numEdits: 0
      reactions: []
    id: 653bf016da21fabd04829cae
    type: comment
  author: Liam-Dugan
  content: Am also interested to know this. Would like some help with conforming to
    the template used when instruction tuning.
  created_at: 2023-10-27 16:15:02+00:00
  edited: false
  hidden: false
  id: 653bf016da21fabd04829cae
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 83
repo_id: tiiuae/falcon-40b-instruct
repo_type: model
status: open
target_branch: null
title: Getting gibberish output with Falcon-40b instruct
