!!python/object:huggingface_hub.community.DiscussionWithDetails
author: johnjohndoedoe
conflicting_files: null
created_at: 2023-06-04 20:14:39+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c5878350f014d6e6f8c254d4b57c99b4.svg
      fullname: john doe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: johnjohndoedoe
      type: user
    createdAt: '2023-06-04T21:14:39.000Z'
    data:
      edited: false
      editors:
      - johnjohndoedoe
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.987744927406311
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c5878350f014d6e6f8c254d4b57c99b4.svg
          fullname: john doe
          isHf: false
          isPro: false
          name: johnjohndoedoe
          type: user
        html: '<p>Hi<br>I had to search for a while to find a bit of info about what
          the requirements are to run this, it would be nice to have more info on
          the model card!</p>

          <p>thx</p>

          '
        raw: "Hi\r\nI had to search for a while to find a bit of info about what the\
          \ requirements are to run this, it would be nice to have more info on the\
          \ model card!\r\n\r\nthx"
        updatedAt: '2023-06-04T21:14:39.340Z'
      numEdits: 0
      reactions: []
    id: 647cfebfadaf5cc26da8dc72
    type: comment
  author: johnjohndoedoe
  content: "Hi\r\nI had to search for a while to find a bit of info about what the\
    \ requirements are to run this, it would be nice to have more info on the model\
    \ card!\r\n\r\nthx"
  created_at: 2023-06-04 20:14:39+00:00
  edited: false
  hidden: false
  id: 647cfebfadaf5cc26da8dc72
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
      fullname: Muhammad Ichsan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ichsan2895
      type: user
    createdAt: '2023-06-05T04:28:52.000Z'
    data:
      edited: false
      editors:
      - Ichsan2895
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7398844361305237
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
          fullname: Muhammad Ichsan
          isHf: false
          isPro: false
          name: Ichsan2895
          type: user
        html: '<p>Using newest transformer &amp; accelerate library from pip github
          + using bitsandbytes config (load_in_4bit, bfloat16, and nf4 quant type),
          I am able to run this on single A100 40 GB. Its using 80 GB of disk space
          for saving pretrained model.</p>

          '
        raw: Using newest transformer & accelerate library from pip github + using
          bitsandbytes config (load_in_4bit, bfloat16, and nf4 quant type), I am able
          to run this on single A100 40 GB. Its using 80 GB of disk space for saving
          pretrained model.
        updatedAt: '2023-06-05T04:28:52.382Z'
      numEdits: 0
      reactions: []
    id: 647d648483c62f3249338265
    type: comment
  author: Ichsan2895
  content: Using newest transformer & accelerate library from pip github + using bitsandbytes
    config (load_in_4bit, bfloat16, and nf4 quant type), I am able to run this on
    single A100 40 GB. Its using 80 GB of disk space for saving pretrained model.
  created_at: 2023-06-05 03:28:52+00:00
  edited: false
  hidden: false
  id: 647d648483c62f3249338265
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/171341790bda6be72c02cc60a27cf9a5.svg
      fullname: Chandra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tckb
      type: user
    createdAt: '2023-06-05T05:40:24.000Z'
    data:
      edited: false
      editors:
      - tckb
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9651399850845337
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/171341790bda6be72c02cc60a27cf9a5.svg
          fullname: Chandra
          isHf: false
          isPro: false
          name: tckb
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;Ichsan2895&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Ichsan2895\"\
          >@<span class=\"underline\">Ichsan2895</span></a></span>\n\n\t</span></span>\
          \  I\u2019m pretty new to this model and llm general. I\u2019d like test\
          \ this in one of azure environment and there are many which are available.\
          \ Do you by any chance know which one of the vm sizes can be used. There\
          \ are many which are not available due to shortage and high demands.</p>\n\
          <p>Thank you</p>\n"
        raw: "Hi @Ichsan2895  I\u2019m pretty new to this model and llm general. I\u2019\
          d like test this in one of azure environment and there are many which are\
          \ available. Do you by any chance know which one of the vm sizes can be\
          \ used. There are many which are not available due to shortage and high\
          \ demands.\n\nThank you"
        updatedAt: '2023-06-05T05:40:24.291Z'
      numEdits: 0
      reactions: []
    id: 647d75481c0644de8d41c386
    type: comment
  author: tckb
  content: "Hi @Ichsan2895  I\u2019m pretty new to this model and llm general. I\u2019\
    d like test this in one of azure environment and there are many which are available.\
    \ Do you by any chance know which one of the vm sizes can be used. There are many\
    \ which are not available due to shortage and high demands.\n\nThank you"
  created_at: 2023-06-05 04:40:24+00:00
  edited: false
  hidden: false
  id: 647d75481c0644de8d41c386
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
      fullname: Muhammad Ichsan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ichsan2895
      type: user
    createdAt: '2023-06-05T07:11:26.000Z'
    data:
      edited: false
      editors:
      - Ichsan2895
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9373876452445984
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
          fullname: Muhammad Ichsan
          isHf: false
          isPro: false
          name: Ichsan2895
          type: user
        html: "<blockquote>\n<p>Hi <span data-props=\"{&quot;user&quot;:&quot;Ichsan2895&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Ichsan2895\"\
          >@<span class=\"underline\">Ichsan2895</span></a></span>\n\n\t</span></span>\
          \  I\u2019m pretty new to this model and llm general. I\u2019d like test\
          \ this in one of azure environment and there are many which are available.\
          \ Do you by any chance know which one of the vm sizes can be used. There\
          \ are many which are not available due to shortage and high demands.</p>\n\
          <p>Thank you</p>\n</blockquote>\n<p>Hello, Sorry I never test it on Azure.<br>I\
          \ tested it on Runpods environment. It cost $ 0.85/hour which has A6000\
          \ 48GB VRAM + 58 GB RAM + 200 GB Disk when it running and cost $ 0.03/hour\
          \ when system idle because I saving pretrained model in their Disk too.</p>\n"
        raw: "> Hi @Ichsan2895  I\u2019m pretty new to this model and llm general.\
          \ I\u2019d like test this in one of azure environment and there are many\
          \ which are available. Do you by any chance know which one of the vm sizes\
          \ can be used. There are many which are not available due to shortage and\
          \ high demands.\n> \n> Thank you\n\nHello, Sorry I never test it on Azure.\
          \ \nI tested it on Runpods environment. It cost $ 0.85/hour which has A6000\
          \ 48GB VRAM + 58 GB RAM + 200 GB Disk when it running and cost $ 0.03/hour\
          \ when system idle because I saving pretrained model in their Disk too."
        updatedAt: '2023-06-05T07:11:26.773Z'
      numEdits: 0
      reactions: []
    id: 647d8a9e10b7a3b157f7a1a3
    type: comment
  author: Ichsan2895
  content: "> Hi @Ichsan2895  I\u2019m pretty new to this model and llm general. I\u2019\
    d like test this in one of azure environment and there are many which are available.\
    \ Do you by any chance know which one of the vm sizes can be used. There are many\
    \ which are not available due to shortage and high demands.\n> \n> Thank you\n\
    \nHello, Sorry I never test it on Azure. \nI tested it on Runpods environment.\
    \ It cost $ 0.85/hour which has A6000 48GB VRAM + 58 GB RAM + 200 GB Disk when\
    \ it running and cost $ 0.03/hour when system idle because I saving pretrained\
    \ model in their Disk too."
  created_at: 2023-06-05 06:11:26+00:00
  edited: false
  hidden: false
  id: 647d8a9e10b7a3b157f7a1a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/171341790bda6be72c02cc60a27cf9a5.svg
      fullname: Chandra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tckb
      type: user
    createdAt: '2023-06-05T08:14:30.000Z'
    data:
      edited: false
      editors:
      - tckb
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9589729309082031
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/171341790bda6be72c02cc60a27cf9a5.svg
          fullname: Chandra
          isHf: false
          isPro: false
          name: tckb
          type: user
        html: '<p>thank you for the response. How was the performance on this machine(tk/sec)?</p>

          '
        raw: thank you for the response. How was the performance on this machine(tk/sec)?
        updatedAt: '2023-06-05T08:14:30.293Z'
      numEdits: 0
      reactions: []
    id: 647d9966f14eafc3b446267f
    type: comment
  author: tckb
  content: thank you for the response. How was the performance on this machine(tk/sec)?
  created_at: 2023-06-05 07:14:30+00:00
  edited: false
  hidden: false
  id: 647d9966f14eafc3b446267f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
      fullname: Muhammad Ichsan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ichsan2895
      type: user
    createdAt: '2023-06-05T14:23:00.000Z'
    data:
      edited: true
      editors:
      - Ichsan2895
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.31247657537460327
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
          fullname: Muhammad Ichsan
          isHf: false
          isPro: false
          name: Ichsan2895
          type: user
        html: '<p>Pretty slow.. About 0.5-1 token/second. BTW, Guanaco-65-GPTQ is
          faster but unfortunatelly it can not be use for commercial.</p>

          '
        raw: Pretty slow.. About 0.5-1 token/second. BTW, Guanaco-65-GPTQ is faster
          but unfortunatelly it can not be use for commercial.
        updatedAt: '2023-06-05T14:24:34.811Z'
      numEdits: 1
      reactions: []
    id: 647defc4f14eafc3b45216be
    type: comment
  author: Ichsan2895
  content: Pretty slow.. About 0.5-1 token/second. BTW, Guanaco-65-GPTQ is faster
    but unfortunatelly it can not be use for commercial.
  created_at: 2023-06-05 13:23:00+00:00
  edited: true
  hidden: false
  id: 647defc4f14eafc3b45216be
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/171341790bda6be72c02cc60a27cf9a5.svg
      fullname: Chandra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tckb
      type: user
    createdAt: '2023-06-05T21:57:15.000Z'
    data:
      edited: false
      editors:
      - tckb
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9739022254943848
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/171341790bda6be72c02cc60a27cf9a5.svg
          fullname: Chandra
          isHf: false
          isPro: false
          name: tckb
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Ichsan2895&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Ichsan2895\">@<span class=\"\
          underline\">Ichsan2895</span></a></span>\n\n\t</span></span>  I was able\
          \ to run this on Standard_NC48ads_A100_v4 which has 160 GiB GPU mem.  I\
          \ wasn't able to use bitsandbytes module (some issue, I couldn't debug it).\
          \  The results were surprisingly good.  I could only use it for a very short\
          \ time because its pretty expensive.  See <a rel=\"nofollow\" href=\"https://twitter.com/this_is_tckb/status/1665814803829473280/\"\
          >https://twitter.com/this_is_tckb/status/1665814803829473280/</a></p>\n"
        raw: '@Ichsan2895  I was able to run this on Standard_NC48ads_A100_v4 which
          has 160 GiB GPU mem.  I wasn''t able to use bitsandbytes module (some issue,
          I couldn''t debug it).  The results were surprisingly good.  I could only
          use it for a very short time because its pretty expensive.  See https://twitter.com/this_is_tckb/status/1665814803829473280/'
        updatedAt: '2023-06-05T21:57:15.255Z'
      numEdits: 0
      reactions: []
    id: 647e5a3b5214d172cbc73c30
    type: comment
  author: tckb
  content: '@Ichsan2895  I was able to run this on Standard_NC48ads_A100_v4 which
    has 160 GiB GPU mem.  I wasn''t able to use bitsandbytes module (some issue, I
    couldn''t debug it).  The results were surprisingly good.  I could only use it
    for a very short time because its pretty expensive.  See https://twitter.com/this_is_tckb/status/1665814803829473280/'
  created_at: 2023-06-05 20:57:15+00:00
  edited: false
  hidden: false
  id: 647e5a3b5214d172cbc73c30
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1b63868da3a8b3ec8e0fc5658e040312.svg
      fullname: adeeb aldkheel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: adeebaldkheel
      type: user
    createdAt: '2023-06-07T09:54:18.000Z'
    data:
      edited: false
      editors:
      - adeebaldkheel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9782599806785583
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1b63868da3a8b3ec8e0fc5658e040312.svg
          fullname: adeeb aldkheel
          isHf: false
          isPro: false
          name: adeebaldkheel
          type: user
        html: '<p>is it possible to run it on RTX 4090?<br>sorry guys but can someone
          tell me what does 40b mean? what I know is 40b x 4 = 160GB right?<br>does
          it mean one GPU with total of 160GB can load this model?<br>or I need 160GB+
          for training? and training is different than using?</p>

          '
        raw: 'is it possible to run it on RTX 4090?

          sorry guys but can someone tell me what does 40b mean? what I know is 40b
          x 4 = 160GB right?

          does it mean one GPU with total of 160GB can load this model?

          or I need 160GB+ for training? and training is different than using?'
        updatedAt: '2023-06-07T09:54:18.177Z'
      numEdits: 0
      reactions: []
    id: 648053ca40facadc55699b15
    type: comment
  author: adeebaldkheel
  content: 'is it possible to run it on RTX 4090?

    sorry guys but can someone tell me what does 40b mean? what I know is 40b x 4
    = 160GB right?

    does it mean one GPU with total of 160GB can load this model?

    or I need 160GB+ for training? and training is different than using?'
  created_at: 2023-06-07 08:54:18+00:00
  edited: false
  hidden: false
  id: 648053ca40facadc55699b15
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
      fullname: Muhammad Ichsan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ichsan2895
      type: user
    createdAt: '2023-06-07T12:48:57.000Z'
    data:
      edited: true
      editors:
      - Ichsan2895
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7223559021949768
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
          fullname: Muhammad Ichsan
          isHf: false
          isPro: false
          name: Ichsan2895
          type: user
        html: '<p>40b is 40 billion parameter used. But it does not mean that it need
          40 GB GPU RAM. I used  48 GB A6000 to run this model. It can be optimized
          (for lowering consumption) by activating bitsandbytes config. Which enable
          bfloat16 and load_in_4bit. Unfortunatelly it wont run in 24GB VRAM (OOM).</p>

          <p>Sorry I dont know the consumption when it training/fine tuning new dataset.</p>

          '
        raw: '40b is 40 billion parameter used. But it does not mean that it need
          40 GB GPU RAM. I used  48 GB A6000 to run this model. It can be optimized
          (for lowering consumption) by activating bitsandbytes config. Which enable
          bfloat16 and load_in_4bit. Unfortunatelly it wont run in 24GB VRAM (OOM).


          Sorry I dont know the consumption when it training/fine tuning new dataset.'
        updatedAt: '2023-06-07T12:50:40.808Z'
      numEdits: 1
      reactions: []
    id: 64807cb940facadc556c9696
    type: comment
  author: Ichsan2895
  content: '40b is 40 billion parameter used. But it does not mean that it need 40
    GB GPU RAM. I used  48 GB A6000 to run this model. It can be optimized (for lowering
    consumption) by activating bitsandbytes config. Which enable bfloat16 and load_in_4bit.
    Unfortunatelly it wont run in 24GB VRAM (OOM).


    Sorry I dont know the consumption when it training/fine tuning new dataset.'
  created_at: 2023-06-07 11:48:57+00:00
  edited: true
  hidden: false
  id: 64807cb940facadc556c9696
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
      fullname: Falcon LLM TII UAE
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: FalconLLM
      type: user
    createdAt: '2023-06-09T14:56:47.000Z'
    data:
      edited: false
      editors:
      - FalconLLM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9646783471107483
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
          fullname: Falcon LLM TII UAE
          isHf: false
          isPro: false
          name: FalconLLM
          type: user
        html: '<p>We have added some basic info on running the model to the card.
          It takes ~80-100GB to comfortably infer Falcon-40B. There has been some
          work with <a rel="nofollow" href="https://github.com/rmihaylov/falcontune">FalconTune</a>
          on 4-bit quantization as well.</p>

          '
        raw: We have added some basic info on running the model to the card. It takes
          ~80-100GB to comfortably infer Falcon-40B. There has been some work with
          [FalconTune](https://github.com/rmihaylov/falcontune) on 4-bit quantization
          as well.
        updatedAt: '2023-06-09T14:56:47.441Z'
      numEdits: 0
      reactions: []
    id: 64833daf68af3aed0a53b6c9
    type: comment
  author: FalconLLM
  content: We have added some basic info on running the model to the card. It takes
    ~80-100GB to comfortably infer Falcon-40B. There has been some work with [FalconTune](https://github.com/rmihaylov/falcontune)
    on 4-bit quantization as well.
  created_at: 2023-06-09 13:56:47+00:00
  edited: false
  hidden: false
  id: 64833daf68af3aed0a53b6c9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 28
repo_id: tiiuae/falcon-40b-instruct
repo_type: model
status: open
target_branch: null
title: Why not add system requirements on the model card?
