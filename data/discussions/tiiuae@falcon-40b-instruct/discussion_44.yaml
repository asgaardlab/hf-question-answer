!!python/object:huggingface_hub.community.DiscussionWithDetails
author: amnasher
conflicting_files: null
created_at: 2023-06-15 10:32:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/76a4df67bfc77200bc25d9a798fcef6a.svg
      fullname: Amna sher afal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: amnasher
      type: user
    createdAt: '2023-06-15T11:32:37.000Z'
    data:
      edited: false
      editors:
      - amnasher
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8607680797576904
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/76a4df67bfc77200bc25d9a798fcef6a.svg
          fullname: Amna sher afal
          isHf: false
          isPro: false
          name: amnasher
          type: user
        html: '<p>Hello I wanted to ask my max token length is 4k + tokens can I finetune
          the 40-b instruct/ 7b- instruct model for my own data since the max seq
          length mentioned is 2048?</p>

          '
        raw: Hello I wanted to ask my max token length is 4k + tokens can I finetune
          the 40-b instruct/ 7b- instruct model for my own data since the max seq
          length mentioned is 2048?
        updatedAt: '2023-06-15T11:32:37.609Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - SamuelAzran
        - Theblaxkertheberry
    id: 648af6d5a912977b61a88dc1
    type: comment
  author: amnasher
  content: Hello I wanted to ask my max token length is 4k + tokens can I finetune
    the 40-b instruct/ 7b- instruct model for my own data since the max seq length
    mentioned is 2048?
  created_at: 2023-06-15 10:32:37+00:00
  edited: false
  hidden: false
  id: 648af6d5a912977b61a88dc1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef12e1c4ae1cdf9a5b3309ce35988b53.svg
      fullname: Akharaz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Theblaxkertheberry
      type: user
    createdAt: '2023-06-22T10:02:22.000Z'
    data:
      edited: false
      editors:
      - Theblaxkertheberry
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9281647801399231
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef12e1c4ae1cdf9a5b3309ce35988b53.svg
          fullname: Akharaz
          isHf: false
          isPro: false
          name: Theblaxkertheberry
          type: user
        html: '<p>I do have the same issue, I am trying to create a chatgpt kind of.
          But the falcon40b instruct do not contextualize at  all. </p>

          <p>It act like it is not have any memory of the previous prompt.</p>

          '
        raw: "I do have the same issue, I am trying to create a chatgpt kind of. But\
          \ the falcon40b instruct do not contextualize at  all. \n\nIt act like it\
          \ is not have any memory of the previous prompt."
        updatedAt: '2023-06-22T10:02:22.310Z'
      numEdits: 0
      reactions: []
    id: 64941c2e68862e8711a8df2c
    type: comment
  author: Theblaxkertheberry
  content: "I do have the same issue, I am trying to create a chatgpt kind of. But\
    \ the falcon40b instruct do not contextualize at  all. \n\nIt act like it is not\
    \ have any memory of the previous prompt."
  created_at: 2023-06-22 09:02:22+00:00
  edited: false
  hidden: false
  id: 64941c2e68862e8711a8df2c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f9849a8e3dfec54fe989b5605c5dd097.svg
      fullname: yang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: run
      type: user
    createdAt: '2023-07-03T07:14:54.000Z'
    data:
      edited: false
      editors:
      - run
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.674461305141449
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f9849a8e3dfec54fe989b5605c5dd097.svg
          fullname: yang
          isHf: false
          isPro: false
          name: run
          type: user
        html: '<p>this kinda of working, see <a rel="nofollow" href="https://colab.research.google.com/drive/1VI2nhlyKvd5cw4-zHvAIk00cAVj2lCCC#scrollTo=b80b3f37">https://colab.research.google.com/drive/1VI2nhlyKvd5cw4-zHvAIk00cAVj2lCCC#scrollTo=b80b3f37</a></p>

          '
        raw: this kinda of working, see https://colab.research.google.com/drive/1VI2nhlyKvd5cw4-zHvAIk00cAVj2lCCC#scrollTo=b80b3f37
        updatedAt: '2023-07-03T07:14:54.294Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - deepakkaura26
    id: 64a2756e8f953945fa522de8
    type: comment
  author: run
  content: this kinda of working, see https://colab.research.google.com/drive/1VI2nhlyKvd5cw4-zHvAIk00cAVj2lCCC#scrollTo=b80b3f37
  created_at: 2023-07-03 06:14:54+00:00
  edited: false
  hidden: false
  id: 64a2756e8f953945fa522de8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 44
repo_id: tiiuae/falcon-40b-instruct
repo_type: model
status: open
target_branch: null
title: Finetune Falcon-4b with large token size.
