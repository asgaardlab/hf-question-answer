!!python/object:huggingface_hub.community.DiscussionWithDetails
author: garystafford
conflicting_files: null
created_at: 2023-06-04 16:50:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1AltROWohmoRop3-QeimM.png?w=200&h=200&f=face
      fullname: Gary Stafford
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: garystafford
      type: user
    createdAt: '2023-06-04T17:50:24.000Z'
    data:
      edited: true
      editors:
      - garystafford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7397798299789429
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1AltROWohmoRop3-QeimM.png?w=200&h=200&f=face
          fullname: Gary Stafford
          isHf: false
          isPro: false
          name: garystafford
          type: user
        html: "<p>When deploying the model to Amazon SageMaker using the supplied\
          \ code in the Deploy tab I am getting the following error, on the <code>predictor.predict</code>\
          \ call:</p>\n<pre><code class=\"language-text\">ModelError: An error occurred\
          \ (ModelError) when calling the InvokeEndpoint operation: Received client\
          \ error (400) from primary with message \"{\n  \"code\": 400,\n  \"type\"\
          : \"InternalServerException\",\n  \"message\": \"Loading /.sagemaker/mms/models/tiiuae__falcon-40b-instruct\
          \ requires you to execute the configuration file in that repo on your local\
          \ machine. Make sure you have read the code there to avoid malicious use,\
          \ then set the option `trust_remote_code\\u003dTrue` to remove this error.\"\
          \n}\n</code></pre>\n"
        raw: "When deploying the model to Amazon SageMaker using the supplied code\
          \ in the Deploy tab I am getting the following error, on the `predictor.predict`\
          \ call:\n```text\nModelError: An error occurred (ModelError) when calling\
          \ the InvokeEndpoint operation: Received client error (400) from primary\
          \ with message \"{\n  \"code\": 400,\n  \"type\": \"InternalServerException\"\
          ,\n  \"message\": \"Loading /.sagemaker/mms/models/tiiuae__falcon-40b-instruct\
          \ requires you to execute the configuration file in that repo on your local\
          \ machine. Make sure you have read the code there to avoid malicious use,\
          \ then set the option `trust_remote_code\\u003dTrue` to remove this error.\"\
          \n}\n```"
        updatedAt: '2023-06-04T17:52:15.988Z'
      numEdits: 1
      reactions: []
    id: 647ccee0d2da33779cbacc1c
    type: comment
  author: garystafford
  content: "When deploying the model to Amazon SageMaker using the supplied code in\
    \ the Deploy tab I am getting the following error, on the `predictor.predict`\
    \ call:\n```text\nModelError: An error occurred (ModelError) when calling the\
    \ InvokeEndpoint operation: Received client error (400) from primary with message\
    \ \"{\n  \"code\": 400,\n  \"type\": \"InternalServerException\",\n  \"message\"\
    : \"Loading /.sagemaker/mms/models/tiiuae__falcon-40b-instruct requires you to\
    \ execute the configuration file in that repo on your local machine. Make sure\
    \ you have read the code there to avoid malicious use, then set the option `trust_remote_code\\\
    u003dTrue` to remove this error.\"\n}\n```"
  created_at: 2023-06-04 16:50:24+00:00
  edited: true
  hidden: false
  id: 647ccee0d2da33779cbacc1c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/399a4ea2c22aa2c731e34216e2106877.svg
      fullname: Shridhar Alve
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Shridharalve
      type: user
    createdAt: '2023-06-05T06:42:33.000Z'
    data:
      edited: true
      editors:
      - Shridharalve
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4319687783718109
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/399a4ea2c22aa2c731e34216e2106877.svg
          fullname: Shridhar Alve
          isHf: false
          isPro: false
          name: Shridharalve
          type: user
        html: '<p>You can use this in your model_fn function in inference.py</p>

          <pre><code>tokenizer = AutoTokenizer.from_pretrained("tiiuae/falcon-40b-instruct")

          model = AutoModelForCausalLM.from_pretrained("tiiuae/falcon-40b-instruct",
          trust_remote_code=True,torch_dtype=torch.bfloat16, device_map="auto")

          </code></pre>

          '
        raw: 'You can use this in your model_fn function in inference.py


          ```

          tokenizer = AutoTokenizer.from_pretrained("tiiuae/falcon-40b-instruct")

          model = AutoModelForCausalLM.from_pretrained("tiiuae/falcon-40b-instruct",
          trust_remote_code=True,torch_dtype=torch.bfloat16, device_map="auto")

          ```'
        updatedAt: '2023-06-05T07:58:27.703Z'
      numEdits: 1
      reactions: []
    id: 647d83d9f14eafc3b443136b
    type: comment
  author: Shridharalve
  content: 'You can use this in your model_fn function in inference.py


    ```

    tokenizer = AutoTokenizer.from_pretrained("tiiuae/falcon-40b-instruct")

    model = AutoModelForCausalLM.from_pretrained("tiiuae/falcon-40b-instruct", trust_remote_code=True,torch_dtype=torch.bfloat16,
    device_map="auto")

    ```'
  created_at: 2023-06-05 05:42:33+00:00
  edited: true
  hidden: false
  id: 647d83d9f14eafc3b443136b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a1d0bd9daf981ed3adf049e7096aade4.svg
      fullname: Martin Holste
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: martin-holste
      type: user
    createdAt: '2023-06-06T02:02:48.000Z'
    data:
      edited: false
      editors:
      - martin-holste
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7659183144569397
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a1d0bd9daf981ed3adf049e7096aade4.svg
          fullname: Martin Holste
          isHf: false
          isPro: false
          name: martin-holste
          type: user
        html: "<p>I'm struggling with this as well. In Sagemaker Studio, I have created\
          \ a file code/inference.py, and put in it:</p>\n<pre>from transformers import\
          \ pipeline\ndef model_fn(model_dir):\n    tokenizer = AutoTokenizer.from_pretrained(\"\
          tiiuae/falcon-40b-instruct\")\n    model = AutoModelForCausalLM.from_pretrained(\"\
          tiiuae/falcon-40b-instruct\", trust_remote_code=True,torch_dtype=torch.bfloat16,\
          \ device_map=\"auto\")\n\n    return pipeline(\n        \"question-answering\"\
          ,\n        model=model,\n        tokenizer=tokenizer,\n        torch_dtype=\"\
          auto\",\n        trust_remote_code=True,\n        device_map=\"auto\",\n\
          \        )\n</pre>\n<p>But I continue to get the error regarding \"trust_remote_code.\"\
          \ Can someone please explain a bit more on exactly what is required to get\
          \ falcon to work as a Sagemaker endpoint? I'd really appreciate it.</p>\n"
        raw: "I'm struggling with this as well. In Sagemaker Studio, I have created\
          \ a file code/inference.py, and put in it:\n\n<pre>\nfrom transformers import\
          \ pipeline\ndef model_fn(model_dir):\n    tokenizer = AutoTokenizer.from_pretrained(\"\
          tiiuae/falcon-40b-instruct\")\n    model = AutoModelForCausalLM.from_pretrained(\"\
          tiiuae/falcon-40b-instruct\", trust_remote_code=True,torch_dtype=torch.bfloat16,\
          \ device_map=\"auto\")\n\n    return pipeline(\n        \"question-answering\"\
          ,\n        model=model,\n        tokenizer=tokenizer,\n        torch_dtype=\"\
          auto\",\n        trust_remote_code=True,\n        device_map=\"auto\",\n\
          \        )\n</pre>\nBut I continue to get the error regarding \"trust_remote_code.\"\
          \ Can someone please explain a bit more on exactly what is required to get\
          \ falcon to work as a Sagemaker endpoint? I'd really appreciate it."
        updatedAt: '2023-06-06T02:02:48.071Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - garystafford
    id: 647e93c832c471a7fa9f261a
    type: comment
  author: martin-holste
  content: "I'm struggling with this as well. In Sagemaker Studio, I have created\
    \ a file code/inference.py, and put in it:\n\n<pre>\nfrom transformers import\
    \ pipeline\ndef model_fn(model_dir):\n    tokenizer = AutoTokenizer.from_pretrained(\"\
    tiiuae/falcon-40b-instruct\")\n    model = AutoModelForCausalLM.from_pretrained(\"\
    tiiuae/falcon-40b-instruct\", trust_remote_code=True,torch_dtype=torch.bfloat16,\
    \ device_map=\"auto\")\n\n    return pipeline(\n        \"question-answering\"\
    ,\n        model=model,\n        tokenizer=tokenizer,\n        torch_dtype=\"\
    auto\",\n        trust_remote_code=True,\n        device_map=\"auto\",\n     \
    \   )\n</pre>\nBut I continue to get the error regarding \"trust_remote_code.\"\
    \ Can someone please explain a bit more on exactly what is required to get falcon\
    \ to work as a Sagemaker endpoint? I'd really appreciate it."
  created_at: 2023-06-06 01:02:48+00:00
  edited: false
  hidden: false
  id: 647e93c832c471a7fa9f261a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/399a4ea2c22aa2c731e34216e2106877.svg
      fullname: Shridhar Alve
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Shridharalve
      type: user
    createdAt: '2023-06-08T16:15:50.000Z'
    data:
      edited: false
      editors:
      - Shridharalve
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5931455492973328
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/399a4ea2c22aa2c731e34216e2106877.svg
          fullname: Shridhar Alve
          isHf: false
          isPro: false
          name: Shridharalve
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;martin-holste&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/martin-holste\"\
          >@<span class=\"underline\">martin-holste</span></a></span>\n\n\t</span></span>\
          \ <span data-props=\"{&quot;user&quot;:&quot;garystafford&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/garystafford\">@<span\
          \ class=\"underline\">garystafford</span></a></span>\n\n\t</span></span>\
          \ </p>\n<p>Here's the guide by Phil Schmid to deploy this model on sage\
          \ maker... Works like a charm</p>\n<p><a rel=\"nofollow\" href=\"https://www.philschmid.de/sagemaker-falcon-llm\"\
          >https://www.philschmid.de/sagemaker-falcon-llm</a></p>\n"
        raw: "@martin-holste @garystafford \n\nHere's the guide by Phil Schmid to\
          \ deploy this model on sage maker... Works like a charm\n\nhttps://www.philschmid.de/sagemaker-falcon-llm"
        updatedAt: '2023-06-08T16:15:50.179Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - FalconLLM
    id: 6481feb63ce52056e93a0073
    type: comment
  author: Shridharalve
  content: "@martin-holste @garystafford \n\nHere's the guide by Phil Schmid to deploy\
    \ this model on sage maker... Works like a charm\n\nhttps://www.philschmid.de/sagemaker-falcon-llm"
  created_at: 2023-06-08 15:15:50+00:00
  edited: false
  hidden: false
  id: 6481feb63ce52056e93a0073
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
      fullname: Falcon LLM TII UAE
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: FalconLLM
      type: user
    createdAt: '2023-06-09T14:55:17.000Z'
    data:
      status: closed
    id: 64833d555df64037b1bc6714
    type: status-change
  author: FalconLLM
  created_at: 2023-06-09 13:55:17+00:00
  id: 64833d555df64037b1bc6714
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 27
repo_id: tiiuae/falcon-40b-instruct
repo_type: model
status: closed
target_branch: null
title: Getting "trust_remote_code" Error when Running SageMaker Deploy Code Sample
