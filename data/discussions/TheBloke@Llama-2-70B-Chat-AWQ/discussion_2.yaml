!!python/object:huggingface_hub.community.DiscussionWithDetails
author: abhatia2
conflicting_files: null
created_at: 2023-11-10 08:38:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
      fullname: Archit Bhatia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhatia2
      type: user
    createdAt: '2023-11-10T08:38:05.000Z'
    data:
      edited: false
      editors:
      - abhatia2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9062092304229736
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
          fullname: Archit Bhatia
          isHf: false
          isPro: false
          name: abhatia2
          type: user
        html: '<p>Has anyone been able to deploy this model successfully via AWS Sagemaker?</p>

          <p>AWQ support for TGI Inference was added in this PR: <a rel="nofollow"
          href="https://github.com/huggingface/text-generation-inference/pull/1019">https://github.com/huggingface/text-generation-inference/pull/1019</a><br>But
          still, I''m unable to deploy it.</p>

          <p>Getting this error: RuntimeError: weight model.layers.0.self_attn.q_proj.weight
          does not exist</p>

          <p>Any help/leads are appreciated, thanks!</p>

          '
        raw: "Has anyone been able to deploy this model successfully via AWS Sagemaker?\r\
          \n\r\nAWQ support for TGI Inference was added in this PR: https://github.com/huggingface/text-generation-inference/pull/1019\r\
          \nBut still, I'm unable to deploy it.\r\n\r\nGetting this error: RuntimeError:\
          \ weight model.layers.0.self_attn.q_proj.weight does not exist\r\n\r\nAny\
          \ help/leads are appreciated, thanks!"
        updatedAt: '2023-11-10T08:38:05.172Z'
      numEdits: 0
      reactions: []
    id: 654debedb70aa2e94fa2089f
    type: comment
  author: abhatia2
  content: "Has anyone been able to deploy this model successfully via AWS Sagemaker?\r\
    \n\r\nAWQ support for TGI Inference was added in this PR: https://github.com/huggingface/text-generation-inference/pull/1019\r\
    \nBut still, I'm unable to deploy it.\r\n\r\nGetting this error: RuntimeError:\
    \ weight model.layers.0.self_attn.q_proj.weight does not exist\r\n\r\nAny help/leads\
    \ are appreciated, thanks!"
  created_at: 2023-11-10 08:38:05+00:00
  edited: false
  hidden: false
  id: 654debedb70aa2e94fa2089f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-10T08:40:15.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9377152323722839
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>That error indicates it doesn''t know to load it as an AWQ model,
          and is trying to load it as a full fp16 model.</p>

          <p>TGI requires passing the <code>--quantize awq</code> parameter. I''m
          afraid I have no idea how one is meant to do that on Sagemaker.  Check the
          docs to see if they support TGI parameters, and then see if you can pass
          <code>--quantize awq</code> or <code>quantize=awq</code> in whatever way
          you''re meant to pass params on Sagemaker.</p>

          '
        raw: 'That error indicates it doesn''t know to load it as an AWQ model, and
          is trying to load it as a full fp16 model.


          TGI requires passing the `--quantize awq` parameter. I''m afraid I have
          no idea how one is meant to do that on Sagemaker.  Check the docs to see
          if they support TGI parameters, and then see if you can pass `--quantize
          awq` or `quantize=awq` in whatever way you''re meant to pass params on Sagemaker.'
        updatedAt: '2023-11-10T08:40:15.367Z'
      numEdits: 0
      reactions: []
    id: 654dec6fa6e1f56b3b690c02
    type: comment
  author: TheBloke
  content: 'That error indicates it doesn''t know to load it as an AWQ model, and
    is trying to load it as a full fp16 model.


    TGI requires passing the `--quantize awq` parameter. I''m afraid I have no idea
    how one is meant to do that on Sagemaker.  Check the docs to see if they support
    TGI parameters, and then see if you can pass `--quantize awq` or `quantize=awq`
    in whatever way you''re meant to pass params on Sagemaker.'
  created_at: 2023-11-10 08:40:15+00:00
  edited: false
  hidden: false
  id: 654dec6fa6e1f56b3b690c02
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
      fullname: Archit Bhatia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhatia2
      type: user
    createdAt: '2023-11-10T08:56:30.000Z'
    data:
      edited: false
      editors:
      - abhatia2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7446599006652832
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
          fullname: Archit Bhatia
          isHf: false
          isPro: false
          name: abhatia2
          type: user
        html: '<p>I was successfully able to deploy the GPTQ model: <a href="https://huggingface.co/TheBloke/Llama-2-70B-Chat-GPTQ">https://huggingface.co/TheBloke/Llama-2-70B-Chat-GPTQ</a></p>

          <p>In that, we used to pass this parameter as: </p>

          <p><code>hub = {     ''HF_MODEL_ID'':''TheBloke/Llama-2-70B-Chat-GPTQ'',     ''SM_NUM_GPUS'':
          json.dumps(8),     ''HF_MODEL_QUANTIZE'': ''gptq'' }</code></p>

          <p>When I tried setting it as ''awq'' , I got the following error:<br><code>NameError:
          name ''WQLinear'' is not defined</code></p>

          '
        raw: "I was successfully able to deploy the GPTQ model: https://huggingface.co/TheBloke/Llama-2-70B-Chat-GPTQ\n\
          \nIn that, we used to pass this parameter as: \n```hub = {\n\t'HF_MODEL_ID':'TheBloke/Llama-2-70B-Chat-GPTQ',\n\
          \t'SM_NUM_GPUS': json.dumps(8),\n\t'HF_MODEL_QUANTIZE': 'gptq'\n}```\n\n\
          When I tried setting it as 'awq' , I got the following error:\n```NameError:\
          \ name 'WQLinear' is not defined```"
        updatedAt: '2023-11-10T08:56:30.311Z'
      numEdits: 0
      reactions: []
    id: 654df03e2fdbbde41e7f4935
    type: comment
  author: abhatia2
  content: "I was successfully able to deploy the GPTQ model: https://huggingface.co/TheBloke/Llama-2-70B-Chat-GPTQ\n\
    \nIn that, we used to pass this parameter as: \n```hub = {\n\t'HF_MODEL_ID':'TheBloke/Llama-2-70B-Chat-GPTQ',\n\
    \t'SM_NUM_GPUS': json.dumps(8),\n\t'HF_MODEL_QUANTIZE': 'gptq'\n}```\n\nWhen I\
    \ tried setting it as 'awq' , I got the following error:\n```NameError: name 'WQLinear'\
    \ is not defined```"
  created_at: 2023-11-10 08:56:30+00:00
  edited: false
  hidden: false
  id: 654df03e2fdbbde41e7f4935
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-10T08:58:06.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.951325535774231
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I see. My tentative guess is that the version of TGI on Sagemaker
          hasn''t yet been updated for AWQ support, but I don''t know for certain.</p>

          <p>Does it show the TGI version number used on Sagemaker?</p>

          '
        raw: 'I see. My tentative guess is that the version of TGI on Sagemaker hasn''t
          yet been updated for AWQ support, but I don''t know for certain.


          Does it show the TGI version number used on Sagemaker?'
        updatedAt: '2023-11-10T08:58:06.572Z'
      numEdits: 0
      reactions: []
    id: 654df09e921f4f1ff4c9f72e
    type: comment
  author: TheBloke
  content: 'I see. My tentative guess is that the version of TGI on Sagemaker hasn''t
    yet been updated for AWQ support, but I don''t know for certain.


    Does it show the TGI version number used on Sagemaker?'
  created_at: 2023-11-10 08:58:06+00:00
  edited: false
  hidden: false
  id: 654df09e921f4f1ff4c9f72e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
      fullname: Archit Bhatia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhatia2
      type: user
    createdAt: '2023-11-10T08:59:40.000Z'
    data:
      edited: true
      editors:
      - abhatia2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6909279823303223
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
          fullname: Archit Bhatia
          isHf: false
          isPro: false
          name: abhatia2
          type: user
        html: '<p>I think this is the version used: [number].dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04</p>

          '
        raw: 'I think this is the version used: [number].dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04

          '
        updatedAt: '2023-11-10T08:59:58.364Z'
      numEdits: 1
      reactions: []
    id: 654df0fc2fdbbde41e7f68b6
    type: comment
  author: abhatia2
  content: 'I think this is the version used: [number].dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04

    '
  created_at: 2023-11-10 08:59:40+00:00
  edited: true
  hidden: false
  id: 654df0fc2fdbbde41e7f68b6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-10T09:03:41.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9903935790061951
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Hmm, that version does have AWQ support.</p>

          <p>In that case I''m afraid I have no idea.</p>

          <p>I''ll do a test with TGI myself shortly</p>

          '
        raw: 'Hmm, that version does have AWQ support.


          In that case I''m afraid I have no idea.


          I''ll do a test with TGI myself shortly'
        updatedAt: '2023-11-10T09:03:41.097Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - abhatia2
    id: 654df1ed6db202b83549a794
    type: comment
  author: TheBloke
  content: 'Hmm, that version does have AWQ support.


    In that case I''m afraid I have no idea.


    I''ll do a test with TGI myself shortly'
  created_at: 2023-11-10 09:03:41+00:00
  edited: false
  hidden: false
  id: 654df1ed6db202b83549a794
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
      fullname: Archit Bhatia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhatia2
      type: user
    createdAt: '2023-11-10T09:09:25.000Z'
    data:
      edited: false
      editors:
      - abhatia2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9498599171638489
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
          fullname: Archit Bhatia
          isHf: false
          isPro: false
          name: abhatia2
          type: user
        html: '<p>Thanks a lot for your response!</p>

          '
        raw: Thanks a lot for your response!
        updatedAt: '2023-11-10T09:09:25.753Z'
      numEdits: 0
      reactions: []
    id: 654df345c9916525ebf73573
    type: comment
  author: abhatia2
  content: Thanks a lot for your response!
  created_at: 2023-11-10 09:09:25+00:00
  edited: false
  hidden: false
  id: 654df345c9916525ebf73573
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-10T09:13:21.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4072524607181549
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p>OK I tested TGI 1.1.0 and it works fine with this model in AWQ.\
          \ So yes it must be a SageMaker specific error - perhaps you can contact\
          \ their support, or raise it on the TGI Github Issues page?</p>\n<p>Logs:</p>\n\
          <pre><code>2023-11-10T09:05:39.522435546Z 2023-11-10T09:05:39.522312Z  INFO\
          \ text_generation_launcher: Args { model_id: \"TheBloke/Llama-2-70B-Chat-AWQ\"\
          , revision: None, validation_workers: 2, sharded: None, num_shard: None,\
          \ quantize: Some(Awq), dtype: None, trust_remote_code: false, max_concurrent_requests:\
          \ 15, max_best_of: 1, max_stop_sequences: 4, max_top_n_tokens: 5, max_input_length:\
          \ 1748, max_total_tokens: 2048, waiting_served_ratio: 1.2, max_batch_prefill_tokens:\
          \ 4096, max_batch_total_tokens: None, max_waiting_tokens: 20, hostname:\
          \ \"8964d39b570b\", port: 80, shard_uds_path: \"/tmp/text-generation-server\"\
          , master_addr: \"localhost\", master_port: 29500, huggingface_hub_cache:\
          \ Some(\"/data\"), weights_cache_override: None, disable_custom_kernels:\
          \ false, cuda_memory_fraction: 1.0, rope_scaling: None, rope_factor: None,\
          \ json_output: false, otlp_endpoint: None, cors_allow_origin: [], watermark_gamma:\
          \ None, watermark_delta: None, ngrok: false, ngrok_authtoken: None, ngrok_edge:\
          \ None, env: false }\n2023-11-10T09:05:39.522544778Z 2023-11-10T09:05:39.522483Z\
          \  INFO download: text_generation_launcher: Starting download process.\n\
          2023-11-10T09:05:42.315068236Z 2023-11-10T09:05:42.314833Z  INFO text_generation_launcher:\
          \ Download file: model-00001-of-00004.safetensors\n2023-11-10T09:05:42.315114540Z\
          \ \n2023-11-10T09:07:15.902265462Z 2023-11-10T09:07:15.902062Z  INFO text_generation_launcher:\
          \ Downloaded /data/models--TheBloke--Llama-2-70B-Chat-AWQ/snapshots/55c2786a75adef2b89bf3157d1517536d817c936/model-00001-of-00004.safetensors\
          \ in 0:01:33.\n2023-11-10T09:07:15.902328389Z \n2023-11-10T09:07:15.902333139Z\
          \ 2023-11-10T09:07:15.902147Z  INFO text_generation_launcher: Download:\
          \ [1/4] -- ETA: 0:04:39\n2023-11-10T09:07:15.902337888Z \n2023-11-10T09:07:15.906472082Z\
          \ 2023-11-10T09:07:15.906342Z  INFO text_generation_launcher: Download file:\
          \ model-00002-of-00004.safetensors\n2023-11-10T09:07:15.906511263Z \n2023-11-10T09:08:47.940922762Z\
          \ 2023-11-10T09:08:47.940757Z  INFO text_generation_launcher: Downloaded\
          \ /data/models--TheBloke--Llama-2-70B-Chat-AWQ/snapshots/55c2786a75adef2b89bf3157d1517536d817c936/model-00002-of-00004.safetensors\
          \ in 0:01:32.\n2023-11-10T09:08:47.940967880Z \n2023-11-10T09:08:47.940973816Z\
          \ 2023-11-10T09:08:47.940843Z  INFO text_generation_launcher: Download:\
          \ [2/4] -- ETA: 0:03:05\n2023-11-10T09:08:47.940978566Z \n2023-11-10T09:08:47.945311040Z\
          \ 2023-11-10T09:08:47.945205Z  INFO text_generation_launcher: Download file:\
          \ model-00003-of-00004.safetensors\n2023-11-10T09:08:47.945330037Z \n2023-11-10T09:10:20.270476788Z\
          \ 2023-11-10T09:10:20.270307Z  INFO text_generation_launcher: Downloaded\
          \ /data/models--TheBloke--Llama-2-70B-Chat-AWQ/snapshots/55c2786a75adef2b89bf3157d1517536d817c936/model-00003-of-00004.safetensors\
          \ in 0:01:32.\n2023-11-10T09:10:20.270514782Z \n2023-11-10T09:10:20.270519531Z\
          \ 2023-11-10T09:10:20.270415Z  INFO text_generation_launcher: Download:\
          \ [3/4] -- ETA: 0:01:32.333333\n2023-11-10T09:10:20.270524280Z \n2023-11-10T09:10:20.274980234Z\
          \ 2023-11-10T09:10:20.274843Z  INFO text_generation_launcher: Download file:\
          \ model-00004-of-00004.safetensors\n2023-11-10T09:10:20.275017040Z \n2023-11-10T09:11:25.412663457Z\
          \ 2023-11-10T09:11:25.412473Z  INFO text_generation_launcher: Downloaded\
          \ /data/models--TheBloke--Llama-2-70B-Chat-AWQ/snapshots/55c2786a75adef2b89bf3157d1517536d817c936/model-00004-of-00004.safetensors\
          \ in 0:01:05.\n2023-11-10T09:11:25.412701450Z \n2023-11-10T09:11:25.412707387Z\
          \ 2023-11-10T09:11:25.412512Z  INFO text_generation_launcher: Download:\
          \ [4/4] -- ETA: 0\n2023-11-10T09:11:25.412714511Z \n2023-11-10T09:11:25.834379766Z\
          \ 2023-11-10T09:11:25.834141Z  INFO download: text_generation_launcher:\
          \ Successfully downloaded weights.\n2023-11-10T09:11:25.834701526Z 2023-11-10T09:11:25.834580Z\
          \  INFO shard-manager: text_generation_launcher: Starting shard rank=0\n\
          2023-11-10T09:11:35.849216024Z 2023-11-10T09:11:35.848950Z  INFO shard-manager:\
          \ text_generation_launcher: Waiting for shard to be ready... rank=0\n2023-11-10T09:11:45.862731998Z\
          \ 2023-11-10T09:11:45.862549Z  INFO shard-manager: text_generation_launcher:\
          \ Waiting for shard to be ready... rank=0\n2023-11-10T09:11:55.876080563Z\
          \ 2023-11-10T09:11:55.875857Z  INFO shard-manager: text_generation_launcher:\
          \ Waiting for shard to be ready... rank=0\n2023-11-10T09:12:05.889716455Z\
          \ 2023-11-10T09:12:05.889505Z  INFO shard-manager: text_generation_launcher:\
          \ Waiting for shard to be ready... rank=0\n2023-11-10T09:12:15.903991117Z\
          \ 2023-11-10T09:12:15.903779Z  INFO shard-manager: text_generation_launcher:\
          \ Waiting for shard to be ready... rank=0\n2023-11-10T09:12:22.123551559Z\
          \ 2023-11-10T09:12:22.123316Z  INFO text_generation_launcher: Server started\
          \ at unix:///tmp/text-generation-server-0\n2023-11-10T09:12:22.123595489Z\
          \ \n2023-11-10T09:12:22.211694670Z 2023-11-10T09:12:22.211527Z  INFO shard-manager:\
          \ text_generation_launcher: Shard ready in 56.375529197s rank=0\n2023-11-10T09:12:22.242591895Z\
          \ 2023-11-10T09:12:22.242378Z  INFO text_generation_launcher: Starting Webserver\n\
          2023-11-10T09:12:22.750219183Z 2023-11-10T09:12:22.749887Z  WARN text_generation_router:\
          \ router/src/main.rs:349: `--revision` is not set\n2023-11-10T09:12:22.750259552Z\
          \ 2023-11-10T09:12:22.749944Z  WARN text_generation_router: router/src/main.rs:350:\
          \ We strongly advise to set it to a known supported commit.\n2023-11-10T09:12:23.139812970Z\
          \ 2023-11-10T09:12:23.139531Z  INFO text_generation_router: router/src/main.rs:371:\
          \ Serving revision <a href=\"/TheBloke/Llama-2-70B-Chat-AWQ/commit/55c2786a75adef2b89bf3157d1517536d817c936\"\
          >55c2786a75adef2b89bf3157d1517536d817c936</a> of model TheBloke/Llama-2-70B-Chat-AWQ\n\
          2023-11-10T09:12:23.146714771Z 2023-11-10T09:12:23.146544Z  INFO text_generation_router:\
          \ router/src/main.rs:213: Warming up model\n2023-11-10T09:12:34.683371443Z\
          \ 2023-11-10T09:12:34.683085Z  INFO text_generation_router: router/src/main.rs:246:\
          \ Setting max batch total tokens to 124880\n2023-11-10T09:12:34.683411812Z\
          \ 2023-11-10T09:12:34.683117Z  INFO text_generation_router: router/src/main.rs:247:\
          \ Connected\n</code></pre>\n"
        raw: "OK I tested TGI 1.1.0 and it works fine with this model in AWQ. So yes\
          \ it must be a SageMaker specific error - perhaps you can contact their\
          \ support, or raise it on the TGI Github Issues page?\n\nLogs:\n```\n2023-11-10T09:05:39.522435546Z\
          \ 2023-11-10T09:05:39.522312Z  INFO text_generation_launcher: Args { model_id:\
          \ \"TheBloke/Llama-2-70B-Chat-AWQ\", revision: None, validation_workers:\
          \ 2, sharded: None, num_shard: None, quantize: Some(Awq), dtype: None, trust_remote_code:\
          \ false, max_concurrent_requests: 15, max_best_of: 1, max_stop_sequences:\
          \ 4, max_top_n_tokens: 5, max_input_length: 1748, max_total_tokens: 2048,\
          \ waiting_served_ratio: 1.2, max_batch_prefill_tokens: 4096, max_batch_total_tokens:\
          \ None, max_waiting_tokens: 20, hostname: \"8964d39b570b\", port: 80, shard_uds_path:\
          \ \"/tmp/text-generation-server\", master_addr: \"localhost\", master_port:\
          \ 29500, huggingface_hub_cache: Some(\"/data\"), weights_cache_override:\
          \ None, disable_custom_kernels: false, cuda_memory_fraction: 1.0, rope_scaling:\
          \ None, rope_factor: None, json_output: false, otlp_endpoint: None, cors_allow_origin:\
          \ [], watermark_gamma: None, watermark_delta: None, ngrok: false, ngrok_authtoken:\
          \ None, ngrok_edge: None, env: false }\n2023-11-10T09:05:39.522544778Z 2023-11-10T09:05:39.522483Z\
          \  INFO download: text_generation_launcher: Starting download process.\n\
          2023-11-10T09:05:42.315068236Z 2023-11-10T09:05:42.314833Z  INFO text_generation_launcher:\
          \ Download file: model-00001-of-00004.safetensors\n2023-11-10T09:05:42.315114540Z\
          \ \n2023-11-10T09:07:15.902265462Z 2023-11-10T09:07:15.902062Z  INFO text_generation_launcher:\
          \ Downloaded /data/models--TheBloke--Llama-2-70B-Chat-AWQ/snapshots/55c2786a75adef2b89bf3157d1517536d817c936/model-00001-of-00004.safetensors\
          \ in 0:01:33.\n2023-11-10T09:07:15.902328389Z \n2023-11-10T09:07:15.902333139Z\
          \ 2023-11-10T09:07:15.902147Z  INFO text_generation_launcher: Download:\
          \ [1/4] -- ETA: 0:04:39\n2023-11-10T09:07:15.902337888Z \n2023-11-10T09:07:15.906472082Z\
          \ 2023-11-10T09:07:15.906342Z  INFO text_generation_launcher: Download file:\
          \ model-00002-of-00004.safetensors\n2023-11-10T09:07:15.906511263Z \n2023-11-10T09:08:47.940922762Z\
          \ 2023-11-10T09:08:47.940757Z  INFO text_generation_launcher: Downloaded\
          \ /data/models--TheBloke--Llama-2-70B-Chat-AWQ/snapshots/55c2786a75adef2b89bf3157d1517536d817c936/model-00002-of-00004.safetensors\
          \ in 0:01:32.\n2023-11-10T09:08:47.940967880Z \n2023-11-10T09:08:47.940973816Z\
          \ 2023-11-10T09:08:47.940843Z  INFO text_generation_launcher: Download:\
          \ [2/4] -- ETA: 0:03:05\n2023-11-10T09:08:47.940978566Z \n2023-11-10T09:08:47.945311040Z\
          \ 2023-11-10T09:08:47.945205Z  INFO text_generation_launcher: Download file:\
          \ model-00003-of-00004.safetensors\n2023-11-10T09:08:47.945330037Z \n2023-11-10T09:10:20.270476788Z\
          \ 2023-11-10T09:10:20.270307Z  INFO text_generation_launcher: Downloaded\
          \ /data/models--TheBloke--Llama-2-70B-Chat-AWQ/snapshots/55c2786a75adef2b89bf3157d1517536d817c936/model-00003-of-00004.safetensors\
          \ in 0:01:32.\n2023-11-10T09:10:20.270514782Z \n2023-11-10T09:10:20.270519531Z\
          \ 2023-11-10T09:10:20.270415Z  INFO text_generation_launcher: Download:\
          \ [3/4] -- ETA: 0:01:32.333333\n2023-11-10T09:10:20.270524280Z \n2023-11-10T09:10:20.274980234Z\
          \ 2023-11-10T09:10:20.274843Z  INFO text_generation_launcher: Download file:\
          \ model-00004-of-00004.safetensors\n2023-11-10T09:10:20.275017040Z \n2023-11-10T09:11:25.412663457Z\
          \ 2023-11-10T09:11:25.412473Z  INFO text_generation_launcher: Downloaded\
          \ /data/models--TheBloke--Llama-2-70B-Chat-AWQ/snapshots/55c2786a75adef2b89bf3157d1517536d817c936/model-00004-of-00004.safetensors\
          \ in 0:01:05.\n2023-11-10T09:11:25.412701450Z \n2023-11-10T09:11:25.412707387Z\
          \ 2023-11-10T09:11:25.412512Z  INFO text_generation_launcher: Download:\
          \ [4/4] -- ETA: 0\n2023-11-10T09:11:25.412714511Z \n2023-11-10T09:11:25.834379766Z\
          \ 2023-11-10T09:11:25.834141Z  INFO download: text_generation_launcher:\
          \ Successfully downloaded weights.\n2023-11-10T09:11:25.834701526Z 2023-11-10T09:11:25.834580Z\
          \  INFO shard-manager: text_generation_launcher: Starting shard rank=0\n\
          2023-11-10T09:11:35.849216024Z 2023-11-10T09:11:35.848950Z  INFO shard-manager:\
          \ text_generation_launcher: Waiting for shard to be ready... rank=0\n2023-11-10T09:11:45.862731998Z\
          \ 2023-11-10T09:11:45.862549Z  INFO shard-manager: text_generation_launcher:\
          \ Waiting for shard to be ready... rank=0\n2023-11-10T09:11:55.876080563Z\
          \ 2023-11-10T09:11:55.875857Z  INFO shard-manager: text_generation_launcher:\
          \ Waiting for shard to be ready... rank=0\n2023-11-10T09:12:05.889716455Z\
          \ 2023-11-10T09:12:05.889505Z  INFO shard-manager: text_generation_launcher:\
          \ Waiting for shard to be ready... rank=0\n2023-11-10T09:12:15.903991117Z\
          \ 2023-11-10T09:12:15.903779Z  INFO shard-manager: text_generation_launcher:\
          \ Waiting for shard to be ready... rank=0\n2023-11-10T09:12:22.123551559Z\
          \ 2023-11-10T09:12:22.123316Z  INFO text_generation_launcher: Server started\
          \ at unix:///tmp/text-generation-server-0\n2023-11-10T09:12:22.123595489Z\
          \ \n2023-11-10T09:12:22.211694670Z 2023-11-10T09:12:22.211527Z  INFO shard-manager:\
          \ text_generation_launcher: Shard ready in 56.375529197s rank=0\n2023-11-10T09:12:22.242591895Z\
          \ 2023-11-10T09:12:22.242378Z  INFO text_generation_launcher: Starting Webserver\n\
          2023-11-10T09:12:22.750219183Z 2023-11-10T09:12:22.749887Z  WARN text_generation_router:\
          \ router/src/main.rs:349: `--revision` is not set\n2023-11-10T09:12:22.750259552Z\
          \ 2023-11-10T09:12:22.749944Z  WARN text_generation_router: router/src/main.rs:350:\
          \ We strongly advise to set it to a known supported commit.\n2023-11-10T09:12:23.139812970Z\
          \ 2023-11-10T09:12:23.139531Z  INFO text_generation_router: router/src/main.rs:371:\
          \ Serving revision 55c2786a75adef2b89bf3157d1517536d817c936 of model TheBloke/Llama-2-70B-Chat-AWQ\n\
          2023-11-10T09:12:23.146714771Z 2023-11-10T09:12:23.146544Z  INFO text_generation_router:\
          \ router/src/main.rs:213: Warming up model\n2023-11-10T09:12:34.683371443Z\
          \ 2023-11-10T09:12:34.683085Z  INFO text_generation_router: router/src/main.rs:246:\
          \ Setting max batch total tokens to 124880\n2023-11-10T09:12:34.683411812Z\
          \ 2023-11-10T09:12:34.683117Z  INFO text_generation_router: router/src/main.rs:247:\
          \ Connected\n```"
        updatedAt: '2023-11-10T09:13:43.127Z'
      numEdits: 1
      reactions: []
    id: 654df43171a30c4bca1b8725
    type: comment
  author: TheBloke
  content: "OK I tested TGI 1.1.0 and it works fine with this model in AWQ. So yes\
    \ it must be a SageMaker specific error - perhaps you can contact their support,\
    \ or raise it on the TGI Github Issues page?\n\nLogs:\n```\n2023-11-10T09:05:39.522435546Z\
    \ 2023-11-10T09:05:39.522312Z  INFO text_generation_launcher: Args { model_id:\
    \ \"TheBloke/Llama-2-70B-Chat-AWQ\", revision: None, validation_workers: 2, sharded:\
    \ None, num_shard: None, quantize: Some(Awq), dtype: None, trust_remote_code:\
    \ false, max_concurrent_requests: 15, max_best_of: 1, max_stop_sequences: 4, max_top_n_tokens:\
    \ 5, max_input_length: 1748, max_total_tokens: 2048, waiting_served_ratio: 1.2,\
    \ max_batch_prefill_tokens: 4096, max_batch_total_tokens: None, max_waiting_tokens:\
    \ 20, hostname: \"8964d39b570b\", port: 80, shard_uds_path: \"/tmp/text-generation-server\"\
    , master_addr: \"localhost\", master_port: 29500, huggingface_hub_cache: Some(\"\
    /data\"), weights_cache_override: None, disable_custom_kernels: false, cuda_memory_fraction:\
    \ 1.0, rope_scaling: None, rope_factor: None, json_output: false, otlp_endpoint:\
    \ None, cors_allow_origin: [], watermark_gamma: None, watermark_delta: None, ngrok:\
    \ false, ngrok_authtoken: None, ngrok_edge: None, env: false }\n2023-11-10T09:05:39.522544778Z\
    \ 2023-11-10T09:05:39.522483Z  INFO download: text_generation_launcher: Starting\
    \ download process.\n2023-11-10T09:05:42.315068236Z 2023-11-10T09:05:42.314833Z\
    \  INFO text_generation_launcher: Download file: model-00001-of-00004.safetensors\n\
    2023-11-10T09:05:42.315114540Z \n2023-11-10T09:07:15.902265462Z 2023-11-10T09:07:15.902062Z\
    \  INFO text_generation_launcher: Downloaded /data/models--TheBloke--Llama-2-70B-Chat-AWQ/snapshots/55c2786a75adef2b89bf3157d1517536d817c936/model-00001-of-00004.safetensors\
    \ in 0:01:33.\n2023-11-10T09:07:15.902328389Z \n2023-11-10T09:07:15.902333139Z\
    \ 2023-11-10T09:07:15.902147Z  INFO text_generation_launcher: Download: [1/4]\
    \ -- ETA: 0:04:39\n2023-11-10T09:07:15.902337888Z \n2023-11-10T09:07:15.906472082Z\
    \ 2023-11-10T09:07:15.906342Z  INFO text_generation_launcher: Download file: model-00002-of-00004.safetensors\n\
    2023-11-10T09:07:15.906511263Z \n2023-11-10T09:08:47.940922762Z 2023-11-10T09:08:47.940757Z\
    \  INFO text_generation_launcher: Downloaded /data/models--TheBloke--Llama-2-70B-Chat-AWQ/snapshots/55c2786a75adef2b89bf3157d1517536d817c936/model-00002-of-00004.safetensors\
    \ in 0:01:32.\n2023-11-10T09:08:47.940967880Z \n2023-11-10T09:08:47.940973816Z\
    \ 2023-11-10T09:08:47.940843Z  INFO text_generation_launcher: Download: [2/4]\
    \ -- ETA: 0:03:05\n2023-11-10T09:08:47.940978566Z \n2023-11-10T09:08:47.945311040Z\
    \ 2023-11-10T09:08:47.945205Z  INFO text_generation_launcher: Download file: model-00003-of-00004.safetensors\n\
    2023-11-10T09:08:47.945330037Z \n2023-11-10T09:10:20.270476788Z 2023-11-10T09:10:20.270307Z\
    \  INFO text_generation_launcher: Downloaded /data/models--TheBloke--Llama-2-70B-Chat-AWQ/snapshots/55c2786a75adef2b89bf3157d1517536d817c936/model-00003-of-00004.safetensors\
    \ in 0:01:32.\n2023-11-10T09:10:20.270514782Z \n2023-11-10T09:10:20.270519531Z\
    \ 2023-11-10T09:10:20.270415Z  INFO text_generation_launcher: Download: [3/4]\
    \ -- ETA: 0:01:32.333333\n2023-11-10T09:10:20.270524280Z \n2023-11-10T09:10:20.274980234Z\
    \ 2023-11-10T09:10:20.274843Z  INFO text_generation_launcher: Download file: model-00004-of-00004.safetensors\n\
    2023-11-10T09:10:20.275017040Z \n2023-11-10T09:11:25.412663457Z 2023-11-10T09:11:25.412473Z\
    \  INFO text_generation_launcher: Downloaded /data/models--TheBloke--Llama-2-70B-Chat-AWQ/snapshots/55c2786a75adef2b89bf3157d1517536d817c936/model-00004-of-00004.safetensors\
    \ in 0:01:05.\n2023-11-10T09:11:25.412701450Z \n2023-11-10T09:11:25.412707387Z\
    \ 2023-11-10T09:11:25.412512Z  INFO text_generation_launcher: Download: [4/4]\
    \ -- ETA: 0\n2023-11-10T09:11:25.412714511Z \n2023-11-10T09:11:25.834379766Z 2023-11-10T09:11:25.834141Z\
    \  INFO download: text_generation_launcher: Successfully downloaded weights.\n\
    2023-11-10T09:11:25.834701526Z 2023-11-10T09:11:25.834580Z  INFO shard-manager:\
    \ text_generation_launcher: Starting shard rank=0\n2023-11-10T09:11:35.849216024Z\
    \ 2023-11-10T09:11:35.848950Z  INFO shard-manager: text_generation_launcher: Waiting\
    \ for shard to be ready... rank=0\n2023-11-10T09:11:45.862731998Z 2023-11-10T09:11:45.862549Z\
    \  INFO shard-manager: text_generation_launcher: Waiting for shard to be ready...\
    \ rank=0\n2023-11-10T09:11:55.876080563Z 2023-11-10T09:11:55.875857Z  INFO shard-manager:\
    \ text_generation_launcher: Waiting for shard to be ready... rank=0\n2023-11-10T09:12:05.889716455Z\
    \ 2023-11-10T09:12:05.889505Z  INFO shard-manager: text_generation_launcher: Waiting\
    \ for shard to be ready... rank=0\n2023-11-10T09:12:15.903991117Z 2023-11-10T09:12:15.903779Z\
    \  INFO shard-manager: text_generation_launcher: Waiting for shard to be ready...\
    \ rank=0\n2023-11-10T09:12:22.123551559Z 2023-11-10T09:12:22.123316Z  INFO text_generation_launcher:\
    \ Server started at unix:///tmp/text-generation-server-0\n2023-11-10T09:12:22.123595489Z\
    \ \n2023-11-10T09:12:22.211694670Z 2023-11-10T09:12:22.211527Z  INFO shard-manager:\
    \ text_generation_launcher: Shard ready in 56.375529197s rank=0\n2023-11-10T09:12:22.242591895Z\
    \ 2023-11-10T09:12:22.242378Z  INFO text_generation_launcher: Starting Webserver\n\
    2023-11-10T09:12:22.750219183Z 2023-11-10T09:12:22.749887Z  WARN text_generation_router:\
    \ router/src/main.rs:349: `--revision` is not set\n2023-11-10T09:12:22.750259552Z\
    \ 2023-11-10T09:12:22.749944Z  WARN text_generation_router: router/src/main.rs:350:\
    \ We strongly advise to set it to a known supported commit.\n2023-11-10T09:12:23.139812970Z\
    \ 2023-11-10T09:12:23.139531Z  INFO text_generation_router: router/src/main.rs:371:\
    \ Serving revision 55c2786a75adef2b89bf3157d1517536d817c936 of model TheBloke/Llama-2-70B-Chat-AWQ\n\
    2023-11-10T09:12:23.146714771Z 2023-11-10T09:12:23.146544Z  INFO text_generation_router:\
    \ router/src/main.rs:213: Warming up model\n2023-11-10T09:12:34.683371443Z 2023-11-10T09:12:34.683085Z\
    \  INFO text_generation_router: router/src/main.rs:246: Setting max batch total\
    \ tokens to 124880\n2023-11-10T09:12:34.683411812Z 2023-11-10T09:12:34.683117Z\
    \  INFO text_generation_router: router/src/main.rs:247: Connected\n```"
  created_at: 2023-11-10 09:13:21+00:00
  edited: true
  hidden: false
  id: 654df43171a30c4bca1b8725
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
      fullname: Archit Bhatia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhatia2
      type: user
    createdAt: '2023-11-10T09:22:09.000Z'
    data:
      edited: false
      editors:
      - abhatia2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9686996936798096
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
          fullname: Archit Bhatia
          isHf: false
          isPro: false
          name: abhatia2
          type: user
        html: '<p>Sure would raise it there, thanks for checking.</p>

          <p>One clarification, what does this mean:- " quantize: Some(Awq) "<br>What
          value exactly did you set here, I can probably try using the same</p>

          '
        raw: 'Sure would raise it there, thanks for checking.


          One clarification, what does this mean:- " quantize: Some(Awq) "

          What value exactly did you set here, I can probably try using the same'
        updatedAt: '2023-11-10T09:22:09.987Z'
      numEdits: 0
      reactions: []
    id: 654df641f3c69b38d5b08dc9
    type: comment
  author: abhatia2
  content: 'Sure would raise it there, thanks for checking.


    One clarification, what does this mean:- " quantize: Some(Awq) "

    What value exactly did you set here, I can probably try using the same'
  created_at: 2023-11-10 09:22:09+00:00
  edited: false
  hidden: false
  id: 654df641f3c69b38d5b08dc9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-10T09:23:15.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7746286392211914
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>That''s just how it shows the parameters, a bit weird - they''re
          tagged either <code>None</code> or <code>Some(value)</code></p>

          <p>I set <code>--quantize awq</code></p>

          '
        raw: 'That''s just how it shows the parameters, a bit weird - they''re tagged
          either `None` or `Some(value)`


          I set `--quantize awq`'
        updatedAt: '2023-11-10T09:23:15.859Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - abhatia2
        - omarelshehy
    id: 654df6834caca6080b0102ab
    type: comment
  author: TheBloke
  content: 'That''s just how it shows the parameters, a bit weird - they''re tagged
    either `None` or `Some(value)`


    I set `--quantize awq`'
  created_at: 2023-11-10 09:23:15+00:00
  edited: false
  hidden: false
  id: 654df6834caca6080b0102ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
      fullname: Archit Bhatia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhatia2
      type: user
    createdAt: '2023-11-23T09:58:50.000Z'
    data:
      edited: false
      editors:
      - abhatia2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9621244072914124
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
          fullname: Archit Bhatia
          isHf: false
          isPro: false
          name: abhatia2
          type: user
        html: '<p>Update: The error was indeed from the AWS side.<br>The workaround
          to get it deployed was to use a HF TGI image directly instead of the sagemaker
          one</p>

          '
        raw: 'Update: The error was indeed from the AWS side.

          The workaround to get it deployed was to use a HF TGI image directly instead
          of the sagemaker one'
        updatedAt: '2023-11-23T09:58:50.178Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - omarelshehy
    id: 655f225aabb296623a36763e
    type: comment
  author: abhatia2
  content: 'Update: The error was indeed from the AWS side.

    The workaround to get it deployed was to use a HF TGI image directly instead of
    the sagemaker one'
  created_at: 2023-11-23 09:58:50+00:00
  edited: false
  hidden: false
  id: 655f225aabb296623a36763e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1547437451c7accb87e6e7f823b3a0e6.svg
      fullname: Omar Elshehy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: omarelshehy
      type: user
    createdAt: '2023-11-25T02:12:58.000Z'
    data:
      edited: false
      editors:
      - omarelshehy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8732725381851196
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1547437451c7accb87e6e7f823b3a0e6.svg
          fullname: Omar Elshehy
          isHf: false
          isPro: false
          name: omarelshehy
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;abhatia2&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/abhatia2\">@<span class=\"\
          underline\">abhatia2</span></a></span>\n\n\t</span></span> could you please\
          \ elaborate more on how you used the image directly ? I am interested in\
          \ the same use case </p>\n"
        raw: '@abhatia2 could you please elaborate more on how you used the image
          directly ? I am interested in the same use case '
        updatedAt: '2023-11-25T02:12:58.363Z'
      numEdits: 0
      reactions: []
    id: 6561582af231380a6cd14130
    type: comment
  author: omarelshehy
  content: '@abhatia2 could you please elaborate more on how you used the image directly
    ? I am interested in the same use case '
  created_at: 2023-11-25 02:12:58+00:00
  edited: false
  hidden: false
  id: 6561582af231380a6cd14130
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
      fullname: Archit Bhatia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhatia2
      type: user
    createdAt: '2023-11-27T07:24:01.000Z'
    data:
      edited: true
      editors:
      - abhatia2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6778252124786377
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bff4ca0786b26654d7a02fec79848832.svg
          fullname: Archit Bhatia
          isHf: false
          isPro: false
          name: abhatia2
          type: user
        html: '<p>You can build a docker image of TGI version 1.1.0 locally and push
          it to ECR.<br>Then that can be used while deploying the sagemaker endpoint</p>

          <p>Something like this:</p>

          <p>huggingface_model = HuggingFaceModel(<br>    image_uri=custom_image_uri,<br>    env=hub,<br>    role=role,<br>)<br>Also
          make sure you''re setting this parameter: ''HF_MODEL_QUANTIZE'': ''awq''</p>

          '
        raw: "You can build a docker image of TGI version 1.1.0 locally and push it\
          \ to ECR.\nThen that can be used while deploying the sagemaker endpoint\n\
          \nSomething like this:\n\nhuggingface_model = HuggingFaceModel(\n\timage_uri=custom_image_uri,\n\
          \tenv=hub,\n\trole=role, \n)\nAlso make sure you're setting this parameter:\
          \ 'HF_MODEL_QUANTIZE': 'awq'"
        updatedAt: '2023-11-27T07:24:56.852Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - omarelshehy
    id: 656444112d309fa7e2db0f53
    type: comment
  author: abhatia2
  content: "You can build a docker image of TGI version 1.1.0 locally and push it\
    \ to ECR.\nThen that can be used while deploying the sagemaker endpoint\n\nSomething\
    \ like this:\n\nhuggingface_model = HuggingFaceModel(\n\timage_uri=custom_image_uri,\n\
    \tenv=hub,\n\trole=role, \n)\nAlso make sure you're setting this parameter: 'HF_MODEL_QUANTIZE':\
    \ 'awq'"
  created_at: 2023-11-27 07:24:01+00:00
  edited: true
  hidden: false
  id: 656444112d309fa7e2db0f53
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1547437451c7accb87e6e7f823b3a0e6.svg
      fullname: Omar Elshehy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: omarelshehy
      type: user
    createdAt: '2023-11-28T13:38:52.000Z'
    data:
      edited: false
      editors:
      - omarelshehy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9776483178138733
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1547437451c7accb87e6e7f823b3a0e6.svg
          fullname: Omar Elshehy
          isHf: false
          isPro: false
          name: omarelshehy
          type: user
        html: '<p>Thank you very much. I will definetly do that :) </p>

          '
        raw: "Thank you very much. I will definetly do that :) \n"
        updatedAt: '2023-11-28T13:38:52.502Z'
      numEdits: 0
      reactions: []
    id: 6565ed6ce320894e09d489b3
    type: comment
  author: omarelshehy
  content: "Thank you very much. I will definetly do that :) \n"
  created_at: 2023-11-28 13:38:52+00:00
  edited: false
  hidden: false
  id: 6565ed6ce320894e09d489b3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/Llama-2-70B-Chat-AWQ
repo_type: model
status: open
target_branch: null
title: Deployment via Sagemaker
