!!python/object:huggingface_hub.community.DiscussionWithDetails
author: krumeto
conflicting_files: null
created_at: 2023-11-14 07:20:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e55253efd9dab60819257255e2dd959d.svg
      fullname: Krum Arnaudov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: krumeto
      type: user
    createdAt: '2023-11-14T07:20:04.000Z'
    data:
      edited: false
      editors:
      - krumeto
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9653589129447937
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e55253efd9dab60819257255e2dd959d.svg
          fullname: Krum Arnaudov
          isHf: false
          isPro: false
          name: krumeto
          type: user
        html: "<p>I know AWQ is expected to be faster with similar quality to GPTQ,\
          \ but reading through TGI issues, folks report similar latency. At the same\
          \ time, there is only one AWQ on the  LLM Leaderboard (TheBloke/Llama-2-7b-Chat-AWQ)\
          \ and its score is (way) lower compared to (TheBloke/Llama-2-7B-GPTQ) (I\
          \ know the base models are different, but it was the closest I could find).</p>\n\
          <p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> do you happen\
          \ to have a quality and/or latency experience of AWQ vs. GPTQ? Any insights\
          \ would be helpful.</p>\n<p>Thank you in advance!</p>\n"
        raw: "I know AWQ is expected to be faster with similar quality to GPTQ, but\
          \ reading through TGI issues, folks report similar latency. At the same\
          \ time, there is only one AWQ on the  LLM Leaderboard (TheBloke/Llama-2-7b-Chat-AWQ)\
          \ and its score is (way) lower compared to (TheBloke/Llama-2-7B-GPTQ) (I\
          \ know the base models are different, but it was the closest I could find).\r\
          \n\r\n@TheBloke do you happen to have a quality and/or latency experience\
          \ of AWQ vs. GPTQ? Any insights would be helpful.\r\n\r\nThank you in advance!"
        updatedAt: '2023-11-14T07:20:04.619Z'
      numEdits: 0
      reactions: []
    id: 65531fa49fa2f7205a2c84e7
    type: comment
  author: krumeto
  content: "I know AWQ is expected to be faster with similar quality to GPTQ, but\
    \ reading through TGI issues, folks report similar latency. At the same time,\
    \ there is only one AWQ on the  LLM Leaderboard (TheBloke/Llama-2-7b-Chat-AWQ)\
    \ and its score is (way) lower compared to (TheBloke/Llama-2-7B-GPTQ) (I know\
    \ the base models are different, but it was the closest I could find).\r\n\r\n\
    @TheBloke do you happen to have a quality and/or latency experience of AWQ vs.\
    \ GPTQ? Any insights would be helpful.\r\n\r\nThank you in advance!"
  created_at: 2023-11-14 07:20:04+00:00
  edited: false
  hidden: false
  id: 65531fa49fa2f7205a2c84e7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
      fullname: Yatharth  Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YaTharThShaRma999
      type: user
    createdAt: '2023-11-14T12:09:52.000Z'
    data:
      edited: false
      editors:
      - YaTharThShaRma999
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9397670030593872
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
          fullname: Yatharth  Sharma
          isHf: false
          isPro: false
          name: YaTharThShaRma999
          type: user
        html: "<p>Awq has higher latency but it\u2019s really good for using with\
          \ vllm or tgi and batching. You can get extremely fast speeds and multiple\
          \ responses.</p>\n<p>However exllama v2 with gptq is still considerably\
          \ faster  then vllm in a single response but if you want multiple responses,\
          \ use vllm + awq</p>\n"
        raw: "Awq has higher latency but it\u2019s really good for using with vllm\
          \ or tgi and batching. You can get extremely fast speeds and multiple responses.\n\
          \nHowever exllama v2 with gptq is still considerably faster  then vllm in\
          \ a single response but if you want multiple responses, use vllm + awq"
        updatedAt: '2023-11-14T12:09:52.013Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - krumeto
        - Yhyu13
        - CobraMamba
    id: 655363908fdfd1bff6f071ec
    type: comment
  author: YaTharThShaRma999
  content: "Awq has higher latency but it\u2019s really good for using with vllm or\
    \ tgi and batching. You can get extremely fast speeds and multiple responses.\n\
    \nHowever exllama v2 with gptq is still considerably faster  then vllm in a single\
    \ response but if you want multiple responses, use vllm + awq"
  created_at: 2023-11-14 12:09:52+00:00
  edited: false
  hidden: false
  id: 655363908fdfd1bff6f071ec
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/Llama-2-70B-Chat-AWQ
repo_type: model
status: open
target_branch: null
title: Performance and latency vs. GPTQ
