!!python/object:huggingface_hub.community.DiscussionWithDetails
author: desu24
conflicting_files: null
created_at: 2023-04-28 10:16:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/OOyn6GExI-AHYy9bDCfWR.png?w=200&h=200&f=face
      fullname: machina
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: desu24
      type: user
    createdAt: '2023-04-28T11:16:41.000Z'
    data:
      edited: false
      editors:
      - desu24
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/OOyn6GExI-AHYy9bDCfWR.png?w=200&h=200&f=face
          fullname: machina
          isHf: false
          isPro: false
          name: desu24
          type: user
        html: '<p>Loading wizardLM-7B-GPTQ-4bit-128g...<br>Can''t determine model
          type from model name. Please specify it manually using --model_type argument</p>

          <p>This the error Loading the model, Anyone knows how to fix this? </p>

          '
        raw: "Loading wizardLM-7B-GPTQ-4bit-128g...\r\nCan't determine model type\
          \ from model name. Please specify it manually using --model_type argument\r\
          \n\r\nThis the error Loading the model, Anyone knows how to fix this? "
        updatedAt: '2023-04-28T11:16:41.511Z'
      numEdits: 0
      reactions: []
    id: 644bab199ca7117968e7d4cc
    type: comment
  author: desu24
  content: "Loading wizardLM-7B-GPTQ-4bit-128g...\r\nCan't determine model type from\
    \ model name. Please specify it manually using --model_type argument\r\n\r\nThis\
    \ the error Loading the model, Anyone knows how to fix this? "
  created_at: 2023-04-28 10:16:41+00:00
  edited: false
  hidden: false
  id: 644bab199ca7117968e7d4cc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/679ebee0fd041f2c230f09434b6721fa.svg
      fullname: W
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ware
      type: user
    createdAt: '2023-04-28T11:46:12.000Z'
    data:
      edited: false
      editors:
      - Ware
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/679ebee0fd041f2c230f09434b6721fa.svg
          fullname: W
          isHf: false
          isPro: false
          name: Ware
          type: user
        html: '<p>Try:<br>cd text-generation-webui<br>python server.py --model wizardLM-7B-GPTQ
          --wbits 4 --groupsize 128 --model_type Llama </p>

          <p>It''s in the ''Model card'' section<br><a href="https://huggingface.co/TheBloke/wizardLM-7B-GPTQ#:~:text=python%20server.py%20%2D%2Dmodel%20wizardLM%2D7B%2DGPTQ%20%2D%2Dwbits%204%20%2D%2Dgroupsize%20128%20%2D%2Dmodel_type%20Llama">https://huggingface.co/TheBloke/wizardLM-7B-GPTQ#:~:text=python%20server.py%20%2D%2Dmodel%20wizardLM%2D7B%2DGPTQ%20%2D%2Dwbits%204%20%2D%2Dgroupsize%20128%20%2D%2Dmodel_type%20Llama</a></p>

          '
        raw: "Try:\ncd text-generation-webui\npython server.py --model wizardLM-7B-GPTQ\
          \ --wbits 4 --groupsize 128 --model_type Llama \n\nIt's in the 'Model card'\
          \ section\nhttps://huggingface.co/TheBloke/wizardLM-7B-GPTQ#:~:text=python%20server.py%20%2D%2Dmodel%20wizardLM%2D7B%2DGPTQ%20%2D%2Dwbits%204%20%2D%2Dgroupsize%20128%20%2D%2Dmodel_type%20Llama"
        updatedAt: '2023-04-28T11:46:12.109Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TheBloke
    id: 644bb2046586065501e61c36
    type: comment
  author: Ware
  content: "Try:\ncd text-generation-webui\npython server.py --model wizardLM-7B-GPTQ\
    \ --wbits 4 --groupsize 128 --model_type Llama \n\nIt's in the 'Model card' section\n\
    https://huggingface.co/TheBloke/wizardLM-7B-GPTQ#:~:text=python%20server.py%20%2D%2Dmodel%20wizardLM%2D7B%2DGPTQ%20%2D%2Dwbits%204%20%2D%2Dgroupsize%20128%20%2D%2Dmodel_type%20Llama"
  created_at: 2023-04-28 10:46:12+00:00
  edited: false
  hidden: false
  id: 644bb2046586065501e61c36
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-28T13:26:35.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Ware&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Ware\">@<span class=\"\
          underline\">Ware</span></a></span>\n\n\t</span></span> is correct</p>\n\
          <p>You can also specify this inside text-generation-webui: Go to the Models\
          \ tab, fill out model_type on the right, then click \"Reload model\":</p>\n\
          <p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/Q9EoXkhFQUzC4P20rhFN1.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/Q9EoXkhFQUzC4P20rhFN1.png\"\
          ></a></p>\n"
        raw: '@Ware is correct


          You can also specify this inside text-generation-webui: Go to the Models
          tab, fill out model_type on the right, then click "Reload model":


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/Q9EoXkhFQUzC4P20rhFN1.png)


          '
        updatedAt: '2023-04-28T13:26:35.461Z'
      numEdits: 0
      reactions: []
      relatedEventId: 644bc98b1052ba8699d7ef87
    id: 644bc98b1052ba8699d7ef86
    type: comment
  author: TheBloke
  content: '@Ware is correct


    You can also specify this inside text-generation-webui: Go to the Models tab,
    fill out model_type on the right, then click "Reload model":


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/Q9EoXkhFQUzC4P20rhFN1.png)


    '
  created_at: 2023-04-28 12:26:35+00:00
  edited: false
  hidden: false
  id: 644bc98b1052ba8699d7ef86
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-28T13:26:35.000Z'
    data:
      status: closed
    id: 644bc98b1052ba8699d7ef87
    type: status-change
  author: TheBloke
  created_at: 2023-04-28 12:26:35+00:00
  id: 644bc98b1052ba8699d7ef87
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: TheBloke/wizardLM-7B-GPTQ
repo_type: model
status: closed
target_branch: null
title: ' Can''t determine model type from model name. Please specify it manually using
  --model_type argument'
