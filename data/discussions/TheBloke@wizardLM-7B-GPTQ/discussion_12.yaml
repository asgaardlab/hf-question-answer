!!python/object:huggingface_hub.community.DiscussionWithDetails
author: chouaibmeramria
conflicting_files: null
created_at: 2023-04-30 05:25:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/95771bfa63ccafdfbf30b5f3e4e2fa2e.svg
      fullname: chouaib meramria
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chouaibmeramria
      type: user
    createdAt: '2023-04-30T06:25:56.000Z'
    data:
      edited: false
      editors:
      - chouaibmeramria
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/95771bfa63ccafdfbf30b5f3e4e2fa2e.svg
          fullname: chouaib meramria
          isHf: false
          isPro: false
          name: chouaibmeramria
          type: user
        html: '<p>after model download i get this message </p>

          <p>Can''t determine model type from model name. Please specify it manually
          using --model_type argument<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/63f060d84a788ed1dd8aa531/QXeRtW_E--3LPR07ONSd2.png"><img
          alt="Screenshot 2023-04-30 142540.png" src="https://cdn-uploads.huggingface.co/production/uploads/63f060d84a788ed1dd8aa531/QXeRtW_E--3LPR07ONSd2.png"></a></p>

          '
        raw: "after model download i get this message \r\n\r\nCan't determine model\
          \ type from model name. Please specify it manually using --model_type argument\r\
          \n![Screenshot 2023-04-30 142540.png](https://cdn-uploads.huggingface.co/production/uploads/63f060d84a788ed1dd8aa531/QXeRtW_E--3LPR07ONSd2.png)\r\
          \n"
        updatedAt: '2023-04-30T06:25:56.952Z'
      numEdits: 0
      reactions: []
    id: 644e09f4a8f384abd034356d
    type: comment
  author: chouaibmeramria
  content: "after model download i get this message \r\n\r\nCan't determine model\
    \ type from model name. Please specify it manually using --model_type argument\r\
    \n![Screenshot 2023-04-30 142540.png](https://cdn-uploads.huggingface.co/production/uploads/63f060d84a788ed1dd8aa531/QXeRtW_E--3LPR07ONSd2.png)\r\
    \n"
  created_at: 2023-04-30 05:25:56+00:00
  edited: false
  hidden: false
  id: 644e09f4a8f384abd034356d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-30T07:40:32.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>So did you specify the model type in the GPTQ settings?</p>

          <p>Try following my easy install instructions. I think it''s step 8 you''re
          not doing fully.</p>

          <h2 id="how-to-easily-download-and-use-this-model-in-text-generation-webui">How
          to easily download and use this model in text-generation-webui</h2>

          <p>Open the text-generation-webui UI as normal.</p>

          <ol>

          <li>Click the <strong>Model tab</strong>.</li>

          <li>Under <strong>Download custom model or LoRA</strong>, enter <code>TheBloke/wizardLM-7B-GPTQ</code>.</li>

          <li>Click <strong>Download</strong>.</li>

          <li>Wait until it says it''s finished downloading.</li>

          <li>Click the <strong>Refresh</strong> icon next to <strong>Model</strong>
          in the top left.</li>

          <li>In the <strong>Model drop-down</strong>: choose the model you just downloaded,<code>wizardLM-7B-GPTQg</code>.</li>

          <li>If you see an error in the bottom right, ignore it - it''s temporary.</li>

          <li>Fill out the <code>GPTQ parameters</code> on the right: <code>Bits =
          4</code>, <code>Groupsize = 128</code>, <code>model_type = Llama</code></li>

          <li>Click <strong>Save settings for this model</strong> in the top right.</li>

          <li>Click <strong>Reload the Model</strong> in the top right.</li>

          <li>Once it says it''s loaded, click the <strong>Text Generation tab</strong>
          and enter a prompt!</li>

          </ol>

          '
        raw: 'So did you specify the model type in the GPTQ settings?


          Try following my easy install instructions. I think it''s step 8 you''re
          not doing fully.


          ## How to easily download and use this model in text-generation-webui


          Open the text-generation-webui UI as normal.


          1. Click the **Model tab**.

          2. Under **Download custom model or LoRA**, enter `TheBloke/wizardLM-7B-GPTQ`.

          3. Click **Download**.

          4. Wait until it says it''s finished downloading.

          5. Click the **Refresh** icon next to **Model** in the top left.

          6. In the **Model drop-down**: choose the model you just downloaded,`wizardLM-7B-GPTQg`.

          7. If you see an error in the bottom right, ignore it - it''s temporary.

          8. Fill out the `GPTQ parameters` on the right: `Bits = 4`, `Groupsize =
          128`, `model_type = Llama`

          9. Click **Save settings for this model** in the top right.

          10. Click **Reload the Model** in the top right.

          11. Once it says it''s loaded, click the **Text Generation tab** and enter
          a prompt!'
        updatedAt: '2023-04-30T07:40:32.475Z'
      numEdits: 0
      reactions: []
    id: 644e1b70cf72e60a5b7219e1
    type: comment
  author: TheBloke
  content: 'So did you specify the model type in the GPTQ settings?


    Try following my easy install instructions. I think it''s step 8 you''re not doing
    fully.


    ## How to easily download and use this model in text-generation-webui


    Open the text-generation-webui UI as normal.


    1. Click the **Model tab**.

    2. Under **Download custom model or LoRA**, enter `TheBloke/wizardLM-7B-GPTQ`.

    3. Click **Download**.

    4. Wait until it says it''s finished downloading.

    5. Click the **Refresh** icon next to **Model** in the top left.

    6. In the **Model drop-down**: choose the model you just downloaded,`wizardLM-7B-GPTQg`.

    7. If you see an error in the bottom right, ignore it - it''s temporary.

    8. Fill out the `GPTQ parameters` on the right: `Bits = 4`, `Groupsize = 128`,
    `model_type = Llama`

    9. Click **Save settings for this model** in the top right.

    10. Click **Reload the Model** in the top right.

    11. Once it says it''s loaded, click the **Text Generation tab** and enter a prompt!'
  created_at: 2023-04-30 06:40:32+00:00
  edited: false
  hidden: false
  id: 644e1b70cf72e60a5b7219e1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: TheBloke/wizardLM-7B-GPTQ
repo_type: model
status: open
target_branch: null
title: Can't determine model type from model name. Please specify it manually using
  --model_type argument
