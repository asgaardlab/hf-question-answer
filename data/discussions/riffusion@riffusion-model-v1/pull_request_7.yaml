!!python/object:huggingface_hub.community.DiscussionWithDetails
author: clembeetlebaby
conflicting_files: []
created_at: 2022-12-16 17:07:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665662624016-noauth.jpeg?w=200&h=200&f=face
      fullname: clementine whitewind
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: clembeetlebaby
      type: user
    createdAt: '2022-12-16T17:07:10.000Z'
    data:
      edited: false
      editors:
      - clembeetlebaby
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665662624016-noauth.jpeg?w=200&h=200&f=face
          fullname: clementine whitewind
          isHf: false
          isPro: false
          name: clembeetlebaby
          type: user
        html: '<p>Just a pruned .ckpt of the model, for ease of use.</p>

          '
        raw: Just a pruned .ckpt of the model, for ease of use.
        updatedAt: '2022-12-16T17:07:10.080Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - kunfukedisi
        - breadlicker45
    id: 639ca5be9e1c02384ee61041
    type: comment
  author: clembeetlebaby
  content: Just a pruned .ckpt of the model, for ease of use.
  created_at: 2022-12-16 17:07:10+00:00
  edited: false
  hidden: false
  id: 639ca5be9e1c02384ee61041
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665662624016-noauth.jpeg?w=200&h=200&f=face
      fullname: clementine whitewind
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: clembeetlebaby
      type: user
    createdAt: '2022-12-16T17:07:10.000Z'
    data:
      oid: f0268ef7a8a4d24f276fcc0e1ae375a497cc7251
      parents:
      - 7fe045dd4d4a91cd0544100fa1775a6f3ffb0c31
      subject: Upload riffusion-model-v1-pruned.ckpt
    id: 639ca5be0000000000000000
    type: commit
  author: clembeetlebaby
  created_at: 2022-12-16 17:07:10+00:00
  id: 639ca5be0000000000000000
  oid: f0268ef7a8a4d24f276fcc0e1ae375a497cc7251
  summary: Upload riffusion-model-v1-pruned.ckpt
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2c358104a9c649d0f065c6ccbc686fc9.svg
      fullname: neb
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nebsh
      type: user
    createdAt: '2022-12-17T11:09:11.000Z'
    data:
      edited: false
      editors:
      - Nebsh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2c358104a9c649d0f065c6ccbc686fc9.svg
          fullname: neb
          isHf: false
          isPro: false
          name: Nebsh
          type: user
        html: '<p>how to use localy ?</p>

          '
        raw: how to use localy ?
        updatedAt: '2022-12-17T11:09:11.911Z'
      numEdits: 0
      reactions: []
    id: 639da3577145123e0d463ca2
    type: comment
  author: Nebsh
  content: how to use localy ?
  created_at: 2022-12-17 11:09:11+00:00
  edited: false
  hidden: false
  id: 639da3577145123e0d463ca2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665662624016-noauth.jpeg?w=200&h=200&f=face
      fullname: clementine whitewind
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: clembeetlebaby
      type: user
    createdAt: '2022-12-18T03:13:51.000Z'
    data:
      edited: false
      editors:
      - clembeetlebaby
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665662624016-noauth.jpeg?w=200&h=200&f=face
          fullname: clementine whitewind
          isHf: false
          isPro: false
          name: clembeetlebaby
          type: user
        html: '<p>I use it in voldys sd web-ui</p>

          '
        raw: I use it in voldys sd web-ui
        updatedAt: '2022-12-18T03:13:51.065Z'
      numEdits: 0
      reactions: []
    id: 639e856ff87da5e2eb20e1a7
    type: comment
  author: clembeetlebaby
  content: I use it in voldys sd web-ui
  created_at: 2022-12-18 03:13:51+00:00
  edited: false
  hidden: false
  id: 639e856ff87da5e2eb20e1a7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/972272987cbb3ef75b94c6ef9f7677dc.svg
      fullname: James Maxwell
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jbmaxwell
      type: user
    createdAt: '2023-01-15T00:58:59.000Z'
    data:
      edited: true
      editors:
      - jbmaxwell
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/972272987cbb3ef75b94c6ef9f7677dc.svg
          fullname: James Maxwell
          isHf: false
          isPro: false
          name: jbmaxwell
          type: user
        html: "<p>I tried to fine-tune the model using the HF <code>train_text_to_image.py</code>\
          \ script, but when I load it in Riffusion I'm hitting an error:</p>\n<pre><code>Traceback\
          \ (most recent call last):\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/streamlit/runtime/scriptrunner/script_runner.py\"\
          , line 565, in _run_script\n    exec(code, module.__dict__)\n  File \"/home/james/src/somms/riffusion/riffusion/streamlit/pages/text_to_audio.py\"\
          , line 102, in &lt;module&gt;\n    render_text_to_audio()\n  File \"/home/james/src/somms/riffusion/riffusion/streamlit/pages/text_to_audio.py\"\
          , line 78, in render_text_to_audio\n    image = streamlit_util.run_txt2img(\n\
          \  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/streamlit/runtime/caching/cache_utils.py\"\
          , line 428, in wrapper\n    return get_or_create_cached_value()\n  File\
          \ \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/streamlit/runtime/caching/cache_utils.py\"\
          , line 401, in get_or_create_cached_value\n    return_value = func(*args,\
          \ **kwargs)\n  File \"/home/james/src/somms/riffusion/riffusion/streamlit/util.py\"\
          , line 102, in run_txt2img\n    output = pipeline(\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\"\
          , line 531, in __call__\n    noise_pred = self.unet(latent_model_input,\
          \ t, encoder_hidden_states=text_embeddings).sample\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n\
          \  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/diffusers/models/unet_2d_condition.py\"\
          , line 421, in forward\n    sample = self.conv_in(sample)\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n\
          \  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/nn/modules/conv.py\"\
          , line 463, in forward\n    return self._conv_forward(input, self.weight,\
          \ self.bias)\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/nn/modules/conv.py\"\
          , line 459, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\n\
          RuntimeError: Input type (c10::Half) and bias type (float) should be the\
          \ same\n</code></pre>\n<p>I also tried training with <code>\"--mixed_precision=fp16\"\
          </code>, in case that was an issue, but same error.<br>Any ideas how to\
          \ fix this?</p>\n<p>(I can push the error down the line by calling <code>sample\
          \ = self.conv_in(sample)</code> with autocast, but it's not really a solution...\
          \ I just get a different type error later.)</p>\n<p>Are there special settings\
          \ for the HF script, or for saving/loading the model in Riffusion that I\
          \ should know about?</p>\n"
        raw: "I tried to fine-tune the model using the HF `train_text_to_image.py`\
          \ script, but when I load it in Riffusion I'm hitting an error:\n```\nTraceback\
          \ (most recent call last):\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/streamlit/runtime/scriptrunner/script_runner.py\"\
          , line 565, in _run_script\n    exec(code, module.__dict__)\n  File \"/home/james/src/somms/riffusion/riffusion/streamlit/pages/text_to_audio.py\"\
          , line 102, in <module>\n    render_text_to_audio()\n  File \"/home/james/src/somms/riffusion/riffusion/streamlit/pages/text_to_audio.py\"\
          , line 78, in render_text_to_audio\n    image = streamlit_util.run_txt2img(\n\
          \  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/streamlit/runtime/caching/cache_utils.py\"\
          , line 428, in wrapper\n    return get_or_create_cached_value()\n  File\
          \ \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/streamlit/runtime/caching/cache_utils.py\"\
          , line 401, in get_or_create_cached_value\n    return_value = func(*args,\
          \ **kwargs)\n  File \"/home/james/src/somms/riffusion/riffusion/streamlit/util.py\"\
          , line 102, in run_txt2img\n    output = pipeline(\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\"\
          , line 531, in __call__\n    noise_pred = self.unet(latent_model_input,\
          \ t, encoder_hidden_states=text_embeddings).sample\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n\
          \  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/diffusers/models/unet_2d_condition.py\"\
          , line 421, in forward\n    sample = self.conv_in(sample)\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n\
          \  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/nn/modules/conv.py\"\
          , line 463, in forward\n    return self._conv_forward(input, self.weight,\
          \ self.bias)\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/nn/modules/conv.py\"\
          , line 459, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\n\
          RuntimeError: Input type (c10::Half) and bias type (float) should be the\
          \ same\n```\nI also tried training with `\"--mixed_precision=fp16\"`, in\
          \ case that was an issue, but same error. \nAny ideas how to fix this?\n\
          \n(I can push the error down the line by calling `sample = self.conv_in(sample)`\
          \ with autocast, but it's not really a solution... I just get a different\
          \ type error later.)\n\nAre there special settings for the HF script, or\
          \ for saving/loading the model in Riffusion that I should know about?"
        updatedAt: '2023-01-15T01:01:51.397Z'
      numEdits: 2
      reactions: []
    id: 63c34fd3758e752d9231323f
    type: comment
  author: jbmaxwell
  content: "I tried to fine-tune the model using the HF `train_text_to_image.py` script,\
    \ but when I load it in Riffusion I'm hitting an error:\n```\nTraceback (most\
    \ recent call last):\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/streamlit/runtime/scriptrunner/script_runner.py\"\
    , line 565, in _run_script\n    exec(code, module.__dict__)\n  File \"/home/james/src/somms/riffusion/riffusion/streamlit/pages/text_to_audio.py\"\
    , line 102, in <module>\n    render_text_to_audio()\n  File \"/home/james/src/somms/riffusion/riffusion/streamlit/pages/text_to_audio.py\"\
    , line 78, in render_text_to_audio\n    image = streamlit_util.run_txt2img(\n\
    \  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/streamlit/runtime/caching/cache_utils.py\"\
    , line 428, in wrapper\n    return get_or_create_cached_value()\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/streamlit/runtime/caching/cache_utils.py\"\
    , line 401, in get_or_create_cached_value\n    return_value = func(*args, **kwargs)\n\
    \  File \"/home/james/src/somms/riffusion/riffusion/streamlit/util.py\", line\
    \ 102, in run_txt2img\n    output = pipeline(\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/autograd/grad_mode.py\"\
    , line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\"\
    , line 531, in __call__\n    noise_pred = self.unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n\
    \  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File\
    \ \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/diffusers/models/unet_2d_condition.py\"\
    , line 421, in forward\n    sample = self.conv_in(sample)\n  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File\
    \ \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/nn/modules/conv.py\"\
    , line 463, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n\
    \  File \"/home/james/anaconda3/envs/riffusion/lib/python3.9/site-packages/torch/nn/modules/conv.py\"\
    , line 459, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\n\
    RuntimeError: Input type (c10::Half) and bias type (float) should be the same\n\
    ```\nI also tried training with `\"--mixed_precision=fp16\"`, in case that was\
    \ an issue, but same error. \nAny ideas how to fix this?\n\n(I can push the error\
    \ down the line by calling `sample = self.conv_in(sample)` with autocast, but\
    \ it's not really a solution... I just get a different type error later.)\n\n\
    Are there special settings for the HF script, or for saving/loading the model\
    \ in Riffusion that I should know about?"
  created_at: 2023-01-15 00:58:59+00:00
  edited: true
  hidden: false
  id: 63c34fd3758e752d9231323f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/972272987cbb3ef75b94c6ef9f7677dc.svg
      fullname: James Maxwell
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jbmaxwell
      type: user
    createdAt: '2023-01-15T01:30:36.000Z'
    data:
      edited: false
      editors:
      - jbmaxwell
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/972272987cbb3ef75b94c6ef9f7677dc.svg
          fullname: James Maxwell
          isHf: false
          isPro: false
          name: jbmaxwell
          type: user
        html: '<p>Ugh... I just noticed that you get a special prize if you let the
          script complete it''s full run of <code>num_train_epochs</code>... heh...<br>I''m
          so used to early stopping and grabbing the checkpoint...<br>I''m guessing
          the output of <code>pipeline.save_pretrained(args.output_dir)</code> is
          going to make a lot more sense when loading in Riffusion... (gulp)</p>

          '
        raw: "Ugh... I just noticed that you get a special prize if you let the script\
          \ complete it's full run of `num_train_epochs`... heh... \nI'm so used to\
          \ early stopping and grabbing the checkpoint... \nI'm guessing the output\
          \ of `pipeline.save_pretrained(args.output_dir)` is going to make a lot\
          \ more sense when loading in Riffusion... (gulp)"
        updatedAt: '2023-01-15T01:30:36.130Z'
      numEdits: 0
      reactions: []
    id: 63c3573caa5c9b84171366c6
    type: comment
  author: jbmaxwell
  content: "Ugh... I just noticed that you get a special prize if you let the script\
    \ complete it's full run of `num_train_epochs`... heh... \nI'm so used to early\
    \ stopping and grabbing the checkpoint... \nI'm guessing the output of `pipeline.save_pretrained(args.output_dir)`\
    \ is going to make a lot more sense when loading in Riffusion... (gulp)"
  created_at: 2023-01-15 01:30:36+00:00
  edited: false
  hidden: false
  id: 63c3573caa5c9b84171366c6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/999e8f6a820d7145b60a99eb16bd7f35.svg
      fullname: Ogbogu Kalu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ogkalu
      type: user
    createdAt: '2023-01-18T04:27:06.000Z'
    data:
      edited: false
      editors:
      - ogkalu
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/999e8f6a820d7145b60a99eb16bd7f35.svg
          fullname: Ogbogu Kalu
          isHf: false
          isPro: false
          name: ogkalu
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;jbmaxwell&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/jbmaxwell\">@<span class=\"\
          underline\">jbmaxwell</span></a></span>\n\n\t</span></span> did you fix\
          \ this issue ?</p>\n"
        raw: '@jbmaxwell did you fix this issue ?'
        updatedAt: '2023-01-18T04:27:06.267Z'
      numEdits: 0
      reactions: []
    id: 63c7751a02d8c962334baecd
    type: comment
  author: ogkalu
  content: '@jbmaxwell did you fix this issue ?'
  created_at: 2023-01-18 04:27:06+00:00
  edited: false
  hidden: false
  id: 63c7751a02d8c962334baecd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/972272987cbb3ef75b94c6ef9f7677dc.svg
      fullname: James Maxwell
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jbmaxwell
      type: user
    createdAt: '2023-01-18T05:09:17.000Z'
    data:
      edited: false
      editors:
      - jbmaxwell
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/972272987cbb3ef75b94c6ef9f7677dc.svg
          fullname: James Maxwell
          isHf: false
          isPro: false
          name: jbmaxwell
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ogkalu&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ogkalu\">@<span class=\"\
          underline\">ogkalu</span></a></span>\n\n\t</span></span>, Sorry, I was being\
          \ a bit obscure. Just let the training run to completion and it will save\
          \ the full checkpoint, with everything you need to load in Riffusion.</p>\n"
        raw: '@ogkalu, Sorry, I was being a bit obscure. Just let the training run
          to completion and it will save the full checkpoint, with everything you
          need to load in Riffusion.'
        updatedAt: '2023-01-18T05:09:17.973Z'
      numEdits: 0
      reactions: []
    id: 63c77efd2f651b6762995b28
    type: comment
  author: jbmaxwell
  content: '@ogkalu, Sorry, I was being a bit obscure. Just let the training run to
    completion and it will save the full checkpoint, with everything you need to load
    in Riffusion.'
  created_at: 2023-01-18 05:09:17+00:00
  edited: false
  hidden: false
  id: 63c77efd2f651b6762995b28
  type: comment
is_pull_request: true
merge_commit_oid: null
num: 7
repo_id: riffusion/riffusion-model-v1
repo_type: model
status: open
target_branch: refs/heads/main
title: Upload riffusion-model-v1-pruned.ckpt
