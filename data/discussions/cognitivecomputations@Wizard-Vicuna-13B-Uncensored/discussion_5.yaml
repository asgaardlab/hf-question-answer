!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MrGobbs
conflicting_files: null
created_at: 2023-05-19 19:28:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7d6cae57b6e40c6680479ecfe2fd3c75.svg
      fullname: Harshul Gaba
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MrGobbs
      type: user
    createdAt: '2023-05-19T20:28:14.000Z'
    data:
      edited: false
      editors:
      - MrGobbs
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7d6cae57b6e40c6680479ecfe2fd3c75.svg
          fullname: Harshul Gaba
          isHf: false
          isPro: false
          name: MrGobbs
          type: user
        html: '<p>I wanted to use the model in a python code with pytorch. I did not
          want to use a web-ui just plain old command terminal. I wanted to know how
          I can do it. </p>

          '
        raw: 'I wanted to use the model in a python code with pytorch. I did not want
          to use a web-ui just plain old command terminal. I wanted to know how I
          can do it. '
        updatedAt: '2023-05-19T20:28:14.057Z'
      numEdits: 0
      reactions: []
    id: 6467dbde8334813a7ae65e83
    type: comment
  author: MrGobbs
  content: 'I wanted to use the model in a python code with pytorch. I did not want
    to use a web-ui just plain old command terminal. I wanted to know how I can do
    it. '
  created_at: 2023-05-19 19:28:14+00:00
  edited: false
  hidden: false
  id: 6467dbde8334813a7ae65e83
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-05-19T21:57:40.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>Llama.cpp or python</p>

          '
        raw: Llama.cpp or python
        updatedAt: '2023-05-19T21:57:40.568Z'
      numEdits: 0
      reactions: []
    id: 6467f0d4e92e2372d5d61adc
    type: comment
  author: ehartford
  content: Llama.cpp or python
  created_at: 2023-05-19 20:57:40+00:00
  edited: false
  hidden: false
  id: 6467f0d4e92e2372d5d61adc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-05-19T21:59:39.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>I have a little guide for vicuna here you can do it with my models
          too, the ggml that TheBloke published.</p>

          <p><a rel="nofollow" href="https://erichartford.com/vicuna">https://erichartford.com/vicuna</a></p>

          '
        raw: 'I have a little guide for vicuna here you can do it with my models too,
          the ggml that TheBloke published.


          https://erichartford.com/vicuna'
        updatedAt: '2023-05-19T21:59:39.612Z'
      numEdits: 0
      reactions: []
    id: 6467f14b3a7c8dda230c56d7
    type: comment
  author: ehartford
  content: 'I have a little guide for vicuna here you can do it with my models too,
    the ggml that TheBloke published.


    https://erichartford.com/vicuna'
  created_at: 2023-05-19 20:59:39+00:00
  edited: false
  hidden: false
  id: 6467f14b3a7c8dda230c56d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
      fullname: Devon M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Delcos
      type: user
    createdAt: '2023-05-22T04:35:26.000Z'
    data:
      edited: false
      editors:
      - Delcos
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
          fullname: Devon M
          isHf: false
          isPro: false
          name: Delcos
          type: user
        html: '<p>Just import transformers and then get the model the settings you
          want, or just don''t do sampling and then you''re good to go.</p>

          '
        raw: Just import transformers and then get the model the settings you want,
          or just don't do sampling and then you're good to go.
        updatedAt: '2023-05-22T04:35:26.597Z'
      numEdits: 0
      reactions: []
    id: 646af10e13396ee0a57061ef
    type: comment
  author: Delcos
  content: Just import transformers and then get the model the settings you want,
    or just don't do sampling and then you're good to go.
  created_at: 2023-05-22 03:35:26+00:00
  edited: false
  hidden: false
  id: 646af10e13396ee0a57061ef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/aa8e2e38e07d1fa0d2dc611723bc8f4c.svg
      fullname: "\u0141ael Al-Halawani"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ljhwild
      type: user
    createdAt: '2023-08-27T20:28:09.000Z'
    data:
      edited: true
      editors:
      - ljhwild
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9152957201004028
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/aa8e2e38e07d1fa0d2dc611723bc8f4c.svg
          fullname: "\u0141ael Al-Halawani"
          isHf: false
          isPro: false
          name: ljhwild
          type: user
        html: '<p>Can I use this with python using llama ccp?<br>So would that be
          correct:<br><code>LLM = Llama(MODEL, verbose=False, n_ctx=2048)</code><br>and
          have <code>MODEL</code> replaced with the quantized bin file,<br>and <code>n_ctx=161984</code>
          ? Or is there anything else that needs to be done?</p>

          '
        raw: "Can I use this with python using llama ccp?\nSo would that be correct:\n\
          `LLM = Llama(MODEL, verbose=False, n_ctx=2048)`\nand have `MODEL` replaced\
          \ with the quantized bin file, \nand `n_ctx=161984` ? Or is there anything\
          \ else that needs to be done?"
        updatedAt: '2023-08-27T20:28:25.143Z'
      numEdits: 1
      reactions: []
    id: 64ebb1d9345cf9d8c4d14219
    type: comment
  author: ljhwild
  content: "Can I use this with python using llama ccp?\nSo would that be correct:\n\
    `LLM = Llama(MODEL, verbose=False, n_ctx=2048)`\nand have `MODEL` replaced with\
    \ the quantized bin file, \nand `n_ctx=161984` ? Or is there anything else that\
    \ needs to be done?"
  created_at: 2023-08-27 19:28:09+00:00
  edited: true
  hidden: false
  id: 64ebb1d9345cf9d8c4d14219
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: cognitivecomputations/Wizard-Vicuna-13B-Uncensored
repo_type: model
status: open
target_branch: null
title: Loading the model without any webUI
