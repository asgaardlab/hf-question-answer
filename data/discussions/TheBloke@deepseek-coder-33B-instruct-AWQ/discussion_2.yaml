!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Chester111
conflicting_files: null
created_at: 2023-11-05 07:56:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6398203609f12714ed1935c2/uXgl0LgKnFYjq1Wz39-a6.jpeg?w=200&h=200&f=face
      fullname: Chester111
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Chester111
      type: user
    createdAt: '2023-11-05T08:56:54.000Z'
    data:
      edited: false
      editors:
      - Chester111
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9666436910629272
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6398203609f12714ed1935c2/uXgl0LgKnFYjq1Wz39-a6.jpeg?w=200&h=200&f=face
          fullname: Chester111
          isHf: false
          isPro: false
          name: Chester111
          type: user
        html: '<p>Hi, this is developer of DeepSeek Coder. </p>

          <p>Thanks for you great work on quantizing our model and making it more
          popular!</p>

          <p>Though, we noticed the model cards state that "As this model is based
          on Llama 2, it is also subject to the Meta Llama 2 license terms, and the
          license files for that are additionally included. It should therefore be
          considered as being claimed to be licensed under both licenses," which is
          not true.</p>

          <p>Our model is not based on Llama 2. It just shares the model architecture
          with Llama 2 (with slightly different hyper-parameters) so it is compatible
          with toolchains in the Llama ecology, but  the training data and model parameters
          are in no way related to Llama2. We collected training data on our own and
          trained the model from scratch. Thus, the released model is subject to our
          own license, not under both our license and Llama2 license.</p>

          '
        raw: "Hi, this is developer of DeepSeek Coder. \r\n\r\nThanks for you great\
          \ work on quantizing our model and making it more popular!\r\n\r\nThough,\
          \ we noticed the model cards state that \"As this model is based on Llama\
          \ 2, it is also subject to the Meta Llama 2 license terms, and the license\
          \ files for that are additionally included. It should therefore be considered\
          \ as being claimed to be licensed under both licenses,\" which is not true.\r\
          \n\r\nOur model is not based on Llama 2. It just shares the model architecture\
          \ with Llama 2 (with slightly different hyper-parameters) so it is compatible\
          \ with toolchains in the Llama ecology, but  the training data and model\
          \ parameters are in no way related to Llama2. We collected training data\
          \ on our own and trained the model from scratch. Thus, the released model\
          \ is subject to our own license, not under both our license and Llama2 license.\r\
          \n"
        updatedAt: '2023-11-05T08:56:54.492Z'
      numEdits: 0
      reactions: []
    id: 654758d6565e3985e8a21847
    type: comment
  author: Chester111
  content: "Hi, this is developer of DeepSeek Coder. \r\n\r\nThanks for you great\
    \ work on quantizing our model and making it more popular!\r\n\r\nThough, we noticed\
    \ the model cards state that \"As this model is based on Llama 2, it is also subject\
    \ to the Meta Llama 2 license terms, and the license files for that are additionally\
    \ included. It should therefore be considered as being claimed to be licensed\
    \ under both licenses,\" which is not true.\r\n\r\nOur model is not based on Llama\
    \ 2. It just shares the model architecture with Llama 2 (with slightly different\
    \ hyper-parameters) so it is compatible with toolchains in the Llama ecology,\
    \ but  the training data and model parameters are in no way related to Llama2.\
    \ We collected training data on our own and trained the model from scratch. Thus,\
    \ the released model is subject to our own license, not under both our license\
    \ and Llama2 license.\r\n"
  created_at: 2023-11-05 07:56:54+00:00
  edited: false
  hidden: false
  id: 654758d6565e3985e8a21847
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-11-05T09:17:31.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8738651871681213
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Chester111&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Chester111\">@<span class=\"\
          underline\">Chester111</span></a></span>\n\n\t</span></span> Thanks for\
          \ clearifying it!</p>\n<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ Would you please edit this correction? Thanks!</p>\n"
        raw: '@Chester111 Thanks for clearifying it!


          @TheBloke Would you please edit this correction? Thanks!'
        updatedAt: '2023-11-05T09:17:31.613Z'
      numEdits: 0
      reactions: []
    id: 65475dab6070dd5df77400ac
    type: comment
  author: Yhyu13
  content: '@Chester111 Thanks for clearifying it!


    @TheBloke Would you please edit this correction? Thanks!'
  created_at: 2023-11-05 09:17:31+00:00
  edited: false
  hidden: false
  id: 65475dab6070dd5df77400ac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-05T12:29:29.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9791883230209351
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p>HI <span data-props=\"{&quot;user&quot;:&quot;Chester111&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Chester111\"\
          >@<span class=\"underline\">Chester111</span></a></span>\n\n\t</span></span>\
          \ - sorry about that!</p>\n<p>I have added <code>deepseek</code> as a new\
          \ model type in my code and re-run all the repos to remove the LLama 2 license\
          \ files and all mentions of Llama 2.  All repos should now be fixed</p>\n\
          <p>I was doing these uploads at 3am this morning, having missed the release\
          \ on the day and being inundated with requests to do this model, so I didn't\
          \ look at the models closely enough.</p>\n<p>Thanks very much for the amazing\
          \ new models!</p>\n"
        raw: 'HI @Chester111 - sorry about that!


          I have added `deepseek` as a new model type in my code and re-run all the
          repos to remove the LLama 2 license files and all mentions of Llama 2.  All
          repos should now be fixed


          I was doing these uploads at 3am this morning, having missed the release
          on the day and being inundated with requests to do this model, so I didn''t
          look at the models closely enough.


          Thanks very much for the amazing new models!'
        updatedAt: '2023-11-05T13:41:21.413Z'
      numEdits: 2
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - Chester111
        - josefandersson
        - jmtl
    id: 65478aa9af7c27330d3cf121
    type: comment
  author: TheBloke
  content: 'HI @Chester111 - sorry about that!


    I have added `deepseek` as a new model type in my code and re-run all the repos
    to remove the LLama 2 license files and all mentions of Llama 2.  All repos should
    now be fixed


    I was doing these uploads at 3am this morning, having missed the release on the
    day and being inundated with requests to do this model, so I didn''t look at the
    models closely enough.


    Thanks very much for the amazing new models!'
  created_at: 2023-11-05 12:29:29+00:00
  edited: true
  hidden: false
  id: 65478aa9af7c27330d3cf121
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-11-05T13:23:19.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9261986613273621
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<p>This may not be the place and should be in the source project instead,
          and if so i apologize, but was going to try to convert those models over
          to GGUF to use on a smaller non-gpu device for comparing python output with
          wizard.  But the tokenizer.model is missing in the source repositories.  Is
          this a side effect of the difference? Is there a way to generate that myself,
          or am i outta luck? ( still new at this game.. sorry )</p>

          '
        raw: This may not be the place and should be in the source project instead,
          and if so i apologize, but was going to try to convert those models over
          to GGUF to use on a smaller non-gpu device for comparing python output with
          wizard.  But the tokenizer.model is missing in the source repositories.  Is
          this a side effect of the difference? Is there a way to generate that myself,
          or am i outta luck? ( still new at this game.. sorry )
        updatedAt: '2023-11-05T13:23:19.846Z'
      numEdits: 0
      reactions: []
    id: 65479747cf50edb69f0d1bcf
    type: comment
  author: Nurb432
  content: This may not be the place and should be in the source project instead,
    and if so i apologize, but was going to try to convert those models over to GGUF
    to use on a smaller non-gpu device for comparing python output with wizard.  But
    the tokenizer.model is missing in the source repositories.  Is this a side effect
    of the difference? Is there a way to generate that myself, or am i outta luck?
    ( still new at this game.. sorry )
  created_at: 2023-11-05 13:23:19+00:00
  edited: false
  hidden: false
  id: 65479747cf50edb69f0d1bcf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-05T13:23:54.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8433094024658203
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Nurb432&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Nurb432\">@<span class=\"\
          underline\">Nurb432</span></a></span>\n\n\t</span></span> I'm uploading\
          \ GGUFs now, check back in 10 - 15 minutes</p>\n"
        raw: '@Nurb432 I''m uploading GGUFs now, check back in 10 - 15 minutes'
        updatedAt: '2023-11-05T13:23:54.092Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Nurb432
    id: 6547976a08deaa0c91040c91
    type: comment
  author: TheBloke
  content: '@Nurb432 I''m uploading GGUFs now, check back in 10 - 15 minutes'
  created_at: 2023-11-05 13:23:54+00:00
  edited: false
  hidden: false
  id: 6547976a08deaa0c91040c91
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-11-05T13:44:05.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8137249946594238
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span>  great. thank\
          \ you.</p>\n<p>Still curious what was needed to get past the error i got,\
          \ or if im doing it wrong ( the normal convert.py from llama.ccp )</p>\n"
        raw: '@TheBloke  great. thank you.


          Still curious what was needed to get past the error i got, or if im doing
          it wrong ( the normal convert.py from llama.ccp )'
        updatedAt: '2023-11-05T13:44:05.120Z'
      numEdits: 0
      reactions: []
    id: 65479c25f104457da1394902
    type: comment
  author: Nurb432
  content: '@TheBloke  great. thank you.


    Still curious what was needed to get past the error i got, or if im doing it wrong
    ( the normal convert.py from llama.ccp )'
  created_at: 2023-11-05 13:44:05+00:00
  edited: false
  hidden: false
  id: 65479c25f104457da1394902
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-05T13:46:36.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9218751788139343
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>You''re not doing anything wrong. The normal <code>convert.py</code>
          can''t handle these models, as DeepSeek did not provide a <code>tokenizer.model</code>
          file, only a Hugging Face tokenizer <code>tokenizer.json</code></p>

          <p>In order to convert these models I needed to use a new PR for convert.py
          which can make GGUFs using the Hugging Face vocab configuration, from a
          tokenizer.json file.  Although even that didn''t work at first, due to bugs
          in the llama.cpp PR.  Those bugs were fixed this morning, enabling me to
          make them.</p>

          <p>The PR is here: <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp/pull/3633">https://github.com/ggerganov/llama.cpp/pull/3633</a></p>

          '
        raw: 'You''re not doing anything wrong. The normal `convert.py` can''t handle
          these models, as DeepSeek did not provide a `tokenizer.model` file, only
          a Hugging Face tokenizer `tokenizer.json`


          In order to convert these models I needed to use a new PR for convert.py
          which can make GGUFs using the Hugging Face vocab configuration, from a
          tokenizer.json file.  Although even that didn''t work at first, due to bugs
          in the llama.cpp PR.  Those bugs were fixed this morning, enabling me to
          make them.


          The PR is here: https://github.com/ggerganov/llama.cpp/pull/3633'
        updatedAt: '2023-11-05T13:46:36.673Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Nurb432
        - dlface
    id: 65479cbcaf5d7944324d5153
    type: comment
  author: TheBloke
  content: 'You''re not doing anything wrong. The normal `convert.py` can''t handle
    these models, as DeepSeek did not provide a `tokenizer.model` file, only a Hugging
    Face tokenizer `tokenizer.json`


    In order to convert these models I needed to use a new PR for convert.py which
    can make GGUFs using the Hugging Face vocab configuration, from a tokenizer.json
    file.  Although even that didn''t work at first, due to bugs in the llama.cpp
    PR.  Those bugs were fixed this morning, enabling me to make them.


    The PR is here: https://github.com/ggerganov/llama.cpp/pull/3633'
  created_at: 2023-11-05 13:46:36+00:00
  edited: false
  hidden: false
  id: 65479cbcaf5d7944324d5153
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-11-05T14:30:10.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9846513271331787
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<p>cool. i figured i was missing a step on how to create that file.  I
          was using yesterdays llama.ccp and didnt even notice there was a newer one  (
          it was in my mail, i do watch the repo but missed it )   will bump it up
          when i get home later.</p>

          <p>And again, thanks for all you do for us.</p>

          '
        raw: 'cool. i figured i was missing a step on how to create that file.  I
          was using yesterdays llama.ccp and didnt even notice there was a newer one  (
          it was in my mail, i do watch the repo but missed it )   will bump it up
          when i get home later.


          And again, thanks for all you do for us.'
        updatedAt: '2023-11-05T14:30:10.907Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - TheBloke
    id: 6547a6f2c1949364696ae13f
    type: comment
  author: Nurb432
  content: 'cool. i figured i was missing a step on how to create that file.  I was
    using yesterdays llama.ccp and didnt even notice there was a newer one  ( it was
    in my mail, i do watch the repo but missed it )   will bump it up when i get home
    later.


    And again, thanks for all you do for us.'
  created_at: 2023-11-05 14:30:10+00:00
  edited: false
  hidden: false
  id: 6547a6f2c1949364696ae13f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-05T14:32:22.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9841002225875854
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>The PR I mentioned hasn''t been merged yet, so you won''t find the
          file there.  It''s still in development. If you want to try making one yourself,
          you''ll need to download the code from the PR I listed, not the main branch</p>

          <p>Hopefully it''ll be merged sometime in the coming week and then it''ll
          be available to everyone as <code>convert.py</code></p>

          '
        raw: 'The PR I mentioned hasn''t been merged yet, so you won''t find the file
          there.  It''s still in development. If you want to try making one yourself,
          you''ll need to download the code from the PR I listed, not the main branch


          Hopefully it''ll be merged sometime in the coming week and then it''ll be
          available to everyone as `convert.py`'
        updatedAt: '2023-11-05T14:32:22.019Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Nurb432
    id: 6547a7765f6c84d8f4b00ccd
    type: comment
  author: TheBloke
  content: 'The PR I mentioned hasn''t been merged yet, so you won''t find the file
    there.  It''s still in development. If you want to try making one yourself, you''ll
    need to download the code from the PR I listed, not the main branch


    Hopefully it''ll be merged sometime in the coming week and then it''ll be available
    to everyone as `convert.py`'
  created_at: 2023-11-05 14:32:22+00:00
  edited: false
  hidden: false
  id: 6547a7765f6c84d8f4b00ccd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/deepseek-coder-33B-instruct-AWQ
repo_type: model
status: open
target_branch: null
title: DeepSeek Coder is not based on Llama 2
