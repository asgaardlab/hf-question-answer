!!python/object:huggingface_hub.community.DiscussionWithDetails
author: YokaiKoibito
conflicting_files: null
created_at: 2023-08-10 07:01:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
      fullname: Yokai Koibito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YokaiKoibito
      type: user
    createdAt: '2023-08-10T08:01:17.000Z'
    data:
      edited: true
      editors:
      - YokaiKoibito
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9560893177986145
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
          fullname: Yokai Koibito
          isHf: false
          isPro: false
          name: YokaiKoibito
          type: user
        html: '<p>I appreciate having this 32-bit version for anyone who wants to
          do further training, but I''m never going to run this in 32-bit for inference,
          so downloading a 32-bit version then downsizing it to 4/8/16 locally is
          a huge waste of time/bandwidth.</p>

          '
        raw: I appreciate having this 32-bit version for anyone who wants to do further
          training, but I'm never going to run this in 32-bit for inference, so downloading
          a 32-bit version then downsizing it to 4/8/16 locally is a huge waste of
          time/bandwidth.
        updatedAt: '2023-08-10T08:01:44.017Z'
      numEdits: 1
      reactions: []
    id: 64d4994dac8d2ee42ff1fd5c
    type: comment
  author: YokaiKoibito
  content: I appreciate having this 32-bit version for anyone who wants to do further
    training, but I'm never going to run this in 32-bit for inference, so downloading
    a 32-bit version then downsizing it to 4/8/16 locally is a huge waste of time/bandwidth.
  created_at: 2023-08-10 07:01:17+00:00
  edited: true
  hidden: false
  id: 64d4994dac8d2ee42ff1fd5c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
      fullname: Yokai Koibito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YokaiKoibito
      type: user
    createdAt: '2023-08-10T08:08:54.000Z'
    data:
      edited: false
      editors:
      - YokaiKoibito
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9527974724769592
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
          fullname: Yokai Koibito
          isHf: false
          isPro: false
          name: YokaiKoibito
          type: user
        html: '<p>Your model card says this is fp16. But it''s 29 shards of around
          9.3GB, so around 4 bytes per parameter, so it''s clearly actually fp32.</p>

          '
        raw: Your model card says this is fp16. But it's 29 shards of around 9.3GB,
          so around 4 bytes per parameter, so it's clearly actually fp32.
        updatedAt: '2023-08-10T08:08:54.682Z'
      numEdits: 0
      reactions: []
    id: 64d49b1616300e48f2e5686f
    type: comment
  author: YokaiKoibito
  content: Your model card says this is fp16. But it's 29 shards of around 9.3GB,
    so around 4 bytes per parameter, so it's clearly actually fp32.
  created_at: 2023-08-10 07:08:54+00:00
  edited: false
  hidden: false
  id: 64d49b1616300e48f2e5686f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
      fullname: Yokai Koibito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YokaiKoibito
      type: user
    createdAt: '2023-08-12T06:27:26.000Z'
    data:
      edited: false
      editors:
      - YokaiKoibito
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9189884662628174
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
          fullname: Yokai Koibito
          isHf: false
          isPro: false
          name: YokaiKoibito
          type: user
        html: '<p>I made an fp16 copy at YokaiKoibito/llama2_70b_chat_uncensored by
          importing to CPU as torch.float16 and then rexporting. It is indeed half
          the size. If you make an fp16 copy I can take mine down.</p>

          '
        raw: I made an fp16 copy at YokaiKoibito/llama2_70b_chat_uncensored by importing
          to CPU as torch.float16 and then rexporting. It is indeed half the size.
          If you make an fp16 copy I can take mine down.
        updatedAt: '2023-08-12T06:27:26.827Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - BioNeuron
        - prosodydev
    id: 64d7264ec13c27a7017cdea4
    type: comment
  author: YokaiKoibito
  content: I made an fp16 copy at YokaiKoibito/llama2_70b_chat_uncensored by importing
    to CPU as torch.float16 and then rexporting. It is indeed half the size. If you
    make an fp16 copy I can take mine down.
  created_at: 2023-08-12 05:27:26+00:00
  edited: false
  hidden: false
  id: 64d7264ec13c27a7017cdea4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: jarradh/llama2_70b_chat_uncensored
repo_type: model
status: open
target_branch: null
title: Could we get an fp16 version? This thing is huge...
