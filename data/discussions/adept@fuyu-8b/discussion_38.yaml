!!python/object:huggingface_hub.community.DiscussionWithDetails
author: liupei0408
conflicting_files: null
created_at: 2023-10-27 01:32:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ba98a05b4874190be238d17bcc2583e3.svg
      fullname: Pei Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: liupei0408
      type: user
    createdAt: '2023-10-27T02:32:38.000Z'
    data:
      edited: false
      editors:
      - liupei0408
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9554679989814758
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ba98a05b4874190be238d17bcc2583e3.svg
          fullname: Pei Liu
          isHf: false
          isPro: false
          name: liupei0408
          type: user
        html: '<p>as mentioned above, whether special instruction is need for OCR
          location feature using Fuyu-8b to get same result as showing in blog?</p>

          '
        raw: as mentioned above, whether special instruction is need for OCR location
          feature using Fuyu-8b to get same result as showing in blog?
        updatedAt: '2023-10-27T02:32:38.319Z'
      numEdits: 0
      reactions: []
    id: 653b21468abd634b83edfda9
    type: comment
  author: liupei0408
  content: as mentioned above, whether special instruction is need for OCR location
    feature using Fuyu-8b to get same result as showing in blog?
  created_at: 2023-10-27 01:32:38+00:00
  edited: false
  hidden: false
  id: 653b21468abd634b83edfda9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4dadb7295810c41de02fedd7106d436c.svg
      fullname: cc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nooodles
      type: user
    createdAt: '2023-10-30T02:32:04.000Z'
    data:
      edited: false
      editors:
      - Nooodles
      hidden: false
      identifiedLanguage:
        language: it
        probability: 0.9861560463905334
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4dadb7295810c41de02fedd7106d436c.svg
          fullname: cc
          isHf: false
          isPro: false
          name: Nooodles
          type: user
        html: '<p>+1</p>

          '
        raw: '+1'
        updatedAt: '2023-10-30T02:32:04.566Z'
      numEdits: 0
      reactions: []
    id: 653f15a43479e9ebbe60e62f
    type: comment
  author: Nooodles
  content: '+1'
  created_at: 2023-10-30 01:32:04+00:00
  edited: false
  hidden: false
  id: 653f15a43479e9ebbe60e62f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
      fullname: Pablo Montalvo
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Molbap
      type: user
    createdAt: '2023-11-03T10:42:51.000Z'
    data:
      edited: false
      editors:
      - Molbap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6124697923660278
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
          fullname: Pablo Montalvo
          isHf: true
          isPro: false
          name: Molbap
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;liupei0408&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/liupei0408\"\
          >@<span class=\"underline\">liupei0408</span></a></span>\n\n\t</span></span>\
          \ , <span data-props=\"{&quot;user&quot;:&quot;Nooodles&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Nooodles\">@<span class=\"\
          underline\">Nooodles</span></a></span>\n\n\t</span></span> : you can try\
          \ this from the new release of <code>transformers</code>! <span data-props=\"\
          {&quot;user&quot;:&quot;pcuenq&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/pcuenq\">@<span class=\"underline\">pcuenq</span></a></span>\n\
          \n\t</span></span> worked on the bbox postprocessing, you can localise text\
          \ by doing:</p>\n<pre><code class=\"language-python\"><span class=\"hljs-keyword\"\
          >from</span> PIL <span class=\"hljs-keyword\">import</span> Image\n<span\
          \ class=\"hljs-keyword\">import</span> requests\n<span class=\"hljs-keyword\"\
          >import</span> io\n<span class=\"hljs-keyword\">from</span> transformers\
          \ <span class=\"hljs-keyword\">import</span> FuyuForCausalLM, FuyuProcessor\n\
          \npretrained_path = <span class=\"hljs-string\">\"adept/fuyu-8b\"</span>\n\
          processor = FuyuProcessor.from_pretrained(pretrained_path)\nmodel = FuyuForCausalLM.from_pretrained(pretrained_path,\
          \ device_map=<span class=\"hljs-string\">'auto'</span>)\n\nbbox_prompt =\
          \ <span class=\"hljs-string\">\"When presented with a box, perform OCR to\
          \ extract text contained within it. If provided with text, generate the\
          \ corresponding bounding box.\\\\n Williams\"</span>\nbbox_image_url = <span\
          \ class=\"hljs-string\">\"https://huggingface.co/datasets/hf-internal-testing/fixtures-captioning/resolve/main/bbox_sample_image.jpeg\"\
          </span>\nbbox_image_pil = Image.<span class=\"hljs-built_in\">open</span>(io.BytesIO(requests.get(bbox_image_url).content))\n\
          \nmodel_inputs = processor(text=bbox_prompt, images=bbox_image_pil).to(<span\
          \ class=\"hljs-string\">'cuda'</span>)\n\noutputs = model.generate(**model_inputs,\
          \ max_new_tokens=<span class=\"hljs-number\">10</span>)\npost_processed_bbox_tokens\
          \ = processor.post_process_box_coordinates(outputs)[<span class=\"hljs-number\"\
          >0</span>]\nmodel_outputs = processor.decode(post_processed_bbox_tokens,\
          \ skip_special_tokens=<span class=\"hljs-literal\">True</span>)\nprediction\
          \ = model_outputs.split(<span class=\"hljs-string\">'\\x04'</span>, <span\
          \ class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>]\
          \ <span class=\"hljs-keyword\">if</span> <span class=\"hljs-string\">'\\\
          x04'</span> <span class=\"hljs-keyword\">in</span> model_outputs <span class=\"\
          hljs-keyword\">else</span> <span class=\"hljs-string\">''</span>\n</code></pre>\n\
          <p><code>prediction</code> will output the coordinates of the text <code>Williams</code>\
          \ in the image.</p>\n"
        raw: 'Hi @liupei0408 , @Nooodles : you can try this from the new release of
          `transformers`! @pcuenq worked on the bbox postprocessing, you can localise
          text by doing:


          ```python

          from PIL import Image

          import requests

          import io

          from transformers import FuyuForCausalLM, FuyuProcessor


          pretrained_path = "adept/fuyu-8b"

          processor = FuyuProcessor.from_pretrained(pretrained_path)

          model = FuyuForCausalLM.from_pretrained(pretrained_path, device_map=''auto'')


          bbox_prompt = "When presented with a box, perform OCR to extract text contained
          within it. If provided with text, generate the corresponding bounding box.\\n
          Williams"

          bbox_image_url = "https://huggingface.co/datasets/hf-internal-testing/fixtures-captioning/resolve/main/bbox_sample_image.jpeg"

          bbox_image_pil = Image.open(io.BytesIO(requests.get(bbox_image_url).content))


          model_inputs = processor(text=bbox_prompt, images=bbox_image_pil).to(''cuda'')


          outputs = model.generate(**model_inputs, max_new_tokens=10)

          post_processed_bbox_tokens = processor.post_process_box_coordinates(outputs)[0]

          model_outputs = processor.decode(post_processed_bbox_tokens, skip_special_tokens=True)

          prediction = model_outputs.split(''\x04'', 1)[1] if ''\x04'' in model_outputs
          else ''''


          ```

          `prediction` will output the coordinates of the text `Williams` in the image.

          '
        updatedAt: '2023-11-03T10:42:51.081Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - whpyjnqd
    id: 6544ceab1681e2cd42751b13
    type: comment
  author: Molbap
  content: 'Hi @liupei0408 , @Nooodles : you can try this from the new release of
    `transformers`! @pcuenq worked on the bbox postprocessing, you can localise text
    by doing:


    ```python

    from PIL import Image

    import requests

    import io

    from transformers import FuyuForCausalLM, FuyuProcessor


    pretrained_path = "adept/fuyu-8b"

    processor = FuyuProcessor.from_pretrained(pretrained_path)

    model = FuyuForCausalLM.from_pretrained(pretrained_path, device_map=''auto'')


    bbox_prompt = "When presented with a box, perform OCR to extract text contained
    within it. If provided with text, generate the corresponding bounding box.\\n
    Williams"

    bbox_image_url = "https://huggingface.co/datasets/hf-internal-testing/fixtures-captioning/resolve/main/bbox_sample_image.jpeg"

    bbox_image_pil = Image.open(io.BytesIO(requests.get(bbox_image_url).content))


    model_inputs = processor(text=bbox_prompt, images=bbox_image_pil).to(''cuda'')


    outputs = model.generate(**model_inputs, max_new_tokens=10)

    post_processed_bbox_tokens = processor.post_process_box_coordinates(outputs)[0]

    model_outputs = processor.decode(post_processed_bbox_tokens, skip_special_tokens=True)

    prediction = model_outputs.split(''\x04'', 1)[1] if ''\x04'' in model_outputs
    else ''''


    ```

    `prediction` will output the coordinates of the text `Williams` in the image.

    '
  created_at: 2023-11-03 09:42:51+00:00
  edited: false
  hidden: false
  id: 6544ceab1681e2cd42751b13
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4dadb7295810c41de02fedd7106d436c.svg
      fullname: cc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nooodles
      type: user
    createdAt: '2023-12-01T06:35:03.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/4dadb7295810c41de02fedd7106d436c.svg
          fullname: cc
          isHf: false
          isPro: false
          name: Nooodles
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-12-01T06:45:29.014Z'
      numEdits: 1
      reactions: []
    id: 65697e9715c7a64e889a16fb
    type: comment
  author: Nooodles
  content: This comment has been hidden
  created_at: 2023-12-01 06:35:03+00:00
  edited: true
  hidden: true
  id: 65697e9715c7a64e889a16fb
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 38
repo_id: adept/fuyu-8b
repo_type: model
status: open
target_branch: null
title: whether special instruction is need to trigger OCR location function?
