!!python/object:huggingface_hub.community.DiscussionWithDetails
author: simonbrbx
conflicting_files: null
created_at: 2023-11-25 14:17:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1281fbd7e6b1b4ec7b7e915c0ed3f5c6.svg
      fullname: barbeaux
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: simonbrbx
      type: user
    createdAt: '2023-11-25T14:17:05.000Z'
    data:
      edited: false
      editors:
      - simonbrbx
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8249421715736389
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1281fbd7e6b1b4ec7b7e915c0ed3f5c6.svg
          fullname: barbeaux
          isHf: false
          isPro: false
          name: simonbrbx
          type: user
        html: "<p>Hello, when I try to run the following script, my environment crashes\
          \ suddenly. If someone could help me, please.</p>\n<p>The Kernel has become\
          \ unresponsive while executing the code in the active cell or a previous\
          \ cell. Please check the code in the cells to identify a possible cause\
          \ of the failure. Click here for more information. For additional details,\
          \ consult the Jupyter log.<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/65578d8f26100eef4a5ce39d/_6X7lrkm35hHjczXU2YsV.png\"\
          ><img alt=\"Capture d\u2019\xE9cran du 2023-11-25 15-14-30.png\" src=\"\
          https://cdn-uploads.huggingface.co/production/uploads/65578d8f26100eef4a5ce39d/_6X7lrkm35hHjczXU2YsV.png\"\
          ></a></p>\n"
        raw: "Hello, when I try to run the following script, my environment crashes\
          \ suddenly. If someone could help me, please.\r\n\r\nThe Kernel has become\
          \ unresponsive while executing the code in the active cell or a previous\
          \ cell. Please check the code in the cells to identify a possible cause\
          \ of the failure. Click here for more information. For additional details,\
          \ consult the Jupyter log.\r\n![Capture d\u2019\xE9cran du 2023-11-25 15-14-30.png](https://cdn-uploads.huggingface.co/production/uploads/65578d8f26100eef4a5ce39d/_6X7lrkm35hHjczXU2YsV.png)\r\
          \n"
        updatedAt: '2023-11-25T14:17:05.295Z'
      numEdits: 0
      reactions: []
    id: 656201e1133861018496fed1
    type: comment
  author: simonbrbx
  content: "Hello, when I try to run the following script, my environment crashes\
    \ suddenly. If someone could help me, please.\r\n\r\nThe Kernel has become unresponsive\
    \ while executing the code in the active cell or a previous cell. Please check\
    \ the code in the cells to identify a possible cause of the failure. Click here\
    \ for more information. For additional details, consult the Jupyter log.\r\n![Capture\
    \ d\u2019\xE9cran du 2023-11-25 15-14-30.png](https://cdn-uploads.huggingface.co/production/uploads/65578d8f26100eef4a5ce39d/_6X7lrkm35hHjczXU2YsV.png)\r\
    \n"
  created_at: 2023-11-25 14:17:05+00:00
  edited: false
  hidden: false
  id: 656201e1133861018496fed1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
      fullname: Pedro Cuenca
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pcuenq
      type: user
    createdAt: '2023-11-25T16:29:26.000Z'
    data:
      edited: false
      editors:
      - pcuenq
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9644753336906433
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
          fullname: Pedro Cuenca
          isHf: true
          isPro: false
          name: pcuenq
          type: user
        html: '<p>How many images are there in the folder you preprocess before loading
          the model? What does the jupyter log say? How much system and GPU memory
          is being used when you run the notebook?</p>

          <p>I would recommend you split the cell in two: one to load the model (run
          this first), and another one to process the images. My bet is you might
          be running out of system memory.</p>

          '
        raw: 'How many images are there in the folder you preprocess before loading
          the model? What does the jupyter log say? How much system and GPU memory
          is being used when you run the notebook?


          I would recommend you split the cell in two: one to load the model (run
          this first), and another one to process the images. My bet is you might
          be running out of system memory.'
        updatedAt: '2023-11-25T16:29:26.740Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - simonbrbx
    id: 656220e6d2e4352d644a9d96
    type: comment
  author: pcuenq
  content: 'How many images are there in the folder you preprocess before loading
    the model? What does the jupyter log say? How much system and GPU memory is being
    used when you run the notebook?


    I would recommend you split the cell in two: one to load the model (run this first),
    and another one to process the images. My bet is you might be running out of system
    memory.'
  created_at: 2023-11-25 16:29:26+00:00
  edited: false
  hidden: false
  id: 656220e6d2e4352d644a9d96
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1281fbd7e6b1b4ec7b7e915c0ed3f5c6.svg
      fullname: barbeaux
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: simonbrbx
      type: user
    createdAt: '2023-11-25T17:28:35.000Z'
    data:
      edited: false
      editors:
      - simonbrbx
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8995461463928223
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1281fbd7e6b1b4ec7b7e915c0ed3f5c6.svg
          fullname: barbeaux
          isHf: false
          isPro: false
          name: simonbrbx
          type: user
        html: '<p>Thank you for your quick response.</p>

          <p>There are only 2 images in the folder. Jupyter redirects me to this page:
          <a rel="nofollow" href="https://github.com/microsoft/vscode-jupyter/wiki/Kernel-crashes">https://github.com/microsoft/vscode-jupyter/wiki/Kernel-crashes</a>.
          The script still crashes at 43 seconds.</p>

          <p>So, I split the code into two parts, with downloading and processing
          the image. However, it still crashes during the model download. The code
          crashes when it reaches my 16GB of RAM, which is 100% utilization.</p>

          <p>What should I do?</p>

          '
        raw: 'Thank you for your quick response.


          There are only 2 images in the folder. Jupyter redirects me to this page:
          [https://github.com/microsoft/vscode-jupyter/wiki/Kernel-crashes](https://github.com/microsoft/vscode-jupyter/wiki/Kernel-crashes).
          The script still crashes at 43 seconds.


          So, I split the code into two parts, with downloading and processing the
          image. However, it still crashes during the model download. The code crashes
          when it reaches my 16GB of RAM, which is 100% utilization.


          What should I do?'
        updatedAt: '2023-11-25T17:28:35.499Z'
      numEdits: 0
      reactions: []
    id: 65622ec384a9fbe322d3387a
    type: comment
  author: simonbrbx
  content: 'Thank you for your quick response.


    There are only 2 images in the folder. Jupyter redirects me to this page: [https://github.com/microsoft/vscode-jupyter/wiki/Kernel-crashes](https://github.com/microsoft/vscode-jupyter/wiki/Kernel-crashes).
    The script still crashes at 43 seconds.


    So, I split the code into two parts, with downloading and processing the image.
    However, it still crashes during the model download. The code crashes when it
    reaches my 16GB of RAM, which is 100% utilization.


    What should I do?'
  created_at: 2023-11-25 17:28:35+00:00
  edited: false
  hidden: false
  id: 65622ec384a9fbe322d3387a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
      fullname: Pedro Cuenca
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pcuenq
      type: user
    createdAt: '2023-11-27T12:29:01.000Z'
    data:
      edited: false
      editors:
      - pcuenq
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8375071883201599
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
          fullname: Pedro Cuenca
          isHf: true
          isPro: false
          name: pcuenq
          type: user
        html: '<p>Do you have a GPU? How much memory does it have? Fuyu requires ~20
          GB of RAM to run in half precision, and double as much in full precision.
          In addition, if you install <code>accelerate</code> (using <code>pip install
          accelerate</code>) you can load the model directly on GPU instead of using
          your system memory and move the weights to GPU later. The following snippet
          uses both techniques to load the model:</p>

          <pre><code class="language-py"><span class="hljs-keyword">from</span> transformers
          <span class="hljs-keyword">import</span> FuyuProcessor, FuyuForCausalLM

          <span class="hljs-keyword">import</span> torch


          model_id = <span class="hljs-string">"adept/fuyu-8b"</span>

          processor = FuyuProcessor.from_pretrained(model_id)

          model = FuyuForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16,
          device_map=<span class="hljs-string">"cuda"</span>)

          </code></pre>

          '
        raw: 'Do you have a GPU? How much memory does it have? Fuyu requires ~20 GB
          of RAM to run in half precision, and double as much in full precision. In
          addition, if you install `accelerate` (using `pip install accelerate`) you
          can load the model directly on GPU instead of using your system memory and
          move the weights to GPU later. The following snippet uses both techniques
          to load the model:


          ```py

          from transformers import FuyuProcessor, FuyuForCausalLM

          import torch


          model_id = "adept/fuyu-8b"

          processor = FuyuProcessor.from_pretrained(model_id)

          model = FuyuForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16,
          device_map="cuda")

          ```

          '
        updatedAt: '2023-11-27T12:29:01.907Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - simonbrbx
    id: 65648b8d3f801175b5a84d90
    type: comment
  author: pcuenq
  content: 'Do you have a GPU? How much memory does it have? Fuyu requires ~20 GB
    of RAM to run in half precision, and double as much in full precision. In addition,
    if you install `accelerate` (using `pip install accelerate`) you can load the
    model directly on GPU instead of using your system memory and move the weights
    to GPU later. The following snippet uses both techniques to load the model:


    ```py

    from transformers import FuyuProcessor, FuyuForCausalLM

    import torch


    model_id = "adept/fuyu-8b"

    processor = FuyuProcessor.from_pretrained(model_id)

    model = FuyuForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16,
    device_map="cuda")

    ```

    '
  created_at: 2023-11-27 12:29:01+00:00
  edited: false
  hidden: false
  id: 65648b8d3f801175b5a84d90
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1281fbd7e6b1b4ec7b7e915c0ed3f5c6.svg
      fullname: barbeaux
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: simonbrbx
      type: user
    createdAt: '2023-11-27T12:45:22.000Z'
    data:
      edited: false
      editors:
      - simonbrbx
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9693315625190735
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1281fbd7e6b1b4ec7b7e915c0ed3f5c6.svg
          fullname: barbeaux
          isHf: false
          isPro: false
          name: simonbrbx
          type: user
        html: '<p>Yes, I have a GPU and it has 8GB of RAM. On my computer, I have
          16GB of DDR4, so that''s probably why it crashes. Do you think I should
          run the code on a cloud, like Google Colab for example?<br>Thank you in
          advance!</p>

          '
        raw: 'Yes, I have a GPU and it has 8GB of RAM. On my computer, I have 16GB
          of DDR4, so that''s probably why it crashes. Do you think I should run the
          code on a cloud, like Google Colab for example?

          Thank you in advance!'
        updatedAt: '2023-11-27T12:45:22.859Z'
      numEdits: 0
      reactions: []
    id: 65648f626c9793d92e6ca190
    type: comment
  author: simonbrbx
  content: 'Yes, I have a GPU and it has 8GB of RAM. On my computer, I have 16GB of
    DDR4, so that''s probably why it crashes. Do you think I should run the code on
    a cloud, like Google Colab for example?

    Thank you in advance!'
  created_at: 2023-11-27 12:45:22+00:00
  edited: false
  hidden: false
  id: 65648f626c9793d92e6ca190
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
      fullname: Pedro Cuenca
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pcuenq
      type: user
    createdAt: '2023-11-27T12:59:35.000Z'
    data:
      edited: false
      editors:
      - pcuenq
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9872040152549744
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
          fullname: Pedro Cuenca
          isHf: true
          isPro: false
          name: pcuenq
          type: user
        html: '<p>Yes, 8 GB of GPU RAM is not much for these large models.</p>

          '
        raw: Yes, 8 GB of GPU RAM is not much for these large models.
        updatedAt: '2023-11-27T12:59:35.732Z'
      numEdits: 0
      reactions: []
    id: 656492b79f7d5e8a3744993c
    type: comment
  author: pcuenq
  content: Yes, 8 GB of GPU RAM is not much for these large models.
  created_at: 2023-11-27 12:59:35+00:00
  edited: false
  hidden: false
  id: 656492b79f7d5e8a3744993c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0355c91c06e3eb80b972d66c810b3633.svg
      fullname: sanchd
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchd
      type: user
    createdAt: '2023-12-07T18:31:24.000Z'
    data:
      edited: false
      editors:
      - sanchd
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9880633354187012
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0355c91c06e3eb80b972d66c810b3633.svg
          fullname: sanchd
          isHf: false
          isPro: false
          name: sanchd
          type: user
        html: '<p>Hi,<br>I have same issue here. I am trying to run this model in
          GPU but it gets out of memory. I have a 3080Ti with 12GiB and my computer
          has 32GiB.</p>

          '
        raw: 'Hi,

          I have same issue here. I am trying to run this model in GPU but it gets
          out of memory. I have a 3080Ti with 12GiB and my computer has 32GiB.'
        updatedAt: '2023-12-07T18:31:24.637Z'
      numEdits: 0
      reactions: []
    id: 65720f7c05e8971e5a0d54a4
    type: comment
  author: sanchd
  content: 'Hi,

    I have same issue here. I am trying to run this model in GPU but it gets out of
    memory. I have a 3080Ti with 12GiB and my computer has 32GiB.'
  created_at: 2023-12-07 18:31:24+00:00
  edited: false
  hidden: false
  id: 65720f7c05e8971e5a0d54a4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 57
repo_id: adept/fuyu-8b
repo_type: model
status: open
target_branch: null
title: crash kernel
