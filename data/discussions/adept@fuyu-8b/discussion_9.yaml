!!python/object:huggingface_hub.community.DiscussionWithDetails
author: NickyNicky
conflicting_files: null
created_at: 2023-10-18 23:28:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ab1fba948e86cce23e8ab573f12ff04.svg
      fullname: Nicky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NickyNicky
      type: user
    createdAt: '2023-10-19T00:28:05.000Z'
    data:
      edited: false
      editors:
      - NickyNicky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9353148937225342
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ab1fba948e86cce23e8ab573f12ff04.svg
          fullname: Nicky
          isHf: false
          isPro: false
          name: NickyNicky
          type: user
        html: '<p>Thank you very much for a model with these capabilities.</p>

          <p>I have some questions:</p>

          <p>Is it possible to fine tune the Qlora model, flash-attention, add special
          tokens?<br>Is there an example in collaboration so I can reproduce it?</p>

          '
        raw: "Thank you very much for a model with these capabilities.\r\n\r\nI have\
          \ some questions:\r\n\r\nIs it possible to fine tune the Qlora model, flash-attention,\
          \ add special tokens?\r\nIs there an example in collaboration so I can reproduce\
          \ it?\r\n"
        updatedAt: '2023-10-19T00:28:05.332Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\U0001F44D"
        users:
        - Kernel
        - latent-variable
        - osanseviero
        - Andcircle
        - laraSL
    id: 6530781548dfcb0ba9c15c0b
    type: comment
  author: NickyNicky
  content: "Thank you very much for a model with these capabilities.\r\n\r\nI have\
    \ some questions:\r\n\r\nIs it possible to fine tune the Qlora model, flash-attention,\
    \ add special tokens?\r\nIs there an example in collaboration so I can reproduce\
    \ it?\r\n"
  created_at: 2023-10-18 23:28:05+00:00
  edited: false
  hidden: false
  id: 6530781548dfcb0ba9c15c0b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-10-20T10:14:02.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9894821643829346
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>We''ll try to share finetuning scripts as soon as possible ! </p>

          '
        raw: 'We''ll try to share finetuning scripts as soon as possible ! '
        updatedAt: '2023-10-20T10:14:02.076Z'
      numEdits: 0
      reactions:
      - count: 8
        reaction: "\U0001F44D"
        users:
        - Andcircle
        - tim9510019
        - victor
        - kangzhe
        - daniellawson9999
        - Nooodles
        - fanqing
        - nengelmann
      - count: 4
        reaction: "\u2764\uFE0F"
        users:
        - pcuenq
        - tim9510019
        - victor
        - Benson
    id: 653252ea6e2c9340314e7480
    type: comment
  author: ArthurZ
  content: 'We''ll try to share finetuning scripts as soon as possible ! '
  created_at: 2023-10-20 09:14:02+00:00
  edited: false
  hidden: false
  id: 653252ea6e2c9340314e7480
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ab1fba948e86cce23e8ab573f12ff04.svg
      fullname: Nicky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NickyNicky
      type: user
    createdAt: '2023-10-20T10:31:05.000Z'
    data:
      edited: false
      editors:
      - NickyNicky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9718029499053955
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ab1fba948e86cce23e8ab573f12ff04.svg
          fullname: Nicky
          isHf: false
          isPro: false
          name: NickyNicky
          type: user
        html: '<p>Thank you very much for the model, it is very good. Will it not
          be possible to observe the evaluations with large models?</p>

          '
        raw: Thank you very much for the model, it is very good. Will it not be possible
          to observe the evaluations with large models?
        updatedAt: '2023-10-20T10:31:05.910Z'
      numEdits: 0
      reactions: []
    id: 653256e950f0ed02adf67208
    type: comment
  author: NickyNicky
  content: Thank you very much for the model, it is very good. Will it not be possible
    to observe the evaluations with large models?
  created_at: 2023-10-20 09:31:05+00:00
  edited: false
  hidden: false
  id: 653256e950f0ed02adf67208
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1633453199694-5ebb6509a8e72729bee106a0.png?w=200&h=200&f=face
      fullname: Nathan Cooper
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ncoop57
      type: user
    createdAt: '2023-10-23T00:13:48.000Z'
    data:
      edited: false
      editors:
      - ncoop57
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9153881072998047
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1633453199694-5ebb6509a8e72729bee106a0.png?w=200&h=200&f=face
          fullname: Nathan Cooper
          isHf: false
          isPro: false
          name: ncoop57
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ArthurZ&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ArthurZ\">@<span class=\"\
          underline\">ArthurZ</span></a></span>\n\n\t</span></span> not sure if this\
          \ help, but I have been trying to create a finetuning example for huggingface\
          \ here: <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/pull/26997\"\
          >https://github.com/huggingface/transformers/pull/26997</a></p>\n<p>Ran\
          \ into issues around padding the batches and would love some help :D</p>\n"
        raw: '@ArthurZ not sure if this help, but I have been trying to create a finetuning
          example for huggingface here: https://github.com/huggingface/transformers/pull/26997


          Ran into issues around padding the batches and would love some help :D'
        updatedAt: '2023-10-23T00:13:48.809Z'
      numEdits: 0
      reactions: []
    id: 6535babc31e73689f32c0641
    type: comment
  author: ncoop57
  content: '@ArthurZ not sure if this help, but I have been trying to create a finetuning
    example for huggingface here: https://github.com/huggingface/transformers/pull/26997


    Ran into issues around padding the batches and would love some help :D'
  created_at: 2023-10-22 23:13:48+00:00
  edited: false
  hidden: false
  id: 6535babc31e73689f32c0641
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
      fullname: Pablo Montalvo
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Molbap
      type: user
    createdAt: '2023-10-24T13:40:31.000Z'
    data:
      edited: false
      editors:
      - Molbap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8716980218887329
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
          fullname: Pablo Montalvo
          isHf: true
          isPro: false
          name: Molbap
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ncoop57&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ncoop57\">@<span class=\"\
          underline\">ncoop57</span></a></span>\n\n\t</span></span> the padding of\
          \ batches is a bit tricky, and it will be supported in main when this PR\
          \ <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/pull/27007\"\
          >https://github.com/huggingface/transformers/pull/27007</a> is done, we're\
          \ on it!</p>\n"
        raw: '@ncoop57 the padding of batches is a bit tricky, and it will be supported
          in main when this PR https://github.com/huggingface/transformers/pull/27007
          is done, we''re on it!'
        updatedAt: '2023-10-24T13:40:31.834Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - to-be
        - yizhilll
        - ncoop57
    id: 6537c94f81da1e536e30f3f2
    type: comment
  author: Molbap
  content: '@ncoop57 the padding of batches is a bit tricky, and it will be supported
    in main when this PR https://github.com/huggingface/transformers/pull/27007 is
    done, we''re on it!'
  created_at: 2023-10-24 12:40:31+00:00
  edited: false
  hidden: false
  id: 6537c94f81da1e536e30f3f2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: adept/fuyu-8b
repo_type: model
status: open
target_branch: null
title: fine tune model Posible?
