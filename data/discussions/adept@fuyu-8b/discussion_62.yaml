!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Nyandwi
conflicting_files: null
created_at: 2023-12-04 13:33:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654168730944-noauth.png?w=200&h=200&f=face
      fullname: Jean de Dieu Nyandwi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nyandwi
      type: user
    createdAt: '2023-12-04T13:33:25.000Z'
    data:
      edited: false
      editors:
      - Nyandwi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8675766587257385
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654168730944-noauth.png?w=200&h=200&f=face
          fullname: Jean de Dieu Nyandwi
          isHf: false
          isPro: false
          name: Nyandwi
          type: user
        html: "<p>I am wondering if there are some special tokens that are ignored\
          \ from the processed inputs when computing the loss(given the input ids\
          \ as labels). My inputs ids looks something like below(attached image).\
          \  When forwarding all inputs from processor to the model, the loss is very\
          \ high. Without 71011(Speaker token), the loss is low but still not good.\
          \ From the source code of <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/blob/main/src/transformers/models/fuyu/processing_fuyu.py\"\
          >processor</a>, the speaker tokens are place-holder for image. Given that\
          \ images are represented by speaker token, it's somehow counterintuitive\
          \ that removing the speaker tokens in loss computations will reduce the\
          \ loss.</p>\n<p>Is there something that I am missing or something that was\
          \ not documented about how the loss is computed?</p>\n<p><a rel=\"nofollow\"\
          \ href=\"https://cdn-uploads.huggingface.co/production/uploads/62989cd743e990340bead77c/ANVGkR6I8dgsMNuj8SbIB.png\"\
          ><img alt=\"Screenshot 2023-12-03 at 12.18.20.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/62989cd743e990340bead77c/ANVGkR6I8dgsMNuj8SbIB.png\"\
          ></a></p>\n<p>Support on this appreciated! CC: <span data-props=\"{&quot;user&quot;:&quot;pcuenq&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/pcuenq\"\
          >@<span class=\"underline\">pcuenq</span></a></span>\n\n\t</span></span>\
          \  <span data-props=\"{&quot;user&quot;:&quot;ArthurZ&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ArthurZ\">@<span class=\"\
          underline\">ArthurZ</span></a></span>\n\n\t</span></span> <span data-props=\"\
          {&quot;user&quot;:&quot;Molbap&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/Molbap\">@<span class=\"underline\">Molbap</span></a></span>\n\
          \n\t</span></span> </p>\n"
        raw: "I am wondering if there are some special tokens that are ignored from\
          \ the processed inputs when computing the loss(given the input ids as labels).\
          \ My inputs ids looks something like below(attached image).  When forwarding\
          \ all inputs from processor to the model, the loss is very high. Without\
          \ 71011(Speaker token), the loss is low but still not good. From the source\
          \ code of [processor](https://github.com/huggingface/transformers/blob/main/src/transformers/models/fuyu/processing_fuyu.py),\
          \ the speaker tokens are place-holder for image. Given that images are represented\
          \ by speaker token, it's somehow counterintuitive that removing the speaker\
          \ tokens in loss computations will reduce the loss.\r\n\r\nIs there something\
          \ that I am missing or something that was not documented about how the loss\
          \ is computed?\r\n\r\n![Screenshot 2023-12-03 at 12.18.20.png](https://cdn-uploads.huggingface.co/production/uploads/62989cd743e990340bead77c/ANVGkR6I8dgsMNuj8SbIB.png)\r\
          \n\r\nSupport on this appreciated! CC: @pcuenq  @ArthurZ @Molbap \r\n"
        updatedAt: '2023-12-04T13:33:25.613Z'
      numEdits: 0
      reactions: []
    id: 656dd5256836cb340aa69c94
    type: comment
  author: Nyandwi
  content: "I am wondering if there are some special tokens that are ignored from\
    \ the processed inputs when computing the loss(given the input ids as labels).\
    \ My inputs ids looks something like below(attached image).  When forwarding all\
    \ inputs from processor to the model, the loss is very high. Without 71011(Speaker\
    \ token), the loss is low but still not good. From the source code of [processor](https://github.com/huggingface/transformers/blob/main/src/transformers/models/fuyu/processing_fuyu.py),\
    \ the speaker tokens are place-holder for image. Given that images are represented\
    \ by speaker token, it's somehow counterintuitive that removing the speaker tokens\
    \ in loss computations will reduce the loss.\r\n\r\nIs there something that I\
    \ am missing or something that was not documented about how the loss is computed?\r\
    \n\r\n![Screenshot 2023-12-03 at 12.18.20.png](https://cdn-uploads.huggingface.co/production/uploads/62989cd743e990340bead77c/ANVGkR6I8dgsMNuj8SbIB.png)\r\
    \n\r\nSupport on this appreciated! CC: @pcuenq  @ArthurZ @Molbap \r\n"
  created_at: 2023-12-04 13:33:25+00:00
  edited: false
  hidden: false
  id: 656dd5256836cb340aa69c94
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
      fullname: Pablo Montalvo
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Molbap
      type: user
    createdAt: '2023-12-04T13:49:01.000Z'
    data:
      edited: false
      editors:
      - Molbap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8929921388626099
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
          fullname: Pablo Montalvo
          isHf: true
          isPro: false
          name: Molbap
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Nyandwi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Nyandwi\"\
          >@<span class=\"underline\">Nyandwi</span></a></span>\n\n\t</span></span>\
          \ , the code available around Fuyu is indeed inference-centered, and we\
          \ do not have an official training script. There are ongoing contributors\
          \ work at <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/pull/26997\"\
          >https://github.com/huggingface/transformers/pull/26997</a> for instance,\
          \ and the folks from OtterHD have independently retrained a Fuyu-like architecture\
          \ on high-resolution data, you can take a look there <a rel=\"nofollow\"\
          \ href=\"https://github.com/Luodian/Otter/blob/main/docs/OtterHD.md\">https://github.com/Luodian/Otter/blob/main/docs/OtterHD.md</a>\
          \ ! If you have a code snippet, that can be helpful :) </p>\n"
        raw: 'Hey @Nyandwi , the code available around Fuyu is indeed inference-centered,
          and we do not have an official training script. There are ongoing contributors
          work at https://github.com/huggingface/transformers/pull/26997 for instance,
          and the folks from OtterHD have independently retrained a Fuyu-like architecture
          on high-resolution data, you can take a look there https://github.com/Luodian/Otter/blob/main/docs/OtterHD.md
          ! If you have a code snippet, that can be helpful :) '
        updatedAt: '2023-12-04T13:49:01.180Z'
      numEdits: 0
      reactions: []
    id: 656dd8cd1812378141c273b2
    type: comment
  author: Molbap
  content: 'Hey @Nyandwi , the code available around Fuyu is indeed inference-centered,
    and we do not have an official training script. There are ongoing contributors
    work at https://github.com/huggingface/transformers/pull/26997 for instance, and
    the folks from OtterHD have independently retrained a Fuyu-like architecture on
    high-resolution data, you can take a look there https://github.com/Luodian/Otter/blob/main/docs/OtterHD.md
    ! If you have a code snippet, that can be helpful :) '
  created_at: 2023-12-04 13:49:01+00:00
  edited: false
  hidden: false
  id: 656dd8cd1812378141c273b2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654168730944-noauth.png?w=200&h=200&f=face
      fullname: Jean de Dieu Nyandwi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nyandwi
      type: user
    createdAt: '2023-12-04T14:32:39.000Z'
    data:
      edited: false
      editors:
      - Nyandwi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.676037609577179
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654168730944-noauth.png?w=200&h=200&f=face
          fullname: Jean de Dieu Nyandwi
          isHf: false
          isPro: false
          name: Nyandwi
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;Molbap&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Molbap\">@<span class=\"\
          underline\">Molbap</span></a></span>\n\n\t</span></span>. Thanks for the\
          \ quick response and sharing those pointers.</p>\n<p>I am also doing inference\
          \ where given an image and text prompt, I want to compute the loss, the\
          \ labels being the input_ids.</p>\n<pre><code class=\"language-py\">model_id\
          \ = <span class=\"hljs-string\">\"adept/fuyu-8b\"</span>\nprocessor = FuyuProcessor.from_pretrained(model_id)\n\
          model = FuyuForCausalLM.from_pretrained(model_id, device_map=<span class=\"\
          hljs-string\">\"cuda:0\"</span>, torch_dtype=torch.bfloat16)\n\ninputs =\
          \ processor(text=prompt, images=sample_im_1, return_tensors=<span class=\"\
          hljs-string\">\"pt\"</span>).to(<span class=\"hljs-string\">\"cuda:0\"</span>,\
          \ torch.bfloat16)\n\n<span class=\"hljs-keyword\">with</span> torch.inference_mode():\n\
          \    outputs =  model(**inputs, labels=inputs[<span class=\"hljs-string\"\
          >\"input_ids\"</span>])\n\nloss = outputs.loss\n</code></pre>\n<p>The above\
          \ gives me high loss but when I removes the speaker token, the loss reduces\
          \ significantly but the model is likely not using images since speaker token\
          \ refers to image place holder according to preprocessing script.</p>\n\
          <pre><code class=\"language-py\">input_ids = inputs[<span class=\"hljs-string\"\
          >\"input_ids\"</span>]\nspeaker_token = processor.tokenizer.convert_tokens_to_ids(<span\
          \ class=\"hljs-string\">'|SPEAKER|'</span>)\ninput_labels = input_ids.masked_fill(input_ids\
          \ == speaker_token, -<span class=\"hljs-number\">100</span>)\n</code></pre>\n\
          <p>Also related, is <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/blob/main/src/transformers/models/fuyu/modeling_fuyu.py#L316\"\
          >prepare_inputs_for_generation()</a> hard requirement to apply to model\
          \ inputs(from processor)?</p>\n"
        raw: "Hi @Molbap. Thanks for the quick response and sharing those pointers.\n\
          \nI am also doing inference where given an image and text prompt, I want\
          \ to compute the loss, the labels being the input_ids.\n\n```py\nmodel_id\
          \ = \"adept/fuyu-8b\"\nprocessor = FuyuProcessor.from_pretrained(model_id)\n\
          model = FuyuForCausalLM.from_pretrained(model_id, device_map=\"cuda:0\"\
          , torch_dtype=torch.bfloat16)\n\ninputs = processor(text=prompt, images=sample_im_1,\
          \ return_tensors=\"pt\").to(\"cuda:0\", torch.bfloat16)\n\nwith torch.inference_mode():\n\
          \    outputs =  model(**inputs, labels=inputs[\"input_ids\"])\n\nloss =\
          \ outputs.loss\n```\n\nThe above gives me high loss but when I removes the\
          \ speaker token, the loss reduces significantly but the model is likely\
          \ not using images since speaker token refers to image place holder according\
          \ to preprocessing script.\n\n```py\ninput_ids = inputs[\"input_ids\"]\n\
          speaker_token = processor.tokenizer.convert_tokens_to_ids('|SPEAKER|')\n\
          input_labels = input_ids.masked_fill(input_ids == speaker_token, -100)\n\
          ```\n\nAlso related, is [prepare_inputs_for_generation()](https://github.com/huggingface/transformers/blob/main/src/transformers/models/fuyu/modeling_fuyu.py#L316)\
          \ hard requirement to apply to model inputs(from processor)?"
        updatedAt: '2023-12-04T14:32:39.006Z'
      numEdits: 0
      reactions: []
    id: 656de307b9fa60e33d2d91f4
    type: comment
  author: Nyandwi
  content: "Hi @Molbap. Thanks for the quick response and sharing those pointers.\n\
    \nI am also doing inference where given an image and text prompt, I want to compute\
    \ the loss, the labels being the input_ids.\n\n```py\nmodel_id = \"adept/fuyu-8b\"\
    \nprocessor = FuyuProcessor.from_pretrained(model_id)\nmodel = FuyuForCausalLM.from_pretrained(model_id,\
    \ device_map=\"cuda:0\", torch_dtype=torch.bfloat16)\n\ninputs = processor(text=prompt,\
    \ images=sample_im_1, return_tensors=\"pt\").to(\"cuda:0\", torch.bfloat16)\n\n\
    with torch.inference_mode():\n    outputs =  model(**inputs, labels=inputs[\"\
    input_ids\"])\n\nloss = outputs.loss\n```\n\nThe above gives me high loss but\
    \ when I removes the speaker token, the loss reduces significantly but the model\
    \ is likely not using images since speaker token refers to image place holder\
    \ according to preprocessing script.\n\n```py\ninput_ids = inputs[\"input_ids\"\
    ]\nspeaker_token = processor.tokenizer.convert_tokens_to_ids('|SPEAKER|')\ninput_labels\
    \ = input_ids.masked_fill(input_ids == speaker_token, -100)\n```\n\nAlso related,\
    \ is [prepare_inputs_for_generation()](https://github.com/huggingface/transformers/blob/main/src/transformers/models/fuyu/modeling_fuyu.py#L316)\
    \ hard requirement to apply to model inputs(from processor)?"
  created_at: 2023-12-04 14:32:39+00:00
  edited: false
  hidden: false
  id: 656de307b9fa60e33d2d91f4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
      fullname: Pablo Montalvo
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Molbap
      type: user
    createdAt: '2023-12-05T07:41:51.000Z'
    data:
      edited: false
      editors:
      - Molbap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8179858922958374
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
          fullname: Pablo Montalvo
          isHf: true
          isPro: false
          name: Molbap
          type: user
        html: '<p>The model <em>is</em> using images: in the model, the embeddings
          of your image patches <code>sample_im_1</code> are placed at the positions
          indicated by the placeholder image tokens. Check out the source code here
          in particular <a rel="nofollow" href="https://github.com/huggingface/transformers/blob/235e5d4991e8a0984aa78db91087b49622c7740e/src/transformers/models/fuyu/modeling_fuyu.py#L289C1-L300C18">https://github.com/huggingface/transformers/blob/235e5d4991e8a0984aa78db91087b49622c7740e/src/transformers/models/fuyu/modeling_fuyu.py#L289C1-L300C18</a>.
          So it is expected to have different losses. By removing the speaker tokens,
          you''re actually disabling the image input. </p>

          <p>I''m not sure I get your second question, it might be better suited for
          the forums  <a rel="nofollow" href="https://discuss.huggingface.co/">https://discuss.huggingface.co/</a>
          ? <code>prepare_inputs_for_generation</code> is a <code>GenerationMixin</code>-related
          method, it is not linked to the call <code>model(**inputs)</code>. It will
          be if you do <code>model.generate(**inputs)</code>, for instance.</p>

          '
        raw: "The model _is_ using images: in the model, the embeddings of your image\
          \ patches `sample_im_1` are placed at the positions indicated by the placeholder\
          \ image tokens. Check out the source code here in particular https://github.com/huggingface/transformers/blob/235e5d4991e8a0984aa78db91087b49622c7740e/src/transformers/models/fuyu/modeling_fuyu.py#L289C1-L300C18.\
          \ So it is expected to have different losses. By removing the speaker tokens,\
          \ you're actually disabling the image input. \n\nI'm not sure I get your\
          \ second question, it might be better suited for the forums  https://discuss.huggingface.co/\
          \ ? `prepare_inputs_for_generation` is a `GenerationMixin`-related method,\
          \ it is not linked to the call `model(**inputs)`. It will be if you do `model.generate(**inputs)`,\
          \ for instance."
        updatedAt: '2023-12-05T07:41:51.500Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Nyandwi
    id: 656ed43f2e0a38afd19d3567
    type: comment
  author: Molbap
  content: "The model _is_ using images: in the model, the embeddings of your image\
    \ patches `sample_im_1` are placed at the positions indicated by the placeholder\
    \ image tokens. Check out the source code here in particular https://github.com/huggingface/transformers/blob/235e5d4991e8a0984aa78db91087b49622c7740e/src/transformers/models/fuyu/modeling_fuyu.py#L289C1-L300C18.\
    \ So it is expected to have different losses. By removing the speaker tokens,\
    \ you're actually disabling the image input. \n\nI'm not sure I get your second\
    \ question, it might be better suited for the forums  https://discuss.huggingface.co/\
    \ ? `prepare_inputs_for_generation` is a `GenerationMixin`-related method, it\
    \ is not linked to the call `model(**inputs)`. It will be if you do `model.generate(**inputs)`,\
    \ for instance."
  created_at: 2023-12-05 07:41:51+00:00
  edited: false
  hidden: false
  id: 656ed43f2e0a38afd19d3567
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654168730944-noauth.png?w=200&h=200&f=face
      fullname: Jean de Dieu Nyandwi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nyandwi
      type: user
    createdAt: '2023-12-05T10:40:49.000Z'
    data:
      from: Are there special tokens that are ignore during loss computation?
      to: Are there special tokens that are ignored during loss computation?
    id: 656efe31b467bcf6d3e92692
    type: title-change
  author: Nyandwi
  created_at: 2023-12-05 10:40:49+00:00
  id: 656efe31b467bcf6d3e92692
  new_title: Are there special tokens that are ignored during loss computation?
  old_title: Are there special tokens that are ignore during loss computation?
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654168730944-noauth.png?w=200&h=200&f=face
      fullname: Jean de Dieu Nyandwi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nyandwi
      type: user
    createdAt: '2023-12-05T11:08:32.000Z'
    data:
      edited: true
      editors:
      - Nyandwi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.961510956287384
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654168730944-noauth.png?w=200&h=200&f=face
          fullname: Jean de Dieu Nyandwi
          isHf: false
          isPro: false
          name: Nyandwi
          type: user
        html: "<p>Thanks for the support, <span data-props=\"{&quot;user&quot;:&quot;Molbap&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Molbap\"\
          >@<span class=\"underline\">Molbap</span></a></span>\n\n\t</span></span>.\
          \ I will keep inspecting where the issue of exponential loss(with all input\
          \ ids) might be coming from. For the later, that was my guess too since\
          \ using it for further input preprocessing didn't even make a difference\
          \ for my case.</p>\n<p>Edit: Can the absence of training support impacts\
          \ the inference of <code>model(**inputs)</code>? It's unlikely, but just\
          \ to clarify. With generate functionality, I get good response out. It's\
          \ a bit weird the loss does not agree.</p>\n"
        raw: 'Thanks for the support, @Molbap. I will keep inspecting where the issue
          of exponential loss(with all input ids) might be coming from. For the later,
          that was my guess too since using it for further input preprocessing didn''t
          even make a difference for my case.


          Edit: Can the absence of training support impacts the inference of `model(**inputs)`?
          It''s unlikely, but just to clarify. With generate functionality, I get
          good response out. It''s a bit weird the loss does not agree.'
        updatedAt: '2023-12-05T11:29:39.243Z'
      numEdits: 1
      reactions: []
    id: 656f04b07e3e612b356fe4a3
    type: comment
  author: Nyandwi
  content: 'Thanks for the support, @Molbap. I will keep inspecting where the issue
    of exponential loss(with all input ids) might be coming from. For the later, that
    was my guess too since using it for further input preprocessing didn''t even make
    a difference for my case.


    Edit: Can the absence of training support impacts the inference of `model(**inputs)`?
    It''s unlikely, but just to clarify. With generate functionality, I get good response
    out. It''s a bit weird the loss does not agree.'
  created_at: 2023-12-05 11:08:32+00:00
  edited: true
  hidden: false
  id: 656f04b07e3e612b356fe4a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
      fullname: Pablo Montalvo
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Molbap
      type: user
    createdAt: '2023-12-06T13:57:43.000Z'
    data:
      edited: false
      editors:
      - Molbap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9904652237892151
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
          fullname: Pablo Montalvo
          isHf: true
          isPro: false
          name: Molbap
          type: user
        html: '<p>As you said, no, I don''t think it would impact the output of a
          forward pass. :) </p>

          '
        raw: 'As you said, no, I don''t think it would impact the output of a forward
          pass. :) '
        updatedAt: '2023-12-06T13:57:43.813Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Nyandwi
    id: 65707dd7ea13fc152ae4f9a9
    type: comment
  author: Molbap
  content: 'As you said, no, I don''t think it would impact the output of a forward
    pass. :) '
  created_at: 2023-12-06 13:57:43+00:00
  edited: false
  hidden: false
  id: 65707dd7ea13fc152ae4f9a9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1f2ad9bc4e9e729fe7bfd7dcc76207a4.svg
      fullname: graham
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: besiktas
      type: user
    createdAt: '2023-12-07T18:34:19.000Z'
    data:
      edited: true
      editors:
      - besiktas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8461692929267883
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1f2ad9bc4e9e729fe7bfd7dcc76207a4.svg
          fullname: graham
          isHf: false
          isPro: false
          name: besiktas
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Nyandwi&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Nyandwi\">@<span class=\"\
          underline\">Nyandwi</span></a></span>\n\n\t</span></span> you will want\
          \ to mask out the |SPEAKER| and tokens related to your input/instructions\
          \ to the ignore index. Otherwise while finetuning this model it will be\
          \ focused on predicted what part of the input is actually just image patches\
          \ and instructions (not helpful).</p>\n"
        raw: '@Nyandwi you will want to mask out the |SPEAKER| and tokens related
          to your input/instructions to the ignore index. Otherwise while finetuning
          this model it will be focused on predicted what part of the input is actually
          just image patches and instructions (not helpful).'
        updatedAt: '2023-12-08T19:29:21.731Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Molbap
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Nyandwi
    id: 6572102b2bb242937ce60b69
    type: comment
  author: besiktas
  content: '@Nyandwi you will want to mask out the |SPEAKER| and tokens related to
    your input/instructions to the ignore index. Otherwise while finetuning this model
    it will be focused on predicted what part of the input is actually just image
    patches and instructions (not helpful).'
  created_at: 2023-12-07 18:34:19+00:00
  edited: true
  hidden: false
  id: 6572102b2bb242937ce60b69
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654168730944-noauth.png?w=200&h=200&f=face
      fullname: Jean de Dieu Nyandwi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nyandwi
      type: user
    createdAt: '2023-12-09T19:14:05.000Z'
    data:
      edited: false
      editors:
      - Nyandwi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9156227707862854
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654168730944-noauth.png?w=200&h=200&f=face
          fullname: Jean de Dieu Nyandwi
          isHf: false
          isPro: false
          name: Nyandwi
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;besiktas&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/besiktas\"\
          >@<span class=\"underline\">besiktas</span></a></span>\n\n\t</span></span>.\
          \ Thanks for sharing that, really appreciate. That might speak to why removing\
          \ the speaker tokens reduce loss substantially. What part of the input instructions\
          \ that you meant or I generally should mask all special tokens? One of my\
          \ input prompts is <code>\"Is the {caption} a good description of the image?\"\
          .</code>Do you meant to mask everything except <code>{caption}</code>? If\
          \ you have a reason why we have to mask out those tokens from the model\
          \ perspective or beyond, I would love to hear that. Thank you!</p>\n"
        raw: Hi @besiktas. Thanks for sharing that, really appreciate. That might
          speak to why removing the speaker tokens reduce loss substantially. What
          part of the input instructions that you meant or I generally should mask
          all special tokens? One of my input prompts is `"Is the {caption} a good
          description of the image?".`Do you meant to mask everything except `{caption}`?
          If you have a reason why we have to mask out those tokens from the model
          perspective or beyond, I would love to hear that. Thank you!
        updatedAt: '2023-12-09T19:14:05.538Z'
      numEdits: 0
      reactions: []
    id: 6574bc7d54d1749612d1b3b9
    type: comment
  author: Nyandwi
  content: Hi @besiktas. Thanks for sharing that, really appreciate. That might speak
    to why removing the speaker tokens reduce loss substantially. What part of the
    input instructions that you meant or I generally should mask all special tokens?
    One of my input prompts is `"Is the {caption} a good description of the image?".`Do
    you meant to mask everything except `{caption}`? If you have a reason why we have
    to mask out those tokens from the model perspective or beyond, I would love to
    hear that. Thank you!
  created_at: 2023-12-09 19:14:05+00:00
  edited: false
  hidden: false
  id: 6574bc7d54d1749612d1b3b9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1f2ad9bc4e9e729fe7bfd7dcc76207a4.svg
      fullname: graham
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: besiktas
      type: user
    createdAt: '2023-12-09T20:02:28.000Z'
    data:
      edited: false
      editors:
      - besiktas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9599420428276062
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1f2ad9bc4e9e729fe7bfd7dcc76207a4.svg
          fullname: graham
          isHf: false
          isPro: false
          name: besiktas
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Nyandwi&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Nyandwi\">@<span class=\"\
          underline\">Nyandwi</span></a></span>\n\n\t</span></span> I would maybe\
          \ rephrase the instruction so that it is \"Is the following caption a good\
          \ description of the image: {caption}\" in which case you just mask out\
          \ the length of the tokens for <code>Is the following caption a good description\
          \ of the image:</code> (meaning don't mask out based on token values and\
          \ you may also want to include the boa token before caption).  </p>\n<p>I\
          \ believe I have seen it done both ways, conceptually masking out the instruction\
          \ is trying to get the model to provide an appropriate response given the\
          \ caption. </p>\n<p>If you don't mask them out, in theory I would bet it\
          \ still works and trains eventually to what you aim for but given the CrossEntropyLoss\
          \ uses mean reduction (if you provide labels to the model for forward) as\
          \ the model learns to complete the instruction, the gradient wrt the caption/answer\
          \ you actually want the model to output will be dampened compared to if\
          \ you had masked out the instructions.</p>\n"
        raw: "@Nyandwi I would maybe rephrase the instruction so that it is \"Is the\
          \ following caption a good description of the image: {caption}\" in which\
          \ case you just mask out the length of the tokens for `Is the following\
          \ caption a good description of the image:` (meaning don't mask out based\
          \ on token values and you may also want to include the boa token before\
          \ caption).  \n\nI believe I have seen it done both ways, conceptually masking\
          \ out the instruction is trying to get the model to provide an appropriate\
          \ response given the caption. \n\nIf you don't mask them out, in theory\
          \ I would bet it still works and trains eventually to what you aim for but\
          \ given the CrossEntropyLoss uses mean reduction (if you provide labels\
          \ to the model for forward) as the model learns to complete the instruction,\
          \ the gradient wrt the caption/answer you actually want the model to output\
          \ will be dampened compared to if you had masked out the instructions."
        updatedAt: '2023-12-09T20:02:28.508Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Nyandwi
    id: 6574c7d47184b6d40829e3b9
    type: comment
  author: besiktas
  content: "@Nyandwi I would maybe rephrase the instruction so that it is \"Is the\
    \ following caption a good description of the image: {caption}\" in which case\
    \ you just mask out the length of the tokens for `Is the following caption a good\
    \ description of the image:` (meaning don't mask out based on token values and\
    \ you may also want to include the boa token before caption).  \n\nI believe I\
    \ have seen it done both ways, conceptually masking out the instruction is trying\
    \ to get the model to provide an appropriate response given the caption. \n\n\
    If you don't mask them out, in theory I would bet it still works and trains eventually\
    \ to what you aim for but given the CrossEntropyLoss uses mean reduction (if you\
    \ provide labels to the model for forward) as the model learns to complete the\
    \ instruction, the gradient wrt the caption/answer you actually want the model\
    \ to output will be dampened compared to if you had masked out the instructions."
  created_at: 2023-12-09 20:02:28+00:00
  edited: false
  hidden: false
  id: 6574c7d47184b6d40829e3b9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654168730944-noauth.png?w=200&h=200&f=face
      fullname: Jean de Dieu Nyandwi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nyandwi
      type: user
    createdAt: '2023-12-10T08:48:32.000Z'
    data:
      edited: false
      editors:
      - Nyandwi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9341964721679688
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654168730944-noauth.png?w=200&h=200&f=face
          fullname: Jean de Dieu Nyandwi
          isHf: false
          isPro: false
          name: Nyandwi
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;besiktas&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/besiktas\">@<span class=\"\
          underline\">besiktas</span></a></span>\n\n\t</span></span>, Thanks a lot,\
          \ that really helps and once again appreciate your time. With that, is the\
          \ instruction(or any other prefix) useful in this regard since we ultimately\
          \ mask it out, or it is(since the input ids in forward still contains all\
          \ tokens, speaker &amp; instructions) but it's not relevant for loss computation?\
          \ I like the instruction rephrase, that's brilliant.</p>\n"
        raw: '@besiktas, Thanks a lot, that really helps and once again appreciate
          your time. With that, is the instruction(or any other prefix) useful in
          this regard since we ultimately mask it out, or it is(since the input ids
          in forward still contains all tokens, speaker & instructions) but it''s
          not relevant for loss computation? I like the instruction rephrase, that''s
          brilliant.'
        updatedAt: '2023-12-10T08:48:32.493Z'
      numEdits: 0
      reactions: []
    id: 65757b60addd9129ff7f9932
    type: comment
  author: Nyandwi
  content: '@besiktas, Thanks a lot, that really helps and once again appreciate your
    time. With that, is the instruction(or any other prefix) useful in this regard
    since we ultimately mask it out, or it is(since the input ids in forward still
    contains all tokens, speaker & instructions) but it''s not relevant for loss computation?
    I like the instruction rephrase, that''s brilliant.'
  created_at: 2023-12-10 08:48:32+00:00
  edited: false
  hidden: false
  id: 65757b60addd9129ff7f9932
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 62
repo_id: adept/fuyu-8b
repo_type: model
status: open
target_branch: null
title: Are there special tokens that are ignored during loss computation?
