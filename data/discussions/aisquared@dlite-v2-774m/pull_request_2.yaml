!!python/object:huggingface_hub.community.DiscussionWithDetails
author: srowen
conflicting_files: []
created_at: 2023-05-13 20:45:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-13T21:45:16.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>We found that on the related Dolly v2 model, use_cache got set to
          false during training, but it really should be true for faster generation.
          Worked well! Could be applied to all of these similar models.<br>Ex: <a
          href="https://huggingface.co/databricks/dolly-v2-12b/commit/a7077365ca9caa324d6fdda760e953f2f75fac54">https://huggingface.co/databricks/dolly-v2-12b/commit/a7077365ca9caa324d6fdda760e953f2f75fac54</a></p>

          '
        raw: 'We found that on the related Dolly v2 model, use_cache got set to false
          during training, but it really should be true for faster generation. Worked
          well! Could be applied to all of these similar models.

          Ex: https://huggingface.co/databricks/dolly-v2-12b/commit/a7077365ca9caa324d6fdda760e953f2f75fac54'
        updatedAt: '2023-05-13T21:45:16.885Z'
      numEdits: 0
      reactions: []
    id: 646004ec4357049a57f7ba6c
    type: comment
  author: srowen
  content: 'We found that on the related Dolly v2 model, use_cache got set to false
    during training, but it really should be true for faster generation. Worked well!
    Could be applied to all of these similar models.

    Ex: https://huggingface.co/databricks/dolly-v2-12b/commit/a7077365ca9caa324d6fdda760e953f2f75fac54'
  created_at: 2023-05-13 20:45:16+00:00
  edited: false
  hidden: false
  id: 646004ec4357049a57f7ba6c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-13T21:45:17.000Z'
    data:
      oid: 1c75ca189df481ea3dea56af2282c57d794b88ee
      parents:
      - 0ea894a33e491912cd1a65dde47b4af03f03c4f2
      subject: 'Set "use_cache": true for faster generation'
    id: 646004ed0000000000000000
    type: commit
  author: srowen
  created_at: 2023-05-13 20:45:17+00:00
  id: 646004ed0000000000000000
  oid: 1c75ca189df481ea3dea56af2282c57d794b88ee
  summary: 'Set "use_cache": true for faster generation'
  type: commit
is_pull_request: true
merge_commit_oid: null
num: 2
repo_id: aisquared/dlite-v2-774m
repo_type: model
status: open
target_branch: refs/heads/main
title: 'Set "use_cache": true for faster generation'
