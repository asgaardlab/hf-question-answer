!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Ont
conflicting_files: null
created_at: 2023-09-08 04:36:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/320243a2588740e3ad886cebb082098c.svg
      fullname: Ontario
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ont
      type: user
    createdAt: '2023-09-08T05:36:52.000Z'
    data:
      edited: false
      editors:
      - Ont
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9261509776115417
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/320243a2588740e3ad886cebb082098c.svg
          fullname: Ontario
          isHf: false
          isPro: false
          name: Ont
          type: user
        html: '<p>After responding to user instructions, I notice that this model
          always volunteers more text, whether in the form of narrative analysis,
          continuation of the initial text, or postscript, even if instructed to stop.
          On one run after including the phrase "stop and wait" in the instructions,
          the model printed "(Waiting)" after finishing the text that satisfied the
          instructions and then proceeded to ramble on with notes and didactic discourse
          about the story it generated. In another run, the model printed "The End."
          followed by continuation text, "The end. (For now.)" followed by a postscript,
          and "The end. (For real this time.)" followed by a string of emojis and
          more text inside parenthesis.</p>

          <p>In comparison, the Airoboros model included in the merge for this model
          does not share this behavior. I wonder where this model developed its aversion
          to stopping.</p>

          <p>Regardless, thank you to the creators of this model for building and
          sharing.</p>

          '
        raw: "After responding to user instructions, I notice that this model always\
          \ volunteers more text, whether in the form of narrative analysis, continuation\
          \ of the initial text, or postscript, even if instructed to stop. On one\
          \ run after including the phrase \"stop and wait\" in the instructions,\
          \ the model printed \"(Waiting)\" after finishing the text that satisfied\
          \ the instructions and then proceeded to ramble on with notes and didactic\
          \ discourse about the story it generated. In another run, the model printed\
          \ \"The End.\" followed by continuation text, \"The end. (For now.)\" followed\
          \ by a postscript, and \"The end. (For real this time.)\" followed by a\
          \ string of emojis and more text inside parenthesis.\r\n\r\nIn comparison,\
          \ the Airoboros model included in the merge for this model does not share\
          \ this behavior. I wonder where this model developed its aversion to stopping.\r\
          \n\r\nRegardless, thank you to the creators of this model for building and\
          \ sharing."
        updatedAt: '2023-09-08T05:36:52.846Z'
      numEdits: 0
      reactions: []
    id: 64fab2f452e82dd4325cdbf4
    type: comment
  author: Ont
  content: "After responding to user instructions, I notice that this model always\
    \ volunteers more text, whether in the form of narrative analysis, continuation\
    \ of the initial text, or postscript, even if instructed to stop. On one run after\
    \ including the phrase \"stop and wait\" in the instructions, the model printed\
    \ \"(Waiting)\" after finishing the text that satisfied the instructions and then\
    \ proceeded to ramble on with notes and didactic discourse about the story it\
    \ generated. In another run, the model printed \"The End.\" followed by continuation\
    \ text, \"The end. (For now.)\" followed by a postscript, and \"The end. (For\
    \ real this time.)\" followed by a string of emojis and more text inside parenthesis.\r\
    \n\r\nIn comparison, the Airoboros model included in the merge for this model\
    \ does not share this behavior. I wonder where this model developed its aversion\
    \ to stopping.\r\n\r\nRegardless, thank you to the creators of this model for\
    \ building and sharing."
  created_at: 2023-09-08 04:36:52+00:00
  edited: false
  hidden: false
  id: 64fab2f452e82dd4325cdbf4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64be6a5376a6e2efccc638c1/WeV-NfIS6SMPzTI--lNvd.jpeg?w=200&h=200&f=face
      fullname: Saofiq
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Sao10K
      type: user
    createdAt: '2023-09-08T07:42:08.000Z'
    data:
      edited: false
      editors:
      - Sao10K
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.985444962978363
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64be6a5376a6e2efccc638c1/WeV-NfIS6SMPzTI--lNvd.jpeg?w=200&h=200&f=face
          fullname: Saofiq
          isHf: false
          isPro: false
          name: Sao10K
          type: user
        html: '<p>The goal of the model was to be an all-in-one 13b model capable
          of.. everything, but it did not work as expected. The narration and all
          is likely from the coder / puddle jumper models being far off compared to
          the other ones mentioned, and likely something went horribly wrong in the
          merge. It did well in benchmarks but not real life use cases. Perhaps it
          would have been better to merge less models at once, then merge the results
          together instead of doing it in one go. I won''t be pursuing this further
          though, as it''s not really my idea in the first place, unless Dampf wants
          to continue.</p>

          '
        raw: The goal of the model was to be an all-in-one 13b model capable of..
          everything, but it did not work as expected. The narration and all is likely
          from the coder / puddle jumper models being far off compared to the other
          ones mentioned, and likely something went horribly wrong in the merge. It
          did well in benchmarks but not real life use cases. Perhaps it would have
          been better to merge less models at once, then merge the results together
          instead of doing it in one go. I won't be pursuing this further though,
          as it's not really my idea in the first place, unless Dampf wants to continue.
        updatedAt: '2023-09-08T07:42:08.420Z'
      numEdits: 0
      reactions: []
    id: 64fad050d82fc6977d5d64eb
    type: comment
  author: Sao10K
  content: The goal of the model was to be an all-in-one 13b model capable of.. everything,
    but it did not work as expected. The narration and all is likely from the coder
    / puddle jumper models being far off compared to the other ones mentioned, and
    likely something went horribly wrong in the merge. It did well in benchmarks but
    not real life use cases. Perhaps it would have been better to merge less models
    at once, then merge the results together instead of doing it in one go. I won't
    be pursuing this further though, as it's not really my idea in the first place,
    unless Dampf wants to continue.
  created_at: 2023-09-08 06:42:08+00:00
  edited: false
  hidden: false
  id: 64fad050d82fc6977d5d64eb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/875283d9bb2c0965fb6a96fab5335c70.svg
      fullname: Drago
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 3-3
      type: user
    createdAt: '2023-10-23T12:12:04.000Z'
    data:
      edited: false
      editors:
      - 3-3
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9681494832038879
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/875283d9bb2c0965fb6a96fab5335c70.svg
          fullname: Drago
          isHf: false
          isPro: false
          name: 3-3
          type: user
        html: "<p>It's not a bug, it's a feature. I ask it to explain technical concepts\
          \ and I love it. It explain in a warm, friendly manner, long-ass explanations\
          \ with many real life analogies. Without any prompt engineering, at 0.7\
          \ temp. I really wish I could get a 70B model to act like this \u2013 this\
          \ one makes factual mistakes which I believe would be more or less improved\
          \ in a larger one.</p>\n"
        raw: "It's not a bug, it's a feature. I ask it to explain technical concepts\
          \ and I love it. It explain in a warm, friendly manner, long-ass explanations\
          \ with many real life analogies. Without any prompt engineering, at 0.7\
          \ temp. I really wish I could get a 70B model to act like this \u2013 this\
          \ one makes factual mistakes which I believe would be more or less improved\
          \ in a larger one."
        updatedAt: '2023-10-23T12:12:04.085Z'
      numEdits: 0
      reactions: []
    id: 6536631433c5982a29869fa8
    type: comment
  author: 3-3
  content: "It's not a bug, it's a feature. I ask it to explain technical concepts\
    \ and I love it. It explain in a warm, friendly manner, long-ass explanations\
    \ with many real life analogies. Without any prompt engineering, at 0.7 temp.\
    \ I really wish I could get a 70B model to act like this \u2013 this one makes\
    \ factual mistakes which I believe would be more or less improved in a larger\
    \ one."
  created_at: 2023-10-23 11:12:04+00:00
  edited: false
  hidden: false
  id: 6536631433c5982a29869fa8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: Sao10K/Mythical-Destroyer-V2-L2-13B
repo_type: model
status: open
target_branch: null
title: Can't stop. Won't stop.
