!!python/object:huggingface_hub.community.DiscussionWithDetails
author: willu
conflicting_files: null
created_at: 2024-01-09 23:50:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9bdd727ecaf1cc2d1256ac5cf675272b.svg
      fullname: Will U
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: willu
      type: user
    createdAt: '2024-01-09T23:50:31.000Z'
    data:
      edited: false
      editors:
      - willu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.40689796209335327
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9bdd727ecaf1cc2d1256ac5cf675272b.svg
          fullname: Will U
          isHf: false
          isPro: false
          name: willu
          type: user
        html: "<p>Hi,</p>\n<p>I'm trying to use this with <strong>text-generation-webui</strong>,\
          \ but unfortunately I'm getting the following:</p>\n<pre><code class=\"\
          language-python\"> \n<span class=\"hljs-number\">2</span> INFO     Loading\
          \ TheBloke_phi-<span class=\"hljs-number\">2</span>-GPTQ\n !! Warning, unknown\
          \ architecture [<span class=\"hljs-string\">'PhiForCausalLM'</span>]\n !!\
          \ Loading <span class=\"hljs-keyword\">as</span> LlamaForCausalLM\n\nERROR\
          \    Failed to load the model.\nTraceback (most recent call last):\n  File\
          \ <span class=\"hljs-string\">\"~/git/text-generation-webui/modules/ui_model_menu.py\"\
          </span>, line <span class=\"hljs-number\">213</span>, <span class=\"hljs-keyword\"\
          >in</span> load_model_wrapper\n    shared.model, shared.tokenizer = load_model(selected_model,\
          \ loader)\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File <span class=\"hljs-string\">\"~/git/text-generation-webui/modules/models.py\"\
          </span>, line <span class=\"hljs-number\">87</span>, <span class=\"hljs-keyword\"\
          >in</span> load_model\n    output = load_func_map[loader](model_name)\n\
          \             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File <span class=\"hljs-string\"\
          >\"~/git/text-generation-webui/modules/models.py\"</span>, line <span class=\"\
          hljs-number\">389</span>, <span class=\"hljs-keyword\">in</span> ExLlamav2_HF_loader\n\
          \    <span class=\"hljs-keyword\">return</span> Exllamav2HF.from_pretrained(model_name)\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File <span class=\"\
          hljs-string\">\"~/git/text-generation-webui/modules/exllamav2_hf.py\"</span>,\
          \ line <span class=\"hljs-number\">162</span>, <span class=\"hljs-keyword\"\
          >in</span> from_pretrained\n    config.prepare()\n  File <span class=\"\
          hljs-string\">\"~/git/text-generation-webui/installer_files/env/lib/python3.11/site-packages/exllamav2/config.py\"\
          </span>, line <span class=\"hljs-number\">150</span>, <span class=\"hljs-keyword\"\
          >in</span> prepare\n    self.hidden_size = read_config[<span class=\"hljs-string\"\
          >\"hidden_size\"</span>]\n                       ~~~~~~~~~~~^^^^^^^^^^^^^^^\n\
          KeyError: <span class=\"hljs-string\">'hidden_size'</span>\n</code></pre>\n\
          <p>Many thanks for any help, and all your amazing work!!</p>\n"
        raw: "Hi,\r\n\r\nI'm trying to use this with **text-generation-webui**, but\
          \ unfortunately I'm getting the following:\r\n\r\n```python\r\n \r\n2 INFO\
          \     Loading TheBloke_phi-2-GPTQ\r\n !! Warning, unknown architecture ['PhiForCausalLM']\r\
          \n !! Loading as LlamaForCausalLM\r\n\r\nERROR    Failed to load the model.\r\
          \nTraceback (most recent call last):\r\n  File \"~/git/text-generation-webui/modules/ui_model_menu.py\"\
          , line 213, in load_model_wrapper\r\n    shared.model, shared.tokenizer\
          \ = load_model(selected_model, loader)\r\n                             \
          \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"~/git/text-generation-webui/modules/models.py\"\
          , line 87, in load_model\r\n    output = load_func_map[loader](model_name)\r\
          \n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"~/git/text-generation-webui/modules/models.py\"\
          , line 389, in ExLlamav2_HF_loader\r\n    return Exllamav2HF.from_pretrained(model_name)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"~/git/text-generation-webui/modules/exllamav2_hf.py\"\
          , line 162, in from_pretrained\r\n    config.prepare()\r\n  File \"~/git/text-generation-webui/installer_files/env/lib/python3.11/site-packages/exllamav2/config.py\"\
          , line 150, in prepare\r\n    self.hidden_size = read_config[\"hidden_size\"\
          ]\r\n                       ~~~~~~~~~~~^^^^^^^^^^^^^^^\r\nKeyError: 'hidden_size'\r\
          \n\r\n```\r\n\r\nMany thanks for any help, and all your amazing work!!"
        updatedAt: '2024-01-09T23:50:31.737Z'
      numEdits: 0
      reactions: []
    id: 659ddbc79dd5a71bd3d52b5c
    type: comment
  author: willu
  content: "Hi,\r\n\r\nI'm trying to use this with **text-generation-webui**, but\
    \ unfortunately I'm getting the following:\r\n\r\n```python\r\n \r\n2 INFO   \
    \  Loading TheBloke_phi-2-GPTQ\r\n !! Warning, unknown architecture ['PhiForCausalLM']\r\
    \n !! Loading as LlamaForCausalLM\r\n\r\nERROR    Failed to load the model.\r\n\
    Traceback (most recent call last):\r\n  File \"~/git/text-generation-webui/modules/ui_model_menu.py\"\
    , line 213, in load_model_wrapper\r\n    shared.model, shared.tokenizer = load_model(selected_model,\
    \ loader)\r\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"~/git/text-generation-webui/modules/models.py\", line 87, in load_model\r\
    \n    output = load_func_map[loader](model_name)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"~/git/text-generation-webui/modules/models.py\", line 389, in ExLlamav2_HF_loader\r\
    \n    return Exllamav2HF.from_pretrained(model_name)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"~/git/text-generation-webui/modules/exllamav2_hf.py\", line 162, in\
    \ from_pretrained\r\n    config.prepare()\r\n  File \"~/git/text-generation-webui/installer_files/env/lib/python3.11/site-packages/exllamav2/config.py\"\
    , line 150, in prepare\r\n    self.hidden_size = read_config[\"hidden_size\"]\r\
    \n                       ~~~~~~~~~~~^^^^^^^^^^^^^^^\r\nKeyError: 'hidden_size'\r\
    \n\r\n```\r\n\r\nMany thanks for any help, and all your amazing work!!"
  created_at: 2024-01-09 23:50:31+00:00
  edited: false
  hidden: false
  id: 659ddbc79dd5a71bd3d52b5c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
      fullname: Yatharth  Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YaTharThShaRma999
      type: user
    createdAt: '2024-01-10T13:14:06.000Z'
    data:
      edited: false
      editors:
      - YaTharThShaRma999
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.879823625087738
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
          fullname: Yatharth  Sharma
          isHf: false
          isPro: false
          name: YaTharThShaRma999
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;willu&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/willu\">@<span class=\"\
          underline\">willu</span></a></span>\n\n\t</span></span> you cant use phi\
          \ with exllamav2 yet i believe. you have to use transformers or auto gptq(im\
          \ not sure if autogptq has support yet but transformers does)</p>\n"
        raw: '@willu you cant use phi with exllamav2 yet i believe. you have to use
          transformers or auto gptq(im not sure if autogptq has support yet but transformers
          does)'
        updatedAt: '2024-01-10T13:14:06.247Z'
      numEdits: 0
      reactions: []
    id: 659e981e9fdbb8346884fabc
    type: comment
  author: YaTharThShaRma999
  content: '@willu you cant use phi with exllamav2 yet i believe. you have to use
    transformers or auto gptq(im not sure if autogptq has support yet but transformers
    does)'
  created_at: 2024-01-10 13:14:06+00:00
  edited: false
  hidden: false
  id: 659e981e9fdbb8346884fabc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9bdd727ecaf1cc2d1256ac5cf675272b.svg
      fullname: Will U
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: willu
      type: user
    createdAt: '2024-01-10T17:41:19.000Z'
    data:
      edited: false
      editors:
      - willu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8769623041152954
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9bdd727ecaf1cc2d1256ac5cf675272b.svg
          fullname: Will U
          isHf: false
          isPro: false
          name: willu
          type: user
        html: "<p>Thanks for the info <span data-props=\"{&quot;user&quot;:&quot;YaTharThShaRma999&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/YaTharThShaRma999\"\
          >@<span class=\"underline\">YaTharThShaRma999</span></a></span>\n\n\t</span></span>,\
          \ I've been following <a href=\"https://huggingface.co/TheBloke/phi-2-GPTQ#in-text-generation-webui\"\
          >https://huggingface.co/TheBloke/phi-2-GPTQ#in-text-generation-webui</a>,\
          \ but it would appear to not currently work.</p>\n"
        raw: Thanks for the info @YaTharThShaRma999, I've been following https://huggingface.co/TheBloke/phi-2-GPTQ#in-text-generation-webui,
          but it would appear to not currently work.
        updatedAt: '2024-01-10T17:41:19.083Z'
      numEdits: 0
      reactions: []
    id: 659ed6bfab6361525e1b2876
    type: comment
  author: willu
  content: Thanks for the info @YaTharThShaRma999, I've been following https://huggingface.co/TheBloke/phi-2-GPTQ#in-text-generation-webui,
    but it would appear to not currently work.
  created_at: 2024-01-10 17:41:19+00:00
  edited: false
  hidden: false
  id: 659ed6bfab6361525e1b2876
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
      fullname: Yatharth  Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YaTharThShaRma999
      type: user
    createdAt: '2024-01-10T17:57:10.000Z'
    data:
      edited: false
      editors:
      - YaTharThShaRma999
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8732790946960449
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
          fullname: Yatharth  Sharma
          isHf: false
          isPro: false
          name: YaTharThShaRma999
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;willu&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/willu\">@<span class=\"\
          underline\">willu</span></a></span>\n\n\t</span></span> yeah theblokess\
          \ information just tells you how to load the model but not what loader to\
          \ choose in text generation web ui. You have to select transformers as the\
          \ loader</p>\n"
        raw: '@willu yeah theblokess information just tells you how to load the model
          but not what loader to choose in text generation web ui. You have to select
          transformers as the loader'
        updatedAt: '2024-01-10T17:57:10.781Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - willu
    id: 659eda76934fdef9bfccd225
    type: comment
  author: YaTharThShaRma999
  content: '@willu yeah theblokess information just tells you how to load the model
    but not what loader to choose in text generation web ui. You have to select transformers
    as the loader'
  created_at: 2024-01-10 17:57:10+00:00
  edited: false
  hidden: false
  id: 659eda76934fdef9bfccd225
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9bdd727ecaf1cc2d1256ac5cf675272b.svg
      fullname: Will U
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: willu
      type: user
    createdAt: '2024-01-10T20:43:36.000Z'
    data:
      edited: false
      editors:
      - willu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7585529088973999
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9bdd727ecaf1cc2d1256ac5cf675272b.svg
          fullname: Will U
          isHf: false
          isPro: false
          name: willu
          type: user
        html: "<p>Many thanks for your help <span data-props=\"{&quot;user&quot;:&quot;YaTharThShaRma999&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/YaTharThShaRma999\"\
          >@<span class=\"underline\">YaTharThShaRma999</span></a></span>\n\n\t</span></span>,\
          \ can confirm these settings worked for me:</p>\n<p><a rel=\"nofollow\"\
          \ href=\"https://cdn-uploads.huggingface.co/production/uploads/633ed2e67f69125dce9aea08/VboP-rudZdx0xQJV-E7hG.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/633ed2e67f69125dce9aea08/VboP-rudZdx0xQJV-E7hG.png\"\
          ></a></p>\n"
        raw: 'Many thanks for your help @YaTharThShaRma999, can confirm these settings
          worked for me:



          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/633ed2e67f69125dce9aea08/VboP-rudZdx0xQJV-E7hG.png)

          '
        updatedAt: '2024-01-10T20:43:36.912Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - YaTharThShaRma999
      relatedEventId: 659f0178697a41751b8b08dc
    id: 659f0178697a41751b8b08d9
    type: comment
  author: willu
  content: 'Many thanks for your help @YaTharThShaRma999, can confirm these settings
    worked for me:



    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/633ed2e67f69125dce9aea08/VboP-rudZdx0xQJV-E7hG.png)

    '
  created_at: 2024-01-10 20:43:36+00:00
  edited: false
  hidden: false
  id: 659f0178697a41751b8b08d9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9bdd727ecaf1cc2d1256ac5cf675272b.svg
      fullname: Will U
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: willu
      type: user
    createdAt: '2024-01-10T20:43:36.000Z'
    data:
      status: closed
    id: 659f0178697a41751b8b08dc
    type: status-change
  author: willu
  created_at: 2024-01-10 20:43:36+00:00
  id: 659f0178697a41751b8b08dc
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: TheBloke/phi-2-GPTQ
repo_type: model
status: closed
target_branch: null
title: 'KeyError: ''hidden_size'''
