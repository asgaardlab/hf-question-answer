!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Manu9000k
conflicting_files: null
created_at: 2023-11-05 18:47:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3b19d15f0d03e6393408c0e358c8d0dc.svg
      fullname: Manu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Manu9000k
      type: user
    createdAt: '2023-11-05T18:47:22.000Z'
    data:
      edited: false
      editors:
      - Manu9000k
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6994168758392334
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3b19d15f0d03e6393408c0e358c8d0dc.svg
          fullname: Manu
          isHf: false
          isPro: false
          name: Manu9000k
          type: user
        html: '<p>Can you please explain how to use it with Colab free? I see in the
          server there is the option --load_in_8bit but it does not run in colab free<br>!python3
          server.py --model "meetkai/functionary-7b-v1.1" --load_in_8bit True --device
          "cuda:0"</p>

          '
        raw: "Can you please explain how to use it with Colab free? I see in the server\
          \ there is the option --load_in_8bit but it does not run in colab free\r\
          \n!python3 server.py --model \"meetkai/functionary-7b-v1.1\" --load_in_8bit\
          \ True --device \"cuda:0\""
        updatedAt: '2023-11-05T18:47:22.989Z'
      numEdits: 0
      reactions: []
    id: 6547e33a407bb19ff5a25fbd
    type: comment
  author: Manu9000k
  content: "Can you please explain how to use it with Colab free? I see in the server\
    \ there is the option --load_in_8bit but it does not run in colab free\r\n!python3\
    \ server.py --model \"meetkai/functionary-7b-v1.1\" --load_in_8bit True --device\
    \ \"cuda:0\""
  created_at: 2023-11-05 18:47:22+00:00
  edited: false
  hidden: false
  id: 6547e33a407bb19ff5a25fbd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/add9a871afde947efd415032571bb672.svg
      fullname: Musab Gultekin
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: musab-mk
      type: user
    createdAt: '2023-11-22T07:38:29.000Z'
    data:
      edited: false
      editors:
      - musab-mk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9476569890975952
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/add9a871afde947efd415032571bb672.svg
          fullname: Musab Gultekin
          isHf: false
          isPro: false
          name: musab-mk
          type: user
        html: '<p>Hi, unfortunately we have just removed server.py and moved to server
          vllm. That might be the reason. Maybe we can add it in the future, but it
          takes resources/time to keep two server files.</p>

          '
        raw: Hi, unfortunately we have just removed server.py and moved to server
          vllm. That might be the reason. Maybe we can add it in the future, but it
          takes resources/time to keep two server files.
        updatedAt: '2023-11-22T07:38:29.534Z'
      numEdits: 0
      reactions: []
    id: 655daff559fa2e30996e034a
    type: comment
  author: musab-mk
  content: Hi, unfortunately we have just removed server.py and moved to server vllm.
    That might be the reason. Maybe we can add it in the future, but it takes resources/time
    to keep two server files.
  created_at: 2023-11-22 07:38:29+00:00
  edited: false
  hidden: false
  id: 655daff559fa2e30996e034a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: meetkai/functionary-7b-v1.1
repo_type: model
status: open
target_branch: null
title: Using in Colab with T4 GPU
