!!python/object:huggingface_hub.community.DiscussionWithDetails
author: wilfoderek
conflicting_files: null
created_at: 2023-06-21 15:14:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a6d2fe8117535665d7790e0b700b1fbd.svg
      fullname: Wilfredo Martel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wilfoderek
      type: user
    createdAt: '2023-06-21T16:14:10.000Z'
    data:
      edited: false
      editors:
      - wilfoderek
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9637768268585205
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a6d2fe8117535665d7790e0b700b1fbd.svg
          fullname: Wilfredo Martel
          isHf: false
          isPro: false
          name: wilfoderek
          type: user
        html: '<p>Guys really amazing work! brave!!!<br>Now i have a questiosn for
          all of you. I want to fine tuning this model for my own domain, so could
          you explain how to achieve this ?<br>Thanks in advance </p>

          '
        raw: "Guys really amazing work! brave!!!\r\nNow i have a questiosn for all\
          \ of you. I want to fine tuning this model for my own domain, so could you\
          \ explain how to achieve this ?\r\nThanks in advance "
        updatedAt: '2023-06-21T16:14:10.722Z'
      numEdits: 0
      reactions: []
    id: 649321d2f6347997e80f8c87
    type: comment
  author: wilfoderek
  content: "Guys really amazing work! brave!!!\r\nNow i have a questiosn for all of\
    \ you. I want to fine tuning this model for my own domain, so could you explain\
    \ how to achieve this ?\r\nThanks in advance "
  created_at: 2023-06-21 15:14:10+00:00
  edited: false
  hidden: false
  id: 649321d2f6347997e80f8c87
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ddc6a5256ca8be1ac44f6d13f7e26dc8.svg
      fullname: Danso
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Banso
      type: user
    createdAt: '2023-06-21T16:26:43.000Z'
    data:
      edited: false
      editors:
      - Banso
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8363307118415833
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ddc6a5256ca8be1ac44f6d13f7e26dc8.svg
          fullname: Danso
          isHf: false
          isPro: false
          name: Banso
          type: user
        html: "<p>Hey,</p>\n<p>all credits go to <a href=\"https://huggingface.co/intfloat\"\
          >intfloat</a> and Microsoft. <span data-props=\"{&quot;user&quot;:&quot;intfloat&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/intfloat\"\
          >@<span class=\"underline\">intfloat</span></a></span>\n\n\t</span></span>\
          \ mentioned his training here: <a rel=\"nofollow\" href=\"https://github.com/microsoft/unilm/tree/master/simlm\"\
          >https://github.com/microsoft/unilm/tree/master/simlm</a>.</p>\n<p>But the\
          \ model you work also with <a rel=\"nofollow\" href=\"https://www.sbert.net/docs/training/overview.html\"\
          >sentence-transformers training functions</a>. </p>\n<p>Another possibility\
          \ would be just to fine tune the last layer, which seems to be a easy and\
          \ powerful solution. Check out this <a rel=\"nofollow\" href=\"https://github.com/openai/openai-cookbook/blob/main/examples/Customizing_embeddings.ipynb\"\
          >here</a>.</p>\n"
        raw: "Hey,\n\nall credits go to [intfloat](https://huggingface.co/intfloat)\
          \ and Microsoft. @intfloat mentioned his training here: https://github.com/microsoft/unilm/tree/master/simlm.\n\
          \nBut the model you work also with [sentence-transformers training functions](https://www.sbert.net/docs/training/overview.html).\
          \ \n\nAnother possibility would be just to fine tune the last layer, which\
          \ seems to be a easy and powerful solution. Check out this [here](https://github.com/openai/openai-cookbook/blob/main/examples/Customizing_embeddings.ipynb)."
        updatedAt: '2023-06-21T16:26:43.173Z'
      numEdits: 0
      reactions: []
    id: 649324c3c05c8f958df0b6e1
    type: comment
  author: Banso
  content: "Hey,\n\nall credits go to [intfloat](https://huggingface.co/intfloat)\
    \ and Microsoft. @intfloat mentioned his training here: https://github.com/microsoft/unilm/tree/master/simlm.\n\
    \nBut the model you work also with [sentence-transformers training functions](https://www.sbert.net/docs/training/overview.html).\
    \ \n\nAnother possibility would be just to fine tune the last layer, which seems\
    \ to be a easy and powerful solution. Check out this [here](https://github.com/openai/openai-cookbook/blob/main/examples/Customizing_embeddings.ipynb)."
  created_at: 2023-06-21 15:26:43+00:00
  edited: false
  hidden: false
  id: 649324c3c05c8f958df0b6e1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a6d2fe8117535665d7790e0b700b1fbd.svg
      fullname: Wilfredo Martel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wilfoderek
      type: user
    createdAt: '2023-06-21T19:14:27.000Z'
    data:
      edited: false
      editors:
      - wilfoderek
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8513644933700562
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a6d2fe8117535665d7790e0b700b1fbd.svg
          fullname: Wilfredo Martel
          isHf: false
          isPro: false
          name: wilfoderek
          type: user
        html: '<p>Man, thank you so much! i will check out "Another possibility would
          be just to fine tune the last layer". i </p>

          '
        raw: 'Man, thank you so much! i will check out "Another possibility would
          be just to fine tune the last layer". i '
        updatedAt: '2023-06-21T19:14:27.196Z'
      numEdits: 0
      reactions: []
    id: 64934c139621f988db7071c2
    type: comment
  author: wilfoderek
  content: 'Man, thank you so much! i will check out "Another possibility would be
    just to fine tune the last layer". i '
  created_at: 2023-06-21 18:14:27+00:00
  edited: false
  hidden: false
  id: 64934c139621f988db7071c2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/ddc6a5256ca8be1ac44f6d13f7e26dc8.svg
      fullname: Danso
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Banso
      type: user
    createdAt: '2023-07-04T10:24:32.000Z'
    data:
      status: closed
    id: 64a3f36057b750c563009abd
    type: status-change
  author: Banso
  created_at: 2023-07-04 09:24:32+00:00
  id: 64a3f36057b750c563009abd
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: embaas/sentence-transformers-multilingual-e5-base
repo_type: model
status: closed
target_branch: null
title: Fine tuning in my own domain
