!!python/object:huggingface_hub.community.DiscussionWithDetails
author: stochastic
conflicting_files: null
created_at: 2023-05-14 02:42:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ced9b97a2fb782180c9d2df446f89e06.svg
      fullname: Winson Truong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: stochastic
      type: user
    createdAt: '2023-05-14T03:42:02.000Z'
    data:
      edited: false
      editors:
      - stochastic
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ced9b97a2fb782180c9d2df446f89e06.svg
          fullname: Winson Truong
          isHf: false
          isPro: false
          name: stochastic
          type: user
        html: '<p>Am I using this model incorrectly? I try downloading it using a
          call from AutoModel and get the following error:</p>

          <p>Traceback (most recent call last):<br>  File "/home/winson/projects/gpt/redpajama.cpp/examples/redpajama/scripts/./convert_gptneox_to_ggml.py",
          line 62, in <br>    model = AutoModelForCausalLM.from_pretrained(model_name,
          torch_dtype=torch.float16 if ftype == 1 else torch.float32,<br>  File "/home/winson/miniconda3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py",
          line 471, in from_pretrained<br>    return model_class.from_pretrained(<br>  File
          "/home/winson/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py",
          line 2511, in from_pretrained<br>    raise EnvironmentError(<br>OSError:
          keldenl/RedPajama-INCITE-Chat-3B-v1-GGML does not appear to have a file
          named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.</p>

          '
        raw: "Am I using this model incorrectly? I try downloading it using a call\
          \ from AutoModel and get the following error:\r\n\r\nTraceback (most recent\
          \ call last):\r\n  File \"/home/winson/projects/gpt/redpajama.cpp/examples/redpajama/scripts/./convert_gptneox_to_ggml.py\"\
          , line 62, in <module>\r\n    model = AutoModelForCausalLM.from_pretrained(model_name,\
          \ torch_dtype=torch.float16 if ftype == 1 else torch.float32, \r\n  File\
          \ \"/home/winson/miniconda3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 471, in from_pretrained\r\n    return model_class.from_pretrained(\r\
          \n  File \"/home/winson/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
          , line 2511, in from_pretrained\r\n    raise EnvironmentError(\r\nOSError:\
          \ keldenl/RedPajama-INCITE-Chat-3B-v1-GGML does not appear to have a file\
          \ named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack."
        updatedAt: '2023-05-14T03:42:02.209Z'
      numEdits: 0
      reactions: []
    id: 6460588aadc75ee1ed513371
    type: comment
  author: stochastic
  content: "Am I using this model incorrectly? I try downloading it using a call from\
    \ AutoModel and get the following error:\r\n\r\nTraceback (most recent call last):\r\
    \n  File \"/home/winson/projects/gpt/redpajama.cpp/examples/redpajama/scripts/./convert_gptneox_to_ggml.py\"\
    , line 62, in <module>\r\n    model = AutoModelForCausalLM.from_pretrained(model_name,\
    \ torch_dtype=torch.float16 if ftype == 1 else torch.float32, \r\n  File \"/home/winson/miniconda3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\"\
    , line 471, in from_pretrained\r\n    return model_class.from_pretrained(\r\n\
    \  File \"/home/winson/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
    , line 2511, in from_pretrained\r\n    raise EnvironmentError(\r\nOSError: keldenl/RedPajama-INCITE-Chat-3B-v1-GGML\
    \ does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt\
    \ or flax_model.msgpack."
  created_at: 2023-05-14 02:42:02+00:00
  edited: false
  hidden: false
  id: 6460588aadc75ee1ed513371
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a813dedbb9e28866a91b27/i2pGYzY1htiY-L3WFPSgl.jpeg?w=200&h=200&f=face
      fullname: appvoid
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: appvoid
      type: user
    createdAt: '2023-05-19T15:59:56.000Z'
    data:
      edited: false
      editors:
      - appvoid
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a813dedbb9e28866a91b27/i2pGYzY1htiY-L3WFPSgl.jpeg?w=200&h=200&f=face
          fullname: appvoid
          isHf: false
          isPro: false
          name: appvoid
          type: user
        html: '<p>This model is supposed to be used with a llama.cpp like implementation.
          Not with transformers library, but a C++ implementation. You can try redpajama.cpp?</p>

          '
        raw: This model is supposed to be used with a llama.cpp like implementation.
          Not with transformers library, but a C++ implementation. You can try redpajama.cpp?
        updatedAt: '2023-05-19T15:59:56.988Z'
      numEdits: 0
      reactions: []
    id: 64679cfce92e2372d5d11781
    type: comment
  author: appvoid
  content: This model is supposed to be used with a llama.cpp like implementation.
    Not with transformers library, but a C++ implementation. You can try redpajama.cpp?
  created_at: 2023-05-19 14:59:56+00:00
  edited: false
  hidden: false
  id: 64679cfce92e2372d5d11781
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: keldenl/RedPajama-INCITE-Chat-3B-v1-GGML
repo_type: model
status: open
target_branch: null
title: Missing pytorch_model.bin?
