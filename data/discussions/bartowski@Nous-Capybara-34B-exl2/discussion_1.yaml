!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mammour
conflicting_files: null
created_at: 2023-11-15 16:59:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b7a12edd32b236ef45e0cc6525a4e389.svg
      fullname: Margaux Ammour
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mammour
      type: user
    createdAt: '2023-11-15T16:59:14.000Z'
    data:
      edited: true
      editors:
      - mammour
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4755977988243103
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b7a12edd32b236ef45e0cc6525a4e389.svg
          fullname: Margaux Ammour
          isHf: false
          isPro: false
          name: mammour
          type: user
        html: "<h4 id=\"using-text-gen-webui-and-exllama2-008-wheels-\">Using Text\
          \ Gen Webui and exllama2 0.0.8 wheels :</h4>\n<p>The model loads correctly\
          \ with exllama2 as loader but with exllama2_HF I get the following error\
          \ :</p>\n<pre><code>2023-11-15 17:22:43 INFO:Loading bartowski_Nous-Capybara-34B-exl2_4.25...\
          \ [exl2_hf loader]\n2023-11-15 17:23:38 ERROR:Failed to load the model.\n\
          Traceback (most recent call last):\n  File \"L:\\...\\text-generation-webui\\\
          modules\\ui_model_menu.py\", line 210, in load_model_wrapper\n    shared.model,\
          \ shared.tokenizer = load_model(shared.model_name, loader)\n  File \"L:\\\
          ...\\text-generation-webui\\modules\\models.py\", line 93, in load_model\n\
          \    tokenizer = load_tokenizer(model_name, model)\n  File \"L:\\...\\text-generation-webui\\\
          modules\\models.py\", line 113, in load_tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(\n\
          \  File \"L:\\...\\text-generation-webui\\installer_files\\env\\lib\\site-packages\\\
          transformers\\models\\auto\\tokenization_auto.py\", line 751, in from_pretrained\n\
          \    tokenizer_class = get_class_from_dynamic_module(class_ref, pretrained_model_name_or_path,\
          \ **kwargs)\n  File \"L:\\...\\text-generation-webui\\installer_files\\\
          env\\lib\\site-packages\\transformers\\dynamic_module_utils.py\", line 499,\
          \ in get_class_from_dynamic_module\n    return get_class_in_module(class_name,\
          \ final_module.replace(\".py\", \"\"))\n  File \"L:\\...\\text-generation-webui\\\
          installer_files\\env\\lib\\site-packages\\transformers\\dynamic_module_utils.py\"\
          , line 199, in get_class_in_module\n    module = importlib.import_module(module_path)\n\
          \  File \"L:\\...\\text-generation-webui\\installer_files\\env\\lib\\importlib\\\
          __init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:],\
          \ package, level)\n  File \"&lt;frozen importlib._bootstrap&gt;\", line\
          \ 1050, in _gcd_import\n  File \"&lt;frozen importlib._bootstrap&gt;\",\
          \ line 1027, in _find_and_load\n  File \"&lt;frozen importlib._bootstrap&gt;\"\
          , line 992, in _find_and_load_unlocked\n  File \"&lt;frozen importlib._bootstrap&gt;\"\
          , line 241, in _call_with_frames_removed\n  File \"&lt;frozen importlib._bootstrap&gt;\"\
          , line 1050, in _gcd_import\n  File \"&lt;frozen importlib._bootstrap&gt;\"\
          , line 1027, in _find_and_load\n  File \"&lt;frozen importlib._bootstrap&gt;\"\
          , line 992, in _find_and_load_unlocked\n  File \"&lt;frozen importlib._bootstrap&gt;\"\
          , line 241, in _call_with_frames_removed\n  File \"&lt;frozen importlib._bootstrap&gt;\"\
          , line 1050, in _gcd_import\n  File \"&lt;frozen importlib._bootstrap&gt;\"\
          , line 1027, in _find_and_load\n  File \"&lt;frozen importlib._bootstrap&gt;\"\
          , line 1004, in _find_and_load_unlocked\nModuleNotFoundError: No module\
          \ named 'transformers_modules.bartowski_Nous-Capybara-34B-exl2_4'\n\n2023-11-15\
          \ 17:25:37 INFO:Loading bartowski_Nous-Capybara-34B-exl2_4.25... [exl2 loader]\n\
          2023-11-15 17:26:33 INFO:Loaded the model in 56.14 seconds.\n2023-11-15\
          \ 17:31:02 INFO:Loading bartowski_airoboros-2.2.1-y34b-exl2_4.25...   [exl2\
          \ loader]\n2023-11-15 17:31:55 INFO:Loaded the model in 52.89 seconds.\n\
          2023-11-15 17:32:05 INFO:Loading bartowski_airoboros-2.2.1-y34b-exl2_4.25...\
          \  [exl2_hf loader]\n2023-11-15 17:32:58 INFO:Loaded the model in 52.72\
          \ seconds.\n2023-11-15 17:34:07 INFO:Loading bartowski_Nous-Capybara-34B-exl2_4_25...\
          \  [exl2_hf loader]\n2023-11-15 17:35:00 INFO:Loaded the model in 53.17\
          \ seconds.\n</code></pre>\n<h4 id=\"fixed-by-\">Fixed by :</h4>\n<p>Changing\
          \ directory name to transformers_modules.bartowski_Nous-Capybara-34B-exl2_<strong>4_25</strong></p>\n\
          <h4 id=\"notes-\">Notes :</h4>\n<p>I didn't meet this issue with your Airo-YI:4.25\
          \ repo, making this issue quite mystic from my perspective (not enough free\
          \ time to dig into it right now).</p>\n<h4 id=\"conclusion-good-practice-\"\
          >Conclusion (good practice) :</h4>\n<p>Avoiding the use of dots in branch\
          \ names.</p>\n<p><strong>Thanks as always for the amazing work</strong>\
          \ \U0001F917 </p>\n"
        raw: "#### Using Text Gen Webui and exllama2 0.0.8 wheels :\nThe model loads\
          \ correctly with exllama2 as loader but with exllama2_HF I get the following\
          \ error :\n```\n2023-11-15 17:22:43 INFO:Loading bartowski_Nous-Capybara-34B-exl2_4.25...\
          \ [exl2_hf loader]\n2023-11-15 17:23:38 ERROR:Failed to load the model.\n\
          Traceback (most recent call last):\n  File \"L:\\...\\text-generation-webui\\\
          modules\\ui_model_menu.py\", line 210, in load_model_wrapper\n    shared.model,\
          \ shared.tokenizer = load_model(shared.model_name, loader)\n  File \"L:\\\
          ...\\text-generation-webui\\modules\\models.py\", line 93, in load_model\n\
          \    tokenizer = load_tokenizer(model_name, model)\n  File \"L:\\...\\text-generation-webui\\\
          modules\\models.py\", line 113, in load_tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(\n\
          \  File \"L:\\...\\text-generation-webui\\installer_files\\env\\lib\\site-packages\\\
          transformers\\models\\auto\\tokenization_auto.py\", line 751, in from_pretrained\n\
          \    tokenizer_class = get_class_from_dynamic_module(class_ref, pretrained_model_name_or_path,\
          \ **kwargs)\n  File \"L:\\...\\text-generation-webui\\installer_files\\\
          env\\lib\\site-packages\\transformers\\dynamic_module_utils.py\", line 499,\
          \ in get_class_from_dynamic_module\n    return get_class_in_module(class_name,\
          \ final_module.replace(\".py\", \"\"))\n  File \"L:\\...\\text-generation-webui\\\
          installer_files\\env\\lib\\site-packages\\transformers\\dynamic_module_utils.py\"\
          , line 199, in get_class_in_module\n    module = importlib.import_module(module_path)\n\
          \  File \"L:\\...\\text-generation-webui\\installer_files\\env\\lib\\importlib\\\
          __init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:],\
          \ package, level)\n  File \"<frozen importlib._bootstrap>\", line 1050,\
          \ in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1027, in\
          \ _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 992, in\
          \ _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line\
          \ 241, in _call_with_frames_removed\n  File \"<frozen importlib._bootstrap>\"\
          , line 1050, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line\
          \ 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line\
          \ 992, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\"\
          , line 241, in _call_with_frames_removed\n  File \"<frozen importlib._bootstrap>\"\
          , line 1050, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line\
          \ 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line\
          \ 1004, in _find_and_load_unlocked\nModuleNotFoundError: No module named\
          \ 'transformers_modules.bartowski_Nous-Capybara-34B-exl2_4'\n\n2023-11-15\
          \ 17:25:37 INFO:Loading bartowski_Nous-Capybara-34B-exl2_4.25... [exl2 loader]\n\
          2023-11-15 17:26:33 INFO:Loaded the model in 56.14 seconds.\n2023-11-15\
          \ 17:31:02 INFO:Loading bartowski_airoboros-2.2.1-y34b-exl2_4.25...   [exl2\
          \ loader]\n2023-11-15 17:31:55 INFO:Loaded the model in 52.89 seconds.\n\
          2023-11-15 17:32:05 INFO:Loading bartowski_airoboros-2.2.1-y34b-exl2_4.25...\
          \  [exl2_hf loader]\n2023-11-15 17:32:58 INFO:Loaded the model in 52.72\
          \ seconds.\n2023-11-15 17:34:07 INFO:Loading bartowski_Nous-Capybara-34B-exl2_4_25...\
          \  [exl2_hf loader]\n2023-11-15 17:35:00 INFO:Loaded the model in 53.17\
          \ seconds.\n```\n#### Fixed by :\nChanging directory name to transformers_modules.bartowski_Nous-Capybara-34B-exl2_**4_25**\n\
          \n#### Notes :\nI didn't meet this issue with your Airo-YI:4.25 repo, making\
          \ this issue quite mystic from my perspective (not enough free time to dig\
          \ into it right now).\n\n#### Conclusion (good practice) :\nAvoiding the\
          \ use of dots in branch names.\n\n**Thanks as always for the amazing work**\
          \ \U0001F917 "
        updatedAt: '2023-11-15T17:01:21.602Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - bartowski
    id: 6554f8e2bce11b9cde6f3f21
    type: comment
  author: mammour
  content: "#### Using Text Gen Webui and exllama2 0.0.8 wheels :\nThe model loads\
    \ correctly with exllama2 as loader but with exllama2_HF I get the following error\
    \ :\n```\n2023-11-15 17:22:43 INFO:Loading bartowski_Nous-Capybara-34B-exl2_4.25...\
    \ [exl2_hf loader]\n2023-11-15 17:23:38 ERROR:Failed to load the model.\nTraceback\
    \ (most recent call last):\n  File \"L:\\...\\text-generation-webui\\modules\\\
    ui_model_menu.py\", line 210, in load_model_wrapper\n    shared.model, shared.tokenizer\
    \ = load_model(shared.model_name, loader)\n  File \"L:\\...\\text-generation-webui\\\
    modules\\models.py\", line 93, in load_model\n    tokenizer = load_tokenizer(model_name,\
    \ model)\n  File \"L:\\...\\text-generation-webui\\modules\\models.py\", line\
    \ 113, in load_tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(\n  File\
    \ \"L:\\...\\text-generation-webui\\installer_files\\env\\lib\\site-packages\\\
    transformers\\models\\auto\\tokenization_auto.py\", line 751, in from_pretrained\n\
    \    tokenizer_class = get_class_from_dynamic_module(class_ref, pretrained_model_name_or_path,\
    \ **kwargs)\n  File \"L:\\...\\text-generation-webui\\installer_files\\env\\lib\\\
    site-packages\\transformers\\dynamic_module_utils.py\", line 499, in get_class_from_dynamic_module\n\
    \    return get_class_in_module(class_name, final_module.replace(\".py\", \"\"\
    ))\n  File \"L:\\...\\text-generation-webui\\installer_files\\env\\lib\\site-packages\\\
    transformers\\dynamic_module_utils.py\", line 199, in get_class_in_module\n  \
    \  module = importlib.import_module(module_path)\n  File \"L:\\...\\text-generation-webui\\\
    installer_files\\env\\lib\\importlib\\__init__.py\", line 126, in import_module\n\
    \    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen\
    \ importlib._bootstrap>\", line 1050, in _gcd_import\n  File \"<frozen importlib._bootstrap>\"\
    , line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line\
    \ 992, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line\
    \ 241, in _call_with_frames_removed\n  File \"<frozen importlib._bootstrap>\"\
    , line 1050, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1027,\
    \ in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 992, in _find_and_load_unlocked\n\
    \  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n\
    \  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n  File \"\
    <frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen\
    \ importlib._bootstrap>\", line 1004, in _find_and_load_unlocked\nModuleNotFoundError:\
    \ No module named 'transformers_modules.bartowski_Nous-Capybara-34B-exl2_4'\n\n\
    2023-11-15 17:25:37 INFO:Loading bartowski_Nous-Capybara-34B-exl2_4.25... [exl2\
    \ loader]\n2023-11-15 17:26:33 INFO:Loaded the model in 56.14 seconds.\n2023-11-15\
    \ 17:31:02 INFO:Loading bartowski_airoboros-2.2.1-y34b-exl2_4.25...   [exl2 loader]\n\
    2023-11-15 17:31:55 INFO:Loaded the model in 52.89 seconds.\n2023-11-15 17:32:05\
    \ INFO:Loading bartowski_airoboros-2.2.1-y34b-exl2_4.25...  [exl2_hf loader]\n\
    2023-11-15 17:32:58 INFO:Loaded the model in 52.72 seconds.\n2023-11-15 17:34:07\
    \ INFO:Loading bartowski_Nous-Capybara-34B-exl2_4_25...  [exl2_hf loader]\n2023-11-15\
    \ 17:35:00 INFO:Loaded the model in 53.17 seconds.\n```\n#### Fixed by :\nChanging\
    \ directory name to transformers_modules.bartowski_Nous-Capybara-34B-exl2_**4_25**\n\
    \n#### Notes :\nI didn't meet this issue with your Airo-YI:4.25 repo, making this\
    \ issue quite mystic from my perspective (not enough free time to dig into it\
    \ right now).\n\n#### Conclusion (good practice) :\nAvoiding the use of dots in\
    \ branch names.\n\n**Thanks as always for the amazing work** \U0001F917 "
  created_at: 2023-11-15 16:59:14+00:00
  edited: true
  hidden: false
  id: 6554f8e2bce11b9cde6f3f21
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6435718aaaef013d1aec3b8b/XKf-8MA47tjVAM6SCX0MP.jpeg?w=200&h=200&f=face
      fullname: Bartowski
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: bartowski
      type: user
    createdAt: '2023-11-15T20:02:10.000Z'
    data:
      edited: false
      editors:
      - bartowski
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9349725246429443
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6435718aaaef013d1aec3b8b/XKf-8MA47tjVAM6SCX0MP.jpeg?w=200&h=200&f=face
          fullname: Bartowski
          isHf: false
          isPro: false
          name: bartowski
          type: user
        html: '<p>Ah that''s quite interesting, I''ll parse the numbers to replace
          . with _ in the future thanks for the comment!</p>

          '
        raw: Ah that's quite interesting, I'll parse the numbers to replace . with
          _ in the future thanks for the comment!
        updatedAt: '2023-11-15T20:02:10.010Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - mammour
    id: 655523c238df282b0ff83b61
    type: comment
  author: bartowski
  content: Ah that's quite interesting, I'll parse the numbers to replace . with _
    in the future thanks for the comment!
  created_at: 2023-11-15 20:02:10+00:00
  edited: false
  hidden: false
  id: 655523c238df282b0ff83b61
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: bartowski/Nous-Capybara-34B-exl2
repo_type: model
status: open
target_branch: null
title: Small issue with 4.25 branch
