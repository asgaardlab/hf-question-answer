!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hdpsantos
conflicting_files: null
created_at: 2022-07-08 09:26:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1611750890006-noauth.jpeg?w=200&h=200&f=face
      fullname: Henrique Dias
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hdpsantos
      type: user
    createdAt: '2022-07-08T10:26:37.000Z'
    data:
      edited: true
      editors:
      - hdpsantos
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1611750890006-noauth.jpeg?w=200&h=200&f=face
          fullname: Henrique Dias
          isHf: false
          isPro: false
          name: hdpsantos
          type: user
        html: '<p>Hello guys,</p>

          <p>Just to share our results with you: we previous were using <a rel="nofollow"
          href="https://github.com/jneto04/ner-pt">FlairBBP language model</a> for
          our patient risk tool at <a rel="nofollow" href="https://noharm.ai/en">NoHarm.ai</a>.<br>With
          FlairBBP we achieve f1-score (macro avg)  0.7711<br>This week, we try biobertpt-all
          LM and had an excellent result: f1-score (macro avg)  0.8917 (so far)</p>

          <p>We searched for a transformer model so we can <a rel="nofollow" href="https://aws.amazon.com/pt/blogs/machine-learning/achieve-12x-higher-throughput-and-lowest-latency-for-pytorch-natural-language-processing-applications-out-of-the-box-on-aws-inferentia/">optimize
          it for AWS Neuron</a> production inference <a rel="nofollow" href="https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_13_TRANSFORMERS_PRODUCTION.md">using
          Flair framework</a>.</p>

          <p>Next week will evaluate the inference speed between FlairBBP (running
          in a g4dn) and BioBertPt (running in a inf1).</p>

          <p>Thanks for sharing your LM!</p>

          '
        raw: 'Hello guys,


          Just to share our results with you: we previous were using [FlairBBP language
          model](https://github.com/jneto04/ner-pt) for our patient risk tool at [NoHarm.ai](https://noharm.ai/en).

          With FlairBBP we achieve f1-score (macro avg)  0.7711

          This week, we try biobertpt-all LM and had an excellent result: f1-score
          (macro avg)  0.8917 (so far)


          We searched for a transformer model so we can [optimize it for AWS Neuron](https://aws.amazon.com/pt/blogs/machine-learning/achieve-12x-higher-throughput-and-lowest-latency-for-pytorch-natural-language-processing-applications-out-of-the-box-on-aws-inferentia/)
          production inference [using Flair framework](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_13_TRANSFORMERS_PRODUCTION.md).


          Next week will evaluate the inference speed between FlairBBP (running in
          a g4dn) and BioBertPt (running in a inf1).


          Thanks for sharing your LM!'
        updatedAt: '2022-07-10T14:10:21.460Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - lisaterumi
    id: 62c8065d46b925ad8e9f1ed6
    type: comment
  author: hdpsantos
  content: 'Hello guys,


    Just to share our results with you: we previous were using [FlairBBP language
    model](https://github.com/jneto04/ner-pt) for our patient risk tool at [NoHarm.ai](https://noharm.ai/en).

    With FlairBBP we achieve f1-score (macro avg)  0.7711

    This week, we try biobertpt-all LM and had an excellent result: f1-score (macro
    avg)  0.8917 (so far)


    We searched for a transformer model so we can [optimize it for AWS Neuron](https://aws.amazon.com/pt/blogs/machine-learning/achieve-12x-higher-throughput-and-lowest-latency-for-pytorch-natural-language-processing-applications-out-of-the-box-on-aws-inferentia/)
    production inference [using Flair framework](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_13_TRANSFORMERS_PRODUCTION.md).


    Next week will evaluate the inference speed between FlairBBP (running in a g4dn)
    and BioBertPt (running in a inf1).


    Thanks for sharing your LM!'
  created_at: 2022-07-08 09:26:37+00:00
  edited: true
  hidden: false
  id: 62c8065d46b925ad8e9f1ed6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1611750890006-noauth.jpeg?w=200&h=200&f=face
      fullname: Henrique Dias
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hdpsantos
      type: user
    createdAt: '2022-07-18T10:19:25.000Z'
    data:
      edited: false
      editors:
      - hdpsantos
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1611750890006-noauth.jpeg?w=200&h=200&f=face
          fullname: Henrique Dias
          isHf: false
          isPro: false
          name: hdpsantos
          type: user
        html: "<p>Hello guys,</p>\n<p>Here is the comparison between Flair and Bert\
          \ models running in several GPUs in AWS Instances.</p>\n<div class=\"max-w-full\
          \ overflow-auto\">\n\t<table>\n\t\t<thead><tr>\n<th align=\"right\">inf1\
          \ (bert)</th>\n<th align=\"right\">g4dn (bert)</th>\n<th align=\"right\"\
          >g4dn (flair)</th>\n<th align=\"right\">g3s (flair)</th>\n<th align=\"right\"\
          >Instance</th>\n</tr>\n\n\t\t</thead><tbody><tr>\n<td align=\"right\">2.28</td>\n\
          <td align=\"right\">3.25</td>\n<td align=\"right\">1.43</td>\n<td align=\"\
          right\">1.10</td>\n<td align=\"right\">text per second</td>\n</tr>\n<tr>\n\
          <td align=\"right\">196,914.24</td>\n<td align=\"right\">280,972.80</td>\n\
          <td align=\"right\">123,698.88</td>\n<td align=\"right\">95,169.60</td>\n\
          <td align=\"right\">text per day</td>\n</tr>\n<tr>\n<td align=\"right\"\
          >$49.25</td>\n<td align=\"right\">$113.62</td>\n<td align=\"right\">$113.62</td>\n\
          <td align=\"right\">$162.00</td>\n<td align=\"right\">price per month</td>\n\
          </tr>\n<tr>\n<td align=\"right\">$0.000008</td>\n<td align=\"right\">$0.000013</td>\n\
          <td align=\"right\">$0.000031</td>\n<td align=\"right\">$0.000057</td>\n\
          <td align=\"right\">price per text</td>\n</tr>\n<tr>\n<td align=\"right\"\
          >0.91</td>\n<td align=\"right\">0.91</td>\n<td align=\"right\">0.77</td>\n\
          <td align=\"right\">0.77</td>\n<td align=\"right\">f1-score (macro)</td>\n\
          </tr>\n<tr>\n<td align=\"right\">518</td>\n<td align=\"right\">691</td>\n\
          <td align=\"right\">237</td>\n<td align=\"right\">237</td>\n<td align=\"\
          right\">size (MB)</td>\n</tr>\n</tbody>\n\t</table>\n</div>\n<p>The price\
          \ considers Spot Instances, since I run the inference in ECS Spot.<br>Cheers!!</p>\n"
        raw: 'Hello guys,


          Here is the comparison between Flair and Bert models running in several
          GPUs in AWS Instances.


          | inf1 (bert) | g4dn (bert) | g4dn (flair) | g3s (flair) |         Instance
          |

          |----------:|----------:|-----------:|----------:|---------------:|

          |        2.28 |        3.25 |         1.43 |      1.10 |  text per second
          |

          |  196,914.24 |  280,972.80 |   123,698.88 |   95,169.60 |     text per
          day |

          |      $49.25 |     $113.62 |      $113.62 |     $162.00 |  price per month
          |

          |   $0.000008 |   $0.000013 |    $0.000031 |   $0.000057 |   price per text
          |

          |        0.91 |        0.91 |         0.77 |        0.77 | f1-score (macro)
          |

          |         518 |         691 |          237 |         237 |        size (MB)
          |


          The price considers Spot Instances, since I run the inference in ECS Spot.

          Cheers!!'
        updatedAt: '2022-07-18T10:19:25.331Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - lisaterumi
    id: 62d533ad0157a52e22bda53e
    type: comment
  author: hdpsantos
  content: 'Hello guys,


    Here is the comparison between Flair and Bert models running in several GPUs in
    AWS Instances.


    | inf1 (bert) | g4dn (bert) | g4dn (flair) | g3s (flair) |         Instance |

    |----------:|----------:|-----------:|----------:|---------------:|

    |        2.28 |        3.25 |         1.43 |      1.10 |  text per second |

    |  196,914.24 |  280,972.80 |   123,698.88 |   95,169.60 |     text per day |

    |      $49.25 |     $113.62 |      $113.62 |     $162.00 |  price per month |

    |   $0.000008 |   $0.000013 |    $0.000031 |   $0.000057 |   price per text |

    |        0.91 |        0.91 |         0.77 |        0.77 | f1-score (macro) |

    |         518 |         691 |          237 |         237 |        size (MB) |


    The price considers Spot Instances, since I run the inference in ECS Spot.

    Cheers!!'
  created_at: 2022-07-18 09:19:25+00:00
  edited: false
  hidden: false
  id: 62d533ad0157a52e22bda53e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1611750890006-noauth.jpeg?w=200&h=200&f=face
      fullname: Henrique Dias
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hdpsantos
      type: user
    createdAt: '2022-07-18T10:19:25.000Z'
    data:
      status: closed
    id: 62d533ad0157a52e22bda53f
    type: status-change
  author: hdpsantos
  created_at: 2022-07-18 09:19:25+00:00
  id: 62d533ad0157a52e22bda53f
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658523730859-5fb57b380f98667521e6f806.jpeg?w=200&h=200&f=face
      fullname: Elisa Terumi Rubel Schneider
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lisaterumi
      type: user
    createdAt: '2022-08-20T11:22:23.000Z'
    data:
      edited: false
      editors:
      - lisaterumi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658523730859-5fb57b380f98667521e6f806.jpeg?w=200&h=200&f=face
          fullname: Elisa Terumi Rubel Schneider
          isHf: false
          isPro: false
          name: lisaterumi
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;hdpsantos&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/hdpsantos\">@<span class=\"\
          underline\">hdpsantos</span></a></span>\n\n\t</span></span> Great! We are\
          \ glad that our model is being useful. Thanks for sharing your results and\
          \ analysis.</p>\n"
        raw: '@hdpsantos Great! We are glad that our model is being useful. Thanks
          for sharing your results and analysis.'
        updatedAt: '2022-08-20T11:22:23.288Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - hdpsantos
    id: 6300c3efa123c93a5fac4d46
    type: comment
  author: lisaterumi
  content: '@hdpsantos Great! We are glad that our model is being useful. Thanks for
    sharing your results and analysis.'
  created_at: 2022-08-20 10:22:23+00:00
  edited: false
  hidden: false
  id: 6300c3efa123c93a5fac4d46
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: pucpr/biobertpt-all
repo_type: model
status: closed
target_branch: null
title: NoHarm Care - Patient Risk
