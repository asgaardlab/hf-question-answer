!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TheBloke
conflicting_files: null
created_at: 2023-11-14 16:03:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-14T16:03:55.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5637801289558411
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p>Trying to load the tokenizer from this model in Transformers 4.35.0\
          \ results in the following error:</p>\n<pre><code>Python 3.10.12 (main,\
          \ Jun 11 2023, 05:26:28) [GCC 11.4.0] on linux\nType \"help\", \"copyright\"\
          , \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; from transformers\
          \ import AutoTokenizer\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"\
          OpenNLPLab/TransNormerLLM-1B\", trust_remote_code=True)\nTraceback (most\
          \ recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n\
          \  File \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 755, in from_pretrained\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\n  File \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2024, in from_pretrained\n    return cls._from_pretrained(\n  File\
          \ \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2256, in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
          \  File \"/workspace/huggingface/modules/transformers_modules/OpenNLPLab/TransNormerLLM-1B/cf951417e7539e292188864a12171e2e2051917f/tokenization_baichuan.py\"\
          , line 76, in __init__\n    super().__init__(\n  File \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils.py\"\
          , line 367, in __init__\n    self._add_tokens(\n  File \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils.py\"\
          , line 467, in _add_tokens\n    current_vocab = self.get_vocab().copy()\n\
          \  File \"/workspace/huggingface/modules/transformers_modules/OpenNLPLab/TransNormerLLM-1B/cf951417e7539e292188864a12171e2e2051917f/tokenization_baichuan.py\"\
          , line 112, in get_vocab\n    for i in range(self.vocab_size)\n  File \"\
          /workspace/huggingface/modules/transformers_modules/OpenNLPLab/TransNormerLLM-1B/cf951417e7539e292188864a12171e2e2051917f/tokenization_baichuan.py\"\
          , line 106, in vocab_size\n    return self.sp_model.get_piece_size()\nAttributeError:\
          \ 'BaiChuanTokenizer' object has no attribute 'sp_model'\n&gt;&gt;&gt; import\
          \ transformers\n&gt;&gt;&gt; print(transformers.__version__)\n4.35.0\n&gt;&gt;&gt;\n\
          </code></pre>\n<p>I haven't tested earlier Transformers versions, but this\
          \ serr <code>no attribute 'sp_model'</code> is identical to an error I had\
          \ with another model, which proved to be related to recent Transformers\
          \ versions.</p>\n<p>Note that your other model TransNormerLLM-7B, does not\
          \ have this problem:</p>\n<pre><code>&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"\
          OpenNLPLab/TransNormerLLM-7B\", trust_remote_code=True)\nA new version of\
          \ the following files was downloaded from https://huggingface.co/OpenNLPLab/TransNormerLLM-7B:\n\
          - tokenization_baichuan.py\n. Make sure to double-check they do not contain\
          \ any added malicious code. To avoid downloading new versions of the code\
          \ file, you can pin a revision.\n&gt;&gt;&gt;\n</code></pre>\n<p>Could you\
          \ fix the tokenizer of this model so it works with recent Transformers versions,\
          \ like TransNormerLLM 7B does?</p>\n<p>Thanks in advance</p>\n<p>TheBloke</p>\n"
        raw: "Trying to load the tokenizer from this model in Transformers 4.35.0\
          \ results in the following error:\n```\nPython 3.10.12 (main, Jun 11 2023,\
          \ 05:26:28) [GCC 11.4.0] on linux\nType \"help\", \"copyright\", \"credits\"\
          \ or \"license\" for more information.\n>>> from transformers import AutoTokenizer\n\
          >>> tokenizer = AutoTokenizer.from_pretrained(\"OpenNLPLab/TransNormerLLM-1B\"\
          , trust_remote_code=True)\nTraceback (most recent call last):\n  File \"\
          <stdin>\", line 1, in <module>\n  File \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 755, in from_pretrained\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\n  File \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2024, in from_pretrained\n    return cls._from_pretrained(\n  File\
          \ \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2256, in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
          \  File \"/workspace/huggingface/modules/transformers_modules/OpenNLPLab/TransNormerLLM-1B/cf951417e7539e292188864a12171e2e2051917f/tokenization_baichuan.py\"\
          , line 76, in __init__\n    super().__init__(\n  File \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils.py\"\
          , line 367, in __init__\n    self._add_tokens(\n  File \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils.py\"\
          , line 467, in _add_tokens\n    current_vocab = self.get_vocab().copy()\n\
          \  File \"/workspace/huggingface/modules/transformers_modules/OpenNLPLab/TransNormerLLM-1B/cf951417e7539e292188864a12171e2e2051917f/tokenization_baichuan.py\"\
          , line 112, in get_vocab\n    for i in range(self.vocab_size)\n  File \"\
          /workspace/huggingface/modules/transformers_modules/OpenNLPLab/TransNormerLLM-1B/cf951417e7539e292188864a12171e2e2051917f/tokenization_baichuan.py\"\
          , line 106, in vocab_size\n    return self.sp_model.get_piece_size()\nAttributeError:\
          \ 'BaiChuanTokenizer' object has no attribute 'sp_model'\n>>> import transformers\n\
          >>> print(transformers.__version__)\n4.35.0\n>>>\n```\n\nI haven't tested\
          \ earlier Transformers versions, but this serr `no attribute 'sp_model'`\
          \ is identical to an error I had with another model, which proved to be\
          \ related to recent Transformers versions.\n\nNote that your other model\
          \ TransNormerLLM-7B, does not have this problem:\n```\n>>> tokenizer = AutoTokenizer.from_pretrained(\"\
          OpenNLPLab/TransNormerLLM-7B\", trust_remote_code=True)\nA new version of\
          \ the following files was downloaded from https://huggingface.co/OpenNLPLab/TransNormerLLM-7B:\n\
          - tokenization_baichuan.py\n. Make sure to double-check they do not contain\
          \ any added malicious code. To avoid downloading new versions of the code\
          \ file, you can pin a revision.\n>>>\n```\n\nCould you fix the tokenizer\
          \ of this model so it works with recent Transformers versions, like TransNormerLLM\
          \ 7B does?\n\nThanks in advance\n\nTheBloke"
        updatedAt: '2023-11-14T16:04:42.873Z'
      numEdits: 1
      reactions: []
    id: 65539a6b39e7d0cfa73e341f
    type: comment
  author: TheBloke
  content: "Trying to load the tokenizer from this model in Transformers 4.35.0 results\
    \ in the following error:\n```\nPython 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC\
    \ 11.4.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for\
    \ more information.\n>>> from transformers import AutoTokenizer\n>>> tokenizer\
    \ = AutoTokenizer.from_pretrained(\"OpenNLPLab/TransNormerLLM-1B\", trust_remote_code=True)\n\
    Traceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n\
    \  File \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\"\
    , line 755, in from_pretrained\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
    \ *inputs, **kwargs)\n  File \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
    , line 2024, in from_pretrained\n    return cls._from_pretrained(\n  File \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
    , line 2256, in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
    \  File \"/workspace/huggingface/modules/transformers_modules/OpenNLPLab/TransNormerLLM-1B/cf951417e7539e292188864a12171e2e2051917f/tokenization_baichuan.py\"\
    , line 76, in __init__\n    super().__init__(\n  File \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils.py\"\
    , line 367, in __init__\n    self._add_tokens(\n  File \"/workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils.py\"\
    , line 467, in _add_tokens\n    current_vocab = self.get_vocab().copy()\n  File\
    \ \"/workspace/huggingface/modules/transformers_modules/OpenNLPLab/TransNormerLLM-1B/cf951417e7539e292188864a12171e2e2051917f/tokenization_baichuan.py\"\
    , line 112, in get_vocab\n    for i in range(self.vocab_size)\n  File \"/workspace/huggingface/modules/transformers_modules/OpenNLPLab/TransNormerLLM-1B/cf951417e7539e292188864a12171e2e2051917f/tokenization_baichuan.py\"\
    , line 106, in vocab_size\n    return self.sp_model.get_piece_size()\nAttributeError:\
    \ 'BaiChuanTokenizer' object has no attribute 'sp_model'\n>>> import transformers\n\
    >>> print(transformers.__version__)\n4.35.0\n>>>\n```\n\nI haven't tested earlier\
    \ Transformers versions, but this serr `no attribute 'sp_model'` is identical\
    \ to an error I had with another model, which proved to be related to recent Transformers\
    \ versions.\n\nNote that your other model TransNormerLLM-7B, does not have this\
    \ problem:\n```\n>>> tokenizer = AutoTokenizer.from_pretrained(\"OpenNLPLab/TransNormerLLM-7B\"\
    , trust_remote_code=True)\nA new version of the following files was downloaded\
    \ from https://huggingface.co/OpenNLPLab/TransNormerLLM-7B:\n- tokenization_baichuan.py\n\
    . Make sure to double-check they do not contain any added malicious code. To avoid\
    \ downloading new versions of the code file, you can pin a revision.\n>>>\n```\n\
    \nCould you fix the tokenizer of this model so it works with recent Transformers\
    \ versions, like TransNormerLLM 7B does?\n\nThanks in advance\n\nTheBloke"
  created_at: 2023-11-14 16:03:55+00:00
  edited: true
  hidden: false
  id: 65539a6b39e7d0cfa73e341f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671072912067-noauth.jpeg?w=200&h=200&f=face
      fullname: OpenNLPLab
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: OpenNLPLab
      type: user
    createdAt: '2023-11-15T04:03:20.000Z'
    data:
      edited: false
      editors:
      - OpenNLPLab
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8875309228897095
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671072912067-noauth.jpeg?w=200&h=200&f=face
          fullname: OpenNLPLab
          isHf: false
          isPro: false
          name: OpenNLPLab
          type: user
        html: '<p>Appreciate it, for flagging this problem.</p>

          <p>The root of the issue lies in the transformer''s version. We''ll be updating
          the tokenizer file for both the TransNormerLLM-1B and 385M models.</p>

          <p>For a swift solution, check this link: <a rel="nofollow" href="https://github.com/baichuan-inc/Baichuan2/issues/204">https://github.com/baichuan-inc/Baichuan2/issues/204</a></p>

          '
        raw: 'Appreciate it, for flagging this problem.


          The root of the issue lies in the transformer''s version. We''ll be updating
          the tokenizer file for both the TransNormerLLM-1B and 385M models.


          For a swift solution, check this link: https://github.com/baichuan-inc/Baichuan2/issues/204'
        updatedAt: '2023-11-15T04:03:20.900Z'
      numEdits: 0
      reactions: []
    id: 655443089bd4907a06744bdf
    type: comment
  author: OpenNLPLab
  content: 'Appreciate it, for flagging this problem.


    The root of the issue lies in the transformer''s version. We''ll be updating the
    tokenizer file for both the TransNormerLLM-1B and 385M models.


    For a swift solution, check this link: https://github.com/baichuan-inc/Baichuan2/issues/204'
  created_at: 2023-11-15 04:03:20+00:00
  edited: false
  hidden: false
  id: 655443089bd4907a06744bdf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671072912067-noauth.jpeg?w=200&h=200&f=face
      fullname: OpenNLPLab
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: OpenNLPLab
      type: user
    createdAt: '2023-11-17T04:16:51.000Z'
    data:
      edited: false
      editors:
      - OpenNLPLab
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9431706666946411
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671072912067-noauth.jpeg?w=200&h=200&f=face
          fullname: OpenNLPLab
          isHf: false
          isPro: false
          name: OpenNLPLab
          type: user
        html: '<p>We''ve made updates to the associated files to resolve the problem
          stemming from the transformer''s version.</p>

          '
        raw: We've made updates to the associated files to resolve the problem stemming
          from the transformer's version.
        updatedAt: '2023-11-17T04:16:51.096Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6556e933bff42e6fa5bda8a4
    id: 6556e933bff42e6fa5bda8a1
    type: comment
  author: OpenNLPLab
  content: We've made updates to the associated files to resolve the problem stemming
    from the transformer's version.
  created_at: 2023-11-17 04:16:51+00:00
  edited: false
  hidden: false
  id: 6556e933bff42e6fa5bda8a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671072912067-noauth.jpeg?w=200&h=200&f=face
      fullname: OpenNLPLab
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: OpenNLPLab
      type: user
    createdAt: '2023-11-17T04:16:51.000Z'
    data:
      status: closed
    id: 6556e933bff42e6fa5bda8a4
    type: status-change
  author: OpenNLPLab
  created_at: 2023-11-17 04:16:51+00:00
  id: 6556e933bff42e6fa5bda8a4
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: OpenNLPLab/TransNormerLLM-1B
repo_type: model
status: closed
target_branch: null
title: Tokenizer can't be loaded - possibly related to recent Transformers versions
