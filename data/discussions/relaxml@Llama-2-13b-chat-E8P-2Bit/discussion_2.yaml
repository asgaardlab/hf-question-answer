!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TuringsSolutions
conflicting_files: null
created_at: 2023-12-09 01:07:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/cA64Ix1vh75C7HoClUBhx.png?w=200&h=200&f=face
      fullname: Richard A Aragon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TuringsSolutions
      type: user
    createdAt: '2023-12-09T01:07:49.000Z'
    data:
      edited: false
      editors:
      - TuringsSolutions
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9191434979438782
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/cA64Ix1vh75C7HoClUBhx.png?w=200&h=200&f=face
          fullname: Richard A Aragon
          isHf: false
          isPro: false
          name: TuringsSolutions
          type: user
        html: '<p>The pipeline method works fine for these models. Trying to load
          the models directly though throws a tokenizer error. I am super eager to
          try these models out so reporting this issue right away!</p>

          '
        raw: The pipeline method works fine for these models. Trying to load the models
          directly though throws a tokenizer error. I am super eager to try these
          models out so reporting this issue right away!
        updatedAt: '2023-12-09T01:07:49.675Z'
      numEdits: 0
      reactions: []
    id: 6573bde530a4401dfb37ef86
    type: comment
  author: TuringsSolutions
  content: The pipeline method works fine for these models. Trying to load the models
    directly though throws a tokenizer error. I am super eager to try these models
    out so reporting this issue right away!
  created_at: 2023-12-09 01:07:49+00:00
  edited: false
  hidden: false
  id: 6573bde530a4401dfb37ef86
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/35298884b7633c67a9bcff0a32d31211.svg
      fullname: Albert
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: at676
      type: user
    createdAt: '2023-12-09T01:18:42.000Z'
    data:
      edited: false
      editors:
      - at676
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.876828134059906
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/35298884b7633c67a9bcff0a32d31211.svg
          fullname: Albert
          isHf: false
          isPro: false
          name: at676
          type: user
        html: '<p>Can you give a command to reproduce this error? Thanks</p>

          '
        raw: Can you give a command to reproduce this error? Thanks
        updatedAt: '2023-12-09T01:18:42.854Z'
      numEdits: 0
      reactions: []
    id: 6573c0724fffc3f08b22d1ea
    type: comment
  author: at676
  content: Can you give a command to reproduce this error? Thanks
  created_at: 2023-12-09 01:18:42+00:00
  edited: false
  hidden: false
  id: 6573c0724fffc3f08b22d1ea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/cA64Ix1vh75C7HoClUBhx.png?w=200&h=200&f=face
      fullname: Richard A Aragon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TuringsSolutions
      type: user
    createdAt: '2023-12-09T01:23:48.000Z'
    data:
      edited: false
      editors:
      - TuringsSolutions
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6773968935012817
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/cA64Ix1vh75C7HoClUBhx.png?w=200&h=200&f=face
          fullname: Richard A Aragon
          isHf: false
          isPro: false
          name: TuringsSolutions
          type: user
        html: '<p>I just run this:<br>from transformers import AutoTokenizer, AutoModelForCausalLM</p>

          <p>tokenizer = AutoTokenizer.from_pretrained("relaxml/Llama-2-13b-chat-E8P-2Bit")<br>model
          = AutoModelForCausalLM.from_pretrained("relaxml/Llama-2-13b-chat-E8P-2Bit")</p>

          <p>I get this error:</p>

          <p>OSError                                   Traceback (most recent call
          last)<br> in &lt;cell line: 4&gt;()<br>      2 from transformers import
          AutoTokenizer, AutoModelForCausalLM<br>      3<br>----&gt; 4 tokenizer =
          AutoTokenizer.from_pretrained("relaxml/Openhermes-7b-E8P-2Bit")<br>      5
          model = AutoModelForCausalLM.from_pretrained("relaxml/Openhermes-7b-E8P-2Bit")</p>

          <p>1 frames<br>/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py
          in from_pretrained(cls, pretrained_model_name_or_path, cache_dir, force_download,
          local_files_only, token, revision, *init_inputs, **kwargs)<br>   2006<br>   2007         if
          all(full_file_name is None for full_file_name in resolved_vocab_files.values()):<br>-&gt;
          2008             raise EnvironmentError(<br>   2009                 f"Can''t
          load tokenizer for ''{pretrained_model_name_or_path}''. If you were trying
          to load it from "<br>   2010                 "''<a href="https://huggingface.co/models''">https://huggingface.co/models''</a>,
          make sure you don''t have a local directory with the same name. "</p>

          <p>OSError: Can''t load tokenizer for ''relaxml/Openhermes-7b-E8P-2Bit''.
          If you were trying to load it from ''<a href="https://huggingface.co/models''">https://huggingface.co/models''</a>,
          make sure you don''t have a local directory with the same name. Otherwise,
          make sure ''relaxml/Openhermes-7b-E8P-2Bit'' is the correct path to a directory
          containing all relevant files for a LlamaTokenizerFast tokenizer.</p>

          '
        raw: "I just run this:\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\
          \ntokenizer = AutoTokenizer.from_pretrained(\"relaxml/Llama-2-13b-chat-E8P-2Bit\"\
          )\nmodel = AutoModelForCausalLM.from_pretrained(\"relaxml/Llama-2-13b-chat-E8P-2Bit\"\
          )\n\nI get this error:\n\nOSError                                   Traceback\
          \ (most recent call last)\n<ipython-input-4-3c00838f8378> in <cell line:\
          \ 4>()\n      2 from transformers import AutoTokenizer, AutoModelForCausalLM\n\
          \      3 \n----> 4 tokenizer = AutoTokenizer.from_pretrained(\"relaxml/Openhermes-7b-E8P-2Bit\"\
          )\n      5 model = AutoModelForCausalLM.from_pretrained(\"relaxml/Openhermes-7b-E8P-2Bit\"\
          )\n\n\n1 frames\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, cache_dir, force_download,\
          \ local_files_only, token, revision, *init_inputs, **kwargs)\n   2006 \n\
          \   2007         if all(full_file_name is None for full_file_name in resolved_vocab_files.values()):\n\
          -> 2008             raise EnvironmentError(\n   2009                 f\"\
          Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were\
          \ trying to load it from \"\n   2010                 \"'https://huggingface.co/models',\
          \ make sure you don't have a local directory with the same name. \"\n\n\
          OSError: Can't load tokenizer for 'relaxml/Openhermes-7b-E8P-2Bit'. If you\
          \ were trying to load it from 'https://huggingface.co/models', make sure\
          \ you don't have a local directory with the same name. Otherwise, make sure\
          \ 'relaxml/Openhermes-7b-E8P-2Bit' is the correct path to a directory containing\
          \ all relevant files for a LlamaTokenizerFast tokenizer."
        updatedAt: '2023-12-09T01:23:48.315Z'
      numEdits: 0
      reactions: []
    id: 6573c1a405e573071528462e
    type: comment
  author: TuringsSolutions
  content: "I just run this:\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\
    \ntokenizer = AutoTokenizer.from_pretrained(\"relaxml/Llama-2-13b-chat-E8P-2Bit\"\
    )\nmodel = AutoModelForCausalLM.from_pretrained(\"relaxml/Llama-2-13b-chat-E8P-2Bit\"\
    )\n\nI get this error:\n\nOSError                                   Traceback\
    \ (most recent call last)\n<ipython-input-4-3c00838f8378> in <cell line: 4>()\n\
    \      2 from transformers import AutoTokenizer, AutoModelForCausalLM\n      3\
    \ \n----> 4 tokenizer = AutoTokenizer.from_pretrained(\"relaxml/Openhermes-7b-E8P-2Bit\"\
    )\n      5 model = AutoModelForCausalLM.from_pretrained(\"relaxml/Openhermes-7b-E8P-2Bit\"\
    )\n\n\n1 frames\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\
    \ in from_pretrained(cls, pretrained_model_name_or_path, cache_dir, force_download,\
    \ local_files_only, token, revision, *init_inputs, **kwargs)\n   2006 \n   2007\
    \         if all(full_file_name is None for full_file_name in resolved_vocab_files.values()):\n\
    -> 2008             raise EnvironmentError(\n   2009                 f\"Can't\
    \ load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to\
    \ load it from \"\n   2010                 \"'https://huggingface.co/models',\
    \ make sure you don't have a local directory with the same name. \"\n\nOSError:\
    \ Can't load tokenizer for 'relaxml/Openhermes-7b-E8P-2Bit'. If you were trying\
    \ to load it from 'https://huggingface.co/models', make sure you don't have a\
    \ local directory with the same name. Otherwise, make sure 'relaxml/Openhermes-7b-E8P-2Bit'\
    \ is the correct path to a directory containing all relevant files for a LlamaTokenizerFast\
    \ tokenizer."
  created_at: 2023-12-09 01:23:48+00:00
  edited: false
  hidden: false
  id: 6573c1a405e573071528462e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/35298884b7633c67a9bcff0a32d31211.svg
      fullname: Albert
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: at676
      type: user
    createdAt: '2023-12-09T01:37:51.000Z'
    data:
      edited: false
      editors:
      - at676
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8727938532829285
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/35298884b7633c67a9bcff0a32d31211.svg
          fullname: Albert
          isHf: false
          isPro: false
          name: at676
          type: user
        html: '<p>The tokenizer has to be loaded with the original model tokenizer
          (eg meta-llama/Llama-2-13b-chat-hf). We''re in the process of fixing this
          by uploading tokenizer files to each folder, but in the meantime you can
          get the original model string from the model config under the _name_or_path
          entry. You can see how we do this in our model_from_hf_path function here
          <a rel="nofollow" href="https://github.com/Cornell-RelaxML/quip-sharp/blob/main/lib/utils/unsafe_import.py">https://github.com/Cornell-RelaxML/quip-sharp/blob/main/lib/utils/unsafe_import.py</a>.</p>

          '
        raw: The tokenizer has to be loaded with the original model tokenizer (eg
          meta-llama/Llama-2-13b-chat-hf). We're in the process of fixing this by
          uploading tokenizer files to each folder, but in the meantime you can get
          the original model string from the model config under the _name_or_path
          entry. You can see how we do this in our model_from_hf_path function here
          https://github.com/Cornell-RelaxML/quip-sharp/blob/main/lib/utils/unsafe_import.py.
        updatedAt: '2023-12-09T01:37:51.897Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - TuringsSolutions
    id: 6573c4ef177b3b46631423b4
    type: comment
  author: at676
  content: The tokenizer has to be loaded with the original model tokenizer (eg meta-llama/Llama-2-13b-chat-hf).
    We're in the process of fixing this by uploading tokenizer files to each folder,
    but in the meantime you can get the original model string from the model config
    under the _name_or_path entry. You can see how we do this in our model_from_hf_path
    function here https://github.com/Cornell-RelaxML/quip-sharp/blob/main/lib/utils/unsafe_import.py.
  created_at: 2023-12-09 01:37:51+00:00
  edited: false
  hidden: false
  id: 6573c4ef177b3b46631423b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/cA64Ix1vh75C7HoClUBhx.png?w=200&h=200&f=face
      fullname: Richard A Aragon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TuringsSolutions
      type: user
    createdAt: '2023-12-09T01:48:48.000Z'
    data:
      edited: false
      editors:
      - TuringsSolutions
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.46368739008903503
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/cA64Ix1vh75C7HoClUBhx.png?w=200&h=200&f=face
          fullname: Richard A Aragon
          isHf: false
          isPro: false
          name: TuringsSolutions
          type: user
        html: '<p>Thank you!</p>

          '
        raw: Thank you!
        updatedAt: '2023-12-09T01:48:48.800Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6573c78006fdcd4ca9192887
    id: 6573c78006fdcd4ca9192883
    type: comment
  author: TuringsSolutions
  content: Thank you!
  created_at: 2023-12-09 01:48:48+00:00
  edited: false
  hidden: false
  id: 6573c78006fdcd4ca9192883
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/cA64Ix1vh75C7HoClUBhx.png?w=200&h=200&f=face
      fullname: Richard A Aragon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TuringsSolutions
      type: user
    createdAt: '2023-12-09T01:48:48.000Z'
    data:
      status: closed
    id: 6573c78006fdcd4ca9192887
    type: status-change
  author: TuringsSolutions
  created_at: 2023-12-09 01:48:48+00:00
  id: 6573c78006fdcd4ca9192887
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: relaxml/Llama-2-13b-chat-E8P-2Bit
repo_type: model
status: closed
target_branch: null
title: Discrepency between model card and tokenizer
