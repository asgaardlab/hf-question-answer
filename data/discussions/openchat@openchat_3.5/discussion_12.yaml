!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Simkinhu
conflicting_files: null
created_at: 2023-11-09 17:17:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/57babc1227214736713fff0e2576a83e.svg
      fullname: Xiao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Simkinhu
      type: user
    createdAt: '2023-11-09T17:17:09.000Z'
    data:
      edited: true
      editors:
      - Simkinhu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7203071713447571
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/57babc1227214736713fff0e2576a83e.svg
          fullname: Xiao
          isHf: false
          isPro: false
          name: Simkinhu
          type: user
        html: '<p>Hello openchat team,</p>

          <p>root@autodl-container-a44e4284cd-59f17d3a:<del>/autodl-tmp# python -m
          ochat.serving.openai_api_server --model openchat/openchat_3.5<br>FlashAttention
          not found. Install it if you need to train models.<br>FlashAttention not
          found. Install it if you need to train models.<br>2023-11-10 01:15:51,222
          WARNING utils.py:581 -- Detecting docker specified CPUs. In previous versions
          of Ray, CPU detection in containers was incorrect. Please ensure that Ray
          has enough CPUs allocated. As a temporary workaround to revert to the prior
          behavior, set <code>RAY_USE_MULTIPROCESSING_CPU_COUNT=1</code> as an env
          var before starting Ray. Set the env var: <code>RAY_DISABLE_DOCKER_CPU_WARNING=1</code>
          to mute this warning.<br>2023-11-10 01:15:52,296 INFO worker.py:1673 --
          Started a local Ray instance.<br>(pid=3924) FlashAttention not found. Install
          it if you need to train models.<br>(pid=3924) FlashAttention not found.
          Install it if you need to train models.<br>(AsyncTokenizer pid=3924) Special
          tokens have been added in the vocabulary, make sure the associated word
          embeddings are fine-tuned or trained.<br>INFO 11-10 01:15:56 llm_engine.py:72]
          Initializing an LLM engine with config: model=''openchat/openchat_3.5'',
          tokenizer=''openchat/openchat_3.5'', tokenizer_mode=auto, revision=None,
          tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16,
          max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1,
          quantization=None, seed=0)<br>Special tokens have been added in the vocabulary,
          make sure the associated word embeddings are fine-tuned or trained.<br>INFO
          11-10 01:16:10 llm_engine.py:207] # GPU blocks: 3490, # CPU blocks: 2048<br>INFO:     Started
          server process [3216]<br>INFO:     Waiting for application startup.<br>INFO:     Application
          startup complete.<br>ERROR:    [Errno 99] error while attempting to bind
          on address (''::1'', 18888, 0, 0): cannot assign requested address<br>INFO:     Waiting
          for application shutdown.<br>INFO:     Application shutdown complete.<br>root@autodl-container-a44e4284cd-59f17d3a:</del>/autodl-tmp#
          </p>

          '
        raw: 'Hello openchat team,


          root@autodl-container-a44e4284cd-59f17d3a:~/autodl-tmp# python -m ochat.serving.openai_api_server
          --model openchat/openchat_3.5

          FlashAttention not found. Install it if you need to train models.

          FlashAttention not found. Install it if you need to train models.

          2023-11-10 01:15:51,222 WARNING utils.py:581 -- Detecting docker specified
          CPUs. In previous versions of Ray, CPU detection in containers was incorrect.
          Please ensure that Ray has enough CPUs allocated. As a temporary workaround
          to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1`
          as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1`
          to mute this warning.

          2023-11-10 01:15:52,296 INFO worker.py:1673 -- Started a local Ray instance.

          (pid=3924) FlashAttention not found. Install it if you need to train models.

          (pid=3924) FlashAttention not found. Install it if you need to train models.

          (AsyncTokenizer pid=3924) Special tokens have been added in the vocabulary,
          make sure the associated word embeddings are fine-tuned or trained.

          INFO 11-10 01:15:56 llm_engine.py:72] Initializing an LLM engine with config:
          model=''openchat/openchat_3.5'', tokenizer=''openchat/openchat_3.5'', tokenizer_mode=auto,
          revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16,
          max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1,
          quantization=None, seed=0)

          Special tokens have been added in the vocabulary, make sure the associated
          word embeddings are fine-tuned or trained.

          INFO 11-10 01:16:10 llm_engine.py:207] # GPU blocks: 3490, # CPU blocks:
          2048

          INFO:     Started server process [3216]

          INFO:     Waiting for application startup.

          INFO:     Application startup complete.

          ERROR:    [Errno 99] error while attempting to bind on address (''::1'',
          18888, 0, 0): cannot assign requested address

          INFO:     Waiting for application shutdown.

          INFO:     Application shutdown complete.

          root@autodl-container-a44e4284cd-59f17d3a:~/autodl-tmp# '
        updatedAt: '2023-11-10T01:53:57.365Z'
      numEdits: 1
      reactions: []
    id: 654d14154caca6080bdd44f1
    type: comment
  author: Simkinhu
  content: 'Hello openchat team,


    root@autodl-container-a44e4284cd-59f17d3a:~/autodl-tmp# python -m ochat.serving.openai_api_server
    --model openchat/openchat_3.5

    FlashAttention not found. Install it if you need to train models.

    FlashAttention not found. Install it if you need to train models.

    2023-11-10 01:15:51,222 WARNING utils.py:581 -- Detecting docker specified CPUs.
    In previous versions of Ray, CPU detection in containers was incorrect. Please
    ensure that Ray has enough CPUs allocated. As a temporary workaround to revert
    to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var
    before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute
    this warning.

    2023-11-10 01:15:52,296 INFO worker.py:1673 -- Started a local Ray instance.

    (pid=3924) FlashAttention not found. Install it if you need to train models.

    (pid=3924) FlashAttention not found. Install it if you need to train models.

    (AsyncTokenizer pid=3924) Special tokens have been added in the vocabulary, make
    sure the associated word embeddings are fine-tuned or trained.

    INFO 11-10 01:15:56 llm_engine.py:72] Initializing an LLM engine with config:
    model=''openchat/openchat_3.5'', tokenizer=''openchat/openchat_3.5'', tokenizer_mode=auto,
    revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16,
    max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1,
    quantization=None, seed=0)

    Special tokens have been added in the vocabulary, make sure the associated word
    embeddings are fine-tuned or trained.

    INFO 11-10 01:16:10 llm_engine.py:207] # GPU blocks: 3490, # CPU blocks: 2048

    INFO:     Started server process [3216]

    INFO:     Waiting for application startup.

    INFO:     Application startup complete.

    ERROR:    [Errno 99] error while attempting to bind on address (''::1'', 18888,
    0, 0): cannot assign requested address

    INFO:     Waiting for application shutdown.

    INFO:     Application shutdown complete.

    root@autodl-container-a44e4284cd-59f17d3a:~/autodl-tmp# '
  created_at: 2023-11-09 17:17:09+00:00
  edited: true
  hidden: false
  id: 654d14154caca6080bdd44f1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/57babc1227214736713fff0e2576a83e.svg
      fullname: Xiao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Simkinhu
      type: user
    createdAt: '2023-11-09T17:17:48.000Z'
    data:
      edited: false
      editors:
      - Simkinhu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9226495027542114
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/57babc1227214736713fff0e2576a83e.svg
          fullname: Xiao
          isHf: false
          isPro: false
          name: Simkinhu
          type: user
        html: '<p>The environment has been installed and nothing is wrong. The graphics
          card is a 4090 single card. The command to run is</p>

          <p>python -m ochat.serving.openai_api_server --model openchat/openchat_3.5</p>

          '
        raw: 'The environment has been installed and nothing is wrong. The graphics
          card is a 4090 single card. The command to run is


          python -m ochat.serving.openai_api_server --model openchat/openchat_3.5'
        updatedAt: '2023-11-09T17:17:48.658Z'
      numEdits: 0
      reactions: []
    id: 654d143c52214f778a479458
    type: comment
  author: Simkinhu
  content: 'The environment has been installed and nothing is wrong. The graphics
    card is a 4090 single card. The command to run is


    python -m ochat.serving.openai_api_server --model openchat/openchat_3.5'
  created_at: 2023-11-09 17:17:48+00:00
  edited: false
  hidden: false
  id: 654d143c52214f778a479458
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b6cbbdbfb266841ec0f24a/PHUVNOOMEw_R2CF3u-sMS.png?w=200&h=200&f=face
      fullname: One
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: imone
      type: user
    createdAt: '2023-11-10T03:43:23.000Z'
    data:
      edited: false
      editors:
      - imone
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9415103793144226
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b6cbbdbfb266841ec0f24a/PHUVNOOMEw_R2CF3u-sMS.png?w=200&h=200&f=face
          fullname: One
          isHf: false
          isPro: false
          name: imone
          type: user
        html: '<p>This means that your computer does not have an IPv6 address. Try
          adding <code>--host 127.0.0.1</code> as a command line argument.</p>

          '
        raw: This means that your computer does not have an IPv6 address. Try adding
          `--host 127.0.0.1` as a command line argument.
        updatedAt: '2023-11-10T03:43:23.861Z'
      numEdits: 0
      reactions: []
    id: 654da6dbb36f85a025bc3f0a
    type: comment
  author: imone
  content: This means that your computer does not have an IPv6 address. Try adding
    `--host 127.0.0.1` as a command line argument.
  created_at: 2023-11-10 03:43:23+00:00
  edited: false
  hidden: false
  id: 654da6dbb36f85a025bc3f0a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: openchat/openchat_3.5
repo_type: model
status: open
target_branch: null
title: Why does it report an error like this when running?
