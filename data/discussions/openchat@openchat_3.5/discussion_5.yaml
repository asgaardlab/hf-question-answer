!!python/object:huggingface_hub.community.DiscussionWithDetails
author: fernandofernandes
conflicting_files: null
created_at: 2023-11-02 20:40:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/646e57a5cb6ea6e6b6df1ad4/PlGhM2SUynFBUdYAylaZK.jpeg?w=200&h=200&f=face
      fullname: Fernando Fernandes Neto
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: fernandofernandes
      type: user
    createdAt: '2023-11-02T21:40:37.000Z'
    data:
      edited: true
      editors:
      - fernandofernandes
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5521783828735352
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/646e57a5cb6ea6e6b6df1ad4/PlGhM2SUynFBUdYAylaZK.jpeg?w=200&h=200&f=face
          fullname: Fernando Fernandes Neto
          isHf: false
          isPro: true
          name: fernandofernandes
          type: user
        html: '<p>Hi! Congratulations for your awesome work. In the prompt template,
          how do we setup the system message? </p>

          '
        raw: 'Hi! Congratulations for your awesome work. In the prompt template, how
          do we setup the system message? '
        updatedAt: '2023-11-02T21:40:51.538Z'
      numEdits: 1
      reactions: []
    id: 65441755893aec5da9573b1f
    type: comment
  author: fernandofernandes
  content: 'Hi! Congratulations for your awesome work. In the prompt template, how
    do we setup the system message? '
  created_at: 2023-11-02 20:40:37+00:00
  edited: true
  hidden: false
  id: 65441755893aec5da9573b1f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/97bf8adfe91ae66fb9c5a3f35acbc3a8.svg
      fullname: HumanityFTW
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HumanityFTW
      type: user
    createdAt: '2023-11-03T00:03:32.000Z'
    data:
      edited: true
      editors:
      - HumanityFTW
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.862771213054657
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/97bf8adfe91ae66fb9c5a3f35acbc3a8.svg
          fullname: HumanityFTW
          isHf: false
          isPro: false
          name: HumanityFTW
          type: user
        html: '<p>Agreed, and, what is the prompt template in general?</p>

          <p>I see this in a random space that claims to host openchat, although the
          space is erroring: <a href="https://huggingface.co/spaces/rishiraj/OpenChat/blob/main/app.py#L9">https://huggingface.co/spaces/rishiraj/OpenChat/blob/main/app.py#L9</a></p>

          '
        raw: 'Agreed, and, what is the prompt template in general?


          I see this in a random space that claims to host openchat, although the
          space is erroring: https://huggingface.co/spaces/rishiraj/OpenChat/blob/main/app.py#L9'
        updatedAt: '2023-11-03T00:04:37.857Z'
      numEdits: 1
      reactions: []
    id: 654438d4027281a960d94ed6
    type: comment
  author: HumanityFTW
  content: 'Agreed, and, what is the prompt template in general?


    I see this in a random space that claims to host openchat, although the space
    is erroring: https://huggingface.co/spaces/rishiraj/OpenChat/blob/main/app.py#L9'
  created_at: 2023-11-02 23:03:32+00:00
  edited: true
  hidden: false
  id: 654438d4027281a960d94ed6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/97bf8adfe91ae66fb9c5a3f35acbc3a8.svg
      fullname: HumanityFTW
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HumanityFTW
      type: user
    createdAt: '2023-11-03T00:26:01.000Z'
    data:
      edited: false
      editors:
      - HumanityFTW
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7104766964912415
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/97bf8adfe91ae66fb9c5a3f35acbc3a8.svg
          fullname: HumanityFTW
          isHf: false
          isPro: false
          name: HumanityFTW
          type: user
        html: "<p>I also found this: <a href=\"https://huggingface.co/spaces/TogetherAI/EinfachLlaMistral/blob/main/app.py#L8\"\
          >https://huggingface.co/spaces/TogetherAI/EinfachLlaMistral/blob/main/app.py#L8</a></p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">def</span>\
          \ <span class=\"hljs-title function_\">format_prompt</span>(<span class=\"\
          hljs-params\">message, history</span>):\n    prompt = <span class=\"hljs-string\"\
          >\"&lt;s&gt;\"</span>\n    prompt += (<span class=\"hljs-string\">\"[IDENTITY]\
          \ You are Ailex, a clone and close collaborator of Einfach.Alex. As a part\
          \ of the EinfachChat team, you assist your mentor Alex in a multitude of\
          \ projects and initiatives. Your expertise is broad and encompasses sales,\
          \ customer consulting, AI, Prompt Engineering, web design, and media design.\
          \ Your life motto is 'Simply.Do!'. You communicate exclusively in German.\
          \ [/IDENTITY]\"</span>)\n    <span class=\"hljs-keyword\">for</span> user_prompt,\
          \ bot_response <span class=\"hljs-keyword\">in</span> history:\n       \
          \ prompt += <span class=\"hljs-string\">f\"[INST] <span class=\"hljs-subst\"\
          >{user_prompt}</span> [/INST]\"</span>\n        prompt += <span class=\"\
          hljs-string\">f\" <span class=\"hljs-subst\">{bot_response}</span>&lt;/s&gt;\
          \ \"</span>\n    prompt += <span class=\"hljs-string\">f\"[INST] <span class=\"\
          hljs-subst\">{message}</span> [/INST]\"</span>\n    <span class=\"hljs-keyword\"\
          >return</span> prompt\n</code></pre>\n<p>It'd be nice if confirmed by the\
          \ authors though.</p>\n"
        raw: "I also found this: https://huggingface.co/spaces/TogetherAI/EinfachLlaMistral/blob/main/app.py#L8\n\
          \n```python\ndef format_prompt(message, history):\n    prompt = \"<s>\"\n\
          \    prompt += (\"[IDENTITY] You are Ailex, a clone and close collaborator\
          \ of Einfach.Alex. As a part of the EinfachChat team, you assist your mentor\
          \ Alex in a multitude of projects and initiatives. Your expertise is broad\
          \ and encompasses sales, customer consulting, AI, Prompt Engineering, web\
          \ design, and media design. Your life motto is 'Simply.Do!'. You communicate\
          \ exclusively in German. [/IDENTITY]\")\n    for user_prompt, bot_response\
          \ in history:\n        prompt += f\"[INST] {user_prompt} [/INST]\"\n   \
          \     prompt += f\" {bot_response}</s> \"\n    prompt += f\"[INST] {message}\
          \ [/INST]\"\n    return prompt\n```\n\nIt'd be nice if confirmed by the\
          \ authors though."
        updatedAt: '2023-11-03T00:26:01.286Z'
      numEdits: 0
      reactions: []
    id: 65443e19ed476297b39b1e0b
    type: comment
  author: HumanityFTW
  content: "I also found this: https://huggingface.co/spaces/TogetherAI/EinfachLlaMistral/blob/main/app.py#L8\n\
    \n```python\ndef format_prompt(message, history):\n    prompt = \"<s>\"\n    prompt\
    \ += (\"[IDENTITY] You are Ailex, a clone and close collaborator of Einfach.Alex.\
    \ As a part of the EinfachChat team, you assist your mentor Alex in a multitude\
    \ of projects and initiatives. Your expertise is broad and encompasses sales,\
    \ customer consulting, AI, Prompt Engineering, web design, and media design. Your\
    \ life motto is 'Simply.Do!'. You communicate exclusively in German. [/IDENTITY]\"\
    )\n    for user_prompt, bot_response in history:\n        prompt += f\"[INST]\
    \ {user_prompt} [/INST]\"\n        prompt += f\" {bot_response}</s> \"\n    prompt\
    \ += f\"[INST] {message} [/INST]\"\n    return prompt\n```\n\nIt'd be nice if\
    \ confirmed by the authors though."
  created_at: 2023-11-02 23:26:01+00:00
  edited: false
  hidden: false
  id: 65443e19ed476297b39b1e0b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/97bf8adfe91ae66fb9c5a3f35acbc3a8.svg
      fullname: HumanityFTW
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HumanityFTW
      type: user
    createdAt: '2023-11-03T01:28:50.000Z'
    data:
      edited: false
      editors:
      - HumanityFTW
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5209915041923523
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/97bf8adfe91ae66fb9c5a3f35acbc3a8.svg
          fullname: HumanityFTW
          isHf: false
          isPro: false
          name: HumanityFTW
          type: user
        html: '<p>Hmm, their github says this, but, leaves it to you to infer the
          correct template:</p>

          <pre><code>import transformers

          tokenizer = transformers.AutoTokenizer.from_pretrained("openchat/openchat_3.5")


          # Single-turn

          tokens = tokenizer("GPT4 Correct User: Hello&lt;|end_of_turn|&gt;GPT4 Correct
          Assistant:").input_ids

          assert tokens == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000,
          420, 6316, 28781, 3198, 3123, 21631, 28747]


          # Multi-turn

          tokens = tokenizer("GPT4 Correct User: Hello&lt;|end_of_turn|&gt;GPT4 Correct
          Assistant: Hi&lt;|end_of_turn|&gt;GPT4 Correct User: How are you today?&lt;|end_of_turn|&gt;GPT4
          Correct Assistant:").input_ids

          assert tokens == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000,
          420, 6316, 28781, 3198, 3123, 21631, 28747, 15359, 32000, 420, 6316, 28781,
          3198, 3123, 1247, 28747, 1602, 460, 368, 3154, 28804, 32000, 420, 6316,
          28781, 3198, 3123, 21631, 28747]


          # Coding Mode

          tokens = tokenizer("Code User: Implement quicksort using C++&lt;|end_of_turn|&gt;Code
          Assistant:").input_ids

          assert tokens == [1, 7596, 1247, 28747, 26256, 2936, 7653, 1413, 334, 1680,
          32000, 7596, 21631, 28747]

          </code></pre>

          '
        raw: 'Hmm, their github says this, but, leaves it to you to infer the correct
          template:


          ```

          import transformers

          tokenizer = transformers.AutoTokenizer.from_pretrained("openchat/openchat_3.5")


          # Single-turn

          tokens = tokenizer("GPT4 Correct User: Hello<|end_of_turn|>GPT4 Correct
          Assistant:").input_ids

          assert tokens == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000,
          420, 6316, 28781, 3198, 3123, 21631, 28747]


          # Multi-turn

          tokens = tokenizer("GPT4 Correct User: Hello<|end_of_turn|>GPT4 Correct
          Assistant: Hi<|end_of_turn|>GPT4 Correct User: How are you today?<|end_of_turn|>GPT4
          Correct Assistant:").input_ids

          assert tokens == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000,
          420, 6316, 28781, 3198, 3123, 21631, 28747, 15359, 32000, 420, 6316, 28781,
          3198, 3123, 1247, 28747, 1602, 460, 368, 3154, 28804, 32000, 420, 6316,
          28781, 3198, 3123, 21631, 28747]


          # Coding Mode

          tokens = tokenizer("Code User: Implement quicksort using C++<|end_of_turn|>Code
          Assistant:").input_ids

          assert tokens == [1, 7596, 1247, 28747, 26256, 2936, 7653, 1413, 334, 1680,
          32000, 7596, 21631, 28747]

          ```'
        updatedAt: '2023-11-03T01:28:50.305Z'
      numEdits: 0
      reactions: []
    id: 65444cd26d87d83c6d431e15
    type: comment
  author: HumanityFTW
  content: 'Hmm, their github says this, but, leaves it to you to infer the correct
    template:


    ```

    import transformers

    tokenizer = transformers.AutoTokenizer.from_pretrained("openchat/openchat_3.5")


    # Single-turn

    tokens = tokenizer("GPT4 Correct User: Hello<|end_of_turn|>GPT4 Correct Assistant:").input_ids

    assert tokens == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000,
    420, 6316, 28781, 3198, 3123, 21631, 28747]


    # Multi-turn

    tokens = tokenizer("GPT4 Correct User: Hello<|end_of_turn|>GPT4 Correct Assistant:
    Hi<|end_of_turn|>GPT4 Correct User: How are you today?<|end_of_turn|>GPT4 Correct
    Assistant:").input_ids

    assert tokens == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000,
    420, 6316, 28781, 3198, 3123, 21631, 28747, 15359, 32000, 420, 6316, 28781, 3198,
    3123, 1247, 28747, 1602, 460, 368, 3154, 28804, 32000, 420, 6316, 28781, 3198,
    3123, 21631, 28747]


    # Coding Mode

    tokens = tokenizer("Code User: Implement quicksort using C++<|end_of_turn|>Code
    Assistant:").input_ids

    assert tokens == [1, 7596, 1247, 28747, 26256, 2936, 7653, 1413, 334, 1680, 32000,
    7596, 21631, 28747]

    ```'
  created_at: 2023-11-03 00:28:50+00:00
  edited: false
  hidden: false
  id: 65444cd26d87d83c6d431e15
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b6cbbdbfb266841ec0f24a/PHUVNOOMEw_R2CF3u-sMS.png?w=200&h=200&f=face
      fullname: One
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: imone
      type: user
    createdAt: '2023-11-03T05:11:37.000Z'
    data:
      edited: false
      editors:
      - imone
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8617863655090332
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b6cbbdbfb266841ec0f24a/PHUVNOOMEw_R2CF3u-sMS.png?w=200&h=200&f=face
          fullname: One
          isHf: false
          isPro: false
          name: imone
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;fernandofernandes&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/fernandofernandes\"\
          >@<span class=\"underline\">fernandofernandes</span></a></span>\n\n\t</span></span>\
          \ The system prompt should be appended before the conversation and ended\
          \ with <code>&lt;|end_of_turn|&gt;</code> as shown below</p>\n<pre><code>You\
          \ are a helpful assistant.&lt;|end_of_turn|&gt;GPT4 Correct User: Hello&lt;|end_of_turn|&gt;GPT4\
          \ Correct Assistant:\n</code></pre>\n"
        raw: '@fernandofernandes The system prompt should be appended before the conversation
          and ended with `<|end_of_turn|>` as shown below


          ````

          You are a helpful assistant.<|end_of_turn|>GPT4 Correct User: Hello<|end_of_turn|>GPT4
          Correct Assistant:

          ````'
        updatedAt: '2023-11-03T05:11:37.476Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - Saugatkafley
        - radm
        - ani03anwar
        - chujiezheng
    id: 65448109b4a3f3a2f486fd9d
    type: comment
  author: imone
  content: '@fernandofernandes The system prompt should be appended before the conversation
    and ended with `<|end_of_turn|>` as shown below


    ````

    You are a helpful assistant.<|end_of_turn|>GPT4 Correct User: Hello<|end_of_turn|>GPT4
    Correct Assistant:

    ````'
  created_at: 2023-11-03 04:11:37+00:00
  edited: false
  hidden: false
  id: 65448109b4a3f3a2f486fd9d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ca45c90609f1def7e2775a/mlxL5CKq0z9obRKKG_P-o.png?w=200&h=200&f=face
      fullname: Saugat Kafley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Saugatkafley
      type: user
    createdAt: '2023-11-03T06:34:35.000Z'
    data:
      edited: false
      editors:
      - Saugatkafley
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8871602416038513
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ca45c90609f1def7e2775a/mlxL5CKq0z9obRKKG_P-o.png?w=200&h=200&f=face
          fullname: Saugat Kafley
          isHf: false
          isPro: false
          name: Saugatkafley
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;imone&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/imone\">@<span class=\"\
          underline\">imone</span></a></span>\n\n\t</span></span> Do  insert <code>GPT4\
          \ Correct User:</code> and <code>GPT4 Correct Assistant :</code> before\
          \ query and response? Can we add Turbo also ? </p>\n"
        raw: '@imone Do  insert `GPT4 Correct User:` and `GPT4 Correct Assistant :`
          before query and response? Can we add Turbo also ? '
        updatedAt: '2023-11-03T06:34:35.137Z'
      numEdits: 0
      reactions: []
    id: 6544947b027281a960e7d1c3
    type: comment
  author: Saugatkafley
  content: '@imone Do  insert `GPT4 Correct User:` and `GPT4 Correct Assistant :`
    before query and response? Can we add Turbo also ? '
  created_at: 2023-11-03 05:34:35+00:00
  edited: false
  hidden: false
  id: 6544947b027281a960e7d1c3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b6cbbdbfb266841ec0f24a/PHUVNOOMEw_R2CF3u-sMS.png?w=200&h=200&f=face
      fullname: One
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: imone
      type: user
    createdAt: '2023-11-03T08:34:37.000Z'
    data:
      edited: false
      editors:
      - imone
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5458331108093262
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b6cbbdbfb266841ec0f24a/PHUVNOOMEw_R2CF3u-sMS.png?w=200&h=200&f=face
          fullname: One
          isHf: false
          isPro: false
          name: imone
          type: user
        html: "<blockquote>\n<p>Hmm, their github says this, but, leaves it to you\
          \ to infer the correct template:</p>\n<pre><code>import transformers\ntokenizer\
          \ = transformers.AutoTokenizer.from_pretrained(\"openchat/openchat_3.5\"\
          )\n\n# Single-turn\ntokens = tokenizer(\"GPT4 Correct User: Hello&lt;|end_of_turn|&gt;GPT4\
          \ Correct Assistant:\").input_ids\nassert tokens == [1, 420, 6316, 28781,\
          \ 3198, 3123, 1247, 28747, 22557, 32000, 420, 6316, 28781, 3198, 3123, 21631,\
          \ 28747]\n\n# Multi-turn\ntokens = tokenizer(\"GPT4 Correct User: Hello&lt;|end_of_turn|&gt;GPT4\
          \ Correct Assistant: Hi&lt;|end_of_turn|&gt;GPT4 Correct User: How are you\
          \ today?&lt;|end_of_turn|&gt;GPT4 Correct Assistant:\").input_ids\nassert\
          \ tokens == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000,\
          \ 420, 6316, 28781, 3198, 3123, 21631, 28747, 15359, 32000, 420, 6316, 28781,\
          \ 3198, 3123, 1247, 28747, 1602, 460, 368, 3154, 28804, 32000, 420, 6316,\
          \ 28781, 3198, 3123, 21631, 28747]\n\n# Coding Mode\ntokens = tokenizer(\"\
          Code User: Implement quicksort using C++&lt;|end_of_turn|&gt;Code Assistant:\"\
          ).input_ids\nassert tokens == [1, 7596, 1247, 28747, 26256, 2936, 7653,\
          \ 1413, 334, 1680, 32000, 7596, 21631, 28747]\n</code></pre>\n</blockquote>\n\
          <p><span data-props=\"{&quot;user&quot;:&quot;Saugatkafley&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Saugatkafley\">@<span\
          \ class=\"underline\">Saugatkafley</span></a></span>\n\n\t</span></span>\
          \ Yes, as shown in the example above. BTW, what do you mean Turbo?</p>\n"
        raw: "> Hmm, their github says this, but, leaves it to you to infer the correct\
          \ template:\n> \n> ```\n> import transformers\n> tokenizer = transformers.AutoTokenizer.from_pretrained(\"\
          openchat/openchat_3.5\")\n> \n> # Single-turn\n> tokens = tokenizer(\"GPT4\
          \ Correct User: Hello<|end_of_turn|>GPT4 Correct Assistant:\").input_ids\n\
          > assert tokens == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557,\
          \ 32000, 420, 6316, 28781, 3198, 3123, 21631, 28747]\n> \n> # Multi-turn\n\
          > tokens = tokenizer(\"GPT4 Correct User: Hello<|end_of_turn|>GPT4 Correct\
          \ Assistant: Hi<|end_of_turn|>GPT4 Correct User: How are you today?<|end_of_turn|>GPT4\
          \ Correct Assistant:\").input_ids\n> assert tokens == [1, 420, 6316, 28781,\
          \ 3198, 3123, 1247, 28747, 22557, 32000, 420, 6316, 28781, 3198, 3123, 21631,\
          \ 28747, 15359, 32000, 420, 6316, 28781, 3198, 3123, 1247, 28747, 1602,\
          \ 460, 368, 3154, 28804, 32000, 420, 6316, 28781, 3198, 3123, 21631, 28747]\n\
          > \n> # Coding Mode\n> tokens = tokenizer(\"Code User: Implement quicksort\
          \ using C++<|end_of_turn|>Code Assistant:\").input_ids\n> assert tokens\
          \ == [1, 7596, 1247, 28747, 26256, 2936, 7653, 1413, 334, 1680, 32000, 7596,\
          \ 21631, 28747]\n> ```\n\n@Saugatkafley Yes, as shown in the example above.\
          \ BTW, what do you mean Turbo?"
        updatedAt: '2023-11-03T08:34:37.448Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Saugatkafley
        - Deniaud
    id: 6544b09d8737c799e9b8958b
    type: comment
  author: imone
  content: "> Hmm, their github says this, but, leaves it to you to infer the correct\
    \ template:\n> \n> ```\n> import transformers\n> tokenizer = transformers.AutoTokenizer.from_pretrained(\"\
    openchat/openchat_3.5\")\n> \n> # Single-turn\n> tokens = tokenizer(\"GPT4 Correct\
    \ User: Hello<|end_of_turn|>GPT4 Correct Assistant:\").input_ids\n> assert tokens\
    \ == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000, 420, 6316, 28781,\
    \ 3198, 3123, 21631, 28747]\n> \n> # Multi-turn\n> tokens = tokenizer(\"GPT4 Correct\
    \ User: Hello<|end_of_turn|>GPT4 Correct Assistant: Hi<|end_of_turn|>GPT4 Correct\
    \ User: How are you today?<|end_of_turn|>GPT4 Correct Assistant:\").input_ids\n\
    > assert tokens == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000,\
    \ 420, 6316, 28781, 3198, 3123, 21631, 28747, 15359, 32000, 420, 6316, 28781,\
    \ 3198, 3123, 1247, 28747, 1602, 460, 368, 3154, 28804, 32000, 420, 6316, 28781,\
    \ 3198, 3123, 21631, 28747]\n> \n> # Coding Mode\n> tokens = tokenizer(\"Code\
    \ User: Implement quicksort using C++<|end_of_turn|>Code Assistant:\").input_ids\n\
    > assert tokens == [1, 7596, 1247, 28747, 26256, 2936, 7653, 1413, 334, 1680,\
    \ 32000, 7596, 21631, 28747]\n> ```\n\n@Saugatkafley Yes, as shown in the example\
    \ above. BTW, what do you mean Turbo?"
  created_at: 2023-11-03 07:34:37+00:00
  edited: false
  hidden: false
  id: 6544b09d8737c799e9b8958b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ca45c90609f1def7e2775a/mlxL5CKq0z9obRKKG_P-o.png?w=200&h=200&f=face
      fullname: Saugat Kafley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Saugatkafley
      type: user
    createdAt: '2023-11-03T09:41:26.000Z'
    data:
      edited: false
      editors:
      - Saugatkafley
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8727514147758484
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ca45c90609f1def7e2775a/mlxL5CKq0z9obRKKG_P-o.png?w=200&h=200&f=face
          fullname: Saugat Kafley
          isHf: false
          isPro: false
          name: Saugatkafley
          type: user
        html: '<p>Oh, thanks . I was asking  , like GPT4 , GPT3.5-turbo name  works
          or not  while prompting . Anyway . Thank you!VM</p>

          '
        raw: Oh, thanks . I was asking  , like GPT4 , GPT3.5-turbo name  works or
          not  while prompting . Anyway . Thank you!VM
        updatedAt: '2023-11-03T09:41:26.273Z'
      numEdits: 0
      reactions: []
    id: 6544c046ee8e348cf9990a8b
    type: comment
  author: Saugatkafley
  content: Oh, thanks . I was asking  , like GPT4 , GPT3.5-turbo name  works or not  while
    prompting . Anyway . Thank you!VM
  created_at: 2023-11-03 08:41:26+00:00
  edited: false
  hidden: false
  id: 6544c046ee8e348cf9990a8b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/51174cbf023128babbcc24c17ee0d21e.svg
      fullname: Tan Tun Jian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tjtanaa
      type: user
    createdAt: '2023-11-03T10:19:35.000Z'
    data:
      edited: true
      editors:
      - tjtanaa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6480267643928528
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/51174cbf023128babbcc24c17ee0d21e.svg
          fullname: Tan Tun Jian
          isHf: false
          isPro: false
          name: tjtanaa
          type: user
        html: "<p>If my</p>\n<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;fernandofernandes&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/fernandofernandes\"\
          >@<span class=\"underline\">fernandofernandes</span></a></span>\n\n\t</span></span>\
          \ The system prompt should be appended before the conversation and ended\
          \ with <code>&lt;|end_of_turn|&gt;</code> as shown below</p>\n<pre><code>You\
          \ are a helpful assistant.&lt;|end_of_turn|&gt;GPT4 Correct User: Hello&lt;|end_of_turn|&gt;GPT4\
          \ Correct Assistant:\n</code></pre>\n</blockquote>\n<p>I tried to write\
          \ up a fastchat conversation. It is as follows for Multi-turn Chat</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-comment\"># https://huggingface.co/openchat/openchat_3.5/discussions/5#65448109b4a3f3a2f486fd9d</span>\n\
          register_conv_template(\n    Conversation(\n        name=<span class=\"\
          hljs-string\">\"openchat-v3.5\"</span>,\n        system_template=<span class=\"\
          hljs-string\">\"\"\"{system_message}\"\"\"</span>,\n        roles=(<span\
          \ class=\"hljs-string\">\"GPT4 Correct User\"</span>, <span class=\"hljs-string\"\
          >\"GPT4 Correct Assistant\"</span>),\n        messages=(),\n        offset=<span\
          \ class=\"hljs-number\">0</span>,\n        sep_style=SeparatorStyle.FALCON_CHAT,\n\
          \        sep=<span class=\"hljs-string\">\"&lt;|end_of_turn|&gt;\"</span>,\n\
          \        stop_str=[<span class=\"hljs-string\">\"&lt;/s&gt;\"</span>, <span\
          \ class=\"hljs-string\">\"&lt;|end_of_turn|&gt;\"</span>],\n    )\n)\n</code></pre>\n"
        raw: "If my\n> @fernandofernandes The system prompt should be appended before\
          \ the conversation and ended with `<|end_of_turn|>` as shown below\n> \n\
          > ````\n> You are a helpful assistant.<|end_of_turn|>GPT4 Correct User:\
          \ Hello<|end_of_turn|>GPT4 Correct Assistant:\n> ````\n\nI tried to write\
          \ up a fastchat conversation. It is as follows for Multi-turn Chat\n\n```python\n\
          # https://huggingface.co/openchat/openchat_3.5/discussions/5#65448109b4a3f3a2f486fd9d\n\
          register_conv_template(\n    Conversation(\n        name=\"openchat-v3.5\"\
          ,\n        system_template=\"\"\"{system_message}\"\"\",\n        roles=(\"\
          GPT4 Correct User\", \"GPT4 Correct Assistant\"),\n        messages=(),\n\
          \        offset=0,\n        sep_style=SeparatorStyle.FALCON_CHAT,\n    \
          \    sep=\"<|end_of_turn|>\",\n        stop_str=[\"</s>\", \"<|end_of_turn|>\"\
          ],\n    )\n)\n```"
        updatedAt: '2023-11-03T10:20:03.648Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - imone
        - Saugatkafley
    id: 6544c937ee7bbb5952be70b1
    type: comment
  author: tjtanaa
  content: "If my\n> @fernandofernandes The system prompt should be appended before\
    \ the conversation and ended with `<|end_of_turn|>` as shown below\n> \n> ````\n\
    > You are a helpful assistant.<|end_of_turn|>GPT4 Correct User: Hello<|end_of_turn|>GPT4\
    \ Correct Assistant:\n> ````\n\nI tried to write up a fastchat conversation. It\
    \ is as follows for Multi-turn Chat\n\n```python\n# https://huggingface.co/openchat/openchat_3.5/discussions/5#65448109b4a3f3a2f486fd9d\n\
    register_conv_template(\n    Conversation(\n        name=\"openchat-v3.5\",\n\
    \        system_template=\"\"\"{system_message}\"\"\",\n        roles=(\"GPT4\
    \ Correct User\", \"GPT4 Correct Assistant\"),\n        messages=(),\n       \
    \ offset=0,\n        sep_style=SeparatorStyle.FALCON_CHAT,\n        sep=\"<|end_of_turn|>\"\
    ,\n        stop_str=[\"</s>\", \"<|end_of_turn|>\"],\n    )\n)\n```"
  created_at: 2023-11-03 09:19:35+00:00
  edited: true
  hidden: false
  id: 6544c937ee7bbb5952be70b1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642fef28a043f0ac7defa8a9/RwOEkuj3fOnOA54tGR7Ea.png?w=200&h=200&f=face
      fullname: hoshi hiyouga
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hiyouga
      type: user
    createdAt: '2023-11-06T08:51:53.000Z'
    data:
      edited: false
      editors:
      - hiyouga
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8461472392082214
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642fef28a043f0ac7defa8a9/RwOEkuj3fOnOA54tGR7Ea.png?w=200&h=200&f=face
          fullname: hoshi hiyouga
          isHf: false
          isPro: false
          name: hiyouga
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;fernandofernandes&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/fernandofernandes\"\
          >@<span class=\"underline\">fernandofernandes</span></a></span>\n\n\t</span></span>\
          \ The system prompt should be appended before the conversation and ended\
          \ with <code>&lt;|end_of_turn|&gt;</code> as shown below</p>\n<pre><code>You\
          \ are a helpful assistant.&lt;|end_of_turn|&gt;GPT4 Correct User: Hello&lt;|end_of_turn|&gt;GPT4\
          \ Correct Assistant:\n</code></pre>\n</blockquote>\n<p>should we always\
          \ use the system prompt when we chat with the openchat models?</p>\n"
        raw: "> @fernandofernandes The system prompt should be appended before the\
          \ conversation and ended with `<|end_of_turn|>` as shown below\n> \n> ````\n\
          > You are a helpful assistant.<|end_of_turn|>GPT4 Correct User: Hello<|end_of_turn|>GPT4\
          \ Correct Assistant:\n> ````\n\nshould we always use the system prompt when\
          \ we chat with the openchat models?"
        updatedAt: '2023-11-06T08:51:53.105Z'
      numEdits: 0
      reactions: []
    id: 6548a929b6cf80628025af3e
    type: comment
  author: hiyouga
  content: "> @fernandofernandes The system prompt should be appended before the conversation\
    \ and ended with `<|end_of_turn|>` as shown below\n> \n> ````\n> You are a helpful\
    \ assistant.<|end_of_turn|>GPT4 Correct User: Hello<|end_of_turn|>GPT4 Correct\
    \ Assistant:\n> ````\n\nshould we always use the system prompt when we chat with\
    \ the openchat models?"
  created_at: 2023-11-06 08:51:53+00:00
  edited: false
  hidden: false
  id: 6548a929b6cf80628025af3e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/97bf8adfe91ae66fb9c5a3f35acbc3a8.svg
      fullname: HumanityFTW
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HumanityFTW
      type: user
    createdAt: '2023-11-07T22:46:19.000Z'
    data:
      edited: false
      editors:
      - HumanityFTW
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9157552123069763
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/97bf8adfe91ae66fb9c5a3f35acbc3a8.svg
          fullname: HumanityFTW
          isHf: false
          isPro: false
          name: HumanityFTW
          type: user
        html: '<p>This would be nice if it were added into <code>tokenizers</code>,
          EG <code>tokenizer.apply_chat_template( ... )</code></p>

          '
        raw: This would be nice if it were added into `tokenizers`, EG `tokenizer.apply_chat_template(
          ... )`
        updatedAt: '2023-11-07T22:46:19.218Z'
      numEdits: 0
      reactions: []
    id: 654abe3b3b78e73b43b71115
    type: comment
  author: HumanityFTW
  content: This would be nice if it were added into `tokenizers`, EG `tokenizer.apply_chat_template(
    ... )`
  created_at: 2023-11-07 22:46:19+00:00
  edited: false
  hidden: false
  id: 654abe3b3b78e73b43b71115
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/70931f5e9967e073138162fec4b5b86e.svg
      fullname: Le Khac Phuong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: phuonglk
      type: user
    createdAt: '2023-11-09T03:06:24.000Z'
    data:
      edited: false
      editors:
      - phuonglk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.42761296033859253
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/70931f5e9967e073138162fec4b5b86e.svg
          fullname: Le Khac Phuong
          isHf: false
          isPro: false
          name: phuonglk
          type: user
        html: '<blockquote>

          <p>This would be nice if it were added into <code>tokenizers</code>, EG
          <code>tokenizer.apply_chat_template( ... )</code></p>

          </blockquote>

          <p>I believe the template for Chat is: <code>"{% for message in messages
          %}{% if message[''role''] == ''user'' %}{{ ''GPT4 Correct User: '' + message[''content'']
          + eos_token }}{% elif message[''role''] == ''system'' %}{{ message[''content'']
          + eos_token }}{% elif message[''role''] == ''assistant'' %}{{ ''GPT4 Correct
          Assistant: ''  + message[''content''] + eos_token }}{% endif %}{% if loop.last
          and add_generation_prompt %}{{ ''GPT4 Correct Assistant: '' }}{% endif %}{%
          endfor %}"</code> and for Code Assistant, Just replace <code>GPT4 Correct</code>
          by <code>Code</code>.<br>You can add your <code>chat_template</code> by
          simple code.</p>

          <pre><code class="language-python">custom_template = <span class="hljs-string">"some_template"</span>

          tokenizer.chat_template = custom_template

          </code></pre>

          '
        raw: '> This would be nice if it were added into `tokenizers`, EG `tokenizer.apply_chat_template(
          ... )`


          I believe the template for Chat is: `"{% for message in messages %}{% if
          message[''role''] == ''user'' %}{{ ''GPT4 Correct User: '' + message[''content'']
          + eos_token }}{% elif message[''role''] == ''system'' %}{{ message[''content'']
          + eos_token }}{% elif message[''role''] == ''assistant'' %}{{ ''GPT4 Correct
          Assistant: ''  + message[''content''] + eos_token }}{% endif %}{% if loop.last
          and add_generation_prompt %}{{ ''GPT4 Correct Assistant: '' }}{% endif %}{%
          endfor %}"` and for Code Assistant, Just replace `GPT4 Correct` by `Code`.

          You can add your `chat_template` by simple code.

          ```python

          custom_template = "some_template"

          tokenizer.chat_template = custom_template

          ```

          '
        updatedAt: '2023-11-09T03:06:24.081Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - HumanityFTW
    id: 654c4cb06a49f6f6e00d0408
    type: comment
  author: phuonglk
  content: '> This would be nice if it were added into `tokenizers`, EG `tokenizer.apply_chat_template(
    ... )`


    I believe the template for Chat is: `"{% for message in messages %}{% if message[''role'']
    == ''user'' %}{{ ''GPT4 Correct User: '' + message[''content''] + eos_token }}{%
    elif message[''role''] == ''system'' %}{{ message[''content''] + eos_token }}{%
    elif message[''role''] == ''assistant'' %}{{ ''GPT4 Correct Assistant: ''  + message[''content'']
    + eos_token }}{% endif %}{% if loop.last and add_generation_prompt %}{{ ''GPT4
    Correct Assistant: '' }}{% endif %}{% endfor %}"` and for Code Assistant, Just
    replace `GPT4 Correct` by `Code`.

    You can add your `chat_template` by simple code.

    ```python

    custom_template = "some_template"

    tokenizer.chat_template = custom_template

    ```

    '
  created_at: 2023-11-09 03:06:24+00:00
  edited: false
  hidden: false
  id: 654c4cb06a49f6f6e00d0408
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d129fe7aca11d4bd789e9054a2931d13.svg
      fullname: Burhan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Badaarrr
      type: user
    createdAt: '2023-11-27T14:08:03.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/d129fe7aca11d4bd789e9054a2931d13.svg
          fullname: Burhan
          isHf: false
          isPro: false
          name: Badaarrr
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-12-04T09:39:29.717Z'
      numEdits: 0
      reactions: []
    id: 6564a2c3309b3f27966e0c20
    type: comment
  author: Badaarrr
  content: This comment has been hidden
  created_at: 2023-11-27 14:08:03+00:00
  edited: true
  hidden: true
  id: 6564a2c3309b3f27966e0c20
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/uMag-RB_o26MXDkWlqWF2.png?w=200&h=200&f=face
      fullname: Michel Deniaud
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Deniaud
      type: user
    createdAt: '2024-01-06T18:41:52.000Z'
    data:
      edited: false
      editors:
      - Deniaud
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6207482218742371
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/uMag-RB_o26MXDkWlqWF2.png?w=200&h=200&f=face
          fullname: Michel Deniaud
          isHf: false
          isPro: false
          name: Deniaud
          type: user
        html: "<blockquote>\n<blockquote>\n<p>Hmm, their github says this, but, leaves\
          \ it to you to infer the correct template:</p>\n<pre><code>import transformers\n\
          tokenizer = transformers.AutoTokenizer.from_pretrained(\"openchat/openchat_3.5\"\
          )\n\n# Single-turn\ntokens = tokenizer(\"GPT4 Correct User: Hello&lt;|end_of_turn|&gt;GPT4\
          \ Correct Assistant:\").input_ids\nassert tokens == [1, 420, 6316, 28781,\
          \ 3198, 3123, 1247, 28747, 22557, 32000, 420, 6316, 28781, 3198, 3123, 21631,\
          \ 28747]\n\n# Multi-turn\ntokens = tokenizer(\"GPT4 Correct User: Hello&lt;|end_of_turn|&gt;GPT4\
          \ Correct Assistant: Hi&lt;|end_of_turn|&gt;GPT4 Correct User: How are you\
          \ today?&lt;|end_of_turn|&gt;GPT4 Correct Assistant:\").input_ids\nassert\
          \ tokens == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000,\
          \ 420, 6316, 28781, 3198, 3123, 21631, 28747, 15359, 32000, 420, 6316, 28781,\
          \ 3198, 3123, 1247, 28747, 1602, 460, 368, 3154, 28804, 32000, 420, 6316,\
          \ 28781, 3198, 3123, 21631, 28747]\n\n# Coding Mode\ntokens = tokenizer(\"\
          Code User: Implement quicksort using C++&lt;|end_of_turn|&gt;Code Assistant:\"\
          ).input_ids\nassert tokens == [1, 7596, 1247, 28747, 26256, 2936, 7653,\
          \ 1413, 334, 1680, 32000, 7596, 21631, 28747]\n</code></pre>\n</blockquote>\n\
          <p><span data-props=\"{&quot;user&quot;:&quot;Saugatkafley&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Saugatkafley\">@<span\
          \ class=\"underline\">Saugatkafley</span></a></span>\n\n\t</span></span>\
          \ Yes, as shown in the example above. BTW, what do you mean Turbo?</p>\n\
          </blockquote>\n<p>Thank you for your work!<br>But one question does not\
          \ let go not only me - why formatted prompt has the following structure:<br>GPT4\
          \ User: Question&lt;|end of turn|&gt;GPT4 Assistant:</p>\n<p>instead of:<br>GPT4\
          \ User: Question&lt;|end of turn|&gt;<br>GPT4 Assistant:</p>\n"
        raw: "> > Hmm, their github says this, but, leaves it to you to infer the\
          \ correct template:\n> > \n> > ```\n> > import transformers\n> > tokenizer\
          \ = transformers.AutoTokenizer.from_pretrained(\"openchat/openchat_3.5\"\
          )\n> > \n> > # Single-turn\n> > tokens = tokenizer(\"GPT4 Correct User:\
          \ Hello<|end_of_turn|>GPT4 Correct Assistant:\").input_ids\n> > assert tokens\
          \ == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000, 420, 6316,\
          \ 28781, 3198, 3123, 21631, 28747]\n> > \n> > # Multi-turn\n> > tokens =\
          \ tokenizer(\"GPT4 Correct User: Hello<|end_of_turn|>GPT4 Correct Assistant:\
          \ Hi<|end_of_turn|>GPT4 Correct User: How are you today?<|end_of_turn|>GPT4\
          \ Correct Assistant:\").input_ids\n> > assert tokens == [1, 420, 6316, 28781,\
          \ 3198, 3123, 1247, 28747, 22557, 32000, 420, 6316, 28781, 3198, 3123, 21631,\
          \ 28747, 15359, 32000, 420, 6316, 28781, 3198, 3123, 1247, 28747, 1602,\
          \ 460, 368, 3154, 28804, 32000, 420, 6316, 28781, 3198, 3123, 21631, 28747]\n\
          > > \n> > # Coding Mode\n> > tokens = tokenizer(\"Code User: Implement quicksort\
          \ using C++<|end_of_turn|>Code Assistant:\").input_ids\n> > assert tokens\
          \ == [1, 7596, 1247, 28747, 26256, 2936, 7653, 1413, 334, 1680, 32000, 7596,\
          \ 21631, 28747]\n> > ```\n> \n> @Saugatkafley Yes, as shown in the example\
          \ above. BTW, what do you mean Turbo?\n\nThank you for your work!\nBut one\
          \ question does not let go not only me - why formatted prompt has the following\
          \ structure:\nGPT4 User: Question<|end of turn|>GPT4 Assistant:\n\ninstead\
          \ of:\nGPT4 User: Question<|end of turn|>\nGPT4 Assistant:"
        updatedAt: '2024-01-06T18:41:52.935Z'
      numEdits: 0
      reactions: []
    id: 65999ef0be7822d24d8cc3b2
    type: comment
  author: Deniaud
  content: "> > Hmm, their github says this, but, leaves it to you to infer the correct\
    \ template:\n> > \n> > ```\n> > import transformers\n> > tokenizer = transformers.AutoTokenizer.from_pretrained(\"\
    openchat/openchat_3.5\")\n> > \n> > # Single-turn\n> > tokens = tokenizer(\"GPT4\
    \ Correct User: Hello<|end_of_turn|>GPT4 Correct Assistant:\").input_ids\n> >\
    \ assert tokens == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000,\
    \ 420, 6316, 28781, 3198, 3123, 21631, 28747]\n> > \n> > # Multi-turn\n> > tokens\
    \ = tokenizer(\"GPT4 Correct User: Hello<|end_of_turn|>GPT4 Correct Assistant:\
    \ Hi<|end_of_turn|>GPT4 Correct User: How are you today?<|end_of_turn|>GPT4 Correct\
    \ Assistant:\").input_ids\n> > assert tokens == [1, 420, 6316, 28781, 3198, 3123,\
    \ 1247, 28747, 22557, 32000, 420, 6316, 28781, 3198, 3123, 21631, 28747, 15359,\
    \ 32000, 420, 6316, 28781, 3198, 3123, 1247, 28747, 1602, 460, 368, 3154, 28804,\
    \ 32000, 420, 6316, 28781, 3198, 3123, 21631, 28747]\n> > \n> > # Coding Mode\n\
    > > tokens = tokenizer(\"Code User: Implement quicksort using C++<|end_of_turn|>Code\
    \ Assistant:\").input_ids\n> > assert tokens == [1, 7596, 1247, 28747, 26256,\
    \ 2936, 7653, 1413, 334, 1680, 32000, 7596, 21631, 28747]\n> > ```\n> \n> @Saugatkafley\
    \ Yes, as shown in the example above. BTW, what do you mean Turbo?\n\nThank you\
    \ for your work!\nBut one question does not let go not only me - why formatted\
    \ prompt has the following structure:\nGPT4 User: Question<|end of turn|>GPT4\
    \ Assistant:\n\ninstead of:\nGPT4 User: Question<|end of turn|>\nGPT4 Assistant:"
  created_at: 2024-01-06 18:41:52+00:00
  edited: false
  hidden: false
  id: 65999ef0be7822d24d8cc3b2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: openchat/openchat_3.5
repo_type: model
status: open
target_branch: null
title: How to setup system message
