!!python/object:huggingface_hub.community.DiscussionWithDetails
author: khanhj
conflicting_files: null
created_at: 2023-07-16 08:27:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64686ce5f43574d9556b4914/709MMdUq-8DrfSVZw5gCF.png?w=200&h=200&f=face
      fullname: Le Hoang Khanh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: khanhj
      type: user
    createdAt: '2023-07-16T09:27:29.000Z'
    data:
      edited: false
      editors:
      - khanhj
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.565727174282074
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64686ce5f43574d9556b4914/709MMdUq-8DrfSVZw5gCF.png?w=200&h=200&f=face
          fullname: Le Hoang Khanh
          isHf: false
          isPro: false
          name: khanhj
          type: user
        html: "<p>Hi Symanto,</p>\n<p>Thanks for provide this model.<br>I'm using\
          \ this method to convert it to ggml: <a rel=\"nofollow\" href=\"https://github.com/ggerganov/llama.cpp/blob/master/convert.py\"\
          >https://github.com/ggerganov/llama.cpp/blob/master/convert.py</a></p>\n\
          <p>This is the error:</p>\n<pre><code>params: n_vocab:250002 n_embd:768\
          \ n_mult:1536 n_head:12 n_layer:12\nTraceback (most recent call last):\n\
          \  File \"/root/github/llama.cpp/convert.py\", line 1270, in &lt;module&gt;\n\
          \    main()\n  File \"/root/github/llama.cpp/convert.py\", line 1262, in\
          \ main\n    output_type = pick_output_type(model, args.outtype)\n  File\
          \ \"/root/github/llama.cpp/convert.py\", line 1075, in pick_output_type\n\
          \    wq_type = model[\"layers.0.attention.wq.weight\"].data_type\nKeyError:\
          \ 'layers.0.attention.wq.weight'\n</code></pre>\n<p>May i know what is the\
          \ weight number of this model?</p>\n<h2 id=\"thank-you-in-advance\">Thank\
          \ you in advance.</h2>\n<p>Lee</p>\n"
        raw: "Hi Symanto,\r\n\r\nThanks for provide this model.\r\nI'm using this\
          \ method to convert it to ggml: https://github.com/ggerganov/llama.cpp/blob/master/convert.py\r\
          \n\r\nThis is the error:\r\n```\r\nparams: n_vocab:250002 n_embd:768 n_mult:1536\
          \ n_head:12 n_layer:12\r\nTraceback (most recent call last):\r\n  File \"\
          /root/github/llama.cpp/convert.py\", line 1270, in <module>\r\n    main()\r\
          \n  File \"/root/github/llama.cpp/convert.py\", line 1262, in main\r\n \
          \   output_type = pick_output_type(model, args.outtype)\r\n  File \"/root/github/llama.cpp/convert.py\"\
          , line 1075, in pick_output_type\r\n    wq_type = model[\"layers.0.attention.wq.weight\"\
          ].data_type\r\nKeyError: 'layers.0.attention.wq.weight'\r\n```\r\nMay i\
          \ know what is the weight number of this model?\r\n\r\nThank you in advance.\r\
          \n--\r\nLee"
        updatedAt: '2023-07-16T09:27:29.023Z'
      numEdits: 0
      reactions: []
    id: 64b3b8014dd3e248951182dc
    type: comment
  author: khanhj
  content: "Hi Symanto,\r\n\r\nThanks for provide this model.\r\nI'm using this method\
    \ to convert it to ggml: https://github.com/ggerganov/llama.cpp/blob/master/convert.py\r\
    \n\r\nThis is the error:\r\n```\r\nparams: n_vocab:250002 n_embd:768 n_mult:1536\
    \ n_head:12 n_layer:12\r\nTraceback (most recent call last):\r\n  File \"/root/github/llama.cpp/convert.py\"\
    , line 1270, in <module>\r\n    main()\r\n  File \"/root/github/llama.cpp/convert.py\"\
    , line 1262, in main\r\n    output_type = pick_output_type(model, args.outtype)\r\
    \n  File \"/root/github/llama.cpp/convert.py\", line 1075, in pick_output_type\r\
    \n    wq_type = model[\"layers.0.attention.wq.weight\"].data_type\r\nKeyError:\
    \ 'layers.0.attention.wq.weight'\r\n```\r\nMay i know what is the weight number\
    \ of this model?\r\n\r\nThank you in advance.\r\n--\r\nLee"
  created_at: 2023-07-16 08:27:29+00:00
  edited: false
  hidden: false
  id: 64b3b8014dd3e248951182dc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/48d8d410c804bd33c8b546a58a5edb99.svg
      fullname: Angelo Basile
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: abasile
      type: user
    createdAt: '2023-08-01T09:02:01.000Z'
    data:
      edited: false
      editors:
      - abasile
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9568185806274414
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/48d8d410c804bd33c8b546a58a5edb99.svg
          fullname: Angelo Basile
          isHf: false
          isPro: false
          name: abasile
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;khanhj&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/khanhj\">@<span class=\"\
          underline\">khanhj</span></a></span>\n\n\t</span></span> , </p>\n<p>thanks\
          \ for the interest in this model. I took a look at the <code>convert.py</code>\
          \ script that you are using and it seems to work only for specific model.\
          \ From what I understand, <code>llama.cpp</code> does not currently support\
          \ sentence transformer models. From a quick search however, I have seen\
          \ that <a rel=\"nofollow\" href=\"https://github.com/skeskinen/bert.cpp\"\
          >this library</a> should work in principle with this model. Have you tried\
          \ it already?</p>\n"
        raw: "Hi @khanhj , \n\nthanks for the interest in this model. I took a look\
          \ at the `convert.py` script that you are using and it seems to work only\
          \ for specific model. From what I understand, `llama.cpp` does not currently\
          \ support sentence transformer models. From a quick search however, I have\
          \ seen that [this library](https://github.com/skeskinen/bert.cpp) should\
          \ work in principle with this model. Have you tried it already?"
        updatedAt: '2023-08-01T09:02:01.306Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - khanhj
    id: 64c8ca09c547ed5243e5131d
    type: comment
  author: abasile
  content: "Hi @khanhj , \n\nthanks for the interest in this model. I took a look\
    \ at the `convert.py` script that you are using and it seems to work only for\
    \ specific model. From what I understand, `llama.cpp` does not currently support\
    \ sentence transformer models. From a quick search however, I have seen that [this\
    \ library](https://github.com/skeskinen/bert.cpp) should work in principle with\
    \ this model. Have you tried it already?"
  created_at: 2023-08-01 08:02:01+00:00
  edited: false
  hidden: false
  id: 64c8ca09c547ed5243e5131d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli
repo_type: model
status: open
target_branch: null
title: Question about convert model to ggml
