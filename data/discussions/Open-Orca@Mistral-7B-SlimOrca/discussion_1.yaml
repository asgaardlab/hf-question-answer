!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lvkaokao
conflicting_files: null
created_at: 2023-10-16 01:53:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
      fullname: lvkaokao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lvkaokao
      type: user
    createdAt: '2023-10-16T02:53:16.000Z'
    data:
      edited: false
      editors:
      - lvkaokao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7990779876708984
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
          fullname: lvkaokao
          isHf: false
          isPro: false
          name: lvkaokao
          type: user
        html: '<p>hi, can you share the finetuning hyper-parameters?</p>

          <p>I have finetuned the <a href="https://huggingface.co/mistralai/Mistral-7B-v0.1">https://huggingface.co/mistralai/Mistral-7B-v0.1</a>
          with your dataset, but the metric of ARC and hellaswag decreases significantly
          during the training</p>

          <p>here are some information of my hyper-parameters</p>

          <ol>

          <li>full parameters finetuning</li>

          <li>learning rate = 5e-6</li>

          <li>batch_size=64</li>

          <li>epoch=3</li>

          </ol>

          '
        raw: "hi, can you share the finetuning hyper-parameters?\r\n\r\nI have finetuned\
          \ the https://huggingface.co/mistralai/Mistral-7B-v0.1 with your dataset,\
          \ but the metric of ARC and hellaswag decreases significantly during the\
          \ training\r\n\r\nhere are some information of my hyper-parameters\r\n1.\
          \ full parameters finetuning\r\n2. learning rate = 5e-6\r\n3. batch_size=64\r\
          \n4. epoch=3 "
        updatedAt: '2023-10-16T02:53:16.724Z'
      numEdits: 0
      reactions: []
    id: 652ca59c703b3743c27c8aaa
    type: comment
  author: lvkaokao
  content: "hi, can you share the finetuning hyper-parameters?\r\n\r\nI have finetuned\
    \ the https://huggingface.co/mistralai/Mistral-7B-v0.1 with your dataset, but\
    \ the metric of ARC and hellaswag decreases significantly during the training\r\
    \n\r\nhere are some information of my hyper-parameters\r\n1. full parameters finetuning\r\
    \n2. learning rate = 5e-6\r\n3. batch_size=64\r\n4. epoch=3 "
  created_at: 2023-10-16 01:53:16+00:00
  edited: false
  hidden: false
  id: 652ca59c703b3743c27c8aaa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643197ac288c9775673a01e9/DHttvAV4r2WXcZFrsk3-k.png?w=200&h=200&f=face
      fullname: Shootime
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: xDAN2099
      type: user
    createdAt: '2023-10-16T02:57:40.000Z'
    data:
      edited: false
      editors:
      - xDAN2099
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9912127256393433
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643197ac288c9775673a01e9/DHttvAV4r2WXcZFrsk3-k.png?w=200&h=200&f=face
          fullname: Shootime
          isHf: false
          isPro: false
          name: xDAN2099
          type: user
        html: '<p>The batch_size is too huge and you should set to 4 or 6 is better.<br>I
          would prefer set the learning rate as  2e-5</p>

          '
        raw: 'The batch_size is too huge and you should set to 4 or 6 is better.

          I would prefer set the learning rate as  2e-5'
        updatedAt: '2023-10-16T02:57:40.022Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - lvkaokao
    id: 652ca6a460e7067305c9d7ee
    type: comment
  author: xDAN2099
  content: 'The batch_size is too huge and you should set to 4 or 6 is better.

    I would prefer set the learning rate as  2e-5'
  created_at: 2023-10-16 01:57:40+00:00
  edited: false
  hidden: false
  id: 652ca6a460e7067305c9d7ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
      fullname: lvkaokao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lvkaokao
      type: user
    createdAt: '2023-10-16T03:18:51.000Z'
    data:
      edited: false
      editors:
      - lvkaokao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9486792087554932
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
          fullname: lvkaokao
          isHf: false
          isPro: false
          name: lvkaokao
          type: user
        html: '<p>Thanks for your response~<br>I will try!</p>

          '
        raw: 'Thanks for your response~

          I will try!'
        updatedAt: '2023-10-16T03:18:51.108Z'
      numEdits: 0
      reactions: []
    id: 652cab9b68f1d7d1d2982e48
    type: comment
  author: lvkaokao
  content: 'Thanks for your response~

    I will try!'
  created_at: 2023-10-16 02:18:51+00:00
  edited: false
  hidden: false
  id: 652cab9b68f1d7d1d2982e48
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
      fullname: lvkaokao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lvkaokao
      type: user
    createdAt: '2023-10-16T04:20:36.000Z'
    data:
      edited: false
      editors:
      - lvkaokao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7866579294204712
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
          fullname: lvkaokao
          isHf: false
          isPro: false
          name: lvkaokao
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;xDAN2099&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/xDAN2099\">@<span class=\"\
          underline\">xDAN2099</span></a></span>\n\n\t</span></span><br>hi, what about\
          \ other parameters?</p>\n<p>I set<br>full parameters finetuning<br>learning\
          \ rate = 2e-5<br>batch_size=8<br>epoch=3<br>warmup_ratio = 0.03</p>\n<p>but\
          \ the training loss don't coverage</p>\n"
        raw: "@xDAN2099   \nhi, what about other parameters?\n\nI set \nfull parameters\
          \ finetuning\nlearning rate = 2e-5\nbatch_size=8\nepoch=3\nwarmup_ratio\
          \ = 0.03\n\nbut the training loss don't coverage"
        updatedAt: '2023-10-16T04:20:36.417Z'
      numEdits: 0
      reactions: []
    id: 652cba141198736f312db3de
    type: comment
  author: lvkaokao
  content: "@xDAN2099   \nhi, what about other parameters?\n\nI set \nfull parameters\
    \ finetuning\nlearning rate = 2e-5\nbatch_size=8\nepoch=3\nwarmup_ratio = 0.03\n\
    \nbut the training loss don't coverage"
  created_at: 2023-10-16 03:20:36+00:00
  edited: false
  hidden: false
  id: 652cba141198736f312db3de
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12ec5e367e2eac1650b2961097f74fa2.svg
      fullname: Lim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: timlim123
      type: user
    createdAt: '2023-12-05T10:24:55.000Z'
    data:
      edited: false
      editors:
      - timlim123
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9860718250274658
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12ec5e367e2eac1650b2961097f74fa2.svg
          fullname: Lim
          isHf: false
          isPro: false
          name: timlim123
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;lvkaokao&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/lvkaokao\">@<span class=\"\
          underline\">lvkaokao</span></a></span>\n\n\t</span></span> how did u fine-tune?\
          \ was it using axolotl too?</p>\n"
        raw: '@lvkaokao how did u fine-tune? was it using axolotl too?

          '
        updatedAt: '2023-12-05T10:24:55.430Z'
      numEdits: 0
      reactions: []
    id: 656efa778e7f2775ac09e970
    type: comment
  author: timlim123
  content: '@lvkaokao how did u fine-tune? was it using axolotl too?

    '
  created_at: 2023-12-05 10:24:55+00:00
  edited: false
  hidden: false
  id: 656efa778e7f2775ac09e970
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Open-Orca/Mistral-7B-SlimOrca
repo_type: model
status: open
target_branch: null
title: finetuning parameters
