!!python/object:huggingface_hub.community.DiscussionWithDetails
author: xpgx1
conflicting_files: null
created_at: 2023-12-26 20:24:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6357e2e3a680a9d532c84146/gcW4PlIVy8jBBBb8aeh3K.png?w=200&h=200&f=face
      fullname: Santa Clause
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xpgx1
      type: user
    createdAt: '2023-12-26T20:24:17.000Z'
    data:
      edited: true
      editors:
      - xpgx1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9496814608573914
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6357e2e3a680a9d532c84146/gcW4PlIVy8jBBBb8aeh3K.png?w=200&h=200&f=face
          fullname: Santa Clause
          isHf: false
          isPro: false
          name: xpgx1
          type: user
        html: '<p>I''m not sure if this is worthy of a whole community entry - but
          in my local testing - using OoobaBooga and SillyTavern (with Alpaca-ish
          formatting) - this model works rather well! It has some of the same issues
          as many similar "low context &amp; 13b" models, but when using the chat
          instruct mode without ST - it''s WAY above the (public &amp; free) ChatGPT
          responses, and rivals Bing - all without any internet access. It''s also
          not shy when expressing opinions.<br>It''s rather smart, sticks to complex
          orders well and tries its best, in general, to fight the limited reasoning.
          Its so good, in fact, it prompted me to respond here =)</p>

          <p>ERP and RP work well - but common phrases are still to be found, and
          are mostly rather similar. It has it''s moments of clarity - and uses them
          very impressively so. Thanks for the hard work, DaringMaid is certainly
          my new all-rounder for locally hosted, 4k context, Roleplay-Focussed models!
          </p>

          <p>Happy Holidays, btw. </p>

          <p>Edit: I''ve used the "gptq-4bit-32g-actorder_True" permutation as usual.
          VRAM budget was 12GB ideally, running on Windows 10, loaded by ExLlama2_HF.</p>

          '
        raw: "I'm not sure if this is worthy of a whole community entry - but in my\
          \ local testing - using OoobaBooga and SillyTavern (with Alpaca-ish formatting)\
          \ - this model works rather well! It has some of the same issues as many\
          \ similar \"low context & 13b\" models, but when using the chat instruct\
          \ mode without ST - it's WAY above the (public & free) ChatGPT responses,\
          \ and rivals Bing - all without any internet access. It's also not shy when\
          \ expressing opinions.\nIt's rather smart, sticks to complex orders well\
          \ and tries its best, in general, to fight the limited reasoning. Its so\
          \ good, in fact, it prompted me to respond here =)\n\nERP and RP work well\
          \ - but common phrases are still to be found, and are mostly rather similar.\
          \ It has it's moments of clarity - and uses them very impressively so. Thanks\
          \ for the hard work, DaringMaid is certainly my new all-rounder for locally\
          \ hosted, 4k context, Roleplay-Focussed models! \n\nHappy Holidays, btw.\
          \ \n\nEdit: I've used the \"gptq-4bit-32g-actorder_True\" permutation as\
          \ usual. VRAM budget was 12GB ideally, running on Windows 10, loaded by\
          \ ExLlama2_HF."
        updatedAt: '2023-12-26T20:26:14.977Z'
      numEdits: 2
      reactions: []
    id: 658b3671135580745c3a390f
    type: comment
  author: xpgx1
  content: "I'm not sure if this is worthy of a whole community entry - but in my\
    \ local testing - using OoobaBooga and SillyTavern (with Alpaca-ish formatting)\
    \ - this model works rather well! It has some of the same issues as many similar\
    \ \"low context & 13b\" models, but when using the chat instruct mode without\
    \ ST - it's WAY above the (public & free) ChatGPT responses, and rivals Bing -\
    \ all without any internet access. It's also not shy when expressing opinions.\n\
    It's rather smart, sticks to complex orders well and tries its best, in general,\
    \ to fight the limited reasoning. Its so good, in fact, it prompted me to respond\
    \ here =)\n\nERP and RP work well - but common phrases are still to be found,\
    \ and are mostly rather similar. It has it's moments of clarity - and uses them\
    \ very impressively so. Thanks for the hard work, DaringMaid is certainly my new\
    \ all-rounder for locally hosted, 4k context, Roleplay-Focussed models! \n\nHappy\
    \ Holidays, btw. \n\nEdit: I've used the \"gptq-4bit-32g-actorder_True\" permutation\
    \ as usual. VRAM budget was 12GB ideally, running on Windows 10, loaded by ExLlama2_HF."
  created_at: 2023-12-26 20:24:17+00:00
  edited: true
  hidden: false
  id: 658b3671135580745c3a390f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/DaringMaid-13B-GPTQ
repo_type: model
status: open
target_branch: null
title: Exceptional
