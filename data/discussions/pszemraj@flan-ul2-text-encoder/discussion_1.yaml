!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MoritzLaurer
conflicting_files: null
created_at: 2023-09-06 09:10:39+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
      fullname: Moritz Laurer
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MoritzLaurer
      type: user
    createdAt: '2023-09-06T10:10:39.000Z'
    data:
      edited: false
      editors:
      - MoritzLaurer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9489736557006836
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
          fullname: Moritz Laurer
          isHf: true
          isPro: false
          name: MoritzLaurer
          type: user
        html: '<p>Thanks for sharing this encoder-only model on the hub! How did you
          extract it from the encoder-decoder UL2? I remember seeing code from HF
          recently on how to extract an encoder-only model from an encoder-decoder,
          but I don''t remember where I saw it</p>

          '
        raw: Thanks for sharing this encoder-only model on the hub! How did you extract
          it from the encoder-decoder UL2? I remember seeing code from HF recently
          on how to extract an encoder-only model from an encoder-decoder, but I don't
          remember where I saw it
        updatedAt: '2023-09-06T10:10:39.541Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - pszemraj
    id: 64f8501fce75bb0fb5010ad1
    type: comment
  author: MoritzLaurer
  content: Thanks for sharing this encoder-only model on the hub! How did you extract
    it from the encoder-decoder UL2? I remember seeing code from HF recently on how
    to extract an encoder-only model from an encoder-decoder, but I don't remember
    where I saw it
  created_at: 2023-09-06 09:10:39+00:00
  edited: false
  hidden: false
  id: 64f8501fce75bb0fb5010ad1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
      fullname: Peter Szemraj
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: pszemraj
      type: user
    createdAt: '2023-09-06T15:11:04.000Z'
    data:
      edited: false
      editors:
      - pszemraj
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8534059524536133
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
          fullname: Peter Szemraj
          isHf: false
          isPro: false
          name: pszemraj
          type: user
        html: "<p>Hey! Thanks for the kind words. I think it may have been added to\
          \ the docs somewhere by now, but I saw it in <a rel=\"nofollow\" href=\"\
          https://github.com/huggingface/transformers/releases/tag/v4.31.0\">these\
          \ release notes</a>. </p>\n<p><strong>tl;dr</strong> There is a new class\
          \ for this that you can use to both load an existing extracted encoder model\
          \ (like this one) <strong>and</strong> extract one. If it isn't already\
          \ extracted, it will be automatically extracted. Since FLAN-UL2 is huge,\
          \ I thought I'd make a repo to save time/bandwidth.</p>\n<pre><code class=\"\
          language-python\"><span class=\"hljs-keyword\">from</span> transformers\
          \ <span class=\"hljs-keyword\">import</span> AutoModelForTextEncoding, AutoTokenizer\n\
          \n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\"\
          >load_model_and_tokenizer</span>(<span class=\"hljs-params\">model_name:\
          \ <span class=\"hljs-built_in\">str</span></span>):\n\n    model = AutoModelForTextEncoding.from_pretrained(\n\
          \        model_name, device_map=<span class=\"hljs-string\">\"auto\"</span>\n\
          \    ).<span class=\"hljs-built_in\">eval</span>()\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\
          \n    <span class=\"hljs-keyword\">return</span> model, tokenizer\n</code></pre>\n"
        raw: "Hey! Thanks for the kind words. I think it may have been added to the\
          \ docs somewhere by now, but I saw it in [these release notes](https://github.com/huggingface/transformers/releases/tag/v4.31.0).\
          \ \n\n**tl;dr** There is a new class for this that you can use to both load\
          \ an existing extracted encoder model (like this one) **and** extract one.\
          \ If it isn't already extracted, it will be automatically extracted. Since\
          \ FLAN-UL2 is huge, I thought I'd make a repo to save time/bandwidth.\n\n\
          ```python\nfrom transformers import AutoModelForTextEncoding, AutoTokenizer\n\
          \ndef load_model_and_tokenizer(model_name: str):\n\n    model = AutoModelForTextEncoding.from_pretrained(\n\
          \        model_name, device_map=\"auto\"\n    ).eval()\n    tokenizer =\
          \ AutoTokenizer.from_pretrained(model_name)\n\n    return model, tokenizer\n\
          ```"
        updatedAt: '2023-09-06T15:11:04.283Z'
      numEdits: 0
      reactions: []
    id: 64f896888a234f114e2e17f7
    type: comment
  author: pszemraj
  content: "Hey! Thanks for the kind words. I think it may have been added to the\
    \ docs somewhere by now, but I saw it in [these release notes](https://github.com/huggingface/transformers/releases/tag/v4.31.0).\
    \ \n\n**tl;dr** There is a new class for this that you can use to both load an\
    \ existing extracted encoder model (like this one) **and** extract one. If it\
    \ isn't already extracted, it will be automatically extracted. Since FLAN-UL2\
    \ is huge, I thought I'd make a repo to save time/bandwidth.\n\n```python\nfrom\
    \ transformers import AutoModelForTextEncoding, AutoTokenizer\n\ndef load_model_and_tokenizer(model_name:\
    \ str):\n\n    model = AutoModelForTextEncoding.from_pretrained(\n        model_name,\
    \ device_map=\"auto\"\n    ).eval()\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\
    \n    return model, tokenizer\n```"
  created_at: 2023-09-06 14:11:04+00:00
  edited: false
  hidden: false
  id: 64f896888a234f114e2e17f7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
      fullname: Moritz Laurer
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MoritzLaurer
      type: user
    createdAt: '2023-09-06T15:15:18.000Z'
    data:
      edited: false
      editors:
      - MoritzLaurer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.985649585723877
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
          fullname: Moritz Laurer
          isHf: true
          isPro: false
          name: MoritzLaurer
          type: user
        html: '<p>Great, now I remember seeing it in the release notes, that''s what
          I was looking for, thanks!</p>

          '
        raw: Great, now I remember seeing it in the release notes, that's what I was
          looking for, thanks!
        updatedAt: '2023-09-06T15:15:18.369Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - pszemraj
      relatedEventId: 64f8978667adddcb40c1a55e
    id: 64f8978667adddcb40c1a55c
    type: comment
  author: MoritzLaurer
  content: Great, now I remember seeing it in the release notes, that's what I was
    looking for, thanks!
  created_at: 2023-09-06 14:15:18+00:00
  edited: false
  hidden: false
  id: 64f8978667adddcb40c1a55c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
      fullname: Moritz Laurer
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MoritzLaurer
      type: user
    createdAt: '2023-09-06T15:15:18.000Z'
    data:
      status: closed
    id: 64f8978667adddcb40c1a55e
    type: status-change
  author: MoritzLaurer
  created_at: 2023-09-06 14:15:18+00:00
  id: 64f8978667adddcb40c1a55e
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
      fullname: Peter Szemraj
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: pszemraj
      type: user
    createdAt: '2023-09-07T17:40:09.000Z'
    data:
      edited: false
      editors:
      - pszemraj
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8240161538124084
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
          fullname: Peter Szemraj
          isHf: false
          isPro: false
          name: pszemraj
          type: user
        html: '<p>No prob - happy to help </p>

          '
        raw: 'No prob - happy to help '
        updatedAt: '2023-09-07T17:40:09.879Z'
      numEdits: 0
      reactions: []
    id: 64fa0af97904ea30e63c7d96
    type: comment
  author: pszemraj
  content: 'No prob - happy to help '
  created_at: 2023-09-07 16:40:09+00:00
  edited: false
  hidden: false
  id: 64fa0af97904ea30e63c7d96
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: pszemraj/flan-ul2-text-encoder
repo_type: model
status: closed
target_branch: null
title: How to extract encoder from encoder-decoder?
