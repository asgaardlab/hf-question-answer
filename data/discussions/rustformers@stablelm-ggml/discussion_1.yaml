!!python/object:huggingface_hub.community.DiscussionWithDetails
author: wise-time
conflicting_files: null
created_at: 2023-06-14 20:54:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0124f34171dd0903b908facaa5e763e8.svg
      fullname: alexis wasmuth
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wise-time
      type: user
    createdAt: '2023-06-14T21:54:21.000Z'
    data:
      edited: false
      editors:
      - wise-time
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8963050842285156
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0124f34171dd0903b908facaa5e763e8.svg
          fullname: alexis wasmuth
          isHf: false
          isPro: false
          name: wise-time
          type: user
        html: '<p>Would really like to see a q8_0 version, I find this available on
          most other webui compatible language models.</p>

          '
        raw: Would really like to see a q8_0 version, I find this available on most
          other webui compatible language models.
        updatedAt: '2023-06-14T21:54:21.081Z'
      numEdits: 0
      reactions: []
    id: 648a370db3ddfd6019d32de3
    type: comment
  author: wise-time
  content: Would really like to see a q8_0 version, I find this available on most
    other webui compatible language models.
  created_at: 2023-06-14 20:54:21+00:00
  edited: false
  hidden: false
  id: 648a370db3ddfd6019d32de3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62da57f34be126e22e8bed5f/ghmINp1UDr9XnqZVaf_9G.png?w=200&h=200&f=face
      fullname: Lukas Kreussel
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: LLukas22
      type: user
    createdAt: '2023-06-15T08:08:49.000Z'
    data:
      edited: false
      editors:
      - LLukas22
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9428000450134277
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62da57f34be126e22e8bed5f/ghmINp1UDr9XnqZVaf_9G.png?w=200&h=200&f=face
          fullname: Lukas Kreussel
          isHf: false
          isPro: false
          name: LLukas22
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;wise-time&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/wise-time\">@<span class=\"\
          underline\">wise-time</span></a></span>\n\n\t</span></span> I decided to\
          \ exclude q8_0 for now as the difference in performance between q5_1 and\
          \ q8_0 shouldn't be that great according to <a rel=\"nofollow\" href=\"\
          https://github.com/ggerganov/llama.cpp#quantization\">llama.cpp</a>.<br>If\
          \ the <a rel=\"nofollow\" href=\"https://github.com/ggerganov/ggml/issues/220\"\
          >new model format</a> is defined and finalized i will probably uplaod all\
          \ models in all available quantization formats. But as it's not clear when\
          \ this will happen i'm waiting for now. </p>\n"
        raw: '@wise-time I decided to exclude q8_0 for now as the difference in performance
          between q5_1 and q8_0 shouldn''t be that great according to [llama.cpp](https://github.com/ggerganov/llama.cpp#quantization).

          If the [new model format](https://github.com/ggerganov/ggml/issues/220)
          is defined and finalized i will probably uplaod all models in all available
          quantization formats. But as it''s not clear when this will happen i''m
          waiting for now. '
        updatedAt: '2023-06-15T08:08:49.238Z'
      numEdits: 0
      reactions: []
    id: 648ac71191ddcbf171914792
    type: comment
  author: LLukas22
  content: '@wise-time I decided to exclude q8_0 for now as the difference in performance
    between q5_1 and q8_0 shouldn''t be that great according to [llama.cpp](https://github.com/ggerganov/llama.cpp#quantization).

    If the [new model format](https://github.com/ggerganov/ggml/issues/220) is defined
    and finalized i will probably uplaod all models in all available quantization
    formats. But as it''s not clear when this will happen i''m waiting for now. '
  created_at: 2023-06-15 07:08:49+00:00
  edited: false
  hidden: false
  id: 648ac71191ddcbf171914792
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: rustformers/stablelm-ggml
repo_type: model
status: open
target_branch: null
title: Other formats?
