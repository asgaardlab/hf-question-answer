!!python/object:huggingface_hub.community.DiscussionWithDetails
author: diwank
conflicting_files: null
created_at: 2023-07-03 16:35:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659978504573-6093a02dc4a92d63a91c5236.jpeg?w=200&h=200&f=face
      fullname: Diwank Tomer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: diwank
      type: user
    createdAt: '2023-07-03T17:35:40.000Z'
    data:
      edited: false
      editors:
      - diwank
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9604039192199707
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659978504573-6093a02dc4a92d63a91c5236.jpeg?w=200&h=200&f=face
          fullname: Diwank Tomer
          isHf: false
          isPro: false
          name: diwank
          type: user
        html: "<p>Hey there,</p>\n<p>Thanks for the amazing work as always! I want\
          \ to finetune the <code>mpt-30b</code> and its <code>instruct</code> variant\
          \ on a custom dataset. Is there a reference script / notebook available\
          \ that shows an example of how to do so? I tried looking around but couldn't\
          \ find one.</p>\n<p>I did try to finetune it using a vanilla huggingface\
          \ <code>Trainer</code> with qlora and that didn't seem to work unfortunately.\
          \ It gave a weird \"mpt models do not support gradient checkpointing\" error.</p>\n\
          <p>p.s. <span data-props=\"{&quot;user&quot;:&quot;abhi-mosaic&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/abhi-mosaic\"\
          >@<span class=\"underline\">abhi-mosaic</span></a></span>\n\n\t</span></span>\
          \ <span data-props=\"{&quot;user&quot;:&quot;sam-mosaic&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/sam-mosaic\">@<span class=\"\
          underline\">sam-mosaic</span></a></span>\n\n\t</span></span> is this something\
          \ that you could help out with?</p>\n"
        raw: "Hey there,\r\n\r\nThanks for the amazing work as always! I want to finetune\
          \ the `mpt-30b` and its `instruct` variant on a custom dataset. Is there\
          \ a reference script / notebook available that shows an example of how to\
          \ do so? I tried looking around but couldn't find one.\r\n\r\nI did try\
          \ to finetune it using a vanilla huggingface `Trainer` with qlora and that\
          \ didn't seem to work unfortunately. It gave a weird \"mpt models do not\
          \ support gradient checkpointing\" error.\r\n\r\np.s. @abhi-mosaic @sam-mosaic\
          \ is this something that you could help out with?"
        updatedAt: '2023-07-03T17:35:40.515Z'
      numEdits: 0
      reactions: []
    id: 64a306ecfdb0114d28fa32fe
    type: comment
  author: diwank
  content: "Hey there,\r\n\r\nThanks for the amazing work as always! I want to finetune\
    \ the `mpt-30b` and its `instruct` variant on a custom dataset. Is there a reference\
    \ script / notebook available that shows an example of how to do so? I tried looking\
    \ around but couldn't find one.\r\n\r\nI did try to finetune it using a vanilla\
    \ huggingface `Trainer` with qlora and that didn't seem to work unfortunately.\
    \ It gave a weird \"mpt models do not support gradient checkpointing\" error.\r\
    \n\r\np.s. @abhi-mosaic @sam-mosaic is this something that you could help out\
    \ with?"
  created_at: 2023-07-03 16:35:40+00:00
  edited: false
  hidden: false
  id: 64a306ecfdb0114d28fa32fe
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: mosaicml/mpt-30b
repo_type: model
status: open
target_branch: null
title: Instructions for finetuning?
