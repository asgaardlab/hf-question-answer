!!python/object:huggingface_hub.community.DiscussionWithDetails
author: yc
conflicting_files: null
created_at: 2023-07-18 12:42:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9f7580c7be355ac185bc179ad20daeef.svg
      fullname: Yufan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yc
      type: user
    createdAt: '2023-07-18T13:42:36.000Z'
    data:
      edited: false
      editors:
      - yc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8514085412025452
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9f7580c7be355ac185bc179ad20daeef.svg
          fullname: Yufan
          isHf: false
          isPro: false
          name: yc
          type: user
        html: '<p>Running on M1 max with 32G memory. 7B/13B llama/vicuna ggml model
          runs fine though.</p>

          '
        raw: Running on M1 max with 32G memory. 7B/13B llama/vicuna ggml model runs
          fine though.
        updatedAt: '2023-07-18T13:42:36.667Z'
      numEdits: 0
      reactions: []
    id: 64b696ccfb621a3ac583b4ea
    type: comment
  author: yc
  content: Running on M1 max with 32G memory. 7B/13B llama/vicuna ggml model runs
    fine though.
  created_at: 2023-07-18 12:42:36+00:00
  edited: false
  hidden: false
  id: 64b696ccfb621a3ac583b4ea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642d678777078db98b729188/UG42t8m7454PbDTSc7G5o.png?w=200&h=200&f=face
      fullname: algorithm
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: algorithm
      type: user
    createdAt: '2023-07-21T10:33:38.000Z'
    data:
      edited: false
      editors:
      - algorithm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7020565867424011
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642d678777078db98b729188/UG42t8m7454PbDTSc7G5o.png?w=200&h=200&f=face
          fullname: algorithm
          isHf: false
          isPro: false
          name: algorithm
          type: user
        html: '<p><a rel="nofollow" href="https://github.com/ggerganov/llama.cpp/issues/52">https://github.com/ggerganov/llama.cpp/issues/52</a></p>

          '
        raw: https://github.com/ggerganov/llama.cpp/issues/52
        updatedAt: '2023-07-21T10:33:38.231Z'
      numEdits: 0
      reactions: []
    id: 64ba5f02bfd8286d23ae08ea
    type: comment
  author: algorithm
  content: https://github.com/ggerganov/llama.cpp/issues/52
  created_at: 2023-07-21 09:33:38+00:00
  edited: false
  hidden: false
  id: 64ba5f02bfd8286d23ae08ea
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/baichuan-vicuna-7B-GGML
repo_type: model
status: open
target_branch: null
title: 'ggml_new_tensor_impl: not enough space in the context''s memory pool'
