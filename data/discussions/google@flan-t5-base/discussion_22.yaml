!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Mohamed123321
conflicting_files: null
created_at: 2023-10-07 13:00:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c42e0cde8fb73921e776c6a5877d2599.svg
      fullname: Dhouib
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Mohamed123321
      type: user
    createdAt: '2023-10-07T14:00:27.000Z'
    data:
      edited: false
      editors:
      - Mohamed123321
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9503365159034729
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c42e0cde8fb73921e776c6a5877d2599.svg
          fullname: Dhouib
          isHf: false
          isPro: false
          name: Mohamed123321
          type: user
        html: '<p>Hello,<br>I was wondering how can I access and change the tokenizer''s
          token ids ?<br>Thanks !</p>

          '
        raw: "Hello,\r\nI was wondering how can I access and change the tokenizer's\
          \ token ids ?\r\nThanks !"
        updatedAt: '2023-10-07T14:00:27.456Z'
      numEdits: 0
      reactions: []
    id: 6521647b54967a3a499dd264
    type: comment
  author: Mohamed123321
  content: "Hello,\r\nI was wondering how can I access and change the tokenizer's\
    \ token ids ?\r\nThanks !"
  created_at: 2023-10-07 13:00:27+00:00
  edited: false
  hidden: false
  id: 6521647b54967a3a499dd264
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-10-09T16:09:08.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5633304119110107
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: "<p>cc <span data-props=\"{&quot;user&quot;:&quot;ArthurZ&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ArthurZ\">@<span class=\"\
          underline\">ArthurZ</span></a></span>\n\n\t</span></span> </p>\n"
        raw: "cc @ArthurZ \n"
        updatedAt: '2023-10-09T16:09:08.074Z'
      numEdits: 0
      reactions: []
    id: 652425a40b84de275c1bd014
    type: comment
  author: ybelkada
  content: "cc @ArthurZ \n"
  created_at: 2023-10-09 15:09:08+00:00
  edited: false
  hidden: false
  id: 652425a40b84de275c1bd014
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c42e0cde8fb73921e776c6a5877d2599.svg
      fullname: Dhouib
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Mohamed123321
      type: user
    createdAt: '2023-10-09T20:10:57.000Z'
    data:
      edited: false
      editors:
      - Mohamed123321
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9596574902534485
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c42e0cde8fb73921e776c6a5877d2599.svg
          fullname: Dhouib
          isHf: false
          isPro: false
          name: Mohamed123321
          type: user
        html: '<p>I may add  that I speak about the mapping from tokens (part of words)
          and ids</p>

          '
        raw: I may add  that I speak about the mapping from tokens (part of words)
          and ids
        updatedAt: '2023-10-09T20:10:57.550Z'
      numEdits: 0
      reactions: []
    id: 65245e51a9a710554b14edaf
    type: comment
  author: Mohamed123321
  content: I may add  that I speak about the mapping from tokens (part of words) and
    ids
  created_at: 2023-10-09 19:10:57+00:00
  edited: false
  hidden: false
  id: 65245e51a9a710554b14edaf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-10-10T18:14:17.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8382397294044495
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>Hey! The tokenizer by default is based on sentencepiece. You can''t
          really change it but you can add tokens using <code>add_tokens</code> and
          see the vocab using <code>tokenizer.get_vocab()</code></p>

          '
        raw: Hey! The tokenizer by default is based on sentencepiece. You can't really
          change it but you can add tokens using `add_tokens` and see the vocab using
          `tokenizer.get_vocab()`
        updatedAt: '2023-10-10T18:14:17.299Z'
      numEdits: 0
      reactions: []
    id: 652594796b41932089e717cc
    type: comment
  author: ArthurZ
  content: Hey! The tokenizer by default is based on sentencepiece. You can't really
    change it but you can add tokens using `add_tokens` and see the vocab using `tokenizer.get_vocab()`
  created_at: 2023-10-10 17:14:17+00:00
  edited: false
  hidden: false
  id: 652594796b41932089e717cc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 22
repo_id: google/flan-t5-base
repo_type: model
status: open
target_branch: null
title: Where to find the token ids of the tokenizer ?
