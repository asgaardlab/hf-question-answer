!!python/object:huggingface_hub.community.DiscussionWithDetails
author: practical-dreamer
conflicting_files: null
created_at: 2023-07-09 01:30:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642e4fbda0b65dce1f875e90/o08Ni4hSRiqyoBy6MEg-a.jpeg?w=200&h=200&f=face
      fullname: practical-dreamer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: practical-dreamer
      type: user
    createdAt: '2023-07-09T02:30:06.000Z'
    data:
      edited: false
      editors:
      - practical-dreamer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8479450941085815
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642e4fbda0b65dce1f875e90/o08Ni4hSRiqyoBy6MEg-a.jpeg?w=200&h=200&f=face
          fullname: practical-dreamer
          isHf: false
          isPro: false
          name: practical-dreamer
          type: user
        html: '<p>Can you please put approximate VRAM usage for this model? Thank
          you</p>

          '
        raw: Can you please put approximate VRAM usage for this model? Thank you
        updatedAt: '2023-07-09T02:30:06.533Z'
      numEdits: 0
      reactions: []
    id: 64aa1baee368492ab8ead1a3
    type: comment
  author: practical-dreamer
  content: Can you please put approximate VRAM usage for this model? Thank you
  created_at: 2023-07-09 01:30:06+00:00
  edited: false
  hidden: false
  id: 64aa1baee368492ab8ead1a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c2d5207bd79bfe88218e1b5bbb1a2274.svg
      fullname: Ycros
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ycros
      type: user
    createdAt: '2023-07-10T06:17:28.000Z'
    data:
      edited: false
      editors:
      - ycros
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9941690564155579
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c2d5207bd79bfe88218e1b5bbb1a2274.svg
          fullname: Ycros
          isHf: false
          isPro: false
          name: ycros
          type: user
        html: '<p>No idea sorry, I don''t actually use these myself I just did them
          as a favor for someone else who does.</p>

          '
        raw: No idea sorry, I don't actually use these myself I just did them as a
          favor for someone else who does.
        updatedAt: '2023-07-10T06:17:28.423Z'
      numEdits: 0
      reactions: []
    id: 64aba2785a69e2ca88d0457b
    type: comment
  author: ycros
  content: No idea sorry, I don't actually use these myself I just did them as a favor
    for someone else who does.
  created_at: 2023-07-10 05:17:28+00:00
  edited: false
  hidden: false
  id: 64aba2785a69e2ca88d0457b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/640590b591ee7d7f287183ae/PQefPEgtaNqnTNfumrZXr.jpeg?w=200&h=200&f=face
      fullname: David Scott
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ReMeDy-TV
      type: user
    createdAt: '2023-07-16T11:54:16.000Z'
    data:
      edited: true
      editors:
      - ReMeDy-TV
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8599302172660828
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/640590b591ee7d7f287183ae/PQefPEgtaNqnTNfumrZXr.jpeg?w=200&h=200&f=face
          fullname: David Scott
          isHf: false
          isPro: false
          name: ReMeDy-TV
          type: user
        html: '<p>Unfortunately, it needs more than 48GB if using 8192 context. On
          an A100 (80GB), you''ll be at 72% GPU memory used when the model is initially
          loaded.</p>

          '
        raw: Unfortunately, it needs more than 48GB if using 8192 context. On an A100
          (80GB), you'll be at 72% GPU memory used when the model is initially loaded.
        updatedAt: '2023-07-16T11:56:46.085Z'
      numEdits: 1
      reactions: []
    id: 64b3da686d953e7c75f7be15
    type: comment
  author: ReMeDy-TV
  content: Unfortunately, it needs more than 48GB if using 8192 context. On an A100
    (80GB), you'll be at 72% GPU memory used when the model is initially loaded.
  created_at: 2023-07-16 10:54:16+00:00
  edited: true
  hidden: false
  id: 64b3da686d953e7c75f7be15
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642e4fbda0b65dce1f875e90/o08Ni4hSRiqyoBy6MEg-a.jpeg?w=200&h=200&f=face
      fullname: practical-dreamer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: practical-dreamer
      type: user
    createdAt: '2023-07-19T16:47:55.000Z'
    data:
      edited: false
      editors:
      - practical-dreamer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9578490853309631
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642e4fbda0b65dce1f875e90/o08Ni4hSRiqyoBy6MEg-a.jpeg?w=200&h=200&f=face
          fullname: practical-dreamer
          isHf: false
          isPro: false
          name: practical-dreamer
          type: user
        html: "<p>Yeah I tried splitting across two 3090s and got OOM. I\u2019d be\
          \ interested in a 4K length variant if it ever is made</p>\n"
        raw: "Yeah I tried splitting across two 3090s and got OOM. I\u2019d be interested\
          \ in a 4K length variant if it ever is made"
        updatedAt: '2023-07-19T16:47:55.313Z'
      numEdits: 0
      reactions: []
    id: 64b813bbf62a2c23a6e70b76
    type: comment
  author: practical-dreamer
  content: "Yeah I tried splitting across two 3090s and got OOM. I\u2019d be interested\
    \ in a 4K length variant if it ever is made"
  created_at: 2023-07-19 15:47:55+00:00
  edited: false
  hidden: false
  id: 64b813bbf62a2c23a6e70b76
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c2d5207bd79bfe88218e1b5bbb1a2274.svg
      fullname: Ycros
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ycros
      type: user
    createdAt: '2023-07-20T01:49:40.000Z'
    data:
      edited: false
      editors:
      - ycros
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9405415654182434
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c2d5207bd79bfe88218e1b5bbb1a2274.svg
          fullname: Ycros
          isHf: false
          isPro: false
          name: ycros
          type: user
        html: '<p>Given that the 33b 16k tunes outperform the 33b 8k tunes at all
          context sizes, I suspect a 4k would do worse than this one, if anything
          a 16k might be better. But, I''m also waiting to see proper results from
          the new ntk by parts/ntkv2 finetune method.</p>

          <p>If you''re only after 4k you should be able to run this one with a max
          context of 4k, as long as compress_pos_emb is 4</p>

          '
        raw: 'Given that the 33b 16k tunes outperform the 33b 8k tunes at all context
          sizes, I suspect a 4k would do worse than this one, if anything a 16k might
          be better. But, I''m also waiting to see proper results from the new ntk
          by parts/ntkv2 finetune method.


          If you''re only after 4k you should be able to run this one with a max context
          of 4k, as long as compress_pos_emb is 4'
        updatedAt: '2023-07-20T01:49:40.884Z'
      numEdits: 0
      reactions: []
    id: 64b892b46b5ee8c388587b4c
    type: comment
  author: ycros
  content: 'Given that the 33b 16k tunes outperform the 33b 8k tunes at all context
    sizes, I suspect a 4k would do worse than this one, if anything a 16k might be
    better. But, I''m also waiting to see proper results from the new ntk by parts/ntkv2
    finetune method.


    If you''re only after 4k you should be able to run this one with a max context
    of 4k, as long as compress_pos_emb is 4'
  created_at: 2023-07-20 00:49:40+00:00
  edited: false
  hidden: false
  id: 64b892b46b5ee8c388587b4c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: ycros/airoboros-65b-gpt4-1.4.1-PI-8192-4bit-32g-actorder
repo_type: model
status: open
target_branch: null
title: VRAM Requirements
