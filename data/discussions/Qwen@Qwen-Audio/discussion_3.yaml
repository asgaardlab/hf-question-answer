!!python/object:huggingface_hub.community.DiscussionWithDetails
author: wbbbbb
conflicting_files: null
created_at: 2023-12-02 03:31:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/05ab77ef59831f4d18baddcdb7c3c7c9.svg
      fullname: wb
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wbbbbb
      type: user
    createdAt: '2023-12-02T03:31:13.000Z'
    data:
      edited: false
      editors:
      - wbbbbb
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.39585644006729126
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/05ab77ef59831f4d18baddcdb7c3c7c9.svg
          fullname: wb
          isHf: false
          isPro: false
          name: wbbbbb
          type: user
        html: '<h2 id="audio_start_id-155163-audio_end_id-155164-audio_pad_id-151851">audio_start_id:
          155163, audio_end_id: 155164, audio_pad_id: 151851.</h2>

          <p>OSError                                   Traceback (most recent call
          last)<br>Cell In[17], line 10<br>      6 tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen-Audio",
          trust_remote_code=True)<br>      9 # use cuda device<br>---&gt; 10 model
          = AutoModelForCausalLM.from_pretrained("Qwen/Qwen-Audio", device_map="cuda",
          fp16=True,trust_remote_code=True).eval()</p>

          <p>File /usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:462,
          in _BaseAutoModelClass.from_pretrained(cls, pretrained_model_name_or_path,
          *model_args, **kwargs)<br>    458     class_ref = config.auto_map[cls.<strong>name</strong>]<br>    459     model_class
          = get_class_from_dynamic_module(<br>    460         class_ref, pretrained_model_name_or_path,
          **hub_kwargs, **kwargs<br>    461     )<br>--&gt; 462     return model_class.from_pretrained(<br>    463         pretrained_model_name_or_path,
          *model_args, config=config, **hub_kwargs, **kwargs<br>    464     )<br>    465
          elif type(config) in cls._model_mapping.keys():<br>    466     model_class
          = _get_model_class(config, cls._model_mapping)</p>

          <p>File ~/.cache/huggingface/modules/transformers_modules/Qwen/Qwen-Audio/02f8fd45af17fb606010fead66dc2e56fc803543/modeling_qwen.py:1037,
          in QWenLMHeadModel.from_pretrained(cls, pretrained_model_name_or_path, config,
          cache_dir, *model_args, **kwargs)<br>   1034     from huggingface_hub import
          hf_hub_download<br>   1035     hf_hub_download(repo_id=pretrained_model_name_or_path,
          filename="mel_filters.npz",<br>   1036                     token=kwargs.get(''token'',
          None), local_dir=os.path.dirname(<strong>file</strong>))<br>-&gt; 1037 return
          super().from_pretrained(pretrained_model_name_or_path, *model_args, config=config,
          cache_dir=cache_dir,<br>   1038                                **kwargs)</p>

          <p>File /usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2493,
          in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path, *model_args,
          **kwargs)<br>   2487             raise EnvironmentError(<br>   2488                 f"{pretrained_model_name_or_path}
          does not appear to have a file named"<br>   2489                 f" {_add_variant(WEIGHTS_NAME,
          variant)} but there is a file without the variant"<br>   2490                 f"
          {variant}. Use <code>variant=None</code> to load this model from those weights."<br>   2491             )<br>   2492         else:<br>-&gt;
          2493             raise EnvironmentError(<br>   2494                 f"{pretrained_model_name_or_path}
          does not appear to have a file named"<br>   2495                 f" {_add_variant(WEIGHTS_NAME,
          variant)}, {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME} or"<br>   2496                 f"
          {FLAX_WEIGHTS_NAME}."<br>   2497             )<br>   2498 except EnvironmentError:<br>   2499     #
          Raise any environment error raise by <code>cached_file</code>. It will have
          a helpful error message adapted<br>   2500     # to the original exception.<br>   2501     raise</p>

          <p>OSError: Qwen/Qwen-Audio does not appear to have a file named pytorch_model.bin,
          tf_model.h5, model.ckpt or flax_model.msgpack.</p>

          '
        raw: "audio_start_id: 155163, audio_end_id: 155164, audio_pad_id: 151851.\r\
          \n---------------------------------------------------------------------------\r\
          \nOSError                                   Traceback (most recent call\
          \ last)\r\nCell In[17], line 10\r\n      6 tokenizer = AutoTokenizer.from_pretrained(\"\
          Qwen/Qwen-Audio\", trust_remote_code=True)\r\n      9 # use cuda device\r\
          \n---> 10 model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-Audio\"\
          , device_map=\"cuda\", fp16=True,trust_remote_code=True).eval()\r\n\r\n\
          File /usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:462,\
          \ in _BaseAutoModelClass.from_pretrained(cls, pretrained_model_name_or_path,\
          \ *model_args, **kwargs)\r\n    458     class_ref = config.auto_map[cls.__name__]\r\
          \n    459     model_class = get_class_from_dynamic_module(\r\n    460  \
          \       class_ref, pretrained_model_name_or_path, **hub_kwargs, **kwargs\r\
          \n    461     )\r\n--> 462     return model_class.from_pretrained(\r\n \
          \   463         pretrained_model_name_or_path, *model_args, config=config,\
          \ **hub_kwargs, **kwargs\r\n    464     )\r\n    465 elif type(config) in\
          \ cls._model_mapping.keys():\r\n    466     model_class = _get_model_class(config,\
          \ cls._model_mapping)\r\n\r\nFile ~/.cache/huggingface/modules/transformers_modules/Qwen/Qwen-Audio/02f8fd45af17fb606010fead66dc2e56fc803543/modeling_qwen.py:1037,\
          \ in QWenLMHeadModel.from_pretrained(cls, pretrained_model_name_or_path,\
          \ config, cache_dir, *model_args, **kwargs)\r\n   1034     from huggingface_hub\
          \ import hf_hub_download\r\n   1035     hf_hub_download(repo_id=pretrained_model_name_or_path,\
          \ filename=\"mel_filters.npz\",\r\n   1036                     token=kwargs.get('token',\
          \ None), local_dir=os.path.dirname(__file__))\r\n-> 1037 return super().from_pretrained(pretrained_model_name_or_path,\
          \ *model_args, config=config, cache_dir=cache_dir,\r\n   1038          \
          \                      **kwargs)\r\n\r\nFile /usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2493,\
          \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path,\
          \ *model_args, **kwargs)\r\n   2487             raise EnvironmentError(\r\
          \n   2488                 f\"{pretrained_model_name_or_path} does not appear\
          \ to have a file named\"\r\n   2489                 f\" {_add_variant(WEIGHTS_NAME,\
          \ variant)} but there is a file without the variant\"\r\n   2490       \
          \          f\" {variant}. Use `variant=None` to load this model from those\
          \ weights.\"\r\n   2491             )\r\n   2492         else:\r\n-> 2493\
          \             raise EnvironmentError(\r\n   2494                 f\"{pretrained_model_name_or_path}\
          \ does not appear to have a file named\"\r\n   2495                 f\"\
          \ {_add_variant(WEIGHTS_NAME, variant)}, {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME}\
          \ or\"\r\n   2496                 f\" {FLAX_WEIGHTS_NAME}.\"\r\n   2497\
          \             )\r\n   2498 except EnvironmentError:\r\n   2499     # Raise\
          \ any environment error raise by `cached_file`. It will have a helpful error\
          \ message adapted\r\n   2500     # to the original exception.\r\n   2501\
          \     raise\r\n\r\nOSError: Qwen/Qwen-Audio does not appear to have a file\
          \ named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack."
        updatedAt: '2023-12-02T03:31:13.739Z'
      numEdits: 0
      reactions: []
    id: 656aa501903e16e62b92ba96
    type: comment
  author: wbbbbb
  content: "audio_start_id: 155163, audio_end_id: 155164, audio_pad_id: 151851.\r\n\
    ---------------------------------------------------------------------------\r\n\
    OSError                                   Traceback (most recent call last)\r\n\
    Cell In[17], line 10\r\n      6 tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-Audio\"\
    , trust_remote_code=True)\r\n      9 # use cuda device\r\n---> 10 model = AutoModelForCausalLM.from_pretrained(\"\
    Qwen/Qwen-Audio\", device_map=\"cuda\", fp16=True,trust_remote_code=True).eval()\r\
    \n\r\nFile /usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:462,\
    \ in _BaseAutoModelClass.from_pretrained(cls, pretrained_model_name_or_path, *model_args,\
    \ **kwargs)\r\n    458     class_ref = config.auto_map[cls.__name__]\r\n    459\
    \     model_class = get_class_from_dynamic_module(\r\n    460         class_ref,\
    \ pretrained_model_name_or_path, **hub_kwargs, **kwargs\r\n    461     )\r\n-->\
    \ 462     return model_class.from_pretrained(\r\n    463         pretrained_model_name_or_path,\
    \ *model_args, config=config, **hub_kwargs, **kwargs\r\n    464     )\r\n    465\
    \ elif type(config) in cls._model_mapping.keys():\r\n    466     model_class =\
    \ _get_model_class(config, cls._model_mapping)\r\n\r\nFile ~/.cache/huggingface/modules/transformers_modules/Qwen/Qwen-Audio/02f8fd45af17fb606010fead66dc2e56fc803543/modeling_qwen.py:1037,\
    \ in QWenLMHeadModel.from_pretrained(cls, pretrained_model_name_or_path, config,\
    \ cache_dir, *model_args, **kwargs)\r\n   1034     from huggingface_hub import\
    \ hf_hub_download\r\n   1035     hf_hub_download(repo_id=pretrained_model_name_or_path,\
    \ filename=\"mel_filters.npz\",\r\n   1036                     token=kwargs.get('token',\
    \ None), local_dir=os.path.dirname(__file__))\r\n-> 1037 return super().from_pretrained(pretrained_model_name_or_path,\
    \ *model_args, config=config, cache_dir=cache_dir,\r\n   1038                \
    \                **kwargs)\r\n\r\nFile /usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2493,\
    \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path, *model_args,\
    \ **kwargs)\r\n   2487             raise EnvironmentError(\r\n   2488        \
    \         f\"{pretrained_model_name_or_path} does not appear to have a file named\"\
    \r\n   2489                 f\" {_add_variant(WEIGHTS_NAME, variant)} but there\
    \ is a file without the variant\"\r\n   2490                 f\" {variant}. Use\
    \ `variant=None` to load this model from those weights.\"\r\n   2491         \
    \    )\r\n   2492         else:\r\n-> 2493             raise EnvironmentError(\r\
    \n   2494                 f\"{pretrained_model_name_or_path} does not appear to\
    \ have a file named\"\r\n   2495                 f\" {_add_variant(WEIGHTS_NAME,\
    \ variant)}, {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME} or\"\r\n   2496           \
    \      f\" {FLAX_WEIGHTS_NAME}.\"\r\n   2497             )\r\n   2498 except EnvironmentError:\r\
    \n   2499     # Raise any environment error raise by `cached_file`. It will have\
    \ a helpful error message adapted\r\n   2500     # to the original exception.\r\
    \n   2501     raise\r\n\r\nOSError: Qwen/Qwen-Audio does not appear to have a\
    \ file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack."
  created_at: 2023-12-02 03:31:13+00:00
  edited: false
  hidden: false
  id: 656aa501903e16e62b92ba96
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6b59f49f2cd097eb717d68e69a9d076b.svg
      fullname: banban
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ahban
      type: user
    createdAt: '2023-12-07T06:18:56.000Z'
    data:
      edited: false
      editors:
      - ahban
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9910682439804077
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6b59f49f2cd097eb717d68e69a9d076b.svg
          fullname: banban
          isHf: false
          isPro: false
          name: ahban
          type: user
        html: "<p>\u6211\u4E5F\u9047\u5230\u4E86\u8FD9\u4E2A\u95EE\u9898\uFF0C\u6211\
          \u7528git clone\u4E86modelscope\u4E0A\u7684\u6A21\u578B\u5C31\u53EF\u4EE5\
          \u4E86\uFF0C\u4F46\u662F\u5728\u9047\u5230\u8FD9\u4E2A\u95EE\u9898\u4E4B\
          \u524D\uFF0C\u6A21\u578B\u80FD\u5DE5\u4F5C\u7684\u65F6\u5019\uFF0C\u8FD8\
          \u662F\u80FD\u6B63\u5E38\u8BC6\u522B\u7684\uFF0C\u5F53\u6211\u7528git clone\u6765\
          \u83B7\u5F97\u6A21\u578B\u4E4B\u540E\uFF0C\u6548\u679C\u5C31\u4E0D\u884C\
          \u4E86\uFF0C\u8F93\u51FA\u7684\u8BC6\u522B\u7ED3\u679C\u5C31\u5F88\u4E71\
          \u4E86</p>\n"
        raw: "\u6211\u4E5F\u9047\u5230\u4E86\u8FD9\u4E2A\u95EE\u9898\uFF0C\u6211\u7528\
          git clone\u4E86modelscope\u4E0A\u7684\u6A21\u578B\u5C31\u53EF\u4EE5\u4E86\
          \uFF0C\u4F46\u662F\u5728\u9047\u5230\u8FD9\u4E2A\u95EE\u9898\u4E4B\u524D\
          \uFF0C\u6A21\u578B\u80FD\u5DE5\u4F5C\u7684\u65F6\u5019\uFF0C\u8FD8\u662F\
          \u80FD\u6B63\u5E38\u8BC6\u522B\u7684\uFF0C\u5F53\u6211\u7528git clone\u6765\
          \u83B7\u5F97\u6A21\u578B\u4E4B\u540E\uFF0C\u6548\u679C\u5C31\u4E0D\u884C\
          \u4E86\uFF0C\u8F93\u51FA\u7684\u8BC6\u522B\u7ED3\u679C\u5C31\u5F88\u4E71\
          \u4E86"
        updatedAt: '2023-12-07T06:18:56.796Z'
      numEdits: 0
      reactions: []
    id: 657163d010d0841de2f5b2d8
    type: comment
  author: ahban
  content: "\u6211\u4E5F\u9047\u5230\u4E86\u8FD9\u4E2A\u95EE\u9898\uFF0C\u6211\u7528\
    git clone\u4E86modelscope\u4E0A\u7684\u6A21\u578B\u5C31\u53EF\u4EE5\u4E86\uFF0C\
    \u4F46\u662F\u5728\u9047\u5230\u8FD9\u4E2A\u95EE\u9898\u4E4B\u524D\uFF0C\u6A21\
    \u578B\u80FD\u5DE5\u4F5C\u7684\u65F6\u5019\uFF0C\u8FD8\u662F\u80FD\u6B63\u5E38\
    \u8BC6\u522B\u7684\uFF0C\u5F53\u6211\u7528git clone\u6765\u83B7\u5F97\u6A21\u578B\
    \u4E4B\u540E\uFF0C\u6548\u679C\u5C31\u4E0D\u884C\u4E86\uFF0C\u8F93\u51FA\u7684\
    \u8BC6\u522B\u7ED3\u679C\u5C31\u5F88\u4E71\u4E86"
  created_at: 2023-12-07 06:18:56+00:00
  edited: false
  hidden: false
  id: 657163d010d0841de2f5b2d8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Qwen/Qwen-Audio
repo_type: model
status: open
target_branch: null
title: "\u51FA\u9519\u4E86"
