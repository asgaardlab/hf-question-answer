!!python/object:huggingface_hub.community.DiscussionWithDetails
author: shreyans92dhankhar
conflicting_files: null
created_at: 2023-06-30 07:37:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614182655977-noauth.jpeg?w=200&h=200&f=face
      fullname: Shreyans Dhankhar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shreyans92dhankhar
      type: user
    createdAt: '2023-06-30T08:37:07.000Z'
    data:
      edited: false
      editors:
      - shreyans92dhankhar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9496565461158752
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614182655977-noauth.jpeg?w=200&h=200&f=face
          fullname: Shreyans Dhankhar
          isHf: false
          isPro: false
          name: shreyans92dhankhar
          type: user
        html: '<p>Loading the tokenizer is very slow, any idea why?</p>

          '
        raw: Loading the tokenizer is very slow, any idea why?
        updatedAt: '2023-06-30T08:37:07.487Z'
      numEdits: 0
      reactions: []
    id: 649e94333914db6cf8f1392d
    type: comment
  author: shreyans92dhankhar
  content: Loading the tokenizer is very slow, any idea why?
  created_at: 2023-06-30 07:37:07+00:00
  edited: false
  hidden: false
  id: 649e94333914db6cf8f1392d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-06-30T19:54:52.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9784864783287048
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>Don''t know</p>

          '
        raw: Don't know
        updatedAt: '2023-06-30T19:54:52.481Z'
      numEdits: 0
      reactions: []
    id: 649f330c53158a71804eebcb
    type: comment
  author: teknium
  content: Don't know
  created_at: 2023-06-30 18:54:52+00:00
  edited: false
  hidden: false
  id: 649f330c53158a71804eebcb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/843312997808971e9a3a871781b71ec7.svg
      fullname: Ambesh Shekhar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ambesh
      type: user
    createdAt: '2023-07-14T04:56:11.000Z'
    data:
      edited: false
      editors:
      - Ambesh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5126391649246216
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/843312997808971e9a3a871781b71ec7.svg
          fullname: Ambesh Shekhar
          isHf: false
          isPro: false
          name: Ambesh
          type: user
        html: '<p>Instead of using AutoTokenizer use LlamaTokenizer, it will load
          it fast</p>

          '
        raw: Instead of using AutoTokenizer use LlamaTokenizer, it will load it fast
        updatedAt: '2023-07-14T04:56:11.699Z'
      numEdits: 0
      reactions: []
    id: 64b0d56bf2809c52ed26fc4a
    type: comment
  author: Ambesh
  content: Instead of using AutoTokenizer use LlamaTokenizer, it will load it fast
  created_at: 2023-07-14 03:56:11+00:00
  edited: false
  hidden: false
  id: 64b0d56bf2809c52ed26fc4a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: NousResearch/Nous-Hermes-13b
repo_type: model
status: open
target_branch: null
title: Why loading tokenizer is very slow?
