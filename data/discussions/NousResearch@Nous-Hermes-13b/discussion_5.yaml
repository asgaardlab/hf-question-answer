!!python/object:huggingface_hub.community.DiscussionWithDetails
author: boqsc
conflicting_files: null
created_at: 2023-06-06 04:59:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
      fullname: boqsc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boqsc
      type: user
    createdAt: '2023-06-06T05:59:02.000Z'
    data:
      edited: true
      editors:
      - boqsc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.780475914478302
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
          fullname: boqsc
          isHf: false
          isPro: false
          name: boqsc
          type: user
        html: '<p>It wasn''t too long before I sensed that something is very wrong
          once you keep on having conversation with Nous Hermes.<br>Nous Hermes might
          produce everything faster and in richer way in on the first and second response
          than <code>GPT4-x-Vicuna-13b-4bit</code>,<br>However once the exchange of
          conversation between Nous Hermes gets past a  few messages - the Nous Hermes
          completely forgets things and responds as if having no awareness of its
          previous content.</p>

          <p><code>GPT4-x-Vicuna-13b-4bit</code> does not seem to have such problem
          and its responses feel better.</p>

          <p>Prompt Template used while testing both Nous Hermes and GPT4-x-Vicuna-13b-4bit  :</p>

          <pre><code>### Instruction:

          %1

          ### Response:

          </code></pre>

          <p>Settings while testing: can be any. But I here include Settings image.<br><strong>Note:</strong>
          <code>Save chats to disk</code> option in GPT4ALL App <code>Application</code>tab
          is irrelevant here and have been tested to not have any effect on how models
          perform.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/Qkw2AJ2z5pQ-9jUTrUOJN.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/Qkw2AJ2z5pQ-9jUTrUOJN.png"></a></p>

          <p>The actual test for the problem, should be reproducable every time:</p>

          <h3 id="nous-hermes-losses-memory">Nous Hermes Losses memory</h3>

          <p>Currently I feel like I''ve tried and tested more than enough of variety
          to conclude that in my use cases Nous Hermes Losses memory after a few responses.<br>(Besides
          giving the first two responses rich in detail and performant)</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/QK34C8AZz0MBFzQ9OQora.png"><img
          alt="Screenshot (525).png" src="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/QK34C8AZz0MBFzQ9OQora.png"></a></p>

          <h3 id="gpt4-x-vicuna-13b-4bit-continues-to-behave-and-acts-very-well">GPT4-x-Vicuna-13b-4bit
          continues to behave and acts very well.</h3>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/9zFoZpDNgTizxYQzr1u9t.png"><img
          alt="Screenshot (524).png" src="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/9zFoZpDNgTizxYQzr1u9t.png"></a></p>

          '
        raw: "It wasn't too long before I sensed that something is very wrong once\
          \ you keep on having conversation with Nous Hermes.\nNous Hermes might produce\
          \ everything faster and in richer way in on the first and second response\
          \ than `GPT4-x-Vicuna-13b-4bit`,\nHowever once the exchange of conversation\
          \ between Nous Hermes gets past a  few messages - the Nous Hermes completely\
          \ forgets things and responds as if having no awareness of its previous\
          \ content.\n\n`GPT4-x-Vicuna-13b-4bit` does not seem to have such problem\
          \ and its responses feel better.\n\nPrompt Template used while testing both\
          \ Nous Hermes and GPT4-x-Vicuna-13b-4bit  :\n```\n### Instruction:\n%1\n\
          ### Response:\n```\n\nSettings while testing: can be any. But I here include\
          \ Settings image.  \n**Note:** `Save chats to disk` option in GPT4ALL App\
          \ `Application`tab is irrelevant here and have been tested to not have any\
          \ effect on how models perform.\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/Qkw2AJ2z5pQ-9jUTrUOJN.png)\n\
          \n\nThe actual test for the problem, should be reproducable every time:\n\
          ### Nous Hermes Losses memory\nCurrently I feel like I've tried and tested\
          \ more than enough of variety to conclude that in my use cases Nous Hermes\
          \ Losses memory after a few responses.   \n(Besides giving the first two\
          \ responses rich in detail and performant)\n\n![Screenshot (525).png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/QK34C8AZz0MBFzQ9OQora.png)\n\
          \n### GPT4-x-Vicuna-13b-4bit continues to behave and acts very well.\n![Screenshot\
          \ (524).png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/9zFoZpDNgTizxYQzr1u9t.png)"
        updatedAt: '2023-06-06T06:17:06.687Z'
      numEdits: 9
      reactions: []
    id: 647ecb26cfca67bc50007c3d
    type: comment
  author: boqsc
  content: "It wasn't too long before I sensed that something is very wrong once you\
    \ keep on having conversation with Nous Hermes.\nNous Hermes might produce everything\
    \ faster and in richer way in on the first and second response than `GPT4-x-Vicuna-13b-4bit`,\n\
    However once the exchange of conversation between Nous Hermes gets past a  few\
    \ messages - the Nous Hermes completely forgets things and responds as if having\
    \ no awareness of its previous content.\n\n`GPT4-x-Vicuna-13b-4bit` does not seem\
    \ to have such problem and its responses feel better.\n\nPrompt Template used\
    \ while testing both Nous Hermes and GPT4-x-Vicuna-13b-4bit  :\n```\n### Instruction:\n\
    %1\n### Response:\n```\n\nSettings while testing: can be any. But I here include\
    \ Settings image.  \n**Note:** `Save chats to disk` option in GPT4ALL App `Application`tab\
    \ is irrelevant here and have been tested to not have any effect on how models\
    \ perform.\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/Qkw2AJ2z5pQ-9jUTrUOJN.png)\n\
    \n\nThe actual test for the problem, should be reproducable every time:\n### Nous\
    \ Hermes Losses memory\nCurrently I feel like I've tried and tested more than\
    \ enough of variety to conclude that in my use cases Nous Hermes Losses memory\
    \ after a few responses.   \n(Besides giving the first two responses rich in detail\
    \ and performant)\n\n![Screenshot (525).png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/QK34C8AZz0MBFzQ9OQora.png)\n\
    \n### GPT4-x-Vicuna-13b-4bit continues to behave and acts very well.\n![Screenshot\
    \ (524).png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/9zFoZpDNgTizxYQzr1u9t.png)"
  created_at: 2023-06-06 04:59:02+00:00
  edited: true
  hidden: false
  id: 647ecb26cfca67bc50007c3d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-06-06T06:23:07.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8567322492599487
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<blockquote>

          <p>It wasn''t too long before I sensed that something is very wrong once
          you keep on having conversation with Nous Hermes.<br>Nous Hermes might produce
          everything faster and in richer way in on the first and second response
          than <code>GPT4-x-Vicuna-13b-4bit</code>,<br>However once the exchange of
          conversation between Nous Hermes gets past a  few messages - the Nous Hermes
          completely forgets things and responds as if having no awareness of its
          previous content.</p>

          <p><code>GPT4-x-Vicuna-13b-4bit</code> does not seem to have such problem
          and its responses feel better.</p>

          <p>Prompt Template used while testing both Nous Hermes and GPT4-x-Vicuna-13b-4bit  :</p>

          <pre><code>### Instruction:

          %1

          ### Response:

          </code></pre>

          <p>Settings while testing: can be any. But I here include Settings image.<br><strong>Note:</strong>
          <code>Save chats to disk</code> option in GPT4ALL App <code>Application</code>tab
          is irrelevant here and have been tested to not have any effect on how models
          perform.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/Qkw2AJ2z5pQ-9jUTrUOJN.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/Qkw2AJ2z5pQ-9jUTrUOJN.png"></a></p>

          <p>The actual test for the problem, should be reproducable every time:</p>

          <h3 id="nous-hermes-losses-memory">Nous Hermes Losses memory</h3>

          <p>Currently I feel like I''ve tried and tested more than enough of variety
          to conclude that in my use cases Nous Hermes Losses memory after a few responses.<br>(Besides
          giving the first two responses rich in detail and performant)</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/QK34C8AZz0MBFzQ9OQora.png"><img
          alt="Screenshot (525).png" src="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/QK34C8AZz0MBFzQ9OQora.png"></a></p>

          <h3 id="gpt4-x-vicuna-13b-4bit-continues-to-behave-and-acts-very-well">GPT4-x-Vicuna-13b-4bit
          continues to behave and acts very well.</h3>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/9zFoZpDNgTizxYQzr1u9t.png"><img
          alt="Screenshot (524).png" src="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/9zFoZpDNgTizxYQzr1u9t.png"></a></p>

          </blockquote>

          <p>I dont know what is going on behind the scenes with your ux. Like I said
          in another post, for me with my discord roleplaying bots, I line up all
          past prompts and responses as &lt;user''sname&gt;  conversation inside the
          instruction field. I dont know how the instructions get collected in this
          UX to know what you would need to do</p>

          '
        raw: "> It wasn't too long before I sensed that something is very wrong once\
          \ you keep on having conversation with Nous Hermes.\n> Nous Hermes might\
          \ produce everything faster and in richer way in on the first and second\
          \ response than `GPT4-x-Vicuna-13b-4bit`,\n> However once the exchange of\
          \ conversation between Nous Hermes gets past a  few messages - the Nous\
          \ Hermes completely forgets things and responds as if having no awareness\
          \ of its previous content.\n> \n> `GPT4-x-Vicuna-13b-4bit` does not seem\
          \ to have such problem and its responses feel better.\n> \n> Prompt Template\
          \ used while testing both Nous Hermes and GPT4-x-Vicuna-13b-4bit  :\n> ```\n\
          > ### Instruction:\n> %1\n> ### Response:\n> ```\n> \n> Settings while testing:\
          \ can be any. But I here include Settings image.  \n> **Note:** `Save chats\
          \ to disk` option in GPT4ALL App `Application`tab is irrelevant here and\
          \ have been tested to not have any effect on how models perform.\n> \n>\
          \ ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/Qkw2AJ2z5pQ-9jUTrUOJN.png)\n\
          > \n> \n> The actual test for the problem, should be reproducable every\
          \ time:\n> ### Nous Hermes Losses memory\n> Currently I feel like I've tried\
          \ and tested more than enough of variety to conclude that in my use cases\
          \ Nous Hermes Losses memory after a few responses.   \n> (Besides giving\
          \ the first two responses rich in detail and performant)\n> \n> ![Screenshot\
          \ (525).png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/QK34C8AZz0MBFzQ9OQora.png)\n\
          > \n> ### GPT4-x-Vicuna-13b-4bit continues to behave and acts very well.\n\
          > ![Screenshot (524).png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/9zFoZpDNgTizxYQzr1u9t.png)\n\
          \nI dont know what is going on behind the scenes with your ux. Like I said\
          \ in another post, for me with my discord roleplaying bots, I line up all\
          \ past prompts and responses as <user'sname> <botsname> conversation inside\
          \ the instruction field. I dont know how the instructions get collected\
          \ in this UX to know what you would need to do"
        updatedAt: '2023-06-06T06:23:07.699Z'
      numEdits: 0
      reactions: []
    id: 647ed0cb1a446a624a324c6d
    type: comment
  author: teknium
  content: "> It wasn't too long before I sensed that something is very wrong once\
    \ you keep on having conversation with Nous Hermes.\n> Nous Hermes might produce\
    \ everything faster and in richer way in on the first and second response than\
    \ `GPT4-x-Vicuna-13b-4bit`,\n> However once the exchange of conversation between\
    \ Nous Hermes gets past a  few messages - the Nous Hermes completely forgets things\
    \ and responds as if having no awareness of its previous content.\n> \n> `GPT4-x-Vicuna-13b-4bit`\
    \ does not seem to have such problem and its responses feel better.\n> \n> Prompt\
    \ Template used while testing both Nous Hermes and GPT4-x-Vicuna-13b-4bit  :\n\
    > ```\n> ### Instruction:\n> %1\n> ### Response:\n> ```\n> \n> Settings while\
    \ testing: can be any. But I here include Settings image.  \n> **Note:** `Save\
    \ chats to disk` option in GPT4ALL App `Application`tab is irrelevant here and\
    \ have been tested to not have any effect on how models perform.\n> \n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/Qkw2AJ2z5pQ-9jUTrUOJN.png)\n\
    > \n> \n> The actual test for the problem, should be reproducable every time:\n\
    > ### Nous Hermes Losses memory\n> Currently I feel like I've tried and tested\
    \ more than enough of variety to conclude that in my use cases Nous Hermes Losses\
    \ memory after a few responses.   \n> (Besides giving the first two responses\
    \ rich in detail and performant)\n> \n> ![Screenshot (525).png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/QK34C8AZz0MBFzQ9OQora.png)\n\
    > \n> ### GPT4-x-Vicuna-13b-4bit continues to behave and acts very well.\n> ![Screenshot\
    \ (524).png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/9zFoZpDNgTizxYQzr1u9t.png)\n\
    \nI dont know what is going on behind the scenes with your ux. Like I said in\
    \ another post, for me with my discord roleplaying bots, I line up all past prompts\
    \ and responses as <user'sname> <botsname> conversation inside the instruction\
    \ field. I dont know how the instructions get collected in this UX to know what\
    \ you would need to do"
  created_at: 2023-06-06 05:23:07+00:00
  edited: false
  hidden: false
  id: 647ed0cb1a446a624a324c6d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-06-06T06:24:15.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8521808981895447
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>If its simply adding together each string:</p>

          <pre><code>### Instruction:

          You are an elf

          ### Response:

          &lt;some response&gt;

          ### Instruction:

          Understood

          ### Response:

          &lt;some response&gt;

          </code></pre>

          <p>like this, it is not something I have tested.</p>

          '
        raw: "If its simply adding together each string:\n```  \n### Instruction:\n\
          You are an elf\n### Response:\n<some response>\n### Instruction:\nUnderstood\n\
          ### Response:\n<some response>\n```  \nlike this, it is not something I\
          \ have tested."
        updatedAt: '2023-06-06T06:24:15.269Z'
      numEdits: 0
      reactions: []
    id: 647ed10f1a446a624a325723
    type: comment
  author: teknium
  content: "If its simply adding together each string:\n```  \n### Instruction:\n\
    You are an elf\n### Response:\n<some response>\n### Instruction:\nUnderstood\n\
    ### Response:\n<some response>\n```  \nlike this, it is not something I have tested."
  created_at: 2023-06-06 05:24:15+00:00
  edited: false
  hidden: false
  id: 647ed10f1a446a624a325723
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
      fullname: boqsc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boqsc
      type: user
    createdAt: '2023-06-06T06:35:32.000Z'
    data:
      edited: false
      editors:
      - boqsc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8926063776016235
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
          fullname: boqsc
          isHf: false
          isPro: false
          name: boqsc
          type: user
        html: '<blockquote>

          <p>If its simply adding together each string:</p>

          <pre><code>### Instruction:

          You are an elf

          ### Response:

          &lt;some response&gt;

          ### Instruction:

          Understood

          ### Response:

          &lt;some response&gt;

          </code></pre>

          <p>like this, it is not something I have tested.</p>

          </blockquote>

          <p>It would be great if you could confirm if it is reproducable in your
          environment and settings.</p>

          '
        raw: "> If its simply adding together each string:\n> ```  \n> ### Instruction:\n\
          > You are an elf\n> ### Response:\n> <some response>\n> ### Instruction:\n\
          > Understood\n> ### Response:\n> <some response>\n> ```  \n> like this,\
          \ it is not something I have tested.\n\nIt would be great if you could confirm\
          \ if it is reproducable in your environment and settings."
        updatedAt: '2023-06-06T06:35:32.770Z'
      numEdits: 0
      reactions: []
    id: 647ed3b49c3102445793d898
    type: comment
  author: boqsc
  content: "> If its simply adding together each string:\n> ```  \n> ### Instruction:\n\
    > You are an elf\n> ### Response:\n> <some response>\n> ### Instruction:\n> Understood\n\
    > ### Response:\n> <some response>\n> ```  \n> like this, it is not something\
    \ I have tested.\n\nIt would be great if you could confirm if it is reproducable\
    \ in your environment and settings."
  created_at: 2023-06-06 05:35:32+00:00
  edited: false
  hidden: false
  id: 647ed3b49c3102445793d898
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-06-06T06:56:53.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7689564228057861
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<blockquote>

          <blockquote>

          <p>If its simply adding together each string:</p>

          <pre><code>### Instruction:

          You are an elf

          ### Response:

          &lt;some response&gt;

          ### Instruction:

          Understood

          ### Response:

          &lt;some response&gt;

          </code></pre>

          <p>like this, it is not something I have tested.</p>

          </blockquote>

          <p>It would be great if you could confirm if it is reproducable in your
          environment and settings.</p>

          </blockquote>

          <p>I don''t use gpt4all, I use gptq for gpu inference, and a discord bot
          for the ux.<br>My discord bot keeps a constant preprompt for roleplaying
          task, and a trailing N chat messages for chat history, and produces this
          kind of output:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/Kp94qD73R79cCC7abwVI_.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/Kp94qD73R79cCC7abwVI_.png"></a></p>

          '
        raw: "> > If its simply adding together each string:\n> > ```  \n> > ### Instruction:\n\
          > > You are an elf\n> > ### Response:\n> > <some response>\n> > ### Instruction:\n\
          > > Understood\n> > ### Response:\n> > <some response>\n> > ```  \n> > like\
          \ this, it is not something I have tested.\n> \n> It would be great if you\
          \ could confirm if it is reproducable in your environment and settings.\n\
          \nI don't use gpt4all, I use gptq for gpu inference, and a discord bot for\
          \ the ux. \nMy discord bot keeps a constant preprompt for roleplaying task,\
          \ and a trailing N chat messages for chat history, and produces this kind\
          \ of output:\n\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/Kp94qD73R79cCC7abwVI_.png)"
        updatedAt: '2023-06-06T06:56:53.513Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - nacs
    id: 647ed8b51a446a624a334ee1
    type: comment
  author: teknium
  content: "> > If its simply adding together each string:\n> > ```  \n> > ### Instruction:\n\
    > > You are an elf\n> > ### Response:\n> > <some response>\n> > ### Instruction:\n\
    > > Understood\n> > ### Response:\n> > <some response>\n> > ```  \n> > like this,\
    \ it is not something I have tested.\n> \n> It would be great if you could confirm\
    \ if it is reproducable in your environment and settings.\n\nI don't use gpt4all,\
    \ I use gptq for gpu inference, and a discord bot for the ux. \nMy discord bot\
    \ keeps a constant preprompt for roleplaying task, and a trailing N chat messages\
    \ for chat history, and produces this kind of output:\n\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/Kp94qD73R79cCC7abwVI_.png)"
  created_at: 2023-06-06 05:56:53+00:00
  edited: false
  hidden: false
  id: 647ed8b51a446a624a334ee1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-06-06T06:58:40.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8464224934577942
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>If you can, you should add a preprompt/system prompt like prompt
          giving the AI a roleplay task, that it keeps always at the top of it''s
          context, so no matter what, it will remember who it is.</p>

          '
        raw: If you can, you should add a preprompt/system prompt like prompt giving
          the AI a roleplay task, that it keeps always at the top of it's context,
          so no matter what, it will remember who it is.
        updatedAt: '2023-06-06T06:58:40.297Z'
      numEdits: 0
      reactions: []
    id: 647ed920f41cf810e36d2159
    type: comment
  author: teknium
  content: If you can, you should add a preprompt/system prompt like prompt giving
    the AI a roleplay task, that it keeps always at the top of it's context, so no
    matter what, it will remember who it is.
  created_at: 2023-06-06 05:58:40+00:00
  edited: false
  hidden: false
  id: 647ed920f41cf810e36d2159
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-06-06T07:00:00.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6557326912879944
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>I dont have a discord bot code available for GGML, but this is how
          my inference code looks:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/IPOGyTdAdPDZEiuBwMAbJ.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/IPOGyTdAdPDZEiuBwMAbJ.png"></a></p>

          '
        raw: 'I dont have a discord bot code available for GGML, but this is how my
          inference code looks:


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/IPOGyTdAdPDZEiuBwMAbJ.png)'
        updatedAt: '2023-06-06T07:00:00.555Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - nacs
    id: 647ed9702a7bcaa30794d4eb
    type: comment
  author: teknium
  content: 'I dont have a discord bot code available for GGML, but this is how my
    inference code looks:


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/IPOGyTdAdPDZEiuBwMAbJ.png)'
  created_at: 2023-06-06 06:00:00+00:00
  edited: false
  hidden: false
  id: 647ed9702a7bcaa30794d4eb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-06-06T07:01:02.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9600761532783508
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>and it pulls all those datapoints from a character card, but I don''t
          know if these things are possible to set up in GPT4All interface</p>

          '
        raw: and it pulls all those datapoints from a character card, but I don't
          know if these things are possible to set up in GPT4All interface
        updatedAt: '2023-06-06T07:01:02.912Z'
      numEdits: 0
      reactions: []
    id: 647ed9ae9c310244579491d1
    type: comment
  author: teknium
  content: and it pulls all those datapoints from a character card, but I don't know
    if these things are possible to set up in GPT4All interface
  created_at: 2023-06-06 06:01:02+00:00
  edited: false
  hidden: false
  id: 647ed9ae9c310244579491d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
      fullname: boqsc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boqsc
      type: user
    createdAt: '2023-06-06T17:39:39.000Z'
    data:
      from: Nous Hermes Model consistently loses memory by fourth question ( GPT4-x-Vicuna-13b-4bit
        does not have problems)
      to: 'GPT4ALL: Nous Hermes Model consistently loses memory by fourth question
        ( GPT4-x-Vicuna-13b-4bit does not have problems)'
    id: 647f6f5bf41cf810e382335e
    type: title-change
  author: boqsc
  created_at: 2023-06-06 16:39:39+00:00
  id: 647f6f5bf41cf810e382335e
  new_title: 'GPT4ALL: Nous Hermes Model consistently loses memory by fourth question
    ( GPT4-x-Vicuna-13b-4bit does not have problems)'
  old_title: Nous Hermes Model consistently loses memory by fourth question ( GPT4-x-Vicuna-13b-4bit
    does not have problems)
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
      fullname: boqsc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boqsc
      type: user
    createdAt: '2023-06-06T19:26:01.000Z'
    data:
      edited: true
      editors:
      - boqsc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.809646487236023
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
          fullname: boqsc
          isHf: false
          isPro: false
          name: boqsc
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;teknium&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/teknium\">@<span class=\"\
          underline\">teknium</span></a></span>\n\n\t</span></span><br>The answer\
          \ to why this happens and why Nous Hermes behaves like that is maybe that\
          \ Hermes is not a chat model, but an instruct model.<br>If that's true cause,\
          \ I would really like to see a chat oriented model one day. So that it would\
          \ work like  GPT4-x-Vicuna-13b-4bit </p>\n<p><a rel=\"nofollow\" href=\"\
          https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/ImW6KRJAmi6Egr6ijQ1OP.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/ImW6KRJAmi6Egr6ijQ1OP.png\"\
          ></a> <a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/dL7luy4vMxbpf_GJNdf_W.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/dL7luy4vMxbpf_GJNdf_W.png\"\
          ></a> <a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/Utpp7LtnaXxw2e53f0ktI.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/Utpp7LtnaXxw2e53f0ktI.png\"\
          ></a></p>\n"
        raw: "@teknium \nThe answer to why this happens and why Nous Hermes behaves\
          \ like that is maybe that Hermes is not a chat model, but an instruct model.\
          \   \nIf that's true cause, I would really like to see a chat oriented model\
          \ one day. So that it would work like  GPT4-x-Vicuna-13b-4bit \n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/ImW6KRJAmi6Egr6ijQ1OP.png)\
          \ ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/dL7luy4vMxbpf_GJNdf_W.png)\
          \ ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/Utpp7LtnaXxw2e53f0ktI.png)"
        updatedAt: '2023-06-06T19:38:22.189Z'
      numEdits: 2
      reactions: []
    id: 647f88492a7bcaa307abe72a
    type: comment
  author: boqsc
  content: "@teknium \nThe answer to why this happens and why Nous Hermes behaves\
    \ like that is maybe that Hermes is not a chat model, but an instruct model. \
    \  \nIf that's true cause, I would really like to see a chat oriented model one\
    \ day. So that it would work like  GPT4-x-Vicuna-13b-4bit \n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/ImW6KRJAmi6Egr6ijQ1OP.png)\
    \ ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/dL7luy4vMxbpf_GJNdf_W.png)\
    \ ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/Utpp7LtnaXxw2e53f0ktI.png)"
  created_at: 2023-06-06 18:26:01+00:00
  edited: true
  hidden: false
  id: 647f88492a7bcaa307abe72a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/84c6e02bb51094e3df43ba5b2b857d50.svg
      fullname: Ray Vive
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rayyd
      type: user
    createdAt: '2023-06-07T08:24:01.000Z'
    data:
      edited: false
      editors:
      - rayyd
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9066516757011414
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/84c6e02bb51094e3df43ba5b2b857d50.svg
          fullname: Ray Vive
          isHf: false
          isPro: false
          name: rayyd
          type: user
        html: '<p>Oh, this explains why I cant ask any follow up questions. The one
          shot abilities are impressive though!</p>

          '
        raw: Oh, this explains why I cant ask any follow up questions. The one shot
          abilities are impressive though!
        updatedAt: '2023-06-07T08:24:01.599Z'
      numEdits: 0
      reactions: []
    id: 64803ea14df56f78b3afbf2c
    type: comment
  author: rayyd
  content: Oh, this explains why I cant ask any follow up questions. The one shot
    abilities are impressive though!
  created_at: 2023-06-07 07:24:01+00:00
  edited: false
  hidden: false
  id: 64803ea14df56f78b3afbf2c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-06-07T09:29:52.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9241238832473755
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<blockquote>

          <p>Oh, this explains why I cant ask any follow up questions. The one shot
          abilities are impressive though!</p>

          </blockquote>

          <p>Please see how I setup the prompt format, it can hold a conversation.
          I will work on a new format for the next version to try to improve this
          capability though. As well as some more experimental workarounds</p>

          '
        raw: '> Oh, this explains why I cant ask any follow up questions. The one
          shot abilities are impressive though!


          Please see how I setup the prompt format, it can hold a conversation. I
          will work on a new format for the next version to try to improve this capability
          though. As well as some more experimental workarounds'
        updatedAt: '2023-06-07T09:29:52.773Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - nacs
    id: 64804e1040facadc55692640
    type: comment
  author: teknium
  content: '> Oh, this explains why I cant ask any follow up questions. The one shot
    abilities are impressive though!


    Please see how I setup the prompt format, it can hold a conversation. I will work
    on a new format for the next version to try to improve this capability though.
    As well as some more experimental workarounds'
  created_at: 2023-06-07 08:29:52+00:00
  edited: false
  hidden: false
  id: 64804e1040facadc55692640
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62fc06a221c444a56f7cc595/Ln3m7sK52hwGuMnPe4mfU.jpeg?w=200&h=200&f=face
      fullname: karan4d
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: karan4d
      type: user
    createdAt: '2023-06-07T17:21:00.000Z'
    data:
      edited: false
      editors:
      - karan4d
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9190876483917236
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62fc06a221c444a56f7cc595/Ln3m7sK52hwGuMnPe4mfU.jpeg?w=200&h=200&f=face
          fullname: karan4d
          isHf: false
          isPro: false
          name: karan4d
          type: user
        html: '<p>It can hold conversation, the format is just different.</p>

          <p>Multiple data types will be supported in the future so we can have the
          model retain both "instruct" and "chat" capabilities like our previous release.</p>

          '
        raw: 'It can hold conversation, the format is just different.


          Multiple data types will be supported in the future so we can have the model
          retain both "instruct" and "chat" capabilities like our previous release.'
        updatedAt: '2023-06-07T17:21:00.580Z'
      numEdits: 0
      reactions: []
    id: 6480bc7ce1421e205fdc2347
    type: comment
  author: karan4d
  content: 'It can hold conversation, the format is just different.


    Multiple data types will be supported in the future so we can have the model retain
    both "instruct" and "chat" capabilities like our previous release.'
  created_at: 2023-06-07 16:21:00+00:00
  edited: false
  hidden: false
  id: 6480bc7ce1421e205fdc2347
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62fc06a221c444a56f7cc595/Ln3m7sK52hwGuMnPe4mfU.jpeg?w=200&h=200&f=face
      fullname: karan4d
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: karan4d
      type: user
    createdAt: '2023-06-15T13:19:02.000Z'
    data:
      status: closed
    id: 648b0fc6f868ab7f2d1a6d90
    type: status-change
  author: karan4d
  created_at: 2023-06-15 12:19:02+00:00
  id: 648b0fc6f868ab7f2d1a6d90
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
      fullname: boqsc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boqsc
      type: user
    createdAt: '2023-06-18T10:49:16.000Z'
    data:
      edited: false
      editors:
      - boqsc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8809544444084167
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
          fullname: boqsc
          isHf: false
          isPro: false
          name: boqsc
          type: user
        html: '<p>Not sure about all that, but there is chronos-hermes merge that
          works like Nous-gpt4-x-vicuna.<br>However it is limited and maybe even censored
          by chronos model and is not the same as pure hermes.<br><a href="https://huggingface.co/TheBloke/chronos-hermes-13B-GGML">https://huggingface.co/TheBloke/chronos-hermes-13B-GGML</a><br><a
          rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/CjBx8FHAUznDxwsov9hal.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/CjBx8FHAUznDxwsov9hal.png"></a></p>

          '
        raw: "Not sure about all that, but there is chronos-hermes merge that works\
          \ like Nous-gpt4-x-vicuna. \nHowever it is limited and maybe even censored\
          \ by chronos model and is not the same as pure hermes.\nhttps://huggingface.co/TheBloke/chronos-hermes-13B-GGML\n\
          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/CjBx8FHAUznDxwsov9hal.png)\n"
        updatedAt: '2023-06-18T10:49:16.584Z'
      numEdits: 0
      reactions: []
      relatedEventId: 648ee12c92ea76a2d02f9d67
    id: 648ee12c92ea76a2d02f9d65
    type: comment
  author: boqsc
  content: "Not sure about all that, but there is chronos-hermes merge that works\
    \ like Nous-gpt4-x-vicuna. \nHowever it is limited and maybe even censored by\
    \ chronos model and is not the same as pure hermes.\nhttps://huggingface.co/TheBloke/chronos-hermes-13B-GGML\n\
    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/CjBx8FHAUznDxwsov9hal.png)\n"
  created_at: 2023-06-18 09:49:16+00:00
  edited: false
  hidden: false
  id: 648ee12c92ea76a2d02f9d65
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
      fullname: boqsc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boqsc
      type: user
    createdAt: '2023-06-18T10:49:16.000Z'
    data:
      status: open
    id: 648ee12c92ea76a2d02f9d67
    type: status-change
  author: boqsc
  created_at: 2023-06-18 09:49:16+00:00
  id: 648ee12c92ea76a2d02f9d67
  new_status: open
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: NousResearch/Nous-Hermes-13b
repo_type: model
status: open
target_branch: null
title: 'GPT4ALL: Nous Hermes Model consistently loses memory by fourth question (
  GPT4-x-Vicuna-13b-4bit does not have problems)'
