!!python/object:huggingface_hub.community.DiscussionWithDetails
author: thirdHand
conflicting_files: null
created_at: 2023-07-02 10:32:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/651ce2faa8e3930889dbc45aae1a33f7.svg
      fullname: thirdHand
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thirdHand
      type: user
    createdAt: '2023-07-02T11:32:56.000Z'
    data:
      edited: false
      editors:
      - thirdHand
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.36527666449546814
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/651ce2faa8e3930889dbc45aae1a33f7.svg
          fullname: thirdHand
          isHf: false
          isPro: false
          name: thirdHand
          type: user
        html: '<pre><code>decode = self.tokenizer.batch_decode(response_tensors, skip_special_tokens=True)

          </code></pre>

          <p>lib/python3.9/site-packages/transformers/tokenization_utils_base.py",
          line 3469, in batch_decode<br>    return [<br>python3.9/site-packages/transformers/tokenization_utils_base.py",
          line 3470, in <br>    self.decode(<br>python3.9/site-packages/transformers/tokenization_utils_base.py",
          line 3509, in decode<br>    return self._decode(<br>python3.9/site-packages/transformers/tokenization_utils.py",
          line 931, in _decode<br>    filtered_tokens = self.convert_ids_to_tokens(token_ids,
          skip_special_tokens=skip_special_tokens)<br>python3.9/site-packages/transformers/tokenization_utils.py",
          line 912, in convert_ids_to_tokens<br>    tokens.append(self._convert_id_to_token(index))<br>  File
          "/home/.cache/huggingface/modules/transformers_modules/chatglm2-6b/tokenization_chatglm.py",
          line 121, in _convert_id_to_token<br>    return self.tokenizer.convert_id_to_token(index)<br>  File
          "/home/.cache/huggingface/modules/transformers_modules/chatglm2-6b/tokenization_chatglm.py",
          line 60, in convert_id_to_token<br>    return self.sp_model.IdToPiece(index)<br>  File
          "/python3.9/site-packages/sentencepiece/<strong>init</strong>.py", line
          1045, in _batched_func<br>    return _func(self, arg)<br>  File "/python3.9/site-packages/sentencepiece/<strong>init</strong>.py",
          line 1038, in _func<br>    raise IndexError(''piece id is out of range.'')<br>IndexError:
          piece id is out of range.</p>

          '
        raw: "    decode = self.tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\r\
          \nlib/python3.9/site-packages/transformers/tokenization_utils_base.py\"\
          , line 3469, in batch_decode\r\n    return [\r\npython3.9/site-packages/transformers/tokenization_utils_base.py\"\
          , line 3470, in <listcomp>\r\n    self.decode(\r\npython3.9/site-packages/transformers/tokenization_utils_base.py\"\
          , line 3509, in decode\r\n    return self._decode(\r\npython3.9/site-packages/transformers/tokenization_utils.py\"\
          , line 931, in _decode\r\n    filtered_tokens = self.convert_ids_to_tokens(token_ids,\
          \ skip_special_tokens=skip_special_tokens)\r\npython3.9/site-packages/transformers/tokenization_utils.py\"\
          , line 912, in convert_ids_to_tokens\r\n    tokens.append(self._convert_id_to_token(index))\r\
          \n  File \"/home/.cache/huggingface/modules/transformers_modules/chatglm2-6b/tokenization_chatglm.py\"\
          , line 121, in _convert_id_to_token\r\n    return self.tokenizer.convert_id_to_token(index)\r\
          \n  File \"/home/.cache/huggingface/modules/transformers_modules/chatglm2-6b/tokenization_chatglm.py\"\
          , line 60, in convert_id_to_token\r\n    return self.sp_model.IdToPiece(index)\r\
          \n  File \"/python3.9/site-packages/sentencepiece/__init__.py\", line 1045,\
          \ in _batched_func\r\n    return _func(self, arg)\r\n  File \"/python3.9/site-packages/sentencepiece/__init__.py\"\
          , line 1038, in _func\r\n    raise IndexError('piece id is out of range.')\r\
          \nIndexError: piece id is out of range."
        updatedAt: '2023-07-02T11:32:56.964Z'
      numEdits: 0
      reactions: []
    id: 64a160688148bf0c82a3b4b1
    type: comment
  author: thirdHand
  content: "    decode = self.tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\r\
    \nlib/python3.9/site-packages/transformers/tokenization_utils_base.py\", line\
    \ 3469, in batch_decode\r\n    return [\r\npython3.9/site-packages/transformers/tokenization_utils_base.py\"\
    , line 3470, in <listcomp>\r\n    self.decode(\r\npython3.9/site-packages/transformers/tokenization_utils_base.py\"\
    , line 3509, in decode\r\n    return self._decode(\r\npython3.9/site-packages/transformers/tokenization_utils.py\"\
    , line 931, in _decode\r\n    filtered_tokens = self.convert_ids_to_tokens(token_ids,\
    \ skip_special_tokens=skip_special_tokens)\r\npython3.9/site-packages/transformers/tokenization_utils.py\"\
    , line 912, in convert_ids_to_tokens\r\n    tokens.append(self._convert_id_to_token(index))\r\
    \n  File \"/home/.cache/huggingface/modules/transformers_modules/chatglm2-6b/tokenization_chatglm.py\"\
    , line 121, in _convert_id_to_token\r\n    return self.tokenizer.convert_id_to_token(index)\r\
    \n  File \"/home/.cache/huggingface/modules/transformers_modules/chatglm2-6b/tokenization_chatglm.py\"\
    , line 60, in convert_id_to_token\r\n    return self.sp_model.IdToPiece(index)\r\
    \n  File \"/python3.9/site-packages/sentencepiece/__init__.py\", line 1045, in\
    \ _batched_func\r\n    return _func(self, arg)\r\n  File \"/python3.9/site-packages/sentencepiece/__init__.py\"\
    , line 1038, in _func\r\n    raise IndexError('piece id is out of range.')\r\n\
    IndexError: piece id is out of range."
  created_at: 2023-07-02 10:32:56+00:00
  edited: false
  hidden: false
  id: 64a160688148bf0c82a3b4b1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 32
repo_id: THUDM/chatglm2-6b
repo_type: model
status: open
target_branch: null
title: BatchEncoding error
