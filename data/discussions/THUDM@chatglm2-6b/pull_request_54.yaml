!!python/object:huggingface_hub.community.DiscussionWithDetails
author: yuanzhoulvpi
conflicting_files: []
created_at: 2023-07-17 12:23:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678843753419-6232d58473df4db789c78682.jpeg?w=200&h=200&f=face
      fullname: yuanz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yuanzhoulvpi
      type: user
    createdAt: '2023-07-17T13:23:41.000Z'
    data:
      edited: false
      editors:
      - yuanzhoulvpi
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 1.0000344514846802
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678843753419-6232d58473df4db789c78682.jpeg?w=200&h=200&f=face
          fullname: yuanz
          isHf: false
          isPro: false
          name: yuanzhoulvpi
          type: user
        html: "<p>\u5728\u8FDB\u884C\u6A21\u578B\u5E76\u884C\u7684\u65F6\u5019\uFF0C\
          \u5982\u679C\u4E0D\u52A0\u8FD9\u884C\u7684\u4EE3\u7801\uFF0C\u4F1A\u62A5\
          \u9519\uFF0C\u5EFA\u8BAE\u52A0\u4E0A\u3002</p>\n"
        raw: "\u5728\u8FDB\u884C\u6A21\u578B\u5E76\u884C\u7684\u65F6\u5019\uFF0C\u5982\
          \u679C\u4E0D\u52A0\u8FD9\u884C\u7684\u4EE3\u7801\uFF0C\u4F1A\u62A5\u9519\
          \uFF0C\u5EFA\u8BAE\u52A0\u4E0A\u3002"
        updatedAt: '2023-07-17T13:23:41.882Z'
      numEdits: 0
      reactions: []
    id: 64b540dd25882acb62ff6a6a
    type: comment
  author: yuanzhoulvpi
  content: "\u5728\u8FDB\u884C\u6A21\u578B\u5E76\u884C\u7684\u65F6\u5019\uFF0C\u5982\
    \u679C\u4E0D\u52A0\u8FD9\u884C\u7684\u4EE3\u7801\uFF0C\u4F1A\u62A5\u9519\uFF0C\
    \u5EFA\u8BAE\u52A0\u4E0A\u3002"
  created_at: 2023-07-17 12:23:41+00:00
  edited: false
  hidden: false
  id: 64b540dd25882acb62ff6a6a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678843753419-6232d58473df4db789c78682.jpeg?w=200&h=200&f=face
      fullname: yuanz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yuanzhoulvpi
      type: user
    createdAt: '2023-07-17T13:23:42.000Z'
    data:
      oid: 81c9eae3c2148ac8a4babda2a41ef401faf107c9
      parents:
      - 8eb45c842594b8473f291d0f94e7bbe86ffc67d8
      subject: Update modeling_chatglm.py
    id: 64b540de0000000000000000
    type: commit
  author: yuanzhoulvpi
  created_at: 2023-07-17 12:23:42+00:00
  id: 64b540de0000000000000000
  oid: 81c9eae3c2148ac8a4babda2a41ef401faf107c9
  summary: Update modeling_chatglm.py
  type: commit
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678843753419-6232d58473df4db789c78682.jpeg?w=200&h=200&f=face
      fullname: yuanz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yuanzhoulvpi
      type: user
    createdAt: '2023-07-17T13:24:16.000Z'
    data:
      from: Update modeling_chatglm.py
      to: "\u6A21\u578B\u5E76\u884C\u51FA\u9519"
    id: 64b54100aa03b6520849c426
    type: title-change
  author: yuanzhoulvpi
  created_at: 2023-07-17 12:24:16+00:00
  id: 64b54100aa03b6520849c426
  new_title: "\u6A21\u578B\u5E76\u884C\u51FA\u9519"
  old_title: Update modeling_chatglm.py
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678843753419-6232d58473df4db789c78682.jpeg?w=200&h=200&f=face
      fullname: yuanz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yuanzhoulvpi
      type: user
    createdAt: '2023-07-17T13:24:42.000Z'
    data:
      from: "\u6A21\u578B\u5E76\u884C\u51FA\u9519"
      to: "\u6A21\u578B\u5E76\u884C\u51FA\u9519\u5E76\u7ED9\u51FA\u4FEE\u6539\u65B9\
        \u6848"
    id: 64b5411ad52d67c01c0df88c
    type: title-change
  author: yuanzhoulvpi
  created_at: 2023-07-17 12:24:42+00:00
  id: 64b5411ad52d67c01c0df88c
  new_title: "\u6A21\u578B\u5E76\u884C\u51FA\u9519\u5E76\u7ED9\u51FA\u4FEE\u6539\u65B9\
    \u6848"
  old_title: "\u6A21\u578B\u5E76\u884C\u51FA\u9519"
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678843753419-6232d58473df4db789c78682.jpeg?w=200&h=200&f=face
      fullname: yuanz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yuanzhoulvpi
      type: user
    createdAt: '2023-07-17T13:31:28.000Z'
    data:
      edited: true
      editors:
      - yuanzhoulvpi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2965935468673706
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678843753419-6232d58473df4db789c78682.jpeg?w=200&h=200&f=face
          fullname: yuanz
          isHf: false
          isPro: false
          name: yuanzhoulvpi
          type: user
        html: "<p>\u5728\u4EE3\u7801\u90E8\u5206\uFF1A</p>\n<pre><code class=\"language-python\"\
          >            <span class=\"hljs-comment\"># Shift so that tokens &lt; n\
          \ predict n</span>\n            shift_logits = lm_logits[..., :-<span class=\"\
          hljs-number\">1</span>, :].contiguous()\n            shift_labels = labels[...,\
          \ <span class=\"hljs-number\">1</span>:].contiguous()<span class=\"hljs-comment\"\
          >#.to(shift_logits.device)</span>\n            <span class=\"hljs-comment\"\
          ># Flatten the tokens</span>\n</code></pre>\n<p>\u91C7\u7528\u7684\u8BAD\
          \u7EC3\u65B9\u6848\u662F<a rel=\"nofollow\" href=\"https://github.com/yuanzhoulvpi2017/zero_nlp/tree/main/chatglm_v2_6b_lora\"\
          >https://github.com/yuanzhoulvpi2017/zero_nlp/tree/main/chatglm_v2_6b_lora</a></p>\n\
          <h2 id=\"\u5728\u4E0D\u6DFB\u52A0\u90A3\u4E2A\u4EE3\u7801\uFF0C\u591A\u5361\
          \u8BAD\u7EC3\u4F1A\u62A5\u9519\">\u5728\u4E0D\u6DFB\u52A0\u90A3\u4E2A\u4EE3\
          \u7801\uFF0C\u591A\u5361\u8BAD\u7EC3\u4F1A\u62A5\u9519</h2>\n<p>\u62A5\u9519\
          \u4F4D\u7F6E\uFF1A<code>loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)),\
          \ shift_labels.view(-1))</code></p>\n<pre><code class=\"language-bash\"\
          >\n\n\u53D1\u751F\u5F02\u5E38: RuntimeError\nExpected all tensors to be\
          \ on the same device, but found at least two devices, cuda:1 and cuda:0!\
          \ (when checking argument <span class=\"hljs-keyword\">for</span> argument\
          \ target <span class=\"hljs-keyword\">in</span> method wrapper_CUDA_nll_loss_forward)\n\
          \  File <span class=\"hljs-string\">\"/home/yuanz/.cache/huggingface/modules/transformers_modules/chatglm2-6b_model/modeling_chatglm.py\"\
          </span>, line 958, <span class=\"hljs-keyword\">in</span> forward\n    loss\
          \ = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n\
          \  File <span class=\"hljs-string\">\"/media/yuanz/\u65B0\u52A0\u5377/\u8BAD\
          \u7EC3\u4EE3\u7801/chatglm6b_v2_0716/main.py\"</span>, line 371, <span class=\"\
          hljs-keyword\">in</span> main\n    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n\
          \  File <span class=\"hljs-string\">\"/media/yuanz/\u65B0\u52A0\u5377/\u8BAD\
          \u7EC3\u4EE3\u7801/chatglm6b_v2_0716/main.py\"</span>, line 432, <span class=\"\
          hljs-keyword\">in</span> &lt;module&gt;\n    main()\nRuntimeError: Expected\
          \ all tensors to be on the same device, but found at least two devices,\
          \ cuda:1 and cuda:0! (when checking argument <span class=\"hljs-keyword\"\
          >for</span> argument target <span class=\"hljs-keyword\">in</span> method\
          \ wrapper_CUDA_nll_loss_forward)\n</code></pre>\n<h2 id=\"\u5728\u6DFB\u52A0\
          \u90A3\u4E2A\u4EE3\u7801\u540E\uFF0C\u53EF\u4EE5\u8DD1\u8D77\u6765\">\u5728\
          \u6DFB\u52A0\u90A3\u4E2A\u4EE3\u7801\u540E\uFF0C\u53EF\u4EE5\u8DD1\u8D77\
          \u6765</h2>\n<pre><code class=\"language-bash\">[INFO|trainer.py:1786] 2023-07-17\
          \ 21:18:51,711 &gt;&gt; ***** Running training *****\n[INFO|trainer.py:1787]\
          \ 2023-07-17 21:18:51,711 &gt;&gt;   Num examples = 114,599\n[INFO|trainer.py:1788]\
          \ 2023-07-17 21:18:51,711 &gt;&gt;   Num Epochs = 1\n[INFO|trainer.py:1789]\
          \ 2023-07-17 21:18:51,711 &gt;&gt;   Instantaneous batch size per device\
          \ = 1\n[INFO|trainer.py:1790] 2023-07-17 21:18:51,711 &gt;&gt;   Total train\
          \ batch size (w. parallel, distributed &amp; accumulation) = 16\n[INFO|trainer.py:1791]\
          \ 2023-07-17 21:18:51,711 &gt;&gt;   Gradient Accumulation steps = 16\n\
          [INFO|trainer.py:1792] 2023-07-17 21:18:51,711 &gt;&gt;   Total optimization\
          \ steps = 3,000\n[INFO|trainer.py:1793] 2023-07-17 21:18:51,714 &gt;&gt;\
          \   Number of trainable parameters = 7,798,784\n  0%|                  \
          \                                                                      \
          \                                                                      \
          \               | 0/3000 [00:00&lt;?, ?it/s]07/17/2023 21:18:51 - WARNING\
          \ - transformers_modules.chatglm2-6b_model.modeling_chatglm - `use_cache=True`\
          \ is incompatible with gradient checkpointing. Setting `use_cache=False`...\n\
          {<span class=\"hljs-string\">'loss'</span>: 6.0639, <span class=\"hljs-string\"\
          >'learning_rate'</span>: 1.9933333333333334e-05, <span class=\"hljs-string\"\
          >'epoch'</span>: 0.0}                                                  \
          \                                                                      \
          \            \n{<span class=\"hljs-string\">'loss'</span>: 6.0275, <span\
          \ class=\"hljs-string\">'learning_rate'</span>: 1.9866666666666667e-05,\
          \ <span class=\"hljs-string\">'epoch'</span>: 0.0}                     \
          \                                                                      \
          \                                         \n{<span class=\"hljs-string\"\
          >'loss'</span>: 5.8822, <span class=\"hljs-string\">'learning_rate'</span>:\
          \ 1.98e-05, <span class=\"hljs-string\">'epoch'</span>: 0.0}           \
          \                                                                      \
          \                                                                 \n{<span\
          \ class=\"hljs-string\">'loss'</span>: 5.5463, <span class=\"hljs-string\"\
          >'learning_rate'</span>: 1.9733333333333336e-05, <span class=\"hljs-string\"\
          >'epoch'</span>: 0.01}                                                 \
          \                                                                      \
          \            \n{<span class=\"hljs-string\">'loss'</span>: 5.028, <span\
          \ class=\"hljs-string\">'learning_rate'</span>: 1.9666666666666666e-05,\
          \ <span class=\"hljs-string\">'epoch'</span>: 0.01}                    \
          \                                                                      \
          \                                          \n{<span class=\"hljs-string\"\
          >'loss'</span>: 4.534, <span class=\"hljs-string\">'learning_rate'</span>:\
          \ 1.9600000000000002e-05, <span class=\"hljs-string\">'epoch'</span>: 0.01}\
          \  \n</code></pre>\n<h2 id=\"\u4FEE\u6539\u65B9\u6CD5\">\u4FEE\u6539\u65B9\
          \u6CD5</h2>\n<pre><code class=\"language-python\"><span class=\"hljs-comment\"\
          ># \u5728modeling_chatglm.py\u4EE3\u7801\u7684955\u884C\u5DE6\u53F3</span>\n\
          \            <span class=\"hljs-comment\"># Shift so that tokens &lt; n\
          \ predict n</span>\n            shift_logits = lm_logits[..., :-<span class=\"\
          hljs-number\">1</span>, :].contiguous()\n            shift_labels = labels[...,\
          \ <span class=\"hljs-number\">1</span>:].contiguous().to(shift_logits.device)\
          \ <span class=\"hljs-comment\"># \u5728\u8FD9\u91CC\u6DFB\u52A0\u4E0A\u5373\
          \u53EF</span>\n            <span class=\"hljs-comment\"># Flatten the tokens</span>\n\
          </code></pre>\n"
        raw: "\u5728\u4EE3\u7801\u90E8\u5206\uFF1A\n```python\n            # Shift\
          \ so that tokens < n predict n\n            shift_logits = lm_logits[...,\
          \ :-1, :].contiguous()\n            shift_labels = labels[..., 1:].contiguous()#.to(shift_logits.device)\n\
          \            # Flatten the tokens\n```\n\n\u91C7\u7528\u7684\u8BAD\u7EC3\
          \u65B9\u6848\u662F[https://github.com/yuanzhoulvpi2017/zero_nlp/tree/main/chatglm_v2_6b_lora](https://github.com/yuanzhoulvpi2017/zero_nlp/tree/main/chatglm_v2_6b_lora)\n\
          \n## \u5728\u4E0D\u6DFB\u52A0\u90A3\u4E2A\u4EE3\u7801\uFF0C\u591A\u5361\u8BAD\
          \u7EC3\u4F1A\u62A5\u9519\n\u62A5\u9519\u4F4D\u7F6E\uFF1A`loss = loss_fct(shift_logits.view(-1,\
          \ shift_logits.size(-1)), shift_labels.view(-1))`\n\n\n```bash\n\n\n\u53D1\
          \u751F\u5F02\u5E38: RuntimeError\nExpected all tensors to be on the same\
          \ device, but found at least two devices, cuda:1 and cuda:0! (when checking\
          \ argument for argument target in method wrapper_CUDA_nll_loss_forward)\n\
          \  File \"/home/yuanz/.cache/huggingface/modules/transformers_modules/chatglm2-6b_model/modeling_chatglm.py\"\
          , line 958, in forward\n    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)),\
          \ shift_labels.view(-1))\n  File \"/media/yuanz/\u65B0\u52A0\u5377/\u8BAD\
          \u7EC3\u4EE3\u7801/chatglm6b_v2_0716/main.py\", line 371, in main\n    train_result\
          \ = trainer.train(resume_from_checkpoint=checkpoint)\n  File \"/media/yuanz/\u65B0\
          \u52A0\u5377/\u8BAD\u7EC3\u4EE3\u7801/chatglm6b_v2_0716/main.py\", line\
          \ 432, in <module>\n    main()\nRuntimeError: Expected all tensors to be\
          \ on the same device, but found at least two devices, cuda:1 and cuda:0!\
          \ (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)\n\
          ```\n\n## \u5728\u6DFB\u52A0\u90A3\u4E2A\u4EE3\u7801\u540E\uFF0C\u53EF\u4EE5\
          \u8DD1\u8D77\u6765\n\n```bash\n[INFO|trainer.py:1786] 2023-07-17 21:18:51,711\
          \ >> ***** Running training *****\n[INFO|trainer.py:1787] 2023-07-17 21:18:51,711\
          \ >>   Num examples = 114,599\n[INFO|trainer.py:1788] 2023-07-17 21:18:51,711\
          \ >>   Num Epochs = 1\n[INFO|trainer.py:1789] 2023-07-17 21:18:51,711 >>\
          \   Instantaneous batch size per device = 1\n[INFO|trainer.py:1790] 2023-07-17\
          \ 21:18:51,711 >>   Total train batch size (w. parallel, distributed & accumulation)\
          \ = 16\n[INFO|trainer.py:1791] 2023-07-17 21:18:51,711 >>   Gradient Accumulation\
          \ steps = 16\n[INFO|trainer.py:1792] 2023-07-17 21:18:51,711 >>   Total\
          \ optimization steps = 3,000\n[INFO|trainer.py:1793] 2023-07-17 21:18:51,714\
          \ >>   Number of trainable parameters = 7,798,784\n  0%|               \
          \                                                                      \
          \                                                                      \
          \                  | 0/3000 [00:00<?, ?it/s]07/17/2023 21:18:51 - WARNING\
          \ - transformers_modules.chatglm2-6b_model.modeling_chatglm - `use_cache=True`\
          \ is incompatible with gradient checkpointing. Setting `use_cache=False`...\n\
          {'loss': 6.0639, 'learning_rate': 1.9933333333333334e-05, 'epoch': 0.0}\
          \                                                                      \
          \                                                              \n{'loss':\
          \ 6.0275, 'learning_rate': 1.9866666666666667e-05, 'epoch': 0.0}       \
          \                                                                      \
          \                                                       \n{'loss': 5.8822,\
          \ 'learning_rate': 1.98e-05, 'epoch': 0.0}                             \
          \                                                                      \
          \                                               \n{'loss': 5.5463, 'learning_rate':\
          \ 1.9733333333333336e-05, 'epoch': 0.01}                               \
          \                                                                      \
          \                              \n{'loss': 5.028, 'learning_rate': 1.9666666666666666e-05,\
          \ 'epoch': 0.01}                                                       \
          \                                                                      \
          \       \n{'loss': 4.534, 'learning_rate': 1.9600000000000002e-05, 'epoch':\
          \ 0.01}  \n```\n\n\n## \u4FEE\u6539\u65B9\u6CD5\n```python\n# \u5728modeling_chatglm.py\u4EE3\
          \u7801\u7684955\u884C\u5DE6\u53F3\n            # Shift so that tokens <\
          \ n predict n\n            shift_logits = lm_logits[..., :-1, :].contiguous()\n\
          \            shift_labels = labels[..., 1:].contiguous().to(shift_logits.device)\
          \ # \u5728\u8FD9\u91CC\u6DFB\u52A0\u4E0A\u5373\u53EF\n            # Flatten\
          \ the tokens\n```"
        updatedAt: '2023-07-17T13:32:52.889Z'
      numEdits: 1
      reactions: []
    id: 64b542b05c1ffb087056001c
    type: comment
  author: yuanzhoulvpi
  content: "\u5728\u4EE3\u7801\u90E8\u5206\uFF1A\n```python\n            # Shift so\
    \ that tokens < n predict n\n            shift_logits = lm_logits[..., :-1, :].contiguous()\n\
    \            shift_labels = labels[..., 1:].contiguous()#.to(shift_logits.device)\n\
    \            # Flatten the tokens\n```\n\n\u91C7\u7528\u7684\u8BAD\u7EC3\u65B9\
    \u6848\u662F[https://github.com/yuanzhoulvpi2017/zero_nlp/tree/main/chatglm_v2_6b_lora](https://github.com/yuanzhoulvpi2017/zero_nlp/tree/main/chatglm_v2_6b_lora)\n\
    \n## \u5728\u4E0D\u6DFB\u52A0\u90A3\u4E2A\u4EE3\u7801\uFF0C\u591A\u5361\u8BAD\u7EC3\
    \u4F1A\u62A5\u9519\n\u62A5\u9519\u4F4D\u7F6E\uFF1A`loss = loss_fct(shift_logits.view(-1,\
    \ shift_logits.size(-1)), shift_labels.view(-1))`\n\n\n```bash\n\n\n\u53D1\u751F\
    \u5F02\u5E38: RuntimeError\nExpected all tensors to be on the same device, but\
    \ found at least two devices, cuda:1 and cuda:0! (when checking argument for argument\
    \ target in method wrapper_CUDA_nll_loss_forward)\n  File \"/home/yuanz/.cache/huggingface/modules/transformers_modules/chatglm2-6b_model/modeling_chatglm.py\"\
    , line 958, in forward\n    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)),\
    \ shift_labels.view(-1))\n  File \"/media/yuanz/\u65B0\u52A0\u5377/\u8BAD\u7EC3\
    \u4EE3\u7801/chatglm6b_v2_0716/main.py\", line 371, in main\n    train_result\
    \ = trainer.train(resume_from_checkpoint=checkpoint)\n  File \"/media/yuanz/\u65B0\
    \u52A0\u5377/\u8BAD\u7EC3\u4EE3\u7801/chatglm6b_v2_0716/main.py\", line 432, in\
    \ <module>\n    main()\nRuntimeError: Expected all tensors to be on the same device,\
    \ but found at least two devices, cuda:1 and cuda:0! (when checking argument for\
    \ argument target in method wrapper_CUDA_nll_loss_forward)\n```\n\n## \u5728\u6DFB\
    \u52A0\u90A3\u4E2A\u4EE3\u7801\u540E\uFF0C\u53EF\u4EE5\u8DD1\u8D77\u6765\n\n```bash\n\
    [INFO|trainer.py:1786] 2023-07-17 21:18:51,711 >> ***** Running training *****\n\
    [INFO|trainer.py:1787] 2023-07-17 21:18:51,711 >>   Num examples = 114,599\n[INFO|trainer.py:1788]\
    \ 2023-07-17 21:18:51,711 >>   Num Epochs = 1\n[INFO|trainer.py:1789] 2023-07-17\
    \ 21:18:51,711 >>   Instantaneous batch size per device = 1\n[INFO|trainer.py:1790]\
    \ 2023-07-17 21:18:51,711 >>   Total train batch size (w. parallel, distributed\
    \ & accumulation) = 16\n[INFO|trainer.py:1791] 2023-07-17 21:18:51,711 >>   Gradient\
    \ Accumulation steps = 16\n[INFO|trainer.py:1792] 2023-07-17 21:18:51,711 >> \
    \  Total optimization steps = 3,000\n[INFO|trainer.py:1793] 2023-07-17 21:18:51,714\
    \ >>   Number of trainable parameters = 7,798,784\n  0%|                     \
    \                                                                            \
    \                                                                            |\
    \ 0/3000 [00:00<?, ?it/s]07/17/2023 21:18:51 - WARNING - transformers_modules.chatglm2-6b_model.modeling_chatglm\
    \ - `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n\
    {'loss': 6.0639, 'learning_rate': 1.9933333333333334e-05, 'epoch': 0.0}      \
    \                                                                            \
    \                                                  \n{'loss': 6.0275, 'learning_rate':\
    \ 1.9866666666666667e-05, 'epoch': 0.0}                                      \
    \                                                                            \
    \                  \n{'loss': 5.8822, 'learning_rate': 1.98e-05, 'epoch': 0.0}\
    \                                                                            \
    \                                                                      \n{'loss':\
    \ 5.5463, 'learning_rate': 1.9733333333333336e-05, 'epoch': 0.01}            \
    \                                                                            \
    \                                           \n{'loss': 5.028, 'learning_rate':\
    \ 1.9666666666666666e-05, 'epoch': 0.01}                                     \
    \                                                                            \
    \                   \n{'loss': 4.534, 'learning_rate': 1.9600000000000002e-05,\
    \ 'epoch': 0.01}  \n```\n\n\n## \u4FEE\u6539\u65B9\u6CD5\n```python\n# \u5728\
    modeling_chatglm.py\u4EE3\u7801\u7684955\u884C\u5DE6\u53F3\n            # Shift\
    \ so that tokens < n predict n\n            shift_logits = lm_logits[..., :-1,\
    \ :].contiguous()\n            shift_labels = labels[..., 1:].contiguous().to(shift_logits.device)\
    \ # \u5728\u8FD9\u91CC\u6DFB\u52A0\u4E0A\u5373\u53EF\n            # Flatten the\
    \ tokens\n```"
  created_at: 2023-07-17 12:31:28+00:00
  edited: true
  hidden: false
  id: 64b542b05c1ffb087056001c
  type: comment
is_pull_request: true
merge_commit_oid: null
num: 54
repo_id: THUDM/chatglm2-6b
repo_type: model
status: open
target_branch: refs/heads/main
title: "\u6A21\u578B\u5E76\u884C\u51FA\u9519\u5E76\u7ED9\u51FA\u4FEE\u6539\u65B9\u6848"
