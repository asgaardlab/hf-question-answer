!!python/object:huggingface_hub.community.DiscussionWithDetails
author: elven2023
conflicting_files: null
created_at: 2023-06-29 08:51:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e51335579807dda07633060426b02e0a.svg
      fullname: elven huang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: elven2023
      type: user
    createdAt: '2023-06-29T09:51:44.000Z'
    data:
      edited: false
      editors:
      - elven2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.331043541431427
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e51335579807dda07633060426b02e0a.svg
          fullname: elven huang
          isHf: false
          isPro: false
          name: elven2023
          type: user
        html: '<p>Traceback (most recent call last):<br>File "/ssd_data01/text-generation-webui/modules/callbacks.py",
          line 73, in gentask<br>ret = self.mfunc(callback=_callback, **self.kwargs)<br>File
          "/ssd_data01/text-generation-webui/modules/text_generation.py", line 263,
          in generate_with_callback<br>shared.model.generate(**kwargs)<br>File "/home/elven/miniconda3/envs/tgweb/lib/python3.10/site-packages/torch/utils/_contextlib.py",
          line 115, in decorate_context<br>return func(*args, **kwargs)<br>File "/home/elven/miniconda3/envs/tgweb/lib/python3.10/site-packages/transformers/generation/utils.py",
          line 1285, in generate<br>eos_token_id = eos_token_id[0]<br>IndexError:
          list index out of range</p>

          '
        raw: "Traceback (most recent call last):\r\nFile \"/ssd_data01/text-generation-webui/modules/callbacks.py\"\
          , line 73, in gentask\r\nret = self.mfunc(callback=_callback, **self.kwargs)\r\
          \nFile \"/ssd_data01/text-generation-webui/modules/text_generation.py\"\
          , line 263, in generate_with_callback\r\nshared.model.generate(**kwargs)\r\
          \nFile \"/home/elven/miniconda3/envs/tgweb/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\r\nreturn func(*args, **kwargs)\r\nFile\
          \ \"/home/elven/miniconda3/envs/tgweb/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 1285, in generate\r\neos_token_id = eos_token_id[0]\r\nIndexError:\
          \ list index out of range"
        updatedAt: '2023-06-29T09:51:44.738Z'
      numEdits: 0
      reactions: []
    id: 649d543020e8b3fa299fceee
    type: comment
  author: elven2023
  content: "Traceback (most recent call last):\r\nFile \"/ssd_data01/text-generation-webui/modules/callbacks.py\"\
    , line 73, in gentask\r\nret = self.mfunc(callback=_callback, **self.kwargs)\r\
    \nFile \"/ssd_data01/text-generation-webui/modules/text_generation.py\", line\
    \ 263, in generate_with_callback\r\nshared.model.generate(**kwargs)\r\nFile \"\
    /home/elven/miniconda3/envs/tgweb/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\r\nreturn func(*args, **kwargs)\r\nFile \"/home/elven/miniconda3/envs/tgweb/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 1285, in generate\r\neos_token_id = eos_token_id[0]\r\nIndexError: list\
    \ index out of range"
  created_at: 2023-06-29 08:51:44+00:00
  edited: false
  hidden: false
  id: 649d543020e8b3fa299fceee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653565274938-noauth.png?w=200&h=200&f=face
      fullname: HaoZhou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: upbit
      type: user
    createdAt: '2023-07-01T04:49:00.000Z'
    data:
      edited: true
      editors:
      - upbit
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.7784554958343506
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653565274938-noauth.png?w=200&h=200&f=face
          fullname: HaoZhou
          isHf: false
          isPro: false
          name: upbit
          type: user
        html: "<p>\u53EF\u4EE5\u52A0\u8F7D\uFF0C\u4F46\u8F93\u51FA\u6709\u95EE\u9898\
          \u4E0D\u4F1A\u505C\u6B62\u3002\u53EF\u4EE5\u770B\u8FD9\u4E2AIssue\uFF1A\
          <a rel=\"nofollow\" href=\"https://github.com/oobabooga/text-generation-webui/issues/2906\"\
          >https://github.com/oobabooga/text-generation-webui/issues/2906</a></p>\n\
          <p>\u66F4\u65B0WebUI\uFF0C\u7136\u540E\u91CD\u65B0<code>python download-model.py\
          \ THUDM/chatglm2-6b --text-only</code><br>\u5982\u679C\u8FD8\u662F\u4E0D\
          \u884C\uFF0C\u53EF\u4EE5\u52A0\u8FD9\u884C\uFF08\u5728models\u76EE\u5F55\
          \u4E0B\uFF09\uFF1A</p>\n<pre><code class=\"language-py\">on tokenization_chatglm.py\n\
          line\uFF1A<span class=\"hljs-number\">78</span> add self._eos_token=<span\
          \ class=\"hljs-string\">'&lt;eos&gt;'</span>\n</code></pre>\n<p>\u4E0D\u8FC7\
          \u52A0\u8F7D\u540E\u6709\u70B9\u5FAE\u5999\uFF1A</p>\n<blockquote>\n<p>ChatGLM2\u8F93\
          \u51FA<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/628f676c0ea7e76254bc583a/KKgDeXbm429HKD9kPM3Dd.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/628f676c0ea7e76254bc583a/KKgDeXbm429HKD9kPM3Dd.png\"\
          ></a></p>\n</blockquote>\n<blockquote>\n<p>text-generation-webui\u8F93\u51FA\
          <br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/628f676c0ea7e76254bc583a/e9BLyBnfZ0pL0NNjASrz5.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/628f676c0ea7e76254bc583a/e9BLyBnfZ0pL0NNjASrz5.png\"\
          ></a></p>\n</blockquote>\n"
        raw: "\u53EF\u4EE5\u52A0\u8F7D\uFF0C\u4F46\u8F93\u51FA\u6709\u95EE\u9898\u4E0D\
          \u4F1A\u505C\u6B62\u3002\u53EF\u4EE5\u770B\u8FD9\u4E2AIssue\uFF1Ahttps://github.com/oobabooga/text-generation-webui/issues/2906\n\
          \n\u66F4\u65B0WebUI\uFF0C\u7136\u540E\u91CD\u65B0`python download-model.py\
          \ THUDM/chatglm2-6b --text-only`\n\u5982\u679C\u8FD8\u662F\u4E0D\u884C\uFF0C\
          \u53EF\u4EE5\u52A0\u8FD9\u884C\uFF08\u5728models\u76EE\u5F55\u4E0B\uFF09\
          \uFF1A\n\n```py\non tokenization_chatglm.py\nline\uFF1A78 add self._eos_token='<eos>'\n\
          ```\n\n\u4E0D\u8FC7\u52A0\u8F7D\u540E\u6709\u70B9\u5FAE\u5999\uFF1A\n\n\
          > ChatGLM2\u8F93\u51FA\n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/628f676c0ea7e76254bc583a/KKgDeXbm429HKD9kPM3Dd.png)\n\
          \n> text-generation-webui\u8F93\u51FA\n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/628f676c0ea7e76254bc583a/e9BLyBnfZ0pL0NNjASrz5.png)\n"
        updatedAt: '2023-07-01T04:53:07.724Z'
      numEdits: 1
      reactions: []
    id: 649fb03c8347efe80031b861
    type: comment
  author: upbit
  content: "\u53EF\u4EE5\u52A0\u8F7D\uFF0C\u4F46\u8F93\u51FA\u6709\u95EE\u9898\u4E0D\
    \u4F1A\u505C\u6B62\u3002\u53EF\u4EE5\u770B\u8FD9\u4E2AIssue\uFF1Ahttps://github.com/oobabooga/text-generation-webui/issues/2906\n\
    \n\u66F4\u65B0WebUI\uFF0C\u7136\u540E\u91CD\u65B0`python download-model.py THUDM/chatglm2-6b\
    \ --text-only`\n\u5982\u679C\u8FD8\u662F\u4E0D\u884C\uFF0C\u53EF\u4EE5\u52A0\u8FD9\
    \u884C\uFF08\u5728models\u76EE\u5F55\u4E0B\uFF09\uFF1A\n\n```py\non tokenization_chatglm.py\n\
    line\uFF1A78 add self._eos_token='<eos>'\n```\n\n\u4E0D\u8FC7\u52A0\u8F7D\u540E\
    \u6709\u70B9\u5FAE\u5999\uFF1A\n\n> ChatGLM2\u8F93\u51FA\n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/628f676c0ea7e76254bc583a/KKgDeXbm429HKD9kPM3Dd.png)\n\
    \n> text-generation-webui\u8F93\u51FA\n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/628f676c0ea7e76254bc583a/e9BLyBnfZ0pL0NNjASrz5.png)\n"
  created_at: 2023-07-01 03:49:00+00:00
  edited: true
  hidden: false
  id: 649fb03c8347efe80031b861
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ddd9c5d06a5a4673894a2c56d5225e23.svg
      fullname: Lejun Zhu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lejunzhu
      type: user
    createdAt: '2023-07-04T11:58:48.000Z'
    data:
      edited: false
      editors:
      - lejunzhu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.12767137587070465
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ddd9c5d06a5a4673894a2c56d5225e23.svg
          fullname: Lejun Zhu
          isHf: false
          isPro: false
          name: lejunzhu
          type: user
        html: "<p>\u5728ooba\u7684\u4EE3\u7801\u91CC\u52A0\u4E86\u8FD9\u6837\u4E09\
          \u884C\uFF0C\u597D\u50CF\u6CA1\u6709\u697C\u4E0A\u7684\u95EE\u9898\uFF1A\
          </p>\n<pre><code>--- a/modules/models.py\n+++ b/modules/models.py\n@@ -135,7\
          \ +135,10 @@ def load_tokenizer(model_name, model):\n         path_to_model\
          \ = Path(f\"{shared.args.model_dir}/{model_name}/\")\n         if path_to_model.exists():\n\
          \             tokenizer = AutoTokenizer.from_pretrained(path_to_model, trust_remote_code=shared.args.trust_remote_code)\n\
          -\n+        if shared.args.model_type == 'chatglm':\n+            tokenizer.eos_token_id\
          \ = tokenizer.tokenizer.eos_id\n+            tokenizer.bos_token_id = tokenizer.tokenizer.bos_id\n\
          +            tokenizer.unk_token_id = None\n     return tokenizer\n</code></pre>\n"
        raw: "\u5728ooba\u7684\u4EE3\u7801\u91CC\u52A0\u4E86\u8FD9\u6837\u4E09\u884C\
          \uFF0C\u597D\u50CF\u6CA1\u6709\u697C\u4E0A\u7684\u95EE\u9898\uFF1A\n```\n\
          --- a/modules/models.py\n+++ b/modules/models.py\n@@ -135,7 +135,10 @@ def\
          \ load_tokenizer(model_name, model):\n         path_to_model = Path(f\"\
          {shared.args.model_dir}/{model_name}/\")\n         if path_to_model.exists():\n\
          \             tokenizer = AutoTokenizer.from_pretrained(path_to_model, trust_remote_code=shared.args.trust_remote_code)\n\
          -\n+        if shared.args.model_type == 'chatglm':\n+            tokenizer.eos_token_id\
          \ = tokenizer.tokenizer.eos_id\n+            tokenizer.bos_token_id = tokenizer.tokenizer.bos_id\n\
          +            tokenizer.unk_token_id = None\n     return tokenizer\n```"
        updatedAt: '2023-07-04T11:58:48.329Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - upbit
    id: 64a409781664581878a36ede
    type: comment
  author: lejunzhu
  content: "\u5728ooba\u7684\u4EE3\u7801\u91CC\u52A0\u4E86\u8FD9\u6837\u4E09\u884C\
    \uFF0C\u597D\u50CF\u6CA1\u6709\u697C\u4E0A\u7684\u95EE\u9898\uFF1A\n```\n--- a/modules/models.py\n\
    +++ b/modules/models.py\n@@ -135,7 +135,10 @@ def load_tokenizer(model_name, model):\n\
    \         path_to_model = Path(f\"{shared.args.model_dir}/{model_name}/\")\n \
    \        if path_to_model.exists():\n             tokenizer = AutoTokenizer.from_pretrained(path_to_model,\
    \ trust_remote_code=shared.args.trust_remote_code)\n-\n+        if shared.args.model_type\
    \ == 'chatglm':\n+            tokenizer.eos_token_id = tokenizer.tokenizer.eos_id\n\
    +            tokenizer.bos_token_id = tokenizer.tokenizer.bos_id\n+          \
    \  tokenizer.unk_token_id = None\n     return tokenizer\n```"
  created_at: 2023-07-04 10:58:48+00:00
  edited: false
  hidden: false
  id: 64a409781664581878a36ede
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653565274938-noauth.png?w=200&h=200&f=face
      fullname: HaoZhou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: upbit
      type: user
    createdAt: '2023-07-04T12:07:37.000Z'
    data:
      edited: true
      editors:
      - upbit
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.8935360312461853
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653565274938-noauth.png?w=200&h=200&f=face
          fullname: HaoZhou
          isHf: false
          isPro: false
          name: upbit
          type: user
        html: "<p>\u611F\u8C22\u6307\u70B9\uFF01\u786E\u5B9E\u662Feos/bos/pad\u7684\
          token_id\u4E3ANone\u5BFC\u81F4\u7684\u3002\u7C7B\u4F3CLLaMA\u7684\u4FEE\u590D\
          \u65B9\u5F0F\uFF0C\u76F4\u63A5\u8BBE\u7F6E 2/1/0 \u4E5F\u53EF\u4EE5\uFF08\
          \u4E0D\u8FC7\u5982\u679C\u539F\u6765\u6709\u503C\uFF0C\u76F4\u63A5\u8BBE\
          \u7F6E\u4F1ACrash\uFF09\uFF1A</p>\n<pre><code class=\"language-diff\"><span\
          \ class=\"hljs-comment\">diff --git a/modules/models.py b/modules/models.py</span>\n\
          <span class=\"hljs-comment\">index 4b47e64..dea9e73 100644</span>\n<span\
          \ class=\"hljs-comment\">--- a/modules/models.py</span>\n<span class=\"\
          hljs-comment\">+++ b/modules/models.py</span>\n<span class=\"hljs-meta\"\
          >@@ -116,6 +116,17 @@</span> def load_tokenizer(model_name, model):\n  \
          \       if path_to_model.exists():\n             tokenizer = AutoTokenizer.from_pretrained(path_to_model,\
          \ trust_remote_code=shared.args.trust_remote_code)\n\n<span class=\"hljs-addition\"\
          >+        if 'chatglm' in model_name.lower():</span>\n<span class=\"hljs-addition\"\
          >+            try:</span>\n<span class=\"hljs-addition\">+             \
          \   tokenizer.eos_token_id = 2   # \u6211\u8FD9\u8FB9debug\u65F6\u6709\u503C\
          \uFF0C\u8BBE\u7F6E\u4F1Acrash\u3002\u6240\u4EE5\u62C6\u5206\u4E862\u4E2A\
          try..catch</span>\n<span class=\"hljs-addition\">+            except:</span>\n\
          <span class=\"hljs-addition\">+                pass</span>\n<span class=\"\
          hljs-addition\">+            try:</span>\n<span class=\"hljs-addition\"\
          >+                tokenizer.bos_token_id = 1</span>\n<span class=\"hljs-addition\"\
          >+                tokenizer.pad_token_id = 0</span>\n<span class=\"hljs-addition\"\
          >+            except:</span>\n<span class=\"hljs-addition\">+          \
          \      pass</span>\n<span class=\"hljs-addition\">+</span>\n     return\
          \ tokenizer\n</code></pre>\n"
        raw: "\u611F\u8C22\u6307\u70B9\uFF01\u786E\u5B9E\u662Feos/bos/pad\u7684token_id\u4E3A\
          None\u5BFC\u81F4\u7684\u3002\u7C7B\u4F3CLLaMA\u7684\u4FEE\u590D\u65B9\u5F0F\
          \uFF0C\u76F4\u63A5\u8BBE\u7F6E 2/1/0 \u4E5F\u53EF\u4EE5\uFF08\u4E0D\u8FC7\
          \u5982\u679C\u539F\u6765\u6709\u503C\uFF0C\u76F4\u63A5\u8BBE\u7F6E\u4F1A\
          Crash\uFF09\uFF1A\n\n```diff\ndiff --git a/modules/models.py b/modules/models.py\n\
          index 4b47e64..dea9e73 100644\n--- a/modules/models.py\n+++ b/modules/models.py\n\
          @@ -116,6 +116,17 @@ def load_tokenizer(model_name, model):\n         if\
          \ path_to_model.exists():\n             tokenizer = AutoTokenizer.from_pretrained(path_to_model,\
          \ trust_remote_code=shared.args.trust_remote_code)\n\n+        if 'chatglm'\
          \ in model_name.lower():\n+            try:\n+                tokenizer.eos_token_id\
          \ = 2   # \u6211\u8FD9\u8FB9debug\u65F6\u6709\u503C\uFF0C\u8BBE\u7F6E\u4F1A\
          crash\u3002\u6240\u4EE5\u62C6\u5206\u4E862\u4E2Atry..catch\n+          \
          \  except:\n+                pass\n+            try:\n+                tokenizer.bos_token_id\
          \ = 1\n+                tokenizer.pad_token_id = 0\n+            except:\n\
          +                pass\n+\n     return tokenizer\n```\n"
        updatedAt: '2023-07-04T13:34:39.317Z'
      numEdits: 2
      reactions: []
    id: 64a40b89c1cc4dab59dbc4b2
    type: comment
  author: upbit
  content: "\u611F\u8C22\u6307\u70B9\uFF01\u786E\u5B9E\u662Feos/bos/pad\u7684token_id\u4E3A\
    None\u5BFC\u81F4\u7684\u3002\u7C7B\u4F3CLLaMA\u7684\u4FEE\u590D\u65B9\u5F0F\uFF0C\
    \u76F4\u63A5\u8BBE\u7F6E 2/1/0 \u4E5F\u53EF\u4EE5\uFF08\u4E0D\u8FC7\u5982\u679C\
    \u539F\u6765\u6709\u503C\uFF0C\u76F4\u63A5\u8BBE\u7F6E\u4F1ACrash\uFF09\uFF1A\n\
    \n```diff\ndiff --git a/modules/models.py b/modules/models.py\nindex 4b47e64..dea9e73\
    \ 100644\n--- a/modules/models.py\n+++ b/modules/models.py\n@@ -116,6 +116,17\
    \ @@ def load_tokenizer(model_name, model):\n         if path_to_model.exists():\n\
    \             tokenizer = AutoTokenizer.from_pretrained(path_to_model, trust_remote_code=shared.args.trust_remote_code)\n\
    \n+        if 'chatglm' in model_name.lower():\n+            try:\n+         \
    \       tokenizer.eos_token_id = 2   # \u6211\u8FD9\u8FB9debug\u65F6\u6709\u503C\
    \uFF0C\u8BBE\u7F6E\u4F1Acrash\u3002\u6240\u4EE5\u62C6\u5206\u4E862\u4E2Atry..catch\n\
    +            except:\n+                pass\n+            try:\n+            \
    \    tokenizer.bos_token_id = 1\n+                tokenizer.pad_token_id = 0\n\
    +            except:\n+                pass\n+\n     return tokenizer\n```\n"
  created_at: 2023-07-04 11:07:37+00:00
  edited: true
  hidden: false
  id: 64a40b89c1cc4dab59dbc4b2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 29
repo_id: THUDM/chatglm2-6b
repo_type: model
status: open
target_branch: null
title: "when use oobabooga/ext-generation-webui load this mode \uFF0Cthe chat  message\
  \ was blank and the terminal reponse error\uFF1AIndexError: list index out of range"
