!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ByteHandler
conflicting_files: null
created_at: 2023-10-08 05:54:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bf2f7278c9299640e284888e18dccc57.svg
      fullname: "\u5B5F\u9633\u9633"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ByteHandler
      type: user
    createdAt: '2023-10-08T06:54:48.000Z'
    data:
      edited: false
      editors:
      - ByteHandler
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4677385091781616
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bf2f7278c9299640e284888e18dccc57.svg
          fullname: "\u5B5F\u9633\u9633"
          isHf: false
          isPro: false
          name: ByteHandler
          type: user
        html: "<pre><code class=\"language-python\">Traceback (most recent call last):\n\
          \  File <span class=\"hljs-string\">\"/data/share/code/second-life/finetune.py\"\
          </span>, line <span class=\"hljs-number\">210</span>, <span class=\"hljs-keyword\"\
          >in</span> &lt;module&gt;\n    finetune()\n  File <span class=\"hljs-string\"\
          >\"/data/share/code/second-life/finetune.py\"</span>, line <span class=\"\
          hljs-number\">201</span>, <span class=\"hljs-keyword\">in</span> finetune\n\
          \    trainer.train(resume_from_checkpoint=last_checkpoint)\n  File <span\
          \ class=\"hljs-string\">\"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/trainer.py\"\
          </span>, line <span class=\"hljs-number\">1555</span>, <span class=\"hljs-keyword\"\
          >in</span> train\n    <span class=\"hljs-keyword\">return</span> inner_training_loop(\n\
          \  File <span class=\"hljs-string\">\"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/trainer.py\"\
          </span>, line <span class=\"hljs-number\">1837</span>, <span class=\"hljs-keyword\"\
          >in</span> _inner_training_loop\n    tr_loss_step = self.training_step(model,\
          \ inputs)\n  File <span class=\"hljs-string\">\"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/trainer.py\"\
          </span>, line <span class=\"hljs-number\">2682</span>, <span class=\"hljs-keyword\"\
          >in</span> training_step\n    loss = self.compute_loss(model, inputs)\n\
          \  File <span class=\"hljs-string\">\"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/trainer.py\"\
          </span>, line <span class=\"hljs-number\">2707</span>, <span class=\"hljs-keyword\"\
          >in</span> compute_loss\n    outputs = model(**inputs)\n  File <span class=\"\
          hljs-string\">\"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          </span>, line <span class=\"hljs-number\">1501</span>, <span class=\"hljs-keyword\"\
          >in</span> _call_impl\n    <span class=\"hljs-keyword\">return</span> forward_call(*args,\
          \ **kwargs)\n  File <span class=\"hljs-string\">\"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/deepspeed/utils/nvtx.py\"\
          </span>, line <span class=\"hljs-number\">15</span>, <span class=\"hljs-keyword\"\
          >in</span> wrapped_fn\n    ret_val = func(*args, **kwargs)\n  File <span\
          \ class=\"hljs-string\">\"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/deepspeed/runtime/engine.py\"\
          </span>, line <span class=\"hljs-number\">1801</span>, <span class=\"hljs-keyword\"\
          >in</span> forward\n    loss = self.module(*inputs, **kwargs)\n  File <span\
          \ class=\"hljs-string\">\"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          </span>, line <span class=\"hljs-number\">1501</span>, <span class=\"hljs-keyword\"\
          >in</span> _call_impl\n    <span class=\"hljs-keyword\">return</span> forward_call(*args,\
          \ **kwargs)\n  File <span class=\"hljs-string\">\"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/peft/peft_model.py\"\
          </span>, line <span class=\"hljs-number\">529</span>, <span class=\"hljs-keyword\"\
          >in</span> forward\n    <span class=\"hljs-keyword\">return</span> self.base_model(\n\
          \  File <span class=\"hljs-string\">\"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          </span>, line <span class=\"hljs-number\">1501</span>, <span class=\"hljs-keyword\"\
          >in</span> _call_impl\n    <span class=\"hljs-keyword\">return</span> forward_call(*args,\
          \ **kwargs)\n  File <span class=\"hljs-string\">\"/home/rd/.cache/huggingface/modules/transformers_modules/chatglm2-6b/modeling_chatglm.py\"\
          </span>, line <span class=\"hljs-number\">934</span>, <span class=\"hljs-keyword\"\
          >in</span> forward\n    transformer_outputs = self.transformer(\n  File\
          \ <span class=\"hljs-string\">\"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          </span>, line <span class=\"hljs-number\">1501</span>, <span class=\"hljs-keyword\"\
          >in</span> _call_impl\n    <span class=\"hljs-keyword\">return</span> forward_call(*args,\
          \ **kwargs)\n  File <span class=\"hljs-string\">\"/home/rd/.cache/huggingface/modules/transformers_modules/chatglm2-6b/modeling_chatglm.py\"\
          </span>, line <span class=\"hljs-number\">819</span>, <span class=\"hljs-keyword\"\
          >in</span> forward\n    full_attention_mask = self.get_masks(input_ids,\
          \ past_key_values, padding_mask=attention_mask)\n  File <span class=\"hljs-string\"\
          >\"/home/rd/.cache/huggingface/modules/transformers_modules/chatglm2-6b/modeling_chatglm.py\"\
          </span>, line <span class=\"hljs-number\">690</span>, <span class=\"hljs-keyword\"\
          >in</span> get_masks\n    full_attention_mask -= padding_mask.unsqueeze(-<span\
          \ class=\"hljs-number\">1</span>) - <span class=\"hljs-number\">1</span>\n\
          RuntimeError: Subtraction, the `-` operator, <span class=\"hljs-keyword\"\
          >with</span> a <span class=\"hljs-built_in\">bool</span> tensor <span class=\"\
          hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> supported.\
          \ If you are trying to invert a mask, use the `~` <span class=\"hljs-keyword\"\
          >or</span> `logical_not()` operator instead.\n</code></pre>\n"
        raw: "```python\r\nTraceback (most recent call last):\r\n  File \"/data/share/code/second-life/finetune.py\"\
          , line 210, in <module>\r\n    finetune()\r\n  File \"/data/share/code/second-life/finetune.py\"\
          , line 201, in finetune\r\n    trainer.train(resume_from_checkpoint=last_checkpoint)\r\
          \n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 1555, in train\r\n    return inner_training_loop(\r\n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 1837, in _inner_training_loop\r\n    tr_loss_step = self.training_step(model,\
          \ inputs)\r\n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 2682, in training_step\r\n    loss = self.compute_loss(model, inputs)\r\
          \n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 2707, in compute_loss\r\n    outputs = model(**inputs)\r\n  File\
          \ \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/deepspeed/utils/nvtx.py\"\
          , line 15, in wrapped_fn\r\n    ret_val = func(*args, **kwargs)\r\n  File\
          \ \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/deepspeed/runtime/engine.py\"\
          , line 1801, in forward\r\n    loss = self.module(*inputs, **kwargs)\r\n\
          \  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/peft/peft_model.py\"\
          , line 529, in forward\r\n    return self.base_model(\r\n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/rd/.cache/huggingface/modules/transformers_modules/chatglm2-6b/modeling_chatglm.py\"\
          , line 934, in forward\r\n    transformer_outputs = self.transformer(\r\n\
          \  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/rd/.cache/huggingface/modules/transformers_modules/chatglm2-6b/modeling_chatglm.py\"\
          , line 819, in forward\r\n    full_attention_mask = self.get_masks(input_ids,\
          \ past_key_values, padding_mask=attention_mask)\r\n  File \"/home/rd/.cache/huggingface/modules/transformers_modules/chatglm2-6b/modeling_chatglm.py\"\
          , line 690, in get_masks\r\n    full_attention_mask -= padding_mask.unsqueeze(-1)\
          \ - 1\r\nRuntimeError: Subtraction, the `-` operator, with a bool tensor\
          \ is not supported. If you are trying to invert a mask, use the `~` or `logical_not()`\
          \ operator instead.\r\n```"
        updatedAt: '2023-10-08T06:54:48.812Z'
      numEdits: 0
      reactions: []
    id: 6522523836008ecc889fe77a
    type: comment
  author: ByteHandler
  content: "```python\r\nTraceback (most recent call last):\r\n  File \"/data/share/code/second-life/finetune.py\"\
    , line 210, in <module>\r\n    finetune()\r\n  File \"/data/share/code/second-life/finetune.py\"\
    , line 201, in finetune\r\n    trainer.train(resume_from_checkpoint=last_checkpoint)\r\
    \n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 1555, in train\r\n    return inner_training_loop(\r\n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 1837, in _inner_training_loop\r\n    tr_loss_step = self.training_step(model,\
    \ inputs)\r\n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 2682, in training_step\r\n    loss = self.compute_loss(model, inputs)\r\
    \n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 2707, in compute_loss\r\n    outputs = model(**inputs)\r\n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/deepspeed/utils/nvtx.py\"\
    , line 15, in wrapped_fn\r\n    ret_val = func(*args, **kwargs)\r\n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/deepspeed/runtime/engine.py\"\
    , line 1801, in forward\r\n    loss = self.module(*inputs, **kwargs)\r\n  File\
    \ \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/peft/peft_model.py\"\
    , line 529, in forward\r\n    return self.base_model(\r\n  File \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/rd/.cache/huggingface/modules/transformers_modules/chatglm2-6b/modeling_chatglm.py\"\
    , line 934, in forward\r\n    transformer_outputs = self.transformer(\r\n  File\
    \ \"/data/share/miniconda3/envs/llm/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/rd/.cache/huggingface/modules/transformers_modules/chatglm2-6b/modeling_chatglm.py\"\
    , line 819, in forward\r\n    full_attention_mask = self.get_masks(input_ids,\
    \ past_key_values, padding_mask=attention_mask)\r\n  File \"/home/rd/.cache/huggingface/modules/transformers_modules/chatglm2-6b/modeling_chatglm.py\"\
    , line 690, in get_masks\r\n    full_attention_mask -= padding_mask.unsqueeze(-1)\
    \ - 1\r\nRuntimeError: Subtraction, the `-` operator, with a bool tensor is not\
    \ supported. If you are trying to invert a mask, use the `~` or `logical_not()`\
    \ operator instead.\r\n```"
  created_at: 2023-10-08 05:54:48+00:00
  edited: false
  hidden: false
  id: 6522523836008ecc889fe77a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bf2f7278c9299640e284888e18dccc57.svg
      fullname: "\u5B5F\u9633\u9633"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ByteHandler
      type: user
    createdAt: '2023-10-08T06:57:06.000Z'
    data:
      edited: false
      editors:
      - ByteHandler
      hidden: false
      identifiedLanguage:
        language: pt
        probability: 0.2697567641735077
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bf2f7278c9299640e284888e18dccc57.svg
          fullname: "\u5B5F\u9633\u9633"
          isHf: false
          isPro: false
          name: ByteHandler
          type: user
        html: '<p>duplicate</p>

          '
        raw: duplicate
        updatedAt: '2023-10-08T06:57:06.977Z'
      numEdits: 0
      reactions: []
      relatedEventId: 652252c3ef81ce01a46e876b
    id: 652252c2ef81ce01a46e8769
    type: comment
  author: ByteHandler
  content: duplicate
  created_at: 2023-10-08 05:57:06+00:00
  edited: false
  hidden: false
  id: 652252c2ef81ce01a46e8769
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/bf2f7278c9299640e284888e18dccc57.svg
      fullname: "\u5B5F\u9633\u9633"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ByteHandler
      type: user
    createdAt: '2023-10-08T06:57:07.000Z'
    data:
      status: closed
    id: 652252c3ef81ce01a46e876b
    type: status-change
  author: ByteHandler
  created_at: 2023-10-08 05:57:07+00:00
  id: 652252c3ef81ce01a46e876b
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 89
repo_id: THUDM/chatglm2-6b
repo_type: model
status: closed
target_branch: null
title: get_mask error
