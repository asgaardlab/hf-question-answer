!!python/object:huggingface_hub.community.DiscussionWithDetails
author: 0xrk
conflicting_files: null
created_at: 2023-09-14 10:03:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4d319f7628609a2074c4281329777e06.svg
      fullname: Rifat Khan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 0xrk
      type: user
    createdAt: '2023-09-14T11:03:32.000Z'
    data:
      edited: false
      editors:
      - 0xrk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3096432685852051
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4d319f7628609a2074c4281329777e06.svg
          fullname: Rifat Khan
          isHf: false
          isPro: false
          name: 0xrk
          type: user
        html: '<p>2023-09-14 16:55:40 ERROR:Failed to load the model.<br>Traceback
          (most recent call last):<br>  File "E:\oobabooga_windows\oobabooga_windows\text-generation-webui\modules\ui_model_menu.py",
          line 194, in load_model_wrapper<br>    shared.model, shared.tokenizer =
          load_model(shared.model_name, loader)<br>  File "E:\oobabooga_windows\oobabooga_windows\text-generation-webui\modules\models.py",
          line 77, in load_model<br>    output = load_func_map<a rel="nofollow" href="model_name">loader</a><br>  File
          "E:\oobabooga_windows\oobabooga_windows\text-generation-webui\modules\models.py",
          line 222, in huggingface_loader<br>    model = LoaderClass.from_pretrained(checkpoint,
          **params)<br>  File "E:\oobabooga_windows\oobabooga_windows\installer_files\env\lib\site-packages\transformers\models\auto\auto_factory.py",
          line 558, in from_pretrained<br>    return model_class.from_pretrained(<br>  File
          "E:\oobabooga_windows\oobabooga_windows\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
          line 3175, in from_pretrained<br>    ) = cls._load_pretrained_model(<br>  File
          "E:\oobabooga_windows\oobabooga_windows\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
          line 3563, in _load_pretrained_model<br>    new_error_msgs, offload_index,
          state_dict_index = _load_state_dict_into_meta_model(<br>  File "E:\oobabooga_windows\oobabooga_windows\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
          line 710, in _load_state_dict_into_meta_model<br>    param = param.to(dtype)<br>RuntimeError:
          [enforce fail at ..\c10\core\impl\alloc_cpu.cpp:72] data. DefaultCPUAllocator:
          not enough memory: you tried to allocate 224395264 bytes.</p>

          '
        raw: "2023-09-14 16:55:40 ERROR:Failed to load the model.\r\nTraceback (most\
          \ recent call last):\r\n  File \"E:\\oobabooga_windows\\oobabooga_windows\\\
          text-generation-webui\\modules\\ui_model_menu.py\", line 194, in load_model_wrapper\r\
          \n    shared.model, shared.tokenizer = load_model(shared.model_name, loader)\r\
          \n  File \"E:\\oobabooga_windows\\oobabooga_windows\\text-generation-webui\\\
          modules\\models.py\", line 77, in load_model     \r\n    output = load_func_map[loader](model_name)\r\
          \n  File \"E:\\oobabooga_windows\\oobabooga_windows\\text-generation-webui\\\
          modules\\models.py\", line 222, in huggingface_loader\r\n    model = LoaderClass.from_pretrained(checkpoint,\
          \ **params)\r\n  File \"E:\\oobabooga_windows\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\",\
          \ line 558, in from_pretrained\r\n    return model_class.from_pretrained(\r\
          \n  File \"E:\\oobabooga_windows\\oobabooga_windows\\installer_files\\env\\\
          lib\\site-packages\\transformers\\modeling_utils.py\", line 3175, in from_pretrained\r\
          \n    ) = cls._load_pretrained_model(\r\n  File \"E:\\oobabooga_windows\\\
          oobabooga_windows\\installer_files\\env\\lib\\site-packages\\transformers\\\
          modeling_utils.py\", line 3563, in _load_pretrained_model\r\n    new_error_msgs,\
          \ offload_index, state_dict_index = _load_state_dict_into_meta_model(\r\n\
          \  File \"E:\\oobabooga_windows\\oobabooga_windows\\installer_files\\env\\\
          lib\\site-packages\\transformers\\modeling_utils.py\", line 710, in _load_state_dict_into_meta_model\r\
          \n    param = param.to(dtype)\r\nRuntimeError: [enforce fail at ..\\c10\\\
          core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory:\
          \ you tried to allocate 224395264 bytes.\r\n"
        updatedAt: '2023-09-14T11:03:32.595Z'
      numEdits: 0
      reactions: []
    id: 6502e8841e4cba6f174f5b35
    type: comment
  author: 0xrk
  content: "2023-09-14 16:55:40 ERROR:Failed to load the model.\r\nTraceback (most\
    \ recent call last):\r\n  File \"E:\\oobabooga_windows\\oobabooga_windows\\text-generation-webui\\\
    modules\\ui_model_menu.py\", line 194, in load_model_wrapper\r\n    shared.model,\
    \ shared.tokenizer = load_model(shared.model_name, loader)\r\n  File \"E:\\oobabooga_windows\\\
    oobabooga_windows\\text-generation-webui\\modules\\models.py\", line 77, in load_model\
    \     \r\n    output = load_func_map[loader](model_name)\r\n  File \"E:\\oobabooga_windows\\\
    oobabooga_windows\\text-generation-webui\\modules\\models.py\", line 222, in huggingface_loader\r\
    \n    model = LoaderClass.from_pretrained(checkpoint, **params)\r\n  File \"E:\\\
    oobabooga_windows\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\models\\auto\\auto_factory.py\", line 558, in from_pretrained\r\n\
    \    return model_class.from_pretrained(\r\n  File \"E:\\oobabooga_windows\\oobabooga_windows\\\
    installer_files\\env\\lib\\site-packages\\transformers\\modeling_utils.py\", line\
    \ 3175, in from_pretrained\r\n    ) = cls._load_pretrained_model(\r\n  File \"\
    E:\\oobabooga_windows\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\modeling_utils.py\", line 3563, in _load_pretrained_model\r\n  \
    \  new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(\r\
    \n  File \"E:\\oobabooga_windows\\oobabooga_windows\\installer_files\\env\\lib\\\
    site-packages\\transformers\\modeling_utils.py\", line 710, in _load_state_dict_into_meta_model\r\
    \n    param = param.to(dtype)\r\nRuntimeError: [enforce fail at ..\\c10\\core\\\
    impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried\
    \ to allocate 224395264 bytes.\r\n"
  created_at: 2023-09-14 10:03:32+00:00
  edited: false
  hidden: false
  id: 6502e8841e4cba6f174f5b35
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 82
repo_id: THUDM/chatglm2-6b
repo_type: model
status: open
target_branch: null
title: 'RuntimeError: DefaultCPUAllocator: not enough memory: you tried to allocate
  224395264 bytes.'
