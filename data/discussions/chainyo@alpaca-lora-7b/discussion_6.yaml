!!python/object:huggingface_hub.community.DiscussionWithDetails
author: chouks
conflicting_files: null
created_at: 2023-06-05 00:04:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2ed50cce34efc29c7baccc0073f736e0.svg
      fullname: choukoushin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chouks
      type: user
    createdAt: '2023-06-05T01:04:35.000Z'
    data:
      edited: false
      editors:
      - chouks
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9554645419120789
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2ed50cce34efc29c7baccc0073f736e0.svg
          fullname: choukoushin
          isHf: false
          isPro: false
          name: chouks
          type: user
        html: '<p>Sorry to bother you.<br>But i''ve been looking around for a while
          but yet to find to solution.<br>After I fine turned my version of alpaca
          lora, all I get is files like "adapter_model.bin" and "adapter_config.json"
          along with some checkpoint, I can use them with the script "generate.py"
          provided by the <a rel="nofollow" href="https://github.com/tloen/alpaca-lora">https://github.com/tloen/alpaca-lora</a>.<br>But
          I couldn''t find a way to build a "complete" model so I can use transformers
          like all the other llama-based models.<br>Then I ran into your project,
          you did it fine.<br>So sorry for asking a question that is not directly
          related to your model, but how did you convert your lora weights to this
          model?<br>Thank you in advance. </p>

          '
        raw: "Sorry to bother you.\r\nBut i've been looking around for a while but\
          \ yet to find to solution.\r\nAfter I fine turned my version of alpaca lora,\
          \ all I get is files like \"adapter_model.bin\" and \"adapter_config.json\"\
          \ along with some checkpoint, I can use them with the script \"generate.py\"\
          \ provided by the https://github.com/tloen/alpaca-lora. \r\nBut I couldn't\
          \ find a way to build a \"complete\" model so I can use transformers like\
          \ all the other llama-based models.\r\nThen I ran into your project, you\
          \ did it fine.\r\nSo sorry for asking a question that is not directly related\
          \ to your model, but how did you convert your lora weights to this model?\r\
          \nThank you in advance. "
        updatedAt: '2023-06-05T01:04:35.459Z'
      numEdits: 0
      reactions: []
    id: 647d34a33fe0f559b4c763c1
    type: comment
  author: chouks
  content: "Sorry to bother you.\r\nBut i've been looking around for a while but yet\
    \ to find to solution.\r\nAfter I fine turned my version of alpaca lora, all I\
    \ get is files like \"adapter_model.bin\" and \"adapter_config.json\" along with\
    \ some checkpoint, I can use them with the script \"generate.py\" provided by\
    \ the https://github.com/tloen/alpaca-lora. \r\nBut I couldn't find a way to build\
    \ a \"complete\" model so I can use transformers like all the other llama-based\
    \ models.\r\nThen I ran into your project, you did it fine.\r\nSo sorry for asking\
    \ a question that is not directly related to your model, but how did you convert\
    \ your lora weights to this model?\r\nThank you in advance. "
  created_at: 2023-06-05 00:04:35+00:00
  edited: false
  hidden: false
  id: 647d34a33fe0f559b4c763c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1675273618630-6162dbe0d928851b47350ae2.jpeg?w=200&h=200&f=face
      fullname: Thomas Chaigneau
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: chainyo
      type: user
    createdAt: '2023-06-05T07:33:20.000Z'
    data:
      edited: false
      editors:
      - chainyo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7189087867736816
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1675273618630-6162dbe0d928851b47350ae2.jpeg?w=200&h=200&f=face
          fullname: Thomas Chaigneau
          isHf: false
          isPro: false
          name: chainyo
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;chouks&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/chouks\">@<span class=\"\
          underline\">chouks</span></a></span>\n\n\t</span></span>, no problem.</p>\n\
          <p>This Python script can merge your LoRa weights with the base Llama model.\
          \ You can edit the model path with your fine-tuned version: <a rel=\"nofollow\"\
          \ href=\"https://github.com/tloen/alpaca-lora/blob/main/export_hf_checkpoint.py\"\
          >https://github.com/tloen/alpaca-lora/blob/main/export_hf_checkpoint.py</a></p>\n"
        raw: 'Hi @chouks, no problem.


          This Python script can merge your LoRa weights with the base Llama model.
          You can edit the model path with your fine-tuned version: https://github.com/tloen/alpaca-lora/blob/main/export_hf_checkpoint.py'
        updatedAt: '2023-06-05T07:33:20.193Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - pankajmathur
      - count: 1
        reaction: "\U0001F44D"
        users:
        - chouks
    id: 647d8fc032c471a7fa7ee351
    type: comment
  author: chainyo
  content: 'Hi @chouks, no problem.


    This Python script can merge your LoRa weights with the base Llama model. You
    can edit the model path with your fine-tuned version: https://github.com/tloen/alpaca-lora/blob/main/export_hf_checkpoint.py'
  created_at: 2023-06-05 06:33:20+00:00
  edited: false
  hidden: false
  id: 647d8fc032c471a7fa7ee351
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: chainyo/alpaca-lora-7b
repo_type: model
status: open
target_branch: null
title: May i ask how should I convert my fine tuned alpaca lora to the format like
  yours?
