!!python/object:huggingface_hub.community.DiscussionWithDetails
author: teslim007
conflicting_files: null
created_at: 2023-09-28 16:17:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/01740c13729995ad67483ca49a66e1be.svg
      fullname: Teslim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: teslim007
      type: user
    createdAt: '2023-09-28T17:17:09.000Z'
    data:
      edited: false
      editors:
      - teslim007
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6310341954231262
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/01740c13729995ad67483ca49a66e1be.svg
          fullname: Teslim
          isHf: false
          isPro: false
          name: teslim007
          type: user
        html: '<p>Great work! I tried applying the same decoder to a new set of SMILES
          strings (see below) but the reconstructed SMILES are completely different.
          Any idea on how to fine-tune the model for these set of SMILES?</p>

          <p>smiles=[''CC(C)CCCC(C)CCCC(C)CCOC1OC<a rel="nofollow" href="O">C@@H</a><a
          rel="nofollow" href="O">C@@H</a>[C@@H]1O'',<br>''CC(C)CCCC(C)CCCC(C)CCOC1OC<a
          rel="nofollow" href="O">C@@H</a><a rel="nofollow" href="O">C@H</a>[C@@H]1O'',<br>''CC(C)CCCC(C)CCCC(C)CCOC1OC<a
          rel="nofollow" href="O">C@@H</a><a rel="nofollow" href="O">C@H</a>[C@H]1O'',<br>''CC(C)CCCC(C)CCCC(C)CCOC1OC<a
          rel="nofollow" href="O">C@H</a><a rel="nofollow" href="O">C@H</a>[C@H]1O'']</p>

          '
        raw: "Great work! I tried applying the same decoder to a new set of SMILES\
          \ strings (see below) but the reconstructed SMILES are completely different.\
          \ Any idea on how to fine-tune the model for these set of SMILES?\r\n\r\n\
          smiles=['CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H](O)[C@@H](O)[C@@H]1O',\r\n'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H](O)[C@H](O)[C@@H]1O',\r\
          \n'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H](O)[C@H](O)[C@H]1O',\r\n'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@H](O)[C@H](O)[C@H]1O']"
        updatedAt: '2023-09-28T17:17:09.415Z'
      numEdits: 0
      reactions: []
    id: 6515b515b26534355cf76e77
    type: comment
  author: teslim007
  content: "Great work! I tried applying the same decoder to a new set of SMILES strings\
    \ (see below) but the reconstructed SMILES are completely different. Any idea\
    \ on how to fine-tune the model for these set of SMILES?\r\n\r\nsmiles=['CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H](O)[C@@H](O)[C@@H]1O',\r\
    \n'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H](O)[C@H](O)[C@@H]1O',\r\n'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H](O)[C@H](O)[C@H]1O',\r\
    \n'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@H](O)[C@H](O)[C@H]1O']"
  created_at: 2023-09-28 16:17:09+00:00
  edited: false
  hidden: false
  id: 6515b515b26534355cf76e77
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a431766edea7ee26aeddd2a1be6ce189.svg
      fullname: Karl
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: entropy
      type: user
    createdAt: '2023-09-28T19:46:56.000Z'
    data:
      edited: false
      editors:
      - entropy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7949659824371338
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a431766edea7ee26aeddd2a1be6ce189.svg
          fullname: Karl
          isHf: false
          isPro: false
          name: entropy
          type: user
        html: "<p>This is an interesting case. First I cleaned up the syntax and canonicalized</p>\n\
          <pre><code class=\"language-python\">raw_smiles = [<span class=\"hljs-string\"\
          >'CC(C)CCCC(C)CCCC(C)CCOC1OCC@@HC@@H[C@@H]1O'</span>,\n              <span\
          \ class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OCC@@HC@H[C@@H]1O'</span>,\n\
          \              <span class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OCC@@HC@H[C@H]1O'</span>,\n\
          \              <span class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OCC@HC@H[C@H]1O'</span>]\n\
          \nsyntax_corrected_smiles = [<span class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H][C@@H][C@@H]1O'</span>,\n\
          \                           <span class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H][C@H][C@@H]1O'</span>,\n\
          \                           <span class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H][C@H][C@H]1O'</span>,\n\
          \                           <span class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@H][C@H][C@H]1O'</span>]\n\
          \ncanonical_corrected_smiles = [<span class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OC[CH][CH][C@@H]1O'</span>,\n\
          \                             <span class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OC[CH][CH][C@@H]1O'</span>,\n\
          \                             <span class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OC[CH][CH][C@H]1O'</span>,\n\
          \                             <span class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OC[CH][CH][C@H]1O'</span>]\n\
          \n<span class=\"hljs-comment\"># `[CH][CH] parses as a carbon with one free\
          \ radical</span>\nradical_removed_smiles = [<span class=\"hljs-string\"\
          >'CC(C)CCCC(C)CCCC(C)CCOC1OCCC[C@@H]1O'</span>,\n                      \
          \       <span class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OCCC[C@@H]1O'</span>,\n\
          \                             <span class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OCCC[C@H]1O'</span>,\n\
          \                             <span class=\"hljs-string\">'CC(C)CCCC(C)CCCC(C)CCOC1OCCC[C@H]1O'</span>]\n\
          </code></pre>\n<p>The cleaned smiles generated more reconstructions that\
          \ are more reasonable but still very wrong</p>\n<pre><code class=\"language-python\"\
          >reconstructed_smiles = [<span class=\"hljs-string\">'CC(C)N(C)CCCN1CCCC[C@@H]1C'</span>,\n\
          \ <span class=\"hljs-string\">'CC(C)N(C)CCCN1CCCC[C@@H]1C'</span>,\n <span\
          \ class=\"hljs-string\">'CC(C)N(C)CCCN1CCCC[C@H]1C'</span>,\n <span class=\"\
          hljs-string\">'CC(C)N(C)CCCN1CCCC[C@H]1C'</span>]\n</code></pre>\n<p>The\
          \ reconstructed smiles show low cosine similarity (<code>[0.6736, 0.6736,\
          \ 0.6770, 0.6770]</code>), suggesting the problem is with the decoder model\
          \ and not the encoder model. The cosine similarity values are notable because\
          \ the test set showed an average cosine similarity of 0.96 for items that\
          \ <em>failed</em> reconstruction.</p>\n<p>The interesting question is where\
          \ the issue comes from. The decoder was only trained on 30m molecules (compared\
          \ to 480m for the encoder), so maybe the answer is \"train more\". Alternatively,\
          \ I searched your compounds against ZINC (training data is from ZINC) and\
          \ didn't find similar results. It's possible the issue is due to data bias\
          \ in ZINC. Your compounds would fall into the <a rel=\"nofollow\" href=\"\
          https://zinc.docking.org/substances/subsets/DK/\">DK</a> tranche for compounds\
          \ with molwt 325-350 and clogP &gt;5. The trance only contains ~100k compounds\
          \ (very small for ZINC), and most of the compounds have a small number of\
          \ rotatable bonds.</p>\n<p>I uploaded two scripts - one for data prep and\
          \ one for training. Try train on your own dataset and see if that improves\
          \ performance.</p>\n"
        raw: "This is an interesting case. First I cleaned up the syntax and canonicalized\n\
          \n```python\nraw_smiles = ['CC(C)CCCC(C)CCCC(C)CCOC1OCC@@HC@@H[C@@H]1O',\n\
          \              'CC(C)CCCC(C)CCCC(C)CCOC1OCC@@HC@H[C@@H]1O',\n          \
          \    'CC(C)CCCC(C)CCCC(C)CCOC1OCC@@HC@H[C@H]1O',\n              'CC(C)CCCC(C)CCCC(C)CCOC1OCC@HC@H[C@H]1O']\n\
          \nsyntax_corrected_smiles = ['CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H][C@@H][C@@H]1O',\n\
          \                           'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H][C@H][C@@H]1O',\n\
          \                           'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H][C@H][C@H]1O',\n\
          \                           'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@H][C@H][C@H]1O']\n\
          \ncanonical_corrected_smiles = ['CC(C)CCCC(C)CCCC(C)CCOC1OC[CH][CH][C@@H]1O',\n\
          \                             'CC(C)CCCC(C)CCCC(C)CCOC1OC[CH][CH][C@@H]1O',\n\
          \                             'CC(C)CCCC(C)CCCC(C)CCOC1OC[CH][CH][C@H]1O',\n\
          \                             'CC(C)CCCC(C)CCCC(C)CCOC1OC[CH][CH][C@H]1O']\n\
          \n# `[CH][CH] parses as a carbon with one free radical\nradical_removed_smiles\
          \ = ['CC(C)CCCC(C)CCCC(C)CCOC1OCCC[C@@H]1O',\n                         \
          \    'CC(C)CCCC(C)CCCC(C)CCOC1OCCC[C@@H]1O',\n                         \
          \    'CC(C)CCCC(C)CCCC(C)CCOC1OCCC[C@H]1O',\n                          \
          \   'CC(C)CCCC(C)CCCC(C)CCOC1OCCC[C@H]1O']\n```\n\nThe cleaned smiles generated\
          \ more reconstructions that are more reasonable but still very wrong\n\n\
          ```python\nreconstructed_smiles = ['CC(C)N(C)CCCN1CCCC[C@@H]1C',\n 'CC(C)N(C)CCCN1CCCC[C@@H]1C',\n\
          \ 'CC(C)N(C)CCCN1CCCC[C@H]1C',\n 'CC(C)N(C)CCCN1CCCC[C@H]1C']\n```\n\nThe\
          \ reconstructed smiles show low cosine similarity (`[0.6736, 0.6736, 0.6770,\
          \ 0.6770]`), suggesting the problem is with the decoder model and not the\
          \ encoder model. The cosine similarity values are notable because the test\
          \ set showed an average cosine similarity of 0.96 for items that _failed_\
          \ reconstruction.\n\nThe interesting question is where the issue comes from.\
          \ The decoder was only trained on 30m molecules (compared to 480m for the\
          \ encoder), so maybe the answer is \"train more\". Alternatively, I searched\
          \ your compounds against ZINC (training data is from ZINC) and didn't find\
          \ similar results. It's possible the issue is due to data bias in ZINC.\
          \ Your compounds would fall into the [DK](https://zinc.docking.org/substances/subsets/DK/)\
          \ tranche for compounds with molwt 325-350 and clogP >5. The trance only\
          \ contains ~100k compounds (very small for ZINC), and most of the compounds\
          \ have a small number of rotatable bonds.\n\nI uploaded two scripts - one\
          \ for data prep and one for training. Try train on your own dataset and\
          \ see if that improves performance.\n\n"
        updatedAt: '2023-09-28T19:46:56.184Z'
      numEdits: 0
      reactions: []
    id: 6515d830c979eb9ca72d1ade
    type: comment
  author: entropy
  content: "This is an interesting case. First I cleaned up the syntax and canonicalized\n\
    \n```python\nraw_smiles = ['CC(C)CCCC(C)CCCC(C)CCOC1OCC@@HC@@H[C@@H]1O',\n   \
    \           'CC(C)CCCC(C)CCCC(C)CCOC1OCC@@HC@H[C@@H]1O',\n              'CC(C)CCCC(C)CCCC(C)CCOC1OCC@@HC@H[C@H]1O',\n\
    \              'CC(C)CCCC(C)CCCC(C)CCOC1OCC@HC@H[C@H]1O']\n\nsyntax_corrected_smiles\
    \ = ['CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H][C@@H][C@@H]1O',\n                     \
    \      'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H][C@H][C@@H]1O',\n                    \
    \       'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@@H][C@H][C@H]1O',\n                    \
    \       'CC(C)CCCC(C)CCCC(C)CCOC1OC[C@H][C@H][C@H]1O']\n\ncanonical_corrected_smiles\
    \ = ['CC(C)CCCC(C)CCCC(C)CCOC1OC[CH][CH][C@@H]1O',\n                         \
    \    'CC(C)CCCC(C)CCCC(C)CCOC1OC[CH][CH][C@@H]1O',\n                         \
    \    'CC(C)CCCC(C)CCCC(C)CCOC1OC[CH][CH][C@H]1O',\n                          \
    \   'CC(C)CCCC(C)CCCC(C)CCOC1OC[CH][CH][C@H]1O']\n\n# `[CH][CH] parses as a carbon\
    \ with one free radical\nradical_removed_smiles = ['CC(C)CCCC(C)CCCC(C)CCOC1OCCC[C@@H]1O',\n\
    \                             'CC(C)CCCC(C)CCCC(C)CCOC1OCCC[C@@H]1O',\n      \
    \                       'CC(C)CCCC(C)CCCC(C)CCOC1OCCC[C@H]1O',\n             \
    \                'CC(C)CCCC(C)CCCC(C)CCOC1OCCC[C@H]1O']\n```\n\nThe cleaned smiles\
    \ generated more reconstructions that are more reasonable but still very wrong\n\
    \n```python\nreconstructed_smiles = ['CC(C)N(C)CCCN1CCCC[C@@H]1C',\n 'CC(C)N(C)CCCN1CCCC[C@@H]1C',\n\
    \ 'CC(C)N(C)CCCN1CCCC[C@H]1C',\n 'CC(C)N(C)CCCN1CCCC[C@H]1C']\n```\n\nThe reconstructed\
    \ smiles show low cosine similarity (`[0.6736, 0.6736, 0.6770, 0.6770]`), suggesting\
    \ the problem is with the decoder model and not the encoder model. The cosine\
    \ similarity values are notable because the test set showed an average cosine\
    \ similarity of 0.96 for items that _failed_ reconstruction.\n\nThe interesting\
    \ question is where the issue comes from. The decoder was only trained on 30m\
    \ molecules (compared to 480m for the encoder), so maybe the answer is \"train\
    \ more\". Alternatively, I searched your compounds against ZINC (training data\
    \ is from ZINC) and didn't find similar results. It's possible the issue is due\
    \ to data bias in ZINC. Your compounds would fall into the [DK](https://zinc.docking.org/substances/subsets/DK/)\
    \ tranche for compounds with molwt 325-350 and clogP >5. The trance only contains\
    \ ~100k compounds (very small for ZINC), and most of the compounds have a small\
    \ number of rotatable bonds.\n\nI uploaded two scripts - one for data prep and\
    \ one for training. Try train on your own dataset and see if that improves performance.\n\
    \n"
  created_at: 2023-09-28 18:46:56+00:00
  edited: false
  hidden: false
  id: 6515d830c979eb9ca72d1ade
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/01740c13729995ad67483ca49a66e1be.svg
      fullname: Teslim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: teslim007
      type: user
    createdAt: '2023-09-28T20:33:06.000Z'
    data:
      edited: false
      editors:
      - teslim007
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9489861726760864
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/01740c13729995ad67483ca49a66e1be.svg
          fullname: Teslim
          isHf: false
          isPro: false
          name: teslim007
          type: user
        html: '<p>Thank you for the prompt response. I had suspected that the error
          might originate from the decoder model. As suggested, I will retrain the
          model and assess the performance.</p>

          '
        raw: Thank you for the prompt response. I had suspected that the error might
          originate from the decoder model. As suggested, I will retrain the model
          and assess the performance.
        updatedAt: '2023-09-28T20:33:06.003Z'
      numEdits: 0
      reactions: []
    id: 6515e3028a8269300daaf390
    type: comment
  author: teslim007
  content: Thank you for the prompt response. I had suspected that the error might
    originate from the decoder model. As suggested, I will retrain the model and assess
    the performance.
  created_at: 2023-09-28 19:33:06+00:00
  edited: false
  hidden: false
  id: 6515e3028a8269300daaf390
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: entropy/roberta_zinc_decoder
repo_type: model
status: open
target_branch: null
title: Reconstruct Failed for new SMILES
