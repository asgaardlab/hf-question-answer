!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jordanparker6
conflicting_files: null
created_at: 2022-07-17 05:20:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/45e4d1df776b554d416474eb5245074e.svg
      fullname: Jordan Parker
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jordanparker6
      type: user
    createdAt: '2022-07-17T06:20:36.000Z'
    data:
      edited: false
      editors:
      - jordanparker6
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/45e4d1df776b554d416474eb5245074e.svg
          fullname: Jordan Parker
          isHf: false
          isPro: false
          name: jordanparker6
          type: user
        html: '<p>Thanks for uploading this.</p>

          <p>Unfortunately, I am getting the following error. I can see there is a
          model_final.pth but it doesn''t seem to work with AutoModel.</p>

          <p>OSError: HYPJUDY/layoutlmv3-base-finetuned-publaynet does not appear
          to have a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.</p>

          '
        raw: "Thanks for uploading this.\r\n\r\nUnfortunately, I am getting the following\
          \ error. I can see there is a model_final.pth but it doesn't seem to work\
          \ with AutoModel.\r\n\r\nOSError: HYPJUDY/layoutlmv3-base-finetuned-publaynet\
          \ does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt\
          \ or flax_model.msgpack."
        updatedAt: '2022-07-17T06:20:36.760Z'
      numEdits: 0
      reactions: []
    id: 62d3aa34c85b0fcf7fd80770
    type: comment
  author: jordanparker6
  content: "Thanks for uploading this.\r\n\r\nUnfortunately, I am getting the following\
    \ error. I can see there is a model_final.pth but it doesn't seem to work with\
    \ AutoModel.\r\n\r\nOSError: HYPJUDY/layoutlmv3-base-finetuned-publaynet does\
    \ not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt or\
    \ flax_model.msgpack."
  created_at: 2022-07-17 05:20:36+00:00
  edited: false
  hidden: false
  id: 62d3aa34c85b0fcf7fd80770
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fffae710e290125eb648a473a4d7987e.svg
      fullname: Louis De Neve
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: louisdeneve
      type: user
    createdAt: '2022-07-26T14:15:16.000Z'
    data:
      edited: false
      editors:
      - louisdeneve
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fffae710e290125eb648a473a4d7987e.svg
          fullname: Louis De Neve
          isHf: false
          isPro: false
          name: louisdeneve
          type: user
        html: '<p>I have the same problem, also tried to download the model and load
          it locally but didn''t help</p>

          '
        raw: I have the same problem, also tried to download the model and load it
          locally but didn't help
        updatedAt: '2022-07-26T14:15:16.682Z'
      numEdits: 0
      reactions: []
    id: 62dff6f4f5ee5ea3eea50f38
    type: comment
  author: louisdeneve
  content: I have the same problem, also tried to download the model and load it locally
    but didn't help
  created_at: 2022-07-26 13:15:16+00:00
  edited: false
  hidden: false
  id: 62dff6f4f5ee5ea3eea50f38
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3083ebe0343a03332b15f0e7f76ba1d7.svg
      fullname: Yupan Huang
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: HYPJUDY
      type: user
    createdAt: '2022-07-31T05:38:14.000Z'
    data:
      edited: false
      editors:
      - HYPJUDY
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3083ebe0343a03332b15f0e7f76ba1d7.svg
          fullname: Yupan Huang
          isHf: false
          isPro: false
          name: HYPJUDY
          type: user
        html: '<p>Sorry for the confusion. I uploaded these models to support the
          usage in <a rel="nofollow" href="https://github.com/microsoft/unilm/tree/master/layoutlmv3#document-layout-analysis-on-publaynet">https://github.com/microsoft/unilm/tree/master/layoutlmv3#document-layout-analysis-on-publaynet</a>,
          which may not be compatible with AutoModel.</p>

          '
        raw: Sorry for the confusion. I uploaded these models to support the usage
          in https://github.com/microsoft/unilm/tree/master/layoutlmv3#document-layout-analysis-on-publaynet,
          which may not be compatible with AutoModel.
        updatedAt: '2022-07-31T05:38:14.766Z'
      numEdits: 0
      reactions: []
    id: 62e615469cf137377d1fa02f
    type: comment
  author: HYPJUDY
  content: Sorry for the confusion. I uploaded these models to support the usage in
    https://github.com/microsoft/unilm/tree/master/layoutlmv3#document-layout-analysis-on-publaynet,
    which may not be compatible with AutoModel.
  created_at: 2022-07-31 04:38:14+00:00
  edited: false
  hidden: false
  id: 62e615469cf137377d1fa02f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/54da579f714424834e0c762507fdf529.svg
      fullname: Debopriya Ghosh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DGHOSH
      type: user
    createdAt: '2023-01-30T16:53:48.000Z'
    data:
      edited: false
      editors:
      - DGHOSH
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/54da579f714424834e0c762507fdf529.svg
          fullname: Debopriya Ghosh
          isHf: false
          isPro: false
          name: DGHOSH
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;HYPJUDY&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/HYPJUDY\">@<span class=\"\
          underline\">HYPJUDY</span></a></span>\n\n\t</span></span>  Could you please\
          \ give some example of how to use \"HYPJUDY/layoutlmv3-base-finetuned-publaynet\"\
          \ pre-trained model for taking inference i.e., detect layouts from custom\
          \ document's image as it is not compatible with AutoModel I cannot use this\
          \ this. </p>\n<p>I was trying below code for using this pre-trained model,\
          \ but getting some error.</p>\n<p>from unilm.layoutlmv3.layoutlmft.models.layoutlmv3\
          \ import LayoutLMv3Model<br>from unilm.layoutlmv3.examples.object_detection.ditod.config\
          \ import add_vit_config<br>import torch<br>from detectron2.config import\
          \ CfgNode as CN<br>from detectron2.config import get_cfg<br>from detectron2.utils.visualizer\
          \ import ColorMode, Visualizer<br>from detectron2.data import MetadataCatalog<br>from\
          \ detectron2.engine import DefaultPredictor</p>\n<h1 id=\"step-1-instantiate-config\"\
          >Step 1: instantiate config</h1>\n<p>cfg = get_cfg()<br>add_vit_config(cfg)<br>cfg.merge_from_file(\"\
          /content/unilm/layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml\"\
          )</p>\n<h1 id=\"step-2-add-model-weights-url-to-config\">Step 2: add model\
          \ weights URL to config</h1>\n<p>cfg.MODEL.WEIGHTS = \"./content/drive/MyDrive/model_final.pth\"\
          </p>\n<h1 id=\"step-3-set-device\">Step 3: set device</h1>\n<p>cfg.MODEL.DEVICE\
          \ = \"cuda\" if torch.cuda.is_available() else \"cpu\"</p>\n<h1 id=\"step-4-define-model\"\
          >Step 4: define model</h1>\n<p>predictor = DefaultPredictor(cfg)</p>\n<hr>\n\
          <h2 id=\"--this-step-is-giving-error\"> -&gt; This step is giving error.....</h2>\n\
          <p>ValueError                                Traceback (most recent call\
          \ last)<br> in <br>      3<br>      4 # Step 4: define model<br>----&gt;\
          \ 5 predictor = DefaultPredictor(cfg)</p>\n<p>8 frames<br>/usr/local/lib/python3.8/dist-packages/detectron2/engine/defaults.py\
          \ in <strong>init</strong>(self, cfg)<br>    280     def <strong>init</strong>(self,\
          \ cfg):<br>    281         self.cfg = cfg.clone()  # cfg can be modified\
          \ by model<br>--&gt; 282         self.model = build_model(self.cfg)<br>\
          \    283         self.model.eval()<br>    284         if len(cfg.DATASETS.TEST):</p>\n\
          <p>/usr/local/lib/python3.8/dist-packages/detectron2/modeling/meta_arch/build.py\
          \ in build_model(cfg)<br>     20     \"\"\"<br>     21     meta_arch = cfg.MODEL.META_ARCHITECTURE<br>---&gt;\
          \ 22     model = META_ARCH_REGISTRY.get(meta_arch)(cfg)<br>     23     model.to(torch.device(cfg.MODEL.DEVICE))<br>\
          \     24     _log_api_usage(\"modeling.meta_arch.\" + meta_arch)</p>\n<p>/usr/local/lib/python3.8/dist-packages/detectron2/config/config.py\
          \ in wrapped(self, *args, **kwargs)<br>    187<br>    188             if\
          \ _called_with_cfg(*args, **kwargs):<br>--&gt; 189                 explicit_args\
          \ = _get_args_from_config(from_config_func, *args, **kwargs)<br>    190\
          \                 init_func(self, **explicit_args)<br>    191          \
          \   else:</p>\n<p>/usr/local/lib/python3.8/dist-packages/detectron2/config/config.py\
          \ in _get_args_from_config(from_config_func, *args, **kwargs)<br>    243\
          \             if name not in supported_arg_names:<br>    244           \
          \      extra_kwargs[name] = kwargs.pop(name)<br>--&gt; 245         ret =\
          \ from_config_func(*args, **kwargs)<br>    246         # forward the other\
          \ arguments to <strong>init</strong><br>    247         ret.update(extra_kwargs)</p>\n\
          <p>/usr/local/lib/python3.8/dist-packages/detectron2/modeling/meta_arch/rcnn.py\
          \ in from_config(cls, cfg)<br>     70     @classmethod<br>     71     def\
          \ from_config(cls, cfg):<br>---&gt; 72         backbone = build_backbone(cfg)<br>\
          \     73         return {<br>     74             \"backbone\": backbone,</p>\n\
          <p>/usr/local/lib/python3.8/dist-packages/detectron2/modeling/backbone/build.py\
          \ in build_backbone(cfg, input_shape)<br>     29<br>     30     backbone_name\
          \ = cfg.MODEL.BACKBONE.NAME<br>---&gt; 31     backbone = BACKBONE_REGISTRY.get(backbone_name)(cfg,\
          \ input_shape)<br>     32     assert isinstance(backbone, Backbone)<br>\
          \     33     return backbone</p>\n<p>/content/unilm/dit/object_detection/ditod/backbone.py\
          \ in build_vit_fpn_backbone(cfg, input_shape)<br>    143         backbone\
          \ (Backbone): backbone module, must be a subclass of :class:<code>Backbone</code>.<br>\
          \    144     \"\"\"<br>--&gt; 145     bottom_up = build_VIT_backbone(cfg)<br>\
          \    146     in_features = cfg.MODEL.FPN.IN_FEATURES<br>    147     out_channels\
          \ = cfg.MODEL.FPN.OUT_CHANNELS</p>\n<p>/content/unilm/dit/object_detection/ditod/backbone.py\
          \ in build_VIT_backbone(cfg)<br>    129     model_kwargs = eval(str(cfg.MODEL.VIT.MODEL_KWARGS).replace(\"\
          `\", \"\"))<br>    130<br>--&gt; 131     return VIT_Backbone(name, out_features,\
          \ drop_path, img_size, pos_type, model_kwargs)<br>    132<br>    133 </p>\n\
          <p>/content/unilm/dit/object_detection/ditod/backbone.py in <strong>init</strong>(self,\
          \ name, out_features, drop_path, img_size, pos_type, model_kwargs)<br> \
          \    61             self._out_feature_channels = {\"layer7\": 1024, \"layer11\"\
          : 1024, \"layer15\": 1024, \"layer23\": 1024}<br>     62         else:<br>---&gt;\
          \ 63             raise ValueError(\"Unsupported VIT name yet.\")<br>   \
          \  64<br>     65         if 'beit' in name or 'dit' in name:</p>\n<p>ValueError:\
          \ Unsupported VIT name yet.</p>\n<p>Could you please help me to resolve\
          \ this.</p>\n"
        raw: "@HYPJUDY  Could you please give some example of how to use \"HYPJUDY/layoutlmv3-base-finetuned-publaynet\"\
          \ pre-trained model for taking inference i.e., detect layouts from custom\
          \ document's image as it is not compatible with AutoModel I cannot use this\
          \ this. \n\nI was trying below code for using this pre-trained model, but\
          \ getting some error.\n\nfrom unilm.layoutlmv3.layoutlmft.models.layoutlmv3\
          \ import LayoutLMv3Model\nfrom unilm.layoutlmv3.examples.object_detection.ditod.config\
          \ import add_vit_config\nimport torch\nfrom detectron2.config import CfgNode\
          \ as CN\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer\
          \ import ColorMode, Visualizer\nfrom detectron2.data import MetadataCatalog\n\
          from detectron2.engine import DefaultPredictor\n\n# Step 1: instantiate\
          \ config\ncfg = get_cfg()\nadd_vit_config(cfg)\ncfg.merge_from_file(\"/content/unilm/layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml\"\
          )\n\n# Step 2: add model weights URL to config\ncfg.MODEL.WEIGHTS = \"./content/drive/MyDrive/model_final.pth\"\
          \n\n# Step 3: set device\ncfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available()\
          \ else \"cpu\"\n\n# Step 4: define model\npredictor = DefaultPredictor(cfg)\n\
          \n\n________________________________________________________________\n ->\
          \ This step is giving error.....\n---------------------------------------------------------------------------\n\
          ValueError                                Traceback (most recent call last)\n\
          <ipython-input-46-b96219b982db> in <module>\n      3 \n      4 # Step 4:\
          \ define model\n----> 5 predictor = DefaultPredictor(cfg)\n\n8 frames\n\
          /usr/local/lib/python3.8/dist-packages/detectron2/engine/defaults.py in\
          \ __init__(self, cfg)\n    280     def __init__(self, cfg):\n    281   \
          \      self.cfg = cfg.clone()  # cfg can be modified by model\n--> 282 \
          \        self.model = build_model(self.cfg)\n    283         self.model.eval()\n\
          \    284         if len(cfg.DATASETS.TEST):\n\n/usr/local/lib/python3.8/dist-packages/detectron2/modeling/meta_arch/build.py\
          \ in build_model(cfg)\n     20     \"\"\"\n     21     meta_arch = cfg.MODEL.META_ARCHITECTURE\n\
          ---> 22     model = META_ARCH_REGISTRY.get(meta_arch)(cfg)\n     23    \
          \ model.to(torch.device(cfg.MODEL.DEVICE))\n     24     _log_api_usage(\"\
          modeling.meta_arch.\" + meta_arch)\n\n/usr/local/lib/python3.8/dist-packages/detectron2/config/config.py\
          \ in wrapped(self, *args, **kwargs)\n    187 \n    188             if _called_with_cfg(*args,\
          \ **kwargs):\n--> 189                 explicit_args = _get_args_from_config(from_config_func,\
          \ *args, **kwargs)\n    190                 init_func(self, **explicit_args)\n\
          \    191             else:\n\n/usr/local/lib/python3.8/dist-packages/detectron2/config/config.py\
          \ in _get_args_from_config(from_config_func, *args, **kwargs)\n    243 \
          \            if name not in supported_arg_names:\n    244              \
          \   extra_kwargs[name] = kwargs.pop(name)\n--> 245         ret = from_config_func(*args,\
          \ **kwargs)\n    246         # forward the other arguments to __init__\n\
          \    247         ret.update(extra_kwargs)\n\n/usr/local/lib/python3.8/dist-packages/detectron2/modeling/meta_arch/rcnn.py\
          \ in from_config(cls, cfg)\n     70     @classmethod\n     71     def from_config(cls,\
          \ cfg):\n---> 72         backbone = build_backbone(cfg)\n     73       \
          \  return {\n     74             \"backbone\": backbone,\n\n/usr/local/lib/python3.8/dist-packages/detectron2/modeling/backbone/build.py\
          \ in build_backbone(cfg, input_shape)\n     29 \n     30     backbone_name\
          \ = cfg.MODEL.BACKBONE.NAME\n---> 31     backbone = BACKBONE_REGISTRY.get(backbone_name)(cfg,\
          \ input_shape)\n     32     assert isinstance(backbone, Backbone)\n    \
          \ 33     return backbone\n\n/content/unilm/dit/object_detection/ditod/backbone.py\
          \ in build_vit_fpn_backbone(cfg, input_shape)\n    143         backbone\
          \ (Backbone): backbone module, must be a subclass of :class:`Backbone`.\n\
          \    144     \"\"\"\n--> 145     bottom_up = build_VIT_backbone(cfg)\n \
          \   146     in_features = cfg.MODEL.FPN.IN_FEATURES\n    147     out_channels\
          \ = cfg.MODEL.FPN.OUT_CHANNELS\n\n/content/unilm/dit/object_detection/ditod/backbone.py\
          \ in build_VIT_backbone(cfg)\n    129     model_kwargs = eval(str(cfg.MODEL.VIT.MODEL_KWARGS).replace(\"\
          `\", \"\"))\n    130 \n--> 131     return VIT_Backbone(name, out_features,\
          \ drop_path, img_size, pos_type, model_kwargs)\n    132 \n    133 \n\n/content/unilm/dit/object_detection/ditod/backbone.py\
          \ in __init__(self, name, out_features, drop_path, img_size, pos_type, model_kwargs)\n\
          \     61             self._out_feature_channels = {\"layer7\": 1024, \"\
          layer11\": 1024, \"layer15\": 1024, \"layer23\": 1024}\n     62        \
          \ else:\n---> 63             raise ValueError(\"Unsupported VIT name yet.\"\
          )\n     64 \n     65         if 'beit' in name or 'dit' in name:\n\nValueError:\
          \ Unsupported VIT name yet.\n\n\nCould you please help me to resolve this."
        updatedAt: '2023-01-30T16:53:48.975Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - Corran
        - nloc2578
        - MLLife
    id: 63d7f61c5ccb2bccedb6c04d
    type: comment
  author: DGHOSH
  content: "@HYPJUDY  Could you please give some example of how to use \"HYPJUDY/layoutlmv3-base-finetuned-publaynet\"\
    \ pre-trained model for taking inference i.e., detect layouts from custom document's\
    \ image as it is not compatible with AutoModel I cannot use this this. \n\nI was\
    \ trying below code for using this pre-trained model, but getting some error.\n\
    \nfrom unilm.layoutlmv3.layoutlmft.models.layoutlmv3 import LayoutLMv3Model\n\
    from unilm.layoutlmv3.examples.object_detection.ditod.config import add_vit_config\n\
    import torch\nfrom detectron2.config import CfgNode as CN\nfrom detectron2.config\
    \ import get_cfg\nfrom detectron2.utils.visualizer import ColorMode, Visualizer\n\
    from detectron2.data import MetadataCatalog\nfrom detectron2.engine import DefaultPredictor\n\
    \n# Step 1: instantiate config\ncfg = get_cfg()\nadd_vit_config(cfg)\ncfg.merge_from_file(\"\
    /content/unilm/layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml\"\
    )\n\n# Step 2: add model weights URL to config\ncfg.MODEL.WEIGHTS = \"./content/drive/MyDrive/model_final.pth\"\
    \n\n# Step 3: set device\ncfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available()\
    \ else \"cpu\"\n\n# Step 4: define model\npredictor = DefaultPredictor(cfg)\n\n\
    \n________________________________________________________________\n -> This step\
    \ is giving error.....\n---------------------------------------------------------------------------\n\
    ValueError                                Traceback (most recent call last)\n\
    <ipython-input-46-b96219b982db> in <module>\n      3 \n      4 # Step 4: define\
    \ model\n----> 5 predictor = DefaultPredictor(cfg)\n\n8 frames\n/usr/local/lib/python3.8/dist-packages/detectron2/engine/defaults.py\
    \ in __init__(self, cfg)\n    280     def __init__(self, cfg):\n    281      \
    \   self.cfg = cfg.clone()  # cfg can be modified by model\n--> 282         self.model\
    \ = build_model(self.cfg)\n    283         self.model.eval()\n    284        \
    \ if len(cfg.DATASETS.TEST):\n\n/usr/local/lib/python3.8/dist-packages/detectron2/modeling/meta_arch/build.py\
    \ in build_model(cfg)\n     20     \"\"\"\n     21     meta_arch = cfg.MODEL.META_ARCHITECTURE\n\
    ---> 22     model = META_ARCH_REGISTRY.get(meta_arch)(cfg)\n     23     model.to(torch.device(cfg.MODEL.DEVICE))\n\
    \     24     _log_api_usage(\"modeling.meta_arch.\" + meta_arch)\n\n/usr/local/lib/python3.8/dist-packages/detectron2/config/config.py\
    \ in wrapped(self, *args, **kwargs)\n    187 \n    188             if _called_with_cfg(*args,\
    \ **kwargs):\n--> 189                 explicit_args = _get_args_from_config(from_config_func,\
    \ *args, **kwargs)\n    190                 init_func(self, **explicit_args)\n\
    \    191             else:\n\n/usr/local/lib/python3.8/dist-packages/detectron2/config/config.py\
    \ in _get_args_from_config(from_config_func, *args, **kwargs)\n    243       \
    \      if name not in supported_arg_names:\n    244                 extra_kwargs[name]\
    \ = kwargs.pop(name)\n--> 245         ret = from_config_func(*args, **kwargs)\n\
    \    246         # forward the other arguments to __init__\n    247         ret.update(extra_kwargs)\n\
    \n/usr/local/lib/python3.8/dist-packages/detectron2/modeling/meta_arch/rcnn.py\
    \ in from_config(cls, cfg)\n     70     @classmethod\n     71     def from_config(cls,\
    \ cfg):\n---> 72         backbone = build_backbone(cfg)\n     73         return\
    \ {\n     74             \"backbone\": backbone,\n\n/usr/local/lib/python3.8/dist-packages/detectron2/modeling/backbone/build.py\
    \ in build_backbone(cfg, input_shape)\n     29 \n     30     backbone_name = cfg.MODEL.BACKBONE.NAME\n\
    ---> 31     backbone = BACKBONE_REGISTRY.get(backbone_name)(cfg, input_shape)\n\
    \     32     assert isinstance(backbone, Backbone)\n     33     return backbone\n\
    \n/content/unilm/dit/object_detection/ditod/backbone.py in build_vit_fpn_backbone(cfg,\
    \ input_shape)\n    143         backbone (Backbone): backbone module, must be\
    \ a subclass of :class:`Backbone`.\n    144     \"\"\"\n--> 145     bottom_up\
    \ = build_VIT_backbone(cfg)\n    146     in_features = cfg.MODEL.FPN.IN_FEATURES\n\
    \    147     out_channels = cfg.MODEL.FPN.OUT_CHANNELS\n\n/content/unilm/dit/object_detection/ditod/backbone.py\
    \ in build_VIT_backbone(cfg)\n    129     model_kwargs = eval(str(cfg.MODEL.VIT.MODEL_KWARGS).replace(\"\
    `\", \"\"))\n    130 \n--> 131     return VIT_Backbone(name, out_features, drop_path,\
    \ img_size, pos_type, model_kwargs)\n    132 \n    133 \n\n/content/unilm/dit/object_detection/ditod/backbone.py\
    \ in __init__(self, name, out_features, drop_path, img_size, pos_type, model_kwargs)\n\
    \     61             self._out_feature_channels = {\"layer7\": 1024, \"layer11\"\
    : 1024, \"layer15\": 1024, \"layer23\": 1024}\n     62         else:\n---> 63\
    \             raise ValueError(\"Unsupported VIT name yet.\")\n     64 \n    \
    \ 65         if 'beit' in name or 'dit' in name:\n\nValueError: Unsupported VIT\
    \ name yet.\n\n\nCould you please help me to resolve this."
  created_at: 2023-01-30 16:53:48+00:00
  edited: false
  hidden: false
  id: 63d7f61c5ccb2bccedb6c04d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/16c9a338485192cfca3aadaeffb19c86.svg
      fullname: Yi He
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: superbean
      type: user
    createdAt: '2023-02-18T20:25:19.000Z'
    data:
      edited: false
      editors:
      - superbean
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/16c9a338485192cfca3aadaeffb19c86.svg
          fullname: Yi He
          isHf: false
          isPro: false
          name: superbean
          type: user
        html: '<p>I made it work by combing content found from another example here:
          <a href="https://huggingface.co/spaces/nielsr/dit-document-layout-analysis/blob/main/app.py">https://huggingface.co/spaces/nielsr/dit-document-layout-analysis/blob/main/app.py</a></p>

          <p>You will need to adjust some code/setting in the example as it was about
          Dit and you want to use LayoutLMv3 here. But both are for document layout
          analysis tasks so the steps are the same and you only need to swap in parts
          from LayoutLM.</p>

          '
        raw: 'I made it work by combing content found from another example here: https://huggingface.co/spaces/nielsr/dit-document-layout-analysis/blob/main/app.py


          You will need to adjust some code/setting in the example as it was about
          Dit and you want to use LayoutLMv3 here. But both are for document layout
          analysis tasks so the steps are the same and you only need to swap in parts
          from LayoutLM.'
        updatedAt: '2023-02-18T20:25:19.664Z'
      numEdits: 0
      reactions: []
    id: 63f1342fcbadc519b8594fb9
    type: comment
  author: superbean
  content: 'I made it work by combing content found from another example here: https://huggingface.co/spaces/nielsr/dit-document-layout-analysis/blob/main/app.py


    You will need to adjust some code/setting in the example as it was about Dit and
    you want to use LayoutLMv3 here. But both are for document layout analysis tasks
    so the steps are the same and you only need to swap in parts from LayoutLM.'
  created_at: 2023-02-18 20:25:19+00:00
  edited: false
  hidden: false
  id: 63f1342fcbadc519b8594fb9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672241196742-noauth.png?w=200&h=200&f=face
      fullname: Dominik Macko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dmacko232
      type: user
    createdAt: '2023-02-21T13:55:56.000Z'
    data:
      edited: false
      editors:
      - dmacko232
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672241196742-noauth.png?w=200&h=200&f=face
          fullname: Dominik Macko
          isHf: false
          isPro: false
          name: dmacko232
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;superbean&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/superbean\">@<span class=\"\
          underline\">superbean</span></a></span>\n\n\t</span></span><br>Could you\
          \ please provide code how u changed the code to work with this layoutLM\
          \ model? I am struggling with this and it would be very helpful!</p>\n"
        raw: "@superbean \nCould you please provide code how u changed the code to\
          \ work with this layoutLM model? I am struggling with this and it would\
          \ be very helpful!"
        updatedAt: '2023-02-21T13:55:56.275Z'
      numEdits: 0
      reactions: []
    id: 63f4cd6c55a70e9901e24660
    type: comment
  author: dmacko232
  content: "@superbean \nCould you please provide code how u changed the code to work\
    \ with this layoutLM model? I am struggling with this and it would be very helpful!"
  created_at: 2023-02-21 13:55:56+00:00
  edited: false
  hidden: false
  id: 63f4cd6c55a70e9901e24660
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/16c9a338485192cfca3aadaeffb19c86.svg
      fullname: Yi He
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: superbean
      type: user
    createdAt: '2023-02-21T14:03:03.000Z'
    data:
      edited: false
      editors:
      - superbean
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/16c9a338485192cfca3aadaeffb19c86.svg
          fullname: Yi He
          isHf: false
          isPro: false
          name: superbean
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;dmacko232&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/dmacko232\">@<span class=\"\
          underline\">dmacko232</span></a></span>\n\n\t</span></span> , you can probably\
          \ have a look at this example: <a rel=\"nofollow\" href=\"https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py\"\
          >https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py</a><br>I\
          \ did pretty much the same thing.</p>\n<p>And you will need ALL layoutlmv3\
          \ (model, configuration, tokenizer and more) implementation from the official\
          \ unilm repo here (<a rel=\"nofollow\" href=\"https://github.com/microsoft/unilm/tree/master/layoutlmv3/layoutlmft/models/layoutlmv3\"\
          >https://github.com/microsoft/unilm/tree/master/layoutlmv3/layoutlmft/models/layoutlmv3</a>),\
          \ and NOT the one from latest huggingface transformers library. (Because\
          \ the implementation is slightly different even though they do overlap completely\
          \ with the class names, etc.)</p>\n"
        raw: '@dmacko232 , you can probably have a look at this example: https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py

          I did pretty much the same thing.


          And you will need ALL layoutlmv3 (model, configuration, tokenizer and more)
          implementation from the official unilm repo here (https://github.com/microsoft/unilm/tree/master/layoutlmv3/layoutlmft/models/layoutlmv3),
          and NOT the one from latest huggingface transformers library. (Because the
          implementation is slightly different even though they do overlap completely
          with the class names, etc.)'
        updatedAt: '2023-02-21T14:03:03.131Z'
      numEdits: 0
      reactions: []
    id: 63f4cf179801da0debf0d9fc
    type: comment
  author: superbean
  content: '@dmacko232 , you can probably have a look at this example: https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py

    I did pretty much the same thing.


    And you will need ALL layoutlmv3 (model, configuration, tokenizer and more) implementation
    from the official unilm repo here (https://github.com/microsoft/unilm/tree/master/layoutlmv3/layoutlmft/models/layoutlmv3),
    and NOT the one from latest huggingface transformers library. (Because the implementation
    is slightly different even though they do overlap completely with the class names,
    etc.)'
  created_at: 2023-02-21 14:03:03+00:00
  edited: false
  hidden: false
  id: 63f4cf179801da0debf0d9fc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3d1cdc15a0e831deaeb426674c8c793e.svg
      fullname: jb
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jiboncom
      type: user
    createdAt: '2023-03-26T15:40:00.000Z'
    data:
      edited: false
      editors:
      - jiboncom
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3d1cdc15a0e831deaeb426674c8c793e.svg
          fullname: jb
          isHf: false
          isPro: false
          name: jiboncom
          type: user
        html: "<p>Downloading the repo and changing the name of the file worked for\
          \ me:</p>\n<pre><code class=\"language-python\"><span class=\"hljs-comment\"\
          ># Load the model from HuggingFace</span>\n!git lfs install\n!git clone\
          \ https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet\n!mv\
          \ layoutlmv3-base-finetuned-publaynet/model_final.pth layoutlmv3-base-finetuned-publaynet/pytorch_model.<span\
          \ class=\"hljs-built_in\">bin</span> \n</code></pre>\n<p>And for processing,\
          \ I used the regular layoutmv3 processor<br><code>processor = AutoProcessor.from_pretrained(\"\
          microsoft/layoutlmv3-base\", apply_ocr=True)</code></p>\n"
        raw: "Downloading the repo and changing the name of the file worked for me:\n\
          \n```python\n# Load the model from HuggingFace\n!git lfs install\n!git clone\
          \ https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet\n!mv\
          \ layoutlmv3-base-finetuned-publaynet/model_final.pth layoutlmv3-base-finetuned-publaynet/pytorch_model.bin\
          \ \n```\n\nAnd for processing, I used the regular layoutmv3 processor\n\
          `processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\"\
          , apply_ocr=True)`"
        updatedAt: '2023-03-26T15:40:00.172Z'
      numEdits: 0
      reactions: []
    id: 6420675036e47752c3114631
    type: comment
  author: jiboncom
  content: "Downloading the repo and changing the name of the file worked for me:\n\
    \n```python\n# Load the model from HuggingFace\n!git lfs install\n!git clone https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet\n\
    !mv layoutlmv3-base-finetuned-publaynet/model_final.pth layoutlmv3-base-finetuned-publaynet/pytorch_model.bin\
    \ \n```\n\nAnd for processing, I used the regular layoutmv3 processor\n`processor\
    \ = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=True)`"
  created_at: 2023-03-26 14:40:00+00:00
  edited: false
  hidden: false
  id: 6420675036e47752c3114631
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a23ded6b84f35cb8803dace63f1efb3f.svg
      fullname: ml life
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MLLife
      type: user
    createdAt: '2023-06-28T08:27:06.000Z'
    data:
      edited: true
      editors:
      - MLLife
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9424076080322266
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a23ded6b84f35cb8803dace63f1efb3f.svg
          fullname: ml life
          isHf: false
          isPro: false
          name: MLLife
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;superbean&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/superbean\"\
          >@<span class=\"underline\">superbean</span></a></span>\n\n\t</span></span><br>Could\
          \ you please provide code how u changed the code to work with this layoutLM\
          \ model? I am struggling with this and it would be very helpful!</p>\n</blockquote>\n\
          <p><span data-props=\"{&quot;user&quot;:&quot;superbean&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/superbean\">@<span class=\"\
          underline\">superbean</span></a></span>\n\n\t</span></span> <span data-props=\"\
          {&quot;user&quot;:&quot;jiboncom&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/jiboncom\">@<span class=\"underline\">jiboncom</span></a></span>\n\
          \n\t</span></span> <span data-props=\"{&quot;user&quot;:&quot;DGHOSH&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/DGHOSH\"\
          >@<span class=\"underline\">DGHOSH</span></a></span>\n\n\t</span></span>\
          \ <span data-props=\"{&quot;user&quot;:&quot;HYPJUDY&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/HYPJUDY\">@<span class=\"\
          underline\">HYPJUDY</span></a></span>\n\n\t</span></span> , can anyone give\
          \ complete code to work with this, taking image as input and getting labels\
          \ as output with bbox info. or something.</p>\n"
        raw: "> @superbean \n> Could you please provide code how u changed the code\
          \ to work with this layoutLM model? I am struggling with this and it would\
          \ be very helpful!\n\n@superbean @jiboncom @DGHOSH @HYPJUDY , can anyone\
          \ give complete code to work with this, taking image as input and getting\
          \ labels as output with bbox info. or something."
        updatedAt: '2023-06-28T09:19:45.194Z'
      numEdits: 1
      reactions: []
    id: 649beedabbc74ae4d1a04ca5
    type: comment
  author: MLLife
  content: "> @superbean \n> Could you please provide code how u changed the code\
    \ to work with this layoutLM model? I am struggling with this and it would be\
    \ very helpful!\n\n@superbean @jiboncom @DGHOSH @HYPJUDY , can anyone give complete\
    \ code to work with this, taking image as input and getting labels as output with\
    \ bbox info. or something."
  created_at: 2023-06-28 07:27:06+00:00
  edited: true
  hidden: false
  id: 649beedabbc74ae4d1a04ca5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/816f1949d1af627dd82a85156fc105aa.svg
      fullname: Luca De Grandis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Blind2015-private
      type: user
    createdAt: '2023-06-28T14:35:45.000Z'
    data:
      edited: false
      editors:
      - Blind2015-private
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7796010375022888
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/816f1949d1af627dd82a85156fc105aa.svg
          fullname: Luca De Grandis
          isHf: false
          isPro: false
          name: Blind2015-private
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;MLLife&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/MLLife\">@<span class=\"\
          underline\">MLLife</span></a></span>\n\n\t</span></span> as <span data-props=\"\
          {&quot;user&quot;:&quot;superbean&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/superbean\">@<span class=\"underline\">superbean</span></a></span>\n\
          \n\t</span></span> said you can use the script <code>inference.py</code>\
          \ at the link <a rel=\"nofollow\" href=\"https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py\"\
          >https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py</a>\
          \ and substitute the paths to the correct config and model weights. You\
          \ DON'T need to change the script if you only want to visualize the results.\
          \ You will have to modify the script if you need to save the bounding boxes,\
          \ labels, and scores somewhere. All the results can be found in the <code>output</code>\
          \ object at line 67 of the script linked above. You must add some lines\
          \ to save them somewhere. Unfortunately, classes are represented with integers,\
          \ not text labels, so if you know the mapping please let me know.</p>\n\
          <p>Here is an example with the raw inference script:<br><code>python ./dit/object_detection/inference.py\
          \ \\ --image_path path/to/image.jpg \\ --output_file_name path/to/output/image.jpg\
          \ \\ --config ./layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml\
          \ \\ --opts MODEL.WEIGHTS path/to/model.pth</code></p>\n<p>You can find\
          \ the model weights at <a href=\"https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet\"\
          >https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet</a>.\
          \ I hope this is useful.</p>\n"
        raw: '@MLLife as @superbean said you can use the script `inference.py` at
          the link https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py
          and substitute the paths to the correct config and model weights. You DON''T
          need to change the script if you only want to visualize the results. You
          will have to modify the script if you need to save the bounding boxes, labels,
          and scores somewhere. All the results can be found in the `output` object
          at line 67 of the script linked above. You must add some lines to save them
          somewhere. Unfortunately, classes are represented with integers, not text
          labels, so if you know the mapping please let me know.


          Here is an example with the raw inference script:

          `python ./dit/object_detection/inference.py \

          --image_path path/to/image.jpg \

          --output_file_name path/to/output/image.jpg \

          --config ./layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml
          \

          --opts MODEL.WEIGHTS path/to/model.pth`


          You can find the model weights at https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet.
          I hope this is useful.'
        updatedAt: '2023-06-28T14:35:45.672Z'
      numEdits: 0
      reactions: []
    id: 649c4541a83f996b41965649
    type: comment
  author: Blind2015-private
  content: '@MLLife as @superbean said you can use the script `inference.py` at the
    link https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py
    and substitute the paths to the correct config and model weights. You DON''T need
    to change the script if you only want to visualize the results. You will have
    to modify the script if you need to save the bounding boxes, labels, and scores
    somewhere. All the results can be found in the `output` object at line 67 of the
    script linked above. You must add some lines to save them somewhere. Unfortunately,
    classes are represented with integers, not text labels, so if you know the mapping
    please let me know.


    Here is an example with the raw inference script:

    `python ./dit/object_detection/inference.py \

    --image_path path/to/image.jpg \

    --output_file_name path/to/output/image.jpg \

    --config ./layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml \

    --opts MODEL.WEIGHTS path/to/model.pth`


    You can find the model weights at https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet.
    I hope this is useful.'
  created_at: 2023-06-28 13:35:45+00:00
  edited: false
  hidden: false
  id: 649c4541a83f996b41965649
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a23ded6b84f35cb8803dace63f1efb3f.svg
      fullname: ml life
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MLLife
      type: user
    createdAt: '2023-06-28T14:53:27.000Z'
    data:
      edited: false
      editors:
      - MLLife
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8185698390007019
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a23ded6b84f35cb8803dace63f1efb3f.svg
          fullname: ml life
          isHf: false
          isPro: false
          name: MLLife
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Blind2015-private&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Blind2015-private\"\
          >@<span class=\"underline\">Blind2015-private</span></a></span>\n\n\t</span></span>\
          \ , i am able to run the code now, using the code available in spaces app.py;<br>thankfully,\
          \ got the labels for PubLayNet dataset as<br>id2label = {0: \"Text\", 1:\
          \ \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"}</p>\n<p>but the but,\
          \ still output is not what i want.</p>\n<p>LayoutLM model only able to classify\
          \ individual words instead of entire sections.<br>how can i fix that?</p>\n"
        raw: "@Blind2015-private , i am able to run the code now, using the code available\
          \ in spaces app.py; \nthankfully, got the labels for PubLayNet dataset as\n\
          id2label = {0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"\
          Figure\"}\n\nbut the but, still output is not what i want.\n\nLayoutLM model\
          \ only able to classify individual words instead of entire sections.\nhow\
          \ can i fix that?"
        updatedAt: '2023-06-28T14:53:27.218Z'
      numEdits: 0
      reactions: []
    id: 649c4967b17bd9da5e2db1f1
    type: comment
  author: MLLife
  content: "@Blind2015-private , i am able to run the code now, using the code available\
    \ in spaces app.py; \nthankfully, got the labels for PubLayNet dataset as\nid2label\
    \ = {0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"}\n\n\
    but the but, still output is not what i want.\n\nLayoutLM model only able to classify\
    \ individual words instead of entire sections.\nhow can i fix that?"
  created_at: 2023-06-28 13:53:27+00:00
  edited: false
  hidden: false
  id: 649c4967b17bd9da5e2db1f1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/816f1949d1af627dd82a85156fc105aa.svg
      fullname: Luca De Grandis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Blind2015-private
      type: user
    createdAt: '2023-06-28T15:02:25.000Z'
    data:
      edited: false
      editors:
      - Blind2015-private
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9342214465141296
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/816f1949d1af627dd82a85156fc105aa.svg
          fullname: Luca De Grandis
          isHf: false
          isPro: false
          name: Blind2015-private
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;MLLife&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/MLLife\">@<span class=\"\
          underline\">MLLife</span></a></span>\n\n\t</span></span> if the model is\
          \ classifying individual words it is possible that the model is not working\
          \ properly on your data because it is overfitting on the original training\
          \ data. I am using a page of the original paper of layoutlmv3 rescaled so\
          \ that the longer axis is 1000 pixels long and it works fine (meaning that\
          \ it is classifying sections).</p>\n<p>If you want a model that classifies\
          \ individual words, the weights I shared earlier are not appropriate. Unfortunately,\
          \ I wouldn't know how to obtain a more appropriate model checkpoint for\
          \ your use case.</p>\n"
        raw: '@MLLife if the model is classifying individual words it is possible
          that the model is not working properly on your data because it is overfitting
          on the original training data. I am using a page of the original paper of
          layoutlmv3 rescaled so that the longer axis is 1000 pixels long and it works
          fine (meaning that it is classifying sections).


          If you want a model that classifies individual words, the weights I shared
          earlier are not appropriate. Unfortunately, I wouldn''t know how to obtain
          a more appropriate model checkpoint for your use case.'
        updatedAt: '2023-06-28T15:02:25.005Z'
      numEdits: 0
      reactions: []
    id: 649c4b81ff9e9056bed1a307
    type: comment
  author: Blind2015-private
  content: '@MLLife if the model is classifying individual words it is possible that
    the model is not working properly on your data because it is overfitting on the
    original training data. I am using a page of the original paper of layoutlmv3
    rescaled so that the longer axis is 1000 pixels long and it works fine (meaning
    that it is classifying sections).


    If you want a model that classifies individual words, the weights I shared earlier
    are not appropriate. Unfortunately, I wouldn''t know how to obtain a more appropriate
    model checkpoint for your use case.'
  created_at: 2023-06-28 14:02:25+00:00
  edited: false
  hidden: false
  id: 649c4b81ff9e9056bed1a307
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a23ded6b84f35cb8803dace63f1efb3f.svg
      fullname: ml life
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MLLife
      type: user
    createdAt: '2023-06-28T15:15:16.000Z'
    data:
      edited: true
      editors:
      - MLLife
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8330424427986145
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a23ded6b84f35cb8803dace63f1efb3f.svg
          fullname: ml life
          isHf: false
          isPro: false
          name: MLLife
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Blind2015-private&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Blind2015-private\"\
          >@<span class=\"underline\">Blind2015-private</span></a></span>\n\n\t</span></span>\
          \ , can you tell what is the exact image size you use to get section wise\
          \ box labels? also, i found something on github - <a rel=\"nofollow\" href=\"\
          https://github.com/microsoft/unilm/issues/906\">https://github.com/microsoft/unilm/issues/906</a><br>but,\
          \ i don't see any such option in huggingface code<br><span data-props=\"\
          {&quot;user&quot;:&quot;nielsr&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/nielsr\">@<span class=\"underline\">nielsr</span></a></span>\n\
          \n\t</span></span> </p>\n<p>edit: found great article here; <a rel=\"nofollow\"\
          \ href=\"https://github.com/microsoft/unilm/issues/800\">https://github.com/microsoft/unilm/issues/800</a></p>\n"
        raw: "@Blind2015-private , can you tell what is the exact image size you use\
          \ to get section wise box labels? also, i found something on github - https://github.com/microsoft/unilm/issues/906\n\
          but, i don't see any such option in huggingface code\n@nielsr \n\nedit:\
          \ found great article here; https://github.com/microsoft/unilm/issues/800"
        updatedAt: '2023-06-28T15:40:47.137Z'
      numEdits: 2
      reactions: []
    id: 649c4e847e233de34509f345
    type: comment
  author: MLLife
  content: "@Blind2015-private , can you tell what is the exact image size you use\
    \ to get section wise box labels? also, i found something on github - https://github.com/microsoft/unilm/issues/906\n\
    but, i don't see any such option in huggingface code\n@nielsr \n\nedit: found\
    \ great article here; https://github.com/microsoft/unilm/issues/800"
  created_at: 2023-06-28 14:15:16+00:00
  edited: true
  hidden: false
  id: 649c4e847e233de34509f345
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a23ded6b84f35cb8803dace63f1efb3f.svg
      fullname: ml life
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MLLife
      type: user
    createdAt: '2023-06-29T04:08:56.000Z'
    data:
      edited: false
      editors:
      - MLLife
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7759177684783936
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a23ded6b84f35cb8803dace63f1efb3f.svg
          fullname: ml life
          isHf: false
          isPro: false
          name: MLLife
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;MLLife&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/MLLife\"\
          >@<span class=\"underline\">MLLife</span></a></span>\n\n\t</span></span>\
          \ as <span data-props=\"{&quot;user&quot;:&quot;superbean&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/superbean\">@<span class=\"\
          underline\">superbean</span></a></span>\n\n\t</span></span> said you can\
          \ use the script <code>inference.py</code> at the link <a rel=\"nofollow\"\
          \ href=\"https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py\"\
          >https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py</a>\
          \ and substitute the paths to the correct config and model weights. You\
          \ DON'T need to change the script if you only want to visualize the results.\
          \ You will have to modify the script if you need to save the bounding boxes,\
          \ labels, and scores somewhere. All the results can be found in the <code>output</code>\
          \ object at line 67 of the script linked above. You must add some lines\
          \ to save them somewhere. Unfortunately, classes are represented with integers,\
          \ not text labels, so if you know the mapping please let me know.</p>\n\
          <p>Here is an example with the raw inference script:<br><code>python ./dit/object_detection/inference.py\
          \ \\ --image_path path/to/image.jpg \\ --output_file_name path/to/output/image.jpg\
          \ \\ --config ./layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml\
          \ \\ --opts MODEL.WEIGHTS path/to/model.pth</code></p>\n<p>You can find\
          \ the model weights at <a href=\"https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet\"\
          >https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet</a>.\
          \ I hope this is useful.</p>\n</blockquote>\n<p>can you share the exact\
          \ code you used? for document layout?</p>\n"
        raw: "> @MLLife as @superbean said you can use the script `inference.py` at\
          \ the link https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py\
          \ and substitute the paths to the correct config and model weights. You\
          \ DON'T need to change the script if you only want to visualize the results.\
          \ You will have to modify the script if you need to save the bounding boxes,\
          \ labels, and scores somewhere. All the results can be found in the `output`\
          \ object at line 67 of the script linked above. You must add some lines\
          \ to save them somewhere. Unfortunately, classes are represented with integers,\
          \ not text labels, so if you know the mapping please let me know.\n> \n\
          > Here is an example with the raw inference script:\n> `python ./dit/object_detection/inference.py\
          \ \\\n> --image_path path/to/image.jpg \\\n> --output_file_name path/to/output/image.jpg\
          \ \\\n> --config ./layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml\
          \ \\\n> --opts MODEL.WEIGHTS path/to/model.pth`\n> \n> You can find the\
          \ model weights at https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet.\
          \ I hope this is useful.\n\ncan you share the exact code you used? for document\
          \ layout?"
        updatedAt: '2023-06-29T04:08:56.720Z'
      numEdits: 0
      reactions: []
    id: 649d03d8715a0b66f7b097ab
    type: comment
  author: MLLife
  content: "> @MLLife as @superbean said you can use the script `inference.py` at\
    \ the link https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py\
    \ and substitute the paths to the correct config and model weights. You DON'T\
    \ need to change the script if you only want to visualize the results. You will\
    \ have to modify the script if you need to save the bounding boxes, labels, and\
    \ scores somewhere. All the results can be found in the `output` object at line\
    \ 67 of the script linked above. You must add some lines to save them somewhere.\
    \ Unfortunately, classes are represented with integers, not text labels, so if\
    \ you know the mapping please let me know.\n> \n> Here is an example with the\
    \ raw inference script:\n> `python ./dit/object_detection/inference.py \\\n> --image_path\
    \ path/to/image.jpg \\\n> --output_file_name path/to/output/image.jpg \\\n> --config\
    \ ./layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml \\\n> --opts\
    \ MODEL.WEIGHTS path/to/model.pth`\n> \n> You can find the model weights at https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet.\
    \ I hope this is useful.\n\ncan you share the exact code you used? for document\
    \ layout?"
  created_at: 2023-06-29 03:08:56+00:00
  edited: false
  hidden: false
  id: 649d03d8715a0b66f7b097ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9e2cbd28ce4eac8d0284bcd81861c00d.svg
      fullname: Vineet Chotaliya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vineetttt
      type: user
    createdAt: '2023-08-23T11:03:20.000Z'
    data:
      edited: false
      editors:
      - Vineetttt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7732633948326111
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9e2cbd28ce4eac8d0284bcd81861c00d.svg
          fullname: Vineet Chotaliya
          isHf: false
          isPro: false
          name: Vineetttt
          type: user
        html: "<blockquote>\n<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;MLLife&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/MLLife\"\
          >@<span class=\"underline\">MLLife</span></a></span>\n\n\t</span></span>\
          \ as <span data-props=\"{&quot;user&quot;:&quot;superbean&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/superbean\">@<span class=\"\
          underline\">superbean</span></a></span>\n\n\t</span></span> said you can\
          \ use the script <code>inference.py</code> at the link <a rel=\"nofollow\"\
          \ href=\"https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py\"\
          >https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py</a>\
          \ and substitute the paths to the correct config and model weights. You\
          \ DON'T need to change the script if you only want to visualize the results.\
          \ You will have to modify the script if you need to save the bounding boxes,\
          \ labels, and scores somewhere. All the results can be found in the <code>output</code>\
          \ object at line 67 of the script linked above. You must add some lines\
          \ to save them somewhere. Unfortunately, classes are represented with integers,\
          \ not text labels, so if you know the mapping please let me know.</p>\n\
          <p>Here is an example with the raw inference script:<br><code>python ./dit/object_detection/inference.py\
          \ \\ --image_path path/to/image.jpg \\ --output_file_name path/to/output/image.jpg\
          \ \\ --config ./layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml\
          \ \\ --opts MODEL.WEIGHTS path/to/model.pth</code></p>\n<p>You can find\
          \ the model weights at <a href=\"https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet\"\
          >https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet</a>.\
          \ I hope this is useful.</p>\n</blockquote>\n<p>can you share the exact\
          \ code you used? for document layout?</p>\n</blockquote>\n<p><span data-props=\"\
          {&quot;user&quot;:&quot;MLLife&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/MLLife\">@<span class=\"underline\">MLLife</span></a></span>\n\
          \n\t</span></span>  got anything on this ?</p>\n"
        raw: "> > @MLLife as @superbean said you can use the script `inference.py`\
          \ at the link https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py\
          \ and substitute the paths to the correct config and model weights. You\
          \ DON'T need to change the script if you only want to visualize the results.\
          \ You will have to modify the script if you need to save the bounding boxes,\
          \ labels, and scores somewhere. All the results can be found in the `output`\
          \ object at line 67 of the script linked above. You must add some lines\
          \ to save them somewhere. Unfortunately, classes are represented with integers,\
          \ not text labels, so if you know the mapping please let me know.\n> > \n\
          > > Here is an example with the raw inference script:\n> > `python ./dit/object_detection/inference.py\
          \ \\\n> > --image_path path/to/image.jpg \\\n> > --output_file_name path/to/output/image.jpg\
          \ \\\n> > --config ./layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml\
          \ \\\n> > --opts MODEL.WEIGHTS path/to/model.pth`\n> > \n> > You can find\
          \ the model weights at https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet.\
          \ I hope this is useful.\n> \n> can you share the exact code you used? for\
          \ document layout?\n\n@MLLife  got anything on this ?"
        updatedAt: '2023-08-23T11:03:20.603Z'
      numEdits: 0
      reactions: []
    id: 64e5e778bc0068244f1a7b13
    type: comment
  author: Vineetttt
  content: "> > @MLLife as @superbean said you can use the script `inference.py` at\
    \ the link https://github.com/microsoft/unilm/blob/master/dit/object_detection/inference.py\
    \ and substitute the paths to the correct config and model weights. You DON'T\
    \ need to change the script if you only want to visualize the results. You will\
    \ have to modify the script if you need to save the bounding boxes, labels, and\
    \ scores somewhere. All the results can be found in the `output` object at line\
    \ 67 of the script linked above. You must add some lines to save them somewhere.\
    \ Unfortunately, classes are represented with integers, not text labels, so if\
    \ you know the mapping please let me know.\n> > \n> > Here is an example with\
    \ the raw inference script:\n> > `python ./dit/object_detection/inference.py \\\
    \n> > --image_path path/to/image.jpg \\\n> > --output_file_name path/to/output/image.jpg\
    \ \\\n> > --config ./layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml\
    \ \\\n> > --opts MODEL.WEIGHTS path/to/model.pth`\n> > \n> > You can find the\
    \ model weights at https://huggingface.co/HYPJUDY/layoutlmv3-base-finetuned-publaynet.\
    \ I hope this is useful.\n> \n> can you share the exact code you used? for document\
    \ layout?\n\n@MLLife  got anything on this ?"
  created_at: 2023-08-23 10:03:20+00:00
  edited: false
  hidden: false
  id: 64e5e778bc0068244f1a7b13
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a23ded6b84f35cb8803dace63f1efb3f.svg
      fullname: ml life
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MLLife
      type: user
    createdAt: '2023-08-23T14:19:23.000Z'
    data:
      edited: false
      editors:
      - MLLife
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.823106586933136
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a23ded6b84f35cb8803dace63f1efb3f.svg
          fullname: ml life
          isHf: false
          isPro: false
          name: MLLife
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Vineetttt&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Vineetttt\">@<span class=\"\
          underline\">Vineetttt</span></a></span>\n\n\t</span></span> , its not straight\
          \ forward but, there is a DiT document layout app file from here, <a href=\"\
          https://huggingface.co/spaces/nielsr/dit-document-layout-analysis/blob/main/app.py\"\
          >https://huggingface.co/spaces/nielsr/dit-document-layout-analysis/blob/main/app.py</a>\
          \ modify it, just the model paths and initial imports, it will work.</p>\n\
          <p>remember, layoutlmv3 can't be used for commerical projects</p>\n"
        raw: '@Vineetttt , its not straight forward but, there is a DiT document layout
          app file from here, https://huggingface.co/spaces/nielsr/dit-document-layout-analysis/blob/main/app.py
          modify it, just the model paths and initial imports, it will work.


          remember, layoutlmv3 can''t be used for commerical projects'
        updatedAt: '2023-08-23T14:19:23.280Z'
      numEdits: 0
      reactions: []
    id: 64e6156b9016a4c172519e50
    type: comment
  author: MLLife
  content: '@Vineetttt , its not straight forward but, there is a DiT document layout
    app file from here, https://huggingface.co/spaces/nielsr/dit-document-layout-analysis/blob/main/app.py
    modify it, just the model paths and initial imports, it will work.


    remember, layoutlmv3 can''t be used for commerical projects'
  created_at: 2023-08-23 13:19:23+00:00
  edited: false
  hidden: false
  id: 64e6156b9016a4c172519e50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9e2cbd28ce4eac8d0284bcd81861c00d.svg
      fullname: Vineet Chotaliya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vineetttt
      type: user
    createdAt: '2023-08-23T14:36:49.000Z'
    data:
      edited: false
      editors:
      - Vineetttt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9062783122062683
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9e2cbd28ce4eac8d0284bcd81861c00d.svg
          fullname: Vineet Chotaliya
          isHf: false
          isPro: false
          name: Vineetttt
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;MLLife&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/MLLife\">@<span class=\"\
          underline\">MLLife</span></a></span>\n\n\t</span></span> can you share the\
          \ notebook/code if you've implemented, it'll be of great help</p>\n"
        raw: '@MLLife can you share the notebook/code if you''ve implemented, it''ll
          be of great help

          '
        updatedAt: '2023-08-23T14:36:49.033Z'
      numEdits: 0
      reactions: []
    id: 64e61981be651cead872f383
    type: comment
  author: Vineetttt
  content: '@MLLife can you share the notebook/code if you''ve implemented, it''ll
    be of great help

    '
  created_at: 2023-08-23 13:36:49+00:00
  edited: false
  hidden: false
  id: 64e61981be651cead872f383
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: HYPJUDY/layoutlmv3-base-finetuned-publaynet
repo_type: model
status: open
target_branch: null
title: OS Error - No pytorch_model.bin
