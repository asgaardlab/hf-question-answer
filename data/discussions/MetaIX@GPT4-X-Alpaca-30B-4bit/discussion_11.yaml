!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Waldschrat
conflicting_files: null
created_at: 2023-05-16 04:17:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6aba330a438e06b98c96f2998550d8a7.svg
      fullname: Holger Pieta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Waldschrat
      type: user
    createdAt: '2023-05-16T05:17:40.000Z'
    data:
      edited: false
      editors:
      - Waldschrat
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6aba330a438e06b98c96f2998550d8a7.svg
          fullname: Holger Pieta
          isHf: false
          isPro: false
          name: Waldschrat
          type: user
        html: '<p>llama.cpp decided to break the quantized ggml file format: <a rel="nofollow"
          href="https://github.com/ggerganov/llama.cpp/pull/1305">https://github.com/ggerganov/llama.cpp/pull/1305</a></p>

          <p>As nobody seems to be able (or willing) to provide a conversion script,
          the models need to be requantized (is that even a word?) from the source
          models.</p>

          <p>As this is quite a hurdle for people new into the field (like me), so:
          May I ask you to please quantize and upload the models in the new format?</p>

          '
        raw: "llama.cpp decided to break the quantized ggml file format: https://github.com/ggerganov/llama.cpp/pull/1305\r\
          \n\r\nAs nobody seems to be able (or willing) to provide a conversion script,\
          \ the models need to be requantized (is that even a word?) from the source\
          \ models.\r\n\r\nAs this is quite a hurdle for people new into the field\
          \ (like me), so: May I ask you to please quantize and upload the models\
          \ in the new format?"
        updatedAt: '2023-05-16T05:17:40.389Z'
      numEdits: 0
      reactions: []
    id: 646311f4514ee1645bd3eea3
    type: comment
  author: Waldschrat
  content: "llama.cpp decided to break the quantized ggml file format: https://github.com/ggerganov/llama.cpp/pull/1305\r\
    \n\r\nAs nobody seems to be able (or willing) to provide a conversion script,\
    \ the models need to be requantized (is that even a word?) from the source models.\r\
    \n\r\nAs this is quite a hurdle for people new into the field (like me), so: May\
    \ I ask you to please quantize and upload the models in the new format?"
  created_at: 2023-05-16 04:17:40+00:00
  edited: false
  hidden: false
  id: 646311f4514ee1645bd3eea3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2cc5f6ee43e3648726fb3cf833e34dab.svg
      fullname: Venkatesh Srinivas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: venketh
      type: user
    createdAt: '2023-05-17T00:44:15.000Z'
    data:
      edited: false
      editors:
      - venketh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2cc5f6ee43e3648726fb3cf833e34dab.svg
          fullname: Venkatesh Srinivas
          isHf: false
          isPro: false
          name: venketh
          type: user
        html: '<p>I''ll take a swing at it - <a href="https://huggingface.co/venketh/GPT4-X-Alpaca-30B-4bit-ggml">https://huggingface.co/venketh/GPT4-X-Alpaca-30B-4bit-ggml</a></p>

          '
        raw: I'll take a swing at it - https://huggingface.co/venketh/GPT4-X-Alpaca-30B-4bit-ggml
        updatedAt: '2023-05-17T00:44:15.385Z'
      numEdits: 0
      reactions: []
    id: 6464235f6dad99445dee0824
    type: comment
  author: venketh
  content: I'll take a swing at it - https://huggingface.co/venketh/GPT4-X-Alpaca-30B-4bit-ggml
  created_at: 2023-05-16 23:44:15+00:00
  edited: false
  hidden: false
  id: 6464235f6dad99445dee0824
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bd6d702643cd5875d6a43e3369945ac5.svg
      fullname: Metal
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: MetaIX
      type: user
    createdAt: '2023-05-18T15:29:22.000Z'
    data:
      edited: false
      editors:
      - MetaIX
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bd6d702643cd5875d6a43e3369945ac5.svg
          fullname: Metal
          isHf: false
          isPro: false
          name: MetaIX
          type: user
        html: '<p>Updated the quants and added q5_0</p>

          '
        raw: Updated the quants and added q5_0
        updatedAt: '2023-05-18T15:29:22.367Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Erilaz
    id: 646644529c627c78f86a65ef
    type: comment
  author: MetaIX
  content: Updated the quants and added q5_0
  created_at: 2023-05-18 14:29:22+00:00
  edited: false
  hidden: false
  id: 646644529c627c78f86a65ef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63cd4b6d1c8a5d1d7d76a778/FAnsBh9h5-wG9Vb252ZNt.png?w=200&h=200&f=face
      fullname: Concedo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: concedo
      type: user
    createdAt: '2023-05-26T06:08:41.000Z'
    data:
      edited: false
      editors:
      - concedo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63cd4b6d1c8a5d1d7d76a778/FAnsBh9h5-wG9Vb252ZNt.png?w=200&h=200&f=face
          fullname: Concedo
          isHf: false
          isPro: false
          name: concedo
          type: user
        html: '<p>Might have to be updated again heh</p>

          '
        raw: Might have to be updated again heh
        updatedAt: '2023-05-26T06:08:41.124Z'
      numEdits: 0
      reactions: []
    id: 64704ce93df93fddecdb5d7c
    type: comment
  author: concedo
  content: Might have to be updated again heh
  created_at: 2023-05-26 05:08:41+00:00
  edited: false
  hidden: false
  id: 64704ce93df93fddecdb5d7c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bd6d702643cd5875d6a43e3369945ac5.svg
      fullname: Metal
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: MetaIX
      type: user
    createdAt: '2023-05-26T21:04:37.000Z'
    data:
      edited: false
      editors:
      - MetaIX
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bd6d702643cd5875d6a43e3369945ac5.svg
          fullname: Metal
          isHf: false
          isPro: false
          name: MetaIX
          type: user
        html: '<p>Updating again today...</p>

          '
        raw: Updating again today...
        updatedAt: '2023-05-26T21:04:37.799Z'
      numEdits: 0
      reactions: []
    id: 64711ee534a8a81ebd8f3e0a
    type: comment
  author: MetaIX
  content: Updating again today...
  created_at: 2023-05-26 20:04:37+00:00
  edited: false
  hidden: false
  id: 64711ee534a8a81ebd8f3e0a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 11
repo_id: MetaIX/GPT4-X-Alpaca-30B-4bit
repo_type: model
status: open
target_branch: null
title: llama.cpp breaks quantized ggml file format
