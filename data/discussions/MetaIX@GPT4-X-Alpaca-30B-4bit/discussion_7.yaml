!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ANGIPO
conflicting_files: null
created_at: 2023-04-22 05:10:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/pqqsxj7ECJuJa-RBfhf-G.png?w=200&h=200&f=face
      fullname: FRAXIS
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ANGIPO
      type: user
    createdAt: '2023-04-22T06:10:54.000Z'
    data:
      edited: false
      editors:
      - ANGIPO
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/pqqsxj7ECJuJa-RBfhf-G.png?w=200&h=200&f=face
          fullname: FRAXIS
          isHf: false
          isPro: false
          name: ANGIPO
          type: user
        html: '<p>cfg: Ryzen 5800X, RTX 3090 24GB<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64436235f99d6629a71e1c43/Mb5-Dssb5pmBmBZG3uU7K.png"><img
          alt="2023-04-22_15-09-47.png" src="https://cdn-uploads.huggingface.co/production/uploads/64436235f99d6629a71e1c43/Mb5-Dssb5pmBmBZG3uU7K.png"></a></p>

          '
        raw: "cfg: Ryzen 5800X, RTX 3090 24GB\r\n![2023-04-22_15-09-47.png](https://cdn-uploads.huggingface.co/production/uploads/64436235f99d6629a71e1c43/Mb5-Dssb5pmBmBZG3uU7K.png)\r\
          \n"
        updatedAt: '2023-04-22T06:10:54.464Z'
      numEdits: 0
      reactions: []
    id: 64437a6eaf034cdfd6998964
    type: comment
  author: ANGIPO
  content: "cfg: Ryzen 5800X, RTX 3090 24GB\r\n![2023-04-22_15-09-47.png](https://cdn-uploads.huggingface.co/production/uploads/64436235f99d6629a71e1c43/Mb5-Dssb5pmBmBZG3uU7K.png)\r\
    \n"
  created_at: 2023-04-22 05:10:54+00:00
  edited: false
  hidden: false
  id: 64437a6eaf034cdfd6998964
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d25b1c5125455b55cecc2bf67a684058.svg
      fullname: wef
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fwre
      type: user
    createdAt: '2023-04-22T09:08:12.000Z'
    data:
      edited: false
      editors:
      - fwre
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d25b1c5125455b55cecc2bf67a684058.svg
          fullname: wef
          isHf: false
          isPro: false
          name: fwre
          type: user
        html: '<p>I think there is an issue with the files provided, it is not referencing
          the safetensor files hence the issue. Hopefully this is updated soon.</p>

          '
        raw: I think there is an issue with the files provided, it is not referencing
          the safetensor files hence the issue. Hopefully this is updated soon.
        updatedAt: '2023-04-22T09:08:12.218Z'
      numEdits: 0
      reactions: []
    id: 6443a3fc8f795c936dfb42c1
    type: comment
  author: fwre
  content: I think there is an issue with the files provided, it is not referencing
    the safetensor files hence the issue. Hopefully this is updated soon.
  created_at: 2023-04-22 08:08:12+00:00
  edited: false
  hidden: false
  id: 6443a3fc8f795c936dfb42c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bd6d702643cd5875d6a43e3369945ac5.svg
      fullname: Metal
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: MetaIX
      type: user
    createdAt: '2023-04-23T03:29:41.000Z'
    data:
      edited: false
      editors:
      - MetaIX
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bd6d702643cd5875d6a43e3369945ac5.svg
          fullname: Metal
          isHf: false
          isPro: false
          name: MetaIX
          type: user
        html: '<p>Not an issue with the files. Try running it with --wbits 4</p>

          '
        raw: Not an issue with the files. Try running it with --wbits 4
        updatedAt: '2023-04-23T03:29:41.121Z'
      numEdits: 0
      reactions: []
    id: 6444a6255298d19c9c09e59d
    type: comment
  author: MetaIX
  content: Not an issue with the files. Try running it with --wbits 4
  created_at: 2023-04-23 02:29:41+00:00
  edited: false
  hidden: false
  id: 6444a6255298d19c9c09e59d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/963d2a4ff3ee629fff358c533ade126d.svg
      fullname: Hendrik Wiese
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HendrikW80
      type: user
    createdAt: '2023-04-23T09:25:02.000Z'
    data:
      edited: true
      editors:
      - HendrikW80
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/963d2a4ff3ee629fff358c533ade126d.svg
          fullname: Hendrik Wiese
          isHf: false
          isPro: false
          name: HendrikW80
          type: user
        html: '<p><del>I have the same issue.</del></p>

          <p>I haven''t downloaded all three big safetensor files, just the 4bit 128g
          file. Are all big files needed for the model to work?</p>

          '
        raw: '~~I have the same issue.~~


          I haven''t downloaded all three big safetensor files, just the 4bit 128g
          file. Are all big files needed for the model to work?'
        updatedAt: '2023-04-23T09:58:32.880Z'
      numEdits: 1
      reactions: []
    id: 6444f96e53ecc52f50e95fd3
    type: comment
  author: HendrikW80
  content: '~~I have the same issue.~~


    I haven''t downloaded all three big safetensor files, just the 4bit 128g file.
    Are all big files needed for the model to work?'
  created_at: 2023-04-23 08:25:02+00:00
  edited: true
  hidden: false
  id: 6444f96e53ecc52f50e95fd3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/963d2a4ff3ee629fff358c533ade126d.svg
      fullname: Hendrik Wiese
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HendrikW80
      type: user
    createdAt: '2023-04-23T09:57:52.000Z'
    data:
      edited: true
      editors:
      - HendrikW80
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/963d2a4ff3ee629fff358c533ade126d.svg
          fullname: Hendrik Wiese
          isHf: false
          isPro: false
          name: HendrikW80
          type: user
        html: '<p>Ah, somehow the UI resets wbits and groupsize to None when I switch
          the model. Now I''ve managed to get past this issue.</p>

          <p>However now, the server.py just exits when I try to load the model. No
          error, nothing.</p>

          <p>Update: it appears to be <code>model.load_state_dict(safe_load(checkpoint),
          strict=False)</code> that crashes Python with no error whatsoever.</p>

          '
        raw: 'Ah, somehow the UI resets wbits and groupsize to None when I switch
          the model. Now I''ve managed to get past this issue.


          However now, the server.py just exits when I try to load the model. No error,
          nothing.


          Update: it appears to be `model.load_state_dict(safe_load(checkpoint), strict=False)`
          that crashes Python with no error whatsoever.'
        updatedAt: '2023-04-23T10:10:59.577Z'
      numEdits: 1
      reactions: []
    id: 6445012053ecc52f50e9f095
    type: comment
  author: HendrikW80
  content: 'Ah, somehow the UI resets wbits and groupsize to None when I switch the
    model. Now I''ve managed to get past this issue.


    However now, the server.py just exits when I try to load the model. No error,
    nothing.


    Update: it appears to be `model.load_state_dict(safe_load(checkpoint), strict=False)`
    that crashes Python with no error whatsoever.'
  created_at: 2023-04-23 08:57:52+00:00
  edited: true
  hidden: false
  id: 6445012053ecc52f50e9f095
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/19HhHFeIU2dUnVRcqb7hb.png?w=200&h=200&f=face
      fullname: Devin Taylor
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DTechNation
      type: user
    createdAt: '2023-04-24T01:45:54.000Z'
    data:
      edited: false
      editors:
      - DTechNation
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/19HhHFeIU2dUnVRcqb7hb.png?w=200&h=200&f=face
          fullname: Devin Taylor
          isHf: false
          isPro: false
          name: DTechNation
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;HendrikW80&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/HendrikW80\">@<span class=\"\
          underline\">HendrikW80</span></a></span>\n\n\t</span></span> download: oobabooga/llama-tokenizer\
          \ and put it in your models folder. This is the default tokenizer</p>\n\
          <p>Enjoy,</p>\n"
        raw: '@HendrikW80 download: oobabooga/llama-tokenizer and put it in your models
          folder. This is the default tokenizer


          Enjoy,'
        updatedAt: '2023-04-24T01:45:54.814Z'
      numEdits: 0
      reactions: []
    id: 6445df5253ecc52f50fa3fc6
    type: comment
  author: DTechNation
  content: '@HendrikW80 download: oobabooga/llama-tokenizer and put it in your models
    folder. This is the default tokenizer


    Enjoy,'
  created_at: 2023-04-24 00:45:54+00:00
  edited: false
  hidden: false
  id: 6445df5253ecc52f50fa3fc6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/52e38a6ecde34148ec3a19767cf83571.svg
      fullname: Keren Elience
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Shaliy
      type: user
    createdAt: '2023-04-24T15:10:34.000Z'
    data:
      edited: false
      editors:
      - Shaliy
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/52e38a6ecde34148ec3a19767cf83571.svg
          fullname: Keren Elience
          isHf: false
          isPro: false
          name: Shaliy
          type: user
        html: '<p>try to change the folder name, <code>GPT4-X-Alpaca-30B-128g-4bit</code>
          to <code>gpt4-x-alpaca-30b-128g-4bit</code></p>

          <pre><code class="language-shell">mv GPT4-X-Alpaca-30B-Int4 gpt4-x-alpaca-30b-128g-4bit

          </code></pre>

          '
        raw: 'try to change the folder name, `GPT4-X-Alpaca-30B-128g-4bit` to `gpt4-x-alpaca-30b-128g-4bit`

          ```shell

          mv GPT4-X-Alpaca-30B-Int4 gpt4-x-alpaca-30b-128g-4bit

          ```'
        updatedAt: '2023-04-24T15:10:34.587Z'
      numEdits: 0
      reactions: []
    id: 64469beac50af850001300c9
    type: comment
  author: Shaliy
  content: 'try to change the folder name, `GPT4-X-Alpaca-30B-128g-4bit` to `gpt4-x-alpaca-30b-128g-4bit`

    ```shell

    mv GPT4-X-Alpaca-30B-Int4 gpt4-x-alpaca-30b-128g-4bit

    ```'
  created_at: 2023-04-24 14:10:34+00:00
  edited: false
  hidden: false
  id: 64469beac50af850001300c9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/963d2a4ff3ee629fff358c533ade126d.svg
      fullname: Hendrik Wiese
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HendrikW80
      type: user
    createdAt: '2023-04-24T15:18:23.000Z'
    data:
      edited: false
      editors:
      - HendrikW80
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/963d2a4ff3ee629fff358c533ade126d.svg
          fullname: Hendrik Wiese
          isHf: false
          isPro: false
          name: HendrikW80
          type: user
        html: '<p>You think it''s a matter of upper/lower case?</p>

          '
        raw: You think it's a matter of upper/lower case?
        updatedAt: '2023-04-24T15:18:23.562Z'
      numEdits: 0
      reactions: []
    id: 64469dbf9cb2a8f4a4eda139
    type: comment
  author: HendrikW80
  content: You think it's a matter of upper/lower case?
  created_at: 2023-04-24 14:18:23+00:00
  edited: false
  hidden: false
  id: 64469dbf9cb2a8f4a4eda139
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/19HhHFeIU2dUnVRcqb7hb.png?w=200&h=200&f=face
      fullname: Devin Taylor
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DTechNation
      type: user
    createdAt: '2023-04-24T15:23:18.000Z'
    data:
      edited: false
      editors:
      - DTechNation
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/19HhHFeIU2dUnVRcqb7hb.png?w=200&h=200&f=face
          fullname: Devin Taylor
          isHf: false
          isPro: false
          name: DTechNation
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;HendrikW80&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/HendrikW80\">@<span class=\"\
          underline\">HendrikW80</span></a></span>\n\n\t</span></span>, I had the\
          \ exact same error as you. Python server would close with no errors given.\
          \ putting oobabooga/llama-tokenizer in my models folder resolved this issue</p>\n"
        raw: '@HendrikW80, I had the exact same error as you. Python server would
          close with no errors given. putting oobabooga/llama-tokenizer in my models
          folder resolved this issue'
        updatedAt: '2023-04-24T15:23:18.842Z'
      numEdits: 0
      reactions: []
    id: 64469ee61dc59ca8aecd2535
    type: comment
  author: DTechNation
  content: '@HendrikW80, I had the exact same error as you. Python server would close
    with no errors given. putting oobabooga/llama-tokenizer in my models folder resolved
    this issue'
  created_at: 2023-04-24 14:23:18+00:00
  edited: false
  hidden: false
  id: 64469ee61dc59ca8aecd2535
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/963d2a4ff3ee629fff358c533ade126d.svg
      fullname: Hendrik Wiese
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HendrikW80
      type: user
    createdAt: '2023-04-24T20:50:31.000Z'
    data:
      edited: false
      editors:
      - HendrikW80
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/963d2a4ff3ee629fff358c533ade126d.svg
          fullname: Hendrik Wiese
          isHf: false
          isPro: false
          name: HendrikW80
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;HendrikW80&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/HendrikW80\"\
          >@<span class=\"underline\">HendrikW80</span></a></span>\n\n\t</span></span>,\
          \ I had the exact same error as you. Python server would close with no errors\
          \ given. putting oobabooga/llama-tokenizer in my models folder resolved\
          \ this issue</p>\n</blockquote>\n<p>I'll try that out and report back if\
          \ it works, thanks.</p>\n"
        raw: '> @HendrikW80, I had the exact same error as you. Python server would
          close with no errors given. putting oobabooga/llama-tokenizer in my models
          folder resolved this issue


          I''ll try that out and report back if it works, thanks.'
        updatedAt: '2023-04-24T20:50:31.768Z'
      numEdits: 0
      reactions: []
    id: 6446eb979cb2a8f4a4f3d233
    type: comment
  author: HendrikW80
  content: '> @HendrikW80, I had the exact same error as you. Python server would
    close with no errors given. putting oobabooga/llama-tokenizer in my models folder
    resolved this issue


    I''ll try that out and report back if it works, thanks.'
  created_at: 2023-04-24 19:50:31+00:00
  edited: false
  hidden: false
  id: 6446eb979cb2a8f4a4f3d233
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/963d2a4ff3ee629fff358c533ade126d.svg
      fullname: Hendrik Wiese
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HendrikW80
      type: user
    createdAt: '2023-04-24T21:13:18.000Z'
    data:
      edited: false
      editors:
      - HendrikW80
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/963d2a4ff3ee629fff358c533ade126d.svg
          fullname: Hendrik Wiese
          isHf: false
          isPro: false
          name: HendrikW80
          type: user
        html: "<blockquote>\n<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;HendrikW80&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/HendrikW80\"\
          >@<span class=\"underline\">HendrikW80</span></a></span>\n\n\t</span></span>,\
          \ I had the exact same error as you. Python server would close with no errors\
          \ given. putting oobabooga/llama-tokenizer in my models folder resolved\
          \ this issue</p>\n</blockquote>\n<p>I'll try that out and report back if\
          \ it works, thanks.</p>\n</blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;DTechNation&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/DTechNation\"\
          >@<span class=\"underline\">DTechNation</span></a></span>\n\n\t</span></span>\
          \ Okay, tried it. No success. Still exits right after \"Loading model...\"\
          \ with no error whatsoever.</p>\n"
        raw: "> > @HendrikW80, I had the exact same error as you. Python server would\
          \ close with no errors given. putting oobabooga/llama-tokenizer in my models\
          \ folder resolved this issue\n> \n> I'll try that out and report back if\
          \ it works, thanks.\n\n@DTechNation Okay, tried it. No success. Still exits\
          \ right after \"Loading model...\" with no error whatsoever."
        updatedAt: '2023-04-24T21:13:18.188Z'
      numEdits: 0
      reactions: []
    id: 6446f0ee9cb2a8f4a4f41f6e
    type: comment
  author: HendrikW80
  content: "> > @HendrikW80, I had the exact same error as you. Python server would\
    \ close with no errors given. putting oobabooga/llama-tokenizer in my models folder\
    \ resolved this issue\n> \n> I'll try that out and report back if it works, thanks.\n\
    \n@DTechNation Okay, tried it. No success. Still exits right after \"Loading model...\"\
    \ with no error whatsoever."
  created_at: 2023-04-24 20:13:18+00:00
  edited: false
  hidden: false
  id: 6446f0ee9cb2a8f4a4f41f6e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d2e44d0e2e9ed4fdd7890264e780b127.svg
      fullname: Satoshi Report
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SatoshiReport
      type: user
    createdAt: '2023-04-27T16:24:17.000Z'
    data:
      edited: true
      editors:
      - SatoshiReport
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d2e44d0e2e9ed4fdd7890264e780b127.svg
          fullname: Satoshi Report
          isHf: false
          isPro: false
          name: SatoshiReport
          type: user
        html: '<p>I downloaded the latest oobabooga/llama-tokenizer and changed the
          directory name to lower case however it loads and then gets killed....  I
          am running on a A10 and tried the 128g model and the non-128g model</p>

          <p>$ python server.py --auto-devices --groupsize 128 --extensions api --listen
          --model gpt4-x-alpaca-30b-128g-4bit --wbits 4</p>

          <p>Gradio HTTP request redirected to localhost :)<br>bin /home/ubuntu/miniconda3/envs/textgen/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so<br>Loading
          gpt4-x-alpaca-30b-128g-4bit...<br>Found the following quantized model: models/gpt4-x-alpaca-30b-128g-4bit/gpt4-x-alpaca-30b-128g-4bit.safetensors<br>Killed</p>

          '
        raw: 'I downloaded the latest oobabooga/llama-tokenizer and changed the directory
          name to lower case however it loads and then gets killed....  I am running
          on a A10 and tried the 128g model and the non-128g model


          $ python server.py --auto-devices --groupsize 128 --extensions api --listen
          --model gpt4-x-alpaca-30b-128g-4bit --wbits 4


          Gradio HTTP request redirected to localhost :)

          bin /home/ubuntu/miniconda3/envs/textgen/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so

          Loading gpt4-x-alpaca-30b-128g-4bit...

          Found the following quantized model: models/gpt4-x-alpaca-30b-128g-4bit/gpt4-x-alpaca-30b-128g-4bit.safetensors

          Killed'
        updatedAt: '2023-04-27T16:29:27.299Z'
      numEdits: 1
      reactions: []
    id: 644aa1b1d4483bfaa06c0cf3
    type: comment
  author: SatoshiReport
  content: 'I downloaded the latest oobabooga/llama-tokenizer and changed the directory
    name to lower case however it loads and then gets killed....  I am running on
    a A10 and tried the 128g model and the non-128g model


    $ python server.py --auto-devices --groupsize 128 --extensions api --listen --model
    gpt4-x-alpaca-30b-128g-4bit --wbits 4


    Gradio HTTP request redirected to localhost :)

    bin /home/ubuntu/miniconda3/envs/textgen/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so

    Loading gpt4-x-alpaca-30b-128g-4bit...

    Found the following quantized model: models/gpt4-x-alpaca-30b-128g-4bit/gpt4-x-alpaca-30b-128g-4bit.safetensors

    Killed'
  created_at: 2023-04-27 15:24:17+00:00
  edited: true
  hidden: false
  id: 644aa1b1d4483bfaa06c0cf3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d2e44d0e2e9ed4fdd7890264e780b127.svg
      fullname: Satoshi Report
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SatoshiReport
      type: user
    createdAt: '2023-04-27T16:49:36.000Z'
    data:
      edited: false
      editors:
      - SatoshiReport
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d2e44d0e2e9ed4fdd7890264e780b127.svg
          fullname: Satoshi Report
          isHf: false
          isPro: false
          name: SatoshiReport
          type: user
        html: '<p>Solved: It needs about 17GB of free RAM to load (not VRAM).</p>

          '
        raw: 'Solved: It needs about 17GB of free RAM to load (not VRAM).'
        updatedAt: '2023-04-27T16:49:36.034Z'
      numEdits: 0
      reactions: []
    id: 644aa7a0af97dfd24c0e1c56
    type: comment
  author: SatoshiReport
  content: 'Solved: It needs about 17GB of free RAM to load (not VRAM).'
  created_at: 2023-04-27 15:49:36+00:00
  edited: false
  hidden: false
  id: 644aa7a0af97dfd24c0e1c56
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/19HhHFeIU2dUnVRcqb7hb.png?w=200&h=200&f=face
      fullname: Devin Taylor
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DTechNation
      type: user
    createdAt: '2023-04-27T18:23:19.000Z'
    data:
      edited: false
      editors:
      - DTechNation
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/19HhHFeIU2dUnVRcqb7hb.png?w=200&h=200&f=face
          fullname: Devin Taylor
          isHf: false
          isPro: false
          name: DTechNation
          type: user
        html: '<p>I have over 40gb of system ram free and it still won''t work.  I
          changed the (non 128) model to lower case and have the same quitting issue</p>

          <p>$ python server.py --auto-devices --model gpt4-x-alpaca-30b-128g-4bit
          --wbits 4 --model_type LLaMa</p>

          <p>Using a 3090 and It worked randomly for a day after I downloaded the
          oobabooga/llama-tokenizer, but then stopped the next day. I removed and
          reinstalled the latest oobabooga web ui, but I am still having the quitting
          issue</p>

          '
        raw: 'I have over 40gb of system ram free and it still won''t work.  I changed
          the (non 128) model to lower case and have the same quitting issue


          $ python server.py --auto-devices --model gpt4-x-alpaca-30b-128g-4bit --wbits
          4 --model_type LLaMa


          Using a 3090 and It worked randomly for a day after I downloaded the oobabooga/llama-tokenizer,
          but then stopped the next day. I removed and reinstalled the latest oobabooga
          web ui, but I am still having the quitting issue'
        updatedAt: '2023-04-27T18:23:19.108Z'
      numEdits: 0
      reactions: []
    id: 644abd97af97dfd24c0fea99
    type: comment
  author: DTechNation
  content: 'I have over 40gb of system ram free and it still won''t work.  I changed
    the (non 128) model to lower case and have the same quitting issue


    $ python server.py --auto-devices --model gpt4-x-alpaca-30b-128g-4bit --wbits
    4 --model_type LLaMa


    Using a 3090 and It worked randomly for a day after I downloaded the oobabooga/llama-tokenizer,
    but then stopped the next day. I removed and reinstalled the latest oobabooga
    web ui, but I am still having the quitting issue'
  created_at: 2023-04-27 17:23:19+00:00
  edited: false
  hidden: false
  id: 644abd97af97dfd24c0fea99
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/963d2a4ff3ee629fff358c533ade126d.svg
      fullname: Hendrik Wiese
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HendrikW80
      type: user
    createdAt: '2023-04-27T18:24:54.000Z'
    data:
      edited: false
      editors:
      - HendrikW80
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/963d2a4ff3ee629fff358c533ade126d.svg
          fullname: Hendrik Wiese
          isHf: false
          isPro: false
          name: HendrikW80
          type: user
        html: '<p>Yeah, same here. It''s really hard to debug with nothing but a cryptic
          error code...</p>

          '
        raw: Yeah, same here. It's really hard to debug with nothing but a cryptic
          error code...
        updatedAt: '2023-04-27T18:24:54.787Z'
      numEdits: 0
      reactions: []
    id: 644abdf6cb45734dfd45d897
    type: comment
  author: HendrikW80
  content: Yeah, same here. It's really hard to debug with nothing but a cryptic error
    code...
  created_at: 2023-04-27 17:24:54+00:00
  edited: false
  hidden: false
  id: 644abdf6cb45734dfd45d897
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/19HhHFeIU2dUnVRcqb7hb.png?w=200&h=200&f=face
      fullname: Devin Taylor
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DTechNation
      type: user
    createdAt: '2023-04-28T01:21:49.000Z'
    data:
      edited: false
      editors:
      - DTechNation
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/19HhHFeIU2dUnVRcqb7hb.png?w=200&h=200&f=face
          fullname: Devin Taylor
          isHf: false
          isPro: false
          name: DTechNation
          type: user
        html: '<p>I FIGURED IT OUT</p>

          <p>You need like 40gb of space on your SSD for it startup!</p>

          '
        raw: 'I FIGURED IT OUT


          You need like 40gb of space on your SSD for it startup!'
        updatedAt: '2023-04-28T01:21:49.642Z'
      numEdits: 0
      reactions: []
    id: 644b1fadf9f1b0cd3d958336
    type: comment
  author: DTechNation
  content: 'I FIGURED IT OUT


    You need like 40gb of space on your SSD for it startup!'
  created_at: 2023-04-28 00:21:49+00:00
  edited: false
  hidden: false
  id: 644b1fadf9f1b0cd3d958336
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c57fd4ec8857fc4e3dcdd488067bc672.svg
      fullname: Kanishka Dubey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kanishka28
      type: user
    createdAt: '2023-06-23T10:26:18.000Z'
    data:
      edited: false
      editors:
      - Kanishka28
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4362943768501282
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c57fd4ec8857fc4e3dcdd488067bc672.svg
          fullname: Kanishka Dubey
          isHf: false
          isPro: false
          name: Kanishka28
          type: user
        html: '<blockquote>

          <p>I FIGURED IT OUT</p>

          <p>You need like 40gb of space on your SSD for it startup!</p>

          </blockquote>

          <p>What script are you using to run the model?<br>$ python server.py --auto-devices
          --model gpt4-x-alpaca-30b-128g-4bit --wbits 4 --model_type LLaMa</p>

          '
        raw: "> I FIGURED IT OUT\n> \n> You need like 40gb of space on your SSD for\
          \ it startup!\n\nWhat script are you using to run the model? \n$ python\
          \ server.py --auto-devices --model gpt4-x-alpaca-30b-128g-4bit --wbits 4\
          \ --model_type LLaMa"
        updatedAt: '2023-06-23T10:26:18.111Z'
      numEdits: 0
      reactions: []
    id: 6495734a86e1286a1de6e80d
    type: comment
  author: Kanishka28
  content: "> I FIGURED IT OUT\n> \n> You need like 40gb of space on your SSD for\
    \ it startup!\n\nWhat script are you using to run the model? \n$ python server.py\
    \ --auto-devices --model gpt4-x-alpaca-30b-128g-4bit --wbits 4 --model_type LLaMa"
  created_at: 2023-06-23 09:26:18+00:00
  edited: false
  hidden: false
  id: 6495734a86e1286a1de6e80d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-23T20:33:48.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9599084258079529
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>The reason for the error is a problem on Windows whereby larger
          models need a very large Pagefile to load, even though you are loading it
          to GPU and even if you have plenty of RAM.</p>

          <p>For 30B models I recommend users have a Pagefile of 100GB.  This can
          be achieved either by manually setting Pagefile to 100GB, or else having
          it on Auto and ensuring you have 100+ GB free on C: (or whatever drive holds
          the Pagefile)</p>

          <p>That''s why it worked for DTechNation when they freed up more disk space;
          the Pagefile was able to grow large enough to allow the model loading.</p>

          '
        raw: 'The reason for the error is a problem on Windows whereby larger models
          need a very large Pagefile to load, even though you are loading it to GPU
          and even if you have plenty of RAM.


          For 30B models I recommend users have a Pagefile of 100GB.  This can be
          achieved either by manually setting Pagefile to 100GB, or else having it
          on Auto and ensuring you have 100+ GB free on C: (or whatever drive holds
          the Pagefile)


          That''s why it worked for DTechNation when they freed up more disk space;
          the Pagefile was able to grow large enough to allow the model loading.'
        updatedAt: '2023-06-23T20:33:48.276Z'
      numEdits: 0
      reactions: []
    id: 649601acb68b87c87b5bc29d
    type: comment
  author: TheBloke
  content: 'The reason for the error is a problem on Windows whereby larger models
    need a very large Pagefile to load, even though you are loading it to GPU and
    even if you have plenty of RAM.


    For 30B models I recommend users have a Pagefile of 100GB.  This can be achieved
    either by manually setting Pagefile to 100GB, or else having it on Auto and ensuring
    you have 100+ GB free on C: (or whatever drive holds the Pagefile)


    That''s why it worked for DTechNation when they freed up more disk space; the
    Pagefile was able to grow large enough to allow the model loading.'
  created_at: 2023-06-23 19:33:48+00:00
  edited: false
  hidden: false
  id: 649601acb68b87c87b5bc29d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: MetaIX/GPT4-X-Alpaca-30B-4bit
repo_type: model
status: open
target_branch: null
title: Please, help :<
