!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ilnurshams
conflicting_files: null
created_at: 2023-05-20 14:13:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/aeb28ba60e2961c979bf0787bc90e40c.svg
      fullname: ilnurshams
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ilnurshams
      type: user
    createdAt: '2023-05-20T15:13:37.000Z'
    data:
      edited: false
      editors:
      - ilnurshams
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/aeb28ba60e2961c979bf0787bc90e40c.svg
          fullname: ilnurshams
          isHf: false
          isPro: false
          name: ilnurshams
          type: user
        html: '<p>Coul you please advise how can I fix the issue when a model does
          not reply to my message?<br>So there is an endless typing ( see pictures
          ). I''ve reduced token sizes to min. Chat mode.<br>Running on Windows 11,
          RTX4090, 64GB RAM</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/6hBpbaQYeYBCbaAPMsSND.png"><img
          alt="2023-05-20 030013.png" src="https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/6hBpbaQYeYBCbaAPMsSND.png"></a><br><a
          rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/l2i97rZwxmnv074ReKavT.png"><img
          alt="2023-05-20 030153.png" src="https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/l2i97rZwxmnv074ReKavT.png"></a></p>

          '
        raw: "Coul you please advise how can I fix the issue when a model does not\
          \ reply to my message?\r\nSo there is an endless typing ( see pictures ).\
          \ I've reduced token sizes to min. Chat mode.\r\nRunning on Windows 11,\
          \ RTX4090, 64GB RAM\r\n\r\n![2023-05-20 030013.png](https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/6hBpbaQYeYBCbaAPMsSND.png)\r\
          \n![2023-05-20 030153.png](https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/l2i97rZwxmnv074ReKavT.png)\r\
          \n"
        updatedAt: '2023-05-20T15:13:37.588Z'
      numEdits: 0
      reactions: []
    id: 6468e3a1188ca2e6bc591d3c
    type: comment
  author: ilnurshams
  content: "Coul you please advise how can I fix the issue when a model does not reply\
    \ to my message?\r\nSo there is an endless typing ( see pictures ). I've reduced\
    \ token sizes to min. Chat mode.\r\nRunning on Windows 11, RTX4090, 64GB RAM\r\
    \n\r\n![2023-05-20 030013.png](https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/6hBpbaQYeYBCbaAPMsSND.png)\r\
    \n![2023-05-20 030153.png](https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/l2i97rZwxmnv074ReKavT.png)\r\
    \n"
  created_at: 2023-05-20 14:13:37+00:00
  edited: false
  hidden: false
  id: 6468e3a1188ca2e6bc591d3c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1b8f6efcb624e6624b0b8c4e99159c40.svg
      fullname: scepter
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: scepter
      type: user
    createdAt: '2023-05-21T01:11:49.000Z'
    data:
      edited: false
      editors:
      - scepter
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1b8f6efcb624e6624b0b8c4e99159c40.svg
          fullname: scepter
          isHf: false
          isPro: false
          name: scepter
          type: user
        html: '<p>The same problem here, "''LlamaForCausalLM'' object has no attribute
          ''generate_with_streaming''" in the console. Linux, RTX 4090, 24 VRAM</p>

          '
        raw: The same problem here, "'LlamaForCausalLM' object has no attribute 'generate_with_streaming'"
          in the console. Linux, RTX 4090, 24 VRAM
        updatedAt: '2023-05-21T01:11:49.070Z'
      numEdits: 0
      reactions: []
    id: 64696fd57407ab1cff3d759f
    type: comment
  author: scepter
  content: The same problem here, "'LlamaForCausalLM' object has no attribute 'generate_with_streaming'"
    in the console. Linux, RTX 4090, 24 VRAM
  created_at: 2023-05-21 00:11:49+00:00
  edited: false
  hidden: false
  id: 64696fd57407ab1cff3d759f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/aeb28ba60e2961c979bf0787bc90e40c.svg
      fullname: ilnurshams
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ilnurshams
      type: user
    createdAt: '2023-05-25T15:32:32.000Z'
    data:
      edited: false
      editors:
      - ilnurshams
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/aeb28ba60e2961c979bf0787bc90e40c.svg
          fullname: ilnurshams
          isHf: false
          isPro: false
          name: ilnurshams
          type: user
        html: '<p>Okay, I fixed it. I don''t know what was the reason.</p>

          <ol>

          <li>Fresh install of oobabooga one-click installers</li>

          <li>Start start_windows file. Don''t dowload any model!</li>

          <li>I manually downloaded the necessary model files from <a href="https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-4bit/tree/main">https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-4bit/tree/main</a><br>(
          see picture in attachment ) and put in oobabooga models folder.</li>

          <li>I installed pytorch and cuda via Conda ( download and install Conda
          first, then run Anaconda Prompt ( miniconda3 ) as admin ). There I run these
          code ( in order to install pytorch and cuda ). You also need to have python
          3.10 as I had it already ( download it )!<br>conda create --name gptq python=3.10
          -y<br>conda activate gptq<br>conda install pytorch torchvision torchaudio
          pytorch-cuda=11.7 -c pytorch -c nvidia</li>

          </ol>

          <p>( I used this tutorial, but it is for linux. <a rel="nofollow" href="https://github.com/qwopqwop200/GPTQ-for-LLaMa">https://github.com/qwopqwop200/GPTQ-for-LLaMa</a><br>I
          used only code from tutorial to install pytorch and cuda )</p>

          <ol start="5">

          <li>Then I run update_windows file in oobabooga main folder.<br>Done!</li>

          </ol>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/UqPFMKlXyTafeygdw3L25.png"><img
          alt="Screenshot 2023-05-25 181833.png" src="https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/UqPFMKlXyTafeygdw3L25.png"></a></p>

          '
        raw: 'Okay, I fixed it. I don''t know what was the reason.


          1. Fresh install of oobabooga one-click installers

          2. Start start_windows file. Don''t dowload any model!

          3. I manually downloaded the necessary model files from https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-4bit/tree/main

          ( see picture in attachment ) and put in oobabooga models folder.

          4. I installed pytorch and cuda via Conda ( download and install Conda first,
          then run Anaconda Prompt ( miniconda3 ) as admin ). There I run these code
          ( in order to install pytorch and cuda ). You also need to have python 3.10
          as I had it already ( download it )!

          conda create --name gptq python=3.10 -y

          conda activate gptq

          conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch
          -c nvidia


          ( I used this tutorial, but it is for linux. https://github.com/qwopqwop200/GPTQ-for-LLaMa

          I used only code from tutorial to install pytorch and cuda )


          5. Then I run update_windows file in oobabooga main folder.

          Done!


          ![Screenshot 2023-05-25 181833.png](https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/UqPFMKlXyTafeygdw3L25.png)'
        updatedAt: '2023-05-25T15:32:32.103Z'
      numEdits: 0
      reactions: []
      relatedEventId: 646f7f90d1f1b73079e83f67
    id: 646f7f90d1f1b73079e83f66
    type: comment
  author: ilnurshams
  content: 'Okay, I fixed it. I don''t know what was the reason.


    1. Fresh install of oobabooga one-click installers

    2. Start start_windows file. Don''t dowload any model!

    3. I manually downloaded the necessary model files from https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-4bit/tree/main

    ( see picture in attachment ) and put in oobabooga models folder.

    4. I installed pytorch and cuda via Conda ( download and install Conda first,
    then run Anaconda Prompt ( miniconda3 ) as admin ). There I run these code ( in
    order to install pytorch and cuda ). You also need to have python 3.10 as I had
    it already ( download it )!

    conda create --name gptq python=3.10 -y

    conda activate gptq

    conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia


    ( I used this tutorial, but it is for linux. https://github.com/qwopqwop200/GPTQ-for-LLaMa

    I used only code from tutorial to install pytorch and cuda )


    5. Then I run update_windows file in oobabooga main folder.

    Done!


    ![Screenshot 2023-05-25 181833.png](https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/UqPFMKlXyTafeygdw3L25.png)'
  created_at: 2023-05-25 14:32:32+00:00
  edited: false
  hidden: false
  id: 646f7f90d1f1b73079e83f66
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/aeb28ba60e2961c979bf0787bc90e40c.svg
      fullname: ilnurshams
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ilnurshams
      type: user
    createdAt: '2023-05-25T15:32:32.000Z'
    data:
      status: closed
    id: 646f7f90d1f1b73079e83f67
    type: status-change
  author: ilnurshams
  created_at: 2023-05-25 14:32:32+00:00
  id: 646f7f90d1f1b73079e83f67
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 14
repo_id: MetaIX/GPT4-X-Alpaca-30B-4bit
repo_type: model
status: closed
target_branch: null
title: Model does not reply ( Is typing.. ) / MetaIX/GPT4-X-Alpaca-30B-4bit
