!!python/object:huggingface_hub.community.DiscussionWithDetails
author: KennyUTC
conflicting_files: null
created_at: 2024-01-24 13:50:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676546883247-noauth.png?w=200&h=200&f=face
      fullname: HAODONG DUAN
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KennyUTC
      type: user
    createdAt: '2024-01-24T13:50:57.000Z'
    data:
      edited: false
      editors:
      - KennyUTC
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7598074674606323
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676546883247-noauth.png?w=200&h=200&f=face
          fullname: HAODONG DUAN
          isHf: false
          isPro: false
          name: KennyUTC
          type: user
        html: "<p>Codebase: <a rel=\"nofollow\" href=\"https://github.com/open-compass/VLMEvalKit\"\
          >https://github.com/open-compass/VLMEvalKit</a><br>Model Class: <a rel=\"\
          nofollow\" href=\"https://github.com/open-compass/VLMEvalKit/blob/main/vlmeval/vlm/yi_vl.py\"\
          >https://github.com/open-compass/VLMEvalKit/blob/main/vlmeval/vlm/yi_vl.py</a><br>Steps\
          \ to run Yi-VL:</p>\n<pre><code>You can perform inference of Yi-VL through\
          \ the following steps:\n1. clone the repo https://github.com/01-ai/Yi to\
          \ path-to-Yi\n2. set up the environment and install the required packages\
          \ in path-to-Yi/VL/requirements.txt\n3. set Yi_ROOT in vlmeval/config.py\
          \ \n    Yi_ROOT = path-to-Yi\n\nYou are all set now! To run a demo for Yi-VL:\n\
          \nfrom vlmeval import *\nmodel = supported_VLM['Yi_VL_6B']()\nmodel.generate('apple.jpg',\
          \ 'What is in this image?')\n\nTo run evaluation for Yi-VL, use `python\
          \ run.py --model Yi_VL_6B --data {dataset_list}`\n</code></pre>\n"
        raw: "Codebase: https://github.com/open-compass/VLMEvalKit\r\nModel Class:\
          \ https://github.com/open-compass/VLMEvalKit/blob/main/vlmeval/vlm/yi_vl.py\r\
          \nSteps to run Yi-VL:\r\n```\r\nYou can perform inference of Yi-VL through\
          \ the following steps:\r\n1. clone the repo https://github.com/01-ai/Yi\
          \ to path-to-Yi\r\n2. set up the environment and install the required packages\
          \ in path-to-Yi/VL/requirements.txt\r\n3. set Yi_ROOT in vlmeval/config.py\
          \ \r\n    Yi_ROOT = path-to-Yi\r\n\r\nYou are all set now! To run a demo\
          \ for Yi-VL:\r\n\r\nfrom vlmeval import *\r\nmodel = supported_VLM['Yi_VL_6B']()\r\
          \nmodel.generate('apple.jpg', 'What is in this image?')\r\n\r\nTo run evaluation\
          \ for Yi-VL, use `python run.py --model Yi_VL_6B --data {dataset_list}`\r\
          \n```"
        updatedAt: '2024-01-24T13:50:57.025Z'
      numEdits: 0
      reactions: []
    id: 65b115c1f30a30ec2a8acbe7
    type: comment
  author: KennyUTC
  content: "Codebase: https://github.com/open-compass/VLMEvalKit\r\nModel Class: https://github.com/open-compass/VLMEvalKit/blob/main/vlmeval/vlm/yi_vl.py\r\
    \nSteps to run Yi-VL:\r\n```\r\nYou can perform inference of Yi-VL through the\
    \ following steps:\r\n1. clone the repo https://github.com/01-ai/Yi to path-to-Yi\r\
    \n2. set up the environment and install the required packages in path-to-Yi/VL/requirements.txt\r\
    \n3. set Yi_ROOT in vlmeval/config.py \r\n    Yi_ROOT = path-to-Yi\r\n\r\nYou\
    \ are all set now! To run a demo for Yi-VL:\r\n\r\nfrom vlmeval import *\r\nmodel\
    \ = supported_VLM['Yi_VL_6B']()\r\nmodel.generate('apple.jpg', 'What is in this\
    \ image?')\r\n\r\nTo run evaluation for Yi-VL, use `python run.py --model Yi_VL_6B\
    \ --data {dataset_list}`\r\n```"
  created_at: 2024-01-24 13:50:57+00:00
  edited: false
  hidden: false
  id: 65b115c1f30a30ec2a8acbe7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: 01-ai/Yi-VL-6B
repo_type: model
status: open
target_branch: null
title: '[Demo] VLMEvalKit now supported demo and evaluation for Yi-VL'
