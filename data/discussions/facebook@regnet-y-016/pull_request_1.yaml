!!python/object:huggingface_hub.community.DiscussionWithDetails
author: joaogante
conflicting_files: []
created_at: 2022-06-28 10:01:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641203017724-noauth.png?w=200&h=200&f=face
      fullname: Joao Gante
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joaogante
      type: user
    createdAt: '2022-06-28T11:01:09.000Z'
    data:
      edited: false
      editors:
      - joaogante
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641203017724-noauth.png?w=200&h=200&f=face
          fullname: Joao Gante
          isHf: true
          isPro: false
          name: joaogante
          type: user
        html: "<p>Model converted by the <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/blob/main/src/transformers/commands/pt_to_tf.py\"\
          ><code>transformers</code>' <code>pt_to_tf</code> CLI</a>.</p>\n<p>All converted\
          \ model outputs and hidden layers were validated against its Pytorch counterpart.\
          \ Maximum crossload output difference=7.744e-04; Maximum converted output\
          \ difference=7.744e-04.</p>\n<p>cc <span data-props=\"{&quot;user&quot;:&quot;patrickvonplaten&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/patrickvonplaten\"\
          >@<span class=\"underline\">patrickvonplaten</span></a></span>\n\n\t</span></span>\
          \ [HF maintainer(s) for this repo]</p>\n"
        raw: 'Model converted by the [`transformers`'' `pt_to_tf` CLI](https://github.com/huggingface/transformers/blob/main/src/transformers/commands/pt_to_tf.py).


          All converted model outputs and hidden layers were validated against its
          Pytorch counterpart. Maximum crossload output difference=7.744e-04; Maximum
          converted output difference=7.744e-04.


          cc @patrickvonplaten [HF maintainer(s) for this repo]'
        updatedAt: '2022-06-28T11:01:09.818Z'
      numEdits: 0
      reactions: []
    id: 62badf75858852c8003c84e5
    type: comment
  author: joaogante
  content: 'Model converted by the [`transformers`'' `pt_to_tf` CLI](https://github.com/huggingface/transformers/blob/main/src/transformers/commands/pt_to_tf.py).


    All converted model outputs and hidden layers were validated against its Pytorch
    counterpart. Maximum crossload output difference=7.744e-04; Maximum converted
    output difference=7.744e-04.


    cc @patrickvonplaten [HF maintainer(s) for this repo]'
  created_at: 2022-06-28 10:01:09+00:00
  edited: false
  hidden: false
  id: 62badf75858852c8003c84e5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641203017724-noauth.png?w=200&h=200&f=face
      fullname: Joao Gante
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joaogante
      type: user
    createdAt: '2022-06-28T11:01:10.000Z'
    data:
      oid: ba10a5a4ff54b4b1dea2e97878b9eeec0cec9576
      parents:
      - e173ec1dc1dc9248c399974d1c003cd06ddb98d9
      subject: Add TF weights
    id: 62badf760000000000000000
    type: commit
  author: joaogante
  created_at: 2022-06-28 10:01:10+00:00
  id: 62badf760000000000000000
  oid: ba10a5a4ff54b4b1dea2e97878b9eeec0cec9576
  summary: Add TF weights
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641203017724-noauth.png?w=200&h=200&f=face
      fullname: Joao Gante
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joaogante
      type: user
    createdAt: '2022-06-28T11:04:17.000Z'
    data:
      edited: false
      editors:
      - joaogante
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641203017724-noauth.png?w=200&h=200&f=face
          fullname: Joao Gante
          isHf: true
          isPro: false
          name: joaogante
          type: user
        html: "<p>Related PR: <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/pull/17554\"\
          >https://github.com/huggingface/transformers/pull/17554</a></p>\n<p>The\
          \ error on the internal hidden layers was slightly above the desired level\
          \ (&lt;1e-5), but the output layers were fine. cc <span data-props=\"{&quot;user&quot;:&quot;sayakpaul&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sayakpaul\"\
          >@<span class=\"underline\">sayakpaul</span></a></span>\n\n\t</span></span>\
          \ <span data-props=\"{&quot;user&quot;:&quot;nielsr&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/nielsr\">@<span class=\"\
          underline\">nielsr</span></a></span>\n\n\t</span></span></p>\n"
        raw: 'Related PR: https://github.com/huggingface/transformers/pull/17554


          The error on the internal hidden layers was slightly above the desired level
          (<1e-5), but the output layers were fine. cc @sayakpaul @nielsr'
        updatedAt: '2022-06-28T11:04:17.585Z'
      numEdits: 0
      reactions: []
    id: 62bae03168bc5c8274791a1e
    type: comment
  author: joaogante
  content: 'Related PR: https://github.com/huggingface/transformers/pull/17554


    The error on the internal hidden layers was slightly above the desired level (<1e-5),
    but the output layers were fine. cc @sayakpaul @nielsr'
  created_at: 2022-06-28 10:04:17+00:00
  edited: false
  hidden: false
  id: 62bae03168bc5c8274791a1e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648203221604-61f91fd5a0f47976407d920f.jpeg?w=200&h=200&f=face
      fullname: Carted
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: carted-ml
      type: user
    createdAt: '2022-06-28T11:20:28.000Z'
    data:
      edited: false
      editors:
      - carted-ml
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648203221604-61f91fd5a0f47976407d920f.jpeg?w=200&h=200&f=face
          fullname: Carted
          isHf: false
          isPro: false
          name: carted-ml
          type: user
        html: "<blockquote>\n<p>The error on the internal hidden layers was slightly\
          \ above the desired level (&lt;1e-5), but the output layers were fine</p>\n\
          </blockquote>\n<p>Those probably were because of <code>num_batches_tracked</code>\
          \ as used in PyTorch's BatchNorm layers. There's relevant information here:\
          \ <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/pull/17554\"\
          >https://github.com/huggingface/transformers/pull/17554</a>. </p>\n<p>Cc:\
          \ <span data-props=\"{&quot;user&quot;:&quot;amyeroberts&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/amyeroberts\">@<span\
          \ class=\"underline\">amyeroberts</span></a></span>\n\n\t</span></span></p>\n"
        raw: "> The error on the internal hidden layers was slightly above the desired\
          \ level (<1e-5), but the output layers were fine\n\nThose probably were\
          \ because of `num_batches_tracked` as used in PyTorch's BatchNorm layers.\
          \ There's relevant information here: https://github.com/huggingface/transformers/pull/17554.\
          \ \n\nCc: @amyeroberts"
        updatedAt: '2022-06-28T11:20:28.100Z'
      numEdits: 0
      reactions: []
    id: 62bae3fc5e3622305c827b9e
    type: comment
  author: carted-ml
  content: "> The error on the internal hidden layers was slightly above the desired\
    \ level (<1e-5), but the output layers were fine\n\nThose probably were because\
    \ of `num_batches_tracked` as used in PyTorch's BatchNorm layers. There's relevant\
    \ information here: https://github.com/huggingface/transformers/pull/17554. \n\
    \nCc: @amyeroberts"
  created_at: 2022-06-28 10:20:28+00:00
  edited: false
  hidden: false
  id: 62bae3fc5e3622305c827b9e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641203017724-noauth.png?w=200&h=200&f=face
      fullname: Joao Gante
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joaogante
      type: user
    createdAt: '2022-06-28T11:37:02.000Z'
    data:
      edited: true
      editors:
      - joaogante
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641203017724-noauth.png?w=200&h=200&f=face
          fullname: Joao Gante
          isHf: true
          isPro: false
          name: joaogante
          type: user
        html: '<p>It''s probably it''s not the case -- we have many models where these
          differences in the internal layers exist, but the output layers have the
          correct values. We haven''t figured out why, but it seems that it is no
          cause for alarm. Models where needed weights are not being loaded have very
          big errors everywhere.</p>

          <p>Nevertheless, I reported it above in case we need to revisit the models
          with this mismatch :)</p>

          '
        raw: 'It''s probably it''s not the case -- we have many models where these
          differences in the internal layers exist, but the output layers have the
          correct values. We haven''t figured out why, but it seems that it is no
          cause for alarm. Models where needed weights are not being loaded have very
          big errors everywhere.


          Nevertheless, I reported it above in case we need to revisit the models
          with this mismatch :)'
        updatedAt: '2022-06-28T11:40:13.893Z'
      numEdits: 2
      reactions: []
    id: 62bae7de31e684f87a53706c
    type: comment
  author: joaogante
  content: 'It''s probably it''s not the case -- we have many models where these differences
    in the internal layers exist, but the output layers have the correct values. We
    haven''t figured out why, but it seems that it is no cause for alarm. Models where
    needed weights are not being loaded have very big errors everywhere.


    Nevertheless, I reported it above in case we need to revisit the models with this
    mismatch :)'
  created_at: 2022-06-28 10:37:02+00:00
  edited: true
  hidden: false
  id: 62bae7de31e684f87a53706c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2022-06-28T11:38:35.000Z'
    data:
      edited: false
      editors:
      - nielsr
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: '<p>Thanks for adding!</p>

          '
        raw: Thanks for adding!
        updatedAt: '2022-06-28T11:38:35.873Z'
      numEdits: 0
      reactions: []
    id: 62bae83b858852c8003d2c43
    type: comment
  author: nielsr
  content: Thanks for adding!
  created_at: 2022-06-28 10:38:35+00:00
  edited: false
  hidden: false
  id: 62bae83b858852c8003d2c43
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2022-06-28T11:38:43.000Z'
    data:
      status: merged
    id: 62bae8435e3622305c82cba7
    type: status-change
  author: nielsr
  created_at: 2022-06-28 10:38:43+00:00
  id: 62bae8435e3622305c82cba7
  new_status: merged
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1650360288463-noauth.jpeg?w=200&h=200&f=face
      fullname: Amy Roberts
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: amyeroberts
      type: user
    createdAt: '2022-06-28T11:40:02.000Z'
    data:
      edited: false
      editors:
      - amyeroberts
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1650360288463-noauth.jpeg?w=200&h=200&f=face
          fullname: Amy Roberts
          isHf: true
          isPro: false
          name: amyeroberts
          type: user
        html: '<p>I''m not sure that accounts for the differences here. As mentioned
          in the PR <a rel="nofollow" href="https://github.com/huggingface/transformers/pull/17554#issuecomment-1149672281">https://github.com/huggingface/transformers/pull/17554#issuecomment-1149672281</a>,
          <code>num_batches_tracked</code> is important only if momentum isn''t set
          and my understanding is it was set for all batch norm layers.</p>

          '
        raw: I'm not sure that accounts for the differences here. As mentioned in
          the PR https://github.com/huggingface/transformers/pull/17554#issuecomment-1149672281,
          `num_batches_tracked` is important only if momentum isn't set and my understanding
          is it was set for all batch norm layers.
        updatedAt: '2022-06-28T11:40:02.692Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - julien-c
    id: 62bae8921b4921b8fd04f971
    type: comment
  author: amyeroberts
  content: I'm not sure that accounts for the differences here. As mentioned in the
    PR https://github.com/huggingface/transformers/pull/17554#issuecomment-1149672281,
    `num_batches_tracked` is important only if momentum isn't set and my understanding
    is it was set for all batch norm layers.
  created_at: 2022-06-28 10:40:02+00:00
  edited: false
  hidden: false
  id: 62bae8921b4921b8fd04f971
  type: comment
is_pull_request: true
merge_commit_oid: 5f453e35ddd0a5c1297dec982ac984a1359a8850
num: 1
repo_id: facebook/regnet-y-016
repo_type: model
status: merged
target_branch: refs/heads/main
title: Add TF weights
