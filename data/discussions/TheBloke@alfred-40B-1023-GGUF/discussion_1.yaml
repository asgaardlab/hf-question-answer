!!python/object:huggingface_hub.community.DiscussionWithDetails
author: cvinker
conflicting_files: null
created_at: 2023-11-17 19:56:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b10d5d067bc3f7d2778d3decbc5d0a71.svg
      fullname: Colin Vink
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cvinker
      type: user
    createdAt: '2023-11-17T19:56:21.000Z'
    data:
      edited: false
      editors:
      - cvinker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2617417871952057
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b10d5d067bc3f7d2778d3decbc5d0a71.svg
          fullname: Colin Vink
          isHf: false
          isPro: false
          name: cvinker
          type: user
        html: "<p>I had it working fine in LM studio but it wasn't following instructions,\
          \ so I wanted to try it in TGWUI. When I try and load it I get this error:</p>\n\
          <pre><code>ERROR: byte not found in vocab: '\n'\n2023-11-17 14:52:47 ERROR:Failed\
          \ to load the model.\nTraceback (most recent call last):\n  File \"C:\\\
          Users\\Colin\\Downloads\\text-generation-webui-main\\modules\\ui_model_menu.py\"\
          , line 210, in load_model_wrapper\n    shared.model, shared.tokenizer =\
          \ load_model(shared.model_name, loader)\n                              \
          \       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Colin\\\
          Downloads\\text-generation-webui-main\\modules\\models.py\", line 85, in\
          \ load_model\n    output = load_func_map[loader](model_name)\n         \
          \    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Colin\\Downloads\\\
          text-generation-webui-main\\modules\\models.py\", line 249, in llamacpp_loader\n\
          \    model, tokenizer = LlamaCppModel.from_pretrained(model_file)\n    \
          \                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"\
          C:\\Users\\Colin\\Downloads\\text-generation-webui-main\\modules\\llamacpp_model.py\"\
          , line 91, in from_pretrained\n    result.model = Llama(**params)\n    \
          \               ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Colin\\Downloads\\\
          text-generation-webui-main\\installer_files\\env\\Lib\\site-packages\\llama_cpp_cuda\\\
          llama.py\", line 357, in __init__\n    self.model = llama_cpp.llama_load_model_from_file(\n\
          \                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\\
          Colin\\Downloads\\text-generation-webui-main\\installer_files\\env\\Lib\\\
          site-packages\\llama_cpp_cuda\\llama_cpp.py\", line 498, in llama_load_model_from_file\n\
          \    return _lib.llama_load_model_from_file(path_model, params)\n      \
          \     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: exception:\
          \ access violation reading 0x0000000000000000\n\nException ignored in: &lt;function\
          \ LlamaCppModel.__del__ at 0x000001A567833880&gt;\nTraceback (most recent\
          \ call last):\n  File \"C:\\Users\\Colin\\Downloads\\text-generation-webui-main\\\
          modules\\llamacpp_model.py\", line 49, in __del__\n    self.model.__del__()\n\
          \    ^^^^^^^^^^\nAttributeError: 'LlamaCppModel' object has no attribute\
          \ 'model'\n</code></pre>\n<p>Any ideas? Thank you for the quantized models\
          \ always.</p>\n"
        raw: "I had it working fine in LM studio but it wasn't following instructions,\
          \ so I wanted to try it in TGWUI. When I try and load it I get this error:\r\
          \n```\r\nERROR: byte not found in vocab: '\r\n'\r\n2023-11-17 14:52:47 ERROR:Failed\
          \ to load the model.\r\nTraceback (most recent call last):\r\n  File \"\
          C:\\Users\\Colin\\Downloads\\text-generation-webui-main\\modules\\ui_model_menu.py\"\
          , line 210, in load_model_wrapper\r\n    shared.model, shared.tokenizer\
          \ = load_model(shared.model_name, loader)\r\n                          \
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\\
          Colin\\Downloads\\text-generation-webui-main\\modules\\models.py\", line\
          \ 85, in load_model\r\n    output = load_func_map[loader](model_name)\r\n\
          \             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\\
          Colin\\Downloads\\text-generation-webui-main\\modules\\models.py\", line\
          \ 249, in llamacpp_loader\r\n    model, tokenizer = LlamaCppModel.from_pretrained(model_file)\r\
          \n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n \
          \ File \"C:\\Users\\Colin\\Downloads\\text-generation-webui-main\\modules\\\
          llamacpp_model.py\", line 91, in from_pretrained\r\n    result.model = Llama(**params)\r\
          \n                   ^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\Colin\\Downloads\\\
          text-generation-webui-main\\installer_files\\env\\Lib\\site-packages\\llama_cpp_cuda\\\
          llama.py\", line 357, in __init__\r\n    self.model = llama_cpp.llama_load_model_from_file(\r\
          \n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\\
          Users\\Colin\\Downloads\\text-generation-webui-main\\installer_files\\env\\\
          Lib\\site-packages\\llama_cpp_cuda\\llama_cpp.py\", line 498, in llama_load_model_from_file\r\
          \n    return _lib.llama_load_model_from_file(path_model, params)\r\n   \
          \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nOSError:\
          \ exception: access violation reading 0x0000000000000000\r\n\r\nException\
          \ ignored in: <function LlamaCppModel.__del__ at 0x000001A567833880>\r\n\
          Traceback (most recent call last):\r\n  File \"C:\\Users\\Colin\\Downloads\\\
          text-generation-webui-main\\modules\\llamacpp_model.py\", line 49, in __del__\r\
          \n    self.model.__del__()\r\n    ^^^^^^^^^^\r\nAttributeError: 'LlamaCppModel'\
          \ object has no attribute 'model'\r\n```\r\n\r\nAny ideas? Thank you for\
          \ the quantized models always."
        updatedAt: '2023-11-17T19:56:21.688Z'
      numEdits: 0
      reactions: []
    id: 6557c565539d4b7c13071ff5
    type: comment
  author: cvinker
  content: "I had it working fine in LM studio but it wasn't following instructions,\
    \ so I wanted to try it in TGWUI. When I try and load it I get this error:\r\n\
    ```\r\nERROR: byte not found in vocab: '\r\n'\r\n2023-11-17 14:52:47 ERROR:Failed\
    \ to load the model.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\\
    Colin\\Downloads\\text-generation-webui-main\\modules\\ui_model_menu.py\", line\
    \ 210, in load_model_wrapper\r\n    shared.model, shared.tokenizer = load_model(shared.model_name,\
    \ loader)\r\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"C:\\Users\\Colin\\Downloads\\text-generation-webui-main\\modules\\\
    models.py\", line 85, in load_model\r\n    output = load_func_map[loader](model_name)\r\
    \n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\Colin\\\
    Downloads\\text-generation-webui-main\\modules\\models.py\", line 249, in llamacpp_loader\r\
    \n    model, tokenizer = LlamaCppModel.from_pretrained(model_file)\r\n       \
    \                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\\
    Colin\\Downloads\\text-generation-webui-main\\modules\\llamacpp_model.py\", line\
    \ 91, in from_pretrained\r\n    result.model = Llama(**params)\r\n           \
    \        ^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\Colin\\Downloads\\text-generation-webui-main\\\
    installer_files\\env\\Lib\\site-packages\\llama_cpp_cuda\\llama.py\", line 357,\
    \ in __init__\r\n    self.model = llama_cpp.llama_load_model_from_file(\r\n  \
    \               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\\
    Colin\\Downloads\\text-generation-webui-main\\installer_files\\env\\Lib\\site-packages\\\
    llama_cpp_cuda\\llama_cpp.py\", line 498, in llama_load_model_from_file\r\n  \
    \  return _lib.llama_load_model_from_file(path_model, params)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \nOSError: exception: access violation reading 0x0000000000000000\r\n\r\nException\
    \ ignored in: <function LlamaCppModel.__del__ at 0x000001A567833880>\r\nTraceback\
    \ (most recent call last):\r\n  File \"C:\\Users\\Colin\\Downloads\\text-generation-webui-main\\\
    modules\\llamacpp_model.py\", line 49, in __del__\r\n    self.model.__del__()\r\
    \n    ^^^^^^^^^^\r\nAttributeError: 'LlamaCppModel' object has no attribute 'model'\r\
    \n```\r\n\r\nAny ideas? Thank you for the quantized models always."
  created_at: 2023-11-17 19:56:21+00:00
  edited: false
  hidden: false
  id: 6557c565539d4b7c13071ff5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1f89cd6a94e4a1e5fea6767a78ba5a0c.svg
      fullname: Vermeille
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vermifuge
      type: user
    createdAt: '2023-11-17T20:11:20.000Z'
    data:
      edited: true
      editors:
      - Vermifuge
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9993008971214294
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1f89cd6a94e4a1e5fea6767a78ba5a0c.svg
          fullname: Vermeille
          isHf: false
          isPro: false
          name: Vermifuge
          type: user
        html: '<p>[deleted]</p>

          '
        raw: '[deleted]'
        updatedAt: '2023-11-18T00:34:23.230Z'
      numEdits: 1
      reactions: []
    id: 6557c8e8b1b102df8cdcf754
    type: comment
  author: Vermifuge
  content: '[deleted]'
  created_at: 2023-11-17 20:11:20+00:00
  edited: true
  hidden: false
  id: 6557c8e8b1b102df8cdcf754
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-17T22:03:15.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9650893807411194
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p>That's the error that llama-cpp-python always gives when it generically\
          \ can't load the model for some reason</p>\n<p>I've not tested llama-cpp-python\
          \ with non Llama models recently. In theory it shoud work, as they're all\
          \ GGUF now, but it's possible there's some issue there..</p>\n<p>In the\
          \ past llama-cpp-python did have issues with BPE vocab models, and this\
          \ is a BPE vocab model. I thought that was fixed, but maybe not.</p>\n<p>I\
          \ tested it in llama.cpp and it appears to work great</p>\n<pre><code> CUDA_VISIBLE_DEVICES=0\
          \ ./main -m /workspace/process/lightonai_alfred-40b-1023/gguf/alfred-40b-1023.Q4_K_M.gguf\
          \ -p \"&lt;start_system&gt;You are Alfred, a helpful assistant trained by\
          \ LightOn. Knowledge cutoff: November 2022. Current date: 16 November, 2023&lt;end_message&gt;&lt;start_user&gt;Write\
          \ a story about llamas&lt;end_message&gt;&lt;start_assistant&gt;\"  -ngl\
          \ 100\n</code></pre>\n<p>Output 1:</p>\n<pre><code>You are Alfred, a helpful\
          \ assistant trained by LightOn. Knowledge cutoff: November 2022. Current\
          \ date: 16 November, 2023Write a story about llamasThe llamas had always\
          \ known that the humans were strange, but they never could have imagined\
          \ what they would find when they looked at them with their powerful telescopes.\n\
          \nThere was a large telescope array on the dark side of the moon, where\
          \ there is no interference from radio waves. The array was powered by solar\
          \ panels and was designed to look for signs of intelligent life in other\
          \ parts of the galaxy.\n\nThe scientists who worked at the array were surprised\
          \ to receive signals coming from the planet Earth that seemed to contain\
          \ information about how to build a large space telescope. The scientists\
          \ decided to point their own telescope array back at Earth to see if they\
          \ could get a better signal.\n\nWhen the scientists looked through their\
          \ own telescope, they saw llamas looking back at them. It turned out that\
          \ the humans had evolved from llamas millions of years ago, but the two\
          \ species had gone their separate ways and lost contact with each other.\n\
          \nThe scientists decided to send a message back to Earth in the hopes that\
          \ the llamas would be able to understand it. The message contained instructions\
          \ on how to build an even larger telescope array that could receive signals\
          \ from much farther away.\n\nThe llamas were skeptical at first, but they\
          \ eventually decided to give it a try. They built the telescope array and\
          \ pointed it towards the moon, where they knew the original signal had come\
          \ from.\n\nWhen the llamas looked through the telescope, they saw images\
          \ of the scientists who had originally sent the message. The scientists\
          \ waved and smiled, and the llamas realized that they were not alone in\
          \ the universe after all. [end of text]\n</code></pre>\n<p>Output 2:</p>\n\
          <pre><code>You are Alfred, a helpful assistant trained by LightOn. Knowledge\
          \ cutoff: November 2022. Current date: 16 November, 2023Write a story about\
          \ llamasOnce upon a time in a faraway land called Llama Land lived many\
          \ llamas. The llamas were happy and peaceful people who loved to dance,\
          \ play music, and spend time with their families. One day, the king of the\
          \ llamas decided to hold a grand celebration to honor his daughter's birthday.\n\
          \nThe kingdom was filled with excitement as preparations began for the big\
          \ event. Everyone worked hard to decorate the streets with colorful banners\
          \ and flowers. Bakers baked delicious cakes and pastries, while chefs prepared\
          \ mouth-watering dishes from fresh ingredients grown in the royal gardens.\
          \ Musicians tuned their instruments, ready to perform joyful songs that\
          \ would fill the air with melody.\n\nOn the day of the princess's birthday,\
          \ all the llamas gathered at the palace courtyard to join in the festivities.\
          \ The atmosphere was filled with laughter and joy as friends reunited and\
          \ families spent time together, sharing stories and memories. But most importantly,\
          \ everyone came together to celebrate the love and happiness that the little\
          \ princess brought into their lives.\n\nAs night fell upon Llama Land, a\
          \ magnificent fireworks display lit up the sky in brilliant colors, creating\
          \ patterns that danced across the heavens like magical creatures come alive.\
          \ And beneath it all, surrounded by those who loved her most dearly, stood\
          \ the birthday girl herself \u2013 a beautiful young llama whose smile radiated\
          \ brighter than any firework ever could.\n\nAnd so ended another wonderful\
          \ day in Llama Land where love and happiness reigned supreme thanks to the\
          \ unbreakable bond shared between its people \u2013 human or otherwise \u2013\
          \ who cherished each moment spent together like precious gems worthy of\
          \ being treasured forevermore. [end of text]\n</code></pre>\n<p>Although\
          \ I did once get this output, when using CUDA, which was total mayhem </p>\n\
          <pre><code>You are Alfred, a helpful assistant trained by LightOn. Knowledge\
          \ cutoff: November 2022. Current date: 16 November, 2023Write a story about\
          \ llamasIn the lush green grassland of the Andes lived the llamas. There\
          \ was Lola, the mother llama who had given birth to three babies named Lulu,\
          \ Luca, and Lilly. One day, when they were playing in the field, they saw\
          \ something peculiar coming down from the sky. It looked like a flying saucer\
          \ made out of metal. The object came closer and finally landed right in\
          \ front of them.\n\nLola and her kids walked towards the mysterious UFO\
          \ cautiously. Suddenly, the door of the spacecraft opened with a swoosh\
          \ sound, revealing four green creatures standing inside. They had long arms\
          \ and legs with three fingers on each hand and foot respectively. Their\
          \ skin was covered by tiny scales similar to those found on reptiles such\
          \ as lizards or snakes.\n\nThe extraterrestrial beings made some unintelligible\
          \ noises while pointing at the llamas using their slender fingers equipped\
          \ with sharp claws at the tips. Despite being initially startled by these\
          \ unexpected guests from outer space, Lola realized that they meant no harm\
          \ since there was no sign of aggression on their faces which resembled humanoid\
          \ versions of turtles due to having beak-like mouths instead typical mammalian\
          \ ones such as nostrils located near eyes etcetera.\n\nLola nudged her kids\
          \ forward so they could approach these strange beings more closely without\
          \ feeling afraid anymore because curiosity had finally overcome fear within\
          \ each member present including herself too now that she understood there\
          \ was nothing dangerous about those who came here seeking only peaceful\
          \ interactions between two different species inhabiting separate worlds\
          \ linked together by chance encounter today under sunny skies above green\
          \ pastures filled with flowers blooming brightly everywhere amidst gentle\
          \ breeze blowing softly across everyone gathered around this unprecedented\
          \ meeting point bridging gap between known universe inhabited primarily\
          \ by humans along with various other forms life yet undiscovered until now\
          \ thanks largely due contributions made possible through advancements achieved\
          \ within field science technology allowing exploration beyond boundaries\
          \ previously thought unattainable except perhaps dreams fueled imagination\
          \ storytellers weaving tales fantastic adventures taking place somewhere\
          \ far away across galaxies unknown never seen before eyes behold wonders\
          \ beholden only those daring enough embark upon journey seeking answers\
          \ questions still left unanswered since beginning time itself forever asking\
          \ why how when where but also what if maybe someday soon even ourselves\
          \ might become part something greater than anything .... \n</code></pre>\n\
          <p>But then I generated a few more CUDA ones and they were fine, so I'm\
          \ not sure.</p>\n<p>It's also possible that the custom NTK-Yarn isn't fully\
          \ supported by llama.cpp yet.</p>\n"
        raw: "That's the error that llama-cpp-python always gives when it generically\
          \ can't load the model for some reason\n\nI've not tested llama-cpp-python\
          \ with non Llama models recently. In theory it shoud work, as they're all\
          \ GGUF now, but it's possible there's some issue there..\n\nIn the past\
          \ llama-cpp-python did have issues with BPE vocab models, and this is a\
          \ BPE vocab model. I thought that was fixed, but maybe not.\n\nI tested\
          \ it in llama.cpp and it appears to work great\n```\n CUDA_VISIBLE_DEVICES=0\
          \ ./main -m /workspace/process/lightonai_alfred-40b-1023/gguf/alfred-40b-1023.Q4_K_M.gguf\
          \ -p \"<start_system>You are Alfred, a helpful assistant trained by LightOn.\
          \ Knowledge cutoff: November 2022. Current date: 16 November, 2023<end_message><start_user>Write\
          \ a story about llamas<end_message><start_assistant>\"  -ngl 100\n```\n\n\
          Output 1:\n```\nYou are Alfred, a helpful assistant trained by LightOn.\
          \ Knowledge cutoff: November 2022. Current date: 16 November, 2023Write\
          \ a story about llamasThe llamas had always known that the humans were strange,\
          \ but they never could have imagined what they would find when they looked\
          \ at them with their powerful telescopes.\n\nThere was a large telescope\
          \ array on the dark side of the moon, where there is no interference from\
          \ radio waves. The array was powered by solar panels and was designed to\
          \ look for signs of intelligent life in other parts of the galaxy.\n\nThe\
          \ scientists who worked at the array were surprised to receive signals coming\
          \ from the planet Earth that seemed to contain information about how to\
          \ build a large space telescope. The scientists decided to point their own\
          \ telescope array back at Earth to see if they could get a better signal.\n\
          \nWhen the scientists looked through their own telescope, they saw llamas\
          \ looking back at them. It turned out that the humans had evolved from llamas\
          \ millions of years ago, but the two species had gone their separate ways\
          \ and lost contact with each other.\n\nThe scientists decided to send a\
          \ message back to Earth in the hopes that the llamas would be able to understand\
          \ it. The message contained instructions on how to build an even larger\
          \ telescope array that could receive signals from much farther away.\n\n\
          The llamas were skeptical at first, but they eventually decided to give\
          \ it a try. They built the telescope array and pointed it towards the moon,\
          \ where they knew the original signal had come from.\n\nWhen the llamas\
          \ looked through the telescope, they saw images of the scientists who had\
          \ originally sent the message. The scientists waved and smiled, and the\
          \ llamas realized that they were not alone in the universe after all. [end\
          \ of text]\n```\n\nOutput 2:\n```\nYou are Alfred, a helpful assistant trained\
          \ by LightOn. Knowledge cutoff: November 2022. Current date: 16 November,\
          \ 2023Write a story about llamasOnce upon a time in a faraway land called\
          \ Llama Land lived many llamas. The llamas were happy and peaceful people\
          \ who loved to dance, play music, and spend time with their families. One\
          \ day, the king of the llamas decided to hold a grand celebration to honor\
          \ his daughter's birthday.\n\nThe kingdom was filled with excitement as\
          \ preparations began for the big event. Everyone worked hard to decorate\
          \ the streets with colorful banners and flowers. Bakers baked delicious\
          \ cakes and pastries, while chefs prepared mouth-watering dishes from fresh\
          \ ingredients grown in the royal gardens. Musicians tuned their instruments,\
          \ ready to perform joyful songs that would fill the air with melody.\n\n\
          On the day of the princess's birthday, all the llamas gathered at the palace\
          \ courtyard to join in the festivities. The atmosphere was filled with laughter\
          \ and joy as friends reunited and families spent time together, sharing\
          \ stories and memories. But most importantly, everyone came together to\
          \ celebrate the love and happiness that the little princess brought into\
          \ their lives.\n\nAs night fell upon Llama Land, a magnificent fireworks\
          \ display lit up the sky in brilliant colors, creating patterns that danced\
          \ across the heavens like magical creatures come alive. And beneath it all,\
          \ surrounded by those who loved her most dearly, stood the birthday girl\
          \ herself \u2013 a beautiful young llama whose smile radiated brighter than\
          \ any firework ever could.\n\nAnd so ended another wonderful day in Llama\
          \ Land where love and happiness reigned supreme thanks to the unbreakable\
          \ bond shared between its people \u2013 human or otherwise \u2013 who cherished\
          \ each moment spent together like precious gems worthy of being treasured\
          \ forevermore. [end of text]\n```\n\nAlthough I did once get this output,\
          \ when using CUDA, which was total mayhem \n```\nYou are Alfred, a helpful\
          \ assistant trained by LightOn. Knowledge cutoff: November 2022. Current\
          \ date: 16 November, 2023Write a story about llamasIn the lush green grassland\
          \ of the Andes lived the llamas. There was Lola, the mother llama who had\
          \ given birth to three babies named Lulu, Luca, and Lilly. One day, when\
          \ they were playing in the field, they saw something peculiar coming down\
          \ from the sky. It looked like a flying saucer made out of metal. The object\
          \ came closer and finally landed right in front of them.\n\nLola and her\
          \ kids walked towards the mysterious UFO cautiously. Suddenly, the door\
          \ of the spacecraft opened with a swoosh sound, revealing four green creatures\
          \ standing inside. They had long arms and legs with three fingers on each\
          \ hand and foot respectively. Their skin was covered by tiny scales similar\
          \ to those found on reptiles such as lizards or snakes.\n\nThe extraterrestrial\
          \ beings made some unintelligible noises while pointing at the llamas using\
          \ their slender fingers equipped with sharp claws at the tips. Despite being\
          \ initially startled by these unexpected guests from outer space, Lola realized\
          \ that they meant no harm since there was no sign of aggression on their\
          \ faces which resembled humanoid versions of turtles due to having beak-like\
          \ mouths instead typical mammalian ones such as nostrils located near eyes\
          \ etcetera.\n\nLola nudged her kids forward so they could approach these\
          \ strange beings more closely without feeling afraid anymore because curiosity\
          \ had finally overcome fear within each member present including herself\
          \ too now that she understood there was nothing dangerous about those who\
          \ came here seeking only peaceful interactions between two different species\
          \ inhabiting separate worlds linked together by chance encounter today under\
          \ sunny skies above green pastures filled with flowers blooming brightly\
          \ everywhere amidst gentle breeze blowing softly across everyone gathered\
          \ around this unprecedented meeting point bridging gap between known universe\
          \ inhabited primarily by humans along with various other forms life yet\
          \ undiscovered until now thanks largely due contributions made possible\
          \ through advancements achieved within field science technology allowing\
          \ exploration beyond boundaries previously thought unattainable except perhaps\
          \ dreams fueled imagination storytellers weaving tales fantastic adventures\
          \ taking place somewhere far away across galaxies unknown never seen before\
          \ eyes behold wonders beholden only those daring enough embark upon journey\
          \ seeking answers questions still left unanswered since beginning time itself\
          \ forever asking why how when where but also what if maybe someday soon\
          \ even ourselves might become part something greater than anything ....\
          \ \n```\n\nBut then I generated a few more CUDA ones and they were fine,\
          \ so I'm not sure.\n\nIt's also possible that the custom NTK-Yarn isn't\
          \ fully supported by llama.cpp yet."
        updatedAt: '2023-11-17T22:05:45.871Z'
      numEdits: 1
      reactions: []
    id: 6557e32327902877020115b8
    type: comment
  author: TheBloke
  content: "That's the error that llama-cpp-python always gives when it generically\
    \ can't load the model for some reason\n\nI've not tested llama-cpp-python with\
    \ non Llama models recently. In theory it shoud work, as they're all GGUF now,\
    \ but it's possible there's some issue there..\n\nIn the past llama-cpp-python\
    \ did have issues with BPE vocab models, and this is a BPE vocab model. I thought\
    \ that was fixed, but maybe not.\n\nI tested it in llama.cpp and it appears to\
    \ work great\n```\n CUDA_VISIBLE_DEVICES=0 ./main -m /workspace/process/lightonai_alfred-40b-1023/gguf/alfred-40b-1023.Q4_K_M.gguf\
    \ -p \"<start_system>You are Alfred, a helpful assistant trained by LightOn. Knowledge\
    \ cutoff: November 2022. Current date: 16 November, 2023<end_message><start_user>Write\
    \ a story about llamas<end_message><start_assistant>\"  -ngl 100\n```\n\nOutput\
    \ 1:\n```\nYou are Alfred, a helpful assistant trained by LightOn. Knowledge cutoff:\
    \ November 2022. Current date: 16 November, 2023Write a story about llamasThe\
    \ llamas had always known that the humans were strange, but they never could have\
    \ imagined what they would find when they looked at them with their powerful telescopes.\n\
    \nThere was a large telescope array on the dark side of the moon, where there\
    \ is no interference from radio waves. The array was powered by solar panels and\
    \ was designed to look for signs of intelligent life in other parts of the galaxy.\n\
    \nThe scientists who worked at the array were surprised to receive signals coming\
    \ from the planet Earth that seemed to contain information about how to build\
    \ a large space telescope. The scientists decided to point their own telescope\
    \ array back at Earth to see if they could get a better signal.\n\nWhen the scientists\
    \ looked through their own telescope, they saw llamas looking back at them. It\
    \ turned out that the humans had evolved from llamas millions of years ago, but\
    \ the two species had gone their separate ways and lost contact with each other.\n\
    \nThe scientists decided to send a message back to Earth in the hopes that the\
    \ llamas would be able to understand it. The message contained instructions on\
    \ how to build an even larger telescope array that could receive signals from\
    \ much farther away.\n\nThe llamas were skeptical at first, but they eventually\
    \ decided to give it a try. They built the telescope array and pointed it towards\
    \ the moon, where they knew the original signal had come from.\n\nWhen the llamas\
    \ looked through the telescope, they saw images of the scientists who had originally\
    \ sent the message. The scientists waved and smiled, and the llamas realized that\
    \ they were not alone in the universe after all. [end of text]\n```\n\nOutput\
    \ 2:\n```\nYou are Alfred, a helpful assistant trained by LightOn. Knowledge cutoff:\
    \ November 2022. Current date: 16 November, 2023Write a story about llamasOnce\
    \ upon a time in a faraway land called Llama Land lived many llamas. The llamas\
    \ were happy and peaceful people who loved to dance, play music, and spend time\
    \ with their families. One day, the king of the llamas decided to hold a grand\
    \ celebration to honor his daughter's birthday.\n\nThe kingdom was filled with\
    \ excitement as preparations began for the big event. Everyone worked hard to\
    \ decorate the streets with colorful banners and flowers. Bakers baked delicious\
    \ cakes and pastries, while chefs prepared mouth-watering dishes from fresh ingredients\
    \ grown in the royal gardens. Musicians tuned their instruments, ready to perform\
    \ joyful songs that would fill the air with melody.\n\nOn the day of the princess's\
    \ birthday, all the llamas gathered at the palace courtyard to join in the festivities.\
    \ The atmosphere was filled with laughter and joy as friends reunited and families\
    \ spent time together, sharing stories and memories. But most importantly, everyone\
    \ came together to celebrate the love and happiness that the little princess brought\
    \ into their lives.\n\nAs night fell upon Llama Land, a magnificent fireworks\
    \ display lit up the sky in brilliant colors, creating patterns that danced across\
    \ the heavens like magical creatures come alive. And beneath it all, surrounded\
    \ by those who loved her most dearly, stood the birthday girl herself \u2013 a\
    \ beautiful young llama whose smile radiated brighter than any firework ever could.\n\
    \nAnd so ended another wonderful day in Llama Land where love and happiness reigned\
    \ supreme thanks to the unbreakable bond shared between its people \u2013 human\
    \ or otherwise \u2013 who cherished each moment spent together like precious gems\
    \ worthy of being treasured forevermore. [end of text]\n```\n\nAlthough I did\
    \ once get this output, when using CUDA, which was total mayhem \n```\nYou are\
    \ Alfred, a helpful assistant trained by LightOn. Knowledge cutoff: November 2022.\
    \ Current date: 16 November, 2023Write a story about llamasIn the lush green grassland\
    \ of the Andes lived the llamas. There was Lola, the mother llama who had given\
    \ birth to three babies named Lulu, Luca, and Lilly. One day, when they were playing\
    \ in the field, they saw something peculiar coming down from the sky. It looked\
    \ like a flying saucer made out of metal. The object came closer and finally landed\
    \ right in front of them.\n\nLola and her kids walked towards the mysterious UFO\
    \ cautiously. Suddenly, the door of the spacecraft opened with a swoosh sound,\
    \ revealing four green creatures standing inside. They had long arms and legs\
    \ with three fingers on each hand and foot respectively. Their skin was covered\
    \ by tiny scales similar to those found on reptiles such as lizards or snakes.\n\
    \nThe extraterrestrial beings made some unintelligible noises while pointing at\
    \ the llamas using their slender fingers equipped with sharp claws at the tips.\
    \ Despite being initially startled by these unexpected guests from outer space,\
    \ Lola realized that they meant no harm since there was no sign of aggression\
    \ on their faces which resembled humanoid versions of turtles due to having beak-like\
    \ mouths instead typical mammalian ones such as nostrils located near eyes etcetera.\n\
    \nLola nudged her kids forward so they could approach these strange beings more\
    \ closely without feeling afraid anymore because curiosity had finally overcome\
    \ fear within each member present including herself too now that she understood\
    \ there was nothing dangerous about those who came here seeking only peaceful\
    \ interactions between two different species inhabiting separate worlds linked\
    \ together by chance encounter today under sunny skies above green pastures filled\
    \ with flowers blooming brightly everywhere amidst gentle breeze blowing softly\
    \ across everyone gathered around this unprecedented meeting point bridging gap\
    \ between known universe inhabited primarily by humans along with various other\
    \ forms life yet undiscovered until now thanks largely due contributions made\
    \ possible through advancements achieved within field science technology allowing\
    \ exploration beyond boundaries previously thought unattainable except perhaps\
    \ dreams fueled imagination storytellers weaving tales fantastic adventures taking\
    \ place somewhere far away across galaxies unknown never seen before eyes behold\
    \ wonders beholden only those daring enough embark upon journey seeking answers\
    \ questions still left unanswered since beginning time itself forever asking why\
    \ how when where but also what if maybe someday soon even ourselves might become\
    \ part something greater than anything .... \n```\n\nBut then I generated a few\
    \ more CUDA ones and they were fine, so I'm not sure.\n\nIt's also possible that\
    \ the custom NTK-Yarn isn't fully supported by llama.cpp yet."
  created_at: 2023-11-17 22:03:15+00:00
  edited: true
  hidden: false
  id: 6557e32327902877020115b8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8fb3c2872b01b4f4fb9672a166d92dc2.svg
      fullname: Mufeed Al-Hashim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mufeed
      type: user
    createdAt: '2023-11-18T09:37:45.000Z'
    data:
      edited: false
      editors:
      - mufeed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4674617648124695
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8fb3c2872b01b4f4fb9672a166d92dc2.svg
          fullname: Mufeed Al-Hashim
          isHf: false
          isPro: false
          name: mufeed
          type: user
        html: '<p>It does work with llama_cpp_python==0.2.17 in my system, CPU.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/63bc20a5b8c61b8aa49662c2/tHuXc38Hw0rBnYLFVHMp9.png"><img
          alt="model.png" src="https://cdn-uploads.huggingface.co/production/uploads/63bc20a5b8c61b8aa49662c2/tHuXc38Hw0rBnYLFVHMp9.png"></a></p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/63bc20a5b8c61b8aa49662c2/f1Tb4gQIuY8_d5HkJrXGk.png"><img
          alt="2nd.png" src="https://cdn-uploads.huggingface.co/production/uploads/63bc20a5b8c61b8aa49662c2/f1Tb4gQIuY8_d5HkJrXGk.png"></a></p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/63bc20a5b8c61b8aa49662c2/i4NcrlZWmRACVrGO7WHji.png"><img
          alt="template.png" src="https://cdn-uploads.huggingface.co/production/uploads/63bc20a5b8c61b8aa49662c2/i4NcrlZWmRACVrGO7WHji.png"></a></p>

          '
        raw: 'It does work with llama_cpp_python==0.2.17 in my system, CPU.


          ![model.png](https://cdn-uploads.huggingface.co/production/uploads/63bc20a5b8c61b8aa49662c2/tHuXc38Hw0rBnYLFVHMp9.png)


          ![2nd.png](https://cdn-uploads.huggingface.co/production/uploads/63bc20a5b8c61b8aa49662c2/f1Tb4gQIuY8_d5HkJrXGk.png)


          ![template.png](https://cdn-uploads.huggingface.co/production/uploads/63bc20a5b8c61b8aa49662c2/i4NcrlZWmRACVrGO7WHji.png)


          '
        updatedAt: '2023-11-18T09:37:45.089Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - cvinker
    id: 655885e9eb411317ebd7d9dc
    type: comment
  author: mufeed
  content: 'It does work with llama_cpp_python==0.2.17 in my system, CPU.


    ![model.png](https://cdn-uploads.huggingface.co/production/uploads/63bc20a5b8c61b8aa49662c2/tHuXc38Hw0rBnYLFVHMp9.png)


    ![2nd.png](https://cdn-uploads.huggingface.co/production/uploads/63bc20a5b8c61b8aa49662c2/f1Tb4gQIuY8_d5HkJrXGk.png)


    ![template.png](https://cdn-uploads.huggingface.co/production/uploads/63bc20a5b8c61b8aa49662c2/i4NcrlZWmRACVrGO7WHji.png)


    '
  created_at: 2023-11-18 09:37:45+00:00
  edited: false
  hidden: false
  id: 655885e9eb411317ebd7d9dc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-18T10:32:54.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9174680113792419
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Great, thanks for the update. That makes sense - recent llama-cpp-python
          versions fixed the vocab issue I think.</p>

          <p>So anyone with TextGen issues just needs to update to the latest version
          which should support this.</p>

          '
        raw: 'Great, thanks for the update. That makes sense - recent llama-cpp-python
          versions fixed the vocab issue I think.


          So anyone with TextGen issues just needs to update to the latest version
          which should support this.'
        updatedAt: '2023-11-18T10:32:54.152Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - cvinker
        - mufeed
    id: 655892d6a296e5c74c0bb966
    type: comment
  author: TheBloke
  content: 'Great, thanks for the update. That makes sense - recent llama-cpp-python
    versions fixed the vocab issue I think.


    So anyone with TextGen issues just needs to update to the latest version which
    should support this.'
  created_at: 2023-11-18 10:32:54+00:00
  edited: false
  hidden: false
  id: 655892d6a296e5c74c0bb966
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/alfred-40B-1023-GGUF
repo_type: model
status: open
target_branch: null
title: Worked in LM Studio, not Text-gen web UI
