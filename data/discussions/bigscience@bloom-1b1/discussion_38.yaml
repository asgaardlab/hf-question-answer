!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Robo0890
conflicting_files: null
created_at: 2023-03-05 17:25:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6375860de3413701a9eef992/oKngiohHerShFMpW9VSQb.png?w=200&h=200&f=face
      fullname: Ryan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Robo0890
      type: user
    createdAt: '2023-03-05T17:25:14.000Z'
    data:
      edited: false
      editors:
      - Robo0890
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6375860de3413701a9eef992/oKngiohHerShFMpW9VSQb.png?w=200&h=200&f=face
          fullname: Ryan
          isHf: false
          isPro: false
          name: Robo0890
          type: user
        html: "<p>I\u2019m hoping to fine tune this model on custom data for an upcoming\
          \ project. I have an RTX-3060 and 16GB of RAM, should I be able to use this\
          \ model for training or should I go with the 560m parameter version?</p>\n"
        raw: "I\u2019m hoping to fine tune this model on custom data for an upcoming\
          \ project. I have an RTX-3060 and 16GB of RAM, should I be able to use this\
          \ model for training or should I go with the 560m parameter version?"
        updatedAt: '2023-03-05T17:25:14.854Z'
      numEdits: 0
      reactions: []
    id: 6404d07aad54665351db3927
    type: comment
  author: Robo0890
  content: "I\u2019m hoping to fine tune this model on custom data for an upcoming\
    \ project. I have an RTX-3060 and 16GB of RAM, should I be able to use this model\
    \ for training or should I go with the 560m parameter version?"
  created_at: 2023-03-05 17:25:14+00:00
  edited: false
  hidden: false
  id: 6404d07aad54665351db3927
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1638782407589-61add580d7133d081a47d1f3.png?w=200&h=200&f=face
      fullname: Chun-Hsien Lin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jslin09
      type: user
    createdAt: '2023-03-19T02:32:04.000Z'
    data:
      edited: false
      editors:
      - jslin09
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1638782407589-61add580d7133d081a47d1f3.png?w=200&h=200&f=face
          fullname: Chun-Hsien Lin
          isHf: false
          isPro: false
          name: jslin09
          type: user
        html: '<p>In my experience, fine-tuning this model need 32GB GPU RAM minimum.
          I fine-tuned this model on Google Colab Pro+. This task expense a lot of
          money.</p>

          '
        raw: In my experience, fine-tuning this model need 32GB GPU RAM minimum. I
          fine-tuned this model on Google Colab Pro+. This task expense a lot of money.
        updatedAt: '2023-03-19T02:32:04.953Z'
      numEdits: 0
      reactions: []
    id: 64167424c2d99a3c5543b24b
    type: comment
  author: jslin09
  content: In my experience, fine-tuning this model need 32GB GPU RAM minimum. I fine-tuned
    this model on Google Colab Pro+. This task expense a lot of money.
  created_at: 2023-03-19 01:32:04+00:00
  edited: false
  hidden: false
  id: 64167424c2d99a3c5543b24b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6375860de3413701a9eef992/oKngiohHerShFMpW9VSQb.png?w=200&h=200&f=face
      fullname: Ryan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Robo0890
      type: user
    createdAt: '2023-03-24T21:08:46.000Z'
    data:
      edited: false
      editors:
      - Robo0890
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6375860de3413701a9eef992/oKngiohHerShFMpW9VSQb.png?w=200&h=200&f=face
          fullname: Ryan
          isHf: false
          isPro: false
          name: Robo0890
          type: user
        html: "<p>Yeah, I\u2019ll just stick with the little one</p>\n"
        raw: "Yeah, I\u2019ll just stick with the little one"
        updatedAt: '2023-03-24T21:08:46.652Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - jslin09
    id: 641e115ee250ea030d0833f7
    type: comment
  author: Robo0890
  content: "Yeah, I\u2019ll just stick with the little one"
  created_at: 2023-03-24 20:08:46+00:00
  edited: false
  hidden: false
  id: 641e115ee250ea030d0833f7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1638782407589-61add580d7133d081a47d1f3.png?w=200&h=200&f=face
      fullname: Chun-Hsien Lin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jslin09
      type: user
    createdAt: '2023-03-24T22:21:49.000Z'
    data:
      edited: false
      editors:
      - jslin09
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1638782407589-61add580d7133d081a47d1f3.png?w=200&h=200&f=face
          fullname: Chun-Hsien Lin
          isHf: false
          isPro: false
          name: jslin09
          type: user
        html: '<p>I recommend using the bloom 560m. It works fine as the same 1b1
          one but need less GPU RAM.</p>

          '
        raw: I recommend using the bloom 560m. It works fine as the same 1b1 one but
          need less GPU RAM.
        updatedAt: '2023-03-24T22:21:49.363Z'
      numEdits: 0
      reactions: []
    id: 641e227d1d05404efd061426
    type: comment
  author: jslin09
  content: I recommend using the bloom 560m. It works fine as the same 1b1 one but
    need less GPU RAM.
  created_at: 2023-03-24 21:21:49+00:00
  edited: false
  hidden: false
  id: 641e227d1d05404efd061426
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 38
repo_id: bigscience/bloom-1b1
repo_type: model
status: open
target_branch: null
title: 'System Requirements '
