!!python/object:huggingface_hub.community.DiscussionWithDetails
author: apobec3f
conflicting_files: null
created_at: 2023-07-04 02:13:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4f53cb7588e4b31221d82943aefebe5a.svg
      fullname: zac
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: apobec3f
      type: user
    createdAt: '2023-07-04T03:13:58.000Z'
    data:
      edited: false
      editors:
      - apobec3f
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9555099010467529
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4f53cb7588e4b31221d82943aefebe5a.svg
          fullname: zac
          isHf: false
          isPro: false
          name: apobec3f
          type: user
        html: '<p>I tried to write up the inference code based on the base model it
          is finetuned on, but no success :(</p>

          '
        raw: I tried to write up the inference code based on the base model it is
          finetuned on, but no success :(
        updatedAt: '2023-07-04T03:13:58.249Z'
      numEdits: 0
      reactions: []
    id: 64a38e76838ef5bafea23c81
    type: comment
  author: apobec3f
  content: I tried to write up the inference code based on the base model it is finetuned
    on, but no success :(
  created_at: 2023-07-04 02:13:58+00:00
  edited: false
  hidden: false
  id: 64a38e76838ef5bafea23c81
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7c58ab35bd375105c497e2818881c130.svg
      fullname: Ed Moman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirix
      type: user
    createdAt: '2023-07-04T14:31:49.000Z'
    data:
      edited: false
      editors:
      - mirix
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5061933994293213
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7c58ab35bd375105c497e2818881c130.svg
          fullname: Ed Moman
          isHf: false
          isPro: false
          name: mirix
          type: user
        html: "<p>Kind of...</p>\n<pre><code>from transformers import Wav2Vec2FeatureExtractor,\
          \ Wav2Vec2ForSequenceClassification\n\nmodelw = Wav2Vec2ForSequenceClassification.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech',\
          \ device=torch.device('cpu'))\nprocessor = Wav2Vec2FeatureExtractor.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech',\
          \ device=torch.device('cpu'))\n\n                sound_array = np.array(waveform)\n\
          \                input_values = processor(sound_array, sampling_rate = 16000,\
          \ padding='longest', return_tensors='pt').input_values\n               \
          \ with torch.no_grad():\n                    result = modelw(input_values).logits\n\
          \                probs = list(result.detach().numpy()[0])\n</code></pre>\n\
          <p>This works and produces reasonable results.</p>\n<p>However, for certain\
          \ files/segments there seems to be memory leaks.</p>\n<p>I am not sure.</p>\n"
        raw: "Kind of...\n\n```\nfrom transformers import Wav2Vec2FeatureExtractor,\
          \ Wav2Vec2ForSequenceClassification\n\nmodelw = Wav2Vec2ForSequenceClassification.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech',\
          \ device=torch.device('cpu'))\nprocessor = Wav2Vec2FeatureExtractor.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech',\
          \ device=torch.device('cpu'))\n\n\t\t\t\tsound_array = np.array(waveform)\n\
          \t\t\t\tinput_values = processor(sound_array, sampling_rate = 16000, padding='longest',\
          \ return_tensors='pt').input_values\n\t\t\t\twith torch.no_grad():\n\t\t\
          \t\t\tresult = modelw(input_values).logits\n\t\t\t\tprobs = list(result.detach().numpy()[0])\n\
          ```\n\n\nThis works and produces reasonable results.\n\nHowever, for certain\
          \ files/segments there seems to be memory leaks.\n\nI am not sure.\n\n"
        updatedAt: '2023-07-04T14:31:49.409Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - apobec3f
        - CleverJF
    id: 64a42d55aaefa18eaaf9b96e
    type: comment
  author: mirix
  content: "Kind of...\n\n```\nfrom transformers import Wav2Vec2FeatureExtractor,\
    \ Wav2Vec2ForSequenceClassification\n\nmodelw = Wav2Vec2ForSequenceClassification.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech',\
    \ device=torch.device('cpu'))\nprocessor = Wav2Vec2FeatureExtractor.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech',\
    \ device=torch.device('cpu'))\n\n\t\t\t\tsound_array = np.array(waveform)\n\t\t\
    \t\tinput_values = processor(sound_array, sampling_rate = 16000, padding='longest',\
    \ return_tensors='pt').input_values\n\t\t\t\twith torch.no_grad():\n\t\t\t\t\t\
    result = modelw(input_values).logits\n\t\t\t\tprobs = list(result.detach().numpy()[0])\n\
    ```\n\n\nThis works and produces reasonable results.\n\nHowever, for certain files/segments\
    \ there seems to be memory leaks.\n\nI am not sure.\n\n"
  created_at: 2023-07-04 13:31:49+00:00
  edited: false
  hidden: false
  id: 64a42d55aaefa18eaaf9b96e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4f53cb7588e4b31221d82943aefebe5a.svg
      fullname: zac
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: apobec3f
      type: user
    createdAt: '2023-07-09T10:00:05.000Z'
    data:
      edited: true
      editors:
      - apobec3f
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4773254692554474
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4f53cb7588e4b31221d82943aefebe5a.svg
          fullname: zac
          isHf: false
          isPro: false
          name: apobec3f
          type: user
        html: "<blockquote>\n<p>Kind of...</p>\n<pre><code>from transformers import\
          \ Wav2Vec2FeatureExtractor, Wav2Vec2ForSequenceClassification\n\nmodelw\
          \ = Wav2Vec2ForSequenceClassification.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech',\
          \ device=torch.device('cpu'))\nprocessor = Wav2Vec2FeatureExtractor.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech',\
          \ device=torch.device('cpu'))\n\n                sound_array = np.array(waveform)\n\
          \                input_values = processor(sound_array, sampling_rate = 16000,\
          \ padding='longest', return_tensors='pt').input_values\n               \
          \ with torch.no_grad():\n                    result = modelw(input_values).logits\n\
          \                probs = list(result.detach().numpy()[0])\n</code></pre>\n\
          <p>This works and produces reasonable results.</p>\n<p>However, for certain\
          \ files/segments there seems to be memory leaks.</p>\n<p>I am not sure.</p>\n\
          </blockquote>\n<p>I tried your code with something like this:</p>\n<pre><code>import\
          \ torch\nimport numpy as np\nfrom transformers import Wav2Vec2FeatureExtractor,\
          \ Wav2Vec2ForSequenceClassification\nfrom scipy.io.wavfile import read\n\
          \nmodelw = Wav2Vec2ForSequenceClassification.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech')\n\
          processor = Wav2Vec2FeatureExtractor.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech')\n\
          audio_pth = 'your_test_audio_path.wav'\noutput = read(audio_pth)\nwaveform\
          \ = np.array(output[1],dtype=float)\nsound_array = np.array(waveform)\n\
          input_values = processor(sound_array, sampling_rate = 16000, padding='longest',\
          \ return_tensors='pt').input_values\nwith torch.no_grad():\n    result =\
          \ modelw(input_values).logits\n    prob = torch.nn.functional.softmax(logits,\
          \ dim=1)\n</code></pre>\n<p>Note I used <code>prob = torch.nn.functional.softmax(logits,\
          \ dim=1)</code> on the last line for the probabilities, which seems to make\
          \ sense based on a few test audios I tried.</p>\n<p><audio src=\"https://cdn-uploads.huggingface.co/production/uploads/637fae78614fe6d85dc14d12/qwGktStDZlK3MU5dR0KVh.wav\"\
          \ controls=\"\"></audio></p>\n"
        raw: "> Kind of...\n> \n> ```\n> from transformers import Wav2Vec2FeatureExtractor,\
          \ Wav2Vec2ForSequenceClassification\n> \n> modelw = Wav2Vec2ForSequenceClassification.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech',\
          \ device=torch.device('cpu'))\n> processor = Wav2Vec2FeatureExtractor.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech',\
          \ device=torch.device('cpu'))\n> \n> \t\t\t\tsound_array = np.array(waveform)\n\
          > \t\t\t\tinput_values = processor(sound_array, sampling_rate = 16000, padding='longest',\
          \ return_tensors='pt').input_values\n> \t\t\t\twith torch.no_grad():\n>\
          \ \t\t\t\t\tresult = modelw(input_values).logits\n> \t\t\t\tprobs = list(result.detach().numpy()[0])\n\
          > ```\n> \n> \n> This works and produces reasonable results.\n> \n> However,\
          \ for certain files/segments there seems to be memory leaks.\n> \n> I am\
          \ not sure.\n\nI tried your code with something like this:\n```\nimport\
          \ torch\nimport numpy as np\nfrom transformers import Wav2Vec2FeatureExtractor,\
          \ Wav2Vec2ForSequenceClassification\nfrom scipy.io.wavfile import read\n\
          \nmodelw = Wav2Vec2ForSequenceClassification.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech')\n\
          processor = Wav2Vec2FeatureExtractor.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech')\n\
          audio_pth = 'your_test_audio_path.wav'\noutput = read(audio_pth)\nwaveform\
          \ = np.array(output[1],dtype=float)\nsound_array = np.array(waveform)\n\
          input_values = processor(sound_array, sampling_rate = 16000, padding='longest',\
          \ return_tensors='pt').input_values\nwith torch.no_grad():\n    result =\
          \ modelw(input_values).logits\n    prob = torch.nn.functional.softmax(logits,\
          \ dim=1)\n```\nNote I used `prob = torch.nn.functional.softmax(logits, dim=1)`\
          \ on the last line for the probabilities, which seems to make sense based\
          \ on a few test audios I tried.\n\n<audio controls src=\"https://cdn-uploads.huggingface.co/production/uploads/637fae78614fe6d85dc14d12/qwGktStDZlK3MU5dR0KVh.wav\"\
          ></audio>\n\n\n"
        updatedAt: '2023-07-09T10:40:54.796Z'
      numEdits: 9
      reactions: []
    id: 64aa85259a803a657dfa43e2
    type: comment
  author: apobec3f
  content: "> Kind of...\n> \n> ```\n> from transformers import Wav2Vec2FeatureExtractor,\
    \ Wav2Vec2ForSequenceClassification\n> \n> modelw = Wav2Vec2ForSequenceClassification.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech',\
    \ device=torch.device('cpu'))\n> processor = Wav2Vec2FeatureExtractor.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech',\
    \ device=torch.device('cpu'))\n> \n> \t\t\t\tsound_array = np.array(waveform)\n\
    > \t\t\t\tinput_values = processor(sound_array, sampling_rate = 16000, padding='longest',\
    \ return_tensors='pt').input_values\n> \t\t\t\twith torch.no_grad():\n> \t\t\t\
    \t\tresult = modelw(input_values).logits\n> \t\t\t\tprobs = list(result.detach().numpy()[0])\n\
    > ```\n> \n> \n> This works and produces reasonable results.\n> \n> However, for\
    \ certain files/segments there seems to be memory leaks.\n> \n> I am not sure.\n\
    \nI tried your code with something like this:\n```\nimport torch\nimport numpy\
    \ as np\nfrom transformers import Wav2Vec2FeatureExtractor, Wav2Vec2ForSequenceClassification\n\
    from scipy.io.wavfile import read\n\nmodelw = Wav2Vec2ForSequenceClassification.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech')\n\
    processor = Wav2Vec2FeatureExtractor.from_pretrained('alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech')\n\
    audio_pth = 'your_test_audio_path.wav'\noutput = read(audio_pth)\nwaveform = np.array(output[1],dtype=float)\n\
    sound_array = np.array(waveform)\ninput_values = processor(sound_array, sampling_rate\
    \ = 16000, padding='longest', return_tensors='pt').input_values\nwith torch.no_grad():\n\
    \    result = modelw(input_values).logits\n    prob = torch.nn.functional.softmax(logits,\
    \ dim=1)\n```\nNote I used `prob = torch.nn.functional.softmax(logits, dim=1)`\
    \ on the last line for the probabilities, which seems to make sense based on a\
    \ few test audios I tried.\n\n<audio controls src=\"https://cdn-uploads.huggingface.co/production/uploads/637fae78614fe6d85dc14d12/qwGktStDZlK3MU5dR0KVh.wav\"\
    ></audio>\n\n\n"
  created_at: 2023-07-09 09:00:05+00:00
  edited: true
  hidden: false
  id: 64aa85259a803a657dfa43e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7c58ab35bd375105c497e2818881c130.svg
      fullname: Ed Moman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirix
      type: user
    createdAt: '2023-07-27T12:18:50.000Z'
    data:
      edited: true
      editors:
      - mirix
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6543057560920715
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7c58ab35bd375105c497e2818881c130.svg
          fullname: Ed Moman
          isHf: false
          isPro: false
          name: mirix
          type: user
        html: "<p>Indeed, the following for instance:</p>\n<pre><code>with torch.no_grad():\n\
          \    logits = modelw(input_values).logits\n    prob = torch.nn.functional.softmax(logits,\
          \ dim=1).tolist()[0][0]\n</code></pre>\n<p>Seems to return the probability\
          \ of the speaker being a female.</p>\n<p>Whereas:</p>\n<pre><code> prob\
          \ = torch.nn.functional.softmax(logits, dim=1).tolist()[0][1]\n</code></pre>\n\
          <p>Returns the probability of a male.</p>\n<p>As this is a binary classifier,\
          \ one plus the other should be approximately 1.</p>\n"
        raw: "Indeed, the following for instance:\n\n```\nwith torch.no_grad():\n\
          \    logits = modelw(input_values).logits\n    prob = torch.nn.functional.softmax(logits,\
          \ dim=1).tolist()[0][0]\n```\n\nSeems to return the probability of the speaker\
          \ being a female.\n\nWhereas:\n\n```\n prob = torch.nn.functional.softmax(logits,\
          \ dim=1).tolist()[0][1]\n```\n\nReturns the probability of a male.\n\nAs\
          \ this is a binary classifier, one plus the other should be approximately\
          \ 1.\n\n"
        updatedAt: '2023-07-27T12:21:04.388Z'
      numEdits: 3
      reactions: []
    id: 64c260aa90f24e254f6a990f
    type: comment
  author: mirix
  content: "Indeed, the following for instance:\n\n```\nwith torch.no_grad():\n  \
    \  logits = modelw(input_values).logits\n    prob = torch.nn.functional.softmax(logits,\
    \ dim=1).tolist()[0][0]\n```\n\nSeems to return the probability of the speaker\
    \ being a female.\n\nWhereas:\n\n```\n prob = torch.nn.functional.softmax(logits,\
    \ dim=1).tolist()[0][1]\n```\n\nReturns the probability of a male.\n\nAs this\
    \ is a binary classifier, one plus the other should be approximately 1.\n\n"
  created_at: 2023-07-27 11:18:50+00:00
  edited: true
  hidden: false
  id: 64c260aa90f24e254f6a990f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4f53cb7588e4b31221d82943aefebe5a.svg
      fullname: zac
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: apobec3f
      type: user
    createdAt: '2023-07-31T09:18:12.000Z'
    data:
      edited: false
      editors:
      - apobec3f
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8542751669883728
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4f53cb7588e4b31221d82943aefebe5a.svg
          fullname: zac
          isHf: false
          isPro: false
          name: apobec3f
          type: user
        html: '<p>Sorry I just found on some audios it''s making wrong prediction
          while on the inference API it is not:<br>This one for example is predicted
          as male while on the inference API it is female (correct)<br><audio src="https://cdn-uploads.huggingface.co/production/uploads/637fae78614fe6d85dc14d12/diO0edsrEfStikov9s92L.wav"
          controls=""></audio></p>

          '
        raw: 'Sorry I just found on some audios it''s making wrong prediction while
          on the inference API it is not:

          This one for example is predicted as male while on the inference API it
          is female (correct)

          <audio controls src="https://cdn-uploads.huggingface.co/production/uploads/637fae78614fe6d85dc14d12/diO0edsrEfStikov9s92L.wav"></audio>'
        updatedAt: '2023-07-31T09:18:12.737Z'
      numEdits: 0
      reactions: []
    id: 64c77c540b2ba05b2f28b91c
    type: comment
  author: apobec3f
  content: 'Sorry I just found on some audios it''s making wrong prediction while
    on the inference API it is not:

    This one for example is predicted as male while on the inference API it is female
    (correct)

    <audio controls src="https://cdn-uploads.huggingface.co/production/uploads/637fae78614fe6d85dc14d12/diO0edsrEfStikov9s92L.wav"></audio>'
  created_at: 2023-07-31 08:18:12+00:00
  edited: false
  hidden: false
  id: 64c77c540b2ba05b2f28b91c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7c58ab35bd375105c497e2818881c130.svg
      fullname: Ed Moman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirix
      type: user
    createdAt: '2023-07-31T10:13:04.000Z'
    data:
      edited: false
      editors:
      - mirix
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.970416784286499
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7c58ab35bd375105c497e2818881c130.svg
          fullname: Ed Moman
          isHf: false
          isPro: false
          name: mirix
          type: user
        html: '<p>For me it works fine so far with some 40 speakers.</p>

          <p>After diarisation, I have concatenated the longest non-overlapping segments
          corresponding to each speaker into separate WAV files (the preprocessing
          involves voice isolation with demucs, normalisation with pydub and conversion
          to 16 kHz mono WAV with pysox). I am also removing silences with pysox as
          that helps for other tasks but so far it does not seem to have a noticeable
          effect for gender attribution.</p>

          <p>With this preprocessing, the model seems to work well.</p>

          <p>Previously I had also experienced some issues, including the inability
          to process certain segments (huge memory usage and never-ending processing)
          as well as gender misassignment. </p>

          '
        raw: "For me it works fine so far with some 40 speakers.\n\nAfter diarisation,\
          \ I have concatenated the longest non-overlapping segments corresponding\
          \ to each speaker into separate WAV files (the preprocessing involves voice\
          \ isolation with demucs, normalisation with pydub and conversion to 16 kHz\
          \ mono WAV with pysox). I am also removing silences with pysox as that helps\
          \ for other tasks but so far it does not seem to have a noticeable effect\
          \ for gender attribution.\n\nWith this preprocessing, the model seems to\
          \ work well.\n\nPreviously I had also experienced some issues, including\
          \ the inability to process certain segments (huge memory usage and never-ending\
          \ processing) as well as gender misassignment. \n"
        updatedAt: '2023-07-31T10:13:04.475Z'
      numEdits: 0
      reactions: []
    id: 64c78930ca915ffd300840a3
    type: comment
  author: mirix
  content: "For me it works fine so far with some 40 speakers.\n\nAfter diarisation,\
    \ I have concatenated the longest non-overlapping segments corresponding to each\
    \ speaker into separate WAV files (the preprocessing involves voice isolation\
    \ with demucs, normalisation with pydub and conversion to 16 kHz mono WAV with\
    \ pysox). I am also removing silences with pysox as that helps for other tasks\
    \ but so far it does not seem to have a noticeable effect for gender attribution.\n\
    \nWith this preprocessing, the model seems to work well.\n\nPreviously I had also\
    \ experienced some issues, including the inability to process certain segments\
    \ (huge memory usage and never-ending processing) as well as gender misassignment.\
    \ \n"
  created_at: 2023-07-31 09:13:04+00:00
  edited: false
  hidden: false
  id: 64c78930ca915ffd300840a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4f53cb7588e4b31221d82943aefebe5a.svg
      fullname: zac
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: apobec3f
      type: user
    createdAt: '2023-07-31T10:33:18.000Z'
    data:
      edited: false
      editors:
      - apobec3f
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9497714042663574
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4f53cb7588e4b31221d82943aefebe5a.svg
          fullname: zac
          isHf: false
          isPro: false
          name: apobec3f
          type: user
        html: '<p>I starts to feel I am you from another universe cause we have been
          doing exactly the same preprocessing steps! Wow!<br>Glad you got it working
          fine, I will look a bit closer to my pipeline.<br>Also out of topic question,
          the official demucs interface is really hard to use, for example it always
          write the results to files in a predefined folder etc. Also it has memory
          issue processing large audio snippets (might due to inefficient segmentation
          and batching).<br>Have you had any luck getting it to work reliably? :D</p>

          '
        raw: 'I starts to feel I am you from another universe cause we have been doing
          exactly the same preprocessing steps! Wow!

          Glad you got it working fine, I will look a bit closer to my pipeline.

          Also out of topic question, the official demucs interface is really hard
          to use, for example it always write the results to files in a predefined
          folder etc. Also it has memory issue processing large audio snippets (might
          due to inefficient segmentation and batching).

          Have you had any luck getting it to work reliably? :D'
        updatedAt: '2023-07-31T10:33:18.316Z'
      numEdits: 0
      reactions: []
    id: 64c78deef723215b6d9ef4cd
    type: comment
  author: apobec3f
  content: 'I starts to feel I am you from another universe cause we have been doing
    exactly the same preprocessing steps! Wow!

    Glad you got it working fine, I will look a bit closer to my pipeline.

    Also out of topic question, the official demucs interface is really hard to use,
    for example it always write the results to files in a predefined folder etc. Also
    it has memory issue processing large audio snippets (might due to inefficient
    segmentation and batching).

    Have you had any luck getting it to work reliably? :D'
  created_at: 2023-07-31 09:33:18+00:00
  edited: false
  hidden: false
  id: 64c78deef723215b6d9ef4cd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7c58ab35bd375105c497e2818881c130.svg
      fullname: Ed Moman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirix
      type: user
    createdAt: '2023-07-31T11:52:43.000Z'
    data:
      edited: false
      editors:
      - mirix
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5659765601158142
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7c58ab35bd375105c497e2818881c130.svg
          fullname: Ed Moman
          isHf: false
          isPro: false
          name: mirix
          type: user
        html: '<p>You can check the initial preprocessing there:</p>

          <p><a rel="nofollow" href="https://github.com/mirix/approaches-to-diarisation/tree/main">https://github.com/mirix/approaches-to-diarisation/tree/main</a></p>

          <p>Namely:</p>

          <pre><code>demucs.separate.main(shlex.split(''--two-stems vocals -n mdx_extra
          '' + ''samples/'' + name + '' -o tmp''))

          </code></pre>

          '
        raw: 'You can check the initial preprocessing there:


          https://github.com/mirix/approaches-to-diarisation/tree/main


          Namely:


          ```

          demucs.separate.main(shlex.split(''--two-stems vocals -n mdx_extra '' +
          ''samples/'' + name + '' -o tmp''))

          ```

          '
        updatedAt: '2023-07-31T11:52:43.769Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - apobec3f
    id: 64c7a08bbaa60107a6769878
    type: comment
  author: mirix
  content: 'You can check the initial preprocessing there:


    https://github.com/mirix/approaches-to-diarisation/tree/main


    Namely:


    ```

    demucs.separate.main(shlex.split(''--two-stems vocals -n mdx_extra '' + ''samples/''
    + name + '' -o tmp''))

    ```

    '
  created_at: 2023-07-31 10:52:43+00:00
  edited: false
  hidden: false
  id: 64c7a08bbaa60107a6769878
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4f53cb7588e4b31221d82943aefebe5a.svg
      fullname: zac
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: apobec3f
      type: user
    createdAt: '2023-07-31T11:59:19.000Z'
    data:
      edited: false
      editors:
      - apobec3f
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8645918965339661
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4f53cb7588e4b31221d82943aefebe5a.svg
          fullname: zac
          isHf: false
          isPro: false
          name: apobec3f
          type: user
        html: '<p>Thanks man! Appreciate that!!</p>

          '
        raw: Thanks man! Appreciate that!!
        updatedAt: '2023-07-31T11:59:19.506Z'
      numEdits: 0
      reactions: []
    id: 64c7a217203170e13cfa3582
    type: comment
  author: apobec3f
  content: Thanks man! Appreciate that!!
  created_at: 2023-07-31 10:59:19+00:00
  edited: false
  hidden: false
  id: 64c7a217203170e13cfa3582
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech
repo_type: model
status: open
target_branch: null
title: Has anyone successfully get the inference code for this to run?
