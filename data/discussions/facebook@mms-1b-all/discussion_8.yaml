!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mohblnk
conflicting_files: null
created_at: 2023-07-05 14:32:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/efd3aa1ceb9d393af398ebe07762f392.svg
      fullname: mohamed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mohblnk
      type: user
    createdAt: '2023-07-05T15:32:38.000Z'
    data:
      edited: false
      editors:
      - mohblnk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9847449660301208
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/efd3aa1ceb9d393af398ebe07762f392.svg
          fullname: mohamed
          isHf: false
          isPro: false
          name: mohblnk
          type: user
        html: '<p><a rel="nofollow" href="https://github.com/huggingface/peft">PEFT</a>
          is amazing, I have been fine tunning whisper large model which require about
          ~24 Vram to fine tune but with PEFT I was able to use my 16GB just fine,
          I was wondering if PEFT is compatible  with MMS yet? if not is there is
          a TBA date?</p>

          '
        raw: '[PEFT](https://github.com/huggingface/peft) is amazing, I have been
          fine tunning whisper large model which require about ~24 Vram to fine tune
          but with PEFT I was able to use my 16GB just fine, I was wondering if PEFT
          is compatible  with MMS yet? if not is there is a TBA date?'
        updatedAt: '2023-07-05T15:32:38.827Z'
      numEdits: 0
      reactions: []
    id: 64a58d16a9d482f319673892
    type: comment
  author: mohblnk
  content: '[PEFT](https://github.com/huggingface/peft) is amazing, I have been fine
    tunning whisper large model which require about ~24 Vram to fine tune but with
    PEFT I was able to use my 16GB just fine, I was wondering if PEFT is compatible  with
    MMS yet? if not is there is a TBA date?'
  created_at: 2023-07-05 14:32:38+00:00
  edited: false
  hidden: false
  id: 64a58d16a9d482f319673892
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-07-05T17:33:38.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9300134778022766
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: '<p>You can check out this blog-post for a low-resource approach to
          fine-tuning MMS for ASR: <a href="https://huggingface.co/blog/mms_adapters">https://huggingface.co/blog/mms_adapters</a></p>

          <p>We only fine tune the adapter weights (a few million params, only a fraction
          of the full model weights), so I expect 16GB VRAM is more than enough here!
          Let me know if it''s not though - happy to provide some more pointers for
          reducing memory with MMS fine-tuning if it''s still too high!</p>

          '
        raw: 'You can check out this blog-post for a low-resource approach to fine-tuning
          MMS for ASR: https://huggingface.co/blog/mms_adapters


          We only fine tune the adapter weights (a few million params, only a fraction
          of the full model weights), so I expect 16GB VRAM is more than enough here!
          Let me know if it''s not though - happy to provide some more pointers for
          reducing memory with MMS fine-tuning if it''s still too high!'
        updatedAt: '2023-07-05T17:33:38.124Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - mohblnk
    id: 64a5a9724ce22fb505271ae1
    type: comment
  author: sanchit-gandhi
  content: 'You can check out this blog-post for a low-resource approach to fine-tuning
    MMS for ASR: https://huggingface.co/blog/mms_adapters


    We only fine tune the adapter weights (a few million params, only a fraction of
    the full model weights), so I expect 16GB VRAM is more than enough here! Let me
    know if it''s not though - happy to provide some more pointers for reducing memory
    with MMS fine-tuning if it''s still too high!'
  created_at: 2023-07-05 16:33:38+00:00
  edited: false
  hidden: false
  id: 64a5a9724ce22fb505271ae1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/efd3aa1ceb9d393af398ebe07762f392.svg
      fullname: mohamed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mohblnk
      type: user
    createdAt: '2023-07-06T06:07:39.000Z'
    data:
      edited: false
      editors:
      - mohblnk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9446032643318176
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/efd3aa1ceb9d393af398ebe07762f392.svg
          fullname: mohamed
          isHf: false
          isPro: false
          name: mohblnk
          type: user
        html: "<blockquote>\n<p>You can check out this blog-post for a low-resource\
          \ approach to fine-tuning MMS for ASR: <a href=\"https://huggingface.co/blog/mms_adapters\"\
          >https://huggingface.co/blog/mms_adapters</a></p>\n<p>We only fine tune\
          \ the adapter weights (a few million params, only a fraction of the full\
          \ model weights), so I expect 16GB VRAM is more than enough here! Let me\
          \ know if it's not though - happy to provide some more pointers for reducing\
          \ memory with MMS fine-tuning if it's still too high!</p>\n</blockquote>\n\
          <p>I have taken a quick look and looks like I'm in for a treat, Thank you\
          \ <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\">@<span\
          \ class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ </p>\n"
        raw: "> You can check out this blog-post for a low-resource approach to fine-tuning\
          \ MMS for ASR: https://huggingface.co/blog/mms_adapters\n> \n> We only fine\
          \ tune the adapter weights (a few million params, only a fraction of the\
          \ full model weights), so I expect 16GB VRAM is more than enough here! Let\
          \ me know if it's not though - happy to provide some more pointers for reducing\
          \ memory with MMS fine-tuning if it's still too high!\n\nI have taken a\
          \ quick look and looks like I'm in for a treat, Thank you @sanchit-gandhi "
        updatedAt: '2023-07-06T06:07:39.014Z'
      numEdits: 0
      reactions: []
    id: 64a65a2bb7397c8ae5205d5d
    type: comment
  author: mohblnk
  content: "> You can check out this blog-post for a low-resource approach to fine-tuning\
    \ MMS for ASR: https://huggingface.co/blog/mms_adapters\n> \n> We only fine tune\
    \ the adapter weights (a few million params, only a fraction of the full model\
    \ weights), so I expect 16GB VRAM is more than enough here! Let me know if it's\
    \ not though - happy to provide some more pointers for reducing memory with MMS\
    \ fine-tuning if it's still too high!\n\nI have taken a quick look and looks like\
    \ I'm in for a treat, Thank you @sanchit-gandhi "
  created_at: 2023-07-06 05:07:39+00:00
  edited: false
  hidden: false
  id: 64a65a2bb7397c8ae5205d5d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: facebook/mms-1b-all
repo_type: model
status: open
target_branch: null
title: is mms compatible with PEFT (parameter efficient fine tuning)?
