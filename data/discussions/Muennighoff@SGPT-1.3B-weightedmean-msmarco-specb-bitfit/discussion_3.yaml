!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dylanAtHum
conflicting_files: null
created_at: 2023-08-28 13:11:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64e8da2cf6d7c8bdfb64d76a/DsPY0-4Qyi5UOsyz5qKC3.jpeg?w=200&h=200&f=face
      fullname: Dylan DiGioia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dylanAtHum
      type: user
    createdAt: '2023-08-28T14:11:55.000Z'
    data:
      edited: false
      editors:
      - dylanAtHum
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9399112462997437
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64e8da2cf6d7c8bdfb64d76a/DsPY0-4Qyi5UOsyz5qKC3.jpeg?w=200&h=200&f=face
          fullname: Dylan DiGioia
          isHf: false
          isPro: false
          name: dylanAtHum
          type: user
        html: '<p>Hey,</p>

          <p>First off, thanks for your work here.</p>

          <p>I was testing out these SGPT models using the SentenceTransformer package
          and I noticed the <code>sentence_bert_config.json</code> has a <code>max_seq_length=300</code>
          parameter. This causes the tokenizer to truncate at 300 tokens, but I know
          the model itself is intended to have a 2k length. I looked in Github and
          saw there that its suggested to load the AutoModel and AutoTokenizer then
          unpack the hidden layers and call the model through torch directly. Testing
          this gave me the correct 2k sequence length as best I can tell, but it might
          be worthwhile to modify that <code>sentence_bert_config</code> just for
          ease of use.</p>

          '
        raw: "Hey,\r\n\r\nFirst off, thanks for your work here.\r\n\r\nI was testing\
          \ out these SGPT models using the SentenceTransformer package and I noticed\
          \ the `sentence_bert_config.json` has a `max_seq_length=300` parameter.\
          \ This causes the tokenizer to truncate at 300 tokens, but I know the model\
          \ itself is intended to have a 2k length. I looked in Github and saw there\
          \ that its suggested to load the AutoModel and AutoTokenizer then unpack\
          \ the hidden layers and call the model through torch directly. Testing this\
          \ gave me the correct 2k sequence length as best I can tell, but it might\
          \ be worthwhile to modify that `sentence_bert_config` just for ease of use."
        updatedAt: '2023-08-28T14:11:55.367Z'
      numEdits: 0
      reactions: []
    id: 64ecab2ba79cf4a895dfce90
    type: comment
  author: dylanAtHum
  content: "Hey,\r\n\r\nFirst off, thanks for your work here.\r\n\r\nI was testing\
    \ out these SGPT models using the SentenceTransformer package and I noticed the\
    \ `sentence_bert_config.json` has a `max_seq_length=300` parameter. This causes\
    \ the tokenizer to truncate at 300 tokens, but I know the model itself is intended\
    \ to have a 2k length. I looked in Github and saw there that its suggested to\
    \ load the AutoModel and AutoTokenizer then unpack the hidden layers and call\
    \ the model through torch directly. Testing this gave me the correct 2k sequence\
    \ length as best I can tell, but it might be worthwhile to modify that `sentence_bert_config`\
    \ just for ease of use."
  created_at: 2023-08-28 13:11:55+00:00
  edited: false
  hidden: false
  id: 64ecab2ba79cf4a895dfce90
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2023-08-28T17:34:43.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9748464226722717
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: '<p>Thanks for noting! The reason it''s set to 300 in the <code>sentence_bert_config</code>
          is because during finetuning all sentences were cut off at 300 tokens. I''m
          not sure how it performs at &gt;300 tokens. For most tasks 300 tokens is
          enough to get a sufficiently comprehensive embedding.</p>

          '
        raw: Thanks for noting! The reason it's set to 300 in the `sentence_bert_config`
          is because during finetuning all sentences were cut off at 300 tokens. I'm
          not sure how it performs at >300 tokens. For most tasks 300 tokens is enough
          to get a sufficiently comprehensive embedding.
        updatedAt: '2023-08-28T17:34:43.948Z'
      numEdits: 0
      reactions: []
    id: 64ecdab34bc026619ab1219e
    type: comment
  author: Muennighoff
  content: Thanks for noting! The reason it's set to 300 in the `sentence_bert_config`
    is because during finetuning all sentences were cut off at 300 tokens. I'm not
    sure how it performs at >300 tokens. For most tasks 300 tokens is enough to get
    a sufficiently comprehensive embedding.
  created_at: 2023-08-28 16:34:43+00:00
  edited: false
  hidden: false
  id: 64ecdab34bc026619ab1219e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Muennighoff/SGPT-1.3B-weightedmean-msmarco-specb-bitfit
repo_type: model
status: open
target_branch: null
title: Sequence Length Setting for Sentence Transformer
