!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ttkciar
conflicting_files: null
created_at: 2023-10-04 00:29:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661973791156-noauth.jpeg?w=200&h=200&f=face
      fullname: TTK Ciar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ttkciar
      type: user
    createdAt: '2023-10-04T01:29:21.000Z'
    data:
      edited: true
      editors:
      - ttkciar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8217795491218567
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661973791156-noauth.jpeg?w=200&h=200&f=face
          fullname: TTK Ciar
          isHf: false
          isPro: false
          name: ttkciar
          type: user
        html: '<p>Hello, thank you for providing this model!  It works surprisingly
          well for a 7B, and the 16K context length is greatly appreciated.</p>

          <p>Your model card does not recommend a prompt template, but since it is
          derived from Glaive-Coder I tried using it using Glaive-Coder''s prompt
          template, and that seems to work well.  Is there a different template you
          would recommend using instead?</p>

          <p>For reference, Glaive-Coder''s recommended templates are:</p>

          <pre><code>&lt;s&gt;[INST]\n&lt;&lt;SYS&gt;&gt;\n$system_prompt\n&lt;&lt;/SYS&gt;&gt;\n\n$prompt\n[/INST]\n

          </code></pre>

          <p>.. and:</p>

          <pre><code>&lt;s&gt;[INST]\n$prompt\n[/INST]\n

          </code></pre>

          '
        raw: "Hello, thank you for providing this model!  It works surprisingly well\
          \ for a 7B, and the 16K context length is greatly appreciated.\n\nYour model\
          \ card does not recommend a prompt template, but since it is derived from\
          \ Glaive-Coder I tried using it using Glaive-Coder's prompt template, and\
          \ that seems to work well.  Is there a different template you would recommend\
          \ using instead?\n\nFor reference, Glaive-Coder's recommended templates\
          \ are:\n\n    <s>[INST]\\n<<SYS>>\\n$system_prompt\\n<</SYS>>\\n\\n$prompt\\\
          n[/INST]\\n\n\n.. and:\n\n    <s>[INST]\\n$prompt\\n[/INST]\\n\n"
        updatedAt: '2023-10-04T01:29:53.015Z'
      numEdits: 1
      reactions: []
    id: 651cbff1d651a1b446aceace
    type: comment
  author: ttkciar
  content: "Hello, thank you for providing this model!  It works surprisingly well\
    \ for a 7B, and the 16K context length is greatly appreciated.\n\nYour model card\
    \ does not recommend a prompt template, but since it is derived from Glaive-Coder\
    \ I tried using it using Glaive-Coder's prompt template, and that seems to work\
    \ well.  Is there a different template you would recommend using instead?\n\n\
    For reference, Glaive-Coder's recommended templates are:\n\n    <s>[INST]\\n<<SYS>>\\\
    n$system_prompt\\n<</SYS>>\\n\\n$prompt\\n[/INST]\\n\n\n.. and:\n\n    <s>[INST]\\\
    n$prompt\\n[/INST]\\n\n"
  created_at: 2023-10-04 00:29:21+00:00
  edited: true
  hidden: false
  id: 651cbff1d651a1b446aceace
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: morph-labs/rift-coder-v0-7b-gguf
repo_type: model
status: open
target_branch: null
title: Using Glaive-Coder prompt template
