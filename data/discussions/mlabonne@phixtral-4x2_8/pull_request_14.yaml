!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mzbac
conflicting_files: []
created_at: 2024-01-21 00:57:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/513e0d2c15cfbb1542cb268eb2c8d68b.svg
      fullname: 'null'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mzbac
      type: user
    createdAt: '2024-01-21T00:57:07.000Z'
    data:
      oid: 32101cbd0e4404d566d6f749bc8617fa3a7146d9
      parents:
      - e9dad464394da163595176f6897c2a4f88761c63
      subject: Update the model type to make it compatible with mlx-lm's model mapping.
    id: 65ac6be30000000000000000
    type: commit
  author: mzbac
  created_at: 2024-01-21 00:57:07+00:00
  id: 65ac6be30000000000000000
  oid: 32101cbd0e4404d566d6f749bc8617fa3a7146d9
  summary: Update the model type to make it compatible with mlx-lm's model mapping.
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/513e0d2c15cfbb1542cb268eb2c8d68b.svg
      fullname: 'null'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mzbac
      type: user
    createdAt: '2024-01-21T00:57:08.000Z'
    data:
      edited: false
      editors:
      - mzbac
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9415780901908875
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/513e0d2c15cfbb1542cb268eb2c8d68b.svg
          fullname: 'null'
          isHf: false
          isPro: false
          name: mzbac
          type: user
        html: '<p>Once the model type is updated, it should be ready to be ported
          into mlx-lm and able to be lora fine-tuned with gate.</p>

          '
        raw: Once the model type is updated, it should be ready to be ported into
          mlx-lm and able to be lora fine-tuned with gate.
        updatedAt: '2024-01-21T00:57:08.879Z'
      numEdits: 0
      reactions: []
    id: 65ac6be4c8903e28ae5d74ed
    type: comment
  author: mzbac
  content: Once the model type is updated, it should be ready to be ported into mlx-lm
    and able to be lora fine-tuned with gate.
  created_at: 2024-01-21 00:57:08+00:00
  edited: false
  hidden: false
  id: 65ac6be4c8903e28ae5d74ed
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
      fullname: Maxime Labonne
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: mlabonne
      type: user
    createdAt: '2024-01-21T13:42:46.000Z'
    data:
      edited: false
      editors:
      - mlabonne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9705191850662231
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
          fullname: Maxime Labonne
          isHf: false
          isPro: false
          name: mlabonne
          type: user
        html: '<p>Hello, not sure it''s that easy. "phi-msft" is also used in configuration_phi.py
          for example. Have you tested it?</p>

          '
        raw: 'Hello, not sure it''s that easy. "phi-msft" is also used in configuration_phi.py
          for example. Have you tested it?

          '
        updatedAt: '2024-01-21T13:42:46.964Z'
      numEdits: 0
      reactions: []
    id: 65ad1f56c2eef2ba11405803
    type: comment
  author: mlabonne
  content: 'Hello, not sure it''s that easy. "phi-msft" is also used in configuration_phi.py
    for example. Have you tested it?

    '
  created_at: 2024-01-21 13:42:46+00:00
  edited: false
  hidden: false
  id: 65ad1f56c2eef2ba11405803
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/513e0d2c15cfbb1542cb268eb2c8d68b.svg
      fullname: 'null'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mzbac
      type: user
    createdAt: '2024-01-21T13:50:57.000Z'
    data:
      edited: true
      editors:
      - mzbac
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9585773348808289
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/513e0d2c15cfbb1542cb268eb2c8d68b.svg
          fullname: 'null'
          isHf: false
          isPro: false
          name: mzbac
          type: user
        html: '<p>I haven''t tested it, but the model type "phi-msft" is for phi series
          models (and it has changed to "phi" in the official model repository "microsoft/phi-2"),
          not for merged models anyway. Since this model configuration uses auto mapping,
          it loads as a custom model and the specific model type doesn''t really matter.
          I quickly checked the transformer code and it seems that for natively supported
          models, it uses <code>config.architectures</code> to load the model class.</p>

          '
        raw: I haven't tested it, but the model type "phi-msft" is for phi series
          models (and it has changed to "phi" in the official model repository "microsoft/phi-2"),
          not for merged models anyway. Since this model configuration uses auto mapping,
          it loads as a custom model and the specific model type doesn't really matter.
          I quickly checked the transformer code and it seems that for natively supported
          models, it uses `config.architectures` to load the model class.
        updatedAt: '2024-01-21T13:52:55.267Z'
      numEdits: 1
      reactions: []
    id: 65ad2141a92a64ef5b30f9dc
    type: comment
  author: mzbac
  content: I haven't tested it, but the model type "phi-msft" is for phi series models
    (and it has changed to "phi" in the official model repository "microsoft/phi-2"),
    not for merged models anyway. Since this model configuration uses auto mapping,
    it loads as a custom model and the specific model type doesn't really matter.
    I quickly checked the transformer code and it seems that for natively supported
    models, it uses `config.architectures` to load the model class.
  created_at: 2024-01-21 13:50:57+00:00
  edited: true
  hidden: false
  id: 65ad2141a92a64ef5b30f9dc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
      fullname: Maxime Labonne
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: mlabonne
      type: user
    createdAt: '2024-01-21T13:57:59.000Z'
    data:
      edited: false
      editors:
      - mlabonne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9324604272842407
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
          fullname: Maxime Labonne
          isHf: false
          isPro: false
          name: mlabonne
          type: user
        html: '<p>Happy to merge it if you can test that this change doesn''t break
          non-mlx configurations.</p>

          '
        raw: Happy to merge it if you can test that this change doesn't break non-mlx
          configurations.
        updatedAt: '2024-01-21T13:57:59.586Z'
      numEdits: 0
      reactions: []
    id: 65ad22e76a55aac02a73ebb2
    type: comment
  author: mlabonne
  content: Happy to merge it if you can test that this change doesn't break non-mlx
    configurations.
  created_at: 2024-01-21 13:57:59+00:00
  edited: false
  hidden: false
  id: 65ad22e76a55aac02a73ebb2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/513e0d2c15cfbb1542cb268eb2c8d68b.svg
      fullname: 'null'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mzbac
      type: user
    createdAt: '2024-01-22T07:21:04.000Z'
    data:
      oid: efd33150d3d4a84f4247560432c483330276c834
      parents:
      - 32101cbd0e4404d566d6f749bc8617fa3a7146d9
      subject: Update configuration_phi.py
    id: 65ae17600000000000000000
    type: commit
  author: mzbac
  created_at: 2024-01-22 07:21:04+00:00
  id: 65ae17600000000000000000
  oid: efd33150d3d4a84f4247560432c483330276c834
  summary: Update configuration_phi.py
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/513e0d2c15cfbb1542cb268eb2c8d68b.svg
      fullname: 'null'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mzbac
      type: user
    createdAt: '2024-01-22T07:26:02.000Z'
    data:
      edited: true
      editors:
      - mzbac
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9234203100204468
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/513e0d2c15cfbb1542cb268eb2c8d68b.svg
          fullname: 'null'
          isHf: false
          isPro: false
          name: mzbac
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mlabonne&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mlabonne\">@<span class=\"\
          underline\">mlabonne</span></a></span>\n\n\t</span></span> Sorry for the\
          \ late reply. I just did a local test and it worked fine on my local machine\
          \ (4090, load_in_4bit). The mode_type doesn't really affect the custom models.\
          \ By the way, since Microsoft updated phi2 to use hf format, would you mind\
          \ re-merging the model using HF format? I can help with porting it in mlx.\
          \ This will make implementing lora in MLX easier due to using standard attention\
          \ layer naming convention.</p>\n"
        raw: '@mlabonne Sorry for the late reply. I just did a local test and it worked
          fine on my local machine (4090, load_in_4bit). The mode_type doesn''t really
          affect the custom models. By the way, since Microsoft updated phi2 to use
          hf format, would you mind re-merging the model using HF format? I can help
          with porting it in mlx. This will make implementing lora in MLX easier due
          to using standard attention layer naming convention.'
        updatedAt: '2024-01-22T08:10:01.159Z'
      numEdits: 1
      reactions: []
    id: 65ae188ae2a2c86356a3b223
    type: comment
  author: mzbac
  content: '@mlabonne Sorry for the late reply. I just did a local test and it worked
    fine on my local machine (4090, load_in_4bit). The mode_type doesn''t really affect
    the custom models. By the way, since Microsoft updated phi2 to use hf format,
    would you mind re-merging the model using HF format? I can help with porting it
    in mlx. This will make implementing lora in MLX easier due to using standard attention
    layer naming convention.'
  created_at: 2024-01-22 07:26:02+00:00
  edited: true
  hidden: false
  id: 65ae188ae2a2c86356a3b223
  type: comment
is_pull_request: true
merge_commit_oid: null
num: 14
repo_id: mlabonne/phixtral-4x2_8
repo_type: model
status: open
target_branch: refs/heads/main
title: Update the model type to make it compatible with mlx-lm's model mapping.
