!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ringle
conflicting_files: null
created_at: 2023-05-16 22:06:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7fb1d241489fb65c6bcb049c2ecaccf3.svg
      fullname: Ryan Inghilterra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ringle
      type: user
    createdAt: '2023-05-16T23:06:33.000Z'
    data:
      edited: true
      editors:
      - ringle
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7fb1d241489fb65c6bcb049c2ecaccf3.svg
          fullname: Ryan Inghilterra
          isHf: false
          isPro: false
          name: ringle
          type: user
        html: '<p>Whenever I try running the model it cuts off after a couple of words.
          Any idea what I am doing wrong?<br><code>tokenizer = AutoTokenizer.from_pretrained("EleutherAI/gpt-neox-20b")</code></p>

          <p><code>config = transformers.AutoConfig.from_pretrained(   ''mosaicml/mpt-7b-instruct'',   trust_remote_code=True,
          ) </code><br><code>config.init_device = "cuda:0"</code></p>

          <p><code>model = transformers.AutoModelForCausalLM.from_pretrained(   ''mosaicml/mpt-7b-instruct'',   config=config,   torch_dtype=torch.bfloat16,   trust_remote_code=True,
          )</code><br><code>model.to(device=''cuda:0'')</code><br><code>text_gen =
          pipeline("text-generation", model=model, tokenizer=tokenizer, device="cuda:0")</code><br><code>text_gen(text_inputs="What
          is a quoll?")</code></p>

          <p>Output: [{''generated_text'': ''What is a quoll?\nThe quoll is a marsupial
          native to Australia. It''}]</p>

          '
        raw: "Whenever I try running the model it cuts off after a couple of words.\
          \ Any idea what I am doing wrong?\n```tokenizer = AutoTokenizer.from_pretrained(\"\
          EleutherAI/gpt-neox-20b\")```\n```config = transformers.AutoConfig.from_pretrained(\n\
          \  'mosaicml/mpt-7b-instruct',\n  trust_remote_code=True,\n) ```\n```config.init_device\
          \ = \"cuda:0\"```\n```model = transformers.AutoModelForCausalLM.from_pretrained(\n\
          \  'mosaicml/mpt-7b-instruct',\n  config=config,\n  torch_dtype=torch.bfloat16,\n\
          \  trust_remote_code=True,\n)```\n```model.to(device='cuda:0')```\n```text_gen\
          \ = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=\"\
          cuda:0\")```\n```text_gen(text_inputs=\"What is a quoll?\")```\n\nOutput:\
          \ [{'generated_text': 'What is a quoll?\\nThe quoll is a marsupial native\
          \ to Australia. It'}]"
        updatedAt: '2023-05-16T23:09:02.529Z'
      numEdits: 1
      reactions: []
    id: 64640c79e0475a83333d3ef7
    type: comment
  author: ringle
  content: "Whenever I try running the model it cuts off after a couple of words.\
    \ Any idea what I am doing wrong?\n```tokenizer = AutoTokenizer.from_pretrained(\"\
    EleutherAI/gpt-neox-20b\")```\n```config = transformers.AutoConfig.from_pretrained(\n\
    \  'mosaicml/mpt-7b-instruct',\n  trust_remote_code=True,\n) ```\n```config.init_device\
    \ = \"cuda:0\"```\n```model = transformers.AutoModelForCausalLM.from_pretrained(\n\
    \  'mosaicml/mpt-7b-instruct',\n  config=config,\n  torch_dtype=torch.bfloat16,\n\
    \  trust_remote_code=True,\n)```\n```model.to(device='cuda:0')```\n```text_gen\
    \ = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=\"\
    cuda:0\")```\n```text_gen(text_inputs=\"What is a quoll?\")```\n\nOutput: [{'generated_text':\
    \ 'What is a quoll?\\nThe quoll is a marsupial native to Australia. It'}]"
  created_at: 2023-05-16 22:06:33+00:00
  edited: true
  hidden: false
  id: 64640c79e0475a83333d3ef7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7fb1d241489fb65c6bcb049c2ecaccf3.svg
      fullname: Ryan Inghilterra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ringle
      type: user
    createdAt: '2023-05-16T23:19:31.000Z'
    data:
      edited: false
      editors:
      - ringle
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7fb1d241489fb65c6bcb049c2ecaccf3.svg
          fullname: Ryan Inghilterra
          isHf: false
          isPro: false
          name: ringle
          type: user
        html: '<p>nevermind, I figured out I need to set max_new_tokens such as:</p>

          <p><code>text_gen = pipeline("text-generation", model=model, tokenizer=tokenizer,                      max_new_tokens=300,
          device="cuda:0")</code></p>

          <p>Overall pretty slow for being on a GPU (~1 token per second) and uses
          100% of the GPU-Util on a v100 (16 GB)</p>

          '
        raw: "nevermind, I figured out I need to set max_new_tokens such as:\n\n```text_gen\
          \ = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, \n \
          \                   max_new_tokens=300, device=\"cuda:0\")```\n\nOverall\
          \ pretty slow for being on a GPU (~1 token per second) and uses 100% of\
          \ the GPU-Util on a v100 (16 GB)"
        updatedAt: '2023-05-16T23:19:31.838Z'
      numEdits: 0
      reactions: []
    id: 64640f8365d811c4962bcfce
    type: comment
  author: ringle
  content: "nevermind, I figured out I need to set max_new_tokens such as:\n\n```text_gen\
    \ = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, \n       \
    \             max_new_tokens=300, device=\"cuda:0\")```\n\nOverall pretty slow\
    \ for being on a GPU (~1 token per second) and uses 100% of the GPU-Util on a\
    \ v100 (16 GB)"
  created_at: 2023-05-16 22:19:31+00:00
  edited: false
  hidden: false
  id: 64640f8365d811c4962bcfce
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/7fb1d241489fb65c6bcb049c2ecaccf3.svg
      fullname: Ryan Inghilterra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ringle
      type: user
    createdAt: '2023-05-16T23:19:35.000Z'
    data:
      status: closed
    id: 64640f8776155a231c8414f8
    type: status-change
  author: ringle
  created_at: 2023-05-16 22:19:35+00:00
  id: 64640f8776155a231c8414f8
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 21
repo_id: mosaicml/mpt-7b-instruct
repo_type: model
status: closed
target_branch: null
title: generated_text output gets truncated
