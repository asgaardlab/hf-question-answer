!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ThreeBlessings
conflicting_files: null
created_at: 2023-05-27 19:55:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/511705723ec776a91bdff4fd4bd37c12.svg
      fullname: Volodymyr
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ThreeBlessings
      type: user
    createdAt: '2023-05-27T20:55:24.000Z'
    data:
      edited: false
      editors:
      - ThreeBlessings
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/511705723ec776a91bdff4fd4bd37c12.svg
          fullname: Volodymyr
          isHf: false
          isPro: false
          name: ThreeBlessings
          type: user
        html: '<p>Hi!</p>

          <p>I''m updating a <a rel="nofollow" href="https://github.com/dcai-course/dcai-lab/blob/master/prompt_engineering/Lab_Prompt_Engineering.ipynb">lab</a>
          for Data-Centric AI course and it would be cool to use this model with <code>load_in_8bit=True</code>
          parameter and have it sharded in 2Gb weights for easy use with free tier
          Colab GPUs.</p>

          <p>Is it planned to add this features?</p>

          '
        raw: "Hi!\r\n\r\nI'm updating a [lab](https://github.com/dcai-course/dcai-lab/blob/master/prompt_engineering/Lab_Prompt_Engineering.ipynb)\
          \ for Data-Centric AI course and it would be cool to use this model with\
          \ `load_in_8bit=True` parameter and have it sharded in 2Gb weights for easy\
          \ use with free tier Colab GPUs.\r\n\r\nIs it planned to add this features?"
        updatedAt: '2023-05-27T20:55:24.638Z'
      numEdits: 0
      reactions: []
    id: 64726e3c0c2b5fdaf1f43a61
    type: comment
  author: ThreeBlessings
  content: "Hi!\r\n\r\nI'm updating a [lab](https://github.com/dcai-course/dcai-lab/blob/master/prompt_engineering/Lab_Prompt_Engineering.ipynb)\
    \ for Data-Centric AI course and it would be cool to use this model with `load_in_8bit=True`\
    \ parameter and have it sharded in 2Gb weights for easy use with free tier Colab\
    \ GPUs.\r\n\r\nIs it planned to add this features?"
  created_at: 2023-05-27 19:55:24+00:00
  edited: false
  hidden: false
  id: 64726e3c0c2b5fdaf1f43a61
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ff5fc4fe6383d50b29052e/Vk9R5rKqG-Z_ou-55J9x-.jpeg?w=200&h=200&f=face
      fullname: AayushShah
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AayushShah
      type: user
    createdAt: '2023-05-29T10:13:22.000Z'
    data:
      edited: false
      editors:
      - AayushShah
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ff5fc4fe6383d50b29052e/Vk9R5rKqG-Z_ou-55J9x-.jpeg?w=200&h=200&f=face
          fullname: AayushShah
          isHf: false
          isPro: false
          name: AayushShah
          type: user
        html: "<p>I've used this code:</p>\n<pre><code class=\"language-python\">model_name\
          \ = <span class=\"hljs-string\">\"mosaicml/mpt-7b-instruct\"</span>\ntokenizer\
          \ = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name,\n\
          \                                             low_cpu_mem_usage=<span class=\"\
          hljs-literal\">True</span>,\n                                          \
          \   trust_remote_code=<span class=\"hljs-literal\">True</span>,\n      \
          \                                       load_in_8bit=<span class=\"hljs-literal\"\
          >True</span>,\n                                             torch_dtype=torch.float16,\n\
          \                                             device_map=<span class=\"\
          hljs-string\">\"auto\"</span>)\n</code></pre>\n<p>But gives this error:</p>\n\
          <pre><code>ValueError: MPTForCausalLM does not support `device_map='auto'`\
          \ yet.\n</code></pre>\n"
        raw: "I've used this code:\n```python\nmodel_name = \"mosaicml/mpt-7b-instruct\"\
          \ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name,\n\
          \                                             low_cpu_mem_usage=True,\n\
          \                                             trust_remote_code=True,\n\
          \                                             load_in_8bit=True,\n     \
          \                                        torch_dtype=torch.float16,\n  \
          \                                           device_map=\"auto\")\n\n```\n\
          But gives this error:\n```\nValueError: MPTForCausalLM does not support\
          \ `device_map='auto'` yet.\n```"
        updatedAt: '2023-05-29T10:13:22.207Z'
      numEdits: 0
      reactions: []
    id: 64747ac25ada8510bc3d62ef
    type: comment
  author: AayushShah
  content: "I've used this code:\n```python\nmodel_name = \"mosaicml/mpt-7b-instruct\"\
    \ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name,\n\
    \                                             low_cpu_mem_usage=True,\n      \
    \                                       trust_remote_code=True,\n            \
    \                                 load_in_8bit=True,\n                       \
    \                      torch_dtype=torch.float16,\n                          \
    \                   device_map=\"auto\")\n\n```\nBut gives this error:\n```\n\
    ValueError: MPTForCausalLM does not support `device_map='auto'` yet.\n```"
  created_at: 2023-05-29 09:13:22+00:00
  edited: false
  hidden: false
  id: 64747ac25ada8510bc3d62ef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
      fullname: Abhi Venigalla
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: abhi-mosaic
      type: user
    createdAt: '2023-06-03T00:50:22.000Z'
    data:
      edited: false
      editors:
      - abhi-mosaic
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8777457475662231
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
          fullname: Abhi Venigalla
          isHf: false
          isPro: false
          name: abhi-mosaic
          type: user
        html: '<p>I believe this should be fixed now as of this PR: <a href="https://huggingface.co/mosaicml/mpt-7b-instruct/discussions/41">https://huggingface.co/mosaicml/mpt-7b-instruct/discussions/41</a></p>

          '
        raw: 'I believe this should be fixed now as of this PR: https://huggingface.co/mosaicml/mpt-7b-instruct/discussions/41'
        updatedAt: '2023-06-03T00:50:22.189Z'
      numEdits: 0
      reactions: []
      relatedEventId: 647a8e4e42abe27747626516
    id: 647a8e4e42abe27747626514
    type: comment
  author: abhi-mosaic
  content: 'I believe this should be fixed now as of this PR: https://huggingface.co/mosaicml/mpt-7b-instruct/discussions/41'
  created_at: 2023-06-02 23:50:22+00:00
  edited: false
  hidden: false
  id: 647a8e4e42abe27747626514
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
      fullname: Abhi Venigalla
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: abhi-mosaic
      type: user
    createdAt: '2023-06-03T00:50:22.000Z'
    data:
      status: closed
    id: 647a8e4e42abe27747626516
    type: status-change
  author: abhi-mosaic
  created_at: 2023-06-02 23:50:22+00:00
  id: 647a8e4e42abe27747626516
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 37
repo_id: mosaicml/mpt-7b-instruct
repo_type: model
status: closed
target_branch: null
title: 8bit and sharded weights
