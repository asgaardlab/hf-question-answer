!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MehtabPathan
conflicting_files: null
created_at: 2023-05-11 09:03:39+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4de8b644d4cf879e7b180b9cda54c702.svg
      fullname: Pathan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MehtabPathan
      type: user
    createdAt: '2023-05-11T10:03:39.000Z'
    data:
      edited: false
      editors:
      - MehtabPathan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4de8b644d4cf879e7b180b9cda54c702.svg
          fullname: Pathan
          isHf: false
          isPro: false
          name: MehtabPathan
          type: user
        html: '<p>I would like to extract embeddings from this model, what would be
          the process to do that? I know in encoder-decoder style model, I can simply
          look at the encoder output.</p>

          '
        raw: I would like to extract embeddings from this model, what would be the
          process to do that? I know in encoder-decoder style model, I can simply
          look at the encoder output.
        updatedAt: '2023-05-11T10:03:39.840Z'
      numEdits: 0
      reactions: []
    id: 645cbd7b7c7258d904e42dd1
    type: comment
  author: MehtabPathan
  content: I would like to extract embeddings from this model, what would be the process
    to do that? I know in encoder-decoder style model, I can simply look at the encoder
    output.
  created_at: 2023-05-11 09:03:39+00:00
  edited: false
  hidden: false
  id: 645cbd7b7c7258d904e42dd1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2fd7bd23254678f7f46ecff823fff1ce.svg
      fullname: Michael Conrad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: michael-newsrx-com
      type: user
    createdAt: '2023-05-11T14:04:15.000Z'
    data:
      edited: false
      editors:
      - michael-newsrx-com
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2fd7bd23254678f7f46ecff823fff1ce.svg
          fullname: Michael Conrad
          isHf: false
          isPro: false
          name: michael-newsrx-com
          type: user
        html: '<p>I also would like to know.</p>

          '
        raw: I also would like to know.
        updatedAt: '2023-05-11T14:04:15.617Z'
      numEdits: 0
      reactions: []
    id: 645cf5df4438da4fcc1cba98
    type: comment
  author: michael-newsrx-com
  content: I also would like to know.
  created_at: 2023-05-11 13:04:15+00:00
  edited: false
  hidden: false
  id: 645cf5df4438da4fcc1cba98
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
      fullname: Abhi Venigalla
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: abhi-mosaic
      type: user
    createdAt: '2023-05-11T23:45:10.000Z'
    data:
      edited: true
      editors:
      - abhi-mosaic
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
          fullname: Abhi Venigalla
          isHf: false
          isPro: false
          name: abhi-mosaic
          type: user
        html: '<p>I would recommend building an <code>MPTModel</code>, which is the
          base model that produces embeddings, and you can see <a rel="nofollow" href="https://github.com/mosaicml/llm-foundry/blob/a3eed9b4276b85491c91693d590c4f85dde26650/llmfoundry/models/mpt/modeling_mpt.py#L53">the
          class here in  LLM Foundry.</a></p>

          <p>You can either fork the repo or pip install the package and import:<br><code>pip
          install llm-foundry</code><br><code>from llmfoundry.models import MPTModel</code></p>

          <p>If you run forward on MPTModel you''ll get an output of size [batch_size,
          seq_len, d_model]. Youll probably want to average the embeddings (or some
          other scheme) along the seq_len dimension to get an average embedding for
          the sentence.</p>

          <p>Hope this helps!</p>

          '
        raw: 'I would recommend building an `MPTModel`, which is the base model that
          produces embeddings, and you can see [the class here in  LLM Foundry.](https://github.com/mosaicml/llm-foundry/blob/a3eed9b4276b85491c91693d590c4f85dde26650/llmfoundry/models/mpt/modeling_mpt.py#L53)


          You can either fork the repo or pip install the package and import:

          ```pip install llm-foundry```

          ```from llmfoundry.models import MPTModel```


          If you run forward on MPTModel you''ll get an output of size [batch_size,
          seq_len, d_model]. Youll probably want to average the embeddings (or some
          other scheme) along the seq_len dimension to get an average embedding for
          the sentence.


          Hope this helps!'
        updatedAt: '2023-05-11T23:45:20.951Z'
      numEdits: 1
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - kil3r
        - madhavatreplit
        - Pragyan-02
        - yyzy1209
    id: 645d7e068ce4443cae74eaf2
    type: comment
  author: abhi-mosaic
  content: 'I would recommend building an `MPTModel`, which is the base model that
    produces embeddings, and you can see [the class here in  LLM Foundry.](https://github.com/mosaicml/llm-foundry/blob/a3eed9b4276b85491c91693d590c4f85dde26650/llmfoundry/models/mpt/modeling_mpt.py#L53)


    You can either fork the repo or pip install the package and import:

    ```pip install llm-foundry```

    ```from llmfoundry.models import MPTModel```


    If you run forward on MPTModel you''ll get an output of size [batch_size, seq_len,
    d_model]. Youll probably want to average the embeddings (or some other scheme)
    along the seq_len dimension to get an average embedding for the sentence.


    Hope this helps!'
  created_at: 2023-05-11 22:45:10+00:00
  edited: true
  hidden: false
  id: 645d7e068ce4443cae74eaf2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
      fullname: Sam Havens
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sam-mosaic
      type: user
    createdAt: '2023-05-19T22:14:22.000Z'
    data:
      status: closed
    id: 6467f4be3a7c8dda230c8679
    type: status-change
  author: sam-mosaic
  created_at: 2023-05-19 21:14:22+00:00
  id: 6467f4be3a7c8dda230c8679
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8aaab676f66023255d397ba82b4bcb6e.svg
      fullname: James Hunter Carter
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: jameshuntercarter
      type: user
    createdAt: '2023-06-15T04:22:46.000Z'
    data:
      edited: false
      editors:
      - jameshuntercarter
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9147511720657349
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8aaab676f66023255d397ba82b4bcb6e.svg
          fullname: James Hunter Carter
          isHf: false
          isPro: true
          name: jameshuntercarter
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;abhi-mosaic&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/abhi-mosaic\"\
          >@<span class=\"underline\">abhi-mosaic</span></a></span>\n\n\t</span></span>\
          \ Thanks for that insight. Is this basic embedding functionality something\
          \ you expect to get added to the LLM Foundry package down the road?</p>\n"
        raw: '@abhi-mosaic Thanks for that insight. Is this basic embedding functionality
          something you expect to get added to the LLM Foundry package down the road?'
        updatedAt: '2023-06-15T04:22:46.003Z'
      numEdits: 0
      reactions: []
    id: 648a92168242d38574973113
    type: comment
  author: jameshuntercarter
  content: '@abhi-mosaic Thanks for that insight. Is this basic embedding functionality
    something you expect to get added to the LLM Foundry package down the road?'
  created_at: 2023-06-15 03:22:46+00:00
  edited: false
  hidden: false
  id: 648a92168242d38574973113
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: mosaicml/mpt-7b-instruct
repo_type: model
status: closed
target_branch: null
title: How can I extract embeddings from this model?
