!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nai-kon
conflicting_files: null
created_at: 2023-06-27 04:22:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d2f29e1d3b11dbd5565b9457b5f8c33c.svg
      fullname: nai-kon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nai-kon
      type: user
    createdAt: '2023-06-27T05:22:55.000Z'
    data:
      edited: true
      editors:
      - nai-kon
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3641941547393799
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d2f29e1d3b11dbd5565b9457b5f8c33c.svg
          fullname: nai-kon
          isHf: false
          isPro: false
          name: nai-kon
          type: user
        html: "<p>Failed to load model by below code. </p>\n<h1 id=\"code\">Code</h1>\n\
          <pre><code class=\"language-python\">llm = HuggingFacePipeline.from_model_id(\n\
          \    <span class=\"hljs-string\">\"TheBloke/Vicuna-13B-1.3.0-SuperHOT-8K-fp16\"\
          </span>,\n    task=<span class=\"hljs-string\">\"text-generation\"</span>,\n\
          \    model_kwargs={\n        <span class=\"hljs-string\">\"trust_remote_code\"\
          </span>: <span class=\"hljs-literal\">True</span>,\n})\n</code></pre>\n\
          <h1 id=\"error\">Error</h1>\n<pre><code>  File \"/home/.local/lib/python3.10/site-packages/langchain/llms/huggingface_pipeline.py\"\
          , line 93, in from_model_id\n    model = AutoModelForCausalLM.from_pretrained(model_id,\
          \ **_model_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\"\
          , line 459, in from_pretrained\n    model_class = get_class_from_dynamic_module(\n\
          \  File \"/usr/local/lib/python3.10/dist-packages/transformers/dynamic_module_utils.py\"\
          , line 437, in get_class_from_dynamic_module\n    return get_class_in_module(class_name,\
          \ final_module.replace(\".py\", \"\"))\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/dynamic_module_utils.py\"\
          , line 163, in get_class_in_module\n    module = importlib.import_module(module_path)\n\
          \  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n\
          \    return _bootstrap._gcd_import(name[level:], package, level)\nModuleNotFoundError:\
          \ No module named 'transformers_modules.TheBloke.Vicuna-13B-1'\n</code></pre>\n\
          <p>It seems the period in model name causes module import error when trust_remote_code=True.</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">def</span>\
          \ <span class=\"hljs-title function_\">get_class_in_module</span>(<span\
          \ class=\"hljs-params\">class_name, module_path</span>):\n    <span class=\"\
          hljs-string\">\"\"\"</span>\n<span class=\"hljs-string\">    Import a module\
          \ on the cache directory for modules and extract a class from it.</span>\n\
          <span class=\"hljs-string\">    \"\"\"</span>\n    module_path = module_path.replace(os.path.sep,\
          \ <span class=\"hljs-string\">\".\"</span>)\n    module = importlib.import_module(module_path)\n\
          \    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\"\
          >getattr</span>(module, class_name)\n</code></pre>\n"
        raw: "Failed to load model by below code. \n\n# Code\n```python\nllm = HuggingFacePipeline.from_model_id(\n\
          \    \"TheBloke/Vicuna-13B-1.3.0-SuperHOT-8K-fp16\",\n    task=\"text-generation\"\
          ,\n    model_kwargs={\n        \"trust_remote_code\": True,\n})\n```\n#\
          \ Error\n```\n  File \"/home/.local/lib/python3.10/site-packages/langchain/llms/huggingface_pipeline.py\"\
          , line 93, in from_model_id\n    model = AutoModelForCausalLM.from_pretrained(model_id,\
          \ **_model_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\"\
          , line 459, in from_pretrained\n    model_class = get_class_from_dynamic_module(\n\
          \  File \"/usr/local/lib/python3.10/dist-packages/transformers/dynamic_module_utils.py\"\
          , line 437, in get_class_from_dynamic_module\n    return get_class_in_module(class_name,\
          \ final_module.replace(\".py\", \"\"))\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/dynamic_module_utils.py\"\
          , line 163, in get_class_in_module\n    module = importlib.import_module(module_path)\n\
          \  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n\
          \    return _bootstrap._gcd_import(name[level:], package, level)\nModuleNotFoundError:\
          \ No module named 'transformers_modules.TheBloke.Vicuna-13B-1'\n```\n\n\
          It seems the period in model name causes module import error when trust_remote_code=True.\n\
          ```python\ndef get_class_in_module(class_name, module_path):\n    \"\"\"\
          \n    Import a module on the cache directory for modules and extract a class\
          \ from it.\n    \"\"\"\n    module_path = module_path.replace(os.path.sep,\
          \ \".\")\n    module = importlib.import_module(module_path)\n    return\
          \ getattr(module, class_name)\n```"
        updatedAt: '2023-06-27T05:30:50.592Z'
      numEdits: 3
      reactions: []
    id: 649a722f342f1414835ce940
    type: comment
  author: nai-kon
  content: "Failed to load model by below code. \n\n# Code\n```python\nllm = HuggingFacePipeline.from_model_id(\n\
    \    \"TheBloke/Vicuna-13B-1.3.0-SuperHOT-8K-fp16\",\n    task=\"text-generation\"\
    ,\n    model_kwargs={\n        \"trust_remote_code\": True,\n})\n```\n# Error\n\
    ```\n  File \"/home/.local/lib/python3.10/site-packages/langchain/llms/huggingface_pipeline.py\"\
    , line 93, in from_model_id\n    model = AutoModelForCausalLM.from_pretrained(model_id,\
    \ **_model_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\"\
    , line 459, in from_pretrained\n    model_class = get_class_from_dynamic_module(\n\
    \  File \"/usr/local/lib/python3.10/dist-packages/transformers/dynamic_module_utils.py\"\
    , line 437, in get_class_from_dynamic_module\n    return get_class_in_module(class_name,\
    \ final_module.replace(\".py\", \"\"))\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/dynamic_module_utils.py\"\
    , line 163, in get_class_in_module\n    module = importlib.import_module(module_path)\n\
    \  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n\
    \    return _bootstrap._gcd_import(name[level:], package, level)\nModuleNotFoundError:\
    \ No module named 'transformers_modules.TheBloke.Vicuna-13B-1'\n```\n\nIt seems\
    \ the period in model name causes module import error when trust_remote_code=True.\n\
    ```python\ndef get_class_in_module(class_name, module_path):\n    \"\"\"\n   \
    \ Import a module on the cache directory for modules and extract a class from\
    \ it.\n    \"\"\"\n    module_path = module_path.replace(os.path.sep, \".\")\n\
    \    module = importlib.import_module(module_path)\n    return getattr(module,\
    \ class_name)\n```"
  created_at: 2023-06-27 04:22:55+00:00
  edited: true
  hidden: false
  id: 649a722f342f1414835ce940
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-27T08:07:13.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8509658575057983
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>This error was caused by the <code>1.3.0</code> in the model name.
          It''s a bug in the Transformers code that breaks if the model contains a
          <code>.</code> </p>

          <p>I''ve fixed it by renaming the model to:</p>

          <ul>

          <li><code>TheBloke/Vicuna-13B-1-3-SuperHOT-8K-fp16</code></li>

          <li><code>TheBloke/Vicuna-13B-1-3-SuperHOT-8K-GPTQ</code></li>

          </ul>

          '
        raw: "This error was caused by the `1.3.0` in the model name. It's a bug in\
          \ the Transformers code that breaks if the model contains a `.` \n\nI've\
          \ fixed it by renaming the model to:\n- `TheBloke/Vicuna-13B-1-3-SuperHOT-8K-fp16`\n\
          - `TheBloke/Vicuna-13B-1-3-SuperHOT-8K-GPTQ`"
        updatedAt: '2023-06-27T08:07:13.917Z'
      numEdits: 0
      reactions: []
    id: 649a98b1e6a46226025345e2
    type: comment
  author: TheBloke
  content: "This error was caused by the `1.3.0` in the model name. It's a bug in\
    \ the Transformers code that breaks if the model contains a `.` \n\nI've fixed\
    \ it by renaming the model to:\n- `TheBloke/Vicuna-13B-1-3-SuperHOT-8K-fp16`\n\
    - `TheBloke/Vicuna-13B-1-3-SuperHOT-8K-GPTQ`"
  created_at: 2023-06-27 07:07:13+00:00
  edited: false
  hidden: false
  id: 649a98b1e6a46226025345e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d2f29e1d3b11dbd5565b9457b5f8c33c.svg
      fullname: nai-kon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nai-kon
      type: user
    createdAt: '2023-06-27T23:29:31.000Z'
    data:
      edited: false
      editors:
      - nai-kon
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.46368739008903503
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d2f29e1d3b11dbd5565b9457b5f8c33c.svg
          fullname: nai-kon
          isHf: false
          isPro: false
          name: nai-kon
          type: user
        html: '<p>Thank you!</p>

          '
        raw: Thank you!
        updatedAt: '2023-06-27T23:29:31.995Z'
      numEdits: 0
      reactions: []
      relatedEventId: 649b70dc2ddbc93209fdc6dc
    id: 649b70db2ddbc93209fdc6db
    type: comment
  author: nai-kon
  content: Thank you!
  created_at: 2023-06-27 22:29:31+00:00
  edited: false
  hidden: false
  id: 649b70db2ddbc93209fdc6db
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/d2f29e1d3b11dbd5565b9457b5f8c33c.svg
      fullname: nai-kon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nai-kon
      type: user
    createdAt: '2023-06-27T23:29:32.000Z'
    data:
      status: closed
    id: 649b70dc2ddbc93209fdc6dc
    type: status-change
  author: nai-kon
  created_at: 2023-06-27 22:29:32+00:00
  id: 649b70dc2ddbc93209fdc6dc
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Vicuna-13B-1-3-SuperHOT-8K-fp16
repo_type: model
status: closed
target_branch: null
title: failed to load the model
