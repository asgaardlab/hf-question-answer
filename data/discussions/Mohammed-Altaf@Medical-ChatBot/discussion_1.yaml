!!python/object:huggingface_hub.community.DiscussionWithDetails
author: visionop19
conflicting_files: null
created_at: 2023-12-25 11:03:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c721f7c2dc5f4867365a4e47a663bf0a.svg
      fullname: chandan c r
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: visionop19
      type: user
    createdAt: '2023-12-25T11:03:59.000Z'
    data:
      edited: false
      editors:
      - visionop19
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9323388934135437
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c721f7c2dc5f4867365a4e47a663bf0a.svg
          fullname: chandan c r
          isHf: false
          isPro: false
          name: visionop19
          type: user
        html: '<p>Hey altaf I am chandan Cr I need to use your model in an hackathon
          I need to connect with you how can I ?</p>

          '
        raw: "Hey altaf I am chandan Cr I need to use your model in an hackathon I\
          \ need to connect with you how can I ?\r\n"
        updatedAt: '2023-12-25T11:03:59.674Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Mohammed-Altaf
    id: 6589619f57244e8129e7ca80
    type: comment
  author: visionop19
  content: "Hey altaf I am chandan Cr I need to use your model in an hackathon I need\
    \ to connect with you how can I ?\r\n"
  created_at: 2023-12-25 11:03:59+00:00
  edited: false
  hidden: false
  id: 6589619f57244e8129e7ca80
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6423e4a4a05235e2f8d1d978/pA_AKIArOrdw_77fWF38R.jpeg?w=200&h=200&f=face
      fullname: Mohammed Altaf
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Mohammed-Altaf
      type: user
    createdAt: '2023-12-26T04:09:19.000Z'
    data:
      edited: false
      editors:
      - Mohammed-Altaf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.914496123790741
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6423e4a4a05235e2f8d1d978/pA_AKIArOrdw_77fWF38R.jpeg?w=200&h=200&f=face
          fullname: Mohammed Altaf
          isHf: false
          isPro: false
          name: Mohammed-Altaf
          type: user
        html: '<p>you can see the details to use at the model card it self. used quantized
          version of the model if you lack hardware reseources. </p>

          '
        raw: 'you can see the details to use at the model card it self. used quantized
          version of the model if you lack hardware reseources. '
        updatedAt: '2023-12-26T04:09:19.958Z'
      numEdits: 0
      reactions: []
    id: 658a51ef067630f69f949ca1
    type: comment
  author: Mohammed-Altaf
  content: 'you can see the details to use at the model card it self. used quantized
    version of the model if you lack hardware reseources. '
  created_at: 2023-12-26 04:09:19+00:00
  edited: false
  hidden: false
  id: 658a51ef067630f69f949ca1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c721f7c2dc5f4867365a4e47a663bf0a.svg
      fullname: chandan c r
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: visionop19
      type: user
    createdAt: '2023-12-26T06:38:59.000Z'
    data:
      edited: false
      editors:
      - visionop19
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.925162672996521
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c721f7c2dc5f4867365a4e47a663bf0a.svg
          fullname: chandan c r
          isHf: false
          isPro: false
          name: visionop19
          type: user
        html: '<p>Sorry for the trouble, I am chandan Cr from banglore studying in
          2nd year Ai and ML, I am new to this field and this is my first hackathon
          can u help me how I can use quantazied model </p>

          '
        raw: 'Sorry for the trouble, I am chandan Cr from banglore studying in 2nd
          year Ai and ML, I am new to this field and this is my first hackathon can
          u help me how I can use quantazied model '
        updatedAt: '2023-12-26T06:38:59.658Z'
      numEdits: 0
      reactions: []
    id: 658a75038dd42194870d6f0f
    type: comment
  author: visionop19
  content: 'Sorry for the trouble, I am chandan Cr from banglore studying in 2nd year
    Ai and ML, I am new to this field and this is my first hackathon can u help me
    how I can use quantazied model '
  created_at: 2023-12-26 06:38:59+00:00
  edited: false
  hidden: false
  id: 658a75038dd42194870d6f0f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6423e4a4a05235e2f8d1d978/pA_AKIArOrdw_77fWF38R.jpeg?w=200&h=200&f=face
      fullname: Mohammed Altaf
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Mohammed-Altaf
      type: user
    createdAt: '2023-12-26T07:01:28.000Z'
    data:
      edited: false
      editors:
      - Mohammed-Altaf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6910590529441833
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6423e4a4a05235e2f8d1d978/pA_AKIArOrdw_77fWF38R.jpeg?w=200&h=200&f=face
          fullname: Mohammed Altaf
          isHf: false
          isPro: false
          name: Mohammed-Altaf
          type: user
        html: "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">import</span>\
          \ torch\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"\
          hljs-keyword\">import</span> GPT2LMHeadModel, GPT2Tokenizer\n\n\npath =\
          \ <span class=\"hljs-string\">\"Mohammed-Altaf/medical_chatbot-8bit\"</span>\n\
          device = <span class=\"hljs-string\">\"cuda\"</span> <span class=\"hljs-keyword\"\
          >if</span> torch.cuda.is_available() <span class=\"hljs-keyword\">else</span>\
          \ <span class=\"hljs-string\">\"cpu\"</span>\ntokenizer = GPT2Tokenizer.from_pretrained(path)\n\
          model = GPT2LMHeadModel.from_pretrained(path).to(device)\n\nprompt_input\
          \ = (\n    <span class=\"hljs-string\">\"The conversation between human\
          \ and AI assistant.\\n\"</span>\n    <span class=\"hljs-string\">\"[|Human|]\
          \ {input}\\n\"</span>\n    <span class=\"hljs-string\">\"[|AI|]\"</span>\n\
          )\nsentence = prompt_input.format_map({<span class=\"hljs-string\">'input'</span>:\
          \ <span class=\"hljs-string\">\"what is parkinson's disease?\"</span>})\n\
          inputs = tokenizer(sentence, return_tensors=<span class=\"hljs-string\"\
          >\"pt\"</span>).to(device)\n\n<span class=\"hljs-keyword\">with</span> torch.no_grad():\n\
          \    beam_output = model.generate(**inputs,\n                          \
          \      min_new_tokens=<span class=\"hljs-number\">1</span>, \n         \
          \                       max_length=<span class=\"hljs-number\">512</span>,\n\
          \                                num_beams=<span class=\"hljs-number\">3</span>,\n\
          \                                repetition_penalty=<span class=\"hljs-number\"\
          >1.2</span>,\n                                early_stopping=<span class=\"\
          hljs-literal\">True</span>,\n                                eos_token_id=<span\
          \ class=\"hljs-number\">198</span> \n                                )\n\
          \    <span class=\"hljs-built_in\">print</span>(tokenizer.decode(beam_output[<span\
          \ class=\"hljs-number\">0</span>], skip_special_tokens=<span class=\"hljs-literal\"\
          >True</span>))\n\n</code></pre>\n<ul>\n<li>using above code you can use\
          \ the quantized model just keep changing the <code>sentence</code> variable\
          \ to change the input  from \"what is parkinsons disease\" to anythig you\
          \ want or take the input from the user and add it there that's it. </li>\n\
          <li>Convert the above code into a function and return the decoded value\
          \ from the tokenizer rather than printing it, </li>\n<li>that should solve\
          \ your problem</li>\n</ul>\n"
        raw: "```python\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\n\
          \n\npath = \"Mohammed-Altaf/medical_chatbot-8bit\"\ndevice = \"cuda\" if\
          \ torch.cuda.is_available() else \"cpu\"\ntokenizer = GPT2Tokenizer.from_pretrained(path)\n\
          model = GPT2LMHeadModel.from_pretrained(path).to(device)\n\nprompt_input\
          \ = (\n    \"The conversation between human and AI assistant.\\n\"\n   \
          \ \"[|Human|] {input}\\n\"\n    \"[|AI|]\"\n)\nsentence = prompt_input.format_map({'input':\
          \ \"what is parkinson's disease?\"})\ninputs = tokenizer(sentence, return_tensors=\"\
          pt\").to(device)\n\nwith torch.no_grad():\n    beam_output = model.generate(**inputs,\n\
          \                                min_new_tokens=1, \n                  \
          \              max_length=512,\n                                num_beams=3,\n\
          \                                repetition_penalty=1.2,\n             \
          \                   early_stopping=True,\n                             \
          \   eos_token_id=198 \n                                )\n    print(tokenizer.decode(beam_output[0],\
          \ skip_special_tokens=True))\n\n\n```\n\n* using above code you can use\
          \ the quantized model just keep changing the `sentence` variable to change\
          \ the input  from \"what is parkinsons disease\" to anythig you want or\
          \ take the input from the user and add it there that's it. \n* Convert the\
          \ above code into a function and return the decoded value from the tokenizer\
          \ rather than printing it, \n* that should solve your problem"
        updatedAt: '2023-12-26T07:01:28.670Z'
      numEdits: 0
      reactions: []
    id: 658a7a48991d8e7fb2590ef4
    type: comment
  author: Mohammed-Altaf
  content: "```python\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\n\
    \n\npath = \"Mohammed-Altaf/medical_chatbot-8bit\"\ndevice = \"cuda\" if torch.cuda.is_available()\
    \ else \"cpu\"\ntokenizer = GPT2Tokenizer.from_pretrained(path)\nmodel = GPT2LMHeadModel.from_pretrained(path).to(device)\n\
    \nprompt_input = (\n    \"The conversation between human and AI assistant.\\n\"\
    \n    \"[|Human|] {input}\\n\"\n    \"[|AI|]\"\n)\nsentence = prompt_input.format_map({'input':\
    \ \"what is parkinson's disease?\"})\ninputs = tokenizer(sentence, return_tensors=\"\
    pt\").to(device)\n\nwith torch.no_grad():\n    beam_output = model.generate(**inputs,\n\
    \                                min_new_tokens=1, \n                        \
    \        max_length=512,\n                                num_beams=3,\n     \
    \                           repetition_penalty=1.2,\n                        \
    \        early_stopping=True,\n                                eos_token_id=198\
    \ \n                                )\n    print(tokenizer.decode(beam_output[0],\
    \ skip_special_tokens=True))\n\n\n```\n\n* using above code you can use the quantized\
    \ model just keep changing the `sentence` variable to change the input  from \"\
    what is parkinsons disease\" to anythig you want or take the input from the user\
    \ and add it there that's it. \n* Convert the above code into a function and return\
    \ the decoded value from the tokenizer rather than printing it, \n* that should\
    \ solve your problem"
  created_at: 2023-12-26 07:01:28+00:00
  edited: false
  hidden: false
  id: 658a7a48991d8e7fb2590ef4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c721f7c2dc5f4867365a4e47a663bf0a.svg
      fullname: chandan c r
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: visionop19
      type: user
    createdAt: '2024-01-01T05:17:25.000Z'
    data:
      edited: false
      editors:
      - visionop19
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.826454758644104
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c721f7c2dc5f4867365a4e47a663bf0a.svg
          fullname: chandan c r
          isHf: false
          isPro: false
          name: visionop19
          type: user
        html: '<p>Is there any social media where I can contact youuu</p>

          '
        raw: Is there any social media where I can contact youuu
        updatedAt: '2024-01-01T05:17:25.882Z'
      numEdits: 0
      reactions: []
    id: 65924ae535331883758170cf
    type: comment
  author: visionop19
  content: Is there any social media where I can contact youuu
  created_at: 2024-01-01 05:17:25+00:00
  edited: false
  hidden: false
  id: 65924ae535331883758170cf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c721f7c2dc5f4867365a4e47a663bf0a.svg
      fullname: chandan c r
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: visionop19
      type: user
    createdAt: '2024-01-03T05:06:49.000Z'
    data:
      edited: false
      editors:
      - visionop19
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8223117589950562
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c721f7c2dc5f4867365a4e47a663bf0a.svg
          fullname: chandan c r
          isHf: false
          isPro: false
          name: visionop19
          type: user
        html: '<p>I am getting error while reading your json file on line 1 itself
          expecting a eof '',''</p>

          '
        raw: I am getting error while reading your json file on line 1 itself expecting
          a eof ','
        updatedAt: '2024-01-03T05:06:49.187Z'
      numEdits: 0
      reactions: []
    id: 6594eb693e72d14e4d9cc59b
    type: comment
  author: visionop19
  content: I am getting error while reading your json file on line 1 itself expecting
    a eof ','
  created_at: 2024-01-03 05:06:49+00:00
  edited: false
  hidden: false
  id: 6594eb693e72d14e4d9cc59b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Mohammed-Altaf/Medical-ChatBot
repo_type: model
status: open
target_branch: null
title: Douts
