!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BlueNipples
conflicting_files: null
created_at: 2023-09-21 15:39:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
      fullname: Matthew Andrews
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BlueNipples
      type: user
    createdAt: '2023-09-21T16:39:24.000Z'
    data:
      edited: false
      editors:
      - BlueNipples
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9560306668281555
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
          fullname: Matthew Andrews
          isHf: false
          isPro: false
          name: BlueNipples
          type: user
        html: '<p>I know it might be a lot to ask of a complete stranger, but it would
          be incredible to see models like this (Airolima-Chronos-Grad-L2), or Stheno-L2-13B,
          zararp-1.1-l2-7b, or mythomax 13b compiled for mlc-llm (vulkan) - those
          are just models I''ve tested and are all great prose/coherency for roleplay.
          Just like a handful of top models in this format would freshen up their
          currently tired selection which is largely just instruct and coding. Just
          1 13b and 1 7b would be incredible!</p>

          <p>Apparently MLC LLM can inference very fast but the issue is you need
          to compile the models and that requires a whole bunch of RAM for the job
          which tends to be beyond the capability of those who can run the models.
          Please ignore me if you wish ofc. Thanks for your great work!</p>

          '
        raw: "I know it might be a lot to ask of a complete stranger, but it would\
          \ be incredible to see models like this (Airolima-Chronos-Grad-L2), or Stheno-L2-13B,\
          \ zararp-1.1-l2-7b, or mythomax 13b compiled for mlc-llm (vulkan) - those\
          \ are just models I've tested and are all great prose/coherency for roleplay.\
          \ Just like a handful of top models in this format would freshen up their\
          \ currently tired selection which is largely just instruct and coding. Just\
          \ 1 13b and 1 7b would be incredible!\r\n\r\nApparently MLC LLM can inference\
          \ very fast but the issue is you need to compile the models and that requires\
          \ a whole bunch of RAM for the job which tends to be beyond the capability\
          \ of those who can run the models. Please ignore me if you wish ofc. Thanks\
          \ for your great work!"
        updatedAt: '2023-09-21T16:39:24.287Z'
      numEdits: 0
      reactions: []
    id: 650c71bcaeb45e887b409aa3
    type: comment
  author: BlueNipples
  content: "I know it might be a lot to ask of a complete stranger, but it would be\
    \ incredible to see models like this (Airolima-Chronos-Grad-L2), or Stheno-L2-13B,\
    \ zararp-1.1-l2-7b, or mythomax 13b compiled for mlc-llm (vulkan) - those are\
    \ just models I've tested and are all great prose/coherency for roleplay. Just\
    \ like a handful of top models in this format would freshen up their currently\
    \ tired selection which is largely just instruct and coding. Just 1 13b and 1\
    \ 7b would be incredible!\r\n\r\nApparently MLC LLM can inference very fast but\
    \ the issue is you need to compile the models and that requires a whole bunch\
    \ of RAM for the job which tends to be beyond the capability of those who can\
    \ run the models. Please ignore me if you wish ofc. Thanks for your great work!"
  created_at: 2023-09-21 15:39:24+00:00
  edited: false
  hidden: false
  id: 650c71bcaeb45e887b409aa3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Airolima-Chronos-Grad-L2-13B-GGUF
repo_type: model
status: open
target_branch: null
title: MLC LLM?
