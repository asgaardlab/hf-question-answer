!!python/object:huggingface_hub.community.DiscussionWithDetails
author: zappa2005
conflicting_files: null
created_at: 2024-01-19 11:54:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/302fb28d27b64624c37c6755526f9d6f.svg
      fullname: Zappa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zappa2005
      type: user
    createdAt: '2024-01-19T11:54:06.000Z'
    data:
      edited: false
      editors:
      - zappa2005
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9506082534790039
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/302fb28d27b64624c37c6755526f9d6f.svg
          fullname: Zappa
          isHf: false
          isPro: false
          name: zappa2005
          type: user
        html: '<p>I couldn''t find this information in the model page, hence the question:
          Did you base on v0.1 or v0.2?</p>

          <p>I read somewhere that the v0.1 uses a context extension method SWA (sliding-window
          attention) which was not working well in some cases, so they changed that
          in v0.2.</p>

          <p>I guess I read it here, but I''m not sure - it was late. Thank you!<br><a
          rel="nofollow" href="https://www.reddit.com/r/LocalLLaMA/comments/18k0fek/psa_you_can_and_may_want_to_disable_mixtrals/">https://www.reddit.com/r/LocalLLaMA/comments/18k0fek/psa_you_can_and_may_want_to_disable_mixtrals/</a></p>

          '
        raw: "I couldn't find this information in the model page, hence the question:\
          \ Did you base on v0.1 or v0.2?\r\n\r\nI read somewhere that the v0.1 uses\
          \ a context extension method SWA (sliding-window attention) which was not\
          \ working well in some cases, so they changed that in v0.2.\r\n\r\nI guess\
          \ I read it here, but I'm not sure - it was late. Thank you!\r\nhttps://www.reddit.com/r/LocalLLaMA/comments/18k0fek/psa_you_can_and_may_want_to_disable_mixtrals/\r\
          \n"
        updatedAt: '2024-01-19T11:54:06.511Z'
      numEdits: 0
      reactions: []
    id: 65aa62deb0b08767905b46e5
    type: comment
  author: zappa2005
  content: "I couldn't find this information in the model page, hence the question:\
    \ Did you base on v0.1 or v0.2?\r\n\r\nI read somewhere that the v0.1 uses a context\
    \ extension method SWA (sliding-window attention) which was not working well in\
    \ some cases, so they changed that in v0.2.\r\n\r\nI guess I read it here, but\
    \ I'm not sure - it was late. Thank you!\r\nhttps://www.reddit.com/r/LocalLLaMA/comments/18k0fek/psa_you_can_and_may_want_to_disable_mixtrals/\r\
    \n"
  created_at: 2024-01-19 11:54:06+00:00
  edited: false
  hidden: false
  id: 65aa62deb0b08767905b46e5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667690511692-630dfb008df86f1e5becadc3.png?w=200&h=200&f=face
      fullname: IkariDev
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: IkariDev
      type: user
    createdAt: '2024-01-19T12:32:02.000Z'
    data:
      edited: false
      editors:
      - IkariDev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8200103044509888
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667690511692-630dfb008df86f1e5becadc3.png?w=200&h=200&f=face
          fullname: IkariDev
          isHf: false
          isPro: false
          name: IkariDev
          type: user
        html: '<p>what? this is Mixtral-8x7B-Instruct-v0.1, not Mistral-7B-Instruct-v0.2,
          this is a mixtral model, there is no 0.2 instruct for mixtral</p>

          '
        raw: what? this is Mixtral-8x7B-Instruct-v0.1, not Mistral-7B-Instruct-v0.2,
          this is a mixtral model, there is no 0.2 instruct for mixtral
        updatedAt: '2024-01-19T12:32:02.414Z'
      numEdits: 0
      reactions: []
    id: 65aa6bc2e0ee7990a62823bf
    type: comment
  author: IkariDev
  content: what? this is Mixtral-8x7B-Instruct-v0.1, not Mistral-7B-Instruct-v0.2,
    this is a mixtral model, there is no 0.2 instruct for mixtral
  created_at: 2024-01-19 12:32:02+00:00
  edited: false
  hidden: false
  id: 65aa6bc2e0ee7990a62823bf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667690511692-630dfb008df86f1e5becadc3.png?w=200&h=200&f=face
      fullname: IkariDev
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: IkariDev
      type: user
    createdAt: '2024-01-19T12:32:04.000Z'
    data:
      status: closed
    id: 65aa6bc4ac588f2a1ce9b4ae
    type: status-change
  author: IkariDev
  created_at: 2024-01-19 12:32:04+00:00
  id: 65aa6bc4ac588f2a1ce9b4ae
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: NeverSleep/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss
repo_type: model
status: closed
target_branch: null
title: Instruct-v0.1 or Instruct-v0.2 based?
