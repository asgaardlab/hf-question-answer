!!python/object:huggingface_hub.community.DiscussionWithDetails
author: abhimortal6
conflicting_files: null
created_at: 2023-06-04 19:28:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bcd4417407bdf732a8c6ead79ba9b904.svg
      fullname: ' Abhi Tripathi'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhimortal6
      type: user
    createdAt: '2023-06-04T20:28:19.000Z'
    data:
      edited: false
      editors:
      - abhimortal6
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.542107105255127
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bcd4417407bdf732a8c6ead79ba9b904.svg
          fullname: ' Abhi Tripathi'
          isHf: false
          isPro: false
          name: abhimortal6
          type: user
        html: '<p>Tried in oobabooga web_ui, not usable in my case<br>3060ti 8GB VRAM,
          24GB RAM</p>

          <p>Output is weird it never returns the code. </p>

          <pre><code>Output generated in 27.06 seconds (0.30 tokens/s, 8 tokens, context
          63, seed 1191894163)

          Output generated in 66.12 seconds (0.47 tokens/s, 31 tokens, context 80,
          seed 1706855517)

          Output generated in 386.01 seconds (0.04 tokens/s, 16 tokens, context 131,
          seed 1791131008)

          Output generated in 50.16 seconds (0.48 tokens/s, 24 tokens, context 118,
          seed 1161001351)

          Output generated in 23.89 seconds (0.04 tokens/s, 1 tokens, context 150,
          seed 1752912455)

          Output generated in 202.32 seconds (0.05 tokens/s, 10 tokens, context 169,
          seed 1726966570)

          </code></pre>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/647c99b5adaf5cc26da67cad/Vxm0maJsP4SuhBAQRZIqd.png"><img
          alt="Screenshot 2023-06-05 014426.png" src="https://cdn-uploads.huggingface.co/production/uploads/647c99b5adaf5cc26da67cad/Vxm0maJsP4SuhBAQRZIqd.png"></a></p>

          '
        raw: "Tried in oobabooga web_ui, not usable in my case \r\n3060ti 8GB VRAM,\
          \ 24GB RAM\r\n\r\nOutput is weird it never returns the code. \r\n\r\n```\r\
          \nOutput generated in 27.06 seconds (0.30 tokens/s, 8 tokens, context 63,\
          \ seed 1191894163)\r\nOutput generated in 66.12 seconds (0.47 tokens/s,\
          \ 31 tokens, context 80, seed 1706855517)\r\nOutput generated in 386.01\
          \ seconds (0.04 tokens/s, 16 tokens, context 131, seed 1791131008)\r\nOutput\
          \ generated in 50.16 seconds (0.48 tokens/s, 24 tokens, context 118, seed\
          \ 1161001351)\r\nOutput generated in 23.89 seconds (0.04 tokens/s, 1 tokens,\
          \ context 150, seed 1752912455)\r\nOutput generated in 202.32 seconds (0.05\
          \ tokens/s, 10 tokens, context 169, seed 1726966570)\r\n```\r\n\r\n![Screenshot\
          \ 2023-06-05 014426.png](https://cdn-uploads.huggingface.co/production/uploads/647c99b5adaf5cc26da67cad/Vxm0maJsP4SuhBAQRZIqd.png)\r\
          \n\r\n"
        updatedAt: '2023-06-04T20:28:19.967Z'
      numEdits: 0
      reactions: []
    id: 647cf3e3adaf5cc26da8a808
    type: comment
  author: abhimortal6
  content: "Tried in oobabooga web_ui, not usable in my case \r\n3060ti 8GB VRAM,\
    \ 24GB RAM\r\n\r\nOutput is weird it never returns the code. \r\n\r\n```\r\nOutput\
    \ generated in 27.06 seconds (0.30 tokens/s, 8 tokens, context 63, seed 1191894163)\r\
    \nOutput generated in 66.12 seconds (0.47 tokens/s, 31 tokens, context 80, seed\
    \ 1706855517)\r\nOutput generated in 386.01 seconds (0.04 tokens/s, 16 tokens,\
    \ context 131, seed 1791131008)\r\nOutput generated in 50.16 seconds (0.48 tokens/s,\
    \ 24 tokens, context 118, seed 1161001351)\r\nOutput generated in 23.89 seconds\
    \ (0.04 tokens/s, 1 tokens, context 150, seed 1752912455)\r\nOutput generated\
    \ in 202.32 seconds (0.05 tokens/s, 10 tokens, context 169, seed 1726966570)\r\
    \n```\r\n\r\n![Screenshot 2023-06-05 014426.png](https://cdn-uploads.huggingface.co/production/uploads/647c99b5adaf5cc26da67cad/Vxm0maJsP4SuhBAQRZIqd.png)\r\
    \n\r\n"
  created_at: 2023-06-04 19:28:19+00:00
  edited: false
  hidden: false
  id: 647cf3e3adaf5cc26da8a808
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7a0e893f40edfc28592a63dc34dffdfe.svg
      fullname: nico radu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nicopara
      type: user
    createdAt: '2023-06-05T19:18:00.000Z'
    data:
      edited: false
      editors:
      - Nicopara
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9813534021377563
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7a0e893f40edfc28592a63dc34dffdfe.svg
          fullname: nico radu
          isHf: false
          isPro: false
          name: Nicopara
          type: user
        html: '<p>This is a quantitized 15b model. Also, how did you get it to run?</p>

          '
        raw: This is a quantitized 15b model. Also, how did you get it to run?
        updatedAt: '2023-06-05T19:18:00.740Z'
      numEdits: 0
      reactions: []
    id: 647e34e85214d172cbc31d49
    type: comment
  author: Nicopara
  content: This is a quantitized 15b model. Also, how did you get it to run?
  created_at: 2023-06-05 18:18:00+00:00
  edited: false
  hidden: false
  id: 647e34e85214d172cbc31d49
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bcd4417407bdf732a8c6ead79ba9b904.svg
      fullname: ' Abhi Tripathi'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhimortal6
      type: user
    createdAt: '2023-06-06T19:11:55.000Z'
    data:
      edited: false
      editors:
      - abhimortal6
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9088278412818909
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bcd4417407bdf732a8c6ead79ba9b904.svg
          fullname: ' Abhi Tripathi'
          isHf: false
          isPro: false
          name: abhimortal6
          type: user
        html: '<blockquote>

          <p>This is a quantitized 15b model. Also, how did you get it to run?</p>

          </blockquote>

          <p>Sure title says so, quality is decreased marginally though. To run in
          webui use configs from -&gt;<br><a href="https://huggingface.co/ShipItMind/starcoder-gptq-4bit-128g">https://huggingface.co/ShipItMind/starcoder-gptq-4bit-128g</a></p>

          '
        raw: '> This is a quantitized 15b model. Also, how did you get it to run?


          Sure title says so, quality is decreased marginally though. To run in webui
          use configs from ->

          https://huggingface.co/ShipItMind/starcoder-gptq-4bit-128g'
        updatedAt: '2023-06-06T19:11:55.057Z'
      numEdits: 0
      reactions: []
    id: 647f84fb9c31024457ab6bb4
    type: comment
  author: abhimortal6
  content: '> This is a quantitized 15b model. Also, how did you get it to run?


    Sure title says so, quality is decreased marginally though. To run in webui use
    configs from ->

    https://huggingface.co/ShipItMind/starcoder-gptq-4bit-128g'
  created_at: 2023-06-06 18:11:55+00:00
  edited: false
  hidden: false
  id: 647f84fb9c31024457ab6bb4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62cd5057674cdb524450093d/Kc2vqHdAc96lAJjkLf1gB.jpeg?w=200&h=200&f=face
      fullname: Mayank Mishra
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: mayank31398
      type: user
    createdAt: '2023-06-07T17:40:07.000Z'
    data:
      edited: false
      editors:
      - mayank31398
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9698621034622192
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62cd5057674cdb524450093d/Kc2vqHdAc96lAJjkLf1gB.jpeg?w=200&h=200&f=face
          fullname: Mayank Mishra
          isHf: false
          isPro: false
          name: mayank31398
          type: user
        html: '<p>hey, just pushed some new fixes.<br>Can you give those a try?</p>

          '
        raw: 'hey, just pushed some new fixes.

          Can you give those a try?'
        updatedAt: '2023-06-07T17:40:07.034Z'
      numEdits: 0
      reactions: []
    id: 6480c0f740facadc55719d63
    type: comment
  author: mayank31398
  content: 'hey, just pushed some new fixes.

    Can you give those a try?'
  created_at: 2023-06-07 16:40:07+00:00
  edited: false
  hidden: false
  id: 6480c0f740facadc55719d63
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bcd4417407bdf732a8c6ead79ba9b904.svg
      fullname: ' Abhi Tripathi'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhimortal6
      type: user
    createdAt: '2023-06-11T19:54:35.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/bcd4417407bdf732a8c6ead79ba9b904.svg
          fullname: ' Abhi Tripathi'
          isHf: false
          isPro: false
          name: abhimortal6
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-06-11T19:55:58.065Z'
      numEdits: 0
      reactions: []
    id: 6486267b10300f65298ca3a1
    type: comment
  author: abhimortal6
  content: This comment has been hidden
  created_at: 2023-06-11 18:54:35+00:00
  edited: true
  hidden: true
  id: 6486267b10300f65298ca3a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bcd4417407bdf732a8c6ead79ba9b904.svg
      fullname: ' Abhi Tripathi'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhimortal6
      type: user
    createdAt: '2023-06-11T19:56:36.000Z'
    data:
      edited: false
      editors:
      - abhimortal6
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7715741991996765
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bcd4417407bdf732a8c6ead79ba9b904.svg
          fullname: ' Abhi Tripathi'
          isHf: false
          isPro: false
          name: abhimortal6
          type: user
        html: '<p>Sorry but where are the updated files? current repo showing last
          updated month ago</p>

          '
        raw: Sorry but where are the updated files? current repo showing last updated
          month ago
        updatedAt: '2023-06-11T19:56:36.256Z'
      numEdits: 0
      reactions: []
    id: 648626f4179334702a991d3a
    type: comment
  author: abhimortal6
  content: Sorry but where are the updated files? current repo showing last updated
    month ago
  created_at: 2023-06-11 18:56:36+00:00
  edited: false
  hidden: false
  id: 648626f4179334702a991d3a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62cd5057674cdb524450093d/Kc2vqHdAc96lAJjkLf1gB.jpeg?w=200&h=200&f=face
      fullname: Mayank Mishra
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: mayank31398
      type: user
    createdAt: '2023-06-11T23:37:51.000Z'
    data:
      edited: false
      editors:
      - mayank31398
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8346510529518127
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62cd5057674cdb524450093d/Kc2vqHdAc96lAJjkLf1gB.jpeg?w=200&h=200&f=face
          fullname: Mayank Mishra
          isHf: false
          isPro: false
          name: mayank31398
          type: user
        html: '<p>the fixes are in the repo: <a rel="nofollow" href="https://github.com/mayank31398/GPTQ-for-SantaCoder">https://github.com/mayank31398/GPTQ-for-SantaCoder</a><br>The
          weights are same.</p>

          '
        raw: 'the fixes are in the repo: https://github.com/mayank31398/GPTQ-for-SantaCoder

          The weights are same.'
        updatedAt: '2023-06-11T23:37:51.649Z'
      numEdits: 0
      reactions: []
    id: 64865acf60b30c3615c36389
    type: comment
  author: mayank31398
  content: 'the fixes are in the repo: https://github.com/mayank31398/GPTQ-for-SantaCoder

    The weights are same.'
  created_at: 2023-06-11 22:37:51+00:00
  edited: false
  hidden: false
  id: 64865acf60b30c3615c36389
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bcd4417407bdf732a8c6ead79ba9b904.svg
      fullname: ' Abhi Tripathi'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhimortal6
      type: user
    createdAt: '2023-06-14T16:01:44.000Z'
    data:
      edited: true
      editors:
      - abhimortal6
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.38155895471572876
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bcd4417407bdf732a8c6ead79ba9b904.svg
          fullname: ' Abhi Tripathi'
          isHf: false
          isPro: false
          name: abhimortal6
          type: user
        html: "<p>OOM<br>3060ti 8GB VRAM, 24GB RAM</p>\n<pre><code> python -m santacoder_inference\
          \ bigcode/starcoder --wbits 4 --groupsize 128 --load starcoder-GPTQ-4bit-128g/model.pt\n\
          Traceback (most recent call last):\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/runpy.py\"\
          , line 197, in _run_module_as_main\n    return _run_code(code, main_globals,\
          \ None,\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/runpy.py\"\
          , line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/abhi/Documents/starcoder/GPTQ-for-SantaCoder/santacoder_inference.py\"\
          , line 96, in &lt;module&gt;\n    main()\n  File \"/home/abhi/Documents/starcoder/GPTQ-for-SantaCoder/santacoder_inference.py\"\
          , line 86, in main\n    model = get_santacoder(args.model, args.load, args.wbits,\
          \ args.groupsize)\n  File \"/home/abhi/Documents/starcoder/GPTQ-for-SantaCoder/santacoder_inference.py\"\
          , line 49, in get_santacoder\n    model = model.cuda()\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 905, in cuda\n    return self._apply(lambda t: t.cuda(device))\n\
          \  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 797, in _apply\n    module._apply(fn)\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 797, in _apply\n    module._apply(fn)\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 797, in _apply\n    module._apply(fn)\n  [Previous line repeated\
          \ 2 more times]\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 844, in _apply\n    self._buffers[key] = fn(buf)\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 905, in &lt;lambda&gt;\n    return self._apply(lambda t: t.cuda(device))\n\
          torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 72.00\
          \ MiB (GPU 0; 7.78 GiB total capacity; 6.68 GiB already allocated; 75.31\
          \ MiB free; 6.74 GiB reserved in total by PyTorch) If reserved memory is\
          \ &gt;&gt; allocated memory try setting max_split_size_mb to avoid fragmentation.\
          \  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\
          </code></pre>\n"
        raw: "OOM \n3060ti 8GB VRAM, 24GB RAM\n\n\n\n```\n python -m santacoder_inference\
          \ bigcode/starcoder --wbits 4 --groupsize 128 --load starcoder-GPTQ-4bit-128g/model.pt\n\
          Traceback (most recent call last):\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/runpy.py\"\
          , line 197, in _run_module_as_main\n    return _run_code(code, main_globals,\
          \ None,\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/runpy.py\"\
          , line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/abhi/Documents/starcoder/GPTQ-for-SantaCoder/santacoder_inference.py\"\
          , line 96, in <module>\n    main()\n  File \"/home/abhi/Documents/starcoder/GPTQ-for-SantaCoder/santacoder_inference.py\"\
          , line 86, in main\n    model = get_santacoder(args.model, args.load, args.wbits,\
          \ args.groupsize)\n  File \"/home/abhi/Documents/starcoder/GPTQ-for-SantaCoder/santacoder_inference.py\"\
          , line 49, in get_santacoder\n    model = model.cuda()\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 905, in cuda\n    return self._apply(lambda t: t.cuda(device))\n\
          \  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 797, in _apply\n    module._apply(fn)\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 797, in _apply\n    module._apply(fn)\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 797, in _apply\n    module._apply(fn)\n  [Previous line repeated\
          \ 2 more times]\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 844, in _apply\n    self._buffers[key] = fn(buf)\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 905, in <lambda>\n    return self._apply(lambda t: t.cuda(device))\n\
          torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 72.00\
          \ MiB (GPU 0; 7.78 GiB total capacity; 6.68 GiB already allocated; 75.31\
          \ MiB free; 6.74 GiB reserved in total by PyTorch) If reserved memory is\
          \ >> allocated memory try setting max_split_size_mb to avoid fragmentation.\
          \  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\
          \n```"
        updatedAt: '2023-06-14T16:02:18.856Z'
      numEdits: 1
      reactions: []
    id: 6489e4684344b9f97db39f74
    type: comment
  author: abhimortal6
  content: "OOM \n3060ti 8GB VRAM, 24GB RAM\n\n\n\n```\n python -m santacoder_inference\
    \ bigcode/starcoder --wbits 4 --groupsize 128 --load starcoder-GPTQ-4bit-128g/model.pt\n\
    Traceback (most recent call last):\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/runpy.py\"\
    , line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n\
    \  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/runpy.py\", line 87, in\
    \ _run_code\n    exec(code, run_globals)\n  File \"/home/abhi/Documents/starcoder/GPTQ-for-SantaCoder/santacoder_inference.py\"\
    , line 96, in <module>\n    main()\n  File \"/home/abhi/Documents/starcoder/GPTQ-for-SantaCoder/santacoder_inference.py\"\
    , line 86, in main\n    model = get_santacoder(args.model, args.load, args.wbits,\
    \ args.groupsize)\n  File \"/home/abhi/Documents/starcoder/GPTQ-for-SantaCoder/santacoder_inference.py\"\
    , line 49, in get_santacoder\n    model = model.cuda()\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 905, in cuda\n    return self._apply(lambda t: t.cuda(device))\n  File\
    \ \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 797, in _apply\n    module._apply(fn)\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 797, in _apply\n    module._apply(fn)\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 797, in _apply\n    module._apply(fn)\n  [Previous line repeated 2 more\
    \ times]\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 844, in _apply\n    self._buffers[key] = fn(buf)\n  File \"/home/abhi/miniconda3/envs/gptq/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 905, in <lambda>\n    return self._apply(lambda t: t.cuda(device))\ntorch.cuda.OutOfMemoryError:\
    \ CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 7.78 GiB total capacity;\
    \ 6.68 GiB already allocated; 75.31 MiB free; 6.74 GiB reserved in total by PyTorch)\
    \ If reserved memory is >> allocated memory try setting max_split_size_mb to avoid\
    \ fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\
    \n```"
  created_at: 2023-06-14 15:01:44+00:00
  edited: true
  hidden: false
  id: 6489e4684344b9f97db39f74
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62cd5057674cdb524450093d/Kc2vqHdAc96lAJjkLf1gB.jpeg?w=200&h=200&f=face
      fullname: Mayank Mishra
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: mayank31398
      type: user
    createdAt: '2023-06-14T20:23:38.000Z'
    data:
      edited: false
      editors:
      - mayank31398
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9910731315612793
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62cd5057674cdb524450093d/Kc2vqHdAc96lAJjkLf1gB.jpeg?w=200&h=200&f=face
          fullname: Mayank Mishra
          isHf: false
          isPro: false
          name: mayank31398
          type: user
        html: '<p>yeah, its not supposed to work with 3060ti.</p>

          '
        raw: yeah, its not supposed to work with 3060ti.
        updatedAt: '2023-06-14T20:23:38.683Z'
      numEdits: 0
      reactions: []
    id: 648a21ca02c8497f58eefada
    type: comment
  author: mayank31398
  content: yeah, its not supposed to work with 3060ti.
  created_at: 2023-06-14 19:23:38+00:00
  edited: false
  hidden: false
  id: 648a21ca02c8497f58eefada
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bcd4417407bdf732a8c6ead79ba9b904.svg
      fullname: ' Abhi Tripathi'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhimortal6
      type: user
    createdAt: '2023-06-15T11:08:13.000Z'
    data:
      edited: false
      editors:
      - abhimortal6
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9666559100151062
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bcd4417407bdf732a8c6ead79ba9b904.svg
          fullname: ' Abhi Tripathi'
          isHf: false
          isPro: false
          name: abhimortal6
          type: user
        html: '<p>alright, closing. </p>

          '
        raw: 'alright, closing. '
        updatedAt: '2023-06-15T11:08:13.773Z'
      numEdits: 0
      reactions: []
      relatedEventId: 648af11dbac07d4ab2a2e688
    id: 648af11dbac07d4ab2a2e681
    type: comment
  author: abhimortal6
  content: 'alright, closing. '
  created_at: 2023-06-15 10:08:13+00:00
  edited: false
  hidden: false
  id: 648af11dbac07d4ab2a2e681
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/bcd4417407bdf732a8c6ead79ba9b904.svg
      fullname: ' Abhi Tripathi'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhimortal6
      type: user
    createdAt: '2023-06-15T11:08:13.000Z'
    data:
      status: closed
    id: 648af11dbac07d4ab2a2e688
    type: status-change
  author: abhimortal6
  created_at: 2023-06-15 10:08:13+00:00
  id: 648af11dbac07d4ab2a2e688
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: mayank31398/starcoder-GPTQ-4bit-128g
repo_type: model
status: closed
target_branch: null
title: 'extreme slowdown and weird output. '
