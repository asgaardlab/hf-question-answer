!!python/object:huggingface_hub.community.DiscussionWithDetails
author: GamingDaveUK
conflicting_files: null
created_at: 2023-05-12 13:31:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/87695e1fdec40517ac6506c6a9f3521a.svg
      fullname: David
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: GamingDaveUK
      type: user
    createdAt: '2023-05-12T14:31:34.000Z'
    data:
      edited: false
      editors:
      - GamingDaveUK
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/87695e1fdec40517ac6506c6a9f3521a.svg
          fullname: David
          isHf: false
          isPro: false
          name: GamingDaveUK
          type: user
        html: "<p>Tried and i get an error that its missing a config file:<br>Traceback\
          \ (most recent call last):<br>File \u201CF:\\oobabooga_windows\\text-generation-webui\\\
          server.py\u201D, line 67, in load_model_wrapper<br>shared.model, shared.tokenizer\
          \ = load_model(shared.model_name)<br>File \u201CF:\\oobabooga_windows\\\
          text-generation-webui\\modules\\models.py\u201D, line 74, in load_model<br>shared.model_type\
          \ = find_model_type(model_name)<br>File \u201CF:\\oobabooga_windows\\text-generation-webui\\\
          modules\\models.py\u201D, line 62, in find_model_type<br>config = AutoConfig.from_pretrained(Path(f\u2019\
          {shared.args.model_dir}/{model_name}'), trust_remote_code=shared.args.trust_remote_code)<br>File\
          \ \u201CF:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
          transformers\\models\\auto\\configuration_auto.py\u201D, line 916, in from_pretrained<br>config_dict,\
          \ unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path,\
          \ **kwargs)<br>File \u201CF:\\oobabooga_windows\\installer_files\\env\\\
          lib\\site-packages\\transformers\\configuration_utils.py\u201D, line 573,\
          \ in get_config_dict<br>config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path,\
          \ **kwargs)<br>File \u201CF:\\oobabooga_windows\\installer_files\\env\\\
          lib\\site-packages\\transformers\\configuration_utils.py\u201D, line 628,\
          \ in _get_config_dict<br>resolved_config_file = cached_file(<br>File \u201C\
          F:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\transformers\\\
          utils\\hub.py\u201D, line 380, in cached_file<br>raise EnvironmentError(<br>OSError:\
          \ models\\mayank31398_starcoder-GPTQ-4bit-128g does not appear to have a\
          \ file named config.json. Checkout \u2018<a href=\"https://huggingface.co/models%5Cmayank31398_starcoder-GPTQ-4bit-128g/None%E2%80%99\"\
          >https://huggingface.co/models\\mayank31398_starcoder-GPTQ-4bit-128g/None\u2019\
          </a> for available files.</p>\n"
        raw: "Tried and i get an error that its missing a config file:\r\nTraceback\
          \ (most recent call last):\r\nFile \u201CF:\\oobabooga_windows\\text-generation-webui\\\
          server.py\u201D, line 67, in load_model_wrapper\r\nshared.model, shared.tokenizer\
          \ = load_model(shared.model_name)\r\nFile \u201CF:\\oobabooga_windows\\\
          text-generation-webui\\modules\\models.py\u201D, line 74, in load_model\r\
          \nshared.model_type = find_model_type(model_name)\r\nFile \u201CF:\\oobabooga_windows\\\
          text-generation-webui\\modules\\models.py\u201D, line 62, in find_model_type\r\
          \nconfig = AutoConfig.from_pretrained(Path(f\u2019{shared.args.model_dir}/{model_name}'),\
          \ trust_remote_code=shared.args.trust_remote_code)\r\nFile \u201CF:\\oobabooga_windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\u201D\
          , line 916, in from_pretrained\r\nconfig_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path,\
          \ **kwargs)\r\nFile \u201CF:\\oobabooga_windows\\installer_files\\env\\\
          lib\\site-packages\\transformers\\configuration_utils.py\u201D, line 573,\
          \ in get_config_dict\r\nconfig_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path,\
          \ **kwargs)\r\nFile \u201CF:\\oobabooga_windows\\installer_files\\env\\\
          lib\\site-packages\\transformers\\configuration_utils.py\u201D, line 628,\
          \ in _get_config_dict\r\nresolved_config_file = cached_file(\r\nFile \u201C\
          F:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\transformers\\\
          utils\\hub.py\u201D, line 380, in cached_file\r\nraise EnvironmentError(\r\
          \nOSError: models\\mayank31398_starcoder-GPTQ-4bit-128g does not appear\
          \ to have a file named config.json. Checkout \u2018https://huggingface.co/models\\\
          mayank31398_starcoder-GPTQ-4bit-128g/None\u2019 for available files.\r\n\
          \r\n"
        updatedAt: '2023-05-12T14:31:34.515Z'
      numEdits: 0
      reactions: []
    id: 645e4dc659bea2e5c3b6dd1e
    type: comment
  author: GamingDaveUK
  content: "Tried and i get an error that its missing a config file:\r\nTraceback\
    \ (most recent call last):\r\nFile \u201CF:\\oobabooga_windows\\text-generation-webui\\\
    server.py\u201D, line 67, in load_model_wrapper\r\nshared.model, shared.tokenizer\
    \ = load_model(shared.model_name)\r\nFile \u201CF:\\oobabooga_windows\\text-generation-webui\\\
    modules\\models.py\u201D, line 74, in load_model\r\nshared.model_type = find_model_type(model_name)\r\
    \nFile \u201CF:\\oobabooga_windows\\text-generation-webui\\modules\\models.py\u201D\
    , line 62, in find_model_type\r\nconfig = AutoConfig.from_pretrained(Path(f\u2019\
    {shared.args.model_dir}/{model_name}'), trust_remote_code=shared.args.trust_remote_code)\r\
    \nFile \u201CF:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\models\\auto\\configuration_auto.py\u201D, line 916, in from_pretrained\r\
    \nconfig_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path,\
    \ **kwargs)\r\nFile \u201CF:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\configuration_utils.py\u201D, line 573, in get_config_dict\r\nconfig_dict,\
    \ kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\r\nFile\
    \ \u201CF:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\transformers\\\
    configuration_utils.py\u201D, line 628, in _get_config_dict\r\nresolved_config_file\
    \ = cached_file(\r\nFile \u201CF:\\oobabooga_windows\\installer_files\\env\\lib\\\
    site-packages\\transformers\\utils\\hub.py\u201D, line 380, in cached_file\r\n\
    raise EnvironmentError(\r\nOSError: models\\mayank31398_starcoder-GPTQ-4bit-128g\
    \ does not appear to have a file named config.json. Checkout \u2018https://huggingface.co/models\\\
    mayank31398_starcoder-GPTQ-4bit-128g/None\u2019 for available files.\r\n\r\n"
  created_at: 2023-05-12 13:31:34+00:00
  edited: false
  hidden: false
  id: 645e4dc659bea2e5c3b6dd1e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/db1b09e9d490556f7279ff0b3d8032a3.svg
      fullname: Yossi Cohen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cojosef96
      type: user
    createdAt: '2023-05-12T16:15:04.000Z'
    data:
      edited: false
      editors:
      - cojosef96
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/db1b09e9d490556f7279ff0b3d8032a3.svg
          fullname: Yossi Cohen
          isHf: false
          isPro: false
          name: cojosef96
          type: user
        html: "<p>hey <span data-props=\"{&quot;user&quot;:&quot;GamingDaveUK&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/GamingDaveUK\"\
          >@<span class=\"underline\">GamingDaveUK</span></a></span>\n\n\t</span></span>,<br>you\
          \ need to copy all the files from the original starcoder model (except from\
          \ the model files .bin)<br>and copy them to the directory of this model,\
          \ then it will work for you, but I cant make it to work properly,<br>I think\
          \ we need to send the correct configuration for the input the model expect\
          \ to recieve.</p>\n"
        raw: 'hey @GamingDaveUK,

          you need to copy all the files from the original starcoder model (except
          from the model files .bin)

          and copy them to the directory of this model, then it will work for you,
          but I cant make it to work properly,

          I think we need to send the correct configuration for the input the model
          expect to recieve.'
        updatedAt: '2023-05-12T16:15:04.808Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - bluesongcurls
        - Nicopara
    id: 645e66085f8408a151fdab2c
    type: comment
  author: cojosef96
  content: 'hey @GamingDaveUK,

    you need to copy all the files from the original starcoder model (except from
    the model files .bin)

    and copy them to the directory of this model, then it will work for you, but I
    cant make it to work properly,

    I think we need to send the correct configuration for the input the model expect
    to recieve.'
  created_at: 2023-05-12 15:15:04+00:00
  edited: false
  hidden: false
  id: 645e66085f8408a151fdab2c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7a0e893f40edfc28592a63dc34dffdfe.svg
      fullname: nico radu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nicopara
      type: user
    createdAt: '2023-05-24T09:53:45.000Z'
    data:
      edited: false
      editors:
      - Nicopara
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7a0e893f40edfc28592a63dc34dffdfe.svg
          fullname: nico radu
          isHf: false
          isPro: false
          name: Nicopara
          type: user
        html: '<p>I really want to use this</p>

          '
        raw: I really want to use this
        updatedAt: '2023-05-24T09:53:45.469Z'
      numEdits: 0
      reactions: []
    id: 646ddea95c3c0df5aef0e724
    type: comment
  author: Nicopara
  content: I really want to use this
  created_at: 2023-05-24 08:53:45+00:00
  edited: false
  hidden: false
  id: 646ddea95c3c0df5aef0e724
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d122c56450972febc9c978d486bebf55.svg
      fullname: Stajic
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nstajic
      type: user
    createdAt: '2023-05-28T13:18:33.000Z'
    data:
      edited: false
      editors:
      - nstajic
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d122c56450972febc9c978d486bebf55.svg
          fullname: Stajic
          isHf: false
          isPro: false
          name: nstajic
          type: user
        html: '<p>I copied config files from bigcode/starcoder and now I can load
          the model in oobabooga webui, but when I try to generate, I get the following
          error:</p>

          <p>Traceback (most recent call last):<br>  File "C:\oobabooga_windows\text-generation-webui\modules\callbacks.py",
          line 73, in gentask<br>    ret = self.mfunc(callback=_callback, **self.kwargs)<br>  File
          "C:\oobabooga_windows\text-generation-webui\modules\text_generation.py",
          line 274, in generate_with_callback<br>    shared.model.generate(**kwargs)<br>  File
          "C:\oobabooga_windows\installer_files\env\lib\site-packages\torch\utils_contextlib.py",
          line 115, in decorate_context<br>    return func(*args, **kwargs)<br>  File
          "C:\oobabooga_windows\installer_files\env\lib\site-packages\transformers\generation\utils.py",
          line 1568, in generate<br>    return self.sample(<br>  File "C:\oobabooga_windows\installer_files\env\lib\site-packages\transformers\generation\utils.py",
          line 2651, in sample<br>    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)<br>RuntimeError:
          probability tensor contains either <code>inf</code>, <code>nan</code> or
          element &lt; 0</p>

          '
        raw: "I copied config files from bigcode/starcoder and now I can load the\
          \ model in oobabooga webui, but when I try to generate, I get the following\
          \ error:\n\nTraceback (most recent call last):\n  File \"C:\\oobabooga_windows\\\
          text-generation-webui\\modules\\callbacks.py\", line 73, in gentask\n  \
          \  ret = self.mfunc(callback=_callback, **self.kwargs)\n  File \"C:\\oobabooga_windows\\\
          text-generation-webui\\modules\\text_generation.py\", line 274, in generate_with_callback\n\
          \    shared.model.generate(**kwargs)\n  File \"C:\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n\
          \    return func(*args, **kwargs)\n  File \"C:\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\generation\\utils.py\", line 1568,\
          \ in generate\n    return self.sample(\n  File \"C:\\oobabooga_windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\generation\\utils.py\"\
          , line 2651, in sample\n    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)\n\
          RuntimeError: probability tensor contains either `inf`, `nan` or element\
          \ < 0"
        updatedAt: '2023-05-28T13:18:33.023Z'
      numEdits: 0
      reactions: []
    id: 647354a963001a0002c9d1f5
    type: comment
  author: nstajic
  content: "I copied config files from bigcode/starcoder and now I can load the model\
    \ in oobabooga webui, but when I try to generate, I get the following error:\n\
    \nTraceback (most recent call last):\n  File \"C:\\oobabooga_windows\\text-generation-webui\\\
    modules\\callbacks.py\", line 73, in gentask\n    ret = self.mfunc(callback=_callback,\
    \ **self.kwargs)\n  File \"C:\\oobabooga_windows\\text-generation-webui\\modules\\\
    text_generation.py\", line 274, in generate_with_callback\n    shared.model.generate(**kwargs)\n\
    \  File \"C:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\torch\\\
    utils\\_contextlib.py\", line 115, in decorate_context\n    return func(*args,\
    \ **kwargs)\n  File \"C:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\generation\\utils.py\", line 1568, in generate\n    return self.sample(\n\
    \  File \"C:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\transformers\\\
    generation\\utils.py\", line 2651, in sample\n    next_tokens = torch.multinomial(probs,\
    \ num_samples=1).squeeze(1)\nRuntimeError: probability tensor contains either\
    \ `inf`, `nan` or element < 0"
  created_at: 2023-05-28 12:18:33+00:00
  edited: false
  hidden: false
  id: 647354a963001a0002c9d1f5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: mayank31398/starcoder-GPTQ-4bit-128g
repo_type: model
status: open
target_branch: null
title: Anyway to load this with oobabooga?
