!!python/object:huggingface_hub.community.DiscussionWithDetails
author: guruace
conflicting_files: null
created_at: 2023-12-20 04:36:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d1670387323c14a8551c0bbb7619f137.svg
      fullname: Ribo Huang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guruace
      type: user
    createdAt: '2023-12-20T04:36:21.000Z'
    data:
      edited: false
      editors:
      - guruace
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9637095928192139
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d1670387323c14a8551c0bbb7619f137.svg
          fullname: Ribo Huang
          isHf: false
          isPro: false
          name: guruace
          type: user
        html: '<p>I did as title, but the output is funny: it contains whole sequence
          of the input(such as PD1 sequence) plus 150 or so amino acids attached at
          the end of input. I don''t understand why. Please advice. Thank you!</p>

          '
        raw: 'I did as title, but the output is funny: it contains whole sequence
          of the input(such as PD1 sequence) plus 150 or so amino acids attached at
          the end of input. I don''t understand why. Please advice. Thank you!'
        updatedAt: '2023-12-20T04:36:21.191Z'
      numEdits: 0
      reactions: []
    id: 65826f45d73d6402f7ac8bb7
    type: comment
  author: guruace
  content: 'I did as title, but the output is funny: it contains whole sequence of
    the input(such as PD1 sequence) plus 150 or so amino acids attached at the end
    of input. I don''t understand why. Please advice. Thank you!'
  created_at: 2023-12-20 04:36:21+00:00
  edited: false
  hidden: false
  id: 65826f45d73d6402f7ac8bb7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641a05d84182690729c600ed/PrinvUOAGKOCB0E1ya1Ct.png?w=200&h=200&f=face
      fullname: Joseph
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: joethequant
      type: user
    createdAt: '2023-12-21T15:38:31.000Z'
    data:
      edited: false
      editors:
      - joethequant
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6594085693359375
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641a05d84182690729c600ed/PrinvUOAGKOCB0E1ya1Ct.png?w=200&h=200&f=face
          fullname: Joseph
          isHf: false
          isPro: false
          name: joethequant
          type: user
        html: "<p>We used ANACRI to parse the output of the model. You can see what\
          \ we did here on how to install ANARCI.<br><a rel=\"nofollow\" href=\"https://github.com/joethequant/antibodygpt\"\
          >https://github.com/joethequant/antibodygpt</a></p>\n<p><a rel=\"nofollow\"\
          \ href=\"https://github.com/joethequant/antibodygpt/blob/main/4_run_models_w_anarci.ipynb\"\
          >https://github.com/joethequant/antibodygpt/blob/main/4_run_models_w_anarci.ipynb</a></p>\n\
          <p><a rel=\"nofollow\" href=\"https://github.com/joethequant/antibodygpt/blob/main/5_model_grading.ipynb\"\
          >https://github.com/joethequant/antibodygpt/blob/main/5_model_grading.ipynb</a></p>\n\
          <p>Here is our predict function we used. In this script we are just checking\
          \ if it returns a valid antibody predicted by ANARCI.</p>\n<p>'''python<br>def\
          \ predict_sequence(model, tokenizer, sequence, device='cuda:0', number_of_sequences=1\
          \ ):<br>    # Tokenize the sequence<br>    tokenized_sequence = tokenizer.encode(sequence)</p>\n\
          <pre><code># Convert to PyTorch tensor and add batch dimension\ninput_tensor\
          \ = torch.tensor([tokenized_sequence.ids]).to(device)\n\n# Pass the tensor\
          \ through the model\nwith torch.no_grad():\n    output = model.generate(input_tensor,\
          \ max_length=1024, pad_token_id=tokenizer.encode('&lt;|pad|&gt;').ids[0],\
          \ do_sample=True, top_p=0.9, temperature=0.8, num_return_sequences=number_of_sequences)\n\
          \n    as_lists = lambda batch: [batch[i, ...].detach().cpu().numpy().tolist()\
          \ for i in range(batch.shape[0])]\n    sequences = tokenizer.decode_batch(as_lists(output))\n\
          \n    if len(sequences) &gt; 0:\n        sequences = [x.replace('2', '')\
          \ for x in sequences] #replace stop token with empty string\n    else:\n\
          \        return []\n\n    sequence_with_heavy_and_light_chains = []\n\n\
          \    #filter out sequences that don't have heavy and light chains\n    for\
          \ sequence in sequences:\n        # print(sequence)\n        species, e_value,\
          \ score, heavy_chain, light_chain = run_anarci(sequence)\n        if (len(heavy_chain)\
          \ &gt; 0) and (len(light_chain) &gt; 0):\n            sequence_with_heavy_and_light_chains.append(sequence)\n\
          \n    return sequence_with_heavy_and_light_chains\n</code></pre>\n<p>'''</p>\n\
          <p>If you want the full ANARCI output into a CSV. In the repo we have some\
          \ code that we import and then call it in the grading script.</p>\n<p>'''python<br>from\
          \ seq import ab_number as abn<br>df_result_H, df_result_KL = abn.number_seqs_as_df(sampled_sequences)<br>'''</p>\n"
        raw: "We used ANACRI to parse the output of the model. You can see what we\
          \ did here on how to install ANARCI.\nhttps://github.com/joethequant/antibodygpt\n\
          \nhttps://github.com/joethequant/antibodygpt/blob/main/4_run_models_w_anarci.ipynb\n\
          \nhttps://github.com/joethequant/antibodygpt/blob/main/5_model_grading.ipynb\n\
          \nHere is our predict function we used. In this script we are just checking\
          \ if it returns a valid antibody predicted by ANARCI.\n\n'''python\ndef\
          \ predict_sequence(model, tokenizer, sequence, device='cuda:0', number_of_sequences=1\
          \ ):\n    # Tokenize the sequence\n    tokenized_sequence = tokenizer.encode(sequence)\n\
          \    \n    # Convert to PyTorch tensor and add batch dimension\n    input_tensor\
          \ = torch.tensor([tokenized_sequence.ids]).to(device)\n    \n    # Pass\
          \ the tensor through the model\n    with torch.no_grad():\n        output\
          \ = model.generate(input_tensor, max_length=1024, pad_token_id=tokenizer.encode('<|pad|>').ids[0],\
          \ do_sample=True, top_p=0.9, temperature=0.8, num_return_sequences=number_of_sequences)\n\
          \n        as_lists = lambda batch: [batch[i, ...].detach().cpu().numpy().tolist()\
          \ for i in range(batch.shape[0])]\n        sequences = tokenizer.decode_batch(as_lists(output))\n\
          \n        if len(sequences) > 0:\n            sequences = [x.replace('2',\
          \ '') for x in sequences] #replace stop token with empty string\n      \
          \  else:\n            return []\n\n        sequence_with_heavy_and_light_chains\
          \ = []\n\n        #filter out sequences that don't have heavy and light\
          \ chains\n        for sequence in sequences:\n            # print(sequence)\n\
          \            species, e_value, score, heavy_chain, light_chain = run_anarci(sequence)\n\
          \            if (len(heavy_chain) > 0) and (len(light_chain) > 0):\n   \
          \             sequence_with_heavy_and_light_chains.append(sequence)\n\n\
          \        return sequence_with_heavy_and_light_chains\n\n'''\n\nIf you want\
          \ the full ANARCI output into a CSV. In the repo we have some code that\
          \ we import and then call it in the grading script.\n\n'''python\nfrom seq\
          \ import ab_number as abn\ndf_result_H, df_result_KL = abn.number_seqs_as_df(sampled_sequences)\n\
          '''\n\n\n"
        updatedAt: '2023-12-21T15:38:31.302Z'
      numEdits: 0
      reactions: []
    id: 65845bf7a76333af9f6cf3bf
    type: comment
  author: joethequant
  content: "We used ANACRI to parse the output of the model. You can see what we did\
    \ here on how to install ANARCI.\nhttps://github.com/joethequant/antibodygpt\n\
    \nhttps://github.com/joethequant/antibodygpt/blob/main/4_run_models_w_anarci.ipynb\n\
    \nhttps://github.com/joethequant/antibodygpt/blob/main/5_model_grading.ipynb\n\
    \nHere is our predict function we used. In this script we are just checking if\
    \ it returns a valid antibody predicted by ANARCI.\n\n'''python\ndef predict_sequence(model,\
    \ tokenizer, sequence, device='cuda:0', number_of_sequences=1 ):\n    # Tokenize\
    \ the sequence\n    tokenized_sequence = tokenizer.encode(sequence)\n    \n  \
    \  # Convert to PyTorch tensor and add batch dimension\n    input_tensor = torch.tensor([tokenized_sequence.ids]).to(device)\n\
    \    \n    # Pass the tensor through the model\n    with torch.no_grad():\n  \
    \      output = model.generate(input_tensor, max_length=1024, pad_token_id=tokenizer.encode('<|pad|>').ids[0],\
    \ do_sample=True, top_p=0.9, temperature=0.8, num_return_sequences=number_of_sequences)\n\
    \n        as_lists = lambda batch: [batch[i, ...].detach().cpu().numpy().tolist()\
    \ for i in range(batch.shape[0])]\n        sequences = tokenizer.decode_batch(as_lists(output))\n\
    \n        if len(sequences) > 0:\n            sequences = [x.replace('2', '')\
    \ for x in sequences] #replace stop token with empty string\n        else:\n \
    \           return []\n\n        sequence_with_heavy_and_light_chains = []\n\n\
    \        #filter out sequences that don't have heavy and light chains\n      \
    \  for sequence in sequences:\n            # print(sequence)\n            species,\
    \ e_value, score, heavy_chain, light_chain = run_anarci(sequence)\n          \
    \  if (len(heavy_chain) > 0) and (len(light_chain) > 0):\n                sequence_with_heavy_and_light_chains.append(sequence)\n\
    \n        return sequence_with_heavy_and_light_chains\n\n'''\n\nIf you want the\
    \ full ANARCI output into a CSV. In the repo we have some code that we import\
    \ and then call it in the grading script.\n\n'''python\nfrom seq import ab_number\
    \ as abn\ndf_result_H, df_result_KL = abn.number_seqs_as_df(sampled_sequences)\n\
    '''\n\n\n"
  created_at: 2023-12-21 15:38:31+00:00
  edited: false
  hidden: false
  id: 65845bf7a76333af9f6cf3bf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d1670387323c14a8551c0bbb7619f137.svg
      fullname: Ribo Huang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guruace
      type: user
    createdAt: '2023-12-21T16:34:33.000Z'
    data:
      edited: false
      editors:
      - guruace
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9308134317398071
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d1670387323c14a8551c0bbb7619f137.svg
          fullname: Ribo Huang
          isHf: false
          isPro: false
          name: guruace
          type: user
        html: '<p>I need sometime to digest your code, since my background is biology,
          not computer science. My understanding is that if I run through your python
          scripts from 1 to 5 at "<a rel="nofollow" href="https://github.com/joethequant/antibodygpt/&quot;">https://github.com/joethequant/antibodygpt/"</a>,
          I will get the same result as your Demo results (shown at "<a rel="nofollow"
          href="https://orca-app-ygzbp.ondigitalocean.app/Demo_Antibody_Generator&quot;">https://orca-app-ygzbp.ondigitalocean.app/Demo_Antibody_Generator"</a>)?
          By the way, the notebook 1_download_pretrained_checkpoints.ipynb at "<a
          rel="nofollow" href="https://github.com/joethequant/antibodygpt/&quot;">https://github.com/joethequant/antibodygpt/"</a>
          seems to be corrupted and unusable, please kindly re-upload a good one (the
          rest of the notebook is ok and can be opened). </p>

          <p>Your work is fascinating, and my group may test some results out of your
          model (if I could be successful in reproducing your results) in my wet lab
          (clone the antibodies designed by your models, and compare it with the other
          methods). Thank you so much for your prompt response, and we all need to
          keep working.</p>

          '
        raw: "I need sometime to digest your code, since my background is biology,\
          \ not computer science. My understanding is that if I run through your python\
          \ scripts from 1 to 5 at \"https://github.com/joethequant/antibodygpt/\"\
          , I will get the same result as your Demo results (shown at \"https://orca-app-ygzbp.ondigitalocean.app/Demo_Antibody_Generator\"\
          )? By the way, the notebook 1_download_pretrained_checkpoints.ipynb at \"\
          https://github.com/joethequant/antibodygpt/\" seems to be corrupted and\
          \ unusable, please kindly re-upload a good one (the rest of the notebook\
          \ is ok and can be opened). \n\nYour work is fascinating, and my group may\
          \ test some results out of your model (if I could be successful in reproducing\
          \ your results) in my wet lab (clone the antibodies designed by your models,\
          \ and compare it with the other methods). Thank you so much for your prompt\
          \ response, and we all need to keep working."
        updatedAt: '2023-12-21T16:34:33.831Z'
      numEdits: 0
      reactions: []
    id: 658469190e68ae8756f14d69
    type: comment
  author: guruace
  content: "I need sometime to digest your code, since my background is biology, not\
    \ computer science. My understanding is that if I run through your python scripts\
    \ from 1 to 5 at \"https://github.com/joethequant/antibodygpt/\", I will get the\
    \ same result as your Demo results (shown at \"https://orca-app-ygzbp.ondigitalocean.app/Demo_Antibody_Generator\"\
    )? By the way, the notebook 1_download_pretrained_checkpoints.ipynb at \"https://github.com/joethequant/antibodygpt/\"\
    \ seems to be corrupted and unusable, please kindly re-upload a good one (the\
    \ rest of the notebook is ok and can be opened). \n\nYour work is fascinating,\
    \ and my group may test some results out of your model (if I could be successful\
    \ in reproducing your results) in my wet lab (clone the antibodies designed by\
    \ your models, and compare it with the other methods). Thank you so much for your\
    \ prompt response, and we all need to keep working."
  created_at: 2023-12-21 16:34:33+00:00
  edited: false
  hidden: false
  id: 658469190e68ae8756f14d69
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641a05d84182690729c600ed/PrinvUOAGKOCB0E1ya1Ct.png?w=200&h=200&f=face
      fullname: Joseph
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: joethequant
      type: user
    createdAt: '2023-12-23T14:40:25.000Z'
    data:
      edited: false
      editors:
      - joethequant
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8122711181640625
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641a05d84182690729c600ed/PrinvUOAGKOCB0E1ya1Ct.png?w=200&h=200&f=face
          fullname: Joseph
          isHf: false
          isPro: false
          name: joethequant
          type: user
        html: '<p>WOW! That would be great; please keep us updated with the results;
          we are happy to help!</p>

          <p>I fixed the 1_download_pretrained_checkpoints.ipynb file. You only need
          this to fine-tune from the progen2 foundational models. Once you download
          the models, you can run 4_run_models_w_anarci.ipynb. We have weights and
          biases embedded for logging. You can remove the wandb lines or get a weights
          and biases account for free and enter your API key when it asks. </p>

          <p>If you want to generate sequences, you can run 5_model_grading.ipynb,
          and it will automatically download our trained weights from huggingface,
          run the outputs through ANARCI, and download them into CSVs. </p>

          <p><strong>Did you have any issues installing ANARCI?</strong></p>

          <p>Also, we have a serverless runpod docker image that runs the model:</p>

          <ul>

          <li><strong>Code:</strong> <a rel="nofollow" href="https://github.com/joethequant/docker_protein_generator">https://github.com/joethequant/docker_protein_generator</a></li>

          <li><strong>Already Built and Pushed Image:</strong> <a rel="nofollow" href="https://hub.docker.com/r/robertsj32/antibody_generation_runpod">https://hub.docker.com/r/robertsj32/antibody_generation_runpod</a><ul>

          <li>This image already has our trained models in it.</li>

          <li>You can reference this image "docker pull robertsj32/antibody_generation_runpod"
          directly in RUNPOD serverless, and then call it using the example script
          in the readme.</li>

          </ul>

          </li>

          </ul>

          <p>Here is the Streamlit app:</p>

          <ul>

          <li><strong>Code:</strong> <a rel="nofollow" href="https://github.com/joethequant/docker_streamlit_antibody_protein_generation">https://github.com/joethequant/docker_streamlit_antibody_protein_generation</a></li>

          <li><strong>Already Built and Pushed Image:</strong> <a rel="nofollow" href="https://hub.docker.com/repository/docker/robertsj32/antibody_generation_streamlit/general">https://hub.docker.com/repository/docker/robertsj32/antibody_generation_streamlit/general</a></li>

          </ul>

          '
        raw: "WOW! That would be great; please keep us updated with the results; we\
          \ are happy to help!\n\nI fixed the 1_download_pretrained_checkpoints.ipynb\
          \ file. You only need this to fine-tune from the progen2 foundational models.\
          \ Once you download the models, you can run 4_run_models_w_anarci.ipynb.\
          \ We have weights and biases embedded for logging. You can remove the wandb\
          \ lines or get a weights and biases account for free and enter your API\
          \ key when it asks. \n\nIf you want to generate sequences, you can run 5_model_grading.ipynb,\
          \ and it will automatically download our trained weights from huggingface,\
          \ run the outputs through ANARCI, and download them into CSVs. \n\n**Did\
          \ you have any issues installing ANARCI?**\n\nAlso, we have a serverless\
          \ runpod docker image that runs the model:\n- **Code:** https://github.com/joethequant/docker_protein_generator\n\
          - **Already Built and Pushed Image:** https://hub.docker.com/r/robertsj32/antibody_generation_runpod\n\
          \  - This image already has our trained models in it.\n  - You can reference\
          \ this image \"docker pull robertsj32/antibody_generation_runpod\" directly\
          \ in RUNPOD serverless, and then call it using the example script in the\
          \ readme.\n\nHere is the Streamlit app:\n- **Code:** https://github.com/joethequant/docker_streamlit_antibody_protein_generation\n\
          - **Already Built and Pushed Image:** https://hub.docker.com/repository/docker/robertsj32/antibody_generation_streamlit/general\n\
          \n"
        updatedAt: '2023-12-23T14:40:25.225Z'
      numEdits: 0
      reactions: []
    id: 6586f159304552ba0c7e42ee
    type: comment
  author: joethequant
  content: "WOW! That would be great; please keep us updated with the results; we\
    \ are happy to help!\n\nI fixed the 1_download_pretrained_checkpoints.ipynb file.\
    \ You only need this to fine-tune from the progen2 foundational models. Once you\
    \ download the models, you can run 4_run_models_w_anarci.ipynb. We have weights\
    \ and biases embedded for logging. You can remove the wandb lines or get a weights\
    \ and biases account for free and enter your API key when it asks. \n\nIf you\
    \ want to generate sequences, you can run 5_model_grading.ipynb, and it will automatically\
    \ download our trained weights from huggingface, run the outputs through ANARCI,\
    \ and download them into CSVs. \n\n**Did you have any issues installing ANARCI?**\n\
    \nAlso, we have a serverless runpod docker image that runs the model:\n- **Code:**\
    \ https://github.com/joethequant/docker_protein_generator\n- **Already Built and\
    \ Pushed Image:** https://hub.docker.com/r/robertsj32/antibody_generation_runpod\n\
    \  - This image already has our trained models in it.\n  - You can reference this\
    \ image \"docker pull robertsj32/antibody_generation_runpod\" directly in RUNPOD\
    \ serverless, and then call it using the example script in the readme.\n\nHere\
    \ is the Streamlit app:\n- **Code:** https://github.com/joethequant/docker_streamlit_antibody_protein_generation\n\
    - **Already Built and Pushed Image:** https://hub.docker.com/repository/docker/robertsj32/antibody_generation_streamlit/general\n\
    \n"
  created_at: 2023-12-23 14:40:25+00:00
  edited: false
  hidden: false
  id: 6586f159304552ba0c7e42ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d1670387323c14a8551c0bbb7619f137.svg
      fullname: Ribo Huang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guruace
      type: user
    createdAt: '2023-12-24T01:38:09.000Z'
    data:
      edited: true
      editors:
      - guruace
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8318777084350586
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d1670387323c14a8551c0bbb7619f137.svg
          fullname: Ribo Huang
          isHf: false
          isPro: false
          name: guruace
          type: user
        html: '<p>Thank you for all. 1. the file"1_download_pretrained_checkpoints.ipynb"
          is working fine now. 2. Yes, we did download your docker image by "docker
          pull robertsj32/antibody_generation_runpod", but when we ran it by "docker
          run -i -t  IMAGE ID", it showed error: </p>

          <p>"--- Starting Serverless Worker |  Version 1.3.4 ---<br>WARN   | test_input.json
          not found, exiting."</p>

          <p>and when we checked within the container by "docker run -it --entrypoint
          /bin/bash  IMAGE ID", we could not find the input file "test_input.json"
          under the root directory. Presumably, the test_input.json should be in the
          root directory as shown at your github repo.</p>

          '
        raw: "Thank you for all. 1. the file\"1_download_pretrained_checkpoints.ipynb\"\
          \ is working fine now. 2. Yes, we did download your docker image by \"docker\
          \ pull robertsj32/antibody_generation_runpod\", but when we ran it by \"\
          docker run -i -t  IMAGE ID\", it showed error: \n\n\"--- Starting Serverless\
          \ Worker |  Version 1.3.4 ---\nWARN   | test_input.json not found, exiting.\"\
          \n\nand when we checked within the container by \"docker run -it --entrypoint\
          \ /bin/bash  IMAGE ID\", we could not find the input file \"test_input.json\"\
          \ under the root directory. Presumably, the test_input.json should be in\
          \ the root directory as shown at your github repo.\n"
        updatedAt: '2023-12-24T01:40:08.372Z'
      numEdits: 2
      reactions: []
    id: 65878b81509bcae23f607e6d
    type: comment
  author: guruace
  content: "Thank you for all. 1. the file\"1_download_pretrained_checkpoints.ipynb\"\
    \ is working fine now. 2. Yes, we did download your docker image by \"docker pull\
    \ robertsj32/antibody_generation_runpod\", but when we ran it by \"docker run\
    \ -i -t  IMAGE ID\", it showed error: \n\n\"--- Starting Serverless Worker | \
    \ Version 1.3.4 ---\nWARN   | test_input.json not found, exiting.\"\n\nand when\
    \ we checked within the container by \"docker run -it --entrypoint /bin/bash \
    \ IMAGE ID\", we could not find the input file \"test_input.json\" under the root\
    \ directory. Presumably, the test_input.json should be in the root directory as\
    \ shown at your github repo.\n"
  created_at: 2023-12-24 01:38:09+00:00
  edited: true
  hidden: false
  id: 65878b81509bcae23f607e6d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/d1670387323c14a8551c0bbb7619f137.svg
      fullname: Ribo Huang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guruace
      type: user
    createdAt: '2023-12-24T01:40:29.000Z'
    data:
      status: closed
    id: 65878c0dae21a8ff2844b2ae
    type: status-change
  author: guruace
  created_at: 2023-12-24 01:40:29+00:00
  id: 65878c0dae21a8ff2844b2ae
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: AntibodyGeneration/fine-tuned-progen2-large
repo_type: model
status: closed
target_branch: null
title: 'Running "example code" inside README.md: the output is the input sequence(target
  seq, or called antigen) extended with about 150-200 amino acids'
