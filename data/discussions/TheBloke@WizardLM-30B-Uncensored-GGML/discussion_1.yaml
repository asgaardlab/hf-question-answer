!!python/object:huggingface_hub.community.DiscussionWithDetails
author: 3g6y9CCsfNCNen
conflicting_files: null
created_at: 2023-05-23 01:39:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/615c93a0b4f472cf796b74d4fd5bb4c2.svg
      fullname: Mike Arndt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 3g6y9CCsfNCNen
      type: user
    createdAt: '2023-05-23T02:39:25.000Z'
    data:
      edited: false
      editors:
      - 3g6y9CCsfNCNen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/615c93a0b4f472cf796b74d4fd5bb4c2.svg
          fullname: Mike Arndt
          isHf: false
          isPro: false
          name: 3g6y9CCsfNCNen
          type: user
        html: '<p>First, thanks for all the hardwork for everyone involved.</p>

          <p>I''m a bit of a noob with all of this stuff. I do have llama.cpp already.
          But which version do I use for a M2 Macbook Pro? From what I found I think
          I have to use the GGML variant from this repo, but what about q4_0, q5_0
          etc? And are there any params I have to mess with on Llama.cpp once I add
          it to /model folder? Thanks!</p>

          '
        raw: "First, thanks for all the hardwork for everyone involved.\r\n\r\nI'm\
          \ a bit of a noob with all of this stuff. I do have llama.cpp already. But\
          \ which version do I use for a M2 Macbook Pro? From what I found I think\
          \ I have to use the GGML variant from this repo, but what about q4_0, q5_0\
          \ etc? And are there any params I have to mess with on Llama.cpp once I\
          \ add it to /model folder? Thanks!"
        updatedAt: '2023-05-23T02:39:25.561Z'
      numEdits: 0
      reactions: []
    id: 646c275dc7f672003c87ca55
    type: comment
  author: 3g6y9CCsfNCNen
  content: "First, thanks for all the hardwork for everyone involved.\r\n\r\nI'm a\
    \ bit of a noob with all of this stuff. I do have llama.cpp already. But which\
    \ version do I use for a M2 Macbook Pro? From what I found I think I have to use\
    \ the GGML variant from this repo, but what about q4_0, q5_0 etc? And are there\
    \ any params I have to mess with on Llama.cpp once I add it to /model folder?\
    \ Thanks!"
  created_at: 2023-05-23 01:39:25+00:00
  edited: false
  hidden: false
  id: 646c275dc7f672003c87ca55
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-05-23T17:52:25.000Z'
    data:
      edited: false
      editors:
      - mirek190
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>READ model card ...</p>

          '
        raw: READ model card ...
        updatedAt: '2023-05-23T17:52:25.093Z'
      numEdits: 0
      reactions: []
    id: 646cfd594a2db77443772666
    type: comment
  author: mirek190
  content: READ model card ...
  created_at: 2023-05-23 16:52:25+00:00
  edited: false
  hidden: false
  id: 646cfd594a2db77443772666
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671986648070-noauth.png?w=200&h=200&f=face
      fullname: ojeda ff
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: carlosgfhg
      type: user
    createdAt: '2023-05-23T18:34:27.000Z'
    data:
      edited: false
      editors:
      - carlosgfhg
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671986648070-noauth.png?w=200&h=200&f=face
          fullname: ojeda ff
          isHf: false
          isPro: false
          name: carlosgfhg
          type: user
        html: '<p>And how to install this, I don''t have the slightest thought, help.</p>

          '
        raw: And how to install this, I don't have the slightest thought, help.
        updatedAt: '2023-05-23T18:34:27.898Z'
      numEdits: 0
      reactions: []
    id: 646d0733e0c5e39573512c20
    type: comment
  author: carlosgfhg
  content: And how to install this, I don't have the slightest thought, help.
  created_at: 2023-05-23 17:34:27+00:00
  edited: false
  hidden: false
  id: 646d0733e0c5e39573512c20
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-05-23T18:54:27.000Z'
    data:
      edited: false
      editors:
      - mirek190
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>If you read and can''t understand it .... you have to learn from
          the beginning...</p>

          <p>That instruction from model card is very straight forward.</p>

          '
        raw: 'If you read and can''t understand it .... you have to learn from the
          beginning...


          That instruction from model card is very straight forward.'
        updatedAt: '2023-05-23T18:54:27.799Z'
      numEdits: 0
      reactions: []
    id: 646d0be3e0c5e3957351e528
    type: comment
  author: mirek190
  content: 'If you read and can''t understand it .... you have to learn from the beginning...


    That instruction from model card is very straight forward.'
  created_at: 2023-05-23 17:54:27+00:00
  edited: false
  hidden: false
  id: 646d0be3e0c5e3957351e528
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/abd1079b4ca2852e2f5ad1dce2d3e2e7.svg
      fullname: Jesper Olsson
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Zodi
      type: user
    createdAt: '2023-11-22T01:30:52.000Z'
    data:
      edited: false
      editors:
      - Zodi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9319298267364502
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/abd1079b4ca2852e2f5ad1dce2d3e2e7.svg
          fullname: Jesper Olsson
          isHf: false
          isPro: false
          name: Zodi
          type: user
        html: '<blockquote>

          <p>And how to install this, I don''t have the slightest thought, help.</p>

          </blockquote>

          <p>I''ll give you a simple way to get started. No priot knowlegde needed
          and with a simple open source interface (I do not own this program or have
          any affiliation with it but it''s awsome). Download Faraday <a rel="nofollow"
          href="https://faraday.dev/">https://faraday.dev/</a> when downloaded you
          can download a character. For example, I downloaded a character that helps
          me in a way chatGPT might. But before you can use it you have to download
          a model. There is models on the app that you can download with one click,
          but WizardLM is not on there. So basically you go the download page on this
          hugginface page, you press on the download button and wait for the model
          to download. In Faraday you can open the model download folder where it
          would download your model and paste in the model.</p>

          <p>A brief description on different models: If the model ends with a .bin
          or .gguf it probably works (WizardLM is .bin), the bigger the model the
          better it is generally, but to start it is usually recommended to start
          with a "Q4" model and "K_M" if there is a K options ("M" stands for medium
          so it''s medium heavy). Paste it in the folder, make your character and
          select your mode. Now you are done and it works if your computer can handle
          it. Hope this helps!</p>

          '
        raw: '> And how to install this, I don''t have the slightest thought, help.


          I''ll give you a simple way to get started. No priot knowlegde needed and
          with a simple open source interface (I do not own this program or have any
          affiliation with it but it''s awsome). Download Faraday https://faraday.dev/
          when downloaded you can download a character. For example, I downloaded
          a character that helps me in a way chatGPT might. But before you can use
          it you have to download a model. There is models on the app that you can
          download with one click, but WizardLM is not on there. So basically you
          go the download page on this hugginface page, you press on the download
          button and wait for the model to download. In Faraday you can open the model
          download folder where it would download your model and paste in the model.


          A brief description on different models: If the model ends with a .bin or
          .gguf it probably works (WizardLM is .bin), the bigger the model the better
          it is generally, but to start it is usually recommended to start with a
          "Q4" model and "K_M" if there is a K options ("M" stands for medium so it''s
          medium heavy). Paste it in the folder, make your character and select your
          mode. Now you are done and it works if your computer can handle it. Hope
          this helps!'
        updatedAt: '2023-11-22T01:30:52.630Z'
      numEdits: 0
      reactions: []
    id: 655d59ccb5da99edaf3221dc
    type: comment
  author: Zodi
  content: '> And how to install this, I don''t have the slightest thought, help.


    I''ll give you a simple way to get started. No priot knowlegde needed and with
    a simple open source interface (I do not own this program or have any affiliation
    with it but it''s awsome). Download Faraday https://faraday.dev/ when downloaded
    you can download a character. For example, I downloaded a character that helps
    me in a way chatGPT might. But before you can use it you have to download a model.
    There is models on the app that you can download with one click, but WizardLM
    is not on there. So basically you go the download page on this hugginface page,
    you press on the download button and wait for the model to download. In Faraday
    you can open the model download folder where it would download your model and
    paste in the model.


    A brief description on different models: If the model ends with a .bin or .gguf
    it probably works (WizardLM is .bin), the bigger the model the better it is generally,
    but to start it is usually recommended to start with a "Q4" model and "K_M" if
    there is a K options ("M" stands for medium so it''s medium heavy). Paste it in
    the folder, make your character and select your mode. Now you are done and it
    works if your computer can handle it. Hope this helps!'
  created_at: 2023-11-22 01:30:52+00:00
  edited: false
  hidden: false
  id: 655d59ccb5da99edaf3221dc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/WizardLM-30B-Uncensored-GGML
repo_type: model
status: open
target_branch: null
title: Run on M2 Macbook?
