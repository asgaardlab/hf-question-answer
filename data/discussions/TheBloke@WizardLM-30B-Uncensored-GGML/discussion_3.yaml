!!python/object:huggingface_hub.community.DiscussionWithDetails
author: CR2022
conflicting_files: null
created_at: 2023-06-07 13:44:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63abbef00ed3c32528509700/N7CUJEuCgYqVU8ntzgggz.jpeg?w=200&h=200&f=face
      fullname: CR2022
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CR2022
      type: user
    createdAt: '2023-06-07T14:44:22.000Z'
    data:
      edited: true
      editors:
      - CR2022
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.39637070894241333
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63abbef00ed3c32528509700/N7CUJEuCgYqVU8ntzgggz.jpeg?w=200&h=200&f=face
          fullname: CR2022
          isHf: false
          isPro: false
          name: CR2022
          type: user
        html: '<p>llama.cpp: loading model from models/TheBloke_WizardLM-30B-Uncensored-GGML/wizardlm-30b-uncensored.ggmlv3.q5_K_S.bin<br>error
          loading model: unrecognized tensor type 13</p>

          <p>llama_init_from_file: failed to load model<br>Traceback (most recent
          call last):<br>  File "/root/text-generation-webui/server.py", line 1079,
          in <br>    shared.model, shared.tokenizer = load_model(shared.model_name)<br>  File
          "/root/text-generation-webui/modules/models.py", line 94, in load_model<br>    output
          = load_func(model_name)<br>  File "/root/text-generation-webui/modules/models.py",
          line 271, in llamacpp_loader<br>    model, tokenizer = LlamaCppModel.from_pretrained(model_file)<br>  File
          "/root/text-generation-webui/modules/llamacpp_model.py", line 49, in from_pretrained<br>    self.model
          = Llama(**params)<br>  File "/root/miniconda3/envs/textgen/lib/python3.10/site-packages/llama_cpp/llama.py",
          line 197, in <strong>init</strong><br>    assert self.ctx is not None<br>AssertionError<br>Exception
          ignored in: &lt;function LlamaCppModel.__del__ at 0x7f354e6704c0&gt;<br>Traceback
          (most recent call last):<br>  File "/root/text-generation-webui/modules/llamacpp_model.py",
          line 23, in <strong>del</strong><br>    self.model.<strong>del</strong>()<br>AttributeError:
          ''LlamaCppModel'' object has no attribute ''model''<br>(textgen) root@DESKTOP:~/text-generation-webui#</p>

          '
        raw: "llama.cpp: loading model from models/TheBloke_WizardLM-30B-Uncensored-GGML/wizardlm-30b-uncensored.ggmlv3.q5_K_S.bin\n\
          error loading model: unrecognized tensor type 13\n\nllama_init_from_file:\
          \ failed to load model\nTraceback (most recent call last):\n  File \"/root/text-generation-webui/server.py\"\
          , line 1079, in <module>\n    shared.model, shared.tokenizer = load_model(shared.model_name)\n\
          \  File \"/root/text-generation-webui/modules/models.py\", line 94, in load_model\n\
          \    output = load_func(model_name)\n  File \"/root/text-generation-webui/modules/models.py\"\
          , line 271, in llamacpp_loader\n    model, tokenizer = LlamaCppModel.from_pretrained(model_file)\n\
          \  File \"/root/text-generation-webui/modules/llamacpp_model.py\", line\
          \ 49, in from_pretrained\n    self.model = Llama(**params)\n  File \"/root/miniconda3/envs/textgen/lib/python3.10/site-packages/llama_cpp/llama.py\"\
          , line 197, in __init__\n    assert self.ctx is not None\nAssertionError\n\
          Exception ignored in: <function LlamaCppModel.__del__ at 0x7f354e6704c0>\n\
          Traceback (most recent call last):\n  File \"/root/text-generation-webui/modules/llamacpp_model.py\"\
          , line 23, in __del__\n    self.model.__del__()\nAttributeError: 'LlamaCppModel'\
          \ object has no attribute 'model'\n(textgen) root@DESKTOP:~/text-generation-webui#"
        updatedAt: '2023-06-07T14:44:55.075Z'
      numEdits: 1
      reactions: []
    id: 648097c6c0d3c70316d20db5
    type: comment
  author: CR2022
  content: "llama.cpp: loading model from models/TheBloke_WizardLM-30B-Uncensored-GGML/wizardlm-30b-uncensored.ggmlv3.q5_K_S.bin\n\
    error loading model: unrecognized tensor type 13\n\nllama_init_from_file: failed\
    \ to load model\nTraceback (most recent call last):\n  File \"/root/text-generation-webui/server.py\"\
    , line 1079, in <module>\n    shared.model, shared.tokenizer = load_model(shared.model_name)\n\
    \  File \"/root/text-generation-webui/modules/models.py\", line 94, in load_model\n\
    \    output = load_func(model_name)\n  File \"/root/text-generation-webui/modules/models.py\"\
    , line 271, in llamacpp_loader\n    model, tokenizer = LlamaCppModel.from_pretrained(model_file)\n\
    \  File \"/root/text-generation-webui/modules/llamacpp_model.py\", line 49, in\
    \ from_pretrained\n    self.model = Llama(**params)\n  File \"/root/miniconda3/envs/textgen/lib/python3.10/site-packages/llama_cpp/llama.py\"\
    , line 197, in __init__\n    assert self.ctx is not None\nAssertionError\nException\
    \ ignored in: <function LlamaCppModel.__del__ at 0x7f354e6704c0>\nTraceback (most\
    \ recent call last):\n  File \"/root/text-generation-webui/modules/llamacpp_model.py\"\
    , line 23, in __del__\n    self.model.__del__()\nAttributeError: 'LlamaCppModel'\
    \ object has no attribute 'model'\n(textgen) root@DESKTOP:~/text-generation-webui#"
  created_at: 2023-06-07 13:44:22+00:00
  edited: true
  hidden: false
  id: 648097c6c0d3c70316d20db5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-07T15:14:50.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9475224018096924
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yeah, as mentioned in the README  the new quant types don''t yet
          work with text-generation-webui.  Use q5_0 for now.</p>

          '
        raw: Yeah, as mentioned in the README  the new quant types don't yet work
          with text-generation-webui.  Use q5_0 for now.
        updatedAt: '2023-06-07T15:14:50.964Z'
      numEdits: 0
      reactions: []
    id: 64809eeae1421e205fda0dcb
    type: comment
  author: TheBloke
  content: Yeah, as mentioned in the README  the new quant types don't yet work with
    text-generation-webui.  Use q5_0 for now.
  created_at: 2023-06-07 14:14:50+00:00
  edited: false
  hidden: false
  id: 64809eeae1421e205fda0dcb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63abbef00ed3c32528509700/N7CUJEuCgYqVU8ntzgggz.jpeg?w=200&h=200&f=face
      fullname: CR2022
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CR2022
      type: user
    createdAt: '2023-06-07T16:58:45.000Z'
    data:
      edited: false
      editors:
      - CR2022
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9800427556037903
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63abbef00ed3c32528509700/N7CUJEuCgYqVU8ntzgggz.jpeg?w=200&h=200&f=face
          fullname: CR2022
          isHf: false
          isPro: false
          name: CR2022
          type: user
        html: '<p>Ok thank you.</p>

          '
        raw: Ok thank you.
        updatedAt: '2023-06-07T16:58:45.882Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6480b745e1421e205fdbcb63
    id: 6480b745e1421e205fdbcb5f
    type: comment
  author: CR2022
  content: Ok thank you.
  created_at: 2023-06-07 15:58:45+00:00
  edited: false
  hidden: false
  id: 6480b745e1421e205fdbcb5f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63abbef00ed3c32528509700/N7CUJEuCgYqVU8ntzgggz.jpeg?w=200&h=200&f=face
      fullname: CR2022
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CR2022
      type: user
    createdAt: '2023-06-07T16:58:45.000Z'
    data:
      status: closed
    id: 6480b745e1421e205fdbcb63
    type: status-change
  author: CR2022
  created_at: 2023-06-07 15:58:45+00:00
  id: 6480b745e1421e205fdbcb63
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/WizardLM-30B-Uncensored-GGML
repo_type: model
status: closed
target_branch: null
title: 'error loading model: unrecognized tensor type 13'
