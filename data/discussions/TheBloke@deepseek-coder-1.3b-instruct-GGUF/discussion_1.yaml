!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Pumba2
conflicting_files: null
created_at: 2023-11-05 14:21:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/64ac7b4159bd86340458e53d3e30aee2.svg
      fullname: Bumba
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pumba2
      type: user
    createdAt: '2023-11-05T14:21:19.000Z'
    data:
      edited: false
      editors:
      - Pumba2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5070980191230774
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/64ac7b4159bd86340458e53d3e30aee2.svg
          fullname: Bumba
          isHf: false
          isPro: false
          name: Pumba2
          type: user
        html: '<p>GPT4all: crashes the whole app<br>KOboldCPP: Generates gibberish</p>

          '
        raw: "GPT4all: crashes the whole app\r\nKOboldCPP: Generates gibberish"
        updatedAt: '2023-11-05T14:21:19.115Z'
      numEdits: 0
      reactions: []
    id: 6547a4df00ca373b7d3d099e
    type: comment
  author: Pumba2
  content: "GPT4all: crashes the whole app\r\nKOboldCPP: Generates gibberish"
  created_at: 2023-11-05 14:21:19+00:00
  edited: false
  hidden: false
  id: 6547a4df00ca373b7d3d099e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-05T14:37:08.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.748720645904541
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p>Working fine in latest llama.cpp. Please report the issues to the\
          \ respective developers of those programs.</p>\n<p>Also, try testing the\
          \ non q-quants, like Q4_0 or Q5_0, if you didn't already.</p>\n<p>This is\
          \ an unusual size model and k-quants would not normally be supported for\
          \ many of the layers, due to them not being divisible by 256.  But due to\
          \ a recent llama.cpp change, those layers are now done using non-k-quant\
          \ methods, like Q4_0.  This enables me to make k-quants.  I don't know if\
          \ that could cause issues for clients besides llama.cpp, but it's worth\
          \ mentioning.</p>\n<p>llama.cpp tests:</p>\n<p>Q6_K:<br>system_info: n_threads\
          \ = 56 / 112 | AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI\
          \ = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD\
          \ = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 |<br>sampling:<br>   \
          \ repeat_last_n = 64, repeat_penalty = 1.100, frequency_penalty = 0.000,\
          \ presence_penalty = 0.000<br>    top_k = 40, tfs_z = 1.000, top_p = 0.950,\
          \ min_p = 0.050, typical_p = 1.000, temp = 0.800<br>    mirostat = 0, mirostat_lr\
          \ = 0.100, mirostat_ent = 5.000<br>generate: n_ctx = 512, n_batch = 512,\
          \ n_predict = 256, n_keep = 0</p>\n<p>You are an AI programming assistant,\
          \ utilizing the Deepseek Coder model, developed by Deepseek Company, and\
          \ you only answer questions related to computer science. For politically\
          \ sensitive questions, security and privacy issues, and other non-computer\
          \ science questions, you will refuse to answer.</p>\n<h3 id=\"instruction\"\
          >Instruction:</h3>\n<p>write a quick sort algorithm in python.</p>\n<h3\
          \ id=\"response\">Response:</h3>\n<p>Sure! Here is the Python implementation\
          \ of Quick Sort Algorithm using recursion:</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\"\
          >quicksort</span>(<span class=\"hljs-params\">arr</span>):\n    <span class=\"\
          hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(arr) &lt;=\
          \ <span class=\"hljs-number\">1</span>: <span class=\"hljs-comment\"># base\
          \ case, return array directly when length less than or equal to one (already\
          \ sorted).</span>\n        <span class=\"hljs-keyword\">return</span> arr\n\
          \    <span class=\"hljs-keyword\">else</span>:              <span class=\"\
          hljs-comment\"># recurse on the rest of the list.</span>\n             \
          \           <span class=\"hljs-comment\"># pivot is always first element\
          \ in partitioning step for simplicity and efficiency reasons \u2013 usually\
          \ randomized choice as well!</span>\n                      value_to_compare\
          \ = arr[<span class=\"hljs-number\">0</span>]\n                  lower =\
          \ [x <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\"\
          >in</span> arr[<span class=\"hljs-number\">1</span>:] <span class=\"hljs-keyword\"\
          >if</span> x &lt; value_to_compare]\n                 upper = [y <span class=\"\
          hljs-keyword\">for</span> y <span class=\"hljs-keyword\">in</span> arr[<span\
          \ class=\"hljs-number\">1</span>:] <span class=\"hljs-keyword\">if</span>\
          \ y &gt;=value_to_compare ]\n                     <span class=\"hljs-keyword\"\
          >return</span> quicksort(lower) + [value_to_compare] +quicksort(upper )\
          \   <span class=\"hljs-comment\"># concatenate and sort the lists \u2013\
          \ this is our recursive call!</span>\n</code></pre>\n<p>You can run above\
          \ function using: <code>print (quickSort([3,60,15])</code>. You will get\
          \ output as : '[27].' which means it sorts array correctly in asc<br>llama_print_timings:\
          \        load time =    1280.79 ms<br>llama_print_timings:      sample time\
          \ =     112.96 ms /   256 runs   (    0.44 ms per token,  2266.25 tokens\
          \ per second)<br>llama_print_timings: prompt eval time =      33.17 ms /\
          \    75 tokens (    0.44 ms per token,  2260.81 tokens per second)<br>llama_print_timings:\
          \        eval time =    1147.97 ms /   255 runs   (    4.50 ms per token,\
          \   222.13 tokens per second)<br>llama_print_timings:       total time =\
          \    1359.18 ms<br>Log end</p>\n<p>Q4_0:</p>\n<p>system_info: n_threads\
          \ = 56 / 112 | AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI\
          \ = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD\
          \ = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 |<br>sampling:<br>   \
          \ repeat_last_n = 64, repeat_penalty = 1.100, frequency_penalty = 0.000,\
          \ presence_penalty = 0.000<br>    top_k = 40, tfs_z = 1.000, top_p = 0.950,\
          \ min_p = 0.050, typical_p = 1.000, temp = 0.800<br>    mirostat = 0, mirostat_lr\
          \ = 0.100, mirostat_ent = 5.000<br>generate: n_ctx = 512, n_batch = 512,\
          \ n_predict = 256, n_keep = 0</p>\n<p>You are an AI programming assistant,\
          \ utilizing the Deepseek Coder model, developed by Deepseek Company, and\
          \ you only answer questions related to computer science. For politically\
          \ sensitive questions, security and privacy issues, and other non-computer\
          \ science questions, you will refuse to answer.</p>\n<h3 id=\"instruction-1\"\
          >Instruction:</h3>\n<p>write a quick sort algorithm in python.</p>\n<h3\
          \ id=\"response-1\">Response:</h3>\n<p>Sure! Here's an implementation of\
          \ Quick Sort Algorithm using Python programming language as requested by\
          \ the problem statement. The <code>quick_sort</code> function takes two\
          \ arguments - list and start index (default is 0) to avoid passing unnecessary\
          \ parameters, which can save some time for large lists or when recursion\
          \ depth exceeded error occurs due to too many iterations:</p>\n<p>```python<br>def\
          \ quick_sort(arr):     # Input must be a sorted array. For non-sorted data\
          \ set the function will not work correctly but sort it with \"quick_sort\"\
          \ first before calling this method on your original list/array if you're\
          \ sure about input being already in order and want to save some time<br>\
          \    less = []            # List of elements smaller than pivot.  Initialised\
          \ as empty at start, so will always be sorted by recursive calls inside\
          \ quicksort(). These are the 'lesser-than' or lesser values we have yet\
          \ seen while partitioning around our chosen \"pivotal\" value in arr<br>\
          \    greater = []         # List of elements larger than pivot.  Initialised\
          \ as empty at start, so will always be sorted by recursive calls inside\
          \ quicksort(). These are the 'greater-than'<br>llama_print_timings:    \
          \    load time =     658.90 ms<br>llama_print_timings:      sample time\
          \ =      99.56 ms /   256 runs   (    0.39 ms per token,  2571.21 tokens\
          \ per second)<br>llama_print_timings: prompt eval time =      27.82 ms /\
          \    75 tokens (    0.37 ms per token,  2695.90 tokens per second)<br>llama_print_timings:\
          \        eval time =     940.49 ms /   255 runs   (    3.69 ms per token,\
          \   271.14 tokens per second)<br>llama_print_timings:       total time =\
          \    1133.29 ms<br>Log end</p>\n"
        raw: "Working fine in latest llama.cpp. Please report the issues to the respective\
          \ developers of those programs.\n\nAlso, try testing the non q-quants, like\
          \ Q4_0 or Q5_0, if you didn't already.\n\nThis is an unusual size model\
          \ and k-quants would not normally be supported for many of the layers, due\
          \ to them not being divisible by 256.  But due to a recent llama.cpp change,\
          \ those layers are now done using non-k-quant methods, like Q4_0.  This\
          \ enables me to make k-quants.  I don't know if that could cause issues\
          \ for clients besides llama.cpp, but it's worth mentioning.\n\nllama.cpp\
          \ tests:\n\nQ6_K:\nsystem_info: n_threads = 56 / 112 | AVX = 1 | AVX2 =\
          \ 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON =\
          \ 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 |\
          \ SSE3 = 1 | SSSE3 = 1 | VSX = 0 |\nsampling:\n\trepeat_last_n = 64, repeat_penalty\
          \ = 1.100, frequency_penalty = 0.000, presence_penalty = 0.000\n\ttop_k\
          \ = 40, tfs_z = 1.000, top_p = 0.950, min_p = 0.050, typical_p = 1.000,\
          \ temp = 0.800\n\tmirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000\n\
          generate: n_ctx = 512, n_batch = 512, n_predict = 256, n_keep = 0\n\n\n\
          You are an AI programming assistant, utilizing the Deepseek Coder model,\
          \ developed by Deepseek Company, and you only answer questions related to\
          \ computer science. For politically sensitive questions, security and privacy\
          \ issues, and other non-computer science questions, you will refuse to answer.\n\
          ### Instruction:\nwrite a quick sort algorithm in python.\n### Response:\n\
          Sure! Here is the Python implementation of Quick Sort Algorithm using recursion:\n\
          ```python\ndef quicksort(arr):\n    if len(arr) <= 1: # base case, return\
          \ array directly when length less than or equal to one (already sorted).\n\
          \        return arr\n    else:              # recurse on the rest of the\
          \ list.\n                        # pivot is always first element in partitioning\
          \ step for simplicity and efficiency reasons \u2013 usually randomized choice\
          \ as well!\n                      value_to_compare = arr[0]\n          \
          \        lower = [x for x in arr[1:] if x < value_to_compare]\n        \
          \         upper = [y for y in arr[1:] if y >=value_to_compare ]\n      \
          \               return quicksort(lower) + [value_to_compare] +quicksort(upper\
          \ )   # concatenate and sort the lists \u2013 this is our recursive call!\n\
          ```\nYou can run above function using: `print (quickSort([3,60,15])`. You\
          \ will get output as : '[27].' which means it sorts array correctly in asc\n\
          llama_print_timings:        load time =    1280.79 ms\nllama_print_timings:\
          \      sample time =     112.96 ms /   256 runs   (    0.44 ms per token,\
          \  2266.25 tokens per second)\nllama_print_timings: prompt eval time = \
          \     33.17 ms /    75 tokens (    0.44 ms per token,  2260.81 tokens per\
          \ second)\nllama_print_timings:        eval time =    1147.97 ms /   255\
          \ runs   (    4.50 ms per token,   222.13 tokens per second)\nllama_print_timings:\
          \       total time =    1359.18 ms\nLog end\n\nQ4_0:\n\n\nsystem_info: n_threads\
          \ = 56 / 112 | AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI\
          \ = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD\
          \ = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 |\nsampling:\n\trepeat_last_n\
          \ = 64, repeat_penalty = 1.100, frequency_penalty = 0.000, presence_penalty\
          \ = 0.000\n\ttop_k = 40, tfs_z = 1.000, top_p = 0.950, min_p = 0.050, typical_p\
          \ = 1.000, temp = 0.800\n\tmirostat = 0, mirostat_lr = 0.100, mirostat_ent\
          \ = 5.000\ngenerate: n_ctx = 512, n_batch = 512, n_predict = 256, n_keep\
          \ = 0\n\n\nYou are an AI programming assistant, utilizing the Deepseek Coder\
          \ model, developed by Deepseek Company, and you only answer questions related\
          \ to computer science. For politically sensitive questions, security and\
          \ privacy issues, and other non-computer science questions, you will refuse\
          \ to answer.\n### Instruction:\nwrite a quick sort algorithm in python.\n\
          ### Response:\nSure! Here's an implementation of Quick Sort Algorithm using\
          \ Python programming language as requested by the problem statement. The\
          \ `quick_sort` function takes two arguments - list and start index (default\
          \ is 0) to avoid passing unnecessary parameters, which can save some time\
          \ for large lists or when recursion depth exceeded error occurs due to too\
          \ many iterations:\n```python\ndef quick_sort(arr):     # Input must be\
          \ a sorted array. For non-sorted data set the function will not work correctly\
          \ but sort it with \"quick_sort\" first before calling this method on your\
          \ original list/array if you're sure about input being already in order\
          \ and want to save some time\n    less = []            # List of elements\
          \ smaller than pivot.  Initialised as empty at start, so will always be\
          \ sorted by recursive calls inside quicksort(). These are the 'lesser-than'\
          \ or lesser values we have yet seen while partitioning around our chosen\
          \ \"pivotal\" value in arr\n    greater = []         # List of elements\
          \ larger than pivot.  Initialised as empty at start, so will always be sorted\
          \ by recursive calls inside quicksort(). These are the 'greater-than'\n\
          llama_print_timings:        load time =     658.90 ms\nllama_print_timings:\
          \      sample time =      99.56 ms /   256 runs   (    0.39 ms per token,\
          \  2571.21 tokens per second)\nllama_print_timings: prompt eval time = \
          \     27.82 ms /    75 tokens (    0.37 ms per token,  2695.90 tokens per\
          \ second)\nllama_print_timings:        eval time =     940.49 ms /   255\
          \ runs   (    3.69 ms per token,   271.14 tokens per second)\nllama_print_timings:\
          \       total time =    1133.29 ms\nLog end"
        updatedAt: '2023-11-05T14:37:08.461Z'
      numEdits: 0
      reactions: []
    id: 6547a894b8ac1a89ff06661a
    type: comment
  author: TheBloke
  content: "Working fine in latest llama.cpp. Please report the issues to the respective\
    \ developers of those programs.\n\nAlso, try testing the non q-quants, like Q4_0\
    \ or Q5_0, if you didn't already.\n\nThis is an unusual size model and k-quants\
    \ would not normally be supported for many of the layers, due to them not being\
    \ divisible by 256.  But due to a recent llama.cpp change, those layers are now\
    \ done using non-k-quant methods, like Q4_0.  This enables me to make k-quants.\
    \  I don't know if that could cause issues for clients besides llama.cpp, but\
    \ it's worth mentioning.\n\nllama.cpp tests:\n\nQ6_K:\nsystem_info: n_threads\
    \ = 56 / 112 | AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI\
    \ = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD\
    \ = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 |\nsampling:\n\trepeat_last_n\
    \ = 64, repeat_penalty = 1.100, frequency_penalty = 0.000, presence_penalty =\
    \ 0.000\n\ttop_k = 40, tfs_z = 1.000, top_p = 0.950, min_p = 0.050, typical_p\
    \ = 1.000, temp = 0.800\n\tmirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000\n\
    generate: n_ctx = 512, n_batch = 512, n_predict = 256, n_keep = 0\n\n\nYou are\
    \ an AI programming assistant, utilizing the Deepseek Coder model, developed by\
    \ Deepseek Company, and you only answer questions related to computer science.\
    \ For politically sensitive questions, security and privacy issues, and other\
    \ non-computer science questions, you will refuse to answer.\n### Instruction:\n\
    write a quick sort algorithm in python.\n### Response:\nSure! Here is the Python\
    \ implementation of Quick Sort Algorithm using recursion:\n```python\ndef quicksort(arr):\n\
    \    if len(arr) <= 1: # base case, return array directly when length less than\
    \ or equal to one (already sorted).\n        return arr\n    else:           \
    \   # recurse on the rest of the list.\n                        # pivot is always\
    \ first element in partitioning step for simplicity and efficiency reasons \u2013\
    \ usually randomized choice as well!\n                      value_to_compare =\
    \ arr[0]\n                  lower = [x for x in arr[1:] if x < value_to_compare]\n\
    \                 upper = [y for y in arr[1:] if y >=value_to_compare ]\n    \
    \                 return quicksort(lower) + [value_to_compare] +quicksort(upper\
    \ )   # concatenate and sort the lists \u2013 this is our recursive call!\n```\n\
    You can run above function using: `print (quickSort([3,60,15])`. You will get\
    \ output as : '[27].' which means it sorts array correctly in asc\nllama_print_timings:\
    \        load time =    1280.79 ms\nllama_print_timings:      sample time =  \
    \   112.96 ms /   256 runs   (    0.44 ms per token,  2266.25 tokens per second)\n\
    llama_print_timings: prompt eval time =      33.17 ms /    75 tokens (    0.44\
    \ ms per token,  2260.81 tokens per second)\nllama_print_timings:        eval\
    \ time =    1147.97 ms /   255 runs   (    4.50 ms per token,   222.13 tokens\
    \ per second)\nllama_print_timings:       total time =    1359.18 ms\nLog end\n\
    \nQ4_0:\n\n\nsystem_info: n_threads = 56 / 112 | AVX = 1 | AVX2 = 1 | AVX512 =\
    \ 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C\
    \ = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX =\
    \ 0 |\nsampling:\n\trepeat_last_n = 64, repeat_penalty = 1.100, frequency_penalty\
    \ = 0.000, presence_penalty = 0.000\n\ttop_k = 40, tfs_z = 1.000, top_p = 0.950,\
    \ min_p = 0.050, typical_p = 1.000, temp = 0.800\n\tmirostat = 0, mirostat_lr\
    \ = 0.100, mirostat_ent = 5.000\ngenerate: n_ctx = 512, n_batch = 512, n_predict\
    \ = 256, n_keep = 0\n\n\nYou are an AI programming assistant, utilizing the Deepseek\
    \ Coder model, developed by Deepseek Company, and you only answer questions related\
    \ to computer science. For politically sensitive questions, security and privacy\
    \ issues, and other non-computer science questions, you will refuse to answer.\n\
    ### Instruction:\nwrite a quick sort algorithm in python.\n### Response:\nSure!\
    \ Here's an implementation of Quick Sort Algorithm using Python programming language\
    \ as requested by the problem statement. The `quick_sort` function takes two arguments\
    \ - list and start index (default is 0) to avoid passing unnecessary parameters,\
    \ which can save some time for large lists or when recursion depth exceeded error\
    \ occurs due to too many iterations:\n```python\ndef quick_sort(arr):     # Input\
    \ must be a sorted array. For non-sorted data set the function will not work correctly\
    \ but sort it with \"quick_sort\" first before calling this method on your original\
    \ list/array if you're sure about input being already in order and want to save\
    \ some time\n    less = []            # List of elements smaller than pivot. \
    \ Initialised as empty at start, so will always be sorted by recursive calls inside\
    \ quicksort(). These are the 'lesser-than' or lesser values we have yet seen while\
    \ partitioning around our chosen \"pivotal\" value in arr\n    greater = []  \
    \       # List of elements larger than pivot.  Initialised as empty at start,\
    \ so will always be sorted by recursive calls inside quicksort(). These are the\
    \ 'greater-than'\nllama_print_timings:        load time =     658.90 ms\nllama_print_timings:\
    \      sample time =      99.56 ms /   256 runs   (    0.39 ms per token,  2571.21\
    \ tokens per second)\nllama_print_timings: prompt eval time =      27.82 ms /\
    \    75 tokens (    0.37 ms per token,  2695.90 tokens per second)\nllama_print_timings:\
    \        eval time =     940.49 ms /   255 runs   (    3.69 ms per token,   271.14\
    \ tokens per second)\nllama_print_timings:       total time =    1133.29 ms\n\
    Log end"
  created_at: 2023-11-05 14:37:08+00:00
  edited: false
  hidden: false
  id: 6547a894b8ac1a89ff06661a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/64ac7b4159bd86340458e53d3e30aee2.svg
      fullname: Bumba
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pumba2
      type: user
    createdAt: '2023-11-05T14:39:20.000Z'
    data:
      edited: false
      editors:
      - Pumba2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9240480065345764
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/64ac7b4159bd86340458e53d3e30aee2.svg
          fullname: Bumba
          isHf: false
          isPro: false
          name: Pumba2
          type: user
        html: '<p>ok thanks for the fast reply. Have a good Sunday !</p>

          '
        raw: ok thanks for the fast reply. Have a good Sunday !
        updatedAt: '2023-11-05T14:39:20.311Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - TheBloke
    id: 6547a918117ecae648e7f543
    type: comment
  author: Pumba2
  content: ok thanks for the fast reply. Have a good Sunday !
  created_at: 2023-11-05 14:39:20+00:00
  edited: false
  hidden: false
  id: 6547a918117ecae648e7f543
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/deepseek-coder-1.3b-instruct-GGUF
repo_type: model
status: open
target_branch: null
title: Crashes or generates gibberish
