!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rkfg
conflicting_files: null
created_at: 2023-09-07 11:43:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2eddc1e4ee95f9530567448534fbbdb2.svg
      fullname: rkfg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rkfg
      type: user
    createdAt: '2023-09-07T12:43:15.000Z'
    data:
      edited: false
      editors:
      - rkfg
      hidden: false
      identifiedLanguage:
        language: ru
        probability: 0.9920150637626648
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2eddc1e4ee95f9530567448534fbbdb2.svg
          fullname: rkfg
          isHf: false
          isPro: false
          name: rkfg
          type: user
        html: "<p>\u042F \u043F\u0435\u0440\u0435\u043F\u0440\u043E\u0431\u043E\u0432\
          \u0430\u043B \u0440\u0430\u0437\u043D\u044B\u0435 \u0432\u0430\u0440\u0438\
          \u0430\u043D\u0442\u044B \u0432 oobabooga, \u0441 monkey patch \u0438 \u0431\
          \u0435\u0437, \u043C\u043E\u0434\u0435\u043B\u044C \u0437\u0430\u0433\u0440\
          \u0443\u0436\u0430\u0435\u0442\u0441\u044F \u0442\u043E\u043B\u044C\u043A\
          \u043E \u0447\u0435\u0440\u0435\u0437 AutoGPTQ, \u043D\u043E \u043F\u0440\
          \u0438 \u043E\u0431\u0443\u0447\u0435\u043D\u0438\u0438 \u043B\u043E\u0440\
          \u044B \u043F\u0440\u043E\u0438\u0441\u0445\u043E\u0434\u0438\u0442 \u043E\
          \u0448\u0438\u0431\u043A\u0430: <code>ValueError: Target modules [\u2018\
          q_proj\u2019, \u2018v_proj\u2019] not found in the base model. Please check\
          \ the target modules and try again.</code>. \u041F\u0440\u0438 \u044D\u0442\
          \u043E\u043C, \u043B\u043E\u0440\u044B \u043D\u0430 LLaMA \u043E\u0431\u0443\
          \u0447\u0430\u0442\u044C \u043F\u043E\u043B\u0443\u0447\u0430\u043B\u043E\
          \u0441\u044C, \u043D\u043E \u0442\u0443\u0442 \u043C\u043E\u0434\u0435\u043B\
          \u044C \u0434\u0440\u0443\u0433\u043E\u0439 \u0430\u0440\u0445\u0438\u0442\
          \u0435\u043A\u0442\u0443\u0440\u044B, GPT-2 (\u0445\u043E\u0442\u044F \u043C\
          \u043E\u0434\u0435\u043B\u044C \u0438 \u043D\u0430\u0437\u044B\u0432\u0430\
          \u0435\u0442\u0441\u044F GPT-3.5), \u0447\u0442\u043E, \u0432\u0438\u0434\
          \u0438\u043C\u043E, \u0438 \u0432\u044B\u0437\u044B\u0432\u0430\u0435\u0442\
          \ \u043E\u0448\u0438\u0431\u043A\u0443. \u0418\u043D\u0444\u043E\u0440\u043C\
          \u0430\u0446\u0438\u044E \u043F\u043E \u043E\u0431\u0443\u0447\u0435\u043D\
          \u0438\u044E \u0438\u043C\u0435\u043D\u043D\u043E \u043B\u043E\u0440\u044B\
          \ \u0442\u043E\u0436\u0435 \u043D\u0430\u0439\u0442\u0438 \u043D\u0435 \u0443\
          \u0434\u0430\u043B\u043E\u0441\u044C, \u0435\u0441\u0442\u044C \u043F\u043E\
          \u043B\u043D\u044B\u0439 \u0444\u0430\u0439\u043D\u0442\u044E\u043D\u0438\
          \u043D\u0433, \u043D\u043E \u0442\u043E\u0436\u0435 \u0434\u043B\u044F \u0441\
          \u0442\u0430\u0440\u044B\u0445 GPT-3 (\u0438\u043B\u0438 2, \u043C\u0443\
          \u0442\u043D\u043E \u0443 \u043D\u0438\u0445 \u0441 \u044D\u0442\u0438\u043C\
          \ \u043A\u0430\u043A-\u0442\u043E). \u0418\u043B\u0438 \u0435\u0441\u0442\
          \u044C \u043E\u0442\u0434\u0435\u043B\u044C\u043D\u044B\u0435 \u0441\u043A\
          \u0440\u0438\u043F\u0442\u044B \u0434\u043B\u044F \u044D\u0442\u043E\u0433\
          \u043E?</p>\n"
        raw: "\u042F \u043F\u0435\u0440\u0435\u043F\u0440\u043E\u0431\u043E\u0432\u0430\
          \u043B \u0440\u0430\u0437\u043D\u044B\u0435 \u0432\u0430\u0440\u0438\u0430\
          \u043D\u0442\u044B \u0432 oobabooga, \u0441 monkey patch \u0438 \u0431\u0435\
          \u0437, \u043C\u043E\u0434\u0435\u043B\u044C \u0437\u0430\u0433\u0440\u0443\
          \u0436\u0430\u0435\u0442\u0441\u044F \u0442\u043E\u043B\u044C\u043A\u043E\
          \ \u0447\u0435\u0440\u0435\u0437 AutoGPTQ, \u043D\u043E \u043F\u0440\u0438\
          \ \u043E\u0431\u0443\u0447\u0435\u043D\u0438\u0438 \u043B\u043E\u0440\u044B\
          \ \u043F\u0440\u043E\u0438\u0441\u0445\u043E\u0434\u0438\u0442 \u043E\u0448\
          \u0438\u0431\u043A\u0430: `ValueError: Target modules [\u2018q_proj\u2019\
          , \u2018v_proj\u2019] not found in the base model. Please check the target\
          \ modules and try again.`. \u041F\u0440\u0438 \u044D\u0442\u043E\u043C,\
          \ \u043B\u043E\u0440\u044B \u043D\u0430 LLaMA \u043E\u0431\u0443\u0447\u0430\
          \u0442\u044C \u043F\u043E\u043B\u0443\u0447\u0430\u043B\u043E\u0441\u044C\
          , \u043D\u043E \u0442\u0443\u0442 \u043C\u043E\u0434\u0435\u043B\u044C \u0434\
          \u0440\u0443\u0433\u043E\u0439 \u0430\u0440\u0445\u0438\u0442\u0435\u043A\
          \u0442\u0443\u0440\u044B, GPT-2 (\u0445\u043E\u0442\u044F \u043C\u043E\u0434\
          \u0435\u043B\u044C \u0438 \u043D\u0430\u0437\u044B\u0432\u0430\u0435\u0442\
          \u0441\u044F GPT-3.5), \u0447\u0442\u043E, \u0432\u0438\u0434\u0438\u043C\
          \u043E, \u0438 \u0432\u044B\u0437\u044B\u0432\u0430\u0435\u0442 \u043E\u0448\
          \u0438\u0431\u043A\u0443. \u0418\u043D\u0444\u043E\u0440\u043C\u0430\u0446\
          \u0438\u044E \u043F\u043E \u043E\u0431\u0443\u0447\u0435\u043D\u0438\u044E\
          \ \u0438\u043C\u0435\u043D\u043D\u043E \u043B\u043E\u0440\u044B \u0442\u043E\
          \u0436\u0435 \u043D\u0430\u0439\u0442\u0438 \u043D\u0435 \u0443\u0434\u0430\
          \u043B\u043E\u0441\u044C, \u0435\u0441\u0442\u044C \u043F\u043E\u043B\u043D\
          \u044B\u0439 \u0444\u0430\u0439\u043D\u0442\u044E\u043D\u0438\u043D\u0433\
          , \u043D\u043E \u0442\u043E\u0436\u0435 \u0434\u043B\u044F \u0441\u0442\u0430\
          \u0440\u044B\u0445 GPT-3 (\u0438\u043B\u0438 2, \u043C\u0443\u0442\u043D\
          \u043E \u0443 \u043D\u0438\u0445 \u0441 \u044D\u0442\u0438\u043C \u043A\u0430\
          \u043A-\u0442\u043E). \u0418\u043B\u0438 \u0435\u0441\u0442\u044C \u043E\
          \u0442\u0434\u0435\u043B\u044C\u043D\u044B\u0435 \u0441\u043A\u0440\u0438\
          \u043F\u0442\u044B \u0434\u043B\u044F \u044D\u0442\u043E\u0433\u043E?"
        updatedAt: '2023-09-07T12:43:15.037Z'
      numEdits: 0
      reactions: []
    id: 64f9c5630681f130cc0a8e90
    type: comment
  author: rkfg
  content: "\u042F \u043F\u0435\u0440\u0435\u043F\u0440\u043E\u0431\u043E\u0432\u0430\
    \u043B \u0440\u0430\u0437\u043D\u044B\u0435 \u0432\u0430\u0440\u0438\u0430\u043D\
    \u0442\u044B \u0432 oobabooga, \u0441 monkey patch \u0438 \u0431\u0435\u0437,\
    \ \u043C\u043E\u0434\u0435\u043B\u044C \u0437\u0430\u0433\u0440\u0443\u0436\u0430\
    \u0435\u0442\u0441\u044F \u0442\u043E\u043B\u044C\u043A\u043E \u0447\u0435\u0440\
    \u0435\u0437 AutoGPTQ, \u043D\u043E \u043F\u0440\u0438 \u043E\u0431\u0443\u0447\
    \u0435\u043D\u0438\u0438 \u043B\u043E\u0440\u044B \u043F\u0440\u043E\u0438\u0441\
    \u0445\u043E\u0434\u0438\u0442 \u043E\u0448\u0438\u0431\u043A\u0430: `ValueError:\
    \ Target modules [\u2018q_proj\u2019, \u2018v_proj\u2019] not found in the base\
    \ model. Please check the target modules and try again.`. \u041F\u0440\u0438 \u044D\
    \u0442\u043E\u043C, \u043B\u043E\u0440\u044B \u043D\u0430 LLaMA \u043E\u0431\u0443\
    \u0447\u0430\u0442\u044C \u043F\u043E\u043B\u0443\u0447\u0430\u043B\u043E\u0441\
    \u044C, \u043D\u043E \u0442\u0443\u0442 \u043C\u043E\u0434\u0435\u043B\u044C \u0434\
    \u0440\u0443\u0433\u043E\u0439 \u0430\u0440\u0445\u0438\u0442\u0435\u043A\u0442\
    \u0443\u0440\u044B, GPT-2 (\u0445\u043E\u0442\u044F \u043C\u043E\u0434\u0435\u043B\
    \u044C \u0438 \u043D\u0430\u0437\u044B\u0432\u0430\u0435\u0442\u0441\u044F GPT-3.5),\
    \ \u0447\u0442\u043E, \u0432\u0438\u0434\u0438\u043C\u043E, \u0438 \u0432\u044B\
    \u0437\u044B\u0432\u0430\u0435\u0442 \u043E\u0448\u0438\u0431\u043A\u0443. \u0418\
    \u043D\u0444\u043E\u0440\u043C\u0430\u0446\u0438\u044E \u043F\u043E \u043E\u0431\
    \u0443\u0447\u0435\u043D\u0438\u044E \u0438\u043C\u0435\u043D\u043D\u043E \u043B\
    \u043E\u0440\u044B \u0442\u043E\u0436\u0435 \u043D\u0430\u0439\u0442\u0438 \u043D\
    \u0435 \u0443\u0434\u0430\u043B\u043E\u0441\u044C, \u0435\u0441\u0442\u044C \u043F\
    \u043E\u043B\u043D\u044B\u0439 \u0444\u0430\u0439\u043D\u0442\u044E\u043D\u0438\
    \u043D\u0433, \u043D\u043E \u0442\u043E\u0436\u0435 \u0434\u043B\u044F \u0441\u0442\
    \u0430\u0440\u044B\u0445 GPT-3 (\u0438\u043B\u0438 2, \u043C\u0443\u0442\u043D\
    \u043E \u0443 \u043D\u0438\u0445 \u0441 \u044D\u0442\u0438\u043C \u043A\u0430\u043A\
    -\u0442\u043E). \u0418\u043B\u0438 \u0435\u0441\u0442\u044C \u043E\u0442\u0434\
    \u0435\u043B\u044C\u043D\u044B\u0435 \u0441\u043A\u0440\u0438\u043F\u0442\u044B\
    \ \u0434\u043B\u044F \u044D\u0442\u043E\u0433\u043E?"
  created_at: 2023-09-07 11:43:15+00:00
  edited: false
  hidden: false
  id: 64f9c5630681f130cc0a8e90
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/634ac294574bb72b10f117a3/OmxgtLSViStxc1hLo7VSn.jpeg?w=200&h=200&f=face
      fullname: zlsl
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: zlsl
      type: user
    createdAt: '2023-09-07T13:06:04.000Z'
    data:
      edited: true
      editors:
      - zlsl
      hidden: false
      identifiedLanguage:
        language: ru
        probability: 0.9640699625015259
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/634ac294574bb72b10f117a3/OmxgtLSViStxc1hLo7VSn.jpeg?w=200&h=200&f=face
          fullname: zlsl
          isHf: false
          isPro: false
          name: zlsl
          type: user
        html: "<p>\u0414\u043B\u044F \u0441\u0442\u0430\u0440\u0442\u0430 \u043C\u043E\
          \u0436\u043D\u043E \u0432\u0437\u044F\u0442\u044C:</p>\n<p><a rel=\"nofollow\"\
          \ href=\"https://github.com/qwopqwop200/gptqlora\">https://github.com/qwopqwop200/gptqlora</a></p>\n\
          <p>\u041D\u043E \u043E\u043D \u043D\u0435\u043C\u043D\u043E\u0436\u043A\u043E\
          \ \u043A\u0440\u0438\u0432\u043E\u0439 \u0438 \u043D\u0443\u0436\u043D\u043E\
          \ \u0438\u0441\u043F\u043E\u043B\u044C\u0437\u043E\u0432\u0430\u0442\u044C\
          \ PEFT \u0432\u0435\u0440\u0441\u0438\u0438 0.4.0, \u0432 \u0441\u0432\u0435\
          \u0436\u0435\u0439 \u043F\u043E\u043B\u043E\u043C\u0430\u043B\u0438 \u0434\
          \u043B\u044F GPT2<br>pip install peft==0.4.0</p>\n<p>\u0412\u043E\u0437\u043C\
          \u043E\u0436\u043D\u043E PEFT 0.4.0 \u0438 \u0434\u043B\u044F ooaboga \u043F\
          \u043E\u0434\u043E\u0439\u0434\u0451\u0442</p>\n"
        raw: "\u0414\u043B\u044F \u0441\u0442\u0430\u0440\u0442\u0430 \u043C\u043E\
          \u0436\u043D\u043E \u0432\u0437\u044F\u0442\u044C:\n\nhttps://github.com/qwopqwop200/gptqlora\n\
          \n\u041D\u043E \u043E\u043D \u043D\u0435\u043C\u043D\u043E\u0436\u043A\u043E\
          \ \u043A\u0440\u0438\u0432\u043E\u0439 \u0438 \u043D\u0443\u0436\u043D\u043E\
          \ \u0438\u0441\u043F\u043E\u043B\u044C\u0437\u043E\u0432\u0430\u0442\u044C\
          \ PEFT \u0432\u0435\u0440\u0441\u0438\u0438 0.4.0, \u0432 \u0441\u0432\u0435\
          \u0436\u0435\u0439 \u043F\u043E\u043B\u043E\u043C\u0430\u043B\u0438 \u0434\
          \u043B\u044F GPT2\npip install peft==0.4.0\n\n\n\u0412\u043E\u0437\u043C\
          \u043E\u0436\u043D\u043E PEFT 0.4.0 \u0438 \u0434\u043B\u044F ooaboga \u043F\
          \u043E\u0434\u043E\u0439\u0434\u0451\u0442"
        updatedAt: '2023-09-07T13:06:50.721Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - rkfg
    id: 64f9cabc056a85eb49d2c0f1
    type: comment
  author: zlsl
  content: "\u0414\u043B\u044F \u0441\u0442\u0430\u0440\u0442\u0430 \u043C\u043E\u0436\
    \u043D\u043E \u0432\u0437\u044F\u0442\u044C:\n\nhttps://github.com/qwopqwop200/gptqlora\n\
    \n\u041D\u043E \u043E\u043D \u043D\u0435\u043C\u043D\u043E\u0436\u043A\u043E \u043A\
    \u0440\u0438\u0432\u043E\u0439 \u0438 \u043D\u0443\u0436\u043D\u043E \u0438\u0441\
    \u043F\u043E\u043B\u044C\u0437\u043E\u0432\u0430\u0442\u044C PEFT \u0432\u0435\
    \u0440\u0441\u0438\u0438 0.4.0, \u0432 \u0441\u0432\u0435\u0436\u0435\u0439 \u043F\
    \u043E\u043B\u043E\u043C\u0430\u043B\u0438 \u0434\u043B\u044F GPT2\npip install\
    \ peft==0.4.0\n\n\n\u0412\u043E\u0437\u043C\u043E\u0436\u043D\u043E PEFT 0.4.0\
    \ \u0438 \u0434\u043B\u044F ooaboga \u043F\u043E\u0434\u043E\u0439\u0434\u0451\
    \u0442"
  created_at: 2023-09-07 12:06:04+00:00
  edited: true
  hidden: false
  id: 64f9cabc056a85eb49d2c0f1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2eddc1e4ee95f9530567448534fbbdb2.svg
      fullname: rkfg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rkfg
      type: user
    createdAt: '2023-09-07T13:46:15.000Z'
    data:
      edited: true
      editors:
      - rkfg
      hidden: false
      identifiedLanguage:
        language: ru
        probability: 0.9468068480491638
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2eddc1e4ee95f9530567448534fbbdb2.svg
          fullname: rkfg
          isHf: false
          isPro: false
          name: rkfg
          type: user
        html: "<p>\u0421\u043F\u0430\u0441\u0438\u0431\u043E! \u041F\u043E\u043B\u0443\
          \u0447\u0438\u043B\u043E\u0441\u044C \u0437\u0430\u043F\u0443\u0441\u0442\
          \u0438\u0442\u044C \u043E\u0431\u0443\u0447\u0435\u043D\u0438\u0435 \u0447\
          \u0435\u0440\u0435\u0437 oobabooga \u043D\u0430 \u0432\u0430\u0448\u0435\
          \u0439 \u043C\u043E\u0434\u0435\u043B\u0438 zlsl/l_erotic_kink_chat, \u0437\
          \u0430\u0433\u0440\u0443\u0437\u0438\u0432 \u0435\u0451 \u0447\u0435\u0440\
          \u0435\u0437 Transformers, \u043F\u0440\u043E\u0431\u043B\u0435\u043C\u0430\
          \ \u043F\u0440\u043E\u044F\u0432\u043B\u044F\u043B\u0430\u0441\u044C \u043D\
          \u0430 fffrrt/ruGPT-3.5-13B-GPTQ \u2014&nbsp;\u0432\u0438\u0434\u0438\u043C\
          \u043E, \u0442\u0430\u043C \u043A\u0430\u043A-\u0442\u043E \u0438\u043D\u0430\
          \u0447\u0435 \u043A\u0432\u0430\u043D\u0442\u0438\u0437\u043E\u0432\u0430\
          \u043D\u043E (\u043E\u043D\u0430 \u0437\u0430\u0433\u0440\u0443\u0436\u0430\
          \u0435\u0442\u0441\u044F \u0442\u043E\u043B\u044C\u043A\u043E \u0447\u0435\
          \u0440\u0435\u0437 AutoGPTQ). \u041F\u043E\u043F\u0440\u043E\u0431\u0443\
          \u044E \u0435\u0449\u0451 iashchak/ruGPT-3.5-13B-gptq-4bits.</p>\n"
        raw: "\u0421\u043F\u0430\u0441\u0438\u0431\u043E! \u041F\u043E\u043B\u0443\
          \u0447\u0438\u043B\u043E\u0441\u044C \u0437\u0430\u043F\u0443\u0441\u0442\
          \u0438\u0442\u044C \u043E\u0431\u0443\u0447\u0435\u043D\u0438\u0435 \u0447\
          \u0435\u0440\u0435\u0437 oobabooga \u043D\u0430 \u0432\u0430\u0448\u0435\
          \u0439 \u043C\u043E\u0434\u0435\u043B\u0438 zlsl/l_erotic_kink_chat, \u0437\
          \u0430\u0433\u0440\u0443\u0437\u0438\u0432 \u0435\u0451 \u0447\u0435\u0440\
          \u0435\u0437 Transformers, \u043F\u0440\u043E\u0431\u043B\u0435\u043C\u0430\
          \ \u043F\u0440\u043E\u044F\u0432\u043B\u044F\u043B\u0430\u0441\u044C \u043D\
          \u0430 fffrrt/ruGPT-3.5-13B-GPTQ \u2014\_\u0432\u0438\u0434\u0438\u043C\u043E\
          , \u0442\u0430\u043C \u043A\u0430\u043A-\u0442\u043E \u0438\u043D\u0430\u0447\
          \u0435 \u043A\u0432\u0430\u043D\u0442\u0438\u0437\u043E\u0432\u0430\u043D\
          \u043E (\u043E\u043D\u0430 \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0435\
          \u0442\u0441\u044F \u0442\u043E\u043B\u044C\u043A\u043E \u0447\u0435\u0440\
          \u0435\u0437 AutoGPTQ). \u041F\u043E\u043F\u0440\u043E\u0431\u0443\u044E\
          \ \u0435\u0449\u0451 iashchak/ruGPT-3.5-13B-gptq-4bits."
        updatedAt: '2023-09-07T13:50:11.335Z'
      numEdits: 1
      reactions: []
    id: 64f9d42774b227f52cbd7aec
    type: comment
  author: rkfg
  content: "\u0421\u043F\u0430\u0441\u0438\u0431\u043E! \u041F\u043E\u043B\u0443\u0447\
    \u0438\u043B\u043E\u0441\u044C \u0437\u0430\u043F\u0443\u0441\u0442\u0438\u0442\
    \u044C \u043E\u0431\u0443\u0447\u0435\u043D\u0438\u0435 \u0447\u0435\u0440\u0435\
    \u0437 oobabooga \u043D\u0430 \u0432\u0430\u0448\u0435\u0439 \u043C\u043E\u0434\
    \u0435\u043B\u0438 zlsl/l_erotic_kink_chat, \u0437\u0430\u0433\u0440\u0443\u0437\
    \u0438\u0432 \u0435\u0451 \u0447\u0435\u0440\u0435\u0437 Transformers, \u043F\u0440\
    \u043E\u0431\u043B\u0435\u043C\u0430 \u043F\u0440\u043E\u044F\u0432\u043B\u044F\
    \u043B\u0430\u0441\u044C \u043D\u0430 fffrrt/ruGPT-3.5-13B-GPTQ \u2014\_\u0432\
    \u0438\u0434\u0438\u043C\u043E, \u0442\u0430\u043C \u043A\u0430\u043A-\u0442\u043E\
    \ \u0438\u043D\u0430\u0447\u0435 \u043A\u0432\u0430\u043D\u0442\u0438\u0437\u043E\
    \u0432\u0430\u043D\u043E (\u043E\u043D\u0430 \u0437\u0430\u0433\u0440\u0443\u0436\
    \u0430\u0435\u0442\u0441\u044F \u0442\u043E\u043B\u044C\u043A\u043E \u0447\u0435\
    \u0440\u0435\u0437 AutoGPTQ). \u041F\u043E\u043F\u0440\u043E\u0431\u0443\u044E\
    \ \u0435\u0449\u0451 iashchak/ruGPT-3.5-13B-gptq-4bits."
  created_at: 2023-09-07 12:46:15+00:00
  edited: true
  hidden: false
  id: 64f9d42774b227f52cbd7aec
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2eddc1e4ee95f9530567448534fbbdb2.svg
      fullname: rkfg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rkfg
      type: user
    createdAt: '2023-09-07T15:31:36.000Z'
    data:
      edited: false
      editors:
      - rkfg
      hidden: false
      identifiedLanguage:
        language: ru
        probability: 0.9976519346237183
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2eddc1e4ee95f9530567448534fbbdb2.svg
          fullname: rkfg
          isHf: false
          isPro: false
          name: rkfg
          type: user
        html: "<p>\u0410 \u043A\u0430\u043A\u0443\u044E \u0432\u044B \u0431\u0430\u0437\
          \u043E\u0432\u0443\u044E \u043C\u043E\u0434\u0435\u043B\u044C \u0438\u0441\
          \u043F\u043E\u043B\u044C\u0437\u043E\u0432\u0430\u043B\u0438 \u0434\u043B\
          \u044F \u043E\u0431\u0443\u0447\u0435\u043D\u0438\u044F? \u041F\u0440\u043E\
          \u0431\u0443\u044E \u0440\u0430\u0437\u043D\u044B\u0435, \u0432\u0435\u0437\
          \u0434\u0435 \u043A\u0430\u043A\u0438\u0435-\u0442\u043E \u043D\u044E\u0430\
          \u043D\u0441\u044B. \u0425\u043E\u0442\u0435\u043B\u043E\u0441\u044C \u0431\
          \u044B 4-\u0431\u0438\u0442\u043D\u0443\u044E ruGPT-3.5, \u043A\u043E\u0442\
          \u043E\u0440\u0443\u044E \u043C\u043E\u0436\u043D\u043E \u0437\u0430\u0433\
          \u0440\u0443\u0437\u0438\u0442\u044C \u0434\u043B\u044F \u043E\u0431\u0443\
          \u0447\u0435\u043D\u0438\u044F \u043B\u043E\u0440\u044B, gptqlora \u043D\
          \u0435 \u043C\u043E\u0436\u0435\u0442 \u0437\u0430\u0433\u0440\u0443\u0437\
          \u0438\u0442\u044C \u043D\u0438\u0447\u0435\u0433\u043E, \u043D\u0435 \u043D\
          \u0430\u0445\u043E\u0434\u0438\u0442 \u043D\u0435\u043A\u0438\u0435 \u0444\
          \u0430\u0439\u043B\u044B (\u0433\u0434\u0435-\u0442\u043E \u043A\u043E\u043D\
          \u0444\u0438\u0433 \u043A\u0432\u0430\u043D\u0442\u0438\u0437\u0430\u0446\
          \u0438\u0438, \u0430 \u0433\u0434\u0435-\u0442\u043E \u0432\u043E\u043E\u0431\
          \u0449\u0435 \u0431\u0435\u0437 \u0443\u0442\u043E\u0447\u043D\u0435\u043D\
          \u0438\u0439). \u0423 \u043C\u0435\u043D\u044F 3090 Ti \u0441 24 \u0413\u0431\
          , \u0442\u0430\u043A \u0447\u0442\u043E \u0442\u043E\u043B\u044C\u043A\u043E\
          \ \u043A\u0432\u0430\u043D\u0442\u0438\u0437\u043E\u0432\u0430\u043D\u043D\
          \u044B\u0435 \u043C\u043E\u0433\u0443\u0442 \u0438\u0441\u043F\u043E\u043B\
          \u044C\u0437\u043E\u0432\u0430\u0442\u044C, \u0431\u043E\u043B\u044C\u0448\
          \u0435 \u043D\u0438\u0447\u0435\u0433\u043E \u043D\u0435 \u0432\u043B\u0435\
          \u0437\u0435\u0442.</p>\n"
        raw: "\u0410 \u043A\u0430\u043A\u0443\u044E \u0432\u044B \u0431\u0430\u0437\
          \u043E\u0432\u0443\u044E \u043C\u043E\u0434\u0435\u043B\u044C \u0438\u0441\
          \u043F\u043E\u043B\u044C\u0437\u043E\u0432\u0430\u043B\u0438 \u0434\u043B\
          \u044F \u043E\u0431\u0443\u0447\u0435\u043D\u0438\u044F? \u041F\u0440\u043E\
          \u0431\u0443\u044E \u0440\u0430\u0437\u043D\u044B\u0435, \u0432\u0435\u0437\
          \u0434\u0435 \u043A\u0430\u043A\u0438\u0435-\u0442\u043E \u043D\u044E\u0430\
          \u043D\u0441\u044B. \u0425\u043E\u0442\u0435\u043B\u043E\u0441\u044C \u0431\
          \u044B 4-\u0431\u0438\u0442\u043D\u0443\u044E ruGPT-3.5, \u043A\u043E\u0442\
          \u043E\u0440\u0443\u044E \u043C\u043E\u0436\u043D\u043E \u0437\u0430\u0433\
          \u0440\u0443\u0437\u0438\u0442\u044C \u0434\u043B\u044F \u043E\u0431\u0443\
          \u0447\u0435\u043D\u0438\u044F \u043B\u043E\u0440\u044B, gptqlora \u043D\
          \u0435 \u043C\u043E\u0436\u0435\u0442 \u0437\u0430\u0433\u0440\u0443\u0437\
          \u0438\u0442\u044C \u043D\u0438\u0447\u0435\u0433\u043E, \u043D\u0435 \u043D\
          \u0430\u0445\u043E\u0434\u0438\u0442 \u043D\u0435\u043A\u0438\u0435 \u0444\
          \u0430\u0439\u043B\u044B (\u0433\u0434\u0435-\u0442\u043E \u043A\u043E\u043D\
          \u0444\u0438\u0433 \u043A\u0432\u0430\u043D\u0442\u0438\u0437\u0430\u0446\
          \u0438\u0438, \u0430 \u0433\u0434\u0435-\u0442\u043E \u0432\u043E\u043E\u0431\
          \u0449\u0435 \u0431\u0435\u0437 \u0443\u0442\u043E\u0447\u043D\u0435\u043D\
          \u0438\u0439). \u0423 \u043C\u0435\u043D\u044F 3090 Ti \u0441 24 \u0413\u0431\
          , \u0442\u0430\u043A \u0447\u0442\u043E \u0442\u043E\u043B\u044C\u043A\u043E\
          \ \u043A\u0432\u0430\u043D\u0442\u0438\u0437\u043E\u0432\u0430\u043D\u043D\
          \u044B\u0435 \u043C\u043E\u0433\u0443\u0442 \u0438\u0441\u043F\u043E\u043B\
          \u044C\u0437\u043E\u0432\u0430\u0442\u044C, \u0431\u043E\u043B\u044C\u0448\
          \u0435 \u043D\u0438\u0447\u0435\u0433\u043E \u043D\u0435 \u0432\u043B\u0435\
          \u0437\u0435\u0442."
        updatedAt: '2023-09-07T15:31:36.288Z'
      numEdits: 0
      reactions: []
    id: 64f9ecd838eb8c75eb321353
    type: comment
  author: rkfg
  content: "\u0410 \u043A\u0430\u043A\u0443\u044E \u0432\u044B \u0431\u0430\u0437\u043E\
    \u0432\u0443\u044E \u043C\u043E\u0434\u0435\u043B\u044C \u0438\u0441\u043F\u043E\
    \u043B\u044C\u0437\u043E\u0432\u0430\u043B\u0438 \u0434\u043B\u044F \u043E\u0431\
    \u0443\u0447\u0435\u043D\u0438\u044F? \u041F\u0440\u043E\u0431\u0443\u044E \u0440\
    \u0430\u0437\u043D\u044B\u0435, \u0432\u0435\u0437\u0434\u0435 \u043A\u0430\u043A\
    \u0438\u0435-\u0442\u043E \u043D\u044E\u0430\u043D\u0441\u044B. \u0425\u043E\u0442\
    \u0435\u043B\u043E\u0441\u044C \u0431\u044B 4-\u0431\u0438\u0442\u043D\u0443\u044E\
    \ ruGPT-3.5, \u043A\u043E\u0442\u043E\u0440\u0443\u044E \u043C\u043E\u0436\u043D\
    \u043E \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u044C \u0434\u043B\u044F\
    \ \u043E\u0431\u0443\u0447\u0435\u043D\u0438\u044F \u043B\u043E\u0440\u044B, gptqlora\
    \ \u043D\u0435 \u043C\u043E\u0436\u0435\u0442 \u0437\u0430\u0433\u0440\u0443\u0437\
    \u0438\u0442\u044C \u043D\u0438\u0447\u0435\u0433\u043E, \u043D\u0435 \u043D\u0430\
    \u0445\u043E\u0434\u0438\u0442 \u043D\u0435\u043A\u0438\u0435 \u0444\u0430\u0439\
    \u043B\u044B (\u0433\u0434\u0435-\u0442\u043E \u043A\u043E\u043D\u0444\u0438\u0433\
    \ \u043A\u0432\u0430\u043D\u0442\u0438\u0437\u0430\u0446\u0438\u0438, \u0430 \u0433\
    \u0434\u0435-\u0442\u043E \u0432\u043E\u043E\u0431\u0449\u0435 \u0431\u0435\u0437\
    \ \u0443\u0442\u043E\u0447\u043D\u0435\u043D\u0438\u0439). \u0423 \u043C\u0435\
    \u043D\u044F 3090 Ti \u0441 24 \u0413\u0431, \u0442\u0430\u043A \u0447\u0442\u043E\
    \ \u0442\u043E\u043B\u044C\u043A\u043E \u043A\u0432\u0430\u043D\u0442\u0438\u0437\
    \u043E\u0432\u0430\u043D\u043D\u044B\u0435 \u043C\u043E\u0433\u0443\u0442 \u0438\
    \u0441\u043F\u043E\u043B\u044C\u0437\u043E\u0432\u0430\u0442\u044C, \u0431\u043E\
    \u043B\u044C\u0448\u0435 \u043D\u0438\u0447\u0435\u0433\u043E \u043D\u0435 \u0432\
    \u043B\u0435\u0437\u0435\u0442."
  created_at: 2023-09-07 14:31:36+00:00
  edited: false
  hidden: false
  id: 64f9ecd838eb8c75eb321353
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/634ac294574bb72b10f117a3/OmxgtLSViStxc1hLo7VSn.jpeg?w=200&h=200&f=face
      fullname: zlsl
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: zlsl
      type: user
    createdAt: '2023-09-07T15:34:07.000Z'
    data:
      edited: false
      editors:
      - zlsl
      hidden: false
      identifiedLanguage:
        language: ru
        probability: 0.9857443571090698
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/634ac294574bb72b10f117a3/OmxgtLSViStxc1hLo7VSn.jpeg?w=200&h=200&f=face
          fullname: zlsl
          isHf: false
          isPro: false
          name: zlsl
          type: user
        html: "<p>\u041E\u0431\u0443\u0447\u0430\u044E \u043D\u0430 4-bit GPTQ, \u043D\
          \u0443\u0436\u043D\u043E \u0442\u043E\u043A\u0435\u043D\u0438\u0437\u0435\
          \u0440 \u043F\u043E\u0434\u043A\u0438\u043D\u0443\u0442\u044C, \u0435\u0441\
          \u043B\u0438 \u0435\u0433\u043E \u0442\u0430\u043C \u043D\u0435\u0442, \u0442\
          \u0430\u043A\u0436\u0435 base_model \u043D\u0443\u0436\u043D\u043E \u0443\
          \u043A\u0430\u0437\u0430\u0442\u044C, \u043B\u0438\u0431\u043E \u0441\u0438\
          \u043C\u043B\u0438\u043D\u043A \u0441\u0434\u0435\u043B\u0430\u0442\u044C\
          \ pytorch_model.bin<br>\u041C\u043E\u0434\u0435\u043B\u044C ruGPT-3.5-13B-GPTQ</p>\n"
        raw: "\u041E\u0431\u0443\u0447\u0430\u044E \u043D\u0430 4-bit GPTQ, \u043D\
          \u0443\u0436\u043D\u043E \u0442\u043E\u043A\u0435\u043D\u0438\u0437\u0435\
          \u0440 \u043F\u043E\u0434\u043A\u0438\u043D\u0443\u0442\u044C, \u0435\u0441\
          \u043B\u0438 \u0435\u0433\u043E \u0442\u0430\u043C \u043D\u0435\u0442, \u0442\
          \u0430\u043A\u0436\u0435 base_model \u043D\u0443\u0436\u043D\u043E \u0443\
          \u043A\u0430\u0437\u0430\u0442\u044C, \u043B\u0438\u0431\u043E \u0441\u0438\
          \u043C\u043B\u0438\u043D\u043A \u0441\u0434\u0435\u043B\u0430\u0442\u044C\
          \ pytorch_model.bin\n\u041C\u043E\u0434\u0435\u043B\u044C ruGPT-3.5-13B-GPTQ"
        updatedAt: '2023-09-07T15:34:07.203Z'
      numEdits: 0
      reactions: []
    id: 64f9ed6ff590462bc4a78cbb
    type: comment
  author: zlsl
  content: "\u041E\u0431\u0443\u0447\u0430\u044E \u043D\u0430 4-bit GPTQ, \u043D\u0443\
    \u0436\u043D\u043E \u0442\u043E\u043A\u0435\u043D\u0438\u0437\u0435\u0440 \u043F\
    \u043E\u0434\u043A\u0438\u043D\u0443\u0442\u044C, \u0435\u0441\u043B\u0438 \u0435\
    \u0433\u043E \u0442\u0430\u043C \u043D\u0435\u0442, \u0442\u0430\u043A\u0436\u0435\
    \ base_model \u043D\u0443\u0436\u043D\u043E \u0443\u043A\u0430\u0437\u0430\u0442\
    \u044C, \u043B\u0438\u0431\u043E \u0441\u0438\u043C\u043B\u0438\u043D\u043A \u0441\
    \u0434\u0435\u043B\u0430\u0442\u044C pytorch_model.bin\n\u041C\u043E\u0434\u0435\
    \u043B\u044C ruGPT-3.5-13B-GPTQ"
  created_at: 2023-09-07 14:34:07+00:00
  edited: false
  hidden: false
  id: 64f9ed6ff590462bc4a78cbb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2eddc1e4ee95f9530567448534fbbdb2.svg
      fullname: rkfg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rkfg
      type: user
    createdAt: '2023-09-07T15:40:21.000Z'
    data:
      edited: false
      editors:
      - rkfg
      hidden: false
      identifiedLanguage:
        language: ru
        probability: 0.42938342690467834
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2eddc1e4ee95f9530567448534fbbdb2.svg
          fullname: rkfg
          isHf: false
          isPro: false
          name: rkfg
          type: user
        html: "<p>\u0410 \u043C\u043E\u0436\u043D\u043E \u043F\u043E\u043B\u043D\u0443\
          \u044E \u043A\u043E\u043C\u0430\u043D\u0434\u0443 \u0434\u043B\u044F \u0437\
          \u0430\u043F\u0443\u0441\u043A\u0430? \u0412\u043E\u0442 \u0443 \u043C\u0435\
          \u043D\u044F \u0435\u0441\u0442\u044C \u0441\u043A\u0430\u0447\u0430\u043D\
          \u043D\u0430\u044F <code>fffrrt_ruGPT-3.5-13B-GPTQ</code>, \u0434\u0435\u043B\
          \u0430\u044E <code>python gptqlora.py --model_path fffrrt_ruGPT-3.5-13B-GPTQ</code>,\
          \ \u0440\u0435\u0437\u0443\u043B\u044C\u0442\u0430\u0442:</p>\n<pre><code>Traceback\
          \ (most recent call last):\n  File \"/mnt/2Tb/gptqlora/gptqlora.py\", line\
          \ 792, in &lt;module&gt;\n    train()\n  File \"/mnt/2Tb/gptqlora/gptqlora.py\"\
          , line 601, in train\n    model = get_accelerate_model(args, checkpoint_dir)\n\
          \  File \"/mnt/2Tb/gptqlora/gptqlora.py\", line 282, in get_accelerate_model\n\
          \    model = AutoGPTQForCausalLM.from_quantized(\n  File \"/mnt/2Tb/textgen/lib/python3.10/site-packages/auto_gptq/modeling/auto.py\"\
          , line 108, in from_quantized\n    return quant_func(\n  File \"/mnt/2Tb/textgen/lib/python3.10/site-packages/auto_gptq/modeling/_base.py\"\
          , line 791, in from_quantized\n    raise FileNotFoundError(f\"Could not\
          \ find model in {model_name_or_path}\")\nFileNotFoundError: Could not find\
          \ model in fffrrt_ruGPT-3.5-13B-GPTQ\n</code></pre>\n<p>\u041F\u0440\u043E\
          \u0431\u0443\u044E \u0434\u0440\u0443\u0433\u0443\u044E \u043C\u043E\u0434\
          \u0435\u043B\u044C: <code>python gptqlora.py --model_path iashchak_ruGPT-3.5-13B-gptq-4bits</code>\
          \ (\u0442\u0430\u043C \u043D\u0435 \u0445\u0432\u0430\u0442\u0430\u043B\u043E\
          \ <code>quantize_config.json</code>, \u0441\u043A\u043E\u043F\u0438\u0440\
          \u043E\u0432\u0430\u043B \u0438\u0437 \u043F\u0440\u0435\u0434\u044B\u0434\
          \u0443\u0449\u0435\u0439), \u0440\u0435\u0437\u0443\u043B\u044C\u0442\u0430\
          \u0442 \u0438\u0434\u0435\u043D\u0442\u0438\u0447\u043D\u044B\u0439 \u0442\
          \u043E\u043C\u0443, \u0447\u0442\u043E \u0432\u044B\u0448\u0435. \u041D\u0435\
          \ \u043F\u043E\u0439\u043C\u0443, \u0447\u0442\u043E \u0438\u043C\u0435\u043D\
          \u043D\u043E \u0435\u043C\u0443 \u043D\u0430\u0434\u043E.</p>\n"
        raw: "\u0410 \u043C\u043E\u0436\u043D\u043E \u043F\u043E\u043B\u043D\u0443\
          \u044E \u043A\u043E\u043C\u0430\u043D\u0434\u0443 \u0434\u043B\u044F \u0437\
          \u0430\u043F\u0443\u0441\u043A\u0430? \u0412\u043E\u0442 \u0443 \u043C\u0435\
          \u043D\u044F \u0435\u0441\u0442\u044C \u0441\u043A\u0430\u0447\u0430\u043D\
          \u043D\u0430\u044F `fffrrt_ruGPT-3.5-13B-GPTQ`, \u0434\u0435\u043B\u0430\
          \u044E `python gptqlora.py --model_path fffrrt_ruGPT-3.5-13B-GPTQ`, \u0440\
          \u0435\u0437\u0443\u043B\u044C\u0442\u0430\u0442:\n```\nTraceback (most\
          \ recent call last):\n  File \"/mnt/2Tb/gptqlora/gptqlora.py\", line 792,\
          \ in <module>\n    train()\n  File \"/mnt/2Tb/gptqlora/gptqlora.py\", line\
          \ 601, in train\n    model = get_accelerate_model(args, checkpoint_dir)\n\
          \  File \"/mnt/2Tb/gptqlora/gptqlora.py\", line 282, in get_accelerate_model\n\
          \    model = AutoGPTQForCausalLM.from_quantized(\n  File \"/mnt/2Tb/textgen/lib/python3.10/site-packages/auto_gptq/modeling/auto.py\"\
          , line 108, in from_quantized\n    return quant_func(\n  File \"/mnt/2Tb/textgen/lib/python3.10/site-packages/auto_gptq/modeling/_base.py\"\
          , line 791, in from_quantized\n    raise FileNotFoundError(f\"Could not\
          \ find model in {model_name_or_path}\")\nFileNotFoundError: Could not find\
          \ model in fffrrt_ruGPT-3.5-13B-GPTQ\n```\n\u041F\u0440\u043E\u0431\u0443\
          \u044E \u0434\u0440\u0443\u0433\u0443\u044E \u043C\u043E\u0434\u0435\u043B\
          \u044C: `python gptqlora.py --model_path iashchak_ruGPT-3.5-13B-gptq-4bits`\
          \ (\u0442\u0430\u043C \u043D\u0435 \u0445\u0432\u0430\u0442\u0430\u043B\u043E\
          \ `quantize_config.json`, \u0441\u043A\u043E\u043F\u0438\u0440\u043E\u0432\
          \u0430\u043B \u0438\u0437 \u043F\u0440\u0435\u0434\u044B\u0434\u0443\u0449\
          \u0435\u0439), \u0440\u0435\u0437\u0443\u043B\u044C\u0442\u0430\u0442 \u0438\
          \u0434\u0435\u043D\u0442\u0438\u0447\u043D\u044B\u0439 \u0442\u043E\u043C\
          \u0443, \u0447\u0442\u043E \u0432\u044B\u0448\u0435. \u041D\u0435 \u043F\
          \u043E\u0439\u043C\u0443, \u0447\u0442\u043E \u0438\u043C\u0435\u043D\u043D\
          \u043E \u0435\u043C\u0443 \u043D\u0430\u0434\u043E."
        updatedAt: '2023-09-07T15:40:21.036Z'
      numEdits: 0
      reactions: []
    id: 64f9eee582d310092651d4ee
    type: comment
  author: rkfg
  content: "\u0410 \u043C\u043E\u0436\u043D\u043E \u043F\u043E\u043B\u043D\u0443\u044E\
    \ \u043A\u043E\u043C\u0430\u043D\u0434\u0443 \u0434\u043B\u044F \u0437\u0430\u043F\
    \u0443\u0441\u043A\u0430? \u0412\u043E\u0442 \u0443 \u043C\u0435\u043D\u044F \u0435\
    \u0441\u0442\u044C \u0441\u043A\u0430\u0447\u0430\u043D\u043D\u0430\u044F `fffrrt_ruGPT-3.5-13B-GPTQ`,\
    \ \u0434\u0435\u043B\u0430\u044E `python gptqlora.py --model_path fffrrt_ruGPT-3.5-13B-GPTQ`,\
    \ \u0440\u0435\u0437\u0443\u043B\u044C\u0442\u0430\u0442:\n```\nTraceback (most\
    \ recent call last):\n  File \"/mnt/2Tb/gptqlora/gptqlora.py\", line 792, in <module>\n\
    \    train()\n  File \"/mnt/2Tb/gptqlora/gptqlora.py\", line 601, in train\n \
    \   model = get_accelerate_model(args, checkpoint_dir)\n  File \"/mnt/2Tb/gptqlora/gptqlora.py\"\
    , line 282, in get_accelerate_model\n    model = AutoGPTQForCausalLM.from_quantized(\n\
    \  File \"/mnt/2Tb/textgen/lib/python3.10/site-packages/auto_gptq/modeling/auto.py\"\
    , line 108, in from_quantized\n    return quant_func(\n  File \"/mnt/2Tb/textgen/lib/python3.10/site-packages/auto_gptq/modeling/_base.py\"\
    , line 791, in from_quantized\n    raise FileNotFoundError(f\"Could not find model\
    \ in {model_name_or_path}\")\nFileNotFoundError: Could not find model in fffrrt_ruGPT-3.5-13B-GPTQ\n\
    ```\n\u041F\u0440\u043E\u0431\u0443\u044E \u0434\u0440\u0443\u0433\u0443\u044E\
    \ \u043C\u043E\u0434\u0435\u043B\u044C: `python gptqlora.py --model_path iashchak_ruGPT-3.5-13B-gptq-4bits`\
    \ (\u0442\u0430\u043C \u043D\u0435 \u0445\u0432\u0430\u0442\u0430\u043B\u043E\
    \ `quantize_config.json`, \u0441\u043A\u043E\u043F\u0438\u0440\u043E\u0432\u0430\
    \u043B \u0438\u0437 \u043F\u0440\u0435\u0434\u044B\u0434\u0443\u0449\u0435\u0439\
    ), \u0440\u0435\u0437\u0443\u043B\u044C\u0442\u0430\u0442 \u0438\u0434\u0435\u043D\
    \u0442\u0438\u0447\u043D\u044B\u0439 \u0442\u043E\u043C\u0443, \u0447\u0442\u043E\
    \ \u0432\u044B\u0448\u0435. \u041D\u0435 \u043F\u043E\u0439\u043C\u0443, \u0447\
    \u0442\u043E \u0438\u043C\u0435\u043D\u043D\u043E \u0435\u043C\u0443 \u043D\u0430\
    \u0434\u043E."
  created_at: 2023-09-07 14:40:21+00:00
  edited: false
  hidden: false
  id: 64f9eee582d310092651d4ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2eddc1e4ee95f9530567448534fbbdb2.svg
      fullname: rkfg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rkfg
      type: user
    createdAt: '2023-09-07T15:52:37.000Z'
    data:
      edited: true
      editors:
      - rkfg
      hidden: false
      identifiedLanguage:
        language: ru
        probability: 0.7744976878166199
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2eddc1e4ee95f9530567448534fbbdb2.svg
          fullname: rkfg
          isHf: false
          isPro: false
          name: rkfg
          type: user
        html: "<p>\u0422\u0430\u043A, \u043A\u0430\u043A\u043E\u0439-\u0442\u043E\
          \ \u043F\u0440\u043E\u0433\u0440\u0435\u0441\u0441 \u0435\u0441\u0442\u044C\
          \ \u0441 <code>iashchak_ruGPT-3.5-13B-gptq-4bits</code> \u2014 \u0432 <code>quantize_config.json</code>\
          \ \u043F\u0440\u043E\u043F\u0438\u0441\u0430\u043B <code>\"model_file_base_name\"\
          : \"pytorch_model\"</code>, \u0441 <code>fffrrt_ruGPT-3.5-13B-GPTQ</code>\
          \ \u0440\u0435\u0448\u0430\u0435\u0442\u0441\u044F \u0434\u043E\u0431\u0430\
          \u0432\u043B\u0435\u043D\u0438\u0435\u043C <code>use_safetensors=True,</code>\
          \ \u0432 \u043F\u0430\u0440\u0430\u043C\u0435\u0442\u0440\u044B <code>AutoGPTQForCausalLM.from_quantized</code>\
          \ (\u0432 \u044D\u0442\u043E\u043C \u0441\u043B\u0443\u0447\u0430\u0435\
          \ \u043D\u0435 \u043D\u0430\u0434\u043E \u043C\u0435\u043D\u044F\u0442\u044C\
          \ <code>quantize_config.json</code>), \u043D\u043E \u043F\u0440\u0438 \u044D\
          \u0442\u043E\u043C \u043F\u0435\u0440\u0435\u0441\u0442\u0430\u0451\u0442\
          \ \u0440\u0430\u0431\u043E\u0442\u0430\u0442\u044C \u043F\u0435\u0440\u0432\
          \u0430\u044F \u043C\u043E\u0434\u0435\u043B\u044C \u2014&nbsp;\u0432\u0438\
          \u0434\u0438\u043C\u043E, \u043D\u0430\u0434\u043E \u044D\u0442\u043E \u0434\
          \u0435\u043B\u0430\u0442\u044C \u043F\u0430\u0440\u0430\u043C\u0435\u0442\
          \u0440\u043E\u043C \u043A\u043E\u043C\u0430\u043D\u0434\u043D\u043E\u0439\
          \ \u0441\u0442\u0440\u043E\u043A\u0438, \u0430\u0432\u0442\u043E\u0440 \u043F\
          \u043E\u043B\u0435\u043D\u0438\u043B\u0441\u044F...</p>\n"
        raw: "\u0422\u0430\u043A, \u043A\u0430\u043A\u043E\u0439-\u0442\u043E \u043F\
          \u0440\u043E\u0433\u0440\u0435\u0441\u0441 \u0435\u0441\u0442\u044C \u0441\
          \ `iashchak_ruGPT-3.5-13B-gptq-4bits` \u2014 \u0432 `quantize_config.json`\
          \ \u043F\u0440\u043E\u043F\u0438\u0441\u0430\u043B `\"model_file_base_name\"\
          : \"pytorch_model\"`, \u0441 `fffrrt_ruGPT-3.5-13B-GPTQ` \u0440\u0435\u0448\
          \u0430\u0435\u0442\u0441\u044F \u0434\u043E\u0431\u0430\u0432\u043B\u0435\
          \u043D\u0438\u0435\u043C `use_safetensors=True,` \u0432 \u043F\u0430\u0440\
          \u0430\u043C\u0435\u0442\u0440\u044B `AutoGPTQForCausalLM.from_quantized`\
          \ (\u0432 \u044D\u0442\u043E\u043C \u0441\u043B\u0443\u0447\u0430\u0435\
          \ \u043D\u0435 \u043D\u0430\u0434\u043E \u043C\u0435\u043D\u044F\u0442\u044C\
          \ `quantize_config.json`), \u043D\u043E \u043F\u0440\u0438 \u044D\u0442\u043E\
          \u043C \u043F\u0435\u0440\u0435\u0441\u0442\u0430\u0451\u0442 \u0440\u0430\
          \u0431\u043E\u0442\u0430\u0442\u044C \u043F\u0435\u0440\u0432\u0430\u044F\
          \ \u043C\u043E\u0434\u0435\u043B\u044C \u2014\_\u0432\u0438\u0434\u0438\u043C\
          \u043E, \u043D\u0430\u0434\u043E \u044D\u0442\u043E \u0434\u0435\u043B\u0430\
          \u0442\u044C \u043F\u0430\u0440\u0430\u043C\u0435\u0442\u0440\u043E\u043C\
          \ \u043A\u043E\u043C\u0430\u043D\u0434\u043D\u043E\u0439 \u0441\u0442\u0440\
          \u043E\u043A\u0438, \u0430\u0432\u0442\u043E\u0440 \u043F\u043E\u043B\u0435\
          \u043D\u0438\u043B\u0441\u044F..."
        updatedAt: '2023-09-07T15:53:40.509Z'
      numEdits: 1
      reactions: []
    id: 64f9f1c50aff1e3de5b35d55
    type: comment
  author: rkfg
  content: "\u0422\u0430\u043A, \u043A\u0430\u043A\u043E\u0439-\u0442\u043E \u043F\
    \u0440\u043E\u0433\u0440\u0435\u0441\u0441 \u0435\u0441\u0442\u044C \u0441 `iashchak_ruGPT-3.5-13B-gptq-4bits`\
    \ \u2014 \u0432 `quantize_config.json` \u043F\u0440\u043E\u043F\u0438\u0441\u0430\
    \u043B `\"model_file_base_name\": \"pytorch_model\"`, \u0441 `fffrrt_ruGPT-3.5-13B-GPTQ`\
    \ \u0440\u0435\u0448\u0430\u0435\u0442\u0441\u044F \u0434\u043E\u0431\u0430\u0432\
    \u043B\u0435\u043D\u0438\u0435\u043C `use_safetensors=True,` \u0432 \u043F\u0430\
    \u0440\u0430\u043C\u0435\u0442\u0440\u044B `AutoGPTQForCausalLM.from_quantized`\
    \ (\u0432 \u044D\u0442\u043E\u043C \u0441\u043B\u0443\u0447\u0430\u0435 \u043D\
    \u0435 \u043D\u0430\u0434\u043E \u043C\u0435\u043D\u044F\u0442\u044C `quantize_config.json`),\
    \ \u043D\u043E \u043F\u0440\u0438 \u044D\u0442\u043E\u043C \u043F\u0435\u0440\u0435\
    \u0441\u0442\u0430\u0451\u0442 \u0440\u0430\u0431\u043E\u0442\u0430\u0442\u044C\
    \ \u043F\u0435\u0440\u0432\u0430\u044F \u043C\u043E\u0434\u0435\u043B\u044C \u2014\
    \_\u0432\u0438\u0434\u0438\u043C\u043E, \u043D\u0430\u0434\u043E \u044D\u0442\u043E\
    \ \u0434\u0435\u043B\u0430\u0442\u044C \u043F\u0430\u0440\u0430\u043C\u0435\u0442\
    \u0440\u043E\u043C \u043A\u043E\u043C\u0430\u043D\u0434\u043D\u043E\u0439 \u0441\
    \u0442\u0440\u043E\u043A\u0438, \u0430\u0432\u0442\u043E\u0440 \u043F\u043E\u043B\
    \u0435\u043D\u0438\u043B\u0441\u044F..."
  created_at: 2023-09-07 14:52:37+00:00
  edited: true
  hidden: false
  id: 64f9f1c50aff1e3de5b35d55
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/634ac294574bb72b10f117a3/OmxgtLSViStxc1hLo7VSn.jpeg?w=200&h=200&f=face
      fullname: zlsl
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: zlsl
      type: user
    createdAt: '2023-09-07T16:27:12.000Z'
    data:
      edited: true
      editors:
      - zlsl
      hidden: false
      identifiedLanguage:
        language: ru
        probability: 0.11015064269304276
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/634ac294574bb72b10f117a3/OmxgtLSViStxc1hLo7VSn.jpeg?w=200&h=200&f=face
          fullname: zlsl
          isHf: false
          isPro: false
          name: zlsl
          type: user
        html: "<p>\u0417\u0430\u0433\u0440\u0443\u0437\u0438\u043B \u043C\u043E\u0434\
          \u0438\u0444\u0438\u0446\u0438\u0440\u043E\u0432\u0430\u043D\u043D\u044B\
          \u0439 _gptqlora.py</p>\n<p>\u0412 src - \u0438\u0441\u0445\u043E\u0434\u043D\
          \u0430\u044F \u043C\u043E\u0434\u0435\u043B\u044C<br>\u0412 src_lora \u043C\
          \u043E\u0436\u043D\u043E \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u044C\
          \ LoRA \u0434\u043B\u044F \u043F\u0440\u043E\u0434\u043E\u043B\u0436\u0435\
          \u043D\u0438\u044F \u0442\u0440\u0435\u043D\u0438\u0440\u043E\u0432\u043A\
          \u0438</p>\n<p>python _gptqlora.py <br>    --cache_dir .cache <br>    --logging_dir\
          \ $RUN_NAME <br>    --model_path src <br>    --dataset dataset <br>    --output_dir\
          \ \"$LORA_NAME\" <br>    --overwrite_output_dir True <br>    --do_train\
          \ <br>    --num_train_epochs 3 <br>    --report_to tensorboard <br>    --save_total_limit\
          \ 8 <br>    --per_device_train_batch_size \"$BATCH_SIZE\" <br>    --num_train_epochs\
          \ 1 <br>    --log_level detail <br>    --logging_strategy steps <br>   \
          \ --logging_first_step <br>    --logging_steps 2 <br>    --save_steps \"\
          $SAVE_STEPS\" <br>    --save_safetensors <br>    --gradient_checkpointing\
          \ True <br>    --gradient_accumulation_steps \"$GAS\" <br>    --lora_r \"\
          $RANK\" <br>    --lora_alpha \"$ALPHA\" <br>    --lora_dropout \"$DROPOUT\"\
          \ <br>    --learning_rate \"$LR\" <br>    --adam8bit <br>    --max_steps\
          \ \"$MAX_STEPS\" \\</p>\n"
        raw: "\u0417\u0430\u0433\u0440\u0443\u0437\u0438\u043B \u043C\u043E\u0434\u0438\
          \u0444\u0438\u0446\u0438\u0440\u043E\u0432\u0430\u043D\u043D\u044B\u0439\
          \ _gptqlora.py\n\n\u0412 src - \u0438\u0441\u0445\u043E\u0434\u043D\u0430\
          \u044F \u043C\u043E\u0434\u0435\u043B\u044C\n\u0412 src_lora \u043C\u043E\
          \u0436\u043D\u043E \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u044C LoRA\
          \ \u0434\u043B\u044F \u043F\u0440\u043E\u0434\u043E\u043B\u0436\u0435\u043D\
          \u0438\u044F \u0442\u0440\u0435\u043D\u0438\u0440\u043E\u0432\u043A\u0438\
          \n\n\npython _gptqlora.py \\\n\t--cache_dir .cache \\\n\t--logging_dir $RUN_NAME\
          \ \\\n\t--model_path src \\\n\t--dataset dataset \\\n\t--output_dir \"$LORA_NAME\"\
          \ \\\n\t--overwrite_output_dir True \\\n\t--do_train \\\n\t--num_train_epochs\
          \ 3 \\\n\t--report_to tensorboard \\\n\t--save_total_limit 8 \\\n\t--per_device_train_batch_size\
          \ \"$BATCH_SIZE\" \\\n\t--num_train_epochs 1 \\\n\t--log_level detail \\\
          \n\t--logging_strategy steps \\\n\t--logging_first_step \\\n\t--logging_steps\
          \ 2 \\\n\t--save_steps \"$SAVE_STEPS\" \\\n\t--save_safetensors \\\n\t--gradient_checkpointing\
          \ True \\\n\t--gradient_accumulation_steps \"$GAS\" \\\n\t--lora_r \"$RANK\"\
          \ \\\n\t--lora_alpha \"$ALPHA\" \\\n\t--lora_dropout \"$DROPOUT\" \\\n\t\
          --learning_rate \"$LR\" \\\n\t--adam8bit \\\n\t--max_steps \"$MAX_STEPS\"\
          \ \\\n"
        updatedAt: '2023-09-07T16:30:41.555Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - rkfg
    id: 64f9f9e03af0d763f8344954
    type: comment
  author: zlsl
  content: "\u0417\u0430\u0433\u0440\u0443\u0437\u0438\u043B \u043C\u043E\u0434\u0438\
    \u0444\u0438\u0446\u0438\u0440\u043E\u0432\u0430\u043D\u043D\u044B\u0439 _gptqlora.py\n\
    \n\u0412 src - \u0438\u0441\u0445\u043E\u0434\u043D\u0430\u044F \u043C\u043E\u0434\
    \u0435\u043B\u044C\n\u0412 src_lora \u043C\u043E\u0436\u043D\u043E \u043F\u043E\
    \u043B\u043E\u0436\u0438\u0442\u044C LoRA \u0434\u043B\u044F \u043F\u0440\u043E\
    \u0434\u043E\u043B\u0436\u0435\u043D\u0438\u044F \u0442\u0440\u0435\u043D\u0438\
    \u0440\u043E\u0432\u043A\u0438\n\n\npython _gptqlora.py \\\n\t--cache_dir .cache\
    \ \\\n\t--logging_dir $RUN_NAME \\\n\t--model_path src \\\n\t--dataset dataset\
    \ \\\n\t--output_dir \"$LORA_NAME\" \\\n\t--overwrite_output_dir True \\\n\t--do_train\
    \ \\\n\t--num_train_epochs 3 \\\n\t--report_to tensorboard \\\n\t--save_total_limit\
    \ 8 \\\n\t--per_device_train_batch_size \"$BATCH_SIZE\" \\\n\t--num_train_epochs\
    \ 1 \\\n\t--log_level detail \\\n\t--logging_strategy steps \\\n\t--logging_first_step\
    \ \\\n\t--logging_steps 2 \\\n\t--save_steps \"$SAVE_STEPS\" \\\n\t--save_safetensors\
    \ \\\n\t--gradient_checkpointing True \\\n\t--gradient_accumulation_steps \"$GAS\"\
    \ \\\n\t--lora_r \"$RANK\" \\\n\t--lora_alpha \"$ALPHA\" \\\n\t--lora_dropout\
    \ \"$DROPOUT\" \\\n\t--learning_rate \"$LR\" \\\n\t--adam8bit \\\n\t--max_steps\
    \ \"$MAX_STEPS\" \\\n"
  created_at: 2023-09-07 15:27:12+00:00
  edited: true
  hidden: false
  id: 64f9f9e03af0d763f8344954
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/634ac294574bb72b10f117a3/OmxgtLSViStxc1hLo7VSn.jpeg?w=200&h=200&f=face
      fullname: zlsl
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: zlsl
      type: user
    createdAt: '2023-09-07T16:30:07.000Z'
    data:
      edited: false
      editors:
      - zlsl
      hidden: false
      identifiedLanguage:
        language: ru
        probability: 0.5570585131645203
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/634ac294574bb72b10f117a3/OmxgtLSViStxc1hLo7VSn.jpeg?w=200&h=200&f=face
          fullname: zlsl
          isHf: false
          isPro: false
          name: zlsl
          type: user
        html: "<p>\u0434\u043B\u044F \u043E\u0431\u0443\u0447\u0435\u043D\u0438\u044F\
          \ - dataset.json \u0441 \u043F\u043E\u043B\u044F\u043C\u0438 input, output</p>\n"
        raw: "\u0434\u043B\u044F \u043E\u0431\u0443\u0447\u0435\u043D\u0438\u044F\
          \ - dataset.json \u0441 \u043F\u043E\u043B\u044F\u043C\u0438 input, output"
        updatedAt: '2023-09-07T16:30:07.739Z'
      numEdits: 0
      reactions: []
    id: 64f9fa8f944b18ae3b94c4d9
    type: comment
  author: zlsl
  content: "\u0434\u043B\u044F \u043E\u0431\u0443\u0447\u0435\u043D\u0438\u044F -\
    \ dataset.json \u0441 \u043F\u043E\u043B\u044F\u043C\u0438 input, output"
  created_at: 2023-09-07 15:30:07+00:00
  edited: false
  hidden: false
  id: 64f9fa8f944b18ae3b94c4d9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2eddc1e4ee95f9530567448534fbbdb2.svg
      fullname: rkfg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rkfg
      type: user
    createdAt: '2023-09-07T16:31:07.000Z'
    data:
      edited: false
      editors:
      - rkfg
      hidden: false
      identifiedLanguage:
        language: ru
        probability: 0.993704617023468
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2eddc1e4ee95f9530567448534fbbdb2.svg
          fullname: rkfg
          isHf: false
          isPro: false
          name: rkfg
          type: user
        html: "<p>\u0411\u043E\u043B\u044C\u0448\u043E\u0435 \u0441\u043F\u0430\u0441\
          \u0438\u0431\u043E! \u041F\u043E\u043F\u0440\u043E\u0431\u0443\u044E.</p>\n"
        raw: "\u0411\u043E\u043B\u044C\u0448\u043E\u0435 \u0441\u043F\u0430\u0441\u0438\
          \u0431\u043E! \u041F\u043E\u043F\u0440\u043E\u0431\u0443\u044E."
        updatedAt: '2023-09-07T16:31:07.131Z'
      numEdits: 0
      reactions: []
    id: 64f9facb5a0b4f7d96473d21
    type: comment
  author: rkfg
  content: "\u0411\u043E\u043B\u044C\u0448\u043E\u0435 \u0441\u043F\u0430\u0441\u0438\
    \u0431\u043E! \u041F\u043E\u043F\u0440\u043E\u0431\u0443\u044E."
  created_at: 2023-09-07 15:31:07+00:00
  edited: false
  hidden: false
  id: 64f9facb5a0b4f7d96473d21
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/634ac294574bb72b10f117a3/OmxgtLSViStxc1hLo7VSn.jpeg?w=200&h=200&f=face
      fullname: zlsl
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: zlsl
      type: user
    createdAt: '2023-09-07T16:31:59.000Z'
    data:
      edited: false
      editors:
      - zlsl
      hidden: false
      identifiedLanguage:
        language: ru
        probability: 0.9894863963127136
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/634ac294574bb72b10f117a3/OmxgtLSViStxc1hLo7VSn.jpeg?w=200&h=200&f=face
          fullname: zlsl
          isHf: false
          isPro: false
          name: zlsl
          type: user
        html: "<p>--adam8bit<br>\u0435\u0441\u043B\u0438 \u043F\u0430\u043C\u044F\u0442\
          \u0438 \u043C\u043D\u043E\u0433\u043E \u043C\u043E\u0436\u043D\u043E \u0443\
          \u0431\u0440\u0430\u0442\u044C</p>\n"
        raw: "--adam8bit\n\u0435\u0441\u043B\u0438 \u043F\u0430\u043C\u044F\u0442\u0438\
          \ \u043C\u043D\u043E\u0433\u043E \u043C\u043E\u0436\u043D\u043E \u0443\u0431\
          \u0440\u0430\u0442\u044C"
        updatedAt: '2023-09-07T16:31:59.340Z'
      numEdits: 0
      reactions: []
    id: 64f9faff5a0b4f7d9647451d
    type: comment
  author: zlsl
  content: "--adam8bit\n\u0435\u0441\u043B\u0438 \u043F\u0430\u043C\u044F\u0442\u0438\
    \ \u043C\u043D\u043E\u0433\u043E \u043C\u043E\u0436\u043D\u043E \u0443\u0431\u0440\
    \u0430\u0442\u044C"
  created_at: 2023-09-07 15:31:59+00:00
  edited: false
  hidden: false
  id: 64f9faff5a0b4f7d9647451d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: zlsl/ruGPT-3.5-13B-erotic-kink-chat-lora
repo_type: model
status: open
target_branch: null
title: "\u041A\u0430\u043A \u043E\u0431\u0443\u0447\u0430\u0442\u044C \u043B\u043E\
  \u0440\u0443?"
