!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TZ20
conflicting_files: null
created_at: 2023-09-15 01:04:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/702a3ecb99ecdb9cc9e5cbec7169ae54.svg
      fullname: T Zeng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TZ20
      type: user
    createdAt: '2023-09-15T02:04:24.000Z'
    data:
      edited: true
      editors:
      - TZ20
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8647730946540833
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/702a3ecb99ecdb9cc9e5cbec7169ae54.svg
          fullname: T Zeng
          isHf: false
          isPro: false
          name: TZ20
          type: user
        html: "<p>Hi, I'm loading this model using 4 bit quantization from huggingface.\
          \ Im using 4 T4 gpus:</p>\n<pre><code>model = LlamaForCausalLM.from_pretrained(\n\
          \    'Open-Orca/OpenOrca-Platypus2-13B',\n    load_in_4bit = True,\n   \
          \ torch_dtype = torch.float16,\n    device_map= 'auto')\n</code></pre>\n\
          <p>However, when I do model.generate, it is extremely slow compared to the\
          \ base LLama-2-13b-chat model. E.g. where the original llama 2 model might\
          \ take 2 min, this one takes 30 min.<br>Any reason for this?</p>\n"
        raw: "Hi, I'm loading this model using 4 bit quantization from huggingface.\
          \ Im using 4 T4 gpus:\n\n```\nmodel = LlamaForCausalLM.from_pretrained(\n\
          \    'Open-Orca/OpenOrca-Platypus2-13B',\n    load_in_4bit = True,\n   \
          \ torch_dtype = torch.float16,\n    device_map= 'auto')\n```\n\nHowever,\
          \ when I do model.generate, it is extremely slow compared to the base LLama-2-13b-chat\
          \ model. E.g. where the original llama 2 model might take 2 min, this one\
          \ takes 30 min. \nAny reason for this?"
        updatedAt: '2023-09-15T02:17:20.187Z'
      numEdits: 2
      reactions: []
    id: 6503bba8b4bbf29f8f33518b
    type: comment
  author: TZ20
  content: "Hi, I'm loading this model using 4 bit quantization from huggingface.\
    \ Im using 4 T4 gpus:\n\n```\nmodel = LlamaForCausalLM.from_pretrained(\n    'Open-Orca/OpenOrca-Platypus2-13B',\n\
    \    load_in_4bit = True,\n    torch_dtype = torch.float16,\n    device_map= 'auto')\n\
    ```\n\nHowever, when I do model.generate, it is extremely slow compared to the\
    \ base LLama-2-13b-chat model. E.g. where the original llama 2 model might take\
    \ 2 min, this one takes 30 min. \nAny reason for this?"
  created_at: 2023-09-15 01:04:24+00:00
  edited: true
  hidden: false
  id: 6503bba8b4bbf29f8f33518b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/635567189c72a7e742f1419c/tbfBz0furS-y4ISgoe6j0.jpeg?w=200&h=200&f=face
      fullname: Alpin
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: alpindale
      type: user
    createdAt: '2023-09-21T19:10:15.000Z'
    data:
      edited: false
      editors:
      - alpindale
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9053688645362854
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/635567189c72a7e742f1419c/tbfBz0furS-y4ISgoe6j0.jpeg?w=200&h=200&f=face
          fullname: Alpin
          isHf: false
          isPro: false
          name: alpindale
          type: user
        html: '<p>Try replacing your current configs with the updated <code>config.json</code>
          and <code>generation_config.json</code>. Looks like the cache was disabled,
          which usually leads to extreme slowdowns.</p>

          '
        raw: Try replacing your current configs with the updated `config.json` and
          `generation_config.json`. Looks like the cache was disabled, which usually
          leads to extreme slowdowns.
        updatedAt: '2023-09-21T19:10:15.668Z'
      numEdits: 0
      reactions: []
    id: 650c95175a8f0b335a2087e8
    type: comment
  author: alpindale
  content: Try replacing your current configs with the updated `config.json` and `generation_config.json`.
    Looks like the cache was disabled, which usually leads to extreme slowdowns.
  created_at: 2023-09-21 18:10:15+00:00
  edited: false
  hidden: false
  id: 650c95175a8f0b335a2087e8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/702a3ecb99ecdb9cc9e5cbec7169ae54.svg
      fullname: T Zeng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TZ20
      type: user
    createdAt: '2023-09-22T02:08:28.000Z'
    data:
      edited: false
      editors:
      - TZ20
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9818424582481384
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/702a3ecb99ecdb9cc9e5cbec7169ae54.svg
          fullname: T Zeng
          isHf: false
          isPro: false
          name: TZ20
          type: user
        html: '<p>Thanks, seemed to do the trick</p>

          '
        raw: Thanks, seemed to do the trick
        updatedAt: '2023-09-22T02:08:28.059Z'
      numEdits: 0
      reactions: []
      relatedEventId: 650cf71c664ad78790c971d6
    id: 650cf71c664ad78790c971d5
    type: comment
  author: TZ20
  content: Thanks, seemed to do the trick
  created_at: 2023-09-22 01:08:28+00:00
  edited: false
  hidden: false
  id: 650cf71c664ad78790c971d5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/702a3ecb99ecdb9cc9e5cbec7169ae54.svg
      fullname: T Zeng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TZ20
      type: user
    createdAt: '2023-09-22T02:08:28.000Z'
    data:
      status: closed
    id: 650cf71c664ad78790c971d6
    type: status-change
  author: TZ20
  created_at: 2023-09-22 01:08:28+00:00
  id: 650cf71c664ad78790c971d6
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: Open-Orca/OpenOrca-Platypus2-13B
repo_type: model
status: closed
target_branch: null
title: 'Extremely slow inference '
