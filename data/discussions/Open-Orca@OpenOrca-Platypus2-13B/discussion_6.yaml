!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nikjohn7
conflicting_files: null
created_at: 2023-08-19 16:14:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/BaM1AWo0MWmKM3qhpnIW1.png?w=200&h=200&f=face
      fullname: Nikhil John
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nikjohn7
      type: user
    createdAt: '2023-08-19T17:14:34.000Z'
    data:
      edited: true
      editors:
      - nikjohn7
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8166224360466003
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/BaM1AWo0MWmKM3qhpnIW1.png?w=200&h=200&f=face
          fullname: Nikhil John
          isHf: false
          isPro: false
          name: nikjohn7
          type: user
        html: '<p>On the <a href="https://huggingface.co/Open-Orca/OpenOrcaxOpenChat-Preview2-13B#prompt-template">OpenOrcaxOpenChat-Preview2-13B</a>
          model card, the following is described as the prompt template:</p>

          <pre><code># Single-turn V1 Llama 2

          tokenize("User: Hello&lt;|end_of_turn|&gt;Assistant:")

          # Result: [1, 4911, 29901, 15043, 32000, 4007, 22137, 29901]

          </code></pre>

          <p>So, if I want to fine-tune a QA dataset on this, is this the appropriate
          way to prompt it?</p>

          <pre><code>User: You will be provided with a multiple choice question followed
          by 3 choices, A,B and C. Give the letter of the option that correctly answers
          the given question. For example, if the correct option is B, then your answer
          should be B.

          Question: {prompt}

          A) {a}

          B) {b}

          C) {c}

          &lt;|end_of_turn|&gt;Assistant: {answer}

          </code></pre>

          <p>Or am I supposed to frame it in a different way?</p>

          '
        raw: 'On the [OpenOrcaxOpenChat-Preview2-13B](https://huggingface.co/Open-Orca/OpenOrcaxOpenChat-Preview2-13B#prompt-template)
          model card, the following is described as the prompt template:


          ```

          # Single-turn V1 Llama 2

          tokenize("User: Hello<|end_of_turn|>Assistant:")

          # Result: [1, 4911, 29901, 15043, 32000, 4007, 22137, 29901]

          ```


          So, if I want to fine-tune a QA dataset on this, is this the appropriate
          way to prompt it?


          ```

          User: You will be provided with a multiple choice question followed by 3
          choices, A,B and C. Give the letter of the option that correctly answers
          the given question. For example, if the correct option is B, then your answer
          should be B.

          Question: {prompt}

          A) {a}

          B) {b}

          C) {c}

          <|end_of_turn|>Assistant: {answer}

          ```


          Or am I supposed to frame it in a different way?'
        updatedAt: '2023-08-19T19:34:51.917Z'
      numEdits: 2
      reactions: []
    id: 64e0f87a97757ec05762df4d
    type: comment
  author: nikjohn7
  content: 'On the [OpenOrcaxOpenChat-Preview2-13B](https://huggingface.co/Open-Orca/OpenOrcaxOpenChat-Preview2-13B#prompt-template)
    model card, the following is described as the prompt template:


    ```

    # Single-turn V1 Llama 2

    tokenize("User: Hello<|end_of_turn|>Assistant:")

    # Result: [1, 4911, 29901, 15043, 32000, 4007, 22137, 29901]

    ```


    So, if I want to fine-tune a QA dataset on this, is this the appropriate way to
    prompt it?


    ```

    User: You will be provided with a multiple choice question followed by 3 choices,
    A,B and C. Give the letter of the option that correctly answers the given question.
    For example, if the correct option is B, then your answer should be B.

    Question: {prompt}

    A) {a}

    B) {b}

    C) {c}

    <|end_of_turn|>Assistant: {answer}

    ```


    Or am I supposed to frame it in a different way?'
  created_at: 2023-08-19 16:14:34+00:00
  edited: true
  hidden: false
  id: 64e0f87a97757ec05762df4d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: Open-Orca/OpenOrca-Platypus2-13B
repo_type: model
status: open
target_branch: null
title: Orca prompt template?
