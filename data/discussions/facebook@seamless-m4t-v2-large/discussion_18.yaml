!!python/object:huggingface_hub.community.DiscussionWithDetails
author: JaimeLugo
conflicting_files: null
created_at: 2023-12-08 15:52:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8613a2b60856b6d5a7b49c2fdf82f9e8.svg
      fullname: Jaime Lugo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JaimeLugo
      type: user
    createdAt: '2023-12-08T15:52:35.000Z'
    data:
      edited: false
      editors:
      - JaimeLugo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5876040458679199
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8613a2b60856b6d5a7b49c2fdf82f9e8.svg
          fullname: Jaime Lugo
          isHf: false
          isPro: false
          name: JaimeLugo
          type: user
        html: "<p>I have the code below and i am only interested in T2T format. I\
          \ am new so very likely i have a newbi mistake but i am not able to see\
          \ the tranlated text if its longer than 500 characters.... i only see the\
          \ first 400 char, anyone knows how to solve this?</p>\n<p>thanks!</p>\n\
          <p>def translate_text(text, src_lang, tgt_lang):<br>   processor = AutoProcessor.from_pretrained(\"\
          facebook/seamless-m4t-v2-large\")<br>   model = SeamlessM4Tv2Model.from_pretrained(\"\
          facebook/seamless-m4t-v2-large\")</p>\n<p>   text_inputs = processor(text\
          \ = text, src_lang=src_lang, return_tensors=\"pt\")<br>   output_tokens\
          \ = model.generate(**text_inputs, tgt_lang=tgt_lang, text_num_beams=5, generate_speech=False)<br>\
          \   translated_text = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)</p>\n\
          <p>   return translated_text\n   </p>\n"
        raw: "I have the code below and i am only interested in T2T format. I am new\
          \ so very likely i have a newbi mistake but i am not able to see the tranlated\
          \ text if its longer than 500 characters.... i only see the first 400 char,\
          \ anyone knows how to solve this?\r\n\r\nthanks!\r\n\r\n\r\ndef translate_text(text,\
          \ src_lang, tgt_lang):\r\n   processor = AutoProcessor.from_pretrained(\"\
          facebook/seamless-m4t-v2-large\")\r\n   model = SeamlessM4Tv2Model.from_pretrained(\"\
          facebook/seamless-m4t-v2-large\")\r\n\r\n   text_inputs = processor(text\
          \ = text, src_lang=src_lang, return_tensors=\"pt\")\r\n   output_tokens\
          \ = model.generate(**text_inputs, tgt_lang=tgt_lang, text_num_beams=5, generate_speech=False)\r\
          \n   translated_text = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\r\
          \n\r\n   return translated_text\r\n   "
        updatedAt: '2023-12-08T15:52:35.291Z'
      numEdits: 0
      reactions: []
    id: 65733bc3983403462af536e1
    type: comment
  author: JaimeLugo
  content: "I have the code below and i am only interested in T2T format. I am new\
    \ so very likely i have a newbi mistake but i am not able to see the tranlated\
    \ text if its longer than 500 characters.... i only see the first 400 char, anyone\
    \ knows how to solve this?\r\n\r\nthanks!\r\n\r\n\r\ndef translate_text(text,\
    \ src_lang, tgt_lang):\r\n   processor = AutoProcessor.from_pretrained(\"facebook/seamless-m4t-v2-large\"\
    )\r\n   model = SeamlessM4Tv2Model.from_pretrained(\"facebook/seamless-m4t-v2-large\"\
    )\r\n\r\n   text_inputs = processor(text = text, src_lang=src_lang, return_tensors=\"\
    pt\")\r\n   output_tokens = model.generate(**text_inputs, tgt_lang=tgt_lang, text_num_beams=5,\
    \ generate_speech=False)\r\n   translated_text = processor.decode(output_tokens[0].tolist()[0],\
    \ skip_special_tokens=True)\r\n\r\n   return translated_text\r\n   "
  created_at: 2023-12-08 15:52:35+00:00
  edited: false
  hidden: false
  id: 65733bc3983403462af536e1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/rInlJb_yskg0WJb61jvkz.png?w=200&h=200&f=face
      fullname: Victor Sung
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: noobmaster29
      type: user
    createdAt: '2024-01-14T09:37:34.000Z'
    data:
      edited: false
      editors:
      - noobmaster29
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7796061635017395
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/rInlJb_yskg0WJb61jvkz.png?w=200&h=200&f=face
          fullname: Victor Sung
          isHf: false
          isPro: false
          name: noobmaster29
          type: user
        html: "<p>It seems the default max_new_tokens is set to 256 for this model.\
          \ You can probably increase this but be mindful of your input token length\
          \ and the context length of the model (which I believe is 4096).</p>\n<p><a\
          \ href=\"https://huggingface.co/docs/transformers/main/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config.max_new_tokens\"\
          >max_new_tokens (int, optional, defaults to 256) \u2014 The maximum numbers\
          \ of text tokens to generate, ignoring the number of tokens in the prompt.</a></p>\n\
          <p>If you need to translate even longer text, probably best to chunk it\
          \ at like a period after its exceeded some length and loop over your entire\
          \ text.</p>\n"
        raw: "It seems the default max_new_tokens is set to 256 for this model. You\
          \ can probably increase this but be mindful of your input token length and\
          \ the context length of the model (which I believe is 4096).\n\n[max_new_tokens\
          \ (int, optional, defaults to 256) \u2014 The maximum numbers of text tokens\
          \ to generate, ignoring the number of tokens in the prompt.](https://huggingface.co/docs/transformers/main/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config.max_new_tokens)\n\
          \nIf you need to translate even longer text, probably best to chunk it at\
          \ like a period after its exceeded some length and loop over your entire\
          \ text."
        updatedAt: '2024-01-14T09:37:34.600Z'
      numEdits: 0
      reactions: []
    id: 65a3ab5e80e2523eeaf22f0b
    type: comment
  author: noobmaster29
  content: "It seems the default max_new_tokens is set to 256 for this model. You\
    \ can probably increase this but be mindful of your input token length and the\
    \ context length of the model (which I believe is 4096).\n\n[max_new_tokens (int,\
    \ optional, defaults to 256) \u2014 The maximum numbers of text tokens to generate,\
    \ ignoring the number of tokens in the prompt.](https://huggingface.co/docs/transformers/main/model_doc/seamless_m4t_v2#transformers.SeamlessM4Tv2Config.max_new_tokens)\n\
    \nIf you need to translate even longer text, probably best to chunk it at like\
    \ a period after its exceeded some length and loop over your entire text."
  created_at: 2024-01-14 09:37:34+00:00
  edited: false
  hidden: false
  id: 65a3ab5e80e2523eeaf22f0b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8613a2b60856b6d5a7b49c2fdf82f9e8.svg
      fullname: Jaime Lugo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JaimeLugo
      type: user
    createdAt: '2024-01-14T10:24:35.000Z'
    data:
      edited: false
      editors:
      - JaimeLugo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.967522144317627
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8613a2b60856b6d5a7b49c2fdf82f9e8.svg
          fullname: Jaime Lugo
          isHf: false
          isPro: false
          name: JaimeLugo
          type: user
        html: '<p>Thanks Noobmaster29! - I managed to increase the answer length simply
          with "max_new_tokens=1000".... this works very well, however, the model
          in general likes to cut sentences... perhaps if it feels the sentence has
          redundant words it simply ignores it.</p>

          '
        raw: Thanks Noobmaster29! - I managed to increase the answer length simply
          with "max_new_tokens=1000".... this works very well, however, the model
          in general likes to cut sentences... perhaps if it feels the sentence has
          redundant words it simply ignores it.
        updatedAt: '2024-01-14T10:24:35.327Z'
      numEdits: 0
      reactions: []
    id: 65a3b6634a68680500680a62
    type: comment
  author: JaimeLugo
  content: Thanks Noobmaster29! - I managed to increase the answer length simply with
    "max_new_tokens=1000".... this works very well, however, the model in general
    likes to cut sentences... perhaps if it feels the sentence has redundant words
    it simply ignores it.
  created_at: 2024-01-14 10:24:35+00:00
  edited: false
  hidden: false
  id: 65a3b6634a68680500680a62
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/rInlJb_yskg0WJb61jvkz.png?w=200&h=200&f=face
      fullname: Victor Sung
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: noobmaster29
      type: user
    createdAt: '2024-01-14T23:20:35.000Z'
    data:
      edited: false
      editors:
      - noobmaster29
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9711675643920898
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/rInlJb_yskg0WJb61jvkz.png?w=200&h=200&f=face
          fullname: Victor Sung
          isHf: false
          isPro: false
          name: noobmaster29
          type: user
        html: '<p>Hmmm, what language are you using? I''m finding some of the translation
          from English to Chinese somewhat questionable. Seems like the model does
          not like long sentences or really short phrases. </p>

          '
        raw: 'Hmmm, what language are you using? I''m finding some of the translation
          from English to Chinese somewhat questionable. Seems like the model does
          not like long sentences or really short phrases. '
        updatedAt: '2024-01-14T23:20:35.821Z'
      numEdits: 0
      reactions: []
    id: 65a46c433581a68c41156734
    type: comment
  author: noobmaster29
  content: 'Hmmm, what language are you using? I''m finding some of the translation
    from English to Chinese somewhat questionable. Seems like the model does not like
    long sentences or really short phrases. '
  created_at: 2024-01-14 23:20:35+00:00
  edited: false
  hidden: false
  id: 65a46c433581a68c41156734
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: facebook/seamless-m4t-v2-large
repo_type: model
status: open
target_branch: null
title: Anyone knows how to translate longer text? - I am new on this
