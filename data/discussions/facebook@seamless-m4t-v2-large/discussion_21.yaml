!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Nathan-Geo
conflicting_files: null
created_at: 2023-12-29 09:43:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/84f2c8b9b045eb5ead0b518bf4753294.svg
      fullname: Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nathan-Geo
      type: user
    createdAt: '2023-12-29T09:43:49.000Z'
    data:
      edited: false
      editors:
      - Nathan-Geo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7381994128227234
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/84f2c8b9b045eb5ead0b518bf4753294.svg
          fullname: Zhang
          isHf: false
          isPro: false
          name: Nathan-Geo
          type: user
        html: "<p>Hello, </p>\n<p>I met a issue that the long text will be truncated\
          \ when running TT2T task , the code is shown below. I tried to set max_new_tokens\
          \ or max_length to 4096,  both did not work.</p>\n<p>This text is extracted\
          \ from BBC news</p>\n<p>text = \"\"\"<br>Britain's most famous steam locomotive\
          \ turned 100 this year, and along the way it has inspired poets, Hitchcock,\
          \ Harry Potter and Royalty. What makes it such an enduring icon?</p>\n<p>Some\
          \ grow misty-eyed with nostalgia at the mere mention of them, waiting for\
          \ hours on a windy platform just to get a glimpse or a photo of these stars\
          \ of a bygone age.    </p>\n<p>Others find them smelly, dirty, and their\
          \ hooting and screeching too much to bear. </p>\n<p>We're talking about\
          \ steam engines, and although travelling by locomotive may be a rare treat\
          \ for most, the golden age of steam is being kept alive at the many heritage\
          \ railways around the world, with more than 30 still running in the UK alone.<br>\"\
          \"\"</p>\n<h1 id=\"process-input\">process input</h1>\n<p>text_inputs =\
          \ processor(text =text, src_lang=\"eng\", return_tensors=\"pt\").to(device)</p>\n\
          <p>gen_kwargs = {<br>    # \"max_length\": 4096<br>    \"max_new_tokens\"\
          : 4096<br>}<br>output_tokens = model.generate(**text_inputs, **gen_kwargs,\
          \ tgt_lang=\"cmn\", generate_speech=False)<br>translated_text_from_text\
          \ = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)<br>print(f\"\
          Translation from text: {translated_text_from_text}\")</p>\n<p>output_tokens\
          \ = model.generate(**text_inputs, **gen_kwargs, tgt_lang=\"cmn\", generate_speech=False)<br>translated_text_from_text\
          \ = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)<br>print(f\"\
          Translation from text: {translated_text_from_text}\")</p>\n<p>Translation\
          \ from text: \u82F1\u56FD\u6700\u8457\u540D\u7684\u84B8\u6C7D\u673A\u8F66\
          \u4ECA\u5E74\u5E74\u6EE1100\u5C81,\u5E76\u6FC0\u53D1\u4E86\u8BD7\u4EBA,\u5E0C\
          \u5947\u79D1\u514B,\u54C8\u5229\u6CE2\u7279\u548C\u7687\u5BB6\u7684\u7075\
          \u611F\u5B83\u662F\u4EC0\u4E48\u8BA9\u5B83\u6210\u4E3A\u5982\u6B64\u6301\
          \u4E45\u7684\u8C61\u5F81?\u6709\u4E9B\u4EBA\u4EC5\u4EC5\u5728\u63D0\u53CA\
          \u5B83\u4EEC\u65F6\u5C31\u611F\u5230\u6000\u5FF5,\u5728\u98CE\u7684\u5E73\
          \u53F0\u4E0A\u7B49\u4E86\u51E0\u4E2A\u5C0F\u65F6,\u53EA\u662F\u4E3A\u4E86\
          \u77A5\u89C1\u6216\u62CD\u6444\u8FD9\u4E9B\u8FC7\u53BB\u7684\u660E\u661F\
          \u7684\u7167\u7247.</p>\n"
        raw: "Hello, \r\n\r\nI met a issue that the long text will be truncated when\
          \ running TT2T task , the code is shown below. I tried to set max_new_tokens\
          \ or max_length to 4096,  both did not work.\r\n\r\nThis text is extracted\
          \ from BBC news\r\n\r\ntext = \"\"\"\r\nBritain's most famous steam locomotive\
          \ turned 100 this year, and along the way it has inspired poets, Hitchcock,\
          \ Harry Potter and Royalty. What makes it such an enduring icon?\r\n\r\n\
          Some grow misty-eyed with nostalgia at the mere mention of them, waiting\
          \ for hours on a windy platform just to get a glimpse or a photo of these\
          \ stars of a bygone age.    \r\n\r\nOthers find them smelly, dirty, and\
          \ their hooting and screeching too much to bear. \r\n\r\nWe're talking about\
          \ steam engines, and although travelling by locomotive may be a rare treat\
          \ for most, the golden age of steam is being kept alive at the many heritage\
          \ railways around the world, with more than 30 still running in the UK alone.\r\
          \n\"\"\"\r\n\r\n# process input\r\ntext_inputs = processor(text =text, src_lang=\"\
          eng\", return_tensors=\"pt\").to(device)\r\n\r\ngen_kwargs = {\r\n    #\
          \ \"max_length\": 4096\r\n    \"max_new_tokens\": 4096\r\n}\r\noutput_tokens\
          \ = model.generate(**text_inputs, **gen_kwargs, tgt_lang=\"cmn\", generate_speech=False)\r\
          \ntranslated_text_from_text = processor.decode(output_tokens[0].tolist()[0],\
          \ skip_special_tokens=True)\r\nprint(f\"Translation from text: {translated_text_from_text}\"\
          )\r\n\r\noutput_tokens = model.generate(**text_inputs, **gen_kwargs, tgt_lang=\"\
          cmn\", generate_speech=False)\r\ntranslated_text_from_text = processor.decode(output_tokens[0].tolist()[0],\
          \ skip_special_tokens=True)\r\nprint(f\"Translation from text: {translated_text_from_text}\"\
          )\r\n\r\n\r\nTranslation from text: \u82F1\u56FD\u6700\u8457\u540D\u7684\
          \u84B8\u6C7D\u673A\u8F66\u4ECA\u5E74\u5E74\u6EE1100\u5C81,\u5E76\u6FC0\u53D1\
          \u4E86\u8BD7\u4EBA,\u5E0C\u5947\u79D1\u514B,\u54C8\u5229\u6CE2\u7279\u548C\
          \u7687\u5BB6\u7684\u7075\u611F\u5B83\u662F\u4EC0\u4E48\u8BA9\u5B83\u6210\
          \u4E3A\u5982\u6B64\u6301\u4E45\u7684\u8C61\u5F81?\u6709\u4E9B\u4EBA\u4EC5\
          \u4EC5\u5728\u63D0\u53CA\u5B83\u4EEC\u65F6\u5C31\u611F\u5230\u6000\u5FF5\
          ,\u5728\u98CE<unk>\u7684\u5E73\u53F0\u4E0A\u7B49\u4E86\u51E0\u4E2A\u5C0F\
          \u65F6,\u53EA\u662F\u4E3A\u4E86\u77A5\u89C1\u6216\u62CD\u6444\u8FD9\u4E9B\
          \u8FC7\u53BB\u7684\u660E\u661F\u7684\u7167\u7247."
        updatedAt: '2023-12-29T09:43:49.571Z'
      numEdits: 0
      reactions: []
    id: 658e94d5a33889b27f3caeb6
    type: comment
  author: Nathan-Geo
  content: "Hello, \r\n\r\nI met a issue that the long text will be truncated when\
    \ running TT2T task , the code is shown below. I tried to set max_new_tokens or\
    \ max_length to 4096,  both did not work.\r\n\r\nThis text is extracted from BBC\
    \ news\r\n\r\ntext = \"\"\"\r\nBritain's most famous steam locomotive turned 100\
    \ this year, and along the way it has inspired poets, Hitchcock, Harry Potter\
    \ and Royalty. What makes it such an enduring icon?\r\n\r\nSome grow misty-eyed\
    \ with nostalgia at the mere mention of them, waiting for hours on a windy platform\
    \ just to get a glimpse or a photo of these stars of a bygone age.    \r\n\r\n\
    Others find them smelly, dirty, and their hooting and screeching too much to bear.\
    \ \r\n\r\nWe're talking about steam engines, and although travelling by locomotive\
    \ may be a rare treat for most, the golden age of steam is being kept alive at\
    \ the many heritage railways around the world, with more than 30 still running\
    \ in the UK alone.\r\n\"\"\"\r\n\r\n# process input\r\ntext_inputs = processor(text\
    \ =text, src_lang=\"eng\", return_tensors=\"pt\").to(device)\r\n\r\ngen_kwargs\
    \ = {\r\n    # \"max_length\": 4096\r\n    \"max_new_tokens\": 4096\r\n}\r\noutput_tokens\
    \ = model.generate(**text_inputs, **gen_kwargs, tgt_lang=\"cmn\", generate_speech=False)\r\
    \ntranslated_text_from_text = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\r\
    \nprint(f\"Translation from text: {translated_text_from_text}\")\r\n\r\noutput_tokens\
    \ = model.generate(**text_inputs, **gen_kwargs, tgt_lang=\"cmn\", generate_speech=False)\r\
    \ntranslated_text_from_text = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\r\
    \nprint(f\"Translation from text: {translated_text_from_text}\")\r\n\r\n\r\nTranslation\
    \ from text: \u82F1\u56FD\u6700\u8457\u540D\u7684\u84B8\u6C7D\u673A\u8F66\u4ECA\
    \u5E74\u5E74\u6EE1100\u5C81,\u5E76\u6FC0\u53D1\u4E86\u8BD7\u4EBA,\u5E0C\u5947\u79D1\
    \u514B,\u54C8\u5229\u6CE2\u7279\u548C\u7687\u5BB6\u7684\u7075\u611F\u5B83\u662F\
    \u4EC0\u4E48\u8BA9\u5B83\u6210\u4E3A\u5982\u6B64\u6301\u4E45\u7684\u8C61\u5F81\
    ?\u6709\u4E9B\u4EBA\u4EC5\u4EC5\u5728\u63D0\u53CA\u5B83\u4EEC\u65F6\u5C31\u611F\
    \u5230\u6000\u5FF5,\u5728\u98CE<unk>\u7684\u5E73\u53F0\u4E0A\u7B49\u4E86\u51E0\
    \u4E2A\u5C0F\u65F6,\u53EA\u662F\u4E3A\u4E86\u77A5\u89C1\u6216\u62CD\u6444\u8FD9\
    \u4E9B\u8FC7\u53BB\u7684\u660E\u661F\u7684\u7167\u7247."
  created_at: 2023-12-29 09:43:49+00:00
  edited: false
  hidden: false
  id: 658e94d5a33889b27f3caeb6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 21
repo_id: facebook/seamless-m4t-v2-large
repo_type: model
status: open
target_branch: null
title: translated text is not complete
