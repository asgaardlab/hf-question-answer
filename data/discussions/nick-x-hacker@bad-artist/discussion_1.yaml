!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Kenkai
conflicting_files: null
created_at: 2022-12-15 15:11:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ecb29830bca7423661b57ddcbf115918.svg
      fullname: Yoshiro
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kenkai
      type: user
    createdAt: '2022-12-15T15:11:02.000Z'
    data:
      edited: false
      editors:
      - Kenkai
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ecb29830bca7423661b57ddcbf115918.svg
          fullname: Yoshiro
          isHf: false
          isPro: false
          name: Kenkai
          type: user
        html: '<p>Hey there, thanks for sharing this embedding. I have used it a bit
          and results are overall great. </p>

          <p>Just wanted to know how did you manage to create images shown in the
          model card. I tried using this embedding with AnythingV3, and exact same
          prompt (''solo'') and other params including seed as mentioned there, but
          results from those were not even close to as good as the ones shown. </p>

          <p>TIA</p>

          '
        raw: "Hey there, thanks for sharing this embedding. I have used it a bit and\
          \ results are overall great. \r\n\r\nJust wanted to know how did you manage\
          \ to create images shown in the model card. I tried using this embedding\
          \ with AnythingV3, and exact same prompt ('solo') and other params including\
          \ seed as mentioned there, but results from those were not even close to\
          \ as good as the ones shown. \r\n\r\nTIA"
        updatedAt: '2022-12-15T15:11:02.796Z'
      numEdits: 0
      reactions: []
    id: 639b3906e8c7ac902b745571
    type: comment
  author: Kenkai
  content: "Hey there, thanks for sharing this embedding. I have used it a bit and\
    \ results are overall great. \r\n\r\nJust wanted to know how did you manage to\
    \ create images shown in the model card. I tried using this embedding with AnythingV3,\
    \ and exact same prompt ('solo') and other params including seed as mentioned\
    \ there, but results from those were not even close to as good as the ones shown.\
    \ \r\n\r\nTIA"
  created_at: 2022-12-15 15:11:02+00:00
  edited: false
  hidden: false
  id: 639b3906e8c7ac902b745571
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5422efd4a00a4e44318d75a0118de747.svg
      fullname: Nick
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nick-x-hacker
      type: user
    createdAt: '2022-12-16T04:16:17.000Z'
    data:
      edited: true
      editors:
      - nick-x-hacker
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5422efd4a00a4e44318d75a0118de747.svg
          fullname: Nick
          isHf: false
          isPro: false
          name: nick-x-hacker
          type: user
        html: '<p>For pure anything, yes just ''solo'' won''t work. Anything is a
          model that, no matter what negative prompt you use, you will need a stronger
          positive prompt (but not by much). For example, adding ''masterpiece, best
          quality and 1girl'' gives me much better results.</p>

          <pre><code>masterpiece, best quality, solo 1girl

          Negative prompt: sketch by bad-artist

          Steps: 10, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 3638101479, Size:
          448x576, Model hash: 7ab762a7, Model: anything, Batch size: 9, Batch pos:
          0, Clip skip: 2

          </code></pre>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1671163985140-63977b5339b41b16c43c61eb.png"><img
          alt="TdSzvoG0IX.png" src="https://cdn-uploads.huggingface.co/production/uploads/1671163985140-63977b5339b41b16c43c61eb.png"></a></p>

          <p>If you use the model that I trained on, you can go with just ''solo''.
          The model in question is ''blossom-extract'', you can make it by following
          the 1-step recipie:<br>[Add Difference, A=AnythingV3, B=F222, C=SD1.4, M=1.0].</p>

          '
        raw: 'For pure anything, yes just ''solo'' won''t work. Anything is a model
          that, no matter what negative prompt you use, you will need a stronger positive
          prompt (but not by much). For example, adding ''masterpiece, best quality
          and 1girl'' gives me much better results.

          ```

          masterpiece, best quality, solo 1girl

          Negative prompt: sketch by bad-artist

          Steps: 10, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 3638101479, Size:
          448x576, Model hash: 7ab762a7, Model: anything, Batch size: 9, Batch pos:
          0, Clip skip: 2

          ```

          ![TdSzvoG0IX.png](https://cdn-uploads.huggingface.co/production/uploads/1671163985140-63977b5339b41b16c43c61eb.png)


          If you use the model that I trained on, you can go with just ''solo''. The
          model in question is ''blossom-extract'', you can make it by following the
          1-step recipie:

          [Add Difference, A=AnythingV3, B=F222, C=SD1.4, M=1.0].'
        updatedAt: '2022-12-16T04:18:18.844Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Kenkai
    id: 639bf11134967bcf4563065d
    type: comment
  author: nick-x-hacker
  content: 'For pure anything, yes just ''solo'' won''t work. Anything is a model
    that, no matter what negative prompt you use, you will need a stronger positive
    prompt (but not by much). For example, adding ''masterpiece, best quality and
    1girl'' gives me much better results.

    ```

    masterpiece, best quality, solo 1girl

    Negative prompt: sketch by bad-artist

    Steps: 10, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 3638101479, Size: 448x576,
    Model hash: 7ab762a7, Model: anything, Batch size: 9, Batch pos: 0, Clip skip:
    2

    ```

    ![TdSzvoG0IX.png](https://cdn-uploads.huggingface.co/production/uploads/1671163985140-63977b5339b41b16c43c61eb.png)


    If you use the model that I trained on, you can go with just ''solo''. The model
    in question is ''blossom-extract'', you can make it by following the 1-step recipie:

    [Add Difference, A=AnythingV3, B=F222, C=SD1.4, M=1.0].'
  created_at: 2022-12-16 04:16:17+00:00
  edited: true
  hidden: false
  id: 639bf11134967bcf4563065d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ecb29830bca7423661b57ddcbf115918.svg
      fullname: Yoshiro
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kenkai
      type: user
    createdAt: '2022-12-16T14:26:56.000Z'
    data:
      edited: false
      editors:
      - Kenkai
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ecb29830bca7423661b57ddcbf115918.svg
          fullname: Yoshiro
          isHf: false
          isPro: false
          name: Kenkai
          type: user
        html: '<p>Gotcha , thanks for the explanation and examples. Really love the
          results I''m getting with this &lt;3</p>

          '
        raw: Gotcha , thanks for the explanation and examples. Really love the results
          I'm getting with this <3
        updatedAt: '2022-12-16T14:26:56.010Z'
      numEdits: 0
      reactions: []
    id: 639c80308a34ed9a404e42ef
    type: comment
  author: Kenkai
  content: Gotcha , thanks for the explanation and examples. Really love the results
    I'm getting with this <3
  created_at: 2022-12-16 14:26:56+00:00
  edited: false
  hidden: false
  id: 639c80308a34ed9a404e42ef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673152930410-noauth.png?w=200&h=200&f=face
      fullname: Joey Rattana
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AkogareCafe
      type: user
    createdAt: '2023-01-08T05:30:49.000Z'
    data:
      edited: true
      editors:
      - AkogareCafe
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673152930410-noauth.png?w=200&h=200&f=face
          fullname: Joey Rattana
          isHf: false
          isPro: false
          name: AkogareCafe
          type: user
        html: '<p>Hi, I''ve been on a journey to increase the quality as I have seen
          on other posts but copying the settings always seems to give a lower quality
          result than the post. I am also trying to get the results of the model card
          image, but the quality seems worse than that?<br>I am using Anythingv3 and
          this embedding with the same settings.<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1673155523254-63ba49b1205688cd2f9811dd.png"><img
          alt="stablediffusion.png" src="https://cdn-uploads.huggingface.co/production/uploads/1673155523254-63ba49b1205688cd2f9811dd.png"></a><br>Another
          attempt with the settings you provided above.<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1673155988844-63ba49b1205688cd2f9811dd.png"><img
          alt="stablediffusion.png" src="https://cdn-uploads.huggingface.co/production/uploads/1673155988844-63ba49b1205688cd2f9811dd.png"></a></p>

          '
        raw: "Hi, I've been on a journey to increase the quality as I have seen on\
          \ other posts but copying the settings always seems to give a lower quality\
          \ result than the post. I am also trying to get the results of the model\
          \ card image, but the quality seems worse than that? \nI am using Anythingv3\
          \ and this embedding with the same settings.\n![stablediffusion.png](https://cdn-uploads.huggingface.co/production/uploads/1673155523254-63ba49b1205688cd2f9811dd.png)\n\
          Another attempt with the settings you provided above.\n![stablediffusion.png](https://cdn-uploads.huggingface.co/production/uploads/1673155988844-63ba49b1205688cd2f9811dd.png)"
        updatedAt: '2023-01-08T05:33:32.995Z'
      numEdits: 1
      reactions: []
    id: 63ba5509d86973cc3d2b93bc
    type: comment
  author: AkogareCafe
  content: "Hi, I've been on a journey to increase the quality as I have seen on other\
    \ posts but copying the settings always seems to give a lower quality result than\
    \ the post. I am also trying to get the results of the model card image, but the\
    \ quality seems worse than that? \nI am using Anythingv3 and this embedding with\
    \ the same settings.\n![stablediffusion.png](https://cdn-uploads.huggingface.co/production/uploads/1673155523254-63ba49b1205688cd2f9811dd.png)\n\
    Another attempt with the settings you provided above.\n![stablediffusion.png](https://cdn-uploads.huggingface.co/production/uploads/1673155988844-63ba49b1205688cd2f9811dd.png)"
  created_at: 2023-01-08 05:30:49+00:00
  edited: true
  hidden: false
  id: 63ba5509d86973cc3d2b93bc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5422efd4a00a4e44318d75a0118de747.svg
      fullname: Nick
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nick-x-hacker
      type: user
    createdAt: '2023-01-09T22:39:58.000Z'
    data:
      edited: true
      editors:
      - nick-x-hacker
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5422efd4a00a4e44318d75a0118de747.svg
          fullname: Nick
          isHf: false
          isPro: false
          name: nick-x-hacker
          type: user
        html: '<p>You are using pure anything, so you want CLIP Skip : 2 (settings
          -&gt; stable diffusion).</p>

          <pre><code>masterpiece, best quality, solo 1girl

          Negative prompt: sketch by bad-artist

          Steps: 10, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 3638101479, Size:
          448x576, Clip skip: 2

          </code></pre>

          <p>Paste that whole thing into your positive prompt, and click the blue
          arrow emoji on the right.</p>

          <p>Edit: also it looks like you are not using the VAE. download the .vae.pt
          file from anything-v3 huggingface and put it into models/VAE. then go into
          settings -&gt; stable diffusion and select the VAE you just downloaded and
          save.</p>

          '
        raw: 'You are using pure anything, so you want CLIP Skip : 2 (settings ->
          stable diffusion).


          ```

          masterpiece, best quality, solo 1girl

          Negative prompt: sketch by bad-artist

          Steps: 10, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 3638101479, Size:
          448x576, Clip skip: 2

          ```


          Paste that whole thing into your positive prompt, and click the blue arrow
          emoji on the right.


          Edit: also it looks like you are not using the VAE. download the .vae.pt
          file from anything-v3 huggingface and put it into models/VAE. then go into
          settings -> stable diffusion and select the VAE you just downloaded and
          save.'
        updatedAt: '2023-01-09T22:41:22.881Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - AkogareCafe
    id: 63bc97beebc6b720d610a632
    type: comment
  author: nick-x-hacker
  content: 'You are using pure anything, so you want CLIP Skip : 2 (settings -> stable
    diffusion).


    ```

    masterpiece, best quality, solo 1girl

    Negative prompt: sketch by bad-artist

    Steps: 10, Sampler: DPM++ 2M Karras, CFG scale: 4, Seed: 3638101479, Size: 448x576,
    Clip skip: 2

    ```


    Paste that whole thing into your positive prompt, and click the blue arrow emoji
    on the right.


    Edit: also it looks like you are not using the VAE. download the .vae.pt file
    from anything-v3 huggingface and put it into models/VAE. then go into settings
    -> stable diffusion and select the VAE you just downloaded and save.'
  created_at: 2023-01-09 22:39:58+00:00
  edited: true
  hidden: false
  id: 63bc97beebc6b720d610a632
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: nick-x-hacker/bad-artist
repo_type: model
status: open
target_branch: null
title: Unable to reproduce the results
