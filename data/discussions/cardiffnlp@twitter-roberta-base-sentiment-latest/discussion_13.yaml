!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Aqsa31
conflicting_files: null
created_at: 2023-06-30 21:15:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2d7d4ca268a946bd289963270e52a476.svg
      fullname: Aqsa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aqsa31
      type: user
    createdAt: '2023-06-30T22:15:56.000Z'
    data:
      edited: false
      editors:
      - Aqsa31
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.545716404914856
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2d7d4ca268a946bd289963270e52a476.svg
          fullname: Aqsa
          isHf: false
          isPro: false
          name: Aqsa31
          type: user
        html: '<p>Not sure what is going on but I tried to run the model on 20 rows
          of my dataset (normal dataset really) it crashed once or twice but then
          ran , I tried running it on full dataset 200 rows but it keeps killing my
          kernel on Jupiter notebook. Even the most simple sentence can''t be processed
          using this model now without crashing my kernel. Any leads? </p>

          <p>from transformers import AutoModelForSequenceClassification<br>from transformers
          import TFAutoModelForSequenceClassification<br>from transformers import
          AutoTokenizer, AutoConfig<br>import numpy as np<br>from scipy.special import
          softmax</p>

          <h1 id="preprocess-text-username-and-link-placeholders">Preprocess text
          (username and link placeholders)</h1>

          <p>def preprocess(text):<br>    new_text = []<br>    for t in text.split("
          "):<br>        t = ''@user'' if t.startswith(''@'') and len(t) &gt; 1 else
          t<br>        t = ''http'' if t.startswith(''http'') else t<br>        new_text.append(t)<br>    return
          " ".join(new_text)<br>MODEL = f"cardiffnlp/twitter-roberta-base-sentiment-latest"<br>tokenizer
          = AutoTokenizer.from_pretrained(MODEL)<br>config = AutoConfig.from_pretrained(MODEL)</p>

          <h1 id="pt">PT</h1>

          <p>model = AutoModelForSequenceClassification.from_pretrained(MODEL)<br>#model.save_pretrained(MODEL)<br>text
          = "Covid cases are increasing fast!"<br>text = preprocess(text)<br>encoded_input
          = tokenizer(text, return_tensors=''pt'')<br>output = model(**encoded_input)<br>scores
          = output[0][0].detach().numpy()<br>scores = softmax(scores)</p>

          <h1 id="-tf"># TF</h1>

          <h1 id="model--tfautomodelforsequenceclassificationfrom_pretrainedmodel">model
          = TFAutoModelForSequenceClassification.from_pretrained(MODEL)</h1>

          <h1 id="modelsave_pretrainedmodel">model.save_pretrained(MODEL)</h1>

          <h1 id="text--covid-cases-are-increasing-fast">text = "Covid cases are increasing
          fast!"</h1>

          <h1 id="encoded_input--tokenizertext-return_tensorstf">encoded_input = tokenizer(text,
          return_tensors=''tf'')</h1>

          <h1 id="output--modelencoded_input">output = model(encoded_input)</h1>

          <h1 id="scores--output00numpy">scores = output[0][0].numpy()</h1>

          <h1 id="scores--softmaxscores">scores = softmax(scores)</h1>

          <h1 id="print-labels-and-scores">Print labels and scores</h1>

          <p>ranking = np.argsort(scores)<br>ranking = ranking[::-1]<br>for i in range(scores.shape[0]):<br>    l
          = config.id2label[ranking[i]]<br>    s = scores[ranking[i]]<br>    print(f"{i+1})
          {l} {np.round(float(s), 4)}")</p>

          '
        raw: "Not sure what is going on but I tried to run the model on 20 rows of\
          \ my dataset (normal dataset really) it crashed once or twice but then ran\
          \ , I tried running it on full dataset 200 rows but it keeps killing my\
          \ kernel on Jupiter notebook. Even the most simple sentence can't be processed\
          \ using this model now without crashing my kernel. Any leads? \r\n\r\nfrom\
          \ transformers import AutoModelForSequenceClassification\r\nfrom transformers\
          \ import TFAutoModelForSequenceClassification\r\nfrom transformers import\
          \ AutoTokenizer, AutoConfig\r\nimport numpy as np\r\nfrom scipy.special\
          \ import softmax\r\n# Preprocess text (username and link placeholders)\r\
          \ndef preprocess(text):\r\n    new_text = []\r\n    for t in text.split(\"\
          \ \"):\r\n        t = '@user' if t.startswith('@') and len(t) > 1 else t\r\
          \n        t = 'http' if t.startswith('http') else t\r\n        new_text.append(t)\r\
          \n    return \" \".join(new_text)\r\nMODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\
          \r\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\r\nconfig = AutoConfig.from_pretrained(MODEL)\r\
          \n# PT\r\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL)\r\
          \n#model.save_pretrained(MODEL)\r\ntext = \"Covid cases are increasing fast!\"\
          \r\ntext = preprocess(text)\r\nencoded_input = tokenizer(text, return_tensors='pt')\r\
          \noutput = model(**encoded_input)\r\nscores = output[0][0].detach().numpy()\r\
          \nscores = softmax(scores)\r\n# # TF\r\n# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\r\
          \n# model.save_pretrained(MODEL)\r\n# text = \"Covid cases are increasing\
          \ fast!\"\r\n# encoded_input = tokenizer(text, return_tensors='tf')\r\n\
          # output = model(encoded_input)\r\n# scores = output[0][0].numpy()\r\n#\
          \ scores = softmax(scores)\r\n# Print labels and scores\r\nranking = np.argsort(scores)\r\
          \nranking = ranking[::-1]\r\nfor i in range(scores.shape[0]):\r\n    l =\
          \ config.id2label[ranking[i]]\r\n    s = scores[ranking[i]]\r\n    print(f\"\
          {i+1}) {l} {np.round(float(s), 4)}\")\r\n\r\n"
        updatedAt: '2023-06-30T22:15:56.465Z'
      numEdits: 0
      reactions: []
    id: 649f541c5f125423262b3676
    type: comment
  author: Aqsa31
  content: "Not sure what is going on but I tried to run the model on 20 rows of my\
    \ dataset (normal dataset really) it crashed once or twice but then ran , I tried\
    \ running it on full dataset 200 rows but it keeps killing my kernel on Jupiter\
    \ notebook. Even the most simple sentence can't be processed using this model\
    \ now without crashing my kernel. Any leads? \r\n\r\nfrom transformers import\
    \ AutoModelForSequenceClassification\r\nfrom transformers import TFAutoModelForSequenceClassification\r\
    \nfrom transformers import AutoTokenizer, AutoConfig\r\nimport numpy as np\r\n\
    from scipy.special import softmax\r\n# Preprocess text (username and link placeholders)\r\
    \ndef preprocess(text):\r\n    new_text = []\r\n    for t in text.split(\" \"\
    ):\r\n        t = '@user' if t.startswith('@') and len(t) > 1 else t\r\n     \
    \   t = 'http' if t.startswith('http') else t\r\n        new_text.append(t)\r\n\
    \    return \" \".join(new_text)\r\nMODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\
    \r\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\r\nconfig = AutoConfig.from_pretrained(MODEL)\r\
    \n# PT\r\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL)\r\n\
    #model.save_pretrained(MODEL)\r\ntext = \"Covid cases are increasing fast!\"\r\
    \ntext = preprocess(text)\r\nencoded_input = tokenizer(text, return_tensors='pt')\r\
    \noutput = model(**encoded_input)\r\nscores = output[0][0].detach().numpy()\r\n\
    scores = softmax(scores)\r\n# # TF\r\n# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\r\
    \n# model.save_pretrained(MODEL)\r\n# text = \"Covid cases are increasing fast!\"\
    \r\n# encoded_input = tokenizer(text, return_tensors='tf')\r\n# output = model(encoded_input)\r\
    \n# scores = output[0][0].numpy()\r\n# scores = softmax(scores)\r\n# Print labels\
    \ and scores\r\nranking = np.argsort(scores)\r\nranking = ranking[::-1]\r\nfor\
    \ i in range(scores.shape[0]):\r\n    l = config.id2label[ranking[i]]\r\n    s\
    \ = scores[ranking[i]]\r\n    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\r\
    \n\r\n"
  created_at: 2023-06-30 21:15:56+00:00
  edited: false
  hidden: false
  id: 649f541c5f125423262b3676
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: cardiffnlp/twitter-roberta-base-sentiment-latest
repo_type: model
status: open
target_branch: null
title: Model keeps crashing
