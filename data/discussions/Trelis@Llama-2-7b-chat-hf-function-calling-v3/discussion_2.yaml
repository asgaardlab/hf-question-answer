!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aisensiy
conflicting_files: null
created_at: 2024-01-22 13:47:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9996cfcbfdc5bc1d57fe42ade6ca7978.svg
      fullname: aisensiy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aisensiy
      type: user
    createdAt: '2024-01-22T13:47:48.000Z'
    data:
      edited: false
      editors:
      - aisensiy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8481647968292236
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9996cfcbfdc5bc1d57fe42ade6ca7978.svg
          fullname: aisensiy
          isHf: false
          isPro: false
          name: aisensiy
          type: user
        html: "<p>vLLM can expose an openai like api and can I just ues the openai\
          \ to make function calling? Right now I have a try like this, and it failed.</p>\n\
          <pre><code class=\"language-py\"><span class=\"hljs-keyword\">import</span>\
          \ json\n\n<span class=\"hljs-comment\"># Example dummy function hard coded\
          \ to return the same weather</span>\n<span class=\"hljs-comment\"># In production,\
          \ this could be your backend API or an external API</span>\n<span class=\"\
          hljs-keyword\">def</span> <span class=\"hljs-title function_\">get_current_weather</span>(<span\
          \ class=\"hljs-params\">location, unit=<span class=\"hljs-string\">\"fahrenheit\"\
          </span></span>):\n    <span class=\"hljs-string\">\"\"\"Get the current\
          \ weather in a given location\"\"\"</span>\n    weather_info = {\n     \
          \   <span class=\"hljs-string\">\"location\"</span>: location,\n       \
          \ <span class=\"hljs-string\">\"temperature\"</span>: <span class=\"hljs-string\"\
          >\"72\"</span>,\n        <span class=\"hljs-string\">\"unit\"</span>: unit,\n\
          \        <span class=\"hljs-string\">\"forecast\"</span>: [<span class=\"\
          hljs-string\">\"sunny\"</span>, <span class=\"hljs-string\">\"windy\"</span>],\n\
          \    }\n    <span class=\"hljs-keyword\">return</span> json.dumps(weather_info)\n\
          \n<span class=\"hljs-comment\"># define a function</span>\nfunctions = [\n\
          \    {\n        <span class=\"hljs-string\">\"name\"</span>: <span class=\"\
          hljs-string\">\"get_current_weather\"</span>,\n        <span class=\"hljs-string\"\
          >\"description\"</span>: <span class=\"hljs-string\">\"Get the current weather\
          \ in a given location\"</span>,\n        <span class=\"hljs-string\">\"\
          parameters\"</span>: {\n            <span class=\"hljs-string\">\"type\"\
          </span>: <span class=\"hljs-string\">\"object\"</span>,\n            <span\
          \ class=\"hljs-string\">\"properties\"</span>: {\n                <span\
          \ class=\"hljs-string\">\"location\"</span>: {\n                    <span\
          \ class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"\
          string\"</span>,\n                    <span class=\"hljs-string\">\"description\"\
          </span>: <span class=\"hljs-string\">\"The city and state, e.g. San Francisco,\
          \ CA\"</span>,\n                },\n                <span class=\"hljs-string\"\
          >\"unit\"</span>: {<span class=\"hljs-string\">\"type\"</span>: <span class=\"\
          hljs-string\">\"string\"</span>, <span class=\"hljs-string\">\"enum\"</span>:\
          \ [<span class=\"hljs-string\">\"celsius\"</span>, <span class=\"hljs-string\"\
          >\"fahrenheit\"</span>]},\n            },\n            <span class=\"hljs-string\"\
          >\"required\"</span>: [<span class=\"hljs-string\">\"location\"</span>],\n\
          \        },\n    }\n]\n\nclient = OpenAI(api_key=<span class=\"hljs-string\"\
          >'abc'</span>, base_url=<span class=\"hljs-string\">'&lt;customized-enpoint&gt;'</span>)\n\
          \nresponse = client.chat.completions.create(messages=messages, functions=functions,\
          \ model=<span class=\"hljs-string\">'Llama-2-7b-chat-hf-function-calling-v3'</span>)\n\
          </code></pre>\n<p>The result looks like this:</p>\n<p><a rel=\"nofollow\"\
          \ href=\"https://cdn-uploads.huggingface.co/production/uploads/62554db4ebfc059817aeede6/v635IHzY3Q7SWR55Z3XYq.png\"\
          ><img alt=\"\u622A\u5C4F2024-01-22 21.47.19.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/62554db4ebfc059817aeede6/v635IHzY3Q7SWR55Z3XYq.png\"\
          ></a></p>\n<pre><code>The weather in Boston can vary depending on the time\
          \ of year. Boston has a humid continental climate, with cold winters and\
          \ hot, humid summers. Here are some general weather patterns in Boston:\n\
          \nWinter (December to February):\n\n* Temperatures can range from 20\xB0\
          F (-7\xB0C) to 40\xB0F (4\xB0C)\n* Snowfall is common, with an average of\
          \ 43 inches (109 cm) per year\n* The coldest months are January and February,\
          \ with average temperatures around 28\xB0F (-2\xB0C)\n\nSpring (March to\
          \ May):\n\n* Temperatures can range from 30\xB0F (-1\xB0C) to 60\xB0F (16\xB0\
          C)\n* Spring is a transition season, with temperatures gradually warming\
          \ up\n* April is usually the rainiest month, with an average of 4 inches\
          \ (10 cm) of rain\n\nSummer (June to August):\n\n* Temperatures can range\
          \ from 60\xB0F (16\xB0C) to 80\xB0F (27\xB0C)\n* Summer is the warmest season,\
          \ with an average temperature of 70\xB0F (21\xB0C) in July and August\n\
          * Humidity is usually high during the summer months\n\nFall (September to\
          \ November):\n\n* Temperatures can range from 50\xB0F (10\xB0C) to 60\xB0\
          F (16\xB0C)\n* Fall is a mild season, with temperatures gradually cooling\
          \ down\n* October is usually the driest month, with an average of 3 inches\
          \ (7 cm) of rain\n\nIt's worth noting that weather patterns can vary from\
          \ year to year, and it's not uncommon for Boston to experience extreme weather\
          \ events such as heatwaves, cold snaps, or heavy snowfall.\n</code></pre>\n"
        raw: "vLLM can expose an openai like api and can I just ues the openai to\
          \ make function calling? Right now I have a try like this, and it failed.\r\
          \n\r\n```py\r\nimport json\r\n\r\n# Example dummy function hard coded to\
          \ return the same weather\r\n# In production, this could be your backend\
          \ API or an external API\r\ndef get_current_weather(location, unit=\"fahrenheit\"\
          ):\r\n    \"\"\"Get the current weather in a given location\"\"\"\r\n  \
          \  weather_info = {\r\n        \"location\": location,\r\n        \"temperature\"\
          : \"72\",\r\n        \"unit\": unit,\r\n        \"forecast\": [\"sunny\"\
          , \"windy\"],\r\n    }\r\n    return json.dumps(weather_info)\r\n\r\n# define\
          \ a function\r\nfunctions = [\r\n    {\r\n        \"name\": \"get_current_weather\"\
          ,\r\n        \"description\": \"Get the current weather in a given location\"\
          ,\r\n        \"parameters\": {\r\n            \"type\": \"object\",\r\n\
          \            \"properties\": {\r\n                \"location\": {\r\n  \
          \                  \"type\": \"string\",\r\n                    \"description\"\
          : \"The city and state, e.g. San Francisco, CA\",\r\n                },\r\
          \n                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\"\
          , \"fahrenheit\"]},\r\n            },\r\n            \"required\": [\"location\"\
          ],\r\n        },\r\n    }\r\n]\r\n\r\nclient = OpenAI(api_key='abc', base_url='<customized-enpoint>')\r\
          \n\r\nresponse = client.chat.completions.create(messages=messages, functions=functions,\
          \ model='Llama-2-7b-chat-hf-function-calling-v3')\r\n```\r\n\r\nThe result\
          \ looks like this:\r\n\r\n\r\n![\u622A\u5C4F2024-01-22 21.47.19.png](https://cdn-uploads.huggingface.co/production/uploads/62554db4ebfc059817aeede6/v635IHzY3Q7SWR55Z3XYq.png)\r\
          \n\r\n\r\n```\r\nThe weather in Boston can vary depending on the time of\
          \ year. Boston has a humid continental climate, with cold winters and hot,\
          \ humid summers. Here are some general weather patterns in Boston:\r\n\r\
          \nWinter (December to February):\r\n\r\n* Temperatures can range from 20\xB0\
          F (-7\xB0C) to 40\xB0F (4\xB0C)\r\n* Snowfall is common, with an average\
          \ of 43 inches (109 cm) per year\r\n* The coldest months are January and\
          \ February, with average temperatures around 28\xB0F (-2\xB0C)\r\n\r\nSpring\
          \ (March to May):\r\n\r\n* Temperatures can range from 30\xB0F (-1\xB0C)\
          \ to 60\xB0F (16\xB0C)\r\n* Spring is a transition season, with temperatures\
          \ gradually warming up\r\n* April is usually the rainiest month, with an\
          \ average of 4 inches (10 cm) of rain\r\n\r\nSummer (June to August):\r\n\
          \r\n* Temperatures can range from 60\xB0F (16\xB0C) to 80\xB0F (27\xB0C)\r\
          \n* Summer is the warmest season, with an average temperature of 70\xB0\
          F (21\xB0C) in July and August\r\n* Humidity is usually high during the\
          \ summer months\r\n\r\nFall (September to November):\r\n\r\n* Temperatures\
          \ can range from 50\xB0F (10\xB0C) to 60\xB0F (16\xB0C)\r\n* Fall is a mild\
          \ season, with temperatures gradually cooling down\r\n* October is usually\
          \ the driest month, with an average of 3 inches (7 cm) of rain\r\n\r\nIt's\
          \ worth noting that weather patterns can vary from year to year, and it's\
          \ not uncommon for Boston to experience extreme weather events such as heatwaves,\
          \ cold snaps, or heavy snowfall.\r\n```"
        updatedAt: '2024-01-22T13:47:48.379Z'
      numEdits: 0
      reactions: []
    id: 65ae72049d5b4222185adc00
    type: comment
  author: aisensiy
  content: "vLLM can expose an openai like api and can I just ues the openai to make\
    \ function calling? Right now I have a try like this, and it failed.\r\n\r\n```py\r\
    \nimport json\r\n\r\n# Example dummy function hard coded to return the same weather\r\
    \n# In production, this could be your backend API or an external API\r\ndef get_current_weather(location,\
    \ unit=\"fahrenheit\"):\r\n    \"\"\"Get the current weather in a given location\"\
    \"\"\r\n    weather_info = {\r\n        \"location\": location,\r\n        \"\
    temperature\": \"72\",\r\n        \"unit\": unit,\r\n        \"forecast\": [\"\
    sunny\", \"windy\"],\r\n    }\r\n    return json.dumps(weather_info)\r\n\r\n#\
    \ define a function\r\nfunctions = [\r\n    {\r\n        \"name\": \"get_current_weather\"\
    ,\r\n        \"description\": \"Get the current weather in a given location\"\
    ,\r\n        \"parameters\": {\r\n            \"type\": \"object\",\r\n      \
    \      \"properties\": {\r\n                \"location\": {\r\n              \
    \      \"type\": \"string\",\r\n                    \"description\": \"The city\
    \ and state, e.g. San Francisco, CA\",\r\n                },\r\n             \
    \   \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\r\
    \n            },\r\n            \"required\": [\"location\"],\r\n        },\r\n\
    \    }\r\n]\r\n\r\nclient = OpenAI(api_key='abc', base_url='<customized-enpoint>')\r\
    \n\r\nresponse = client.chat.completions.create(messages=messages, functions=functions,\
    \ model='Llama-2-7b-chat-hf-function-calling-v3')\r\n```\r\n\r\nThe result looks\
    \ like this:\r\n\r\n\r\n![\u622A\u5C4F2024-01-22 21.47.19.png](https://cdn-uploads.huggingface.co/production/uploads/62554db4ebfc059817aeede6/v635IHzY3Q7SWR55Z3XYq.png)\r\
    \n\r\n\r\n```\r\nThe weather in Boston can vary depending on the time of year.\
    \ Boston has a humid continental climate, with cold winters and hot, humid summers.\
    \ Here are some general weather patterns in Boston:\r\n\r\nWinter (December to\
    \ February):\r\n\r\n* Temperatures can range from 20\xB0F (-7\xB0C) to 40\xB0\
    F (4\xB0C)\r\n* Snowfall is common, with an average of 43 inches (109 cm) per\
    \ year\r\n* The coldest months are January and February, with average temperatures\
    \ around 28\xB0F (-2\xB0C)\r\n\r\nSpring (March to May):\r\n\r\n* Temperatures\
    \ can range from 30\xB0F (-1\xB0C) to 60\xB0F (16\xB0C)\r\n* Spring is a transition\
    \ season, with temperatures gradually warming up\r\n* April is usually the rainiest\
    \ month, with an average of 4 inches (10 cm) of rain\r\n\r\nSummer (June to August):\r\
    \n\r\n* Temperatures can range from 60\xB0F (16\xB0C) to 80\xB0F (27\xB0C)\r\n\
    * Summer is the warmest season, with an average temperature of 70\xB0F (21\xB0\
    C) in July and August\r\n* Humidity is usually high during the summer months\r\
    \n\r\nFall (September to November):\r\n\r\n* Temperatures can range from 50\xB0\
    F (10\xB0C) to 60\xB0F (16\xB0C)\r\n* Fall is a mild season, with temperatures\
    \ gradually cooling down\r\n* October is usually the driest month, with an average\
    \ of 3 inches (7 cm) of rain\r\n\r\nIt's worth noting that weather patterns can\
    \ vary from year to year, and it's not uncommon for Boston to experience extreme\
    \ weather events such as heatwaves, cold snaps, or heavy snowfall.\r\n```"
  created_at: 2024-01-22 13:47:48+00:00
  edited: false
  hidden: false
  id: 65ae72049d5b4222185adc00
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2024-01-23T10:50:09.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9321333765983582
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>Howdy, I see what you''re doing and it''s a good idea.</p>

          <p>Yes, this model works with vLLM and an openai endpoint, but you have
          to feed in the chat template from the tokenizer (which is custom for this
          model).</p>

          <p>The format does not follow the openai function calling format (I''d like
          to do that but the function calling implementation by openai hasn''t been
          stable and has used a "functions" and also a "tools" approach). Ideally
          I would make all models compatible fully - even with openai function calling,
          but what we have now is quasi compatibility - by feeding in the chat template.
          Check out my videos on YouTube.com/@TrelisResearch for the latest function
          calling video and also the latest inference vid.</p>

          '
        raw: 'Howdy, I see what you''re doing and it''s a good idea.


          Yes, this model works with vLLM and an openai endpoint, but you have to
          feed in the chat template from the tokenizer (which is custom for this model).


          The format does not follow the openai function calling format (I''d like
          to do that but the function calling implementation by openai hasn''t been
          stable and has used a "functions" and also a "tools" approach). Ideally
          I would make all models compatible fully - even with openai function calling,
          but what we have now is quasi compatibility - by feeding in the chat template.
          Check out my videos on YouTube.com/@TrelisResearch for the latest function
          calling video and also the latest inference vid.'
        updatedAt: '2024-01-23T10:50:09.381Z'
      numEdits: 0
      reactions: []
    id: 65af99e10214b35f1b673d23
    type: comment
  author: RonanMcGovern
  content: 'Howdy, I see what you''re doing and it''s a good idea.


    Yes, this model works with vLLM and an openai endpoint, but you have to feed in
    the chat template from the tokenizer (which is custom for this model).


    The format does not follow the openai function calling format (I''d like to do
    that but the function calling implementation by openai hasn''t been stable and
    has used a "functions" and also a "tools" approach). Ideally I would make all
    models compatible fully - even with openai function calling, but what we have
    now is quasi compatibility - by feeding in the chat template. Check out my videos
    on YouTube.com/@TrelisResearch for the latest function calling video and also
    the latest inference vid.'
  created_at: 2024-01-23 10:50:09+00:00
  edited: false
  hidden: false
  id: 65af99e10214b35f1b673d23
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Trelis/Llama-2-7b-chat-hf-function-calling-v3
repo_type: model
status: open
target_branch: null
title: Use openai  for function calling
