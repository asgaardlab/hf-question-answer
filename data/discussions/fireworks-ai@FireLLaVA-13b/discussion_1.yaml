!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dchichkov
conflicting_files: null
created_at: 2024-01-19 18:33:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/330ab31805135fcc4005226974035bf3.svg
      fullname: Dmitry Chichkov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: dchichkov
      type: user
    createdAt: '2024-01-19T18:33:41.000Z'
    data:
      edited: false
      editors:
      - dchichkov
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8963255286216736
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/330ab31805135fcc4005226974035bf3.svg
          fullname: Dmitry Chichkov
          isHf: false
          isPro: true
          name: dchichkov
          type: user
        html: '<p>I''ve looked at the repository at <a href="https://huggingface.co/fireworks-ai/FireLLaVA-13b">https://huggingface.co/fireworks-ai/FireLLaVA-13b</a>
          and its using LlavaForConditionalGeneration. I understand that the CLIP
          encoder that you''ve used is "clip_vision_model" as per your config.  Which
          translates to "openai/clip-vit-base-patch32".  And as per the model card
          at:  <a href="https://huggingface.co/openai/clip-vit-base-patch32">https://huggingface.co/openai/clip-vit-base-patch32</a>  this
          is a research/non-commercial model. </p>

          <p>I understand that as per convention, any checkpoints that used research/non-commercial
          models in the pipeline are also  considered to be non-commercial. And a
          combination of models that include non-commercial parts are also non-commercial.</p>

          <p>Please, can you explain how your model checkpoint can be commercial or
          deployed for commercial/API use, while complying with the CLIP license?  Or
          correct the claim of the model being commercial?</p>

          <p>Also, in general, it is good practice to include rough composition of
          the datasets that constitute the model advertised for commercial use.  Otherwise
          is not clear, if that data is "clean enough" for the model to be considered
          commercial.  A quick query to your model reveals Vicuna data for example.<br><a
          rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/630d734181ef9b1772b633bb/nb3w5xDQFCR4kEoTHBE1n.png"><img
          alt="Screenshot from 2024-01-19 09-50-32.png" src="https://cdn-uploads.huggingface.co/production/uploads/630d734181ef9b1772b633bb/nb3w5xDQFCR4kEoTHBE1n.png"></a></p>

          '
        raw: "I've looked at the repository at https://huggingface.co/fireworks-ai/FireLLaVA-13b\
          \ and its using LlavaForConditionalGeneration. I understand that the CLIP\
          \ encoder that you've used is \"clip_vision_model\" as per your config.\
          \  Which translates to \"openai/clip-vit-base-patch32\".  And as per the\
          \ model card at:  https://huggingface.co/openai/clip-vit-base-patch32  this\
          \ is a research/non-commercial model. \r\n\r\nI understand that as per convention,\
          \ any checkpoints that used research/non-commercial models in the pipeline\
          \ are also  considered to be non-commercial. And a combination of models\
          \ that include non-commercial parts are also non-commercial.\r\n\r\nPlease,\
          \ can you explain how your model checkpoint can be commercial or deployed\
          \ for commercial/API use, while complying with the CLIP license?  Or correct\
          \ the claim of the model being commercial?\r\n\r\nAlso, in general, it is\
          \ good practice to include rough composition of the datasets that constitute\
          \ the model advertised for commercial use.  Otherwise is not clear, if that\
          \ data is \"clean enough\" for the model to be considered commercial.  A\
          \ quick query to your model reveals Vicuna data for example.\r\n![Screenshot\
          \ from 2024-01-19 09-50-32.png](https://cdn-uploads.huggingface.co/production/uploads/630d734181ef9b1772b633bb/nb3w5xDQFCR4kEoTHBE1n.png)\r\
          \n"
        updatedAt: '2024-01-19T18:33:41.609Z'
      numEdits: 0
      reactions: []
    id: 65aac08530225893712f8206
    type: comment
  author: dchichkov
  content: "I've looked at the repository at https://huggingface.co/fireworks-ai/FireLLaVA-13b\
    \ and its using LlavaForConditionalGeneration. I understand that the CLIP encoder\
    \ that you've used is \"clip_vision_model\" as per your config.  Which translates\
    \ to \"openai/clip-vit-base-patch32\".  And as per the model card at:  https://huggingface.co/openai/clip-vit-base-patch32\
    \  this is a research/non-commercial model. \r\n\r\nI understand that as per convention,\
    \ any checkpoints that used research/non-commercial models in the pipeline are\
    \ also  considered to be non-commercial. And a combination of models that include\
    \ non-commercial parts are also non-commercial.\r\n\r\nPlease, can you explain\
    \ how your model checkpoint can be commercial or deployed for commercial/API use,\
    \ while complying with the CLIP license?  Or correct the claim of the model being\
    \ commercial?\r\n\r\nAlso, in general, it is good practice to include rough composition\
    \ of the datasets that constitute the model advertised for commercial use.  Otherwise\
    \ is not clear, if that data is \"clean enough\" for the model to be considered\
    \ commercial.  A quick query to your model reveals Vicuna data for example.\r\n\
    ![Screenshot from 2024-01-19 09-50-32.png](https://cdn-uploads.huggingface.co/production/uploads/630d734181ef9b1772b633bb/nb3w5xDQFCR4kEoTHBE1n.png)\r\
    \n"
  created_at: 2024-01-19 18:33:41+00:00
  edited: false
  hidden: false
  id: 65aac08530225893712f8206
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/56dc328d2103aafb4c854a97e5bd94e3.svg
      fullname: Webster Bei
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: websterbei
      type: user
    createdAt: '2024-01-20T21:09:12.000Z'
    data:
      edited: false
      editors:
      - websterbei
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8785017728805542
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/56dc328d2103aafb4c854a97e5bd94e3.svg
          fullname: Webster Bei
          isHf: false
          isPro: false
          name: websterbei
          type: user
        html: '<p>Hi Dmitry, thank you for testing out the model and raising the concern!<br>The
          underlying vision encoder being used is from <a href="https://huggingface.co/openai/clip-vit-large-patch14-336">https://huggingface.co/openai/clip-vit-large-patch14-336</a>,
          while the page itself does not contain any information regarding license,
          we believe CLIP itself is under MIT license (<a rel="nofollow" href="https://github.com/openai/CLIP/blob/main/LICENSE">https://github.com/openai/CLIP/blob/main/LICENSE</a>).
          Models such as SDXL are similarly using the TextEncoder from CLIP if I understand
          correctly. </p>

          <p>As for the composition of data, we briefly mentioned it in our separate
          blog post, but here is a more through list: <a rel="nofollow" href="https://github.com/haotian-liu/LLaVA#train">https://github.com/haotian-liu/LLaVA#train</a><br>The
          only difference we made, is swapping out the GPT generated portion with
          our own. </p>

          '
        raw: "Hi Dmitry, thank you for testing out the model and raising the concern!\n\
          The underlying vision encoder being used is from https://huggingface.co/openai/clip-vit-large-patch14-336,\
          \ while the page itself does not contain any information regarding license,\
          \ we believe CLIP itself is under MIT license (https://github.com/openai/CLIP/blob/main/LICENSE).\
          \ Models such as SDXL are similarly using the TextEncoder from CLIP if I\
          \ understand correctly. \n\nAs for the composition of data, we briefly mentioned\
          \ it in our separate blog post, but here is a more through list: https://github.com/haotian-liu/LLaVA#train\
          \ \nThe only difference we made, is swapping out the GPT generated portion\
          \ with our own. \n\n\n\n"
        updatedAt: '2024-01-20T21:09:12.444Z'
      numEdits: 0
      reactions: []
    id: 65ac3678f8111f40c0c5a5bb
    type: comment
  author: websterbei
  content: "Hi Dmitry, thank you for testing out the model and raising the concern!\n\
    The underlying vision encoder being used is from https://huggingface.co/openai/clip-vit-large-patch14-336,\
    \ while the page itself does not contain any information regarding license, we\
    \ believe CLIP itself is under MIT license (https://github.com/openai/CLIP/blob/main/LICENSE).\
    \ Models such as SDXL are similarly using the TextEncoder from CLIP if I understand\
    \ correctly. \n\nAs for the composition of data, we briefly mentioned it in our\
    \ separate blog post, but here is a more through list: https://github.com/haotian-liu/LLaVA#train\
    \ \nThe only difference we made, is swapping out the GPT generated portion with\
    \ our own. \n\n\n\n"
  created_at: 2024-01-20 21:09:12+00:00
  edited: false
  hidden: false
  id: 65ac3678f8111f40c0c5a5bb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d116ee7bef2ca4f33d68a7883ddcdbbf.svg
      fullname: Sean Huver
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shuver
      type: user
    createdAt: '2024-01-22T14:47:08.000Z'
    data:
      edited: false
      editors:
      - shuver
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9302233457565308
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d116ee7bef2ca4f33d68a7883ddcdbbf.svg
          fullname: Sean Huver
          isHf: false
          isPro: false
          name: shuver
          type: user
        html: '<p>Many of the underlying images in COCO used in the visual instruction
          finetuning stage are non-commercial. </p>

          <p>It''s unclear from "mixed from the permissive portion of the original
          LLaVA training data and Fireworks.ai generated training data" whether these
          were in fact removed or not. Do you have an explicit list of underlying
          images used?</p>

          <p>Thanks</p>

          '
        raw: "Many of the underlying images in COCO used in the visual instruction\
          \ finetuning stage are non-commercial. \n\nIt's unclear from \"mixed from\
          \ the permissive portion of the original LLaVA training data and Fireworks.ai\
          \ generated training data\" whether these were in fact removed or not. Do\
          \ you have an explicit list of underlying images used?\n\nThanks"
        updatedAt: '2024-01-22T14:47:08.994Z'
      numEdits: 0
      reactions: []
    id: 65ae7fec30e33d1b604712b3
    type: comment
  author: shuver
  content: "Many of the underlying images in COCO used in the visual instruction finetuning\
    \ stage are non-commercial. \n\nIt's unclear from \"mixed from the permissive\
    \ portion of the original LLaVA training data and Fireworks.ai generated training\
    \ data\" whether these were in fact removed or not. Do you have an explicit list\
    \ of underlying images used?\n\nThanks"
  created_at: 2024-01-22 14:47:08+00:00
  edited: false
  hidden: false
  id: 65ae7fec30e33d1b604712b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/330ab31805135fcc4005226974035bf3.svg
      fullname: Dmitry Chichkov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: dchichkov
      type: user
    createdAt: '2024-01-22T19:46:43.000Z'
    data:
      edited: false
      editors:
      - dchichkov
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9104982614517212
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/330ab31805135fcc4005226974035bf3.svg
          fullname: Dmitry Chichkov
          isHf: false
          isPro: true
          name: dchichkov
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;websterbei&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/websterbei\">@<span class=\"\
          underline\">websterbei</span></a></span>\n\n\t</span></span>  The MIT license\
          \ is for the code, no?   Model's (weights) license is in the Model Card,\
          \ as far as I understand:<br>  <a rel=\"nofollow\" href=\"https://github.com/openai/CLIP/blob/main/model-card.md\"\
          >https://github.com/openai/CLIP/blob/main/model-card.md</a></p>\n<p>And\
          \ it's: \"any deployed use case of the model - whether commercial or not\
          \ - is currently out of scope\".  Not legally binding?</p>\n"
        raw: "@websterbei  The MIT license is for the code, no?   Model's (weights)\
          \ license is in the Model Card, as far as I understand:\n  https://github.com/openai/CLIP/blob/main/model-card.md\n\
          \nAnd it's: \"any deployed use case of the model - whether commercial or\
          \ not - is currently out of scope\".  Not legally binding?"
        updatedAt: '2024-01-22T19:46:43.242Z'
      numEdits: 0
      reactions: []
    id: 65aec6233e876a638941572d
    type: comment
  author: dchichkov
  content: "@websterbei  The MIT license is for the code, no?   Model's (weights)\
    \ license is in the Model Card, as far as I understand:\n  https://github.com/openai/CLIP/blob/main/model-card.md\n\
    \nAnd it's: \"any deployed use case of the model - whether commercial or not -\
    \ is currently out of scope\".  Not legally binding?"
  created_at: 2024-01-22 19:46:43+00:00
  edited: false
  hidden: false
  id: 65aec6233e876a638941572d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: fireworks-ai/FireLLaVA-13b
repo_type: model
status: open
target_branch: null
title: How can the model be commercial, if it is using OpenAI CLIP?
