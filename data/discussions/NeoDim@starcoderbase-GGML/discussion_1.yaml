!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ultra2mh
conflicting_files: null
created_at: 2023-05-25 10:07:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7afbbafd6ba115c8e72659fa5b44896b.svg
      fullname: mrmohammadreza
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ultra2mh
      type: user
    createdAt: '2023-05-25T11:07:49.000Z'
    data:
      edited: false
      editors:
      - ultra2mh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7afbbafd6ba115c8e72659fa5b44896b.svg
          fullname: mrmohammadreza
          isHf: false
          isPro: false
          name: ultra2mh
          type: user
        html: '<p>i tryied to load the model with llama.cpp but i get this error,
          how can i fix it?:</p>

          <p>my command:<br> ./main -t 12 -m models/starcoderbase-ggml-q5_1.bin  --color
          -c 2048 --temp 0.7 --top_k 40 --top_p 0.5  --repeat_penalty 1.17 -n -1 -r
          "### Human:" -i</p>

          <p>output:<br>main: build = 588 (ac7876a)<br>main: seed  = 1685012620<br>llama.cpp:
          loading model from models/starcoderbase-ggml-q5_1.bin<br>error loading model:
          missing tok_embeddings.weight<br>llama_init_from_file: failed to load model<br>llama_init_from_gpt_params:
          error: failed to load model ''models/starcoderbase-ggml-q5_1.bin''<br>main:
          error: unable to load model</p>

          '
        raw: "i tryied to load the model with llama.cpp but i get this error, how\
          \ can i fix it?:\r\n\r\nmy command: \r\n ./main -t 12 -m models/starcoderbase-ggml-q5_1.bin\
          \  --color -c 2048 --temp 0.7 --top_k 40 --top_p 0.5  --repeat_penalty 1.17\
          \ -n -1 -r \"### Human:\" -i\r\n\r\noutput:\r\nmain: build = 588 (ac7876a)\r\
          \nmain: seed  = 1685012620\r\nllama.cpp: loading model from models/starcoderbase-ggml-q5_1.bin\r\
          \nerror loading model: missing tok_embeddings.weight\r\nllama_init_from_file:\
          \ failed to load model\r\nllama_init_from_gpt_params: error: failed to load\
          \ model 'models/starcoderbase-ggml-q5_1.bin'\r\nmain: error: unable to load\
          \ model"
        updatedAt: '2023-05-25T11:07:49.238Z'
      numEdits: 0
      reactions: []
    id: 646f4185a6a58aa295064ff8
    type: comment
  author: ultra2mh
  content: "i tryied to load the model with llama.cpp but i get this error, how can\
    \ i fix it?:\r\n\r\nmy command: \r\n ./main -t 12 -m models/starcoderbase-ggml-q5_1.bin\
    \  --color -c 2048 --temp 0.7 --top_k 40 --top_p 0.5  --repeat_penalty 1.17 -n\
    \ -1 -r \"### Human:\" -i\r\n\r\noutput:\r\nmain: build = 588 (ac7876a)\r\nmain:\
    \ seed  = 1685012620\r\nllama.cpp: loading model from models/starcoderbase-ggml-q5_1.bin\r\
    \nerror loading model: missing tok_embeddings.weight\r\nllama_init_from_file:\
    \ failed to load model\r\nllama_init_from_gpt_params: error: failed to load model\
    \ 'models/starcoderbase-ggml-q5_1.bin'\r\nmain: error: unable to load model"
  created_at: 2023-05-25 10:07:49+00:00
  edited: false
  hidden: false
  id: 646f4185a6a58aa295064ff8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c6fb4c41a5080aaf44d130e0de5a2df1.svg
      fullname: Neo Dim
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: NeoDim
      type: user
    createdAt: '2023-05-25T15:33:23.000Z'
    data:
      edited: false
      editors:
      - NeoDim
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c6fb4c41a5080aaf44d130e0de5a2df1.svg
          fullname: Neo Dim
          isHf: false
          isPro: false
          name: NeoDim
          type: user
        html: '<p>llama.cpp not supported it - <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp/issues/1441">https://github.com/ggerganov/llama.cpp/issues/1441</a><br>There
          are starcoder.cpp, but there is another issue - <a rel="nofollow" href="https://github.com/bigcode-project/starcoder.cpp/issues/11">https://github.com/bigcode-project/starcoder.cpp/issues/11</a><br>For
          now you can use example code from ggml main repo to inference - <a rel="nofollow"
          href="https://github.com/ggerganov/ggml/tree/master/examples/starcoder">https://github.com/ggerganov/ggml/tree/master/examples/starcoder</a></p>

          '
        raw: 'llama.cpp not supported it - https://github.com/ggerganov/llama.cpp/issues/1441

          There are starcoder.cpp, but there is another issue - https://github.com/bigcode-project/starcoder.cpp/issues/11

          For now you can use example code from ggml main repo to inference - https://github.com/ggerganov/ggml/tree/master/examples/starcoder'
        updatedAt: '2023-05-25T15:33:23.753Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - ultra2mh
    id: 646f7fc3d1f1b73079e843d2
    type: comment
  author: NeoDim
  content: 'llama.cpp not supported it - https://github.com/ggerganov/llama.cpp/issues/1441

    There are starcoder.cpp, but there is another issue - https://github.com/bigcode-project/starcoder.cpp/issues/11

    For now you can use example code from ggml main repo to inference - https://github.com/ggerganov/ggml/tree/master/examples/starcoder'
  created_at: 2023-05-25 14:33:23+00:00
  edited: false
  hidden: false
  id: 646f7fc3d1f1b73079e843d2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c6fb4c41a5080aaf44d130e0de5a2df1.svg
      fullname: Neo Dim
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: NeoDim
      type: user
    createdAt: '2023-05-27T18:21:26.000Z'
    data:
      edited: false
      editors:
      - NeoDim
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c6fb4c41a5080aaf44d130e0de5a2df1.svg
          fullname: Neo Dim
          isHf: false
          isPro: false
          name: NeoDim
          type: user
        html: '<p>For now koboldcpp supports starcoder gglm models.</p>

          '
        raw: For now koboldcpp supports starcoder gglm models.
        updatedAt: '2023-05-27T18:21:26.308Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - ultra2mh
    id: 64724a26c27f74a0eba81bb6
    type: comment
  author: NeoDim
  content: For now koboldcpp supports starcoder gglm models.
  created_at: 2023-05-27 17:21:26+00:00
  edited: false
  hidden: false
  id: 64724a26c27f74a0eba81bb6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: NeoDim/starcoderbase-GGML
repo_type: model
status: open
target_branch: null
title: missing tok_embeddings.weight error when trying to run with llama.cpp
