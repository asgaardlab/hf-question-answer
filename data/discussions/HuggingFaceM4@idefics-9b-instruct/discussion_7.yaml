!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Pwicke
conflicting_files: null
created_at: 2023-10-19 13:20:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662715293681-619e38930b33fae198f1ec41.png?w=200&h=200&f=face
      fullname: Phil Wicke
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pwicke
      type: user
    createdAt: '2023-10-19T14:20:19.000Z'
    data:
      edited: true
      editors:
      - Pwicke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9054543375968933
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662715293681-619e38930b33fae198f1ec41.png?w=200&h=200&f=face
          fullname: Phil Wicke
          isHf: false
          isPro: false
          name: Pwicke
          type: user
        html: "<p>Hi and thanks for this brilliant model.</p>\n<p>I have been running\
          \ your <a rel=\"nofollow\" href=\"https://github.com/huggingface/notebooks/blob/main/examples/idefics/finetune_image_captioning_peft.ipynb\"\
          >Colab</a> notebook and it works like a charm on Google Colab. I have also\
          \ tried to reproduce it on my server with 8x NVIDIA RTX A6000. With the\
          \ exact same code from the notebook I receive the exact same output:</p>\n\
          <p><code>Question: What's on the picture? Answer: Kittens.</code></p>\n\
          <p>But whatever I do, if I do not use the quantised model but <code>idefics-9b</code>\
          \ or <code>idefics-9b-instruct</code>, I only ever receive:</p>\n<p><code>Question:\
          \ What's on the picture? Answer:</code></p>\n<p>The only difference between\
          \ the colab code and my code is the removal of <code>quantization_config=bnb_config</code>\
          \ from the <code>IdeficsForVisionText2Text.from_pretrained(...)</code> parameter\
          \ list. I have a had a colleague find their own way of running the model\
          \ with the code you provided and they have reproduced the exact same issue\
          \ independently (<code>Question: What's on the picture? Answer:</code>).\
          \ I've tried different GPUs and different servers, but without the quantised\
          \ model, I am unable to produce any output. The model loads into memory\
          \ and is accessed during inference - it just does not generate or return\
          \ or display any new tokens (I have also increased <code>max_new_tokens=50</code>,\
          \ tried other prompts like the Pok\xE9mon example).</p>\n<p>Any help would\
          \ be appreciated.\n </p>\n"
        raw: "Hi and thanks for this brilliant model.\n\nI have been running your\
          \ [Colab](https://github.com/huggingface/notebooks/blob/main/examples/idefics/finetune_image_captioning_peft.ipynb)\
          \ notebook and it works like a charm on Google Colab. I have also tried\
          \ to reproduce it on my server with 8x NVIDIA RTX A6000. With the exact\
          \ same code from the notebook I receive the exact same output:\n\n`Question:\
          \ What's on the picture? Answer: Kittens.`\n\nBut whatever I do, if I do\
          \ not use the quantised model but `idefics-9b` or `idefics-9b-instruct`,\
          \ I only ever receive:\n\n`Question: What's on the picture? Answer:`\n\n\
          The only difference between the colab code and my code is the removal of\
          \ `quantization_config=bnb_config` from the `IdeficsForVisionText2Text.from_pretrained(...)`\
          \ parameter list. I have a had a colleague find their own way of running\
          \ the model with the code you provided and they have reproduced the exact\
          \ same issue independently (`Question: What's on the picture? Answer:`).\
          \ I've tried different GPUs and different servers, but without the quantised\
          \ model, I am unable to produce any output. The model loads into memory\
          \ and is accessed during inference - it just does not generate or return\
          \ or display any new tokens (I have also increased `max_new_tokens=50`,\
          \ tried other prompts like the Pok\xE9mon example).\n\nAny help would be\
          \ appreciated.\n "
        updatedAt: '2023-10-19T14:21:21.540Z'
      numEdits: 2
      reactions: []
    id: 65313b2368a8764a565fbe31
    type: comment
  author: Pwicke
  content: "Hi and thanks for this brilliant model.\n\nI have been running your [Colab](https://github.com/huggingface/notebooks/blob/main/examples/idefics/finetune_image_captioning_peft.ipynb)\
    \ notebook and it works like a charm on Google Colab. I have also tried to reproduce\
    \ it on my server with 8x NVIDIA RTX A6000. With the exact same code from the\
    \ notebook I receive the exact same output:\n\n`Question: What's on the picture?\
    \ Answer: Kittens.`\n\nBut whatever I do, if I do not use the quantised model\
    \ but `idefics-9b` or `idefics-9b-instruct`, I only ever receive:\n\n`Question:\
    \ What's on the picture? Answer:`\n\nThe only difference between the colab code\
    \ and my code is the removal of `quantization_config=bnb_config` from the `IdeficsForVisionText2Text.from_pretrained(...)`\
    \ parameter list. I have a had a colleague find their own way of running the model\
    \ with the code you provided and they have reproduced the exact same issue independently\
    \ (`Question: What's on the picture? Answer:`). I've tried different GPUs and\
    \ different servers, but without the quantised model, I am unable to produce any\
    \ output. The model loads into memory and is accessed during inference - it just\
    \ does not generate or return or display any new tokens (I have also increased\
    \ `max_new_tokens=50`, tried other prompts like the Pok\xE9mon example).\n\nAny\
    \ help would be appreciated.\n "
  created_at: 2023-10-19 13:20:19+00:00
  edited: true
  hidden: false
  id: 65313b2368a8764a565fbe31
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619623771844-5ecea265968f6028e0559fa5.jpeg?w=200&h=200&f=face
      fullname: Victor Sanh
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: true
      name: VictorSanh
      type: user
    createdAt: '2023-10-19T15:01:33.000Z'
    data:
      edited: false
      editors:
      - VictorSanh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8763697147369385
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619623771844-5ecea265968f6028e0559fa5.jpeg?w=200&h=200&f=face
          fullname: Victor Sanh
          isHf: true
          isPro: true
          name: VictorSanh
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;Pwicke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Pwicke\">@<span class=\"\
          underline\">Pwicke</span></a></span>\n\n\t</span></span>,<br>That does not\
          \ sound right indeed.<br>Could you say more about your env? In particular\
          \ transformers and tokenizers versions?<br>I'll try to reproduce the error.</p>\n"
        raw: 'Hi @Pwicke,

          That does not sound right indeed.

          Could you say more about your env? In particular transformers and tokenizers
          versions?

          I''ll try to reproduce the error.'
        updatedAt: '2023-10-19T15:01:33.853Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Pwicke
    id: 653144cd8b39121e2183e1c2
    type: comment
  author: VictorSanh
  content: 'Hi @Pwicke,

    That does not sound right indeed.

    Could you say more about your env? In particular transformers and tokenizers versions?

    I''ll try to reproduce the error.'
  created_at: 2023-10-19 14:01:33+00:00
  edited: false
  hidden: false
  id: 653144cd8b39121e2183e1c2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662715293681-619e38930b33fae198f1ec41.png?w=200&h=200&f=face
      fullname: Phil Wicke
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pwicke
      type: user
    createdAt: '2023-10-19T15:13:53.000Z'
    data:
      edited: false
      editors:
      - Pwicke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.24500972032546997
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662715293681-619e38930b33fae198f1ec41.png?w=200&h=200&f=face
          fullname: Phil Wicke
          isHf: false
          isPro: false
          name: Pwicke
          type: user
        html: '<p>Thank you for your response. </p>

          <p><code>      accelerate                0.24.0.dev0,   bitsandbytes              0.41.1,
          nvidia-cublas-cu12        12.1.3.1, python                    3.10.12     ,
          sentencepiece             0.1.99 ,tokenizers                0.14.1, torch                     2.1.0,
          transformers            4.35.0.dev0         </code></p>

          '
        raw: "Thank you for your response. \n\n`      \naccelerate               \
          \ 0.24.0.dev0,   bitsandbytes              0.41.1, nvidia-cublas-cu12  \
          \      12.1.3.1, python                    3.10.12     , sentencepiece \
          \            0.1.99 ,tokenizers                0.14.1, torch           \
          \          2.1.0, transformers            4.35.0.dev0         \n`"
        updatedAt: '2023-10-19T15:13:53.905Z'
      numEdits: 0
      reactions: []
    id: 653147b1175adfb85c80a69e
    type: comment
  author: Pwicke
  content: "Thank you for your response. \n\n`      \naccelerate                0.24.0.dev0,\
    \   bitsandbytes              0.41.1, nvidia-cublas-cu12        12.1.3.1, python\
    \                    3.10.12     , sentencepiece             0.1.99 ,tokenizers\
    \                0.14.1, torch                     2.1.0, transformers       \
    \     4.35.0.dev0         \n`"
  created_at: 2023-10-19 14:13:53+00:00
  edited: false
  hidden: false
  id: 653147b1175adfb85c80a69e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662715293681-619e38930b33fae198f1ec41.png?w=200&h=200&f=face
      fullname: Phil Wicke
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pwicke
      type: user
    createdAt: '2023-11-16T12:45:47.000Z'
    data:
      edited: true
      editors:
      - Pwicke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9438666105270386
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662715293681-619e38930b33fae198f1ec41.png?w=200&h=200&f=face
          fullname: Phil Wicke
          isHf: false
          isPro: false
          name: Pwicke
          type: user
        html: "<p>Could I ask for an update on this? <span data-props=\"{&quot;user&quot;:&quot;VictorSanh&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/VictorSanh\"\
          >@<span class=\"underline\">VictorSanh</span></a></span>\n\n\t</span></span>\
          \ </p>\n"
        raw: 'Could I ask for an update on this? @VictorSanh '
        updatedAt: '2023-11-16T12:46:00.607Z'
      numEdits: 1
      reactions: []
    id: 65560efbbf4c000cc629b288
    type: comment
  author: Pwicke
  content: 'Could I ask for an update on this? @VictorSanh '
  created_at: 2023-11-16 12:45:47+00:00
  edited: true
  hidden: false
  id: 65560efbbf4c000cc629b288
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fa58b13ef3c5b3bb6e555c7a32049402.svg
      fullname: Xie Yang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TITH
      type: user
    createdAt: '2023-11-22T03:04:21.000Z'
    data:
      edited: false
      editors:
      - TITH
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.956783652305603
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fa58b13ef3c5b3bb6e555c7a32049402.svg
          fullname: Xie Yang
          isHf: false
          isPro: false
          name: TITH
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Pwicke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Pwicke\">@<span class=\"\
          underline\">Pwicke</span></a></span>\n\n\t</span></span> Have you solved\
          \ this?</p>\n"
        raw: '@Pwicke Have you solved this?'
        updatedAt: '2023-11-22T03:04:21.002Z'
      numEdits: 0
      reactions: []
    id: 655d6fb5c93b21514323fb2b
    type: comment
  author: TITH
  content: '@Pwicke Have you solved this?'
  created_at: 2023-11-22 03:04:21+00:00
  edited: false
  hidden: false
  id: 655d6fb5c93b21514323fb2b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662715293681-619e38930b33fae198f1ec41.png?w=200&h=200&f=face
      fullname: Phil Wicke
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pwicke
      type: user
    createdAt: '2023-11-22T17:05:09.000Z'
    data:
      edited: false
      editors:
      - Pwicke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9815434813499451
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662715293681-619e38930b33fae198f1ec41.png?w=200&h=200&f=face
          fullname: Phil Wicke
          isHf: false
          isPro: false
          name: Pwicke
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TITH&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TITH\">@<span class=\"\
          underline\">TITH</span></a></span>\n\n\t</span></span> unfortunately not.\
          \ I have to use the 4-bit quantised version. I recently tried the full model\
          \ again, but still no new tokens are being generated. Do you have the same\
          \ issue?</p>\n"
        raw: '@TITH unfortunately not. I have to use the 4-bit quantised version.
          I recently tried the full model again, but still no new tokens are being
          generated. Do you have the same issue?'
        updatedAt: '2023-11-22T17:05:09.405Z'
      numEdits: 0
      reactions: []
    id: 655e34c50523479b97e94529
    type: comment
  author: Pwicke
  content: '@TITH unfortunately not. I have to use the 4-bit quantised version. I
    recently tried the full model again, but still no new tokens are being generated.
    Do you have the same issue?'
  created_at: 2023-11-22 17:05:09+00:00
  edited: false
  hidden: false
  id: 655e34c50523479b97e94529
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fa58b13ef3c5b3bb6e555c7a32049402.svg
      fullname: Xie Yang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TITH
      type: user
    createdAt: '2023-11-23T01:10:43.000Z'
    data:
      edited: false
      editors:
      - TITH
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9678632616996765
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fa58b13ef3c5b3bb6e555c7a32049402.svg
          fullname: Xie Yang
          isHf: false
          isPro: false
          name: TITH
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Pwicke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Pwicke\">@<span class=\"\
          underline\">Pwicke</span></a></span>\n\n\t</span></span> Yes. But I noticed\
          \ that using cpu instead of cuda can solve it. Then I switched to torch\
          \ 2.0.1 and cuda works as well.</p>\n"
        raw: '@Pwicke Yes. But I noticed that using cpu instead of cuda can solve
          it. Then I switched to torch 2.0.1 and cuda works as well.'
        updatedAt: '2023-11-23T01:10:43.147Z'
      numEdits: 0
      reactions: []
    id: 655ea6930bda1e8ff824e30c
    type: comment
  author: TITH
  content: '@Pwicke Yes. But I noticed that using cpu instead of cuda can solve it.
    Then I switched to torch 2.0.1 and cuda works as well.'
  created_at: 2023-11-23 01:10:43+00:00
  edited: false
  hidden: false
  id: 655ea6930bda1e8ff824e30c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662715293681-619e38930b33fae198f1ec41.png?w=200&h=200&f=face
      fullname: Phil Wicke
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pwicke
      type: user
    createdAt: '2023-11-28T08:55:00.000Z'
    data:
      edited: false
      editors:
      - Pwicke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9773949384689331
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662715293681-619e38930b33fae198f1ec41.png?w=200&h=200&f=face
          fullname: Phil Wicke
          isHf: false
          isPro: false
          name: Pwicke
          type: user
        html: "<p>Thanks for the response <span data-props=\"{&quot;user&quot;:&quot;TITH&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TITH\"\
          >@<span class=\"underline\">TITH</span></a></span>\n\n\t</span></span> .\
          \ I've tried cpu and it works. But since I also switched to torch 2.0.1,\
          \ it does no longer use my gpu even though it's specified to do so. Now,\
          \ I am running my experiment on cpu, which is suboptimal.</p>\n"
        raw: Thanks for the response @TITH . I've tried cpu and it works. But since
          I also switched to torch 2.0.1, it does no longer use my gpu even though
          it's specified to do so. Now, I am running my experiment on cpu, which is
          suboptimal.
        updatedAt: '2023-11-28T08:55:00.236Z'
      numEdits: 0
      reactions: []
    id: 6565aae4cfbe8a8570745768
    type: comment
  author: Pwicke
  content: Thanks for the response @TITH . I've tried cpu and it works. But since
    I also switched to torch 2.0.1, it does no longer use my gpu even though it's
    specified to do so. Now, I am running my experiment on cpu, which is suboptimal.
  created_at: 2023-11-28 08:55:00+00:00
  edited: false
  hidden: false
  id: 6565aae4cfbe8a8570745768
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: HuggingFaceM4/idefics-9b-instruct
repo_type: model
status: open
target_branch: null
title: No output generated with sample code on non-quantised model
