!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kastan
conflicting_files: null
created_at: 2023-09-28 18:10:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6271c16667ff0a433db5839d/jHCt86Zs03gLWXRKIK2pD.jpeg?w=200&h=200&f=face
      fullname: Kastan Day
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kastan
      type: user
    createdAt: '2023-09-28T19:10:23.000Z'
    data:
      edited: false
      editors:
      - kastan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6637275815010071
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6271c16667ff0a433db5839d/jHCt86Zs03gLWXRKIK2pD.jpeg?w=200&h=200&f=face
          fullname: Kastan Day
          isHf: false
          isPro: false
          name: kastan
          type: user
        html: "<p>I have this model running on the Endpoints API, but I can't get\
          \ it to accept BOTH text and image inputs simultaneously.<br><a rel=\"nofollow\"\
          \ href=\"https://cdn-uploads.huggingface.co/production/uploads/6271c16667ff0a433db5839d/5JzzfS7kaKLjFun6Gq3jv.png\"\
          ><img alt=\"CleanShot 2023-09-28 at 12.07.44.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6271c16667ff0a433db5839d/5JzzfS7kaKLjFun6Gq3jv.png\"\
          ></a></p>\n<p>What is the required schema? </p>\n<p>I also asked here: <a\
          \ rel=\"nofollow\" href=\"https://github.com/huggingface/api-inference-community/issues/336\"\
          >https://github.com/huggingface/api-inference-community/issues/336</a></p>\n\
          <p>I got close, but it seems it only accepts a single string as input because\
          \ it's part of the \"Text-Generation\" family of models. </p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">import</span> json\n\
          <span class=\"hljs-keyword\">import</span> requests\n<span class=\"hljs-keyword\"\
          >import</span> base64\n\nimg_url = <span class=\"hljs-string\">\"https://upload.wikimedia.org/wikipedia/commons/8/86/Id%C3%A9fix.JPG\"\
          </span>\nAPI_URL = <span class=\"hljs-string\">\"https://api-inference.huggingface.co/models/HuggingFaceM4/idefics-9b-instruct\"\
          </span> \nheaders = {\n    <span class=\"hljs-string\">\"Authorization\"\
          </span>: <span class=\"hljs-string\">f\"Bearer <span class=\"hljs-subst\"\
          >{HF_TOKEN}</span>\"</span>,\n    <span class=\"hljs-string\">\"Content-Type\"\
          </span>: <span class=\"hljs-string\">\"application/json\"</span>\n}\n\n\
          <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\"\
          >query</span>(<span class=\"hljs-params\">image_url</span>):\n    response\
          \ = requests.get(image_url)\n    image_bytes = response.content\n    encoded_image\
          \ = base64.b64encode(image_bytes).decode(<span class=\"hljs-string\">'utf-8'</span>)\n\
          \    data = {\n        <span class=\"hljs-string\">\"inputs\"</span>: img_url,\n\
          \            <span class=\"hljs-comment\"># \"prompt\": \"What's in this\
          \ image?\",</span>\n            <span class=\"hljs-comment\"># \"prompt\"\
          : encoded_image</span>\n        <span class=\"hljs-comment\"># }</span>\n\
          \        <span class=\"hljs-comment\"># \"image\": encoded_image,</span>\n\
          \        <span class=\"hljs-comment\"># \"inputs\": \"What's in this image?\"\
          ,</span>\n    }\n    json_data = json.dumps(data)\n    <span class=\"hljs-built_in\"\
          >print</span>(<span class=\"hljs-string\">\"my request\"</span>, json_data)\n\
          \    response = requests.request(<span class=\"hljs-string\">\"POST\"</span>,\
          \ API_URL, headers=headers, data=json_data)\n    <span class=\"hljs-built_in\"\
          >print</span>(<span class=\"hljs-string\">\"Response content:\"</span>,\
          \ response.content)\n    <span class=\"hljs-keyword\">return</span> json.loads(response.content.decode(<span\
          \ class=\"hljs-string\">\"utf-8\"</span>))\n\n<span class=\"hljs-built_in\"\
          >print</span>(query(img_url))\n\n<span class=\"hljs-comment\">## The results\
          \ seem nearly there! </span>\n<span class=\"hljs-comment\">## [{'generated_text':\
          \ 'https://upload.wikimedia.org/wikipedia/commons/8/86/Id%C3%A9fix.JPGScooby-Doo,\
          \ Where Are You!'}]</span>\n</code></pre>\n"
        raw: "I have this model running on the Endpoints API, but I can't get it to\
          \ accept BOTH text and image inputs simultaneously. \r\n![CleanShot 2023-09-28\
          \ at 12.07.44.png](https://cdn-uploads.huggingface.co/production/uploads/6271c16667ff0a433db5839d/5JzzfS7kaKLjFun6Gq3jv.png)\r\
          \n\r\nWhat is the required schema? \r\n\r\nI also asked here: https://github.com/huggingface/api-inference-community/issues/336\r\
          \n\r\nI got close, but it seems it only accepts a single string as input\
          \ because it's part of the \"Text-Generation\" family of models. \r\n\r\n\
          ```python\r\nimport json\r\nimport requests\r\nimport base64\r\n\r\nimg_url\
          \ = \"https://upload.wikimedia.org/wikipedia/commons/8/86/Id%C3%A9fix.JPG\"\
          \r\nAPI_URL = \"https://api-inference.huggingface.co/models/HuggingFaceM4/idefics-9b-instruct\"\
          \ \r\nheaders = {\r\n    \"Authorization\": f\"Bearer {HF_TOKEN}\",\r\n\
          \    \"Content-Type\": \"application/json\"\r\n}\r\n\r\ndef query(image_url):\r\
          \n    response = requests.get(image_url)\r\n    image_bytes = response.content\r\
          \n    encoded_image = base64.b64encode(image_bytes).decode('utf-8')\r\n\
          \    data = {\r\n        \"inputs\": img_url,\r\n            # \"prompt\"\
          : \"What's in this image?\",\r\n            # \"prompt\": encoded_image\r\
          \n        # }\r\n        # \"image\": encoded_image,\r\n        # \"inputs\"\
          : \"What's in this image?\",\r\n    }\r\n    json_data = json.dumps(data)\r\
          \n    print(\"my request\", json_data)\r\n    response = requests.request(\"\
          POST\", API_URL, headers=headers, data=json_data)\r\n    print(\"Response\
          \ content:\", response.content)\r\n    return json.loads(response.content.decode(\"\
          utf-8\"))\r\n\r\nprint(query(img_url))\r\n\r\n## The results seem nearly\
          \ there! \r\n## [{'generated_text': 'https://upload.wikimedia.org/wikipedia/commons/8/86/Id%C3%A9fix.JPGScooby-Doo,\
          \ Where Are You!'}]\r\n```"
        updatedAt: '2023-09-28T19:10:23.139Z'
      numEdits: 0
      reactions: []
    id: 6515cf9f6f8a6fa0d983d482
    type: comment
  author: kastan
  content: "I have this model running on the Endpoints API, but I can't get it to\
    \ accept BOTH text and image inputs simultaneously. \r\n![CleanShot 2023-09-28\
    \ at 12.07.44.png](https://cdn-uploads.huggingface.co/production/uploads/6271c16667ff0a433db5839d/5JzzfS7kaKLjFun6Gq3jv.png)\r\
    \n\r\nWhat is the required schema? \r\n\r\nI also asked here: https://github.com/huggingface/api-inference-community/issues/336\r\
    \n\r\nI got close, but it seems it only accepts a single string as input because\
    \ it's part of the \"Text-Generation\" family of models. \r\n\r\n```python\r\n\
    import json\r\nimport requests\r\nimport base64\r\n\r\nimg_url = \"https://upload.wikimedia.org/wikipedia/commons/8/86/Id%C3%A9fix.JPG\"\
    \r\nAPI_URL = \"https://api-inference.huggingface.co/models/HuggingFaceM4/idefics-9b-instruct\"\
    \ \r\nheaders = {\r\n    \"Authorization\": f\"Bearer {HF_TOKEN}\",\r\n    \"\
    Content-Type\": \"application/json\"\r\n}\r\n\r\ndef query(image_url):\r\n   \
    \ response = requests.get(image_url)\r\n    image_bytes = response.content\r\n\
    \    encoded_image = base64.b64encode(image_bytes).decode('utf-8')\r\n    data\
    \ = {\r\n        \"inputs\": img_url,\r\n            # \"prompt\": \"What's in\
    \ this image?\",\r\n            # \"prompt\": encoded_image\r\n        # }\r\n\
    \        # \"image\": encoded_image,\r\n        # \"inputs\": \"What's in this\
    \ image?\",\r\n    }\r\n    json_data = json.dumps(data)\r\n    print(\"my request\"\
    , json_data)\r\n    response = requests.request(\"POST\", API_URL, headers=headers,\
    \ data=json_data)\r\n    print(\"Response content:\", response.content)\r\n  \
    \  return json.loads(response.content.decode(\"utf-8\"))\r\n\r\nprint(query(img_url))\r\
    \n\r\n## The results seem nearly there! \r\n## [{'generated_text': 'https://upload.wikimedia.org/wikipedia/commons/8/86/Id%C3%A9fix.JPGScooby-Doo,\
    \ Where Are You!'}]\r\n```"
  created_at: 2023-09-28 18:10:23+00:00
  edited: false
  hidden: false
  id: 6515cf9f6f8a6fa0d983d482
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652185658647-6244866a456803e9500d0f6a.jpeg?w=200&h=200&f=face
      fullname: Leo Tronchon
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Leyo
      type: user
    createdAt: '2023-09-29T15:42:08.000Z'
    data:
      edited: true
      editors:
      - Leyo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5169444680213928
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652185658647-6244866a456803e9500d0f6a.jpeg?w=200&h=200&f=face
          fullname: Leo Tronchon
          isHf: true
          isPro: false
          name: Leyo
          type: user
        html: "<p>Hi!<br>For TGI, if you look into the <a href=\"https://huggingface.co/spaces/HuggingFaceM4/idefics_playground\"\
          >IDEFICS Playground</a> code for example, you'll see this piece of code:</p>\n\
          <pre><code>def prompt_list_to_tgi_input(prompt_list: List[str]) -&gt; str:\n\
          \    \"\"\"\n    TGI expects a string that contains both text and images\
          \ in the image markdown format (i.e. the `![]()` ).\n    The images links\
          \ are parsed on TGI side\n    \"\"\"\n    result_string_input = \"\"\n \
          \   for elem in prompt_list:\n        if is_image(elem):\n            if\
          \ is_url(elem):\n                result_string_input += f\"![]({elem})\"\
          \n            else:\n                result_string_input += f\"![]({gradio_link(img_path=elem)})\"\
          \n        else:\n            result_string_input += elem\n    return result_string_input\n\
          </code></pre>\n<p>As the docstrings says, TGI is expecting a string with\
          \ images in markdown format, so if you pass a list of interleaved image,\
          \ text to this function it should work.</p>\n"
        raw: "Hi!\nFor TGI, if you look into the [IDEFICS Playground](https://huggingface.co/spaces/HuggingFaceM4/idefics_playground)\
          \ code for example, you'll see this piece of code:\n```\ndef prompt_list_to_tgi_input(prompt_list:\
          \ List[str]) -> str:\n    \"\"\"\n    TGI expects a string that contains\
          \ both text and images in the image markdown format (i.e. the `![]()` ).\n\
          \    The images links are parsed on TGI side\n    \"\"\"\n    result_string_input\
          \ = \"\"\n    for elem in prompt_list:\n        if is_image(elem):\n   \
          \         if is_url(elem):\n                result_string_input += f\"![]({elem})\"\
          \n            else:\n                result_string_input += f\"![]({gradio_link(img_path=elem)})\"\
          \n        else:\n            result_string_input += elem\n    return result_string_input\n\
          ```\n\nAs the docstrings says, TGI is expecting a string with images in\
          \ markdown format, so if you pass a list of interleaved image, text to this\
          \ function it should work."
        updatedAt: '2023-09-29T15:42:46.347Z'
      numEdits: 1
      reactions: []
    id: 6516f05070746a75c1ef5c58
    type: comment
  author: Leyo
  content: "Hi!\nFor TGI, if you look into the [IDEFICS Playground](https://huggingface.co/spaces/HuggingFaceM4/idefics_playground)\
    \ code for example, you'll see this piece of code:\n```\ndef prompt_list_to_tgi_input(prompt_list:\
    \ List[str]) -> str:\n    \"\"\"\n    TGI expects a string that contains both\
    \ text and images in the image markdown format (i.e. the `![]()` ).\n    The images\
    \ links are parsed on TGI side\n    \"\"\"\n    result_string_input = \"\"\n \
    \   for elem in prompt_list:\n        if is_image(elem):\n            if is_url(elem):\n\
    \                result_string_input += f\"![]({elem})\"\n            else:\n\
    \                result_string_input += f\"![]({gradio_link(img_path=elem)})\"\
    \n        else:\n            result_string_input += elem\n    return result_string_input\n\
    ```\n\nAs the docstrings says, TGI is expecting a string with images in markdown\
    \ format, so if you pass a list of interleaved image, text to this function it\
    \ should work."
  created_at: 2023-09-29 14:42:08+00:00
  edited: true
  hidden: false
  id: 6516f05070746a75c1ef5c58
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: HuggingFaceM4/idefics-9b-instruct
repo_type: model
status: open
target_branch: null
title: Inference on HF Endpoints API?
