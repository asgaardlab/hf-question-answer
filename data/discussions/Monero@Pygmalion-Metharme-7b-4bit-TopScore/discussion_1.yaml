!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BoreGuy1998
conflicting_files: null
created_at: 2023-05-02 00:19:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
      fullname: Bored Guy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BoreGuy1998
      type: user
    createdAt: '2023-05-02T01:19:05.000Z'
    data:
      edited: false
      editors:
      - BoreGuy1998
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
          fullname: Bored Guy
          isHf: false
          isPro: false
          name: BoreGuy1998
          type: user
        html: '<p>Can''t determine model type from model name</p>

          '
        raw: Can't determine model type from model name
        updatedAt: '2023-05-02T01:19:05.927Z'
      numEdits: 0
      reactions: []
    id: 6450650955932790bc87f017
    type: comment
  author: BoreGuy1998
  content: Can't determine model type from model name
  created_at: 2023-05-02 00:19:05+00:00
  edited: false
  hidden: false
  id: 6450650955932790bc87f017
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63d625232e397d9f8e1eccac/AOZv_jnPhcj9t6thSs11d.png?w=200&h=200&f=face
      fullname: YellowRoseCx
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Monero
      type: user
    createdAt: '2023-05-02T01:35:07.000Z'
    data:
      edited: true
      editors:
      - Monero
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63d625232e397d9f8e1eccac/AOZv_jnPhcj9t6thSs11d.png?w=200&h=200&f=face
          fullname: YellowRoseCx
          isHf: false
          isPro: false
          name: Monero
          type: user
        html: '<blockquote>

          <p>Can''t determine model type from model name</p>

          </blockquote>

          <p>well , what software are you running? if you can provide details maybe
          someone can help. theres probably a certain way you have to name the file
          for the program you''re using</p>

          '
        raw: '> Can''t determine model type from model name


          well , what software are you running? if you can provide details maybe someone
          can help. theres probably a certain way you have to name the file for the
          program you''re using'
        updatedAt: '2023-05-02T01:36:18.951Z'
      numEdits: 1
      reactions: []
    id: 645068cbd5f7dafcfa6d920a
    type: comment
  author: Monero
  content: '> Can''t determine model type from model name


    well , what software are you running? if you can provide details maybe someone
    can help. theres probably a certain way you have to name the file for the program
    you''re using'
  created_at: 2023-05-02 00:35:07+00:00
  edited: true
  hidden: false
  id: 645068cbd5f7dafcfa6d920a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
      fullname: Bored Guy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BoreGuy1998
      type: user
    createdAt: '2023-05-02T01:46:35.000Z'
    data:
      edited: false
      editors:
      - BoreGuy1998
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
          fullname: Bored Guy
          isHf: false
          isPro: false
          name: BoreGuy1998
          type: user
        html: '<p>Nvidia if that is what you mean by software.</p>

          '
        raw: Nvidia if that is what you mean by software.
        updatedAt: '2023-05-02T01:46:35.346Z'
      numEdits: 0
      reactions: []
    id: 64506b7b28774bd665e4d416
    type: comment
  author: BoreGuy1998
  content: Nvidia if that is what you mean by software.
  created_at: 2023-05-02 00:46:35+00:00
  edited: false
  hidden: false
  id: 64506b7b28774bd665e4d416
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63d625232e397d9f8e1eccac/AOZv_jnPhcj9t6thSs11d.png?w=200&h=200&f=face
      fullname: YellowRoseCx
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Monero
      type: user
    createdAt: '2023-05-02T01:53:22.000Z'
    data:
      edited: false
      editors:
      - Monero
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63d625232e397d9f8e1eccac/AOZv_jnPhcj9t6thSs11d.png?w=200&h=200&f=face
          fullname: YellowRoseCx
          isHf: false
          isPro: false
          name: Monero
          type: user
        html: '<blockquote>

          <p>Nvidia if that is what you mean by software.</p>

          </blockquote>

          <p>no i mean what program are you using to run the model? I googled the
          error you got and it looks like it''s with oobabooga''s text ui and that
          it needs a certain naming scheme</p>

          '
        raw: '> Nvidia if that is what you mean by software.


          no i mean what program are you using to run the model? I googled the error
          you got and it looks like it''s with oobabooga''s text ui and that it needs
          a certain naming scheme'
        updatedAt: '2023-05-02T01:53:22.454Z'
      numEdits: 0
      reactions: []
    id: 64506d1228774bd665e4f385
    type: comment
  author: Monero
  content: '> Nvidia if that is what you mean by software.


    no i mean what program are you using to run the model? I googled the error you
    got and it looks like it''s with oobabooga''s text ui and that it needs a certain
    naming scheme'
  created_at: 2023-05-02 00:53:22+00:00
  edited: false
  hidden: false
  id: 64506d1228774bd665e4f385
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
      fullname: Bored Guy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BoreGuy1998
      type: user
    createdAt: '2023-05-02T02:01:48.000Z'
    data:
      edited: false
      editors:
      - BoreGuy1998
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
          fullname: Bored Guy
          isHf: false
          isPro: false
          name: BoreGuy1998
          type: user
        html: '<blockquote>

          <blockquote>

          <p>Can''t determine model type from model name</p>

          </blockquote>

          <p>well , what software are you running? if you can provide details maybe
          someone can help. theres probably a certain way you have to name the file
          for the program you''re using<br>oobabooga_windows\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
          line 2405, in from_pretrained<br>    raise EnvironmentError(<br>OSError:
          Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or
          flax_model.msgpack found in directory models\Monero_Pygmalion-Metharme-7b-4bit-TopScore.</p>

          </blockquote>

          <p>I hope this helps.</p>

          '
        raw: "> > Can't determine model type from model name\n> \n> well , what software\
          \ are you running? if you can provide details maybe someone can help. theres\
          \ probably a certain way you have to name the file for the program you're\
          \ using\noobabooga_windows\\installer_files\\env\\lib\\site-packages\\transformers\\\
          modeling_utils.py\", line 2405, in from_pretrained\n    raise EnvironmentError(\n\
          OSError: Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index\
          \ or flax_model.msgpack found in directory models\\Monero_Pygmalion-Metharme-7b-4bit-TopScore.\n\
          \nI hope this helps."
        updatedAt: '2023-05-02T02:01:48.029Z'
      numEdits: 0
      reactions: []
    id: 64506f0c577838187e07f0ef
    type: comment
  author: BoreGuy1998
  content: "> > Can't determine model type from model name\n> \n> well , what software\
    \ are you running? if you can provide details maybe someone can help. theres probably\
    \ a certain way you have to name the file for the program you're using\noobabooga_windows\\\
    installer_files\\env\\lib\\site-packages\\transformers\\modeling_utils.py\", line\
    \ 2405, in from_pretrained\n    raise EnvironmentError(\nOSError: Error no file\
    \ named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
    \ found in directory models\\Monero_Pygmalion-Metharme-7b-4bit-TopScore.\n\nI\
    \ hope this helps."
  created_at: 2023-05-02 01:01:48+00:00
  edited: false
  hidden: false
  id: 64506f0c577838187e07f0ef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
      fullname: Bored Guy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BoreGuy1998
      type: user
    createdAt: '2023-05-02T02:15:05.000Z'
    data:
      edited: false
      editors:
      - BoreGuy1998
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
          fullname: Bored Guy
          isHf: false
          isPro: false
          name: BoreGuy1998
          type: user
        html: '<p>There is also this if that is what you meant by the program. The
          detected CUDA version (12.1) mismatches the version that was used to compile<br>PyTorch
          (11.7). Please make sure to use the same CUDA versions.</p>

          '
        raw: 'There is also this if that is what you meant by the program. The detected
          CUDA version (12.1) mismatches the version that was used to compile

          PyTorch (11.7). Please make sure to use the same CUDA versions.'
        updatedAt: '2023-05-02T02:15:05.786Z'
      numEdits: 0
      reactions: []
    id: 64507229577838187e0833cc
    type: comment
  author: BoreGuy1998
  content: 'There is also this if that is what you meant by the program. The detected
    CUDA version (12.1) mismatches the version that was used to compile

    PyTorch (11.7). Please make sure to use the same CUDA versions.'
  created_at: 2023-05-02 01:15:05+00:00
  edited: false
  hidden: false
  id: 64507229577838187e0833cc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/32bcafdd0b472786bb390c3f4b2716a9.svg
      fullname: Electric Fox
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ElectricFox
      type: user
    createdAt: '2023-05-02T02:16:31.000Z'
    data:
      edited: false
      editors:
      - ElectricFox
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/32bcafdd0b472786bb390c3f4b2716a9.svg
          fullname: Electric Fox
          isHf: false
          isPro: false
          name: ElectricFox
          type: user
        html: '<blockquote>

          <p>Can''t determine model type from model name</p>

          </blockquote>

          <p>also having this issue I am using oobabooga with pygmalion-7b-4bit-128g-cuda
          following a video from Aitrepreneur</p>

          '
        raw: '> Can''t determine model type from model name


          also having this issue I am using oobabooga with pygmalion-7b-4bit-128g-cuda
          following a video from Aitrepreneur'
        updatedAt: '2023-05-02T02:16:31.741Z'
      numEdits: 0
      reactions: []
    id: 6450727f20ba3e3e4bf74cb4
    type: comment
  author: ElectricFox
  content: '> Can''t determine model type from model name


    also having this issue I am using oobabooga with pygmalion-7b-4bit-128g-cuda following
    a video from Aitrepreneur'
  created_at: 2023-05-02 01:16:31+00:00
  edited: false
  hidden: false
  id: 6450727f20ba3e3e4bf74cb4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d9f6914ed563088d58873eb65976438c.svg
      fullname: rashan bashan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: flygacabra
      type: user
    createdAt: '2023-05-02T13:17:37.000Z'
    data:
      edited: false
      editors:
      - flygacabra
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d9f6914ed563088d58873eb65976438c.svg
          fullname: rashan bashan
          isHf: false
          isPro: false
          name: flygacabra
          type: user
        html: '<p>start it with --model_type llama</p>

          '
        raw: start it with --model_type llama
        updatedAt: '2023-05-02T13:17:37.828Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - barl2021
        - yugihu
    id: 64510d7141f3c769b909cd8e
    type: comment
  author: flygacabra
  content: start it with --model_type llama
  created_at: 2023-05-02 12:17:37+00:00
  edited: false
  hidden: false
  id: 64510d7141f3c769b909cd8e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cada7d3ba0a0082519841f40bfd4bab4.svg
      fullname: Barley Corn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: barl2021
      type: user
    createdAt: '2023-05-02T13:45:28.000Z'
    data:
      edited: false
      editors:
      - barl2021
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cada7d3ba0a0082519841f40bfd4bab4.svg
          fullname: Barley Corn
          isHf: false
          isPro: false
          name: barl2021
          type: user
        html: '<blockquote>

          <p>start it with --model_type llama</p>

          </blockquote>

          <p>That fixed it for me, thanks!</p>

          '
        raw: '> start it with --model_type llama


          That fixed it for me, thanks!'
        updatedAt: '2023-05-02T13:45:28.337Z'
      numEdits: 0
      reactions: []
    id: 645113f85fb40b9f50a7e8cb
    type: comment
  author: barl2021
  content: '> start it with --model_type llama


    That fixed it for me, thanks!'
  created_at: 2023-05-02 12:45:28+00:00
  edited: false
  hidden: false
  id: 645113f85fb40b9f50a7e8cb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
      fullname: Bored Guy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BoreGuy1998
      type: user
    createdAt: '2023-05-02T17:09:49.000Z'
    data:
      edited: false
      editors:
      - BoreGuy1998
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
          fullname: Bored Guy
          isHf: false
          isPro: false
          name: BoreGuy1998
          type: user
        html: '<blockquote>

          <blockquote>

          <p>start it with --model_type llama</p>

          </blockquote>

          <p>That fixed it for me, thanks!</p>

          </blockquote>

          <p>Where should I put that in?</p>

          '
        raw: "> > start it with --model_type llama\n> \n> That fixed it for me, thanks!\n\
          \nWhere should I put that in?"
        updatedAt: '2023-05-02T17:09:49.079Z'
      numEdits: 0
      reactions: []
    id: 645143ddb3f75261a7d7f6e5
    type: comment
  author: BoreGuy1998
  content: "> > start it with --model_type llama\n> \n> That fixed it for me, thanks!\n\
    \nWhere should I put that in?"
  created_at: 2023-05-02 16:09:49+00:00
  edited: false
  hidden: false
  id: 645143ddb3f75261a7d7f6e5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
      fullname: Bored Guy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BoreGuy1998
      type: user
    createdAt: '2023-05-02T17:13:57.000Z'
    data:
      edited: false
      editors:
      - BoreGuy1998
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
          fullname: Bored Guy
          isHf: false
          isPro: false
          name: BoreGuy1998
          type: user
        html: '<p>Getting this I doubt I am putting this in the right place.</p>

          <p>At line:1 char:3</p>

          <ul>

          <li>--model_type llama</li>

          <li>~<br>Missing expression after unary operator ''--''.<br>At line:1 char:3</li>

          <li>--model_type llama</li>

          <li>~~~~~~~~~~<br>Unexpected token ''model_type'' in expression or statement.<ul>

          <li>CategoryInfo          : ParserError: (:) [], ParentContainsErrorRecordException</li>

          <li>FullyQualifiedErrorId : MissingExpressionAfterOperator</li>

          </ul>

          </li>

          </ul>

          '
        raw: "Getting this I doubt I am putting this in the right place.\n\nAt line:1\
          \ char:3\n+ --model_type llama\n+   ~\nMissing expression after unary operator\
          \ '--'.\nAt line:1 char:3\n+ --model_type llama\n+   ~~~~~~~~~~\nUnexpected\
          \ token 'model_type' in expression or statement.\n    + CategoryInfo   \
          \       : ParserError: (:) [], ParentContainsErrorRecordException\n    +\
          \ FullyQualifiedErrorId : MissingExpressionAfterOperator"
        updatedAt: '2023-05-02T17:13:57.734Z'
      numEdits: 0
      reactions: []
    id: 645144d541f3c769b910a6c0
    type: comment
  author: BoreGuy1998
  content: "Getting this I doubt I am putting this in the right place.\n\nAt line:1\
    \ char:3\n+ --model_type llama\n+   ~\nMissing expression after unary operator\
    \ '--'.\nAt line:1 char:3\n+ --model_type llama\n+   ~~~~~~~~~~\nUnexpected token\
    \ 'model_type' in expression or statement.\n    + CategoryInfo          : ParserError:\
    \ (:) [], ParentContainsErrorRecordException\n    + FullyQualifiedErrorId : MissingExpressionAfterOperator"
  created_at: 2023-05-02 16:13:57+00:00
  edited: false
  hidden: false
  id: 645144d541f3c769b910a6c0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
      fullname: Bored Guy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BoreGuy1998
      type: user
    createdAt: '2023-05-02T22:53:46.000Z'
    data:
      edited: false
      editors:
      - BoreGuy1998
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f7024da58278399b5a38d0ee6f525887.svg
          fullname: Bored Guy
          isHf: false
          isPro: false
          name: BoreGuy1998
          type: user
        html: '<blockquote>

          <p>start it with --model_type llama</p>

          </blockquote>

          <p>Where do I put this in oobabooga?</p>

          '
        raw: '> start it with --model_type llama


          Where do I put this in oobabooga?'
        updatedAt: '2023-05-02T22:53:46.029Z'
      numEdits: 0
      reactions: []
    id: 6451947ab3f75261a7e12b02
    type: comment
  author: BoreGuy1998
  content: '> start it with --model_type llama


    Where do I put this in oobabooga?'
  created_at: 2023-05-02 21:53:46+00:00
  edited: false
  hidden: false
  id: 6451947ab3f75261a7e12b02
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63d625232e397d9f8e1eccac/AOZv_jnPhcj9t6thSs11d.png?w=200&h=200&f=face
      fullname: YellowRoseCx
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Monero
      type: user
    createdAt: '2023-05-03T01:55:55.000Z'
    data:
      edited: false
      editors:
      - Monero
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63d625232e397d9f8e1eccac/AOZv_jnPhcj9t6thSs11d.png?w=200&h=200&f=face
          fullname: YellowRoseCx
          isHf: false
          isPro: false
          name: Monero
          type: user
        html: '<blockquote>

          <blockquote>

          <p>start it with --model_type llama</p>

          </blockquote>

          <p>Where do I put this in oobabooga?</p>

          </blockquote>

          <p>Probably as part of the launch options or the model type selector in
          the web ui</p>

          '
        raw: "> > start it with --model_type llama\n> \n> Where do I put this in oobabooga?\n\
          \nProbably as part of the launch options or the model type selector in the\
          \ web ui"
        updatedAt: '2023-05-03T01:55:55.983Z'
      numEdits: 0
      reactions: []
    id: 6451bf2b9d916c596e3bddba
    type: comment
  author: Monero
  content: "> > start it with --model_type llama\n> \n> Where do I put this in oobabooga?\n\
    \nProbably as part of the launch options or the model type selector in the web\
    \ ui"
  created_at: 2023-05-03 00:55:55+00:00
  edited: false
  hidden: false
  id: 6451bf2b9d916c596e3bddba
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/463e621d6252efcf7a38221522b4e6aa.svg
      fullname: Bharat
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Bharatvid
      type: user
    createdAt: '2023-05-03T17:51:57.000Z'
    data:
      edited: true
      editors:
      - Bharatvid
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/463e621d6252efcf7a38221522b4e6aa.svg
          fullname: Bharat
          isHf: false
          isPro: false
          name: Bharatvid
          type: user
        html: '<blockquote>

          <blockquote>

          <p>start it with --model_type llama</p>

          </blockquote>

          <p>Where do I put this in oobabooga?</p>

          </blockquote>

          <p>I think that would be in webui.py file.<br>Open the file, search ''python
          server.py'' and add there.</p>

          <p>Not sure, but it might take every model as llama, so may be other model
          might or might not work.<br>So, may be you can try selecting llama from
          oobabooga web ui and reload. If it doesn''t work, you can try above solution.</p>

          '
        raw: "> > start it with --model_type llama\n> \n> Where do I put this in oobabooga?\n\
          \nI think that would be in webui.py file. \nOpen the file, search 'python\
          \ server.py' and add there.\n\nNot sure, but it might take every model as\
          \ llama, so may be other model might or might not work.\nSo, may be you\
          \ can try selecting llama from oobabooga web ui and reload. If it doesn't\
          \ work, you can try above solution."
        updatedAt: '2023-05-03T18:11:32.061Z'
      numEdits: 1
      reactions: []
    id: 64529f3da0c0a664a245607f
    type: comment
  author: Bharatvid
  content: "> > start it with --model_type llama\n> \n> Where do I put this in oobabooga?\n\
    \nI think that would be in webui.py file. \nOpen the file, search 'python server.py'\
    \ and add there.\n\nNot sure, but it might take every model as llama, so may be\
    \ other model might or might not work.\nSo, may be you can try selecting llama\
    \ from oobabooga web ui and reload. If it doesn't work, you can try above solution."
  created_at: 2023-05-03 16:51:57+00:00
  edited: true
  hidden: false
  id: 64529f3da0c0a664a245607f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Monero/Pygmalion-Metharme-7b-4bit-TopScore
repo_type: model
status: open
target_branch: null
title: How can I fix this issue?
