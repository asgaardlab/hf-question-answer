!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Allayte
conflicting_files: null
created_at: 2023-02-15 14:51:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9e8e940538ef8a5b0c1d59566dc3dd90.svg
      fullname: Alayt Issak
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Allayte
      type: user
    createdAt: '2023-02-15T14:51:21.000Z'
    data:
      edited: true
      editors:
      - Allayte
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9e8e940538ef8a5b0c1d59566dc3dd90.svg
          fullname: Alayt Issak
          isHf: false
          isPro: false
          name: Allayte
          type: user
        html: '<p>Is there a way to visualize the latent space in between the encoder
          and decoder? I see there are reconstruction and interpolation functionalities
          but couldn''t seem to find a way to do so (using beta-vae as well).</p>

          '
        raw: Is there a way to visualize the latent space in between the encoder and
          decoder? I see there are reconstruction and interpolation functionalities
          but couldn't seem to find a way to do so (using beta-vae as well).
        updatedAt: '2023-02-15T14:52:09.301Z'
      numEdits: 2
      reactions: []
    id: 63ecf169c5b3c734085d352c
    type: comment
  author: Allayte
  content: Is there a way to visualize the latent space in between the encoder and
    decoder? I see there are reconstruction and interpolation functionalities but
    couldn't seem to find a way to do so (using beta-vae as well).
  created_at: 2023-02-15 14:51:21+00:00
  edited: true
  hidden: false
  id: 63ecf169c5b3c734085d352c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b9a24e98c7b2d306bd5302e537825d9a.svg
      fullname: "Cl\xE9ment Chadebec"
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: clementchadebec
      type: user
    createdAt: '2023-02-15T15:01:54.000Z'
    data:
      edited: false
      editors:
      - clementchadebec
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b9a24e98c7b2d306bd5302e537825d9a.svg
          fullname: "Cl\xE9ment Chadebec"
          isHf: false
          isPro: false
          name: clementchadebec
          type: user
        html: '<p>Hey!<br>Yes you can simply do the following:</p>

          <pre><code class="language-python"><span class="hljs-meta">&gt;&gt;&gt;
          </span>model.encoder(your_data).embedding

          </code></pre>

          <p>E.g.</p>

          <pre><code class="language-python"><span class="hljs-meta">&gt;&gt;&gt;
          </span><span class="hljs-keyword">from</span> pythae.models <span class="hljs-keyword">import</span>
          AutoModel

          <span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.load_from_hf_hub(<span
          class="hljs-string">"clementchadebec/reproduced_beta_tc_vae"</span>, allow_pickle=<span
          class="hljs-literal">True</span>)

          Downloading config file ...

          Downloading BetaTCVAE files <span class="hljs-keyword">for</span> rebuilding...

          Successfully downloaded BetaTCVAE model!

          <span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span>
          torch

          <span class="hljs-meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="hljs-number">3</span>,
          <span class="hljs-number">1</span>, <span class="hljs-number">64</span>,
          <span class="hljs-number">64</span>)

          <span class="hljs-meta">&gt;&gt;&gt; </span>emb = model.encoder(x).embedding

          <span class="hljs-meta">&gt;&gt;&gt; </span>emb.shape

          torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">10</span>])

          </code></pre>

          '
        raw: 'Hey!

          Yes you can simply do the following:

          ```python

          >>> model.encoder(your_data).embedding

          ```

          E.g.

          ```python

          >>> from pythae.models import AutoModel

          >>> model = AutoModel.load_from_hf_hub("clementchadebec/reproduced_beta_tc_vae",
          allow_pickle=True)

          Downloading config file ...

          Downloading BetaTCVAE files for rebuilding...

          Successfully downloaded BetaTCVAE model!

          >>> import torch

          >>> x = torch.randn(3, 1, 64, 64)

          >>> emb = model.encoder(x).embedding

          >>> emb.shape

          torch.Size([3, 10])

          ```'
        updatedAt: '2023-02-15T15:01:54.129Z'
      numEdits: 0
      reactions: []
    id: 63ecf3e2f3827af9bb4a03ec
    type: comment
  author: clementchadebec
  content: 'Hey!

    Yes you can simply do the following:

    ```python

    >>> model.encoder(your_data).embedding

    ```

    E.g.

    ```python

    >>> from pythae.models import AutoModel

    >>> model = AutoModel.load_from_hf_hub("clementchadebec/reproduced_beta_tc_vae",
    allow_pickle=True)

    Downloading config file ...

    Downloading BetaTCVAE files for rebuilding...

    Successfully downloaded BetaTCVAE model!

    >>> import torch

    >>> x = torch.randn(3, 1, 64, 64)

    >>> emb = model.encoder(x).embedding

    >>> emb.shape

    torch.Size([3, 10])

    ```'
  created_at: 2023-02-15 15:01:54+00:00
  edited: false
  hidden: false
  id: 63ecf3e2f3827af9bb4a03ec
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9e8e940538ef8a5b0c1d59566dc3dd90.svg
      fullname: Alayt Issak
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Allayte
      type: user
    createdAt: '2023-02-16T04:13:27.000Z'
    data:
      edited: false
      editors:
      - Allayte
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9e8e940538ef8a5b0c1d59566dc3dd90.svg
          fullname: Alayt Issak
          isHf: false
          isPro: false
          name: Allayte
          type: user
        html: "<p>Awesome. Thank you! I've added the ability to view it such like\
          \ the previous examples here!</p>\n<pre><code>emb = trained_model.encoder(X_test.float()[:25].to(device).detach().cpu()).embedding\n\
          # emb.shape = torch.Size([25, 16])\n\nembeddings = emb.reshape(emb.shape[0],1,4,4)\n\
          # embeddings.shape = torch.Size([25, 1, 4, 4])\n\nfig, axes = plt.subplots(nrows=5,\
          \ ncols=5, figsize=(5, 5))\n\nwith torch.no_grad():\n  for i in range(5):\n\
          \      for j in range(5):\n          axes[i][j].imshow(embeddings[i*5 +\
          \ j].cpu().squeeze(0), cmap='gray')\n          axes[i][j].axis('off')\n\
          \  plt.tight_layout(pad=0.2)\n</code></pre>\n"
        raw: "Awesome. Thank you! I've added the ability to view it such like the\
          \ previous examples here!\n\n```\nemb = trained_model.encoder(X_test.float()[:25].to(device).detach().cpu()).embedding\n\
          # emb.shape = torch.Size([25, 16])\n\nembeddings = emb.reshape(emb.shape[0],1,4,4)\n\
          # embeddings.shape = torch.Size([25, 1, 4, 4])\n\nfig, axes = plt.subplots(nrows=5,\
          \ ncols=5, figsize=(5, 5))\n\nwith torch.no_grad():\n  for i in range(5):\n\
          \      for j in range(5):\n          axes[i][j].imshow(embeddings[i*5 +\
          \ j].cpu().squeeze(0), cmap='gray')\n          axes[i][j].axis('off')\n\
          \  plt.tight_layout(pad=0.2)\n```"
        updatedAt: '2023-02-16T04:13:27.370Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - clementchadebec
    id: 63edad67eba811fd643a06dd
    type: comment
  author: Allayte
  content: "Awesome. Thank you! I've added the ability to view it such like the previous\
    \ examples here!\n\n```\nemb = trained_model.encoder(X_test.float()[:25].to(device).detach().cpu()).embedding\n\
    # emb.shape = torch.Size([25, 16])\n\nembeddings = emb.reshape(emb.shape[0],1,4,4)\n\
    # embeddings.shape = torch.Size([25, 1, 4, 4])\n\nfig, axes = plt.subplots(nrows=5,\
    \ ncols=5, figsize=(5, 5))\n\nwith torch.no_grad():\n  for i in range(5):\n  \
    \    for j in range(5):\n          axes[i][j].imshow(embeddings[i*5 + j].cpu().squeeze(0),\
    \ cmap='gray')\n          axes[i][j].axis('off')\n  plt.tight_layout(pad=0.2)\n\
    ```"
  created_at: 2023-02-16 04:13:27+00:00
  edited: false
  hidden: false
  id: 63edad67eba811fd643a06dd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9e8e940538ef8a5b0c1d59566dc3dd90.svg
      fullname: Alayt Issak
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Allayte
      type: user
    createdAt: '2023-02-16T15:32:45.000Z'
    data:
      status: closed
    id: 63ee4c9d6349d1a670690f1b
    type: status-change
  author: Allayte
  created_at: 2023-02-16 15:32:45+00:00
  id: 63ee4c9d6349d1a670690f1b
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b9a24e98c7b2d306bd5302e537825d9a.svg
      fullname: "Cl\xE9ment Chadebec"
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: clementchadebec
      type: user
    createdAt: '2023-02-24T20:54:58.000Z'
    data:
      edited: false
      editors:
      - clementchadebec
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b9a24e98c7b2d306bd5302e537825d9a.svg
          fullname: "Cl\xE9ment Chadebec"
          isHf: false
          isPro: false
          name: clementchadebec
          type: user
        html: '<p>Thank you so much for this!</p>

          '
        raw: Thank you so much for this!
        updatedAt: '2023-02-24T20:54:58.638Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - Allayte
    id: 63f92422ce1f61ce151329e2
    type: comment
  author: clementchadebec
  content: Thank you so much for this!
  created_at: 2023-02-24 20:54:58+00:00
  edited: false
  hidden: false
  id: 63f92422ce1f61ce151329e2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: clementchadebec/reproduced_beta_tc_vae
repo_type: model
status: closed
target_branch: null
title: Visualizing Latent space
