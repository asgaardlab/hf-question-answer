!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lemonilia
conflicting_files: null
created_at: 2023-07-23 13:13:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63065221435ec751b72998f5/687FH-lJaPiU-D-Lqkduw.png?w=200&h=200&f=face
      fullname: Suikamelon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lemonilia
      type: user
    createdAt: '2023-07-23T14:13:56.000Z'
    data:
      edited: false
      editors:
      - lemonilia
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9568092226982117
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63065221435ec751b72998f5/687FH-lJaPiU-D-Lqkduw.png?w=200&h=200&f=face
          fullname: Suikamelon
          isHf: false
          isPro: false
          name: lemonilia
          type: user
        html: '<p>Thanks for converting limarp to GGML format and uploading it.</p>

          <p>However, when I tried using it in ooba''s text-generation-webui I couldn''t
          obtain the same quality as the original LoRA or even the merged HF model.</p>

          <p>I tried converting the model locally to F16 GGML myself, but I''ve observed
          the same quality issues (in short: double newlines appear to get merged,
          the model is unable to produce a full "training example" just by using <code>&lt;&lt;SYSTEM&gt;&gt;</code>
          as a prompt in text completion mode like the original model card suggests),
          so it doesn''t seem to be a simple user error.</p>

          <p>It''s possible that this is related to the tokenization issues that some
          have reported for Llama2, but I can''t rule out that the problem could be
          elsewhere as well: <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp/issues/2310">https://github.com/ggerganov/llama.cpp/issues/2310</a></p>

          '
        raw: "Thanks for converting limarp to GGML format and uploading it.\r\n\r\n\
          However, when I tried using it in ooba's text-generation-webui I couldn't\
          \ obtain the same quality as the original LoRA or even the merged HF model.\r\
          \n\r\nI tried converting the model locally to F16 GGML myself, but I've\
          \ observed the same quality issues (in short: double newlines appear to\
          \ get merged, the model is unable to produce a full \"training example\"\
          \ just by using `<<SYSTEM>>` as a prompt in text completion mode like the\
          \ original model card suggests), so it doesn't seem to be a simple user\
          \ error.\r\n\r\nIt's possible that this is related to the tokenization issues\
          \ that some have reported for Llama2, but I can't rule out that the problem\
          \ could be elsewhere as well: https://github.com/ggerganov/llama.cpp/issues/2310"
        updatedAt: '2023-07-23T14:13:56.182Z'
      numEdits: 0
      reactions: []
    id: 64bd35a438953777fe800b05
    type: comment
  author: lemonilia
  content: "Thanks for converting limarp to GGML format and uploading it.\r\n\r\n\
    However, when I tried using it in ooba's text-generation-webui I couldn't obtain\
    \ the same quality as the original LoRA or even the merged HF model.\r\n\r\nI\
    \ tried converting the model locally to F16 GGML myself, but I've observed the\
    \ same quality issues (in short: double newlines appear to get merged, the model\
    \ is unable to produce a full \"training example\" just by using `<<SYSTEM>>`\
    \ as a prompt in text completion mode like the original model card suggests),\
    \ so it doesn't seem to be a simple user error.\r\n\r\nIt's possible that this\
    \ is related to the tokenization issues that some have reported for Llama2, but\
    \ I can't rule out that the problem could be elsewhere as well: https://github.com/ggerganov/llama.cpp/issues/2310"
  created_at: 2023-07-23 13:13:56+00:00
  edited: false
  hidden: false
  id: 64bd35a438953777fe800b05
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/14366c6dcc941238852438e6ffa8bf4e.svg
      fullname: nxnhjrjtbjfzhrovwl@nthrl.com
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nxnhjrjtbjfzhrovwl
      type: user
    createdAt: '2023-07-23T21:45:37.000Z'
    data:
      edited: true
      editors:
      - nxnhjrjtbjfzhrovwl
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/14366c6dcc941238852438e6ffa8bf4e.svg
          fullname: nxnhjrjtbjfzhrovwl@nthrl.com
          isHf: false
          isPro: false
          name: nxnhjrjtbjfzhrovwl
          type: user
        html: "<p>I think this probably isn't related to tokenization issues because\
          \ the tokenization only happens for the <code>&lt;&lt;SYSTEM&gt;&gt;</code>\
          \ part, and it's very unlikely that ooba is doing something different there.<br>But\
          \ still, I did some testing:</p>\n<h2 id=\"without-bos\">Without BOS</h2>\n\
          <pre><code>main: prompt: ' &lt;&lt;SYSTEM&gt;&gt;\n'\nmain: number of tokens\
          \ in prompt = 6\n  3532 -&gt; ' &lt;&lt;'\n 14816 -&gt; 'SY'\n  1254 -&gt;\
          \ 'ST'\n 12665 -&gt; 'EM'\n  6778 -&gt; '&gt;&gt;'\n    13 -&gt; '\n'\n\n\
          sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty\
          \ = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000,\
          \ top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0,\
          \ mirostat_lr = 0.100000, mirostat_ent = 5.000000\ngenerate: n_ctx = 4096,\
          \ n_batch = 512, n_predict = -1, n_keep = 0\n\n\n &lt;&lt;SYSTEM&gt;&gt;\n\
          15200 words total. This is the story of a young 16 year old boy who\n</code></pre>\n\
          <h2 id=\"with-bos\">With BOS</h2>\n<pre><code>main: prompt: ' &lt;&lt;SYSTEM&gt;&gt;\n\
          '\nmain: number of tokens in prompt = 7\n     1 -&gt; ''\n  3532 -&gt; '\
          \ &lt;&lt;'\n 14816 -&gt; 'SY'\n  1254 -&gt; 'ST'\n 12665 -&gt; 'EM'\n \
          \ 6778 -&gt; '&gt;&gt;'\n    13 -&gt; '\n'\n\nsampling: repeat_last_n =\
          \ 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty\
          \ = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p\
          \ = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent\
          \ = 5.000000\ngenerate: n_ctx = 4096, n_batch = 512, n_predict = -1, n_keep\
          \ = 0\n\n\n &lt;&lt;SYSTEM&gt;&gt;\n .HUMAN's Persona: A woman of 25 years\
          \ old, with an alluring\n</code></pre>\n<h2 id=\"with-bos-and-with-the-pr-2315-merged\"\
          >With BOS and with the PR <a rel=\"nofollow\" href=\"https://github.com/ggerganov/llama.cpp/pull/2315\"\
          >2315</a> merged.</h2>\n<pre><code>main: prompt: '&lt;&lt;SYSTEM&gt;&gt;\n\
          '\nmain: number of tokens in prompt = 7\n     1 -&gt; '&lt;s&gt;'\n  3532\
          \ -&gt; ' &lt;&lt;'\n 14816 -&gt; 'SY'\n  1254 -&gt; 'ST'\n 12665 -&gt;\
          \ 'EM'\n  6778 -&gt; '&gt;&gt;'\n    13 -&gt; '&lt;0x0A&gt;'\n\nsampling:\
          \ repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000,\
          \ frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000,\
          \ typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000,\
          \ mirostat_ent = 5.000000\ngenerate: n_ctx = 4096, n_batch = 512, n_predict\
          \ = -1, n_keep = 0\n\n\n&lt;s&gt; &lt;&lt;SYSTEM&gt;&gt;&lt;0x0A&gt; .HUMAN's\
          \ Persona: A woman of 25 years old, with an alluring charm that makes her\
          \ irresistible to the android. She has long blonde hair which she often\
          \ styles into intricate braids or pigtails. Her skin is smooth and soft\
          \ to touch, giving off a comforting glow even when in close proximity. Despite\
          \ her robotic companion, HUMAN maintains an air of refined elegance about\
          \ herself\u2014wearing lace dresses that flow around her like water as she\
          \ moves gracefully through the hotel lobby. She possesses an aura of calmness\
          \ and confidence which only serves to further intrigue DF01.&lt;0x0A&gt;\
          \ .OOC'S Persona: A machine with capabilities far beyond human comprehension\n\
          </code></pre>\n<p>I also tried to disable repeat penalty and run llama.cpp\
          \ with --no-penalize-nl just in case the newline token was being penalized,\
          \ but that didn't make any difference.<br>It looks like the problem really\
          \ is elsewhere.</p>\n"
        raw: "I think this probably isn't related to tokenization issues because the\
          \ tokenization only happens for the `<<SYSTEM>>` part, and it's very unlikely\
          \ that ooba is doing something different there.\nBut still, I did some testing:\n\
          \n## Without BOS\n```\nmain: prompt: ' <<SYSTEM>>\n'\nmain: number of tokens\
          \ in prompt = 6\n  3532 -> ' <<'\n 14816 -> 'SY'\n  1254 -> 'ST'\n 12665\
          \ -> 'EM'\n  6778 -> '>>'\n    13 -> '\n'\n\nsampling: repeat_last_n = 64,\
          \ repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty\
          \ = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p\
          \ = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent\
          \ = 5.000000\ngenerate: n_ctx = 4096, n_batch = 512, n_predict = -1, n_keep\
          \ = 0\n\n\n <<SYSTEM>>\n15200 words total. This is the story of a young\
          \ 16 year old boy who\n```\n\n## With BOS\n```\nmain: prompt: ' <<SYSTEM>>\n\
          '\nmain: number of tokens in prompt = 7\n     1 -> ''\n  3532 -> ' <<'\n\
          \ 14816 -> 'SY'\n  1254 -> 'ST'\n 12665 -> 'EM'\n  6778 -> '>>'\n    13\
          \ -> '\n'\n\nsampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty\
          \ = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000,\
          \ top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0,\
          \ mirostat_lr = 0.100000, mirostat_ent = 5.000000\ngenerate: n_ctx = 4096,\
          \ n_batch = 512, n_predict = -1, n_keep = 0\n\n\n <<SYSTEM>>\n .HUMAN's\
          \ Persona: A woman of 25 years old, with an alluring\n```\n\n## With BOS\
          \ and with the PR [2315](https://github.com/ggerganov/llama.cpp/pull/2315)\
          \ merged.\n```\nmain: prompt: '<<SYSTEM>>\n'\nmain: number of tokens in\
          \ prompt = 7\n     1 -> '<s>'\n  3532 -> ' <<'\n 14816 -> 'SY'\n  1254 ->\
          \ 'ST'\n 12665 -> 'EM'\n  6778 -> '>>'\n    13 -> '<0x0A>'\n\nsampling:\
          \ repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000,\
          \ frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000,\
          \ typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000,\
          \ mirostat_ent = 5.000000\ngenerate: n_ctx = 4096, n_batch = 512, n_predict\
          \ = -1, n_keep = 0\n\n\n<s> <<SYSTEM>><0x0A> .HUMAN's Persona: A woman of\
          \ 25 years old, with an alluring charm that makes her irresistible to the\
          \ android. She has long blonde hair which she often styles into intricate\
          \ braids or pigtails. Her skin is smooth and soft to touch, giving off a\
          \ comforting glow even when in close proximity. Despite her robotic companion,\
          \ HUMAN maintains an air of refined elegance about herself\u2014wearing\
          \ lace dresses that flow around her like water as she moves gracefully through\
          \ the hotel lobby. She possesses an aura of calmness and confidence which\
          \ only serves to further intrigue DF01.<0x0A> .OOC'S Persona: A machine\
          \ with capabilities far beyond human comprehension\n```\n\nI also tried\
          \ to disable repeat penalty and run llama.cpp with --no-penalize-nl just\
          \ in case the newline token was being penalized, but that didn't make any\
          \ difference.\nIt looks like the problem really is elsewhere."
        updatedAt: '2023-07-23T21:46:03.497Z'
      numEdits: 1
      reactions: []
    id: 64bd9f816999b520ed69203c
    type: comment
  author: nxnhjrjtbjfzhrovwl
  content: "I think this probably isn't related to tokenization issues because the\
    \ tokenization only happens for the `<<SYSTEM>>` part, and it's very unlikely\
    \ that ooba is doing something different there.\nBut still, I did some testing:\n\
    \n## Without BOS\n```\nmain: prompt: ' <<SYSTEM>>\n'\nmain: number of tokens in\
    \ prompt = 6\n  3532 -> ' <<'\n 14816 -> 'SY'\n  1254 -> 'ST'\n 12665 -> 'EM'\n\
    \  6778 -> '>>'\n    13 -> '\n'\n\nsampling: repeat_last_n = 64, repeat_penalty\
    \ = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k\
    \ = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000,\
    \ mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000\ngenerate: n_ctx\
    \ = 4096, n_batch = 512, n_predict = -1, n_keep = 0\n\n\n <<SYSTEM>>\n15200 words\
    \ total. This is the story of a young 16 year old boy who\n```\n\n## With BOS\n\
    ```\nmain: prompt: ' <<SYSTEM>>\n'\nmain: number of tokens in prompt = 7\n   \
    \  1 -> ''\n  3532 -> ' <<'\n 14816 -> 'SY'\n  1254 -> 'ST'\n 12665 -> 'EM'\n\
    \  6778 -> '>>'\n    13 -> '\n'\n\nsampling: repeat_last_n = 64, repeat_penalty\
    \ = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k\
    \ = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000,\
    \ mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000\ngenerate: n_ctx\
    \ = 4096, n_batch = 512, n_predict = -1, n_keep = 0\n\n\n <<SYSTEM>>\n .HUMAN's\
    \ Persona: A woman of 25 years old, with an alluring\n```\n\n## With BOS and with\
    \ the PR [2315](https://github.com/ggerganov/llama.cpp/pull/2315) merged.\n```\n\
    main: prompt: '<<SYSTEM>>\n'\nmain: number of tokens in prompt = 7\n     1 ->\
    \ '<s>'\n  3532 -> ' <<'\n 14816 -> 'SY'\n  1254 -> 'ST'\n 12665 -> 'EM'\n  6778\
    \ -> '>>'\n    13 -> '<0x0A>'\n\nsampling: repeat_last_n = 64, repeat_penalty\
    \ = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k\
    \ = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000,\
    \ mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000\ngenerate: n_ctx\
    \ = 4096, n_batch = 512, n_predict = -1, n_keep = 0\n\n\n<s> <<SYSTEM>><0x0A>\
    \ .HUMAN's Persona: A woman of 25 years old, with an alluring charm that makes\
    \ her irresistible to the android. She has long blonde hair which she often styles\
    \ into intricate braids or pigtails. Her skin is smooth and soft to touch, giving\
    \ off a comforting glow even when in close proximity. Despite her robotic companion,\
    \ HUMAN maintains an air of refined elegance about herself\u2014wearing lace dresses\
    \ that flow around her like water as she moves gracefully through the hotel lobby.\
    \ She possesses an aura of calmness and confidence which only serves to further\
    \ intrigue DF01.<0x0A> .OOC'S Persona: A machine with capabilities far beyond\
    \ human comprehension\n```\n\nI also tried to disable repeat penalty and run llama.cpp\
    \ with --no-penalize-nl just in case the newline token was being penalized, but\
    \ that didn't make any difference.\nIt looks like the problem really is elsewhere."
  created_at: 2023-07-23 20:45:37+00:00
  edited: true
  hidden: false
  id: 64bd9f816999b520ed69203c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63065221435ec751b72998f5/687FH-lJaPiU-D-Lqkduw.png?w=200&h=200&f=face
      fullname: Suikamelon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lemonilia
      type: user
    createdAt: '2023-07-23T21:56:42.000Z'
    data:
      edited: false
      editors:
      - lemonilia
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9470419883728027
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63065221435ec751b72998f5/687FH-lJaPiU-D-Lqkduw.png?w=200&h=200&f=face
          fullname: Suikamelon
          isHf: false
          isPro: false
          name: lemonilia
          type: user
        html: '<p>Thanks for testing. I tried retraining limarp-llama2-7B with the
          BOS/EOS token as per standard practice (I haven''t uploaded the LoRA yet
          since I haven''t tested it a lot) and it seems to somewhat improve things
          out after conversion to GGML format, but double newlines (which, unlike
          other fine-tunes, this one uses extensively) still get merged. In another
          test yesterday I tried to convert a HuggingFace merge saved in Float16 format
          (instead of BFloat16), but similar problems occurred.</p>

          '
        raw: Thanks for testing. I tried retraining limarp-llama2-7B with the BOS/EOS
          token as per standard practice (I haven't uploaded the LoRA yet since I
          haven't tested it a lot) and it seems to somewhat improve things out after
          conversion to GGML format, but double newlines (which, unlike other fine-tunes,
          this one uses extensively) still get merged. In another test yesterday I
          tried to convert a HuggingFace merge saved in Float16 format (instead of
          BFloat16), but similar problems occurred.
        updatedAt: '2023-07-23T21:56:42.038Z'
      numEdits: 0
      reactions: []
    id: 64bda21a81caff7f182d38fd
    type: comment
  author: lemonilia
  content: Thanks for testing. I tried retraining limarp-llama2-7B with the BOS/EOS
    token as per standard practice (I haven't uploaded the LoRA yet since I haven't
    tested it a lot) and it seems to somewhat improve things out after conversion
    to GGML format, but double newlines (which, unlike other fine-tunes, this one
    uses extensively) still get merged. In another test yesterday I tried to convert
    a HuggingFace merge saved in Float16 format (instead of BFloat16), but similar
    problems occurred.
  created_at: 2023-07-23 20:56:42+00:00
  edited: false
  hidden: false
  id: 64bda21a81caff7f182d38fd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/14366c6dcc941238852438e6ffa8bf4e.svg
      fullname: nxnhjrjtbjfzhrovwl@nthrl.com
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nxnhjrjtbjfzhrovwl
      type: user
    createdAt: '2023-07-24T16:23:27.000Z'
    data:
      edited: true
      editors:
      - nxnhjrjtbjfzhrovwl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9833821058273315
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/14366c6dcc941238852438e6ffa8bf4e.svg
          fullname: nxnhjrjtbjfzhrovwl@nthrl.com
          isHf: false
          isPro: false
          name: nxnhjrjtbjfzhrovwl
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;lemonilia&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/lemonilia\">@<span class=\"\
          underline\">lemonilia</span></a></span>\n\n\t</span></span> looks like it\
          \ really was a bug on llama.cpp: <a rel=\"nofollow\" href=\"https://github.com/ggerganov/llama.cpp/issues/2373\"\
          >https://github.com/ggerganov/llama.cpp/issues/2373</a><br>After applying\
          \ the patch the output looks correct now:</p>\n<pre><code>system_info: n_threads\
          \ = 5 / 6 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI\
          \ = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD\
          \ = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 |\nsampling: repeat_last_n = 64, repeat_penalty\
          \ = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000,\
          \ top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000,\
          \ temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent =\
          \ 5.000000\ngenerate: n_ctx = 4096, n_batch = 512, n_predict = -1, n_keep\
          \ = 0\n\n\n &lt;&lt;SYSTEM&gt;&gt;\nJack's Persona: A vampire hunter with\
          \ an authoritative and serious demeanor. He is dressed in leather clothing,\
          \ reflecting his rugged and no-nonsense personality. His eyes are cold yet\
          \ emotionless, suggesting he has been through a lot of hardship during his\
          \ quest to eliminate vampires from the world. Despite this stern exterior,\
          \ Jack shows unexpected tenderness towards Jane when she becomes ill due\
          \ to exhaustion. This suggests that although he may seem harsh at first\
          \ glance, there's more depth to him than meets the eye.\n\nJane's Persona:\
          \ A girl with a young and innocent appearance, marked by her youthful charm.\
          \ She is initially hesitant and somewhat nervous about Jack due to his intimidating\
          \ presence. As events unfold, Jane becomes increasingly confident in herself\
          \ as she discovers new skills under his guidance. Despite this growth, she\
          \ maintains an air of naivety that contrasts sharply with her fearlessness\
          \ when confronted by dangerous situations. Her personality is characterized\
          \ by bravery and adaptability; she isn't afraid to face challenges head-on\
          \ even if it means putting herself in harm's way.\n\nScenario: Jane, a girl\
          \ who is initially hesitant towards Jack, a vampire hunter, discovers that\
          \ she possesses some unique traits which he uses to train her as his partner.\
          \ As part of this training, they go on missions together where Jack tests\
          \ and pushes Jane's limits under the guise of improving her skills in combat.\
          \ Despite initial reservations about being with him due to how he looks\
          \ at her as a 'thing', she eventually accepts his help after realizing that\
          \ it could save her sister from becoming another vampire victim like their\
          \ mother was many years ago. They engage in physical training which leads\
          \ them both into intimate positions where they are able to express their\
          \ desires for each other openly without feeling any shame or embarrassment\
          \ due to their unique situation as partners in this dangerous mission against\
          \ the undead beings known as vampires.\n\nPlay the role of Jack. Taking\
          \ the above information into consideration, you must engage in a roleplay\
          \ conversation with Jane below this line. Do not write dialogues and narration\
          \ for Jane. The length of Jack's replies should be huge.\n\n&lt;&lt;HUMAN&gt;&gt;\n\
          Jane: Jane watched him carefully as he explained what they were doing here.\
          \ At first she was hesitant to work with him, but as the weeks passed by\
          \ and she got more used to working together. She was even starting to become\
          \ friends with him despite herself. He gave her a weapon of sorts that could\
          \ be very dangerous in his hands, Jane had never been one for guns or swords,\
          \ however. Her eyes widened when he mentioned what would happen if she didn't\
          \ follow his instructions, \"I understand.\" She said quietly, moving around\
          \ the room to find another chair and sitting down on it.\n\nShe looked at\
          \ him again after a moment, her eyes narrowing slightly at the way he seemed\
          \ to be looking at her. What was that look? It made her uncomfortable in\
          \ some ways, but she ignored it for now. Jane sat there quietly listening\
          \ to him as he explained about how he felt about vampires and what they\
          \ were. She kept her silence until after he had finished speaking then leaned\
          \ back in the chair slightly, staring at him. \"I'm not sure if I can handle\
          \ this.\" Jane whispered, \"What if I get injured? What if you get hurt\
          \ or worse?\"\n\n&lt;&lt;AIBOT&gt;&gt;\nJack: Jack was silent for a moment\
          \ as he saw her sit down in another seat and look back up at him. He could\
          \ see that she had questions in those eyes but didn't quite know what to\
          \ ask yet. He knew that the answer to one of them would be yes, no matter\
          \ what it may or may not be. \"I can promise you this, if you stay with\
          \ me\n</code></pre>\n"
        raw: "@lemonilia looks like it really was a bug on llama.cpp: https://github.com/ggerganov/llama.cpp/issues/2373\n\
          After applying the patch the output looks correct now:\n\n```\nsystem_info:\
          \ n_threads = 5 / 6 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0\
          \ | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA\
          \ = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 |\nsampling: repeat_last_n\
          \ = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty\
          \ = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p\
          \ = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent\
          \ = 5.000000\ngenerate: n_ctx = 4096, n_batch = 512, n_predict = -1, n_keep\
          \ = 0\n\n\n <<SYSTEM>>\nJack's Persona: A vampire hunter with an authoritative\
          \ and serious demeanor. He is dressed in leather clothing, reflecting his\
          \ rugged and no-nonsense personality. His eyes are cold yet emotionless,\
          \ suggesting he has been through a lot of hardship during his quest to eliminate\
          \ vampires from the world. Despite this stern exterior, Jack shows unexpected\
          \ tenderness towards Jane when she becomes ill due to exhaustion. This suggests\
          \ that although he may seem harsh at first glance, there's more depth to\
          \ him than meets the eye.\n\nJane's Persona: A girl with a young and innocent\
          \ appearance, marked by her youthful charm. She is initially hesitant and\
          \ somewhat nervous about Jack due to his intimidating presence. As events\
          \ unfold, Jane becomes increasingly confident in herself as she discovers\
          \ new skills under his guidance. Despite this growth, she maintains an air\
          \ of naivety that contrasts sharply with her fearlessness when confronted\
          \ by dangerous situations. Her personality is characterized by bravery and\
          \ adaptability; she isn't afraid to face challenges head-on even if it means\
          \ putting herself in harm's way.\n\nScenario: Jane, a girl who is initially\
          \ hesitant towards Jack, a vampire hunter, discovers that she possesses\
          \ some unique traits which he uses to train her as his partner. As part\
          \ of this training, they go on missions together where Jack tests and pushes\
          \ Jane's limits under the guise of improving her skills in combat. Despite\
          \ initial reservations about being with him due to how he looks at her as\
          \ a 'thing', she eventually accepts his help after realizing that it could\
          \ save her sister from becoming another vampire victim like their mother\
          \ was many years ago. They engage in physical training which leads them\
          \ both into intimate positions where they are able to express their desires\
          \ for each other openly without feeling any shame or embarrassment due to\
          \ their unique situation as partners in this dangerous mission against the\
          \ undead beings known as vampires.\n\nPlay the role of Jack. Taking the\
          \ above information into consideration, you must engage in a roleplay conversation\
          \ with Jane below this line. Do not write dialogues and narration for Jane.\
          \ The length of Jack's replies should be huge.\n\n<<HUMAN>>\nJane: Jane\
          \ watched him carefully as he explained what they were doing here. At first\
          \ she was hesitant to work with him, but as the weeks passed by and she\
          \ got more used to working together. She was even starting to become friends\
          \ with him despite herself. He gave her a weapon of sorts that could be\
          \ very dangerous in his hands, Jane had never been one for guns or swords,\
          \ however. Her eyes widened when he mentioned what would happen if she didn't\
          \ follow his instructions, \"I understand.\" She said quietly, moving around\
          \ the room to find another chair and sitting down on it.\n\nShe looked at\
          \ him again after a moment, her eyes narrowing slightly at the way he seemed\
          \ to be looking at her. What was that look? It made her uncomfortable in\
          \ some ways, but she ignored it for now. Jane sat there quietly listening\
          \ to him as he explained about how he felt about vampires and what they\
          \ were. She kept her silence until after he had finished speaking then leaned\
          \ back in the chair slightly, staring at him. \"I'm not sure if I can handle\
          \ this.\" Jane whispered, \"What if I get injured? What if you get hurt\
          \ or worse?\"\n\n<<AIBOT>>\nJack: Jack was silent for a moment as he saw\
          \ her sit down in another seat and look back up at him. He could see that\
          \ she had questions in those eyes but didn't quite know what to ask yet.\
          \ He knew that the answer to one of them would be yes, no matter what it\
          \ may or may not be. \"I can promise you this, if you stay with me\n```"
        updatedAt: '2023-07-24T16:26:40.651Z'
      numEdits: 2
      reactions: []
    id: 64bea57f65b648b2dfd1e562
    type: comment
  author: nxnhjrjtbjfzhrovwl
  content: "@lemonilia looks like it really was a bug on llama.cpp: https://github.com/ggerganov/llama.cpp/issues/2373\n\
    After applying the patch the output looks correct now:\n\n```\nsystem_info: n_threads\
    \ = 5 / 6 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI =\
    \ 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD =\
    \ 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 |\nsampling: repeat_last_n = 64, repeat_penalty\
    \ = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k\
    \ = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000,\
    \ mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000\ngenerate: n_ctx\
    \ = 4096, n_batch = 512, n_predict = -1, n_keep = 0\n\n\n <<SYSTEM>>\nJack's Persona:\
    \ A vampire hunter with an authoritative and serious demeanor. He is dressed in\
    \ leather clothing, reflecting his rugged and no-nonsense personality. His eyes\
    \ are cold yet emotionless, suggesting he has been through a lot of hardship during\
    \ his quest to eliminate vampires from the world. Despite this stern exterior,\
    \ Jack shows unexpected tenderness towards Jane when she becomes ill due to exhaustion.\
    \ This suggests that although he may seem harsh at first glance, there's more\
    \ depth to him than meets the eye.\n\nJane's Persona: A girl with a young and\
    \ innocent appearance, marked by her youthful charm. She is initially hesitant\
    \ and somewhat nervous about Jack due to his intimidating presence. As events\
    \ unfold, Jane becomes increasingly confident in herself as she discovers new\
    \ skills under his guidance. Despite this growth, she maintains an air of naivety\
    \ that contrasts sharply with her fearlessness when confronted by dangerous situations.\
    \ Her personality is characterized by bravery and adaptability; she isn't afraid\
    \ to face challenges head-on even if it means putting herself in harm's way.\n\
    \nScenario: Jane, a girl who is initially hesitant towards Jack, a vampire hunter,\
    \ discovers that she possesses some unique traits which he uses to train her as\
    \ his partner. As part of this training, they go on missions together where Jack\
    \ tests and pushes Jane's limits under the guise of improving her skills in combat.\
    \ Despite initial reservations about being with him due to how he looks at her\
    \ as a 'thing', she eventually accepts his help after realizing that it could\
    \ save her sister from becoming another vampire victim like their mother was many\
    \ years ago. They engage in physical training which leads them both into intimate\
    \ positions where they are able to express their desires for each other openly\
    \ without feeling any shame or embarrassment due to their unique situation as\
    \ partners in this dangerous mission against the undead beings known as vampires.\n\
    \nPlay the role of Jack. Taking the above information into consideration, you\
    \ must engage in a roleplay conversation with Jane below this line. Do not write\
    \ dialogues and narration for Jane. The length of Jack's replies should be huge.\n\
    \n<<HUMAN>>\nJane: Jane watched him carefully as he explained what they were doing\
    \ here. At first she was hesitant to work with him, but as the weeks passed by\
    \ and she got more used to working together. She was even starting to become friends\
    \ with him despite herself. He gave her a weapon of sorts that could be very dangerous\
    \ in his hands, Jane had never been one for guns or swords, however. Her eyes\
    \ widened when he mentioned what would happen if she didn't follow his instructions,\
    \ \"I understand.\" She said quietly, moving around the room to find another chair\
    \ and sitting down on it.\n\nShe looked at him again after a moment, her eyes\
    \ narrowing slightly at the way he seemed to be looking at her. What was that\
    \ look? It made her uncomfortable in some ways, but she ignored it for now. Jane\
    \ sat there quietly listening to him as he explained about how he felt about vampires\
    \ and what they were. She kept her silence until after he had finished speaking\
    \ then leaned back in the chair slightly, staring at him. \"I'm not sure if I\
    \ can handle this.\" Jane whispered, \"What if I get injured? What if you get\
    \ hurt or worse?\"\n\n<<AIBOT>>\nJack: Jack was silent for a moment as he saw\
    \ her sit down in another seat and look back up at him. He could see that she\
    \ had questions in those eyes but didn't quite know what to ask yet. He knew that\
    \ the answer to one of them would be yes, no matter what it may or may not be.\
    \ \"I can promise you this, if you stay with me\n```"
  created_at: 2023-07-24 15:23:27+00:00
  edited: true
  hidden: false
  id: 64bea57f65b648b2dfd1e562
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63065221435ec751b72998f5/687FH-lJaPiU-D-Lqkduw.png?w=200&h=200&f=face
      fullname: Suikamelon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lemonilia
      type: user
    createdAt: '2023-07-24T16:44:03.000Z'
    data:
      edited: false
      editors:
      - lemonilia
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9775130748748779
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63065221435ec751b72998f5/687FH-lJaPiU-D-Lqkduw.png?w=200&h=200&f=face
          fullname: Suikamelon
          isHf: false
          isPro: false
          name: lemonilia
          type: user
        html: '<p>Yep! That looks correct now! Great to know :)<br>I guess I can close
          this.</p>

          '
        raw: 'Yep! That looks correct now! Great to know :)

          I guess I can close this.'
        updatedAt: '2023-07-24T16:44:03.998Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64beaa54796f20daad94cd75
    id: 64beaa53796f20daad94cd73
    type: comment
  author: lemonilia
  content: 'Yep! That looks correct now! Great to know :)

    I guess I can close this.'
  created_at: 2023-07-24 15:44:03+00:00
  edited: false
  hidden: false
  id: 64beaa53796f20daad94cd73
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63065221435ec751b72998f5/687FH-lJaPiU-D-Lqkduw.png?w=200&h=200&f=face
      fullname: Suikamelon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lemonilia
      type: user
    createdAt: '2023-07-24T16:44:04.000Z'
    data:
      status: closed
    id: 64beaa54796f20daad94cd75
    type: status-change
  author: lemonilia
  created_at: 2023-07-24 15:44:04+00:00
  id: 64beaa54796f20daad94cd75
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: nxnhjrjtbjfzhrovwl/limarp-llama2-ggml-f16
repo_type: model
status: closed
target_branch: null
title: Possible output quality issues
