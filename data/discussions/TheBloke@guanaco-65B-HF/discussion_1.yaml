!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mikeytrw
conflicting_files: null
created_at: 2023-06-05 12:16:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/133104d2b3cf3758268f9f7f7e64ac19.svg
      fullname: Mike Wharton
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mikeytrw
      type: user
    createdAt: '2023-06-05T13:16:25.000Z'
    data:
      edited: false
      editors:
      - mikeytrw
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7391790747642517
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/133104d2b3cf3758268f9f7f7e64ac19.svg
          fullname: Mike Wharton
          isHf: false
          isPro: false
          name: mikeytrw
          type: user
        html: '<p>Hey, so i''ve got the model loaded onto a node with 4x A100 80GB.
          It loads into memory OK, but crashes out when I try to generate with a CUDA
          error:</p>

          <p>lots of:</p>

          <p>../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0],
          thread: [32,0,0] Assertion <code>index &gt;= -sizes[i] &amp;&amp; index
          &lt; sizes[i] &amp;&amp; "index out of bounds"</code> failed.</p>

          <p>and finally:</p>

          <p>RuntimeError: CUDA error: device-side assert triggered<br>CUDA kernel
          errors might be asynchronously reported at some other API call, so the stacktrace
          below might be incorrect.<br>For debugging consider passing CUDA_LAUNCH_BLOCKING=1.<br>Compile
          with <code>TORCH_USE_CUDA_DSA</code> to enable device-side assertions.</p>

          <p>Let me know if you''d like the error output. </p>

          '
        raw: "Hey, so i've got the model loaded onto a node with 4x A100 80GB. It\
          \ loads into memory OK, but crashes out when I try to generate with a CUDA\
          \ error:\r\n\r\nlots of:\r\n\r\n../aten/src/ATen/native/cuda/IndexKernel.cu:92:\
          \ operator(): block: [0,0,0], thread: [32,0,0] Assertion `index >= -sizes[i]\
          \ && index < sizes[i] && \"index out of bounds\"` failed.\r\n\r\nand finally:\r\
          \n\r\nRuntimeError: CUDA error: device-side assert triggered\r\nCUDA kernel\
          \ errors might be asynchronously reported at some other API call, so the\
          \ stacktrace below might be incorrect.\r\nFor debugging consider passing\
          \ CUDA_LAUNCH_BLOCKING=1.\r\nCompile with `TORCH_USE_CUDA_DSA` to enable\
          \ device-side assertions.\r\n\r\nLet me know if you'd like the error output. "
        updatedAt: '2023-06-05T13:16:25.154Z'
      numEdits: 0
      reactions: []
    id: 647de0299bb822b5cd3e7905
    type: comment
  author: mikeytrw
  content: "Hey, so i've got the model loaded onto a node with 4x A100 80GB. It loads\
    \ into memory OK, but crashes out when I try to generate with a CUDA error:\r\n\
    \r\nlots of:\r\n\r\n../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator():\
    \ block: [0,0,0], thread: [32,0,0] Assertion `index >= -sizes[i] && index < sizes[i]\
    \ && \"index out of bounds\"` failed.\r\n\r\nand finally:\r\n\r\nRuntimeError:\
    \ CUDA error: device-side assert triggered\r\nCUDA kernel errors might be asynchronously\
    \ reported at some other API call, so the stacktrace below might be incorrect.\r\
    \nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\r\nCompile with `TORCH_USE_CUDA_DSA`\
    \ to enable device-side assertions.\r\n\r\nLet me know if you'd like the error\
    \ output. "
  created_at: 2023-06-05 12:16:25+00:00
  edited: false
  hidden: false
  id: 647de0299bb822b5cd3e7905
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/xV4Xlk01BsqfRqxAWsO8Z.png?w=200&h=200&f=face
      fullname: Viktor Ferenczi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: viktor-ferenczi
      type: user
    createdAt: '2023-06-05T13:56:52.000Z'
    data:
      edited: true
      editors:
      - viktor-ferenczi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9486117362976074
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/xV4Xlk01BsqfRqxAWsO8Z.png?w=200&h=200&f=face
          fullname: Viktor Ferenczi
          isHf: false
          isPro: false
          name: viktor-ferenczi
          type: user
        html: '<p>Tried to load the model into text-generation-webui on RunPod with
          2x A100 80GB. Indeed it crashes with the above error.<br>It needs only 2x77GB
          of memory to load at float16 precision, so 2x80GB GPUs should be enough.
          (Unless I''ve overlooked something real bad.)<br>Tried various settings,
          none with float16 precision worked. Loading at 8-bit which fits on a single
          80GB GPU works, but quantized.<br>I''m interested in trying this model at
          full precision to know how good it actually is without quantization.<br>It
          does not have to be the Web UI, could be a script. I just need to get it
          working somehow for testing purposes.</p>

          '
        raw: "Tried to load the model into text-generation-webui on RunPod with 2x\
          \ A100 80GB. Indeed it crashes with the above error. \nIt needs only 2x77GB\
          \ of memory to load at float16 precision, so 2x80GB GPUs should be enough.\
          \ (Unless I've overlooked something real bad.)\nTried various settings,\
          \ none with float16 precision worked. Loading at 8-bit which fits on a single\
          \ 80GB GPU works, but quantized.\nI'm interested in trying this model at\
          \ full precision to know how good it actually is without quantization. \n\
          It does not have to be the Web UI, could be a script. I just need to get\
          \ it working somehow for testing purposes."
        updatedAt: '2023-06-05T14:02:14.832Z'
      numEdits: 3
      reactions: []
    id: 647de9a432c471a7fa8b3281
    type: comment
  author: viktor-ferenczi
  content: "Tried to load the model into text-generation-webui on RunPod with 2x A100\
    \ 80GB. Indeed it crashes with the above error. \nIt needs only 2x77GB of memory\
    \ to load at float16 precision, so 2x80GB GPUs should be enough. (Unless I've\
    \ overlooked something real bad.)\nTried various settings, none with float16 precision\
    \ worked. Loading at 8-bit which fits on a single 80GB GPU works, but quantized.\n\
    I'm interested in trying this model at full precision to know how good it actually\
    \ is without quantization. \nIt does not have to be the Web UI, could be a script.\
    \ I just need to get it working somehow for testing purposes."
  created_at: 2023-06-05 12:56:52+00:00
  edited: true
  hidden: false
  id: 647de9a432c471a7fa8b3281
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659478095068-noauth.jpeg?w=200&h=200&f=face
      fullname: Alexandre Strube
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: surak
      type: user
    createdAt: '2023-06-05T15:47:31.000Z'
    data:
      edited: false
      editors:
      - surak
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7697299122810364
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659478095068-noauth.jpeg?w=200&h=200&f=face
          fullname: Alexandre Strube
          isHf: false
          isPro: false
          name: surak
          type: user
        html: '<p>+1. Tried with 4xA100 -40gb and 8x 3090-24gb.</p>

          '
        raw: +1. Tried with 4xA100 -40gb and 8x 3090-24gb.
        updatedAt: '2023-06-05T15:47:31.445Z'
      numEdits: 0
      reactions: []
    id: 647e039310b7a3b157086733
    type: comment
  author: surak
  content: +1. Tried with 4xA100 -40gb and 8x 3090-24gb.
  created_at: 2023-06-05 14:47:31+00:00
  edited: false
  hidden: false
  id: 647e039310b7a3b157086733
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-05T15:52:05.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9591225385665894
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yeah I have re-created the problem. And have just confirmed it is
          not specific to this model.  It happens also with huggyllama/llama-65B for
          example.</p>

          <p>I am doing my testing and will report back soon.  It may be an issue
          in transformers or accelerate</p>

          '
        raw: 'Yeah I have re-created the problem. And have just confirmed it is not
          specific to this model.  It happens also with huggyllama/llama-65B for example.


          I am doing my testing and will report back soon.  It may be an issue in
          transformers or accelerate'
        updatedAt: '2023-06-05T15:52:05.887Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - mikeytrw
        - viktor-ferenczi
        - calebs
    id: 647e04a5f14eafc3b455086d
    type: comment
  author: TheBloke
  content: 'Yeah I have re-created the problem. And have just confirmed it is not
    specific to this model.  It happens also with huggyllama/llama-65B for example.


    I am doing my testing and will report back soon.  It may be an issue in transformers
    or accelerate'
  created_at: 2023-06-05 14:52:05+00:00
  edited: false
  hidden: false
  id: 647e04a5f14eafc3b455086d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/133104d2b3cf3758268f9f7f7e64ac19.svg
      fullname: Mike Wharton
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mikeytrw
      type: user
    createdAt: '2023-06-07T10:06:52.000Z'
    data:
      edited: true
      editors:
      - mikeytrw
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9512680172920227
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/133104d2b3cf3758268f9f7f7e64ac19.svg
          fullname: Mike Wharton
          isHf: false
          isPro: false
          name: mikeytrw
          type: user
        html: '<p>Update that might help - I have two runpods running, both with 2xA100''s.
          </p>

          <p>Curiously my notebook script will work on one of them but the exact same
          script reproduces the error above.<br>The only difference I can ascertain
          is that the one that works is running an older nvidia driver - 525.105.17
          whereas the newer driver 530.41.03 doesn''t work and produces the error
          above.</p>

          <p>EDIT: Yes - there''s definitely a system config issue that''s playing
          into this causing issues with multi-GPU inference across a bunch of models.
          I have VMs which reliably work and which reliably don''t work. Let me know
          if you want me to log out and system config to assist with diagnosis.</p>

          '
        raw: "Update that might help - I have two runpods running, both with 2xA100's.\
          \ \n\nCuriously my notebook script will work on one of them but the exact\
          \ same script reproduces the error above. \nThe only difference I can ascertain\
          \ is that the one that works is running an older nvidia driver - 525.105.17\
          \ whereas the newer driver 530.41.03 doesn't work and produces the error\
          \ above.\n\nEDIT: Yes - there's definitely a system config issue that's\
          \ playing into this causing issues with multi-GPU inference across a bunch\
          \ of models. I have VMs which reliably work and which reliably don't work.\
          \ Let me know if you want me to log out and system config to assist with\
          \ diagnosis."
        updatedAt: '2023-06-07T11:12:50.112Z'
      numEdits: 1
      reactions: []
    id: 648056bce1421e205fd4a65f
    type: comment
  author: mikeytrw
  content: "Update that might help - I have two runpods running, both with 2xA100's.\
    \ \n\nCuriously my notebook script will work on one of them but the exact same\
    \ script reproduces the error above. \nThe only difference I can ascertain is\
    \ that the one that works is running an older nvidia driver - 525.105.17 whereas\
    \ the newer driver 530.41.03 doesn't work and produces the error above.\n\nEDIT:\
    \ Yes - there's definitely a system config issue that's playing into this causing\
    \ issues with multi-GPU inference across a bunch of models. I have VMs which reliably\
    \ work and which reliably don't work. Let me know if you want me to log out and\
    \ system config to assist with diagnosis."
  created_at: 2023-06-07 09:06:52+00:00
  edited: true
  hidden: false
  id: 648056bce1421e205fd4a65f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12d515ac81b4b904c0d1387732df81fa.svg
      fullname: kirp
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kirp
      type: user
    createdAt: '2023-06-13T21:55:41.000Z'
    data:
      edited: true
      editors:
      - kirp
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7996851205825806
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12d515ac81b4b904c0d1387732df81fa.svg
          fullname: kirp
          isHf: false
          isPro: false
          name: kirp
          type: user
        html: "<p>I have rent 4*A6000 with Xeon\xAE Gold 6248 works while 4 A6000\
          \ with AMD cpu or Xeon\xAE Silver fails. I'm not sure whether the cpu matters.</p>\n"
        raw: "I have rent 4*A6000 with Xeon\xAE Gold 6248 works while 4 A6000 with\
          \ AMD cpu or Xeon\xAE Silver fails. I'm not sure whether the cpu matters."
        updatedAt: '2023-06-13T21:59:09.374Z'
      numEdits: 1
      reactions: []
    id: 6488e5dde1fe04bd263a6a0b
    type: comment
  author: kirp
  content: "I have rent 4*A6000 with Xeon\xAE Gold 6248 works while 4 A6000 with AMD\
    \ cpu or Xeon\xAE Silver fails. I'm not sure whether the cpu matters."
  created_at: 2023-06-13 20:55:41+00:00
  edited: true
  hidden: false
  id: 6488e5dde1fe04bd263a6a0b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/guanaco-65B-HF
repo_type: model
status: open
target_branch: null
title: 'Can''t run model '
