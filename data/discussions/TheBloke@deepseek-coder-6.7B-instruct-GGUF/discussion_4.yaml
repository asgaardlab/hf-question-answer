!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MyUser
conflicting_files: null
created_at: 2023-11-07 01:20:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ac02b902ab16086a7973bc137fa93b4e.svg
      fullname: Name
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MyUser
      type: user
    createdAt: '2023-11-07T01:20:45.000Z'
    data:
      edited: false
      editors:
      - MyUser
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7975108027458191
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ac02b902ab16086a7973bc137fa93b4e.svg
          fullname: Name
          isHf: false
          isPro: false
          name: MyUser
          type: user
        html: '<p>I am using oobabooga in CPU only mode and always get the following
          error. I have tried all models with different quants. I have also reinstalled
          oobabooga.<br>Other gguf models work just fine with llama.cpp in oobabooga.
          But I still get the following error:</p>

          <pre><code>File "E:\text-generation-webui-main\text-generation-webui-main\installer_files\env\Lib\site-packages\llama_cpp\llama_cpp.py",
          line 498, in llama_load_model_from_file


          return _lib.llama_load_model_from_file(path_model, params)


          OSError: exception: access violation reading 0x0000000000000000</code></pre>


          <p>It seems like this is a problem with oobabooga rather than the model
          files as they seem to work with llama.cpp.<br>Can you confirm this? What''s
          the solution? Just waiting for text-generation-webui to catch up?</p>

          '
        raw: "I am using oobabooga in CPU only mode and always get the following error.\
          \ I have tried all models with different quants. I have also reinstalled\
          \ oobabooga.\r\nOther gguf models work just fine with llama.cpp in oobabooga.\
          \ But I still get the following error:\r\n<pre><code>File \"E:\\text-generation-webui-main\\\
          text-generation-webui-main\\installer_files\\env\\Lib\\site-packages\\llama_cpp\\\
          llama_cpp.py\", line 498, in llama_load_model_from_file\r\n\r\nreturn _lib.llama_load_model_from_file(path_model,\
          \ params)\r\n\r\nOSError: exception: access violation reading 0x0000000000000000</code></pre>\r\
          \n\r\nIt seems like this is a problem with oobabooga rather than the model\
          \ files as they seem to work with llama.cpp.\r\nCan you confirm this? What's\
          \ the solution? Just waiting for text-generation-webui to catch up?"
        updatedAt: '2023-11-07T01:20:45.277Z'
      numEdits: 0
      reactions: []
    id: 654990ed44e75a7de4f3bb1b
    type: comment
  author: MyUser
  content: "I am using oobabooga in CPU only mode and always get the following error.\
    \ I have tried all models with different quants. I have also reinstalled oobabooga.\r\
    \nOther gguf models work just fine with llama.cpp in oobabooga. But I still get\
    \ the following error:\r\n<pre><code>File \"E:\\text-generation-webui-main\\text-generation-webui-main\\\
    installer_files\\env\\Lib\\site-packages\\llama_cpp\\llama_cpp.py\", line 498,\
    \ in llama_load_model_from_file\r\n\r\nreturn _lib.llama_load_model_from_file(path_model,\
    \ params)\r\n\r\nOSError: exception: access violation reading 0x0000000000000000</code></pre>\r\
    \n\r\nIt seems like this is a problem with oobabooga rather than the model files\
    \ as they seem to work with llama.cpp.\r\nCan you confirm this? What's the solution?\
    \ Just waiting for text-generation-webui to catch up?"
  created_at: 2023-11-07 01:20:45+00:00
  edited: false
  hidden: false
  id: 654990ed44e75a7de4f3bb1b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-11-07T01:31:55.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9914881587028503
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<p>Ya its not ready to support it yet.  ( there is another thread with
          details, but short version is you have to wait a bit )</p>

          '
        raw: Ya its not ready to support it yet.  ( there is another thread with details,
          but short version is you have to wait a bit )
        updatedAt: '2023-11-07T01:31:55.201Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - MyUser
    id: 6549938b2a292b3e2e553180
    type: comment
  author: Nurb432
  content: Ya its not ready to support it yet.  ( there is another thread with details,
    but short version is you have to wait a bit )
  created_at: 2023-11-07 01:31:55+00:00
  edited: false
  hidden: false
  id: 6549938b2a292b3e2e553180
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cbd1da32e26ac5304ddb8bfaec68c6a6.svg
      fullname: Saba Sanatgar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sab1
      type: user
    createdAt: '2023-11-17T16:20:26.000Z'
    data:
      edited: false
      editors:
      - Sab1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9420777559280396
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cbd1da32e26ac5304ddb8bfaec68c6a6.svg
          fullname: Saba Sanatgar
          isHf: false
          isPro: false
          name: Sab1
          type: user
        html: '<p>try going into the command line for oobabooga (cmd_windows.bat or
          cmd_linux.sh or whatever you use), and upgrade llama-cpp-python manually.
          (pip install --upgrade llama-cpp-python)  At least that''s what I had to
          do, and also I had to check the ''cpu'' flag. Lastly, I found that the StarChat
          preset work better than Divine Intellect for Deepseek-coder. </p>

          '
        raw: 'try going into the command line for oobabooga (cmd_windows.bat or cmd_linux.sh
          or whatever you use), and upgrade llama-cpp-python manually. (pip install
          --upgrade llama-cpp-python)  At least that''s what I had to do, and also
          I had to check the ''cpu'' flag. Lastly, I found that the StarChat preset
          work better than Divine Intellect for Deepseek-coder. '
        updatedAt: '2023-11-17T16:20:26.942Z'
      numEdits: 0
      reactions: []
    id: 655792ca0e7a7067a9552fa3
    type: comment
  author: Sab1
  content: 'try going into the command line for oobabooga (cmd_windows.bat or cmd_linux.sh
    or whatever you use), and upgrade llama-cpp-python manually. (pip install --upgrade
    llama-cpp-python)  At least that''s what I had to do, and also I had to check
    the ''cpu'' flag. Lastly, I found that the StarChat preset work better than Divine
    Intellect for Deepseek-coder. '
  created_at: 2023-11-17 16:20:26+00:00
  edited: false
  hidden: false
  id: 655792ca0e7a7067a9552fa3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-11-17T16:50:28.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9530996680259705
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<p>In my case, i have it running as a service in a conda environment.  Just
          stop service, start environment, do the upgrade piece, then restart service.    I
          have not tried starchat, i have been using vicuna 1.1 with success in general,
          including this model..  ( tho i think that ajibawa-2023/Python-Code-13B/33B
          ( gguf format for me ) is doing much better for output for me, at least
          for python.  But not done a lot of testing yet , just some early testing.
          </p>

          '
        raw: 'In my case, i have it running as a service in a conda environment.  Just
          stop service, start environment, do the upgrade piece, then restart service.    I
          have not tried starchat, i have been using vicuna 1.1 with success in general,
          including this model..  ( tho i think that ajibawa-2023/Python-Code-13B/33B
          ( gguf format for me ) is doing much better for output for me, at least
          for python.  But not done a lot of testing yet , just some early testing. '
        updatedAt: '2023-11-17T16:50:28.821Z'
      numEdits: 0
      reactions: []
    id: 655799d4ffc088730531b2d2
    type: comment
  author: Nurb432
  content: 'In my case, i have it running as a service in a conda environment.  Just
    stop service, start environment, do the upgrade piece, then restart service.    I
    have not tried starchat, i have been using vicuna 1.1 with success in general,
    including this model..  ( tho i think that ajibawa-2023/Python-Code-13B/33B (
    gguf format for me ) is doing much better for output for me, at least for python.  But
    not done a lot of testing yet , just some early testing. '
  created_at: 2023-11-17 16:50:28+00:00
  edited: false
  hidden: false
  id: 655799d4ffc088730531b2d2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/ac02b902ab16086a7973bc137fa93b4e.svg
      fullname: Name
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MyUser
      type: user
    createdAt: '2023-11-20T04:44:50.000Z'
    data:
      status: closed
    id: 655ae442cb17ec19ef86e37d
    type: status-change
  author: MyUser
  created_at: 2023-11-20 04:44:50+00:00
  id: 655ae442cb17ec19ef86e37d
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TheBloke/deepseek-coder-6.7B-instruct-GGUF
repo_type: model
status: closed
target_branch: null
title: Does not work with text-generation-webui.
