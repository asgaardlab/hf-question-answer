!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hyunfzen
conflicting_files: null
created_at: 2023-11-05 14:36:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a8500e4244412a4fc3ed597b6b05914b.svg
      fullname: hyunfzen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hyunfzen
      type: user
    createdAt: '2023-11-05T14:36:13.000Z'
    data:
      edited: false
      editors:
      - hyunfzen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.36437010765075684
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a8500e4244412a4fc3ed597b6b05914b.svg
          fullname: hyunfzen
          isHf: false
          isPro: false
          name: hyunfzen
          type: user
        html: '<p>llama.cpp error:<br><code>libc++abi: terminating due to uncaught
          exception of type std::out_of_range: unordered_map::at: key not found</code></p>

          '
        raw: "llama.cpp error:\r\n`libc++abi: terminating due to uncaught exception\
          \ of type std::out_of_range: unordered_map::at: key not found`"
        updatedAt: '2023-11-05T14:36:13.982Z'
      numEdits: 0
      reactions: []
    id: 6547a85d62fae6b2a7717262
    type: comment
  author: hyunfzen
  content: "llama.cpp error:\r\n`libc++abi: terminating due to uncaught exception\
    \ of type std::out_of_range: unordered_map::at: key not found`"
  created_at: 2023-11-05 14:36:13+00:00
  edited: false
  hidden: false
  id: 6547a85d62fae6b2a7717262
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-05T14:42:38.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8455462455749512
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>ah shit yeah I see the same. Investigating</p>

          '
        raw: ah shit yeah I see the same. Investigating
        updatedAt: '2023-11-05T14:42:38.374Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - atstim731
    id: 6547a9deb8ac1a89ff06b644
    type: comment
  author: TheBloke
  content: ah shit yeah I see the same. Investigating
  created_at: 2023-11-05 14:42:38+00:00
  edited: false
  hidden: false
  id: 6547a9deb8ac1a89ff06b644
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a8500e4244412a4fc3ed597b6b05914b.svg
      fullname: hyunfzen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hyunfzen
      type: user
    createdAt: '2023-11-05T15:00:27.000Z'
    data:
      edited: false
      editors:
      - hyunfzen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7042938470840454
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a8500e4244412a4fc3ed597b6b05914b.svg
          fullname: hyunfzen
          isHf: false
          isPro: false
          name: hyunfzen
          type: user
        html: '<p>I use it in web-ui, and I got<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/641277c0ac08ffb707935e37/i0Jw-BCjaVLRUGBrRjXBF.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/641277c0ac08ffb707935e37/i0Jw-BCjaVLRUGBrRjXBF.png"></a></p>

          <p>Hope that it is useful.</p>

          '
        raw: "I use it in web-ui, and I got \n![image.png](https://cdn-uploads.huggingface.co/production/uploads/641277c0ac08ffb707935e37/i0Jw-BCjaVLRUGBrRjXBF.png)\n\
          \nHope that it is useful.\n"
        updatedAt: '2023-11-05T15:00:27.549Z'
      numEdits: 0
      reactions: []
    id: 6547ae0b407bb19ff5987317
    type: comment
  author: hyunfzen
  content: "I use it in web-ui, and I got \n![image.png](https://cdn-uploads.huggingface.co/production/uploads/641277c0ac08ffb707935e37/i0Jw-BCjaVLRUGBrRjXBF.png)\n\
    \nHope that it is useful.\n"
  created_at: 2023-11-05 15:00:27+00:00
  edited: false
  hidden: false
  id: 6547ae0b407bb19ff5987317
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8fb3c2872b01b4f4fb9672a166d92dc2.svg
      fullname: Mufeed Al-Hashim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mufeed
      type: user
    createdAt: '2023-11-05T15:05:42.000Z'
    data:
      edited: false
      editors:
      - mufeed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6980251669883728
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8fb3c2872b01b4f4fb9672a166d92dc2.svg
          fullname: Mufeed Al-Hashim
          isHf: false
          isPro: false
          name: mufeed
          type: user
        html: '<blockquote>

          <p>I use it in web-ui, and I got<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/641277c0ac08ffb707935e37/i0Jw-BCjaVLRUGBrRjXBF.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/641277c0ac08ffb707935e37/i0Jw-BCjaVLRUGBrRjXBF.png"></a></p>

          <p>Hope that it is useful.</p>

          </blockquote>

          <p>Same here too...</p>

          '
        raw: "> I use it in web-ui, and I got \n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/641277c0ac08ffb707935e37/i0Jw-BCjaVLRUGBrRjXBF.png)\n\
          > \n> Hope that it is useful.\n\nSame here too..."
        updatedAt: '2023-11-05T15:05:42.299Z'
      numEdits: 0
      reactions: []
    id: 6547af4610d47c1f77f5b538
    type: comment
  author: mufeed
  content: "> I use it in web-ui, and I got \n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/641277c0ac08ffb707935e37/i0Jw-BCjaVLRUGBrRjXBF.png)\n\
    > \n> Hope that it is useful.\n\nSame here too..."
  created_at: 2023-11-05 15:05:42+00:00
  edited: false
  hidden: false
  id: 6547af4610d47c1f77f5b538
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-05T15:09:38.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9621617794036865
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I''m remaking all the GGUFs using an updated llama.cpp convert.py
          which I hope will solve the crashing issue in llama.cpp with the 6.7B model.  At
          least it hasn''t crashed for me yet.</p>

          <p>Regarding the "byte not found in vocab", I think that''s an issue in
          the client used by WebUI, and is not something I can solve.  I can only
          confirm the models work with llama.cpp.  After that it requires the developers
          of the various clients to make sure they''re up-to-date with llama.cpp.</p>

          <p>I think in that case it''s because llama-cpp-python, which textgen-webui
          uses, has not been updated to support BPE vocab, which was recently worked
          on in llama.cpp.</p>

          '
        raw: 'I''m remaking all the GGUFs using an updated llama.cpp convert.py which
          I hope will solve the crashing issue in llama.cpp with the 6.7B model.  At
          least it hasn''t crashed for me yet.


          Regarding the "byte not found in vocab", I think that''s an issue in the
          client used by WebUI, and is not something I can solve.  I can only confirm
          the models work with llama.cpp.  After that it requires the developers of
          the various clients to make sure they''re up-to-date with llama.cpp.


          I think in that case it''s because llama-cpp-python, which textgen-webui
          uses, has not been updated to support BPE vocab, which was recently worked
          on in llama.cpp.'
        updatedAt: '2023-11-05T15:09:48.171Z'
      numEdits: 1
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - mufeed
        - Nurb432
        - atstim731
    id: 6547b032407bb19ff598c2d7
    type: comment
  author: TheBloke
  content: 'I''m remaking all the GGUFs using an updated llama.cpp convert.py which
    I hope will solve the crashing issue in llama.cpp with the 6.7B model.  At least
    it hasn''t crashed for me yet.


    Regarding the "byte not found in vocab", I think that''s an issue in the client
    used by WebUI, and is not something I can solve.  I can only confirm the models
    work with llama.cpp.  After that it requires the developers of the various clients
    to make sure they''re up-to-date with llama.cpp.


    I think in that case it''s because llama-cpp-python, which textgen-webui uses,
    has not been updated to support BPE vocab, which was recently worked on in llama.cpp.'
  created_at: 2023-11-05 15:09:38+00:00
  edited: true
  hidden: false
  id: 6547b032407bb19ff598c2d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-11-05T15:26:01.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8874295949935913
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<p>will be really nice once all these libraries and formats stabilize.  moving
          targets suck.</p>

          '
        raw: will be really nice once all these libraries and formats stabilize.  moving
          targets suck.
        updatedAt: '2023-11-05T15:26:01.162Z'
      numEdits: 0
      reactions: []
    id: 6547b409565e3985e8b44e97
    type: comment
  author: Nurb432
  content: will be really nice once all these libraries and formats stabilize.  moving
    targets suck.
  created_at: 2023-11-05 15:26:01+00:00
  edited: false
  hidden: false
  id: 6547b409565e3985e8b44e97
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-05T16:38:05.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9916340708732605
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>There was also an issue with the EOS token on all the Instruct models.
          The source models had it set incorrectly, so the GGUFs would not stop generating.</p>

          <p>I''ve reported that to DeepSeek, they''ve fixed it, and I am now re-re-re-making
          the three Instruct model GGUFs, which are in the process of uploading now.</p>

          '
        raw: 'There was also an issue with the EOS token on all the Instruct models.
          The source models had it set incorrectly, so the GGUFs would not stop generating.


          I''ve reported that to DeepSeek, they''ve fixed it, and I am now re-re-re-making
          the three Instruct model GGUFs, which are in the process of uploading now.'
        updatedAt: '2023-11-05T16:38:05.678Z'
      numEdits: 0
      reactions:
      - count: 6
        reaction: "\U0001F44D"
        users:
        - Nurb432
        - hyunfzen
        - mufeed
        - Notnaton
        - dzupin
        - makysmaky
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - afrideva
        - Olofp
        - mj23978
    id: 6547c4ed2119c8bdf296f9b3
    type: comment
  author: TheBloke
  content: 'There was also an issue with the EOS token on all the Instruct models.
    The source models had it set incorrectly, so the GGUFs would not stop generating.


    I''ve reported that to DeepSeek, they''ve fixed it, and I am now re-re-re-making
    the three Instruct model GGUFs, which are in the process of uploading now.'
  created_at: 2023-11-05 16:38:05+00:00
  edited: false
  hidden: false
  id: 6547c4ed2119c8bdf296f9b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4277729ba8780e59fa072561d4611330.svg
      fullname: John Pitus
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jmp470
      type: user
    createdAt: '2023-11-05T16:41:18.000Z'
    data:
      edited: false
      editors:
      - jmp470
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.955899178981781
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4277729ba8780e59fa072561d4611330.svg
          fullname: John Pitus
          isHf: false
          isPro: false
          name: jmp470
          type: user
        html: '<p>Thank you for doing this!   I''m excited to try deepseek.  </p>

          '
        raw: "Thank you for doing this!   I'm excited to try deepseek.  \n"
        updatedAt: '2023-11-05T16:41:18.128Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - afrideva
    id: 6547c5ae36332b0eedbe3876
    type: comment
  author: jmp470
  content: "Thank you for doing this!   I'm excited to try deepseek.  \n"
  created_at: 2023-11-05 16:41:18+00:00
  edited: false
  hidden: false
  id: 6547c5ae36332b0eedbe3876
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f73e7187e9c0a1a9d99ed7250c66408e.svg
      fullname: Gee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gmacgmac
      type: user
    createdAt: '2023-11-06T14:30:57.000Z'
    data:
      edited: true
      editors:
      - gmacgmac
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9801005721092224
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f73e7187e9c0a1a9d99ed7250c66408e.svg
          fullname: Gee
          isHf: false
          isPro: false
          name: gmacgmac
          type: user
        html: '<p>I have this model deepseek-coder-6.7b-instruct.Q5_K_S.gguf working
          in TG WebUI on Mac M1 Silicon on CPU<br>I don''t get the "byte not found
          in vocab" which is very curious<br>However I can''t get it working on Mac
          M2 Max on CPU and get "byte not found in vocab"- strange</p>

          <p>I did however have to change  n_ctx = 16380 on M1 Mac for it to work<br>Not
          sure why that is but going to explore</p>

          '
        raw: 'I have this model deepseek-coder-6.7b-instruct.Q5_K_S.gguf working in
          TG WebUI on Mac M1 Silicon on CPU

          I don''t get the "byte not found in vocab" which is very curious

          However I can''t get it working on Mac M2 Max on CPU and get "byte not found
          in vocab"- strange


          I did however have to change  n_ctx = 16380 on M1 Mac for it to work

          Not sure why that is but going to explore'
        updatedAt: '2023-11-06T14:32:04.223Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mufeed
    id: 6548f8a1219d8722af5c51a8
    type: comment
  author: gmacgmac
  content: 'I have this model deepseek-coder-6.7b-instruct.Q5_K_S.gguf working in
    TG WebUI on Mac M1 Silicon on CPU

    I don''t get the "byte not found in vocab" which is very curious

    However I can''t get it working on Mac M2 Max on CPU and get "byte not found in
    vocab"- strange


    I did however have to change  n_ctx = 16380 on M1 Mac for it to work

    Not sure why that is but going to explore'
  created_at: 2023-11-06 14:30:57+00:00
  edited: true
  hidden: false
  id: 6548f8a1219d8722af5c51a8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bbfe7f8c8e7ce8b50e48a4a2164a3c2e.svg
      fullname: Jawad Mansoor
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: supercharge19
      type: user
    createdAt: '2023-11-07T04:51:06.000Z'
    data:
      edited: false
      editors:
      - supercharge19
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9702180027961731
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bbfe7f8c8e7ce8b50e48a4a2164a3c2e.svg
          fullname: Jawad Mansoor
          isHf: false
          isPro: false
          name: supercharge19
          type: user
        html: '<blockquote>

          <p>I have this model deepseek-coder-6.7b-instruct.Q5_K_S.gguf working in
          TG WebUI on Mac M1 Silicon on CPU<br>I don''t get the "byte not found in
          vocab" which is very curious<br>However I can''t get it working on Mac M2
          Max on CPU and get "byte not found in vocab"- strange</p>

          <p>I did however have to change  n_ctx = 16380 on M1 Mac for it to work<br>Not
          sure why that is but going to explore</p>

          </blockquote>

          <p>any update?</p>

          '
        raw: "> I have this model deepseek-coder-6.7b-instruct.Q5_K_S.gguf working\
          \ in TG WebUI on Mac M1 Silicon on CPU\n> I don't get the \"byte not found\
          \ in vocab\" which is very curious\n> However I can't get it working on\
          \ Mac M2 Max on CPU and get \"byte not found in vocab\"- strange\n> \n>\
          \ I did however have to change  n_ctx = 16380 on M1 Mac for it to work\n\
          > Not sure why that is but going to explore\n\nany update?"
        updatedAt: '2023-11-07T04:51:06.237Z'
      numEdits: 0
      reactions: []
    id: 6549c23a212b5bd749c77d2d
    type: comment
  author: supercharge19
  content: "> I have this model deepseek-coder-6.7b-instruct.Q5_K_S.gguf working in\
    \ TG WebUI on Mac M1 Silicon on CPU\n> I don't get the \"byte not found in vocab\"\
    \ which is very curious\n> However I can't get it working on Mac M2 Max on CPU\
    \ and get \"byte not found in vocab\"- strange\n> \n> I did however have to change\
    \  n_ctx = 16380 on M1 Mac for it to work\n> Not sure why that is but going to\
    \ explore\n\nany update?"
  created_at: 2023-11-07 04:51:06+00:00
  edited: false
  hidden: false
  id: 6549c23a212b5bd749c77d2d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f73e7187e9c0a1a9d99ed7250c66408e.svg
      fullname: Gee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gmacgmac
      type: user
    createdAt: '2023-11-07T08:27:06.000Z'
    data:
      edited: false
      editors:
      - gmacgmac
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.685009241104126
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f73e7187e9c0a1a9d99ed7250c66408e.svg
          fullname: Gee
          isHf: false
          isPro: false
          name: gmacgmac
          type: user
        html: '<p>It appears to be my version of Llama.cpp<br>But even when I install
          that that module version it doesn''t work in another environment so there''s
          something about the way i built this one!!<br>I copied this module in and
          then I don''t get the errors! any ideas how else to confirm?</p>

          <p>llama-cpp-python          0.2.13                   pypi_0    pypi</p>

          <p>% pip show llama-cpp-python<br>Name: llama_cpp_python<br>Version: 0.2.13<br>Summary:
          Python bindings for the llama.cpp library<br>Home-page:<br>Author:<br>Author-email:
          Andrei Betlen <a rel="nofollow" href="mailto:abetlen@gmail.com">abetlen@gmail.com</a><br>License:
          MIT<br>Location: /Users/gm/miniconda3/envs/textgen/lib/python3.11/site-packages<br>Requires:
          diskcache, numpy, typing-extensions</p>

          '
        raw: "It appears to be my version of Llama.cpp\nBut even when I install that\
          \ that module version it doesn't work in another environment so there's\
          \ something about the way i built this one!!\nI copied this module in and\
          \ then I don't get the errors! any ideas how else to confirm?\n\nllama-cpp-python\
          \          0.2.13                   pypi_0    pypi\n\n% pip show llama-cpp-python\
          \ \nName: llama_cpp_python\nVersion: 0.2.13\nSummary: Python bindings for\
          \ the llama.cpp library\nHome-page: \nAuthor: \nAuthor-email: Andrei Betlen\
          \ <abetlen@gmail.com>\nLicense: MIT\nLocation: /Users/gm/miniconda3/envs/textgen/lib/python3.11/site-packages\n\
          Requires: diskcache, numpy, typing-extensions"
        updatedAt: '2023-11-07T08:27:06.106Z'
      numEdits: 0
      reactions: []
    id: 6549f4da34b28d6ba99a61a7
    type: comment
  author: gmacgmac
  content: "It appears to be my version of Llama.cpp\nBut even when I install that\
    \ that module version it doesn't work in another environment so there's something\
    \ about the way i built this one!!\nI copied this module in and then I don't get\
    \ the errors! any ideas how else to confirm?\n\nllama-cpp-python          0.2.13\
    \                   pypi_0    pypi\n\n% pip show llama-cpp-python \nName: llama_cpp_python\n\
    Version: 0.2.13\nSummary: Python bindings for the llama.cpp library\nHome-page:\
    \ \nAuthor: \nAuthor-email: Andrei Betlen <abetlen@gmail.com>\nLicense: MIT\n\
    Location: /Users/gm/miniconda3/envs/textgen/lib/python3.11/site-packages\nRequires:\
    \ diskcache, numpy, typing-extensions"
  created_at: 2023-11-07 08:27:06+00:00
  edited: false
  hidden: false
  id: 6549f4da34b28d6ba99a61a7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f73e7187e9c0a1a9d99ed7250c66408e.svg
      fullname: Gee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gmacgmac
      type: user
    createdAt: '2023-11-07T09:45:57.000Z'
    data:
      edited: false
      editors:
      - gmacgmac
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4883395731449127
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f73e7187e9c0a1a9d99ed7250c66408e.svg
          fullname: Gee
          isHf: false
          isPro: false
          name: gmacgmac
          type: user
        html: '<p>This works for me on mac but in CPU mode only "n-gpu-layers=0"</p>

          <p>pip uninstall llama-cpp-python -y<br>CMAKE_ARGS="-DLLAMA_METAL=on" pip
          install llama-cpp-python==0.2.13 --no-cache-dir<br>pip install ''llama-cpp-python[server]==0.2.13''</p>

          '
        raw: 'This works for me on mac but in CPU mode only "n-gpu-layers=0"


          pip uninstall llama-cpp-python -y

          CMAKE_ARGS="-DLLAMA_METAL=on" pip install llama-cpp-python==0.2.13 --no-cache-dir

          pip install ''llama-cpp-python[server]==0.2.13'''
        updatedAt: '2023-11-07T09:45:57.518Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mufeed
    id: 654a0755b8d6b1e8632310bf
    type: comment
  author: gmacgmac
  content: 'This works for me on mac but in CPU mode only "n-gpu-layers=0"


    pip uninstall llama-cpp-python -y

    CMAKE_ARGS="-DLLAMA_METAL=on" pip install llama-cpp-python==0.2.13 --no-cache-dir

    pip install ''llama-cpp-python[server]==0.2.13'''
  created_at: 2023-11-07 09:45:57+00:00
  edited: false
  hidden: false
  id: 654a0755b8d6b1e8632310bf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-07T09:49:14.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9273826479911804
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Thanks for reporting. Looks like llama-cpp-python updated yesterday
          and now how has support for models like this, with BPE vocab</p>

          '
        raw: Thanks for reporting. Looks like llama-cpp-python updated yesterday and
          now how has support for models like this, with BPE vocab
        updatedAt: '2023-11-07T09:49:14.309Z'
      numEdits: 0
      reactions: []
    id: 654a081ae6c61d0dc920befd
    type: comment
  author: TheBloke
  content: Thanks for reporting. Looks like llama-cpp-python updated yesterday and
    now how has support for models like this, with BPE vocab
  created_at: 2023-11-07 09:49:14+00:00
  edited: false
  hidden: false
  id: 654a081ae6c61d0dc920befd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-11-07T12:14:10.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.835995078086853
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<p>Sometimes patience is a virtue :) </p>

          '
        raw: 'Sometimes patience is a virtue :) '
        updatedAt: '2023-11-07T12:14:10.101Z'
      numEdits: 0
      reactions: []
    id: 654a2a126167ff03f7f8bf7d
    type: comment
  author: Nurb432
  content: 'Sometimes patience is a virtue :) '
  created_at: 2023-11-07 12:14:10+00:00
  edited: false
  hidden: false
  id: 654a2a126167ff03f7f8bf7d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bbfe7f8c8e7ce8b50e48a4a2164a3c2e.svg
      fullname: Jawad Mansoor
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: supercharge19
      type: user
    createdAt: '2023-11-07T17:10:42.000Z'
    data:
      edited: false
      editors:
      - supercharge19
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9193391799926758
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bbfe7f8c8e7ce8b50e48a4a2164a3c2e.svg
          fullname: Jawad Mansoor
          isHf: false
          isPro: false
          name: supercharge19
          type: user
        html: '<p>sometimes llama cpp gets broken (even latest update a few days ago
          was broken)</p>

          '
        raw: sometimes llama cpp gets broken (even latest update a few days ago was
          broken)
        updatedAt: '2023-11-07T17:10:42.678Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F614"
        users:
        - Catforlife1982
    id: 654a6f9246df37dea5d230cc
    type: comment
  author: supercharge19
  content: sometimes llama cpp gets broken (even latest update a few days ago was
    broken)
  created_at: 2023-11-07 17:10:42+00:00
  edited: false
  hidden: false
  id: 654a6f9246df37dea5d230cc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8fb3c2872b01b4f4fb9672a166d92dc2.svg
      fullname: Mufeed Al-Hashim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mufeed
      type: user
    createdAt: '2023-11-07T18:07:29.000Z'
    data:
      edited: true
      editors:
      - mufeed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6351288557052612
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8fb3c2872b01b4f4fb9672a166d92dc2.svg
          fullname: Mufeed Al-Hashim
          isHf: false
          isPro: false
          name: mufeed
          type: user
        html: '<p>Upgrade llama_cpp_python to 0.2.14, and now it is working with CPU
          in Oobabooga on Linux:</p>

          <p>./cmd_linux.sh<br>pip install llama-cpp-python --force-reinstall --upgrade
          --no-cache-dir</p>

          '
        raw: 'Upgrade llama_cpp_python to 0.2.14, and now it is working with CPU in
          Oobabooga on Linux:


          ./cmd_linux.sh

          pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir

          '
        updatedAt: '2023-11-07T18:48:49.488Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - ani03anwar
        - mufeed
    id: 654a7ce1062a122ee7e77708
    type: comment
  author: mufeed
  content: 'Upgrade llama_cpp_python to 0.2.14, and now it is working with CPU in
    Oobabooga on Linux:


    ./cmd_linux.sh

    pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir

    '
  created_at: 2023-11-07 18:07:29+00:00
  edited: true
  hidden: false
  id: 654a7ce1062a122ee7e77708
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-11-07T18:28:45.000Z'
    data:
      edited: true
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9801633358001709
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<p>that also will work for CPU only. At least it did for me . I just
          did the force upgrade to 0.2.14  ( after i stopped my service , started
          conda env. manually..  bla bla bla....  my setup is a bit different )</p>

          <p>....or at least it did make it load, still not tested how well it works.  Just
          it loaded and spit out some text so i know it "worked"</p>

          '
        raw: 'that also will work for CPU only. At least it did for me . I just did
          the force upgrade to 0.2.14  ( after i stopped my service , started conda
          env. manually..  bla bla bla....  my setup is a bit different )


          ....or at least it did make it load, still not tested how well it works.  Just
          it loaded and spit out some text so i know it "worked"'
        updatedAt: '2023-11-07T18:29:18.729Z'
      numEdits: 1
      reactions: []
    id: 654a81ddfc2ecdff061685eb
    type: comment
  author: Nurb432
  content: 'that also will work for CPU only. At least it did for me . I just did
    the force upgrade to 0.2.14  ( after i stopped my service , started conda env.
    manually..  bla bla bla....  my setup is a bit different )


    ....or at least it did make it load, still not tested how well it works.  Just
    it loaded and spit out some text so i know it "worked"'
  created_at: 2023-11-07 18:28:45+00:00
  edited: true
  hidden: false
  id: 654a81ddfc2ecdff061685eb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/db95fc9a8067cca86444094589fe586b.svg
      fullname: Jonathan McCarthy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JonoMcCarthy
      type: user
    createdAt: '2023-11-08T16:12:16.000Z'
    data:
      edited: true
      editors:
      - JonoMcCarthy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.45021992921829224
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/db95fc9a8067cca86444094589fe586b.svg
          fullname: Jonathan McCarthy
          isHf: false
          isPro: false
          name: JonoMcCarthy
          type: user
        html: '<p>THanks Mr Bloke for all your hard work:<br>Just tested with ctransformers<br>ERROR:
          byte not found in vocab: ''</p>

          <p>code I used<br>llm = AutoModelForCausalLM.from_pretrained(local_model,
          model_file="deepseek-coder-6.7b-instruct.Q4_K_M.gguf", model_type="deepseek",
          gpu_layers=50, local_files_only=True)</p>

          <p>any ideas or tips to get it working?</p>

          '
        raw: "THanks Mr Bloke for all your hard work:\nJust tested with ctransformers\
          \ \nERROR: byte not found in vocab: '\n\ncode I used\nllm = AutoModelForCausalLM.from_pretrained(local_model,\
          \ model_file=\"deepseek-coder-6.7b-instruct.Q4_K_M.gguf\", model_type=\"\
          deepseek\", gpu_layers=50, local_files_only=True)\n\nany ideas or tips to\
          \ get it working?"
        updatedAt: '2023-11-08T16:13:22.094Z'
      numEdits: 1
      reactions: []
    id: 654bb360d6153dccbe2cb51d
    type: comment
  author: JonoMcCarthy
  content: "THanks Mr Bloke for all your hard work:\nJust tested with ctransformers\
    \ \nERROR: byte not found in vocab: '\n\ncode I used\nllm = AutoModelForCausalLM.from_pretrained(local_model,\
    \ model_file=\"deepseek-coder-6.7b-instruct.Q4_K_M.gguf\", model_type=\"deepseek\"\
    , gpu_layers=50, local_files_only=True)\n\nany ideas or tips to get it working?"
  created_at: 2023-11-08 16:12:16+00:00
  edited: true
  hidden: false
  id: 654bb360d6153dccbe2cb51d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bbfe7f8c8e7ce8b50e48a4a2164a3c2e.svg
      fullname: Jawad Mansoor
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: supercharge19
      type: user
    createdAt: '2023-11-10T14:48:59.000Z'
    data:
      edited: false
      editors:
      - supercharge19
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8676984906196594
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bbfe7f8c8e7ce8b50e48a4a2164a3c2e.svg
          fullname: Jawad Mansoor
          isHf: false
          isPro: false
          name: supercharge19
          type: user
        html: '<p>ctransformers is not good at all, for some model it breaks and for
          most outputs are so weird and just not acceptable, try llama_cpp_python</p>

          '
        raw: ctransformers is not good at all, for some model it breaks and for most
          outputs are so weird and just not acceptable, try llama_cpp_python
        updatedAt: '2023-11-10T14:48:59.649Z'
      numEdits: 0
      reactions: []
    id: 654e42db1a60f8c83c2498d1
    type: comment
  author: supercharge19
  content: ctransformers is not good at all, for some model it breaks and for most
    outputs are so weird and just not acceptable, try llama_cpp_python
  created_at: 2023-11-10 14:48:59+00:00
  edited: false
  hidden: false
  id: 654e42db1a60f8c83c2498d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/313a9e2786513613725c10b7a1a01176.svg
      fullname: Andreas Rozek
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rozek
      type: user
    createdAt: '2023-11-24T15:57:44.000Z'
    data:
      edited: false
      editors:
      - rozek
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8434810638427734
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/313a9e2786513613725c10b7a1a01176.svg
          fullname: Andreas Rozek
          isHf: false
          isPro: false
          name: rozek
          type: user
        html: '<p>I just downloaded "deepseek-coder-6.7b-instruct.Q5_K_M.gguf" and
          tested it with the current version of llama.cpp (the C/C++ variant) - and
          it works like a charm</p>

          '
        raw: I just downloaded "deepseek-coder-6.7b-instruct.Q5_K_M.gguf" and tested
          it with the current version of llama.cpp (the C/C++ variant) - and it works
          like a charm
        updatedAt: '2023-11-24T15:57:44.922Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - viktor-ferenczi
        - supercharge19
        - jmp470
    id: 6560c7f830a88a2f1d9c69a4
    type: comment
  author: rozek
  content: I just downloaded "deepseek-coder-6.7b-instruct.Q5_K_M.gguf" and tested
    it with the current version of llama.cpp (the C/C++ variant) - and it works like
    a charm
  created_at: 2023-11-24 15:57:44+00:00
  edited: false
  hidden: false
  id: 6560c7f830a88a2f1d9c69a4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/deepseek-coder-6.7B-instruct-GGUF
repo_type: model
status: open
target_branch: null
title: This model cannot be used normally
