!!python/object:huggingface_hub.community.DiscussionWithDetails
author: frgx
conflicting_files: null
created_at: 2022-10-27 08:06:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666860278801-noauth.png?w=200&h=200&f=face
      fullname: "Fran\xE7ois Gu\xE9rillon"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: frgx
      type: user
    createdAt: '2022-10-27T09:06:07.000Z'
    data:
      edited: false
      editors:
      - frgx
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666860278801-noauth.png?w=200&h=200&f=face
          fullname: "Fran\xE7ois Gu\xE9rillon"
          isHf: false
          isPro: false
          name: frgx
          type: user
        html: "<p>Hi,</p>\n<p>Thank you for publishing your outperforming models to\
          \ 'transformers' library format, a good step to make them become foundation\
          \ models!</p>\n<p>Has anyone succeeded in reproducing the results (accuracy)\
          \ obtained in the OFA paper, on SNLI-VE (visual entailment), with from_pretrained()\
          \ models and fine tuning with huggingface Trainer()? I tried to with OFA-tiny\
          \ and OFA-base, but though validation accuracy shows normal progress during\
          \ training and confusion matrix seems normal, it ends around ~10 points\
          \ below expected performance. I tried to catch all relevant parameters (same\
          \ prompt including spaces and quotation marks, image mean &amp; std at 0.5,\
          \ different image size between models, encoder_drop_path_rate = 0.1, decoder_drop_path_rate\
          \ = 0.1, 5 epochs, warmup ratio = 0.06, peak lr = 3e-5 then decreasing,\
          \ AdamW weight decay = 1e-2...) but I may have missed something.</p>\n<p>Thanks\
          \ for your interest :-)</p>\n<p>Fran\xE7ois</p>\n"
        raw: "Hi,\r\n\r\nThank you for publishing your outperforming models to 'transformers'\
          \ library format, a good step to make them become foundation models!\r\n\
          \r\nHas anyone succeeded in reproducing the results (accuracy) obtained\
          \ in the OFA paper, on SNLI-VE (visual entailment), with from_pretrained()\
          \ models and fine tuning with huggingface Trainer()? I tried to with OFA-tiny\
          \ and OFA-base, but though validation accuracy shows normal progress during\
          \ training and confusion matrix seems normal, it ends around ~10 points\
          \ below expected performance. I tried to catch all relevant parameters (same\
          \ prompt including spaces and quotation marks, image mean & std at 0.5,\
          \ different image size between models, encoder_drop_path_rate = 0.1, decoder_drop_path_rate\
          \ = 0.1, 5 epochs, warmup ratio = 0.06, peak lr = 3e-5 then decreasing,\
          \ AdamW weight decay = 1e-2...) but I may have missed something.\r\n\r\n\
          Thanks for your interest :-)\r\n\r\nFran\xE7ois"
        updatedAt: '2022-10-27T09:06:07.443Z'
      numEdits: 0
      reactions: []
    id: 635a49ff307e8109011bc3a6
    type: comment
  author: frgx
  content: "Hi,\r\n\r\nThank you for publishing your outperforming models to 'transformers'\
    \ library format, a good step to make them become foundation models!\r\n\r\nHas\
    \ anyone succeeded in reproducing the results (accuracy) obtained in the OFA paper,\
    \ on SNLI-VE (visual entailment), with from_pretrained() models and fine tuning\
    \ with huggingface Trainer()? I tried to with OFA-tiny and OFA-base, but though\
    \ validation accuracy shows normal progress during training and confusion matrix\
    \ seems normal, it ends around ~10 points below expected performance. I tried\
    \ to catch all relevant parameters (same prompt including spaces and quotation\
    \ marks, image mean & std at 0.5, different image size between models, encoder_drop_path_rate\
    \ = 0.1, decoder_drop_path_rate = 0.1, 5 epochs, warmup ratio = 0.06, peak lr\
    \ = 3e-5 then decreasing, AdamW weight decay = 1e-2...) but I may have missed\
    \ something.\r\n\r\nThanks for your interest :-)\r\n\r\nFran\xE7ois"
  created_at: 2022-10-27 08:06:07+00:00
  edited: false
  hidden: false
  id: 635a49ff307e8109011bc3a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1644682834896-620760a26e3b7210c2ff1943.jpeg?w=200&h=200&f=face
      fullname: Junyang Lin
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JustinLin610
      type: user
    createdAt: '2022-11-04T14:06:03.000Z'
    data:
      edited: false
      editors:
      - JustinLin610
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1644682834896-620760a26e3b7210c2ff1943.jpeg?w=200&h=200&f=face
          fullname: Junyang Lin
          isHf: false
          isPro: false
          name: JustinLin610
          type: user
        html: '<p>Sorry I have never tried HF trainer. But my colleagues recently
          supported the training of OFA with our HF code, see this repo: <a rel="nofollow"
          href="https://github.com/OFA-Sys/OFA-Compress">https://github.com/OFA-Sys/OFA-Compress</a></p>

          '
        raw: 'Sorry I have never tried HF trainer. But my colleagues recently supported
          the training of OFA with our HF code, see this repo: https://github.com/OFA-Sys/OFA-Compress'
        updatedAt: '2022-11-04T14:06:03.068Z'
      numEdits: 0
      reactions: []
    id: 63651c4b25aa3bd177cef17d
    type: comment
  author: JustinLin610
  content: 'Sorry I have never tried HF trainer. But my colleagues recently supported
    the training of OFA with our HF code, see this repo: https://github.com/OFA-Sys/OFA-Compress'
  created_at: 2022-11-04 13:06:03+00:00
  edited: false
  hidden: false
  id: 63651c4b25aa3bd177cef17d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: OFA-Sys/ofa-tiny
repo_type: model
status: open
target_branch: null
title: Fine tuning on SNLI-VE (visual entailment) with transformers models & Trainer
