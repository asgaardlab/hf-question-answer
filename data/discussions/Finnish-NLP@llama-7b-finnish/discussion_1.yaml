!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mpasila
conflicting_files: null
created_at: 2023-11-01 11:54:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7e5ccbc0dac5c1e16bdddd489802d363.svg
      fullname: minipasila
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mpasila
      type: user
    createdAt: '2023-11-01T12:54:06.000Z'
    data:
      edited: false
      editors:
      - mpasila
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.1770501434803009
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7e5ccbc0dac5c1e16bdddd489802d363.svg
          fullname: minipasila
          isHf: false
          isPro: false
          name: mpasila
          type: user
        html: "<p>I tried loading it in 4bit with bitsandbytes and it gives this error</p>\n\
          <pre><code>Traceback (most recent call last):\n  File \"C:\\Users\\pasil\\\
          text-generation-webui\\server.py\", line 223, in &lt;module&gt;\n    shared.model,\
          \ shared.tokenizer = load_model(model_name)\n                          \
          \           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\pasil\\text-generation-webui\\\
          modules\\models.py\", line 92, in load_model\n    tokenizer = load_tokenizer(model_name,\
          \ model)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\\
          Users\\pasil\\text-generation-webui\\modules\\models.py\", line 111, in\
          \ load_tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(\n     \
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\pasil\\\
          anaconda3\\envs\\textgen\\Lib\\site-packages\\transformers\\models\\auto\\\
          tokenization_auto.py\", line 751, in from_pretrained\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"C:\\Users\\pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\\
          transformers\\tokenization_utils_base.py\", line 2017, in from_pretrained\n\
          \    return cls._from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^\n  File\
          \ \"C:\\Users\\pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\transformers\\\
          tokenization_utils_base.py\", line 2249, in _from_pretrained\n    tokenizer\
          \ = cls(*init_inputs, **init_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"C:\\Users\\pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\\
          transformers\\models\\llama\\tokenization_llama.py\", line 141, in __init__\n\
          \    self.sp_model = self.get_spm_processor(kwargs.pop(\"from_slow\", False))\n\
          \                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"C:\\Users\\pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\\
          transformers\\models\\llama\\tokenization_llama.py\", line 166, in get_spm_processor\n\
          \    tokenizer.Load(self.vocab_file)\n  File \"C:\\Users\\pasil\\anaconda3\\\
          envs\\textgen\\Lib\\site-packages\\sentencepiece\\__init__.py\", line 905,\
          \ in Load\n    return self.LoadFromFile(model_file)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"C:\\Users\\pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\\
          sentencepiece\\__init__.py\", line 310, in LoadFromFile\n    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self,\
          \ arg)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          TypeError: not a string\n</code></pre>\n"
        raw: "I tried loading it in 4bit with bitsandbytes and it gives this error\r\
          \n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\pasil\\\
          text-generation-webui\\server.py\", line 223, in <module>\r\n    shared.model,\
          \ shared.tokenizer = load_model(model_name)\r\n                        \
          \             ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\pasil\\text-generation-webui\\\
          modules\\models.py\", line 92, in load_model\r\n    tokenizer = load_tokenizer(model_name,\
          \ model)\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File\
          \ \"C:\\Users\\pasil\\text-generation-webui\\modules\\models.py\", line\
          \ 111, in load_tokenizer\r\n    tokenizer = AutoTokenizer.from_pretrained(\r\
          \n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\\
          pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\transformers\\models\\\
          auto\\tokenization_auto.py\", line 751, in from_pretrained\r\n    return\
          \ tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs,\
          \ **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"C:\\Users\\pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\\
          transformers\\tokenization_utils_base.py\", line 2017, in from_pretrained\r\
          \n    return cls._from_pretrained(\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"C:\\Users\\pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\\
          transformers\\tokenization_utils_base.py\", line 2249, in _from_pretrained\r\
          \n    tokenizer = cls(*init_inputs, **init_kwargs)\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"C:\\Users\\pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\\
          transformers\\models\\llama\\tokenization_llama.py\", line 141, in __init__\r\
          \n    self.sp_model = self.get_spm_processor(kwargs.pop(\"from_slow\", False))\r\
          \n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"C:\\Users\\pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\\
          transformers\\models\\llama\\tokenization_llama.py\", line 166, in get_spm_processor\r\
          \n    tokenizer.Load(self.vocab_file)\r\n  File \"C:\\Users\\pasil\\anaconda3\\\
          envs\\textgen\\Lib\\site-packages\\sentencepiece\\__init__.py\", line 905,\
          \ in Load\r\n    return self.LoadFromFile(model_file)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"C:\\Users\\pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\\
          sentencepiece\\__init__.py\", line 310, in LoadFromFile\r\n    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self,\
          \ arg)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \nTypeError: not a string\r\n```"
        updatedAt: '2023-11-01T12:54:06.339Z'
      numEdits: 0
      reactions: []
    id: 65424a6eb0170e960704ef7e
    type: comment
  author: mpasila
  content: "I tried loading it in 4bit with bitsandbytes and it gives this error\r\
    \n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\pasil\\text-generation-webui\\\
    server.py\", line 223, in <module>\r\n    shared.model, shared.tokenizer = load_model(model_name)\r\
    \n                                     ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\\
    Users\\pasil\\text-generation-webui\\modules\\models.py\", line 92, in load_model\r\
    \n    tokenizer = load_tokenizer(model_name, model)\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"C:\\Users\\pasil\\text-generation-webui\\modules\\models.py\", line\
    \ 111, in load_tokenizer\r\n    tokenizer = AutoTokenizer.from_pretrained(\r\n\
    \                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\pasil\\\
    anaconda3\\envs\\textgen\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py\"\
    , line 751, in from_pretrained\r\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
    \ *inputs, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"C:\\Users\\pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\transformers\\\
    tokenization_utils_base.py\", line 2017, in from_pretrained\r\n    return cls._from_pretrained(\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\pasil\\anaconda3\\envs\\\
    textgen\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\", line\
    \ 2249, in _from_pretrained\r\n    tokenizer = cls(*init_inputs, **init_kwargs)\r\
    \n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\pasil\\\
    anaconda3\\envs\\textgen\\Lib\\site-packages\\transformers\\models\\llama\\tokenization_llama.py\"\
    , line 141, in __init__\r\n    self.sp_model = self.get_spm_processor(kwargs.pop(\"\
    from_slow\", False))\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"C:\\Users\\pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\transformers\\\
    models\\llama\\tokenization_llama.py\", line 166, in get_spm_processor\r\n   \
    \ tokenizer.Load(self.vocab_file)\r\n  File \"C:\\Users\\pasil\\anaconda3\\envs\\\
    textgen\\Lib\\site-packages\\sentencepiece\\__init__.py\", line 905, in Load\r\
    \n    return self.LoadFromFile(model_file)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"C:\\Users\\pasil\\anaconda3\\envs\\textgen\\Lib\\site-packages\\sentencepiece\\\
    __init__.py\", line 310, in LoadFromFile\r\n    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self,\
    \ arg)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \nTypeError: not a string\r\n```"
  created_at: 2023-11-01 11:54:06+00:00
  edited: false
  hidden: false
  id: 65424a6eb0170e960704ef7e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652770770075-60544ee76158e94e71944d20.jpeg?w=200&h=200&f=face
      fullname: Aapo Tanskanen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: aapot
      type: user
    createdAt: '2023-11-17T15:40:06.000Z'
    data:
      edited: false
      editors:
      - aapot
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8358784914016724
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652770770075-60544ee76158e94e71944d20.jpeg?w=200&h=200&f=face
          fullname: Aapo Tanskanen
          isHf: false
          isPro: false
          name: aapot
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mpasila&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mpasila\">@<span class=\"\
          underline\">mpasila</span></a></span>\n\n\t</span></span> can you try load\
          \ tokenizer with the <code>AutoTokenizer</code> from <code>transformers</code>?\
          \ That should work.</p>\n"
        raw: '@mpasila can you try load tokenizer with the `AutoTokenizer` from `transformers`?
          That should work.'
        updatedAt: '2023-11-17T15:40:06.338Z'
      numEdits: 0
      reactions: []
    id: 655789568076124b8d9fb60f
    type: comment
  author: aapot
  content: '@mpasila can you try load tokenizer with the `AutoTokenizer` from `transformers`?
    That should work.'
  created_at: 2023-11-17 15:40:06+00:00
  edited: false
  hidden: false
  id: 655789568076124b8d9fb60f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7e5ccbc0dac5c1e16bdddd489802d363.svg
      fullname: minipasila
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mpasila
      type: user
    createdAt: '2023-11-18T10:37:46.000Z'
    data:
      edited: false
      editors:
      - mpasila
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9594261050224304
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7e5ccbc0dac5c1e16bdddd489802d363.svg
          fullname: minipasila
          isHf: false
          isPro: false
          name: mpasila
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;mpasila&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/mpasila\"\
          >@<span class=\"underline\">mpasila</span></a></span>\n\n\t</span></span>\
          \ can you try load tokenizer with the <code>AutoTokenizer</code> from <code>transformers</code>?\
          \ That should work.</p>\n</blockquote>\n<p>I tried loading it again today\
          \ and now it's loading it just fine. So I'm not sure what happened last\
          \ time. Oobabooga's text-generation-webui already does what you suggested\
          \ so that shouldn't have been the problem.</p>\n"
        raw: '> @mpasila can you try load tokenizer with the `AutoTokenizer` from
          `transformers`? That should work.


          I tried loading it again today and now it''s loading it just fine. So I''m
          not sure what happened last time. Oobabooga''s text-generation-webui already
          does what you suggested so that shouldn''t have been the problem.'
        updatedAt: '2023-11-18T10:37:46.307Z'
      numEdits: 0
      reactions: []
      relatedEventId: 655893fa51ebd26dbc02196f
    id: 655893fa51ebd26dbc02196e
    type: comment
  author: mpasila
  content: '> @mpasila can you try load tokenizer with the `AutoTokenizer` from `transformers`?
    That should work.


    I tried loading it again today and now it''s loading it just fine. So I''m not
    sure what happened last time. Oobabooga''s text-generation-webui already does
    what you suggested so that shouldn''t have been the problem.'
  created_at: 2023-11-18 10:37:46+00:00
  edited: false
  hidden: false
  id: 655893fa51ebd26dbc02196e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/7e5ccbc0dac5c1e16bdddd489802d363.svg
      fullname: minipasila
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mpasila
      type: user
    createdAt: '2023-11-18T10:37:46.000Z'
    data:
      status: closed
    id: 655893fa51ebd26dbc02196f
    type: status-change
  author: mpasila
  created_at: 2023-11-18 10:37:46+00:00
  id: 655893fa51ebd26dbc02196f
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Finnish-NLP/llama-7b-finnish
repo_type: model
status: closed
target_branch: null
title: Tokenizer is broken?
