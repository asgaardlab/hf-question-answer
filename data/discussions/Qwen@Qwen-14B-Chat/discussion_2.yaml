!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Trenx
conflicting_files: null
created_at: 2023-09-25 07:19:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7805de9923604a4bfa5598e3916b3a74.svg
      fullname: "\u91D1\u6625\u65ED"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Trenx
      type: user
    createdAt: '2023-09-25T08:19:56.000Z'
    data:
      edited: false
      editors:
      - Trenx
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.8938440680503845
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7805de9923604a4bfa5598e3916b3a74.svg
          fullname: "\u91D1\u6625\u65ED"
          isHf: false
          isPro: false
          name: Trenx
          type: user
        html: "<p>\u95EE\u9898\uFF1Aint4\u91CF\u5316\u540Ekey.dtype\u4E3Afloat16\uFF0C\
          \u4F46\u662Fquery.dtype\u4ECD\u7136\u4E3Afloat32\uFF0C\u5728\u8FDB\u884C\
          query\u548Ckey\u70B9\u4E58\u65F6\u62A5\u51FA\u7C7B\u578B\u9519\u8BEF<br>\u5EFA\
          \u8BAE\uFF1A\u5728258\u884C_attn\u51FD\u6570\u4E2D\u7B2C\u4E00\u884C\u52A0\
          \u5165\u5224\u65ADquery\u548Ckey\u662F\u5426\u4E3A\u540C\u4E00\u7C7B\u578B\
          \u7684\u5224\u65AD\uFF0C\u5E76\u7EDF\u4E00\u4E24\u8005\u7C7B\u578B</p>\n"
        raw: "\u95EE\u9898\uFF1Aint4\u91CF\u5316\u540Ekey.dtype\u4E3Afloat16\uFF0C\
          \u4F46\u662Fquery.dtype\u4ECD\u7136\u4E3Afloat32\uFF0C\u5728\u8FDB\u884C\
          query\u548Ckey\u70B9\u4E58\u65F6\u62A5\u51FA\u7C7B\u578B\u9519\u8BEF\r\n\
          \u5EFA\u8BAE\uFF1A\u5728258\u884C_attn\u51FD\u6570\u4E2D\u7B2C\u4E00\u884C\
          \u52A0\u5165\u5224\u65ADquery\u548Ckey\u662F\u5426\u4E3A\u540C\u4E00\u7C7B\
          \u578B\u7684\u5224\u65AD\uFF0C\u5E76\u7EDF\u4E00\u4E24\u8005\u7C7B\u578B"
        updatedAt: '2023-09-25T08:19:56.136Z'
      numEdits: 0
      reactions: []
    id: 651142ac8d01590937040837
    type: comment
  author: Trenx
  content: "\u95EE\u9898\uFF1Aint4\u91CF\u5316\u540Ekey.dtype\u4E3Afloat16\uFF0C\u4F46\
    \u662Fquery.dtype\u4ECD\u7136\u4E3Afloat32\uFF0C\u5728\u8FDB\u884Cquery\u548C\
    key\u70B9\u4E58\u65F6\u62A5\u51FA\u7C7B\u578B\u9519\u8BEF\r\n\u5EFA\u8BAE\uFF1A\
    \u5728258\u884C_attn\u51FD\u6570\u4E2D\u7B2C\u4E00\u884C\u52A0\u5165\u5224\u65AD\
    query\u548Ckey\u662F\u5426\u4E3A\u540C\u4E00\u7C7B\u578B\u7684\u5224\u65AD\uFF0C\
    \u5E76\u7EDF\u4E00\u4E24\u8005\u7C7B\u578B"
  created_at: 2023-09-25 07:19:56+00:00
  edited: false
  hidden: false
  id: 651142ac8d01590937040837
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b2a04c922f26a27e7303e1/ECIboCxE29J-xUJJIS_nv.png?w=200&h=200&f=face
      fullname: Jon Wang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Cornmonster
      type: user
    createdAt: '2023-09-26T11:05:11.000Z'
    data:
      edited: false
      editors:
      - Cornmonster
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.45169228315353394
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b2a04c922f26a27e7303e1/ECIboCxE29J-xUJJIS_nv.png?w=200&h=200&f=face
          fullname: Jon Wang
          isHf: false
          isPro: false
          name: Cornmonster
          type: user
        html: "<p>+1\uFF0Cload in 4bit \u62A5\u9519\u5982\u4E0B\uFF1A</p>\n<pre><code\
          \ class=\"language-python\">  File <span class=\"hljs-string\">\"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          </span>, line <span class=\"hljs-number\">1501</span>, <span class=\"hljs-keyword\"\
          >in</span> _call_impl\n    <span class=\"hljs-keyword\">return</span> forward_call(*args,\
          \ **kwargs)\n  File <span class=\"hljs-string\">\"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/accelerate/hooks.py\"\
          </span>, line <span class=\"hljs-number\">165</span>, <span class=\"hljs-keyword\"\
          >in</span> new_forward\n    output = old_forward(*args, **kwargs)\n  File\
          \ <span class=\"hljs-string\">\"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
          </span>, line <span class=\"hljs-number\">1109</span>, <span class=\"hljs-keyword\"\
          >in</span> forward\n    transformer_outputs = self.transformer(\n  File\
          \ <span class=\"hljs-string\">\"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          </span>, line <span class=\"hljs-number\">1501</span>, <span class=\"hljs-keyword\"\
          >in</span> _call_impl\n    <span class=\"hljs-keyword\">return</span> forward_call(*args,\
          \ **kwargs)\n  File <span class=\"hljs-string\">\"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/accelerate/hooks.py\"\
          </span>, line <span class=\"hljs-number\">165</span>, <span class=\"hljs-keyword\"\
          >in</span> new_forward\n    output = old_forward(*args, **kwargs)\n  File\
          \ <span class=\"hljs-string\">\"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
          </span>, line <span class=\"hljs-number\">930</span>, <span class=\"hljs-keyword\"\
          >in</span> forward\n    outputs = block(\n  File <span class=\"hljs-string\"\
          >\"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          </span>, line <span class=\"hljs-number\">1501</span>, <span class=\"hljs-keyword\"\
          >in</span> _call_impl\n    <span class=\"hljs-keyword\">return</span> forward_call(*args,\
          \ **kwargs)\n  File <span class=\"hljs-string\">\"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/accelerate/hooks.py\"\
          </span>, line <span class=\"hljs-number\">165</span>, <span class=\"hljs-keyword\"\
          >in</span> new_forward\n    output = old_forward(*args, **kwargs)\n  File\
          \ <span class=\"hljs-string\">\"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
          </span>, line <span class=\"hljs-number\">631</span>, <span class=\"hljs-keyword\"\
          >in</span> forward\n    attn_outputs = self.attn(\n  File <span class=\"\
          hljs-string\">\"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          </span>, line <span class=\"hljs-number\">1501</span>, <span class=\"hljs-keyword\"\
          >in</span> _call_impl\n    <span class=\"hljs-keyword\">return</span> forward_call(*args,\
          \ **kwargs)\n  File <span class=\"hljs-string\">\"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/accelerate/hooks.py\"\
          </span>, line <span class=\"hljs-number\">165</span>, <span class=\"hljs-keyword\"\
          >in</span> new_forward\n    output = old_forward(*args, **kwargs)\n  File\
          \ <span class=\"hljs-string\">\"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
          </span>, line <span class=\"hljs-number\">556</span>, <span class=\"hljs-keyword\"\
          >in</span> forward\n    attn_output, attn_weight = self._attn(\n  File <span\
          \ class=\"hljs-string\">\"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
          </span>, line <span class=\"hljs-number\">314</span>, <span class=\"hljs-keyword\"\
          >in</span> _attn\n    attn_weights = torch.matmul(query, key.transpose(-<span\
          \ class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">2</span>))\n\
          RuntimeError: [address=<span class=\"hljs-number\">127.0</span><span class=\"\
          hljs-number\">.0</span><span class=\"hljs-number\">.1</span>:<span class=\"\
          hljs-number\">36263</span>, pid=<span class=\"hljs-number\">21908</span>]\
          \ expected scalar <span class=\"hljs-built_in\">type</span> Half but found\
          \ Float\n</code></pre>\n"
        raw: "+1\uFF0Cload in 4bit \u62A5\u9519\u5982\u4E0B\uFF1A\n```python\n  File\
          \ \"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
          , line 1109, in forward\n    transformer_outputs = self.transformer(\n \
          \ File \"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
          , line 930, in forward\n    outputs = block(\n  File \"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
          , line 631, in forward\n    attn_outputs = self.attn(\n  File \"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
          , line 556, in forward\n    attn_output, attn_weight = self._attn(\n  File\
          \ \"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
          , line 314, in _attn\n    attn_weights = torch.matmul(query, key.transpose(-1,\
          \ -2))\nRuntimeError: [address=127.0.0.1:36263, pid=21908] expected scalar\
          \ type Half but found Float\n```"
        updatedAt: '2023-09-26T11:05:11.320Z'
      numEdits: 0
      reactions: []
    id: 6512bae7442f1142ff0d8a4f
    type: comment
  author: Cornmonster
  content: "+1\uFF0Cload in 4bit \u62A5\u9519\u5982\u4E0B\uFF1A\n```python\n  File\
    \ \"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n  File\
    \ \"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
    , line 1109, in forward\n    transformer_outputs = self.transformer(\n  File \"\
    /home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n  File\
    \ \"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
    , line 930, in forward\n    outputs = block(\n  File \"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n  File\
    \ \"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
    , line 631, in forward\n    attn_outputs = self.attn(\n  File \"/home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /home/ubuntu/miniconda3/envs/wz/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n  File\
    \ \"/home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
    , line 556, in forward\n    attn_output, attn_weight = self._attn(\n  File \"\
    /home/ubuntu/.cache/huggingface/modules/transformers_modules/qwen-chat-pytorch-14b/modeling_qwen.py\"\
    , line 314, in _attn\n    attn_weights = torch.matmul(query, key.transpose(-1,\
    \ -2))\nRuntimeError: [address=127.0.0.1:36263, pid=21908] expected scalar type\
    \ Half but found Float\n```"
  created_at: 2023-09-26 10:05:11+00:00
  edited: false
  hidden: false
  id: 6512bae7442f1142ff0d8a4f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1644682834896-620760a26e3b7210c2ff1943.jpeg?w=200&h=200&f=face
      fullname: Junyang Lin
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JustinLin610
      type: user
    createdAt: '2023-11-13T13:45:05.000Z'
    data:
      edited: false
      editors:
      - JustinLin610
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8093957304954529
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1644682834896-620760a26e3b7210c2ff1943.jpeg?w=200&h=200&f=face
          fullname: Junyang Lin
          isHf: false
          isPro: false
          name: JustinLin610
          type: user
        html: '<p>How about using Qwen-14B-Int4? This one performs better than BNB.
          Check the section quantization in our github readme for more information.</p>

          '
        raw: How about using Qwen-14B-Int4? This one performs better than BNB. Check
          the section quantization in our github readme for more information.
        updatedAt: '2023-11-13T13:45:05.650Z'
      numEdits: 0
      reactions: []
    id: 65522861d9c8ceffd66b87c6
    type: comment
  author: JustinLin610
  content: How about using Qwen-14B-Int4? This one performs better than BNB. Check
    the section quantization in our github readme for more information.
  created_at: 2023-11-13 13:45:05+00:00
  edited: false
  hidden: false
  id: 65522861d9c8ceffd66b87c6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9921ca8568f9d53c919681d8960ad802.svg
      fullname: jklj077
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jklj077
      type: user
    createdAt: '2023-12-21T12:54:59.000Z'
    data:
      status: closed
    id: 658435a32031da25dac572fb
    type: status-change
  author: jklj077
  created_at: 2023-12-21 12:54:59+00:00
  id: 658435a32031da25dac572fb
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Qwen/Qwen-14B-Chat
repo_type: model
status: closed
target_branch: null
title: "int4\u91CF\u5316Qwen/Qwen-14B-Chat\u8FD0\u884C\u51FA\u9519"
