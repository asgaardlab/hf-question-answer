!!python/object:huggingface_hub.community.DiscussionWithDetails
author: zideliu
conflicting_files: null
created_at: 2023-08-04 02:54:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/O6yDcmDTZk9IH2wIbuCQ3.jpeg?w=200&h=200&f=face
      fullname: "\u5218\u81EA\u5F97"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zideliu
      type: user
    createdAt: '2023-08-04T03:54:44.000Z'
    data:
      edited: true
      editors:
      - zideliu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3634105622768402
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/O6yDcmDTZk9IH2wIbuCQ3.jpeg?w=200&h=200&f=face
          fullname: "\u5218\u81EA\u5F97"
          isHf: false
          isPro: false
          name: zideliu
          type: user
        html: "<pre><code class=\"language-shell\"><span class=\"hljs-meta prompt_\"\
          >&gt;</span><span class=\"language-bash\">&gt;&gt; from diffusers.models\
          \ import AutoencoderKL</span>\n<span class=\"hljs-meta prompt_\">&gt;</span><span\
          \ class=\"language-bash\">&gt;&gt; import torch</span>\n<span class=\"hljs-meta\
          \ prompt_\">&gt;</span><span class=\"language-bash\">&gt;&gt; vae16 = AutoencoderKL.from_pretrained(<span\
          \ class=\"hljs-string\">\"sdxl-vae\"</span>,torch_dtype=torch.float16).to(<span\
          \ class=\"hljs-string\">'cuda'</span>)</span>\n<span class=\"hljs-meta prompt_\"\
          >&gt;</span><span class=\"language-bash\">&gt;&gt; vae = AutoencoderKL.from_pretrained(<span\
          \ class=\"hljs-string\">\"sdxl-vae\"</span>).to(<span class=\"hljs-string\"\
          >'cuda'</span>)</span>\n<span class=\"hljs-meta prompt_\"></span>\n<span\
          \ class=\"hljs-meta prompt_\">&gt;</span><span class=\"language-bash\">&gt;&gt;\
          \ import numpy as np</span>\n<span class=\"hljs-meta prompt_\">&gt;</span><span\
          \ class=\"language-bash\">&gt;&gt; from PIL import Image</span>\n<span class=\"\
          hljs-meta prompt_\">&gt;</span><span class=\"language-bash\">&gt;&gt; x\
          \ = np.array(Image.open(<span class=\"hljs-string\">'1.png'</span>).convert(<span\
          \ class=\"hljs-string\">'RGB'</span>))</span>\n<span class=\"hljs-meta prompt_\"\
          ></span>\n<span class=\"hljs-meta prompt_\">&gt;</span><span class=\"language-bash\"\
          >&gt;&gt; x = x/127.5 -1.0</span>\n<span class=\"hljs-meta prompt_\">&gt;</span><span\
          \ class=\"language-bash\">&gt;&gt; x = torch.from_numpy(x)</span>\n<span\
          \ class=\"hljs-meta prompt_\">&gt;</span><span class=\"language-bash\">&gt;&gt;\
          \ x = x.permute(2,0,1)</span>\n<span class=\"hljs-meta prompt_\">&gt;</span><span\
          \ class=\"language-bash\">&gt;&gt; x.shape</span>\ntorch.Size([3, 1024,\
          \ 1024])\n<span class=\"hljs-meta prompt_\"></span>\n<span class=\"hljs-meta\
          \ prompt_\">&gt;</span><span class=\"language-bash\">&gt;&gt; im = x.to(<span\
          \ class=\"hljs-string\">'cuda'</span>,dtype=torch.float32)</span>\n<span\
          \ class=\"hljs-meta prompt_\">&gt;</span><span class=\"language-bash\">&gt;&gt;\
          \ im16 = x.to(<span class=\"hljs-string\">'cuda'</span>,dtype=torch.float16)</span>\n\
          <span class=\"hljs-meta prompt_\">&gt;</span><span class=\"language-bash\"\
          >&gt;&gt; t16 = vae16.encode(im16).latent_dist.sample()</span>\n<span class=\"\
          hljs-meta prompt_\">&gt;</span><span class=\"language-bash\">&gt;&gt; t16</span>\n\
          tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,\
          \  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n\
          \          ...,\n          [nan, nan, nan,  ..., nan, nan, nan],\n     \
          \     [nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan, \
          \ ..., nan, nan, nan]],\n\n         [[nan, nan, nan,  ..., nan, nan, nan],\n\
          \          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,\
          \  ..., nan, nan, nan],\n          ...,\n          [nan, nan, nan,  ...,\
          \ nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n   \
          \       [nan, nan, nan,  ..., nan, nan, nan]],\n\n         [[nan, nan, nan,\
          \  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n\
          \          [nan, nan, nan,  ..., nan, nan, nan],\n          ...,\n     \
          \     [nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan, \
          \ ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan]],\n\
          \n         [[nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan,\
          \ nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan,\
          \ nan],\n          ...,\n          [nan, nan, nan,  ..., nan, nan, nan],\n\
          \          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,\
          \  ..., nan, nan, nan]]]], device='cuda:0',\n       dtype=torch.float16,\
          \ grad_fn=&lt;AddBackward0&gt;)\n<span class=\"hljs-meta prompt_\">&gt;</span><span\
          \ class=\"language-bash\">&gt;&gt; t = vae.encode(im).latent_dist.sample()</span>\n\
          <span class=\"hljs-meta prompt_\">&gt;</span><span class=\"language-bash\"\
          >&gt;&gt; t</span>\ntensor([[[[-10.6650, -10.7863,  -8.9922,  ...,  -4.9603,\
          \  -7.7862,  -5.2480],\n          [ -7.2087, -11.2612,  -7.2466,  ..., \
          \ -5.0280,  -8.4497,  -5.2412],\n          [ -9.8503,  -7.0086,  -8.6645,\
          \  ...,  -6.8731,  -5.7120,  -5.2228],\n          ...,\n          [ -0.8512,\
          \  -2.7118,  -3.6125,  ...,  -8.5498,  -6.7364,  -4.5577],\n          [\
          \ -4.7474,  -4.0266,  -2.2864,  ...,  -5.6377,  -5.6006,  -7.2353],\n  \
          \        [ -3.9695,  -5.3364,  -1.7182,  ...,  -4.1163,  -3.1237,  -8.5114]],\n\
          \n         [[  0.5291,   3.1062,   3.9364,  ...,   6.1754,   6.9985,  10.2787],\n\
          \          [  4.3542,   2.2514,   4.5842,  ...,   9.9785,   7.0942,   9.3612],\n\
          \          [  2.3624,   7.6000,   4.0870,  ...,   8.2662,   7.3177,   7.4536],\n\
          \          ...,\n          [  2.4479,   5.3318,   7.7907,  ...,   2.2813,\
          \   3.3110,   7.9058],\n          [  3.1145,   7.0900,   9.5676,  ..., \
          \  4.0560,   7.3074,   5.4294],\n          [  4.1593,   2.2279,   6.3064,\
          \  ...,   5.3051,   2.4846,  -0.6007]],\n\n         [[ -5.9309,   2.5895,\
          \  -7.6263,  ...,   7.6300,   9.7816,  -3.2628],\n          [  0.0919, \
          \ -4.1963,  -0.4588,  ...,   8.5846,   7.2509,   1.5191],\n          [ -7.2874,\
          \   0.2553,  -0.2289,  ...,   7.3174,  12.3518,   0.0686],\n          ...,\n\
          \          [  7.4820,   4.8404,   2.6403,  ...,  -3.4686,  -7.8857, -10.7730],\n\
          \          [ -3.9887,   5.6537,  -5.4063,  ...,  -4.4793,   0.0799,  -6.0221],\n\
          \          [  5.6877,  -0.1834,   1.8418,  ...,   0.7933,   5.1394,  -2.5688]],\n\
          \n         [[  5.9649,   7.5648,   6.7202,  ...,   7.6067,   2.7659,   2.5190],\n\
          \          [ 11.1852,   4.1965,  11.4174,  ...,   6.5834,   0.0270,  -0.6252],\n\
          \          [  5.5535,   8.5816,  10.5749,  ...,  -0.3417,   3.5020,   3.8151],\n\
          \          ...,\n          [  7.0386,   7.9634,   8.0208,  ...,   2.0303,\
          \   6.1680,   3.0449],\n          [  4.4080,   5.6513,   4.0449,  ..., \
          \  3.7297,   9.5295,   0.9136],\n          [  4.0043,   1.5003,   8.5650,\
          \  ...,  10.1849,   6.6777,   1.8639]]]],\n       device='cuda:0', grad_fn=&lt;AddBackward0&gt;)\n\
          <span class=\"hljs-meta prompt_\">&gt;</span><span class=\"language-bash\"\
          >&gt;&gt;</span> \n</code></pre>\n<p>When I use fp16 the result is nan,\
          \ if I use fp32 the result is normal</p>\n<p>I get it. It's my problem</p>\n"
        raw: "```shell\n>>> from diffusers.models import AutoencoderKL\n>>> import\
          \ torch\n>>> vae16 = AutoencoderKL.from_pretrained(\"sdxl-vae\",torch_dtype=torch.float16).to('cuda')\n\
          >>> vae = AutoencoderKL.from_pretrained(\"sdxl-vae\").to('cuda')\n\n>>>\
          \ import numpy as np\n>>> from PIL import Image\n>>> x = np.array(Image.open('1.png').convert('RGB'))\n\
          \n>>> x = x/127.5 -1.0\n>>> x = torch.from_numpy(x)\n>>> x = x.permute(2,0,1)\n\
          >>> x.shape\ntorch.Size([3, 1024, 1024])\n\n>>> im = x.to('cuda',dtype=torch.float32)\n\
          >>> im16 = x.to('cuda',dtype=torch.float16)\n>>> t16 = vae16.encode(im16).latent_dist.sample()\n\
          >>> t16\ntensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n          [nan,\
          \ nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan,\
          \ nan, nan],\n          ...,\n          [nan, nan, nan,  ..., nan, nan,\
          \ nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan,\
          \ nan, nan,  ..., nan, nan, nan]],\n\n         [[nan, nan, nan,  ..., nan,\
          \ nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n        \
          \  [nan, nan, nan,  ..., nan, nan, nan],\n          ...,\n          [nan,\
          \ nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan,\
          \ nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan]],\n\n     \
          \    [[nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan, \
          \ ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n\
          \          ...,\n          [nan, nan, nan,  ..., nan, nan, nan],\n     \
          \     [nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan, \
          \ ..., nan, nan, nan]],\n\n         [[nan, nan, nan,  ..., nan, nan, nan],\n\
          \          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,\
          \  ..., nan, nan, nan],\n          ...,\n          [nan, nan, nan,  ...,\
          \ nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n   \
          \       [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n    \
          \   dtype=torch.float16, grad_fn=<AddBackward0>)\n>>> t = vae.encode(im).latent_dist.sample()\n\
          >>> t\ntensor([[[[-10.6650, -10.7863,  -8.9922,  ...,  -4.9603,  -7.7862,\
          \  -5.2480],\n          [ -7.2087, -11.2612,  -7.2466,  ...,  -5.0280, \
          \ -8.4497,  -5.2412],\n          [ -9.8503,  -7.0086,  -8.6645,  ...,  -6.8731,\
          \  -5.7120,  -5.2228],\n          ...,\n          [ -0.8512,  -2.7118, \
          \ -3.6125,  ...,  -8.5498,  -6.7364,  -4.5577],\n          [ -4.7474,  -4.0266,\
          \  -2.2864,  ...,  -5.6377,  -5.6006,  -7.2353],\n          [ -3.9695, \
          \ -5.3364,  -1.7182,  ...,  -4.1163,  -3.1237,  -8.5114]],\n\n         [[\
          \  0.5291,   3.1062,   3.9364,  ...,   6.1754,   6.9985,  10.2787],\n  \
          \        [  4.3542,   2.2514,   4.5842,  ...,   9.9785,   7.0942,   9.3612],\n\
          \          [  2.3624,   7.6000,   4.0870,  ...,   8.2662,   7.3177,   7.4536],\n\
          \          ...,\n          [  2.4479,   5.3318,   7.7907,  ...,   2.2813,\
          \   3.3110,   7.9058],\n          [  3.1145,   7.0900,   9.5676,  ..., \
          \  4.0560,   7.3074,   5.4294],\n          [  4.1593,   2.2279,   6.3064,\
          \  ...,   5.3051,   2.4846,  -0.6007]],\n\n         [[ -5.9309,   2.5895,\
          \  -7.6263,  ...,   7.6300,   9.7816,  -3.2628],\n          [  0.0919, \
          \ -4.1963,  -0.4588,  ...,   8.5846,   7.2509,   1.5191],\n          [ -7.2874,\
          \   0.2553,  -0.2289,  ...,   7.3174,  12.3518,   0.0686],\n          ...,\n\
          \          [  7.4820,   4.8404,   2.6403,  ...,  -3.4686,  -7.8857, -10.7730],\n\
          \          [ -3.9887,   5.6537,  -5.4063,  ...,  -4.4793,   0.0799,  -6.0221],\n\
          \          [  5.6877,  -0.1834,   1.8418,  ...,   0.7933,   5.1394,  -2.5688]],\n\
          \n         [[  5.9649,   7.5648,   6.7202,  ...,   7.6067,   2.7659,   2.5190],\n\
          \          [ 11.1852,   4.1965,  11.4174,  ...,   6.5834,   0.0270,  -0.6252],\n\
          \          [  5.5535,   8.5816,  10.5749,  ...,  -0.3417,   3.5020,   3.8151],\n\
          \          ...,\n          [  7.0386,   7.9634,   8.0208,  ...,   2.0303,\
          \   6.1680,   3.0449],\n          [  4.4080,   5.6513,   4.0449,  ..., \
          \  3.7297,   9.5295,   0.9136],\n          [  4.0043,   1.5003,   8.5650,\
          \  ...,  10.1849,   6.6777,   1.8639]]]],\n       device='cuda:0', grad_fn=<AddBackward0>)\n\
          >>> \n```\nWhen I use fp16 the result is nan, if I use fp32 the result is\
          \ normal\n\nI get it. It's my problem"
        updatedAt: '2023-08-04T04:41:00.108Z'
      numEdits: 1
      reactions: []
    id: 64cc768454348e678d62c8ef
    type: comment
  author: zideliu
  content: "```shell\n>>> from diffusers.models import AutoencoderKL\n>>> import torch\n\
    >>> vae16 = AutoencoderKL.from_pretrained(\"sdxl-vae\",torch_dtype=torch.float16).to('cuda')\n\
    >>> vae = AutoencoderKL.from_pretrained(\"sdxl-vae\").to('cuda')\n\n>>> import\
    \ numpy as np\n>>> from PIL import Image\n>>> x = np.array(Image.open('1.png').convert('RGB'))\n\
    \n>>> x = x/127.5 -1.0\n>>> x = torch.from_numpy(x)\n>>> x = x.permute(2,0,1)\n\
    >>> x.shape\ntorch.Size([3, 1024, 1024])\n\n>>> im = x.to('cuda',dtype=torch.float32)\n\
    >>> im16 = x.to('cuda',dtype=torch.float16)\n>>> t16 = vae16.encode(im16).latent_dist.sample()\n\
    >>> t16\ntensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan,\
    \ nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n\
    \          ...,\n          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan,\
    \ nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan]],\n\
    \n         [[nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan, \
    \ ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n    \
    \      ...,\n          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan,\
    \ nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan]],\n\
    \n         [[nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan, \
    \ ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n    \
    \      ...,\n          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan,\
    \ nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan]],\n\
    \n         [[nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan, \
    \ ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n    \
    \      ...,\n          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan,\
    \ nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan]]]],\
    \ device='cuda:0',\n       dtype=torch.float16, grad_fn=<AddBackward0>)\n>>> t\
    \ = vae.encode(im).latent_dist.sample()\n>>> t\ntensor([[[[-10.6650, -10.7863,\
    \  -8.9922,  ...,  -4.9603,  -7.7862,  -5.2480],\n          [ -7.2087, -11.2612,\
    \  -7.2466,  ...,  -5.0280,  -8.4497,  -5.2412],\n          [ -9.8503,  -7.0086,\
    \  -8.6645,  ...,  -6.8731,  -5.7120,  -5.2228],\n          ...,\n          [\
    \ -0.8512,  -2.7118,  -3.6125,  ...,  -8.5498,  -6.7364,  -4.5577],\n        \
    \  [ -4.7474,  -4.0266,  -2.2864,  ...,  -5.6377,  -5.6006,  -7.2353],\n     \
    \     [ -3.9695,  -5.3364,  -1.7182,  ...,  -4.1163,  -3.1237,  -8.5114]],\n\n\
    \         [[  0.5291,   3.1062,   3.9364,  ...,   6.1754,   6.9985,  10.2787],\n\
    \          [  4.3542,   2.2514,   4.5842,  ...,   9.9785,   7.0942,   9.3612],\n\
    \          [  2.3624,   7.6000,   4.0870,  ...,   8.2662,   7.3177,   7.4536],\n\
    \          ...,\n          [  2.4479,   5.3318,   7.7907,  ...,   2.2813,   3.3110,\
    \   7.9058],\n          [  3.1145,   7.0900,   9.5676,  ...,   4.0560,   7.3074,\
    \   5.4294],\n          [  4.1593,   2.2279,   6.3064,  ...,   5.3051,   2.4846,\
    \  -0.6007]],\n\n         [[ -5.9309,   2.5895,  -7.6263,  ...,   7.6300,   9.7816,\
    \  -3.2628],\n          [  0.0919,  -4.1963,  -0.4588,  ...,   8.5846,   7.2509,\
    \   1.5191],\n          [ -7.2874,   0.2553,  -0.2289,  ...,   7.3174,  12.3518,\
    \   0.0686],\n          ...,\n          [  7.4820,   4.8404,   2.6403,  ..., \
    \ -3.4686,  -7.8857, -10.7730],\n          [ -3.9887,   5.6537,  -5.4063,  ...,\
    \  -4.4793,   0.0799,  -6.0221],\n          [  5.6877,  -0.1834,   1.8418,  ...,\
    \   0.7933,   5.1394,  -2.5688]],\n\n         [[  5.9649,   7.5648,   6.7202,\
    \  ...,   7.6067,   2.7659,   2.5190],\n          [ 11.1852,   4.1965,  11.4174,\
    \  ...,   6.5834,   0.0270,  -0.6252],\n          [  5.5535,   8.5816,  10.5749,\
    \  ...,  -0.3417,   3.5020,   3.8151],\n          ...,\n          [  7.0386, \
    \  7.9634,   8.0208,  ...,   2.0303,   6.1680,   3.0449],\n          [  4.4080,\
    \   5.6513,   4.0449,  ...,   3.7297,   9.5295,   0.9136],\n          [  4.0043,\
    \   1.5003,   8.5650,  ...,  10.1849,   6.6777,   1.8639]]]],\n       device='cuda:0',\
    \ grad_fn=<AddBackward0>)\n>>> \n```\nWhen I use fp16 the result is nan, if I\
    \ use fp32 the result is normal\n\nI get it. It's my problem"
  created_at: 2023-08-04 02:54:44+00:00
  edited: true
  hidden: false
  id: 64cc768454348e678d62c8ef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/O6yDcmDTZk9IH2wIbuCQ3.jpeg?w=200&h=200&f=face
      fullname: "\u5218\u81EA\u5F97"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zideliu
      type: user
    createdAt: '2023-08-04T04:41:03.000Z'
    data:
      status: closed
    id: 64cc815fa257a3212c1b8e63
    type: status-change
  author: zideliu
  created_at: 2023-08-04 03:41:03+00:00
  id: 64cc815fa257a3212c1b8e63
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 39
repo_id: stabilityai/stable-diffusion-xl-base-1.0
repo_type: model
status: closed
target_branch: null
title: About VAE in sdxl, when I encode the image with VAE, the result was nan
