!!python/object:huggingface_hub.community.DiscussionWithDetails
author: wzgrx
conflicting_files: null
created_at: 2023-07-27 01:37:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d5174fbc39b9a23d60b44e83b74f303b.svg
      fullname: wzgrx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wzgrx
      type: user
    createdAt: '2023-07-27T02:37:57.000Z'
    data:
      edited: true
      editors:
      - wzgrx
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9477932453155518
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d5174fbc39b9a23d60b44e83b74f303b.svg
          fullname: wzgrx
          isHf: false
          isPro: false
          name: wzgrx
          type: user
        html: '<p>Why is the graphics memory requirement of SDxl 1.0 so high? Starting
          at 12GB, can''t graphics cards below 12GB be used at all?<br>Can SDxl 0.9
          use 4GB graphics memory? Why do we have to upgrade our graphics card? Or
          is it required by Nvidia?</p>

          '
        raw: 'Why is the graphics memory requirement of SDxl 1.0 so high? Starting
          at 12GB, can''t graphics cards below 12GB be used at all?

          Can SDxl 0.9 use 4GB graphics memory? Why do we have to upgrade our graphics
          card? Or is it required by Nvidia?'
        updatedAt: '2023-07-27T02:40:32.476Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - testingbetas7
        - youtubehome
    id: 64c1d8857e6975b39171432a
    type: comment
  author: wzgrx
  content: 'Why is the graphics memory requirement of SDxl 1.0 so high? Starting at
    12GB, can''t graphics cards below 12GB be used at all?

    Can SDxl 0.9 use 4GB graphics memory? Why do we have to upgrade our graphics card?
    Or is it required by Nvidia?'
  created_at: 2023-07-27 01:37:57+00:00
  edited: true
  hidden: false
  id: 64c1d8857e6975b39171432a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1656697099516-noauth.png?w=200&h=200&f=face
      fullname: Murilo Pagliuso
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DarkCeptor44
      type: user
    createdAt: '2023-07-27T03:27:20.000Z'
    data:
      edited: false
      editors:
      - DarkCeptor44
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9740367531776428
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1656697099516-noauth.png?w=200&h=200&f=face
          fullname: Murilo Pagliuso
          isHf: false
          isPro: false
          name: DarkCeptor44
          type: user
        html: '<p>8GB does work it just takes a whole minute, maybe (if you''re using
          A1111) add "--no-half-vae" to launch parameters, I''m not sure if that''s
          why but it''s working for me.</p>

          '
        raw: 8GB does work it just takes a whole minute, maybe (if you're using A1111)
          add "--no-half-vae" to launch parameters, I'm not sure if that's why but
          it's working for me.
        updatedAt: '2023-07-27T03:27:20.849Z'
      numEdits: 0
      reactions: []
    id: 64c1e418e75fd66a71cdf30c
    type: comment
  author: DarkCeptor44
  content: 8GB does work it just takes a whole minute, maybe (if you're using A1111)
    add "--no-half-vae" to launch parameters, I'm not sure if that's why but it's
    working for me.
  created_at: 2023-07-27 02:27:20+00:00
  edited: false
  hidden: false
  id: 64c1e418e75fd66a71cdf30c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/20f92753576b243b56c28dc8c402f1cd.svg
      fullname: James Read
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Galberz
      type: user
    createdAt: '2023-07-27T10:15:36.000Z'
    data:
      edited: true
      editors:
      - Galberz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.580369234085083
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/20f92753576b243b56c28dc8c402f1cd.svg
          fullname: James Read
          isHf: false
          isPro: false
          name: Galberz
          type: user
        html: '<p>If you are limited by GPU VRAM, you can enable cpu offloading by
          calling pipe.enable_model_cpu_offload instead of .to("cuda"):</p>

          <ul>

          <li>pipe.enable_model_cpu_offload()</li>

          </ul>

          '
        raw: 'If you are limited by GPU VRAM, you can enable cpu offloading by calling
          pipe.enable_model_cpu_offload instead of .to("cuda"):



          + pipe.enable_model_cpu_offload()

          '
        updatedAt: '2023-07-27T10:15:52.849Z'
      numEdits: 1
      reactions: []
    id: 64c243c864e3e59137df3be2
    type: comment
  author: Galberz
  content: 'If you are limited by GPU VRAM, you can enable cpu offloading by calling
    pipe.enable_model_cpu_offload instead of .to("cuda"):



    + pipe.enable_model_cpu_offload()

    '
  created_at: 2023-07-27 09:15:36+00:00
  edited: true
  hidden: false
  id: 64c243c864e3e59137df3be2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/d5174fbc39b9a23d60b44e83b74f303b.svg
      fullname: wzgrx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wzgrx
      type: user
    createdAt: '2023-07-27T11:45:09.000Z'
    data:
      status: closed
    id: 64c258c5217c1eff71e985e1
    type: status-change
  author: wzgrx
  created_at: 2023-07-27 10:45:09+00:00
  id: 64c258c5217c1eff71e985e1
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/516298c4de6411ec65a834f005381157.svg
      fullname: youtube
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: youtubehome
      type: user
    createdAt: '2023-07-28T07:38:45.000Z'
    data:
      edited: false
      editors:
      - youtubehome
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9325278997421265
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/516298c4de6411ec65a834f005381157.svg
          fullname: youtube
          isHf: false
          isPro: false
          name: youtubehome
          type: user
        html: '<blockquote>

          <p>Why is the graphics memory requirement of SDxl 1.0 so high? Starting
          at 12GB, can''t graphics cards below 12GB be used at all?<br>Can SDxl 0.9
          use 4GB graphics memory? Why do we have to upgrade our graphics card? Or
          is it required by Nvidia?</p>

          </blockquote>

          <p>idk 0.9 use only 4GB VRAM. Thank you so much. Now i have to google different
          between 0.9 and 1.0,</p>

          '
        raw: '> Why is the graphics memory requirement of SDxl 1.0 so high? Starting
          at 12GB, can''t graphics cards below 12GB be used at all?

          > Can SDxl 0.9 use 4GB graphics memory? Why do we have to upgrade our graphics
          card? Or is it required by Nvidia?


          idk 0.9 use only 4GB VRAM. Thank you so much. Now i have to google different
          between 0.9 and 1.0,'
        updatedAt: '2023-07-28T07:38:45.903Z'
      numEdits: 0
      reactions: []
    id: 64c3708544c64511761cab2a
    type: comment
  author: youtubehome
  content: '> Why is the graphics memory requirement of SDxl 1.0 so high? Starting
    at 12GB, can''t graphics cards below 12GB be used at all?

    > Can SDxl 0.9 use 4GB graphics memory? Why do we have to upgrade our graphics
    card? Or is it required by Nvidia?


    idk 0.9 use only 4GB VRAM. Thank you so much. Now i have to google different between
    0.9 and 1.0,'
  created_at: 2023-07-28 06:38:45+00:00
  edited: false
  hidden: false
  id: 64c3708544c64511761cab2a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: stabilityai/stable-diffusion-xl-base-1.0
repo_type: model
status: closed
target_branch: null
title: 'Why is the graphics memory requirement of SDxl 1.0 so high? Starting at 12GB,
  can''t you use anything below 12GB? '
