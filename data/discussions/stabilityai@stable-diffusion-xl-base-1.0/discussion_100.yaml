!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Abhi0401
conflicting_files: null
created_at: 2023-10-08 08:12:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/61bf959a40b18e3956f99938d7bceb04.svg
      fullname: Abhishek yadav
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Abhi0401
      type: user
    createdAt: '2023-10-08T09:12:47.000Z'
    data:
      edited: false
      editors:
      - Abhi0401
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9205756187438965
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/61bf959a40b18e3956f99938d7bceb04.svg
          fullname: Abhishek yadav
          isHf: false
          isPro: false
          name: Abhi0401
          type: user
        html: '<p>Hi All,</p>

          <p>I am new to hugging face, so I was wondering if it is possible to use
          multiple instance of Inference Api with same access token,  all running
          at same time, will that work, if yes then will there be any latency for
          all parallel requests. If No, then what is the possible solution to achieve
          this. </p>

          '
        raw: "Hi All,\r\n\r\nI am new to hugging face, so I was wondering if it is\
          \ possible to use multiple instance of Inference Api with same access token,\
          \  all running at same time, will that work, if yes then will there be any\
          \ latency for all parallel requests. If No, then what is the possible solution\
          \ to achieve this. "
        updatedAt: '2023-10-08T09:12:47.088Z'
      numEdits: 0
      reactions: []
    id: 6522728fc0ceb75b49756dba
    type: comment
  author: Abhi0401
  content: "Hi All,\r\n\r\nI am new to hugging face, so I was wondering if it is possible\
    \ to use multiple instance of Inference Api with same access token,  all running\
    \ at same time, will that work, if yes then will there be any latency for all\
    \ parallel requests. If No, then what is the possible solution to achieve this. "
  created_at: 2023-10-08 08:12:47+00:00
  edited: false
  hidden: false
  id: 6522728fc0ceb75b49756dba
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/xUeE7fW5WEASovcD1zJxi.jpeg?w=200&h=200&f=face
      fullname: Aaron Carter
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: Arkaen-AtC
      type: user
    createdAt: '2023-12-15T16:58:23.000Z'
    data:
      edited: true
      editors:
      - Arkaen-AtC
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9329705238342285
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/xUeE7fW5WEASovcD1zJxi.jpeg?w=200&h=200&f=face
          fullname: Aaron Carter
          isHf: false
          isPro: true
          name: Arkaen-AtC
          type: user
        html: "<p>An API access token is typically issued to a consumer/user of the\
          \ endpoint to allow them to authenticate on-the-fly and gain access to the\
          \ resources or data it furnishes. And they can be issued at any level you\
          \ wish: one token per user or a single global token for a web service/app,\
          \ that's up to you ... and when you call an endpoint with an access token,\
          \ it's NOT checking with other all the other endpoints in existence and\
          \ comparing your tokens to see if they match, it simply cares if the token\
          \ is valid or not: If it's valid, the API works and respond ... if it's\
          \ not, you get an error code. Pretty simple. </p>\n<p>No magic or voodoo\
          \ going on to try to prevent you reusing tokens. But it's \"good practice\"\
          \ to limit what things can read/access tokens/secrets and try to split up\
          \ your own apps/scripts into sensible groups (that make sense in your project\
          \ or org/team) which have their own token(s) ... that way, you can enable/disable\
          \ certain things on their own, independently, and swap out or refresh keys\
          \ ... for example, say you had a web app that does NLP/text operations,\
          \ one that generates/refines images and one that does text-to-speech ...\
          \ it'd be wise to at least give each app its own token, so if you need perform\
          \ maintenance or deal with security or any other issues, each part of your\
          \ little ecosystem and APIs can be independently managed ...</p>\n<p>I'd\
          \ really like to know where are all the parameters listed for each type\
          \ of endpoint. I set up an experimental SD XL image generation endpoint,\
          \ and its results look really awful ... seems like it has way too low of\
          \ guidance scale or steps/iterations (i.e., never really finishes \"diffusing\"\
          \ the image) or maybe it's not using the \"refiner\" model properly ...\
          \ either way, it looks super \U0001F4A9 ... and I cannot, for the life of\
          \ me, seem to find any straightforward list or documentation on the options/parameters\
          \ for such endpoints and how I can controll sd-xl and how it behaves ...\
          \ </p>\n"
        raw: "An API access token is typically issued to a consumer/user of the endpoint\
          \ to allow them to authenticate on-the-fly and gain access to the resources\
          \ or data it furnishes. And they can be issued at any level you wish: one\
          \ token per user or a single global token for a web service/app, that's\
          \ up to you ... and when you call an endpoint with an access token, it's\
          \ NOT checking with other all the other endpoints in existence and comparing\
          \ your tokens to see if they match, it simply cares if the token is valid\
          \ or not: If it's valid, the API works and respond ... if it's not, you\
          \ get an error code. Pretty simple. \n\nNo magic or voodoo going on to try\
          \ to prevent you reusing tokens. But it's \"good practice\" to limit what\
          \ things can read/access tokens/secrets and try to split up your own apps/scripts\
          \ into sensible groups (that make sense in your project or org/team) which\
          \ have their own token(s) ... that way, you can enable/disable certain things\
          \ on their own, independently, and swap out or refresh keys ... for example,\
          \ say you had a web app that does NLP/text operations, one that generates/refines\
          \ images and one that does text-to-speech ... it'd be wise to at least give\
          \ each app its own token, so if you need perform maintenance or deal with\
          \ security or any other issues, each part of your little ecosystem and APIs\
          \ can be independently managed ...\n\nI'd really like to know where are\
          \ all the parameters listed for each type of endpoint. I set up an experimental\
          \ SD XL image generation endpoint, and its results look really awful ...\
          \ seems like it has way too low of guidance scale or steps/iterations (i.e.,\
          \ never really finishes \"diffusing\" the image) or maybe it's not using\
          \ the \"refiner\" model properly ... either way, it looks super \U0001F4A9\
          \ ... and I cannot, for the life of me, seem to find any straightforward\
          \ list or documentation on the options/parameters for such endpoints and\
          \ how I can controll sd-xl and how it behaves ... "
        updatedAt: '2023-12-15T17:02:48.248Z'
      numEdits: 1
      reactions: []
    id: 657c85af9eef0925e0843173
    type: comment
  author: Arkaen-AtC
  content: "An API access token is typically issued to a consumer/user of the endpoint\
    \ to allow them to authenticate on-the-fly and gain access to the resources or\
    \ data it furnishes. And they can be issued at any level you wish: one token per\
    \ user or a single global token for a web service/app, that's up to you ... and\
    \ when you call an endpoint with an access token, it's NOT checking with other\
    \ all the other endpoints in existence and comparing your tokens to see if they\
    \ match, it simply cares if the token is valid or not: If it's valid, the API\
    \ works and respond ... if it's not, you get an error code. Pretty simple. \n\n\
    No magic or voodoo going on to try to prevent you reusing tokens. But it's \"\
    good practice\" to limit what things can read/access tokens/secrets and try to\
    \ split up your own apps/scripts into sensible groups (that make sense in your\
    \ project or org/team) which have their own token(s) ... that way, you can enable/disable\
    \ certain things on their own, independently, and swap out or refresh keys ...\
    \ for example, say you had a web app that does NLP/text operations, one that generates/refines\
    \ images and one that does text-to-speech ... it'd be wise to at least give each\
    \ app its own token, so if you need perform maintenance or deal with security\
    \ or any other issues, each part of your little ecosystem and APIs can be independently\
    \ managed ...\n\nI'd really like to know where are all the parameters listed for\
    \ each type of endpoint. I set up an experimental SD XL image generation endpoint,\
    \ and its results look really awful ... seems like it has way too low of guidance\
    \ scale or steps/iterations (i.e., never really finishes \"diffusing\" the image)\
    \ or maybe it's not using the \"refiner\" model properly ... either way, it looks\
    \ super \U0001F4A9 ... and I cannot, for the life of me, seem to find any straightforward\
    \ list or documentation on the options/parameters for such endpoints and how I\
    \ can controll sd-xl and how it behaves ... "
  created_at: 2023-12-15 16:58:23+00:00
  edited: true
  hidden: false
  id: 657c85af9eef0925e0843173
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 100
repo_id: stabilityai/stable-diffusion-xl-base-1.0
repo_type: model
status: open
target_branch: null
title: Inference endpoint/inference Api
