!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jiagaoxiang
conflicting_files: null
created_at: 2023-11-28 00:44:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0fc48ae6de8dbadd18cc668240512461.svg
      fullname: Gaoxiang Jia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jiagaoxiang
      type: user
    createdAt: '2023-11-28T00:44:14.000Z'
    data:
      edited: false
      editors:
      - jiagaoxiang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7388631105422974
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0fc48ae6de8dbadd18cc668240512461.svg
          fullname: Gaoxiang Jia
          isHf: false
          isPro: false
          name: jiagaoxiang
          type: user
        html: '<p>I am confused by the format of the stabilityai/stable-diffusion-xl-base-1.0
          model. Is it a pytorch model or is it an onnx model?</p>

          <p>I tested ORTStableDiffusionXLPipeline.from_pretrained(model_id, export=True,
          provider="ROCMExecutionProvider",) vs ORTStableDiffusionXLPipeline.from_pretrained(model_id,
          export=False, provider="ROCMExecutionProvider",), it seems there is no difference
          for setting export to True vs False. Based on my understanding, if the model
          is already in onnx format, then this export argument will play no role here;
          but if it is in pytorch format, it should give me error message if I set
          export to False. Can anyone share any thoughts on this? </p>

          <p>Thank you!</p>

          '
        raw: "I am confused by the format of the stabilityai/stable-diffusion-xl-base-1.0\
          \ model. Is it a pytorch model or is it an onnx model?\r\n\r\nI tested ORTStableDiffusionXLPipeline.from_pretrained(model_id,\
          \ export=True, provider=\"ROCMExecutionProvider\",) vs ORTStableDiffusionXLPipeline.from_pretrained(model_id,\
          \ export=False, provider=\"ROCMExecutionProvider\",), it seems there is\
          \ no difference for setting export to True vs False. Based on my understanding,\
          \ if the model is already in onnx format, then this export argument will\
          \ play no role here; but if it is in pytorch format, it should give me error\
          \ message if I set export to False. Can anyone share any thoughts on this?\
          \ \r\n\r\nThank you!"
        updatedAt: '2023-11-28T00:44:14.667Z'
      numEdits: 0
      reactions: []
    id: 656537de131d13ccc5c36b50
    type: comment
  author: jiagaoxiang
  content: "I am confused by the format of the stabilityai/stable-diffusion-xl-base-1.0\
    \ model. Is it a pytorch model or is it an onnx model?\r\n\r\nI tested ORTStableDiffusionXLPipeline.from_pretrained(model_id,\
    \ export=True, provider=\"ROCMExecutionProvider\",) vs ORTStableDiffusionXLPipeline.from_pretrained(model_id,\
    \ export=False, provider=\"ROCMExecutionProvider\",), it seems there is no difference\
    \ for setting export to True vs False. Based on my understanding, if the model\
    \ is already in onnx format, then this export argument will play no role here;\
    \ but if it is in pytorch format, it should give me error message if I set export\
    \ to False. Can anyone share any thoughts on this? \r\n\r\nThank you!"
  created_at: 2023-11-28 00:44:14+00:00
  edited: false
  hidden: false
  id: 656537de131d13ccc5c36b50
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 125
repo_id: stabilityai/stable-diffusion-xl-base-1.0
repo_type: model
status: open
target_branch: null
title: what is the format of stabilityai/stable-diffusion-xl-base-1.0 model?
