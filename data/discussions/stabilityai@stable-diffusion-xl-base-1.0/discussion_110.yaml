!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Cyphex9
conflicting_files: null
created_at: 2023-10-26 05:58:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/39546438aedad3d0155acf7479fd15d7.svg
      fullname: Nunya Dangbeezwax
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Cyphex9
      type: user
    createdAt: '2023-10-26T06:58:16.000Z'
    data:
      edited: false
      editors:
      - Cyphex9
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9329425096511841
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/39546438aedad3d0155acf7479fd15d7.svg
          fullname: Nunya Dangbeezwax
          isHf: false
          isPro: false
          name: Cyphex9
          type: user
        html: '<p>After a fresh install (both A1111 and SDXL), model merging the SDXL
          base model tries to make a 600gigabyte file!?!?</p>

          <p>As the title suggests, I have a fresh install of everything...Git, Python,
          A1111, cuda, torch, pip, and SDXL, so all are up to date and clean as of
          10/25/2023. When I try to merge any SDXL model with any other model, the
          merge crashes immediately giving me this error code:</p>

          <p>"Error merging checkpoints: [enforce fail at ..\c10\core\impl\alloc_cpu.cpp:72]
          data. DefaultCPUAllocator: not enough memory: you tried to allocate 671088640000
          bytes."</p>

          <p>Why would it try to make SUCH a huge file?</p>

          <p>I have an RTX 4070 gpu (12g), i7-13700k cpu, 32g ram (gskill, 6000MT/s,
          XMP on), samsung 980 pro SSD, so it feels unlikely (although not impossible)
          that my system isn''t capable. I did see someone mention the 980 might have
          a caching issue that can be resolved through command arg stuff (which I
          attempted as well, but without much knowledge on it). I also have very few
          extensions, and do not have dreambooth installed.</p>

          <p>I currently run --autolaunch --no-half-vae --xformers --opt-channelslast
          in command args. I tried --medvram, and --lowvram in command args just to
          see...no change. I also tried changing ram to system controlled...no change.</p>

          <p>Does anyone know what might cause this? That is a HUGE file it''s trying
          to make.</p>

          <p>Happy to offer any additional information that may be needed to diagnose.</p>

          <p>Thanks to anyone willing to chime in on this!</p>

          '
        raw: "After a fresh install (both A1111 and SDXL), model merging the SDXL\
          \ base model tries to make a 600gigabyte file!?!?\r\n\r\nAs the title suggests,\
          \ I have a fresh install of everything...Git, Python, A1111, cuda, torch,\
          \ pip, and SDXL, so all are up to date and clean as of 10/25/2023. When\
          \ I try to merge any SDXL model with any other model, the merge crashes\
          \ immediately giving me this error code:\r\n\r\n\"Error merging checkpoints:\
          \ [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator:\
          \ not enough memory: you tried to allocate 671088640000 bytes.\"\r\n\r\n\
          Why would it try to make SUCH a huge file?\r\n\r\nI have an RTX 4070 gpu\
          \ (12g), i7-13700k cpu, 32g ram (gskill, 6000MT/s, XMP on), samsung 980\
          \ pro SSD, so it feels unlikely (although not impossible) that my system\
          \ isn't capable. I did see someone mention the 980 might have a caching\
          \ issue that can be resolved through command arg stuff (which I attempted\
          \ as well, but without much knowledge on it). I also have very few extensions,\
          \ and do not have dreambooth installed.\r\n\r\nI currently run --autolaunch\
          \ --no-half-vae --xformers --opt-channelslast in command args. I tried --medvram,\
          \ and --lowvram in command args just to see...no change. I also tried changing\
          \ ram to system controlled...no change.\r\n\r\nDoes anyone know what might\
          \ cause this? That is a HUGE file it's trying to make.\r\n\r\nHappy to offer\
          \ any additional information that may be needed to diagnose.\r\n\r\nThanks\
          \ to anyone willing to chime in on this!"
        updatedAt: '2023-10-26T06:58:16.111Z'
      numEdits: 0
      reactions: []
    id: 653a0e0857a5ee1d3069ef5c
    type: comment
  author: Cyphex9
  content: "After a fresh install (both A1111 and SDXL), model merging the SDXL base\
    \ model tries to make a 600gigabyte file!?!?\r\n\r\nAs the title suggests, I have\
    \ a fresh install of everything...Git, Python, A1111, cuda, torch, pip, and SDXL,\
    \ so all are up to date and clean as of 10/25/2023. When I try to merge any SDXL\
    \ model with any other model, the merge crashes immediately giving me this error\
    \ code:\r\n\r\n\"Error merging checkpoints: [enforce fail at ..\\c10\\core\\impl\\\
    alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate\
    \ 671088640000 bytes.\"\r\n\r\nWhy would it try to make SUCH a huge file?\r\n\r\
    \nI have an RTX 4070 gpu (12g), i7-13700k cpu, 32g ram (gskill, 6000MT/s, XMP\
    \ on), samsung 980 pro SSD, so it feels unlikely (although not impossible) that\
    \ my system isn't capable. I did see someone mention the 980 might have a caching\
    \ issue that can be resolved through command arg stuff (which I attempted as well,\
    \ but without much knowledge on it). I also have very few extensions, and do not\
    \ have dreambooth installed.\r\n\r\nI currently run --autolaunch --no-half-vae\
    \ --xformers --opt-channelslast in command args. I tried --medvram, and --lowvram\
    \ in command args just to see...no change. I also tried changing ram to system\
    \ controlled...no change.\r\n\r\nDoes anyone know what might cause this? That\
    \ is a HUGE file it's trying to make.\r\n\r\nHappy to offer any additional information\
    \ that may be needed to diagnose.\r\n\r\nThanks to anyone willing to chime in\
    \ on this!"
  created_at: 2023-10-26 05:58:16+00:00
  edited: false
  hidden: false
  id: 653a0e0857a5ee1d3069ef5c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/39546438aedad3d0155acf7479fd15d7.svg
      fullname: Nunya Dangbeezwax
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Cyphex9
      type: user
    createdAt: '2023-10-27T00:03:20.000Z'
    data:
      edited: true
      editors:
      - Cyphex9
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9912195205688477
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/39546438aedad3d0155acf7479fd15d7.svg
          fullname: Nunya Dangbeezwax
          isHf: false
          isPro: false
          name: Cyphex9
          type: user
        html: '<p>(SOLVED?)</p>

          <p>I should have figured, but I was told SDXL models run on an entirely
          different architecture than 1.5, 1.6, 2.0, or 2.1, so model merging between
          the two isn''t even something that is possible to do.</p>

          '
        raw: '(SOLVED?)


          I should have figured, but I was told SDXL models run on an entirely different
          architecture than 1.5, 1.6, 2.0, or 2.1, so model merging between the two
          isn''t even something that is possible to do.'
        updatedAt: '2023-10-27T00:04:42.236Z'
      numEdits: 1
      reactions: []
    id: 653afe48b375aaf32c7bae14
    type: comment
  author: Cyphex9
  content: '(SOLVED?)


    I should have figured, but I was told SDXL models run on an entirely different
    architecture than 1.5, 1.6, 2.0, or 2.1, so model merging between the two isn''t
    even something that is possible to do.'
  created_at: 2023-10-26 23:03:20+00:00
  edited: true
  hidden: false
  id: 653afe48b375aaf32c7bae14
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/39546438aedad3d0155acf7479fd15d7.svg
      fullname: Nunya Dangbeezwax
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Cyphex9
      type: user
    createdAt: '2023-10-27T00:04:14.000Z'
    data:
      from: Error when merging SDXL model of any type, including the base model.  Tries
        to make a HUGE file.
      to: Error when merging SDXL model of any type, including the base model.  Tries
        to make a HUGE file. (SOLVED)
    id: 653afe7ee935ed5881136d15
    type: title-change
  author: Cyphex9
  created_at: 2023-10-26 23:04:14+00:00
  id: 653afe7ee935ed5881136d15
  new_title: Error when merging SDXL model of any type, including the base model.  Tries
    to make a HUGE file. (SOLVED)
  old_title: Error when merging SDXL model of any type, including the base model.  Tries
    to make a HUGE file.
  type: title-change
is_pull_request: false
merge_commit_oid: null
num: 110
repo_id: stabilityai/stable-diffusion-xl-base-1.0
repo_type: model
status: open
target_branch: null
title: Error when merging SDXL model of any type, including the base model.  Tries
  to make a HUGE file. (SOLVED)
