!!python/object:huggingface_hub.community.DiscussionWithDetails
author: StevenKim
conflicting_files: null
created_at: 2023-08-14 12:25:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9cf6fb8869bb9e64300e088b3284e5e5.svg
      fullname: Leyang Jin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: StevenKim
      type: user
    createdAt: '2023-08-14T13:25:45.000Z'
    data:
      edited: false
      editors:
      - StevenKim
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9117007255554199
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9cf6fb8869bb9e64300e088b3284e5e5.svg
          fullname: Leyang Jin
          isHf: false
          isPro: false
          name: StevenKim
          type: user
        html: '<p>Hi, when I input a quite long prompt I got a message: "the following
          part of your input was truncated because CLIP can only handle sequences
          up to 77 tokens......". How can I pass the full prompt longer than 77 tokens
          into the diffusionXL pipeline? Thank you for your help!</p>

          '
        raw: 'Hi, when I input a quite long prompt I got a message: "the following
          part of your input was truncated because CLIP can only handle sequences
          up to 77 tokens......". How can I pass the full prompt longer than 77 tokens
          into the diffusionXL pipeline? Thank you for your help!'
        updatedAt: '2023-08-14T13:25:45.433Z'
      numEdits: 0
      reactions: []
    id: 64da2b597f749b6e342e509a
    type: comment
  author: StevenKim
  content: 'Hi, when I input a quite long prompt I got a message: "the following part
    of your input was truncated because CLIP can only handle sequences up to 77 tokens......".
    How can I pass the full prompt longer than 77 tokens into the diffusionXL pipeline?
    Thank you for your help!'
  created_at: 2023-08-14 12:25:45+00:00
  edited: false
  hidden: false
  id: 64da2b597f749b6e342e509a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d3d4e30ce260acbf60b2b11c01d7743c.svg
      fullname: fire
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wirewind
      type: user
    createdAt: '2023-08-15T07:48:50.000Z'
    data:
      edited: true
      editors:
      - wirewind
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8805197477340698
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d3d4e30ce260acbf60b2b11c01d7743c.svg
          fullname: fire
          isHf: false
          isPro: false
          name: wirewind
          type: user
        html: "<blockquote>\n<p>Hi, when I input a quite long prompt I got a message:\
          \ \"the following part of your input was truncated because CLIP can only\
          \ handle sequences up to 77 tokens......\". How can I pass the full prompt\
          \ longer than 77 tokens into the diffusionXL pipeline? Thank you for your\
          \ help!</p>\n</blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;StevenKim&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/StevenKim\"\
          >@<span class=\"underline\">StevenKim</span></a></span>\n\n\t</span></span>\
          \ Maybe you can use the lib--compel, the link is <a rel=\"nofollow\" href=\"\
          https://github.com/damian0815/compel/blob/main/README.md\">https://github.com/damian0815/compel/blob/main/README.md</a>,\
          \ which is suport SDXL, and support for prompts longer than the model's\
          \ max token length</p>\n"
        raw: '> Hi, when I input a quite long prompt I got a message: "the following
          part of your input was truncated because CLIP can only handle sequences
          up to 77 tokens......". How can I pass the full prompt longer than 77 tokens
          into the diffusionXL pipeline? Thank you for your help!


          @StevenKim Maybe you can use the lib--compel, the link is https://github.com/damian0815/compel/blob/main/README.md,
          which is suport SDXL, and support for prompts longer than the model''s max
          token length'
        updatedAt: '2023-08-15T07:50:54.514Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - 33min
    id: 64db2de2176ca2c9a2bf74a7
    type: comment
  author: wirewind
  content: '> Hi, when I input a quite long prompt I got a message: "the following
    part of your input was truncated because CLIP can only handle sequences up to
    77 tokens......". How can I pass the full prompt longer than 77 tokens into the
    diffusionXL pipeline? Thank you for your help!


    @StevenKim Maybe you can use the lib--compel, the link is https://github.com/damian0815/compel/blob/main/README.md,
    which is suport SDXL, and support for prompts longer than the model''s max token
    length'
  created_at: 2023-08-15 06:48:50+00:00
  edited: true
  hidden: false
  id: 64db2de2176ca2c9a2bf74a7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 60
repo_id: stabilityai/stable-diffusion-xl-base-1.0
repo_type: model
status: open
target_branch: null
title: How can I input a prompt that is longer than 77 tokens?
