!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SeemaChhatani03
conflicting_files: null
created_at: 2023-04-14 04:46:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e4ecbfe4f44021ec0a06151dfa856ee8.svg
      fullname: Chhatani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SeemaChhatani03
      type: user
    createdAt: '2023-04-14T05:46:24.000Z'
    data:
      edited: false
      editors:
      - SeemaChhatani03
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e4ecbfe4f44021ec0a06151dfa856ee8.svg
          fullname: Chhatani
          isHf: false
          isPro: false
          name: SeemaChhatani03
          type: user
        html: '<p>Hello I am trying to use this model for research paper summarization.<br>My
          dataset has Article as the input, research paper abstract as the ground
          truth.<br>Do I need to add the tokens  and  in the article and  in the ground
          truth which is research paper abstract.?</p>

          <p>Or I can feed the data itself and model tokenizer will take care of the
          required tokens.?</p>

          '
        raw: "Hello I am trying to use this model for research paper summarization.\r\
          \nMy dataset has Article as the input, research paper abstract as the ground\
          \ truth.\r\nDo I need to add the tokens <EV> and <t> in the article and\
          \ <abs> in the ground truth which is research paper abstract.?\r\n\r\nOr\
          \ I can feed the data itself and model tokenizer will take care of the required\
          \ tokens.?"
        updatedAt: '2023-04-14T05:46:24.817Z'
      numEdits: 0
      reactions: []
    id: 6438e8b0b2ea24b52ebc6318
    type: comment
  author: SeemaChhatani03
  content: "Hello I am trying to use this model for research paper summarization.\r\
    \nMy dataset has Article as the input, research paper abstract as the ground truth.\r\
    \nDo I need to add the tokens <EV> and <t> in the article and <abs> in the ground\
    \ truth which is research paper abstract.?\r\n\r\nOr I can feed the data itself\
    \ and model tokenizer will take care of the required tokens.?"
  created_at: 2023-04-14 04:46:24+00:00
  edited: false
  hidden: false
  id: 6438e8b0b2ea24b52ebc6318
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e5f8a329d76433dbde50b8710eb2c877.svg
      fullname: Hye Sun Yun
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: hyesunyun
      type: user
    createdAt: '2023-04-14T14:44:21.000Z'
    data:
      edited: false
      editors:
      - hyesunyun
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e5f8a329d76433dbde50b8710eb2c877.svg
          fullname: Hye Sun Yun
          isHf: false
          isPro: false
          name: hyesunyun
          type: user
        html: '<p>Hello!</p>

          <p>You will have to format the input a bit with some tokens.</p>

          <p>Format your data so that each new article or evidence to add have  token
          in front with each title prefixed by  and each abstract prefixed by . Please
          have the original summary also in the same format. You can have the list
          of articles and original summary concatenated in any order as long as they
          have the correct separator tokens.</p>

          <p>What it would look like: <code>&lt;EV&gt; &lt;t&gt; title_of_article_1
          &lt;abs&gt; abstract_of_article_1 &lt;EV&gt; &lt;t&gt; title_of_article_2
          &lt;abs&gt; abstract_of_article_2 ...</code></p>

          '
        raw: 'Hello!


          You will have to format the input a bit with some tokens.


          Format your data so that each new article or evidence to add have <EV> token
          in front with each title prefixed by <t> and each abstract prefixed by <abs>.
          Please have the original summary also in the same format. You can have the
          list of articles and original summary concatenated in any order as long
          as they have the correct separator tokens.


          What it would look like: `<EV> <t> title_of_article_1 <abs> abstract_of_article_1
          <EV> <t> title_of_article_2 <abs> abstract_of_article_2 ...`'
        updatedAt: '2023-04-14T14:44:21.580Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - SeemaChhatani03
    id: 643966c50cb95b3dbc8f033a
    type: comment
  author: hyesunyun
  content: 'Hello!


    You will have to format the input a bit with some tokens.


    Format your data so that each new article or evidence to add have <EV> token in
    front with each title prefixed by <t> and each abstract prefixed by <abs>. Please
    have the original summary also in the same format. You can have the list of articles
    and original summary concatenated in any order as long as they have the correct
    separator tokens.


    What it would look like: `<EV> <t> title_of_article_1 <abs> abstract_of_article_1
    <EV> <t> title_of_article_2 <abs> abstract_of_article_2 ...`'
  created_at: 2023-04-14 13:44:21+00:00
  edited: false
  hidden: false
  id: 643966c50cb95b3dbc8f033a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e4ecbfe4f44021ec0a06151dfa856ee8.svg
      fullname: Chhatani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SeemaChhatani03
      type: user
    createdAt: '2023-04-14T15:07:56.000Z'
    data:
      edited: false
      editors:
      - SeemaChhatani03
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e4ecbfe4f44021ec0a06151dfa856ee8.svg
          fullname: Chhatani
          isHf: false
          isPro: false
          name: SeemaChhatani03
          type: user
        html: '<p>Hi.. Thanks for reverting back.<br>I am using Pubmed summarization
          dataset added on huggingface: <a href="https://huggingface.co/datasets/scientific_papers/viewer/pubmed/train">https://huggingface.co/datasets/scientific_papers/viewer/pubmed/train</a><br>It
          has three fields article, abstract and section_names. The title of the article
          is not included in article and its not added as a separate field as well.<br>So
          for this dataset I just need to add  token in article and  token in abstract
          field correct .?</p>

          <p>Also I am not sure how to add these tokens to this entire chunk of dataset.
          Any suggestions on that.?</p>

          <p>Thank you in advance.</p>

          '
        raw: 'Hi.. Thanks for reverting back.

          I am using Pubmed summarization dataset added on huggingface: https://huggingface.co/datasets/scientific_papers/viewer/pubmed/train

          It has three fields article, abstract and section_names. The title of the
          article is not included in article and its not added as a separate field
          as well.

          So for this dataset I just need to add <EV> token in article and <abs> token
          in abstract field correct .?


          Also I am not sure how to add these tokens to this entire chunk of dataset.
          Any suggestions on that.?


          Thank you in advance.'
        updatedAt: '2023-04-14T15:07:56.876Z'
      numEdits: 0
      reactions: []
    id: 64396c4cde56ab98fabd43fa
    type: comment
  author: SeemaChhatani03
  content: 'Hi.. Thanks for reverting back.

    I am using Pubmed summarization dataset added on huggingface: https://huggingface.co/datasets/scientific_papers/viewer/pubmed/train

    It has three fields article, abstract and section_names. The title of the article
    is not included in article and its not added as a separate field as well.

    So for this dataset I just need to add <EV> token in article and <abs> token in
    abstract field correct .?


    Also I am not sure how to add these tokens to this entire chunk of dataset. Any
    suggestions on that.?


    Thank you in advance.'
  created_at: 2023-04-14 14:07:56+00:00
  edited: false
  hidden: false
  id: 64396c4cde56ab98fabd43fa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e5f8a329d76433dbde50b8710eb2c877.svg
      fullname: Hye Sun Yun
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: hyesunyun
      type: user
    createdAt: '2023-04-14T15:50:35.000Z'
    data:
      edited: false
      editors:
      - hyesunyun
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e5f8a329d76433dbde50b8710eb2c877.svg
          fullname: Hye Sun Yun
          isHf: false
          isPro: false
          name: hyesunyun
          type: user
        html: '<p>oh I see. Yes, you can just not add <code>&lt;t&gt; title</code>
          part. You can just do something like <code>&lt;EV&gt; &lt;abs&gt; abstract
          text</code> but not really sure what the performance would look like when
          title is not given. </p>

          <p>This model is specifically trained to generate a synthesis summary based
          on an existing summary and new articles. This is a specific form of multi
          document summarization.</p>

          <p>What exactly are you trying to achieve? Could you provide some example
          input and expected output for your task?</p>

          '
        raw: "oh I see. Yes, you can just not add `<t> title` part. You can just do\
          \ something like `<EV> <abs> abstract text` but not really sure what the\
          \ performance would look like when title is not given. \n\nThis model is\
          \ specifically trained to generate a synthesis summary based on an existing\
          \ summary and new articles. This is a specific form of multi document summarization.\n\
          \nWhat exactly are you trying to achieve? Could you provide some example\
          \ input and expected output for your task?"
        updatedAt: '2023-04-14T15:50:35.133Z'
      numEdits: 0
      reactions: []
    id: 6439764bcc228b8099b2da8a
    type: comment
  author: hyesunyun
  content: "oh I see. Yes, you can just not add `<t> title` part. You can just do\
    \ something like `<EV> <abs> abstract text` but not really sure what the performance\
    \ would look like when title is not given. \n\nThis model is specifically trained\
    \ to generate a synthesis summary based on an existing summary and new articles.\
    \ This is a specific form of multi document summarization.\n\nWhat exactly are\
    \ you trying to achieve? Could you provide some example input and expected output\
    \ for your task?"
  created_at: 2023-04-14 14:50:35+00:00
  edited: false
  hidden: false
  id: 6439764bcc228b8099b2da8a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e4ecbfe4f44021ec0a06151dfa856ee8.svg
      fullname: Chhatani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SeemaChhatani03
      type: user
    createdAt: '2023-04-14T21:47:58.000Z'
    data:
      edited: false
      editors:
      - SeemaChhatani03
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e4ecbfe4f44021ec0a06151dfa856ee8.svg
          fullname: Chhatani
          isHf: false
          isPro: false
          name: SeemaChhatani03
          type: user
        html: '<p>Actually I want to perform text summarization on research papers
          dataset provided on huggingface <a href="https://huggingface.co/datasets/scientific_papers/viewer/pubmed/train">https://huggingface.co/datasets/scientific_papers/viewer/pubmed/train</a>
          .<br>My aim is to achieve better rouge score ir some comparable rouge score
          by fine tuning the summarization models on my dataset.</p>

          '
        raw: "Actually I want to perform text summarization on research papers dataset\
          \ provided on huggingface https://huggingface.co/datasets/scientific_papers/viewer/pubmed/train\
          \ . \nMy aim is to achieve better rouge score ir some comparable rouge score\
          \ by fine tuning the summarization models on my dataset."
        updatedAt: '2023-04-14T21:47:58.799Z'
      numEdits: 0
      reactions: []
    id: 6439ca0e68228e8b3345b94f
    type: comment
  author: SeemaChhatani03
  content: "Actually I want to perform text summarization on research papers dataset\
    \ provided on huggingface https://huggingface.co/datasets/scientific_papers/viewer/pubmed/train\
    \ . \nMy aim is to achieve better rouge score ir some comparable rouge score by\
    \ fine tuning the summarization models on my dataset."
  created_at: 2023-04-14 20:47:58+00:00
  edited: false
  hidden: false
  id: 6439ca0e68228e8b3345b94f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e5f8a329d76433dbde50b8710eb2c877.svg
      fullname: Hye Sun Yun
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: hyesunyun
      type: user
    createdAt: '2023-04-14T22:01:09.000Z'
    data:
      edited: false
      editors:
      - hyesunyun
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e5f8a329d76433dbde50b8710eb2c877.svg
          fullname: Hye Sun Yun
          isHf: false
          isPro: false
          name: hyesunyun
          type: user
        html: '<p>I would suggest using a different summarization model for this.
          The type of summarization this particular model is trained to do is a different
          kind of summarization from regular multi-doc summarization. Perhaps just
          LED (<a href="https://huggingface.co/docs/transformers/model_doc/led">https://huggingface.co/docs/transformers/model_doc/led</a>)
          which this model is based on or maybe even T5 can be good candidate models
          for the pubmed text summarization fine tuning that you want to do.</p>

          '
        raw: I would suggest using a different summarization model for this. The type
          of summarization this particular model is trained to do is a different kind
          of summarization from regular multi-doc summarization. Perhaps just LED
          (https://huggingface.co/docs/transformers/model_doc/led) which this model
          is based on or maybe even T5 can be good candidate models for the pubmed
          text summarization fine tuning that you want to do.
        updatedAt: '2023-04-14T22:01:09.807Z'
      numEdits: 0
      reactions: []
    id: 6439cd25cc228b8099b5306e
    type: comment
  author: hyesunyun
  content: I would suggest using a different summarization model for this. The type
    of summarization this particular model is trained to do is a different kind of
    summarization from regular multi-doc summarization. Perhaps just LED (https://huggingface.co/docs/transformers/model_doc/led)
    which this model is based on or maybe even T5 can be good candidate models for
    the pubmed text summarization fine tuning that you want to do.
  created_at: 2023-04-14 21:01:09+00:00
  edited: false
  hidden: false
  id: 6439cd25cc228b8099b5306e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e4ecbfe4f44021ec0a06151dfa856ee8.svg
      fullname: Chhatani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SeemaChhatani03
      type: user
    createdAt: '2023-04-15T08:34:15.000Z'
    data:
      edited: false
      editors:
      - SeemaChhatani03
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e4ecbfe4f44021ec0a06151dfa856ee8.svg
          fullname: Chhatani
          isHf: false
          isPro: false
          name: SeemaChhatani03
          type: user
        html: '<p>Thanks alot for your feedback.</p>

          '
        raw: Thanks alot for your feedback.
        updatedAt: '2023-04-15T08:34:15.315Z'
      numEdits: 0
      reactions: []
    id: 643a618745200ac3e702da8d
    type: comment
  author: SeemaChhatani03
  content: Thanks alot for your feedback.
  created_at: 2023-04-15 07:34:15+00:00
  edited: false
  hidden: false
  id: 643a618745200ac3e702da8d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: hyesunyun/update-summarization-bart-large-longformer
repo_type: model
status: open
target_branch: null
title: Format of the Input article
