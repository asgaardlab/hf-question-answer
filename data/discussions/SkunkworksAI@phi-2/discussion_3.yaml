!!python/object:huggingface_hub.community.DiscussionWithDetails
author: alexweberk
conflicting_files: null
created_at: 2023-12-13 16:52:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/631fef7ec6b20f03c828d0c7/FfLzmXTzohC1mNuyz_5Xu.jpeg?w=200&h=200&f=face
      fullname: Alex Ishida
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexweberk
      type: user
    createdAt: '2023-12-13T16:52:17.000Z'
    data:
      edited: false
      editors:
      - alexweberk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9464605450630188
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/631fef7ec6b20f03c828d0c7/FfLzmXTzohC1mNuyz_5Xu.jpeg?w=200&h=200&f=face
          fullname: Alex Ishida
          isHf: false
          isPro: false
          name: alexweberk
          type: user
        html: '<p>Hi, how exactly do you run this?</p>

          '
        raw: Hi, how exactly do you run this?
        updatedAt: '2023-12-13T16:52:17.172Z'
      numEdits: 0
      reactions: []
    id: 6579e14100f685a3be073435
    type: comment
  author: alexweberk
  content: Hi, how exactly do you run this?
  created_at: 2023-12-13 16:52:17+00:00
  edited: false
  hidden: false
  id: 6579e14100f685a3be073435
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ddc6a5256ca8be1ac44f6d13f7e26dc8.svg
      fullname: Danso
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Banso
      type: user
    createdAt: '2023-12-13T17:09:54.000Z'
    data:
      edited: false
      editors:
      - Banso
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.31370165944099426
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ddc6a5256ca8be1ac44f6d13f7e26dc8.svg
          fullname: Danso
          isHf: false
          isPro: false
          name: Banso
          type: user
        html: '<p>Like this:</p>

          <pre><code>import torch

          from transformers import AutoModelForCausalLM, AutoTokenizer


          model = AutoModelForCausalLM.from_pretrained("SkunkworksAI/phi-2", trust_remote_code=True,
          torch_dtype=torch.float16)

          tokenizer = AutoTokenizer.from_pretrained("SkunkworksAI/phi-2", trust_remote_code=True)

          </code></pre>

          '
        raw: 'Like this:


          ```

          import torch

          from transformers import AutoModelForCausalLM, AutoTokenizer


          model = AutoModelForCausalLM.from_pretrained("SkunkworksAI/phi-2", trust_remote_code=True,
          torch_dtype=torch.float16)

          tokenizer = AutoTokenizer.from_pretrained("SkunkworksAI/phi-2", trust_remote_code=True)

          ```'
        updatedAt: '2023-12-13T17:09:54.963Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - alexweberk
    id: 6579e56200f685a3be07e220
    type: comment
  author: Banso
  content: 'Like this:


    ```

    import torch

    from transformers import AutoModelForCausalLM, AutoTokenizer


    model = AutoModelForCausalLM.from_pretrained("SkunkworksAI/phi-2", trust_remote_code=True,
    torch_dtype=torch.float16)

    tokenizer = AutoTokenizer.from_pretrained("SkunkworksAI/phi-2", trust_remote_code=True)

    ```'
  created_at: 2023-12-13 17:09:54+00:00
  edited: false
  hidden: false
  id: 6579e56200f685a3be07e220
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/65776db462d3ac1817c6d556/44JDdCMeLeujy0sXEqQ-k.jpeg?w=200&h=200&f=face
      fullname: Carlos E. Torres
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cetorres-o
      type: user
    createdAt: '2023-12-13T17:35:15.000Z'
    data:
      edited: false
      editors:
      - cetorres-o
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9574592709541321
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/65776db462d3ac1817c6d556/44JDdCMeLeujy0sXEqQ-k.jpeg?w=200&h=200&f=face
          fullname: Carlos E. Torres
          isHf: false
          isPro: false
          name: cetorres-o
          type: user
        html: '<p>Hi, how to run the model locally?</p>

          '
        raw: Hi, how to run the model locally?
        updatedAt: '2023-12-13T17:35:15.875Z'
      numEdits: 0
      reactions: []
    id: 6579eb53bd9ea8b29c4ada50
    type: comment
  author: cetorres-o
  content: Hi, how to run the model locally?
  created_at: 2023-12-13 17:35:15+00:00
  edited: false
  hidden: false
  id: 6579eb53bd9ea8b29c4ada50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fdfaeb01aedd0e86014de9/UliF1du7InfuCs7RHLiA5.png?w=200&h=200&f=face
      fullname: Ahmed Morsi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eramax
      type: user
    createdAt: '2023-12-13T18:00:35.000Z'
    data:
      edited: false
      editors:
      - eramax
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.769217312335968
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fdfaeb01aedd0e86014de9/UliF1du7InfuCs7RHLiA5.png?w=200&h=200&f=face
          fullname: Ahmed Morsi
          isHf: false
          isPro: false
          name: eramax
          type: user
        html: '<pre><code>model = AutoModelForCausalLM.from_pretrained("SkunkworksAI/phi-2",
          trust_remote_code=True, torch_dtype=torch.float16)

          tokenizer = AutoTokenizer.from_pretrained("SkunkworksAI/phi-2", trust_remote_code=True)

          </code></pre>

          <p>will give </p>

          <pre><code>OSError: SkunkworksAI/phi-2 does not appear to have a file named
          config.json.

          </code></pre>

          <p>this is because the model is not on the root of the repo.<br>can you
          make another repo and include the model and check if it can work. </p>

          <p>Best,</p>

          '
        raw: "```\nmodel = AutoModelForCausalLM.from_pretrained(\"SkunkworksAI/phi-2\"\
          , trust_remote_code=True, torch_dtype=torch.float16)\ntokenizer = AutoTokenizer.from_pretrained(\"\
          SkunkworksAI/phi-2\", trust_remote_code=True)\n```\nwill give \n```\nOSError:\
          \ SkunkworksAI/phi-2 does not appear to have a file named config.json.\n\
          ```\nthis is because the model is not on the root of the repo.\ncan you\
          \ make another repo and include the model and check if it can work. \n\n\
          Best,\n"
        updatedAt: '2023-12-13T18:00:35.196Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - RRRRose
        - mehdigououiad
        - lemi99
    id: 6579f14348287621b1709f75
    type: comment
  author: eramax
  content: "```\nmodel = AutoModelForCausalLM.from_pretrained(\"SkunkworksAI/phi-2\"\
    , trust_remote_code=True, torch_dtype=torch.float16)\ntokenizer = AutoTokenizer.from_pretrained(\"\
    SkunkworksAI/phi-2\", trust_remote_code=True)\n```\nwill give \n```\nOSError:\
    \ SkunkworksAI/phi-2 does not appear to have a file named config.json.\n```\n\
    this is because the model is not on the root of the repo.\ncan you make another\
    \ repo and include the model and check if it can work. \n\nBest,\n"
  created_at: 2023-12-13 18:00:35+00:00
  edited: false
  hidden: false
  id: 6579f14348287621b1709f75
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b7e345f92b20f7a38bf47a/EtTE7HF5b20A8638lrKqq.jpeg?w=200&h=200&f=face
      fullname: Farouk
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: pharaouk
      type: user
    createdAt: '2023-12-13T18:43:04.000Z'
    data:
      edited: false
      editors:
      - pharaouk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6979449987411499
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b7e345f92b20f7a38bf47a/EtTE7HF5b20A8638lrKqq.jpeg?w=200&h=200&f=face
          fullname: Farouk
          isHf: false
          isPro: false
          name: pharaouk
          type: user
        html: '<h1 id="use-a-pipeline-as-a-high-level-helper">Use a pipeline as a
          high-level helper</h1>

          <p>from transformers import pipeline</p>

          <p>pipe = pipeline("text-generation", model="SkunkworksAI/phi-2", trust_remote_code=True)</p>

          '
        raw: '# Use a pipeline as a high-level helper

          from transformers import pipeline


          pipe = pipeline("text-generation", model="SkunkworksAI/phi-2", trust_remote_code=True)'
        updatedAt: '2023-12-13T18:43:04.839Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - eramax
    id: 6579fb386cbe92a65d5042d0
    type: comment
  author: pharaouk
  content: '# Use a pipeline as a high-level helper

    from transformers import pipeline


    pipe = pipeline("text-generation", model="SkunkworksAI/phi-2", trust_remote_code=True)'
  created_at: 2023-12-13 18:43:04+00:00
  edited: false
  hidden: false
  id: 6579fb386cbe92a65d5042d0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d702beb4c9c2f0fff25295fb5172b973.svg
      fullname: Zach
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AnotherZach
      type: user
    createdAt: '2023-12-13T20:52:07.000Z'
    data:
      edited: false
      editors:
      - AnotherZach
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5647996664047241
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d702beb4c9c2f0fff25295fb5172b973.svg
          fullname: Zach
          isHf: false
          isPro: false
          name: AnotherZach
          type: user
        html: '<p>#phi test<br>#need to use pip to install einops, torch, transformers
          .<br>#Model downloading as I run this, going to assume things are working...</p>

          <p>import torch<br>from transformers import AutoModelForCausalLM, pipeline</p>

          <p>model = AutoModelForCausalLM.from_pretrained("SkunkworksAI/phi-2", trust_remote_code=True,
          torch_dtype=torch.float16)<br>#tokenizer = AutoTokenizer.from_pretrained("SkunkworksAI/phi-2",
          trust_remote_code=True)<br>pipe = pipeline("text-generation", model=model,
          trust_remote_code=True)<br>output = pipe("This is a cool example!", do_sample=True,
          top_p=0.95)</p>

          <p>print(output)</p>

          '
        raw: '#phi test

          #need to use pip to install einops, torch, transformers .

          #Model downloading as I run this, going to assume things are working...


          import torch

          from transformers import AutoModelForCausalLM, pipeline


          model = AutoModelForCausalLM.from_pretrained("SkunkworksAI/phi-2", trust_remote_code=True,
          torch_dtype=torch.float16)

          #tokenizer = AutoTokenizer.from_pretrained("SkunkworksAI/phi-2", trust_remote_code=True)

          pipe = pipeline("text-generation", model=model, trust_remote_code=True)

          output = pipe("This is a cool example!", do_sample=True, top_p=0.95)


          print(output)'
        updatedAt: '2023-12-13T20:52:07.737Z'
      numEdits: 0
      reactions: []
    id: 657a197710503b507c4bca14
    type: comment
  author: AnotherZach
  content: '#phi test

    #need to use pip to install einops, torch, transformers .

    #Model downloading as I run this, going to assume things are working...


    import torch

    from transformers import AutoModelForCausalLM, pipeline


    model = AutoModelForCausalLM.from_pretrained("SkunkworksAI/phi-2", trust_remote_code=True,
    torch_dtype=torch.float16)

    #tokenizer = AutoTokenizer.from_pretrained("SkunkworksAI/phi-2", trust_remote_code=True)

    pipe = pipeline("text-generation", model=model, trust_remote_code=True)

    output = pipe("This is a cool example!", do_sample=True, top_p=0.95)


    print(output)'
  created_at: 2023-12-13 20:52:07+00:00
  edited: false
  hidden: false
  id: 657a197710503b507c4bca14
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: SkunkworksAI/phi-2
repo_type: model
status: open
target_branch: null
title: How do you run this?
