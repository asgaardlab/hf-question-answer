!!python/object:huggingface_hub.community.DiscussionWithDetails
author: RajeshkumarV
conflicting_files: null
created_at: 2023-09-04 03:58:28+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8ce5f70298ae4c65e33c3593a8e81ac4.svg
      fullname: Rajesh Kumar V
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RajeshkumarV
      type: user
    createdAt: '2023-09-04T04:58:28.000Z'
    data:
      edited: false
      editors:
      - RajeshkumarV
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5797470808029175
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8ce5f70298ae4c65e33c3593a8e81ac4.svg
          fullname: Rajesh Kumar V
          isHf: false
          isPro: false
          name: RajeshkumarV
          type: user
        html: '<p>ggml_allocr_alloc: not enough space in the buffer (needed 222784000,
          largest block available 24166400)<br>GGML_ASSERT: C:\Users&lt;name&gt;\AppData\Local\Temp\pip-install-0ohg_aj6\llama-cpp-python_29c4846b4af1471bbb28a41659b32aa3\vendor\llama.cpp\ggml-alloc.c:144:
          !"not enough space in the buffer"</p>

          <p>I tried other models as well .. same iissue<br>huginn-13b-v4.5.Q5_K_M.gguf<br>LLaMA-2-7B-32K-Q3_K_S.gguf</p>

          '
        raw: "ggml_allocr_alloc: not enough space in the buffer (needed 222784000,\
          \ largest block available 24166400)\r\nGGML_ASSERT: C:\\Users\\<name>\\\
          AppData\\Local\\Temp\\pip-install-0ohg_aj6\\llama-cpp-python_29c4846b4af1471bbb28a41659b32aa3\\\
          vendor\\llama.cpp\\ggml-alloc.c:144: !\"not enough space in the buffer\"\
          \r\n\r\nI tried other models as well .. same iissue\r\nhuginn-13b-v4.5.Q5_K_M.gguf\r\
          \nLLaMA-2-7B-32K-Q3_K_S.gguf"
        updatedAt: '2023-09-04T04:58:28.677Z'
      numEdits: 0
      reactions: []
    id: 64f563f47f8e5fa90f5c3277
    type: comment
  author: RajeshkumarV
  content: "ggml_allocr_alloc: not enough space in the buffer (needed 222784000, largest\
    \ block available 24166400)\r\nGGML_ASSERT: C:\\Users\\<name>\\AppData\\Local\\\
    Temp\\pip-install-0ohg_aj6\\llama-cpp-python_29c4846b4af1471bbb28a41659b32aa3\\\
    vendor\\llama.cpp\\ggml-alloc.c:144: !\"not enough space in the buffer\"\r\n\r\
    \nI tried other models as well .. same iissue\r\nhuginn-13b-v4.5.Q5_K_M.gguf\r\
    \nLLaMA-2-7B-32K-Q3_K_S.gguf"
  created_at: 2023-09-04 03:58:28+00:00
  edited: false
  hidden: false
  id: 64f563f47f8e5fa90f5c3277
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/921171db37d397559d875d3d49a64a3f.svg
      fullname: Jopaul Jose
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DarkCoverUnleashed
      type: user
    createdAt: '2023-09-05T07:24:39.000Z'
    data:
      edited: false
      editors:
      - DarkCoverUnleashed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7286235690116882
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/921171db37d397559d875d3d49a64a3f.svg
          fullname: Jopaul Jose
          isHf: false
          isPro: false
          name: DarkCoverUnleashed
          type: user
        html: '<blockquote>

          <p>ggml_allocr_alloc: not enough space in the buffer (needed 222784000,
          largest block available 24166400)<br>GGML_ASSERT: C:\Users&lt;name&gt;\AppData\Local\Temp\pip-install-0ohg_aj6\llama-cpp-python_29c4846b4af1471bbb28a41659b32aa3\vendor\llama.cpp\ggml-alloc.c:144:
          !"not enough space in the buffer"</p>

          <p>I tried other models as well .. same iissue<br>huginn-13b-v4.5.Q5_K_M.gguf<br>LLaMA-2-7B-32K-Q3_K_S.gguf</p>

          </blockquote>

          <p>I think it''s probably because you are exceeding your system specs </p>

          '
        raw: "> ggml_allocr_alloc: not enough space in the buffer (needed 222784000,\
          \ largest block available 24166400)\n> GGML_ASSERT: C:\\Users\\<name>\\\
          AppData\\Local\\Temp\\pip-install-0ohg_aj6\\llama-cpp-python_29c4846b4af1471bbb28a41659b32aa3\\\
          vendor\\llama.cpp\\ggml-alloc.c:144: !\"not enough space in the buffer\"\
          \n> \n> I tried other models as well .. same iissue\n> huginn-13b-v4.5.Q5_K_M.gguf\n\
          > LLaMA-2-7B-32K-Q3_K_S.gguf\n\nI think it's probably because you are exceeding\
          \ your system specs \n"
        updatedAt: '2023-09-05T07:24:39.331Z'
      numEdits: 0
      reactions: []
    id: 64f6d7b77c9c53d0837cfdd0
    type: comment
  author: DarkCoverUnleashed
  content: "> ggml_allocr_alloc: not enough space in the buffer (needed 222784000,\
    \ largest block available 24166400)\n> GGML_ASSERT: C:\\Users\\<name>\\AppData\\\
    Local\\Temp\\pip-install-0ohg_aj6\\llama-cpp-python_29c4846b4af1471bbb28a41659b32aa3\\\
    vendor\\llama.cpp\\ggml-alloc.c:144: !\"not enough space in the buffer\"\n> \n\
    > I tried other models as well .. same iissue\n> huginn-13b-v4.5.Q5_K_M.gguf\n\
    > LLaMA-2-7B-32K-Q3_K_S.gguf\n\nI think it's probably because you are exceeding\
    \ your system specs \n"
  created_at: 2023-09-05 06:24:39+00:00
  edited: false
  hidden: false
  id: 64f6d7b77c9c53d0837cfdd0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8ce5f70298ae4c65e33c3593a8e81ac4.svg
      fullname: Rajesh Kumar V
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RajeshkumarV
      type: user
    createdAt: '2023-09-05T07:30:45.000Z'
    data:
      edited: false
      editors:
      - RajeshkumarV
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.909416139125824
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8ce5f70298ae4c65e33c3593a8e81ac4.svg
          fullname: Rajesh Kumar V
          isHf: false
          isPro: false
          name: RajeshkumarV
          type: user
        html: '<p>I have a 32GB RAM windows 11 Laptop with an I7 processor. Also has
          a dedicated GPU T1200</p>

          '
        raw: I have a 32GB RAM windows 11 Laptop with an I7 processor. Also has a
          dedicated GPU T1200
        updatedAt: '2023-09-05T07:30:45.918Z'
      numEdits: 0
      reactions: []
    id: 64f6d9252b10e9369ed5b9e3
    type: comment
  author: RajeshkumarV
  content: I have a 32GB RAM windows 11 Laptop with an I7 processor. Also has a dedicated
    GPU T1200
  created_at: 2023-09-05 06:30:45+00:00
  edited: false
  hidden: false
  id: 64f6d9252b10e9369ed5b9e3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dce3b48af089e214318c97456c87d6e0.svg
      fullname: shafiq alibhai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shafiqalibhai
      type: user
    createdAt: '2023-09-06T17:50:41.000Z'
    data:
      edited: true
      editors:
      - shafiqalibhai
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9424759149551392
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dce3b48af089e214318c97456c87d6e0.svg
          fullname: shafiq alibhai
          isHf: false
          isPro: false
          name: shafiqalibhai
          type: user
        html: '<p>That is not nearly enough memory to load this model in a 64k context.
          You will need nearly 9x more memory.<br>Read this from TheBloke: <a href="https://huggingface.co/TheBloke/Yarn-Llama-2-13B-64K-GGUF/discussions/1#64f1b7d10b27861b2cb6e956">https://huggingface.co/TheBloke/Yarn-Llama-2-13B-64K-GGUF/discussions/1#64f1b7d10b27861b2cb6e956</a></p>

          '
        raw: 'That is not nearly enough memory to load this model in a 64k context.
          You will need nearly 9x more memory.

          Read this from TheBloke: https://huggingface.co/TheBloke/Yarn-Llama-2-13B-64K-GGUF/discussions/1#64f1b7d10b27861b2cb6e956'
        updatedAt: '2023-09-06T17:51:55.536Z'
      numEdits: 1
      reactions: []
    id: 64f8bbf1a9b6fed18c80b90e
    type: comment
  author: shafiqalibhai
  content: 'That is not nearly enough memory to load this model in a 64k context.
    You will need nearly 9x more memory.

    Read this from TheBloke: https://huggingface.co/TheBloke/Yarn-Llama-2-13B-64K-GGUF/discussions/1#64f1b7d10b27861b2cb6e956'
  created_at: 2023-09-06 16:50:41+00:00
  edited: true
  hidden: false
  id: 64f8bbf1a9b6fed18c80b90e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8ce5f70298ae4c65e33c3593a8e81ac4.svg
      fullname: Rajesh Kumar V
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RajeshkumarV
      type: user
    createdAt: '2023-09-06T18:09:20.000Z'
    data:
      edited: false
      editors:
      - RajeshkumarV
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.904376208782196
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8ce5f70298ae4c65e33c3593a8e81ac4.svg
          fullname: Rajesh Kumar V
          isHf: false
          isPro: false
          name: RajeshkumarV
          type: user
        html: '<p>is there a 4k version of this model in gguf format pls? </p>

          '
        raw: 'is there a 4k version of this model in gguf format pls? '
        updatedAt: '2023-09-06T18:09:20.850Z'
      numEdits: 0
      reactions: []
    id: 64f8c0506a71cea1c7f972e3
    type: comment
  author: RajeshkumarV
  content: 'is there a 4k version of this model in gguf format pls? '
  created_at: 2023-09-06 17:09:20+00:00
  edited: false
  hidden: false
  id: 64f8c0506a71cea1c7f972e3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Yarn-Llama-2-7B-64K-GGUF
repo_type: model
status: open
target_branch: null
title: 'when i use this model to embed a PDF file i get an error : ggml_allocr_alloc:
  not enough space in the buffer (needed 222784000, largest block available 24166400)'
