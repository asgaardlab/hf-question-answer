!!python/object:huggingface_hub.community.DiscussionWithDetails
author: KiranAli
conflicting_files: null
created_at: 2023-04-13 18:39:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e7c1bd86b21195a9e351b705ff25dc66.svg
      fullname: Kiran Ali
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KiranAli
      type: user
    createdAt: '2023-04-13T19:39:55.000Z'
    data:
      edited: false
      editors:
      - KiranAli
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e7c1bd86b21195a9e351b705ff25dc66.svg
          fullname: Kiran Ali
          isHf: false
          isPro: false
          name: KiranAli
          type: user
        html: '<p>I''m running my model on GPU:  NVIDIA Tesla V100 16 GB. It takes
          more than a minute to generate output. </p>

          '
        raw: "I'm running my model on GPU:  NVIDIA Tesla V100 16 GB. It takes more\
          \ than a minute to generate output. \r\n\r\n"
        updatedAt: '2023-04-13T19:39:55.167Z'
      numEdits: 0
      reactions: []
    id: 64385a8b3b46237de3cd1e69
    type: comment
  author: KiranAli
  content: "I'm running my model on GPU:  NVIDIA Tesla V100 16 GB. It takes more than\
    \ a minute to generate output. \r\n\r\n"
  created_at: 2023-04-13 18:39:55+00:00
  edited: false
  hidden: false
  id: 64385a8b3b46237de3cd1e69
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-13T19:41:12.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Please see the many other threads here with ideas. What size model?
          that''s too small for a 12B param model. Use 8-bit, a smaller model, or
          a larger GPU.</p>

          '
        raw: Please see the many other threads here with ideas. What size model? that's
          too small for a 12B param model. Use 8-bit, a smaller model, or a larger
          GPU.
        updatedAt: '2023-04-13T19:41:12.192Z'
      numEdits: 0
      reactions: []
    id: 64385ad807583375d77f0cf3
    type: comment
  author: srowen
  content: Please see the many other threads here with ideas. What size model? that's
    too small for a 12B param model. Use 8-bit, a smaller model, or a larger GPU.
  created_at: 2023-04-13 18:41:12+00:00
  edited: false
  hidden: false
  id: 64385ad807583375d77f0cf3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e7c1bd86b21195a9e351b705ff25dc66.svg
      fullname: Kiran Ali
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KiranAli
      type: user
    createdAt: '2023-04-17T07:51:46.000Z'
    data:
      edited: true
      editors:
      - KiranAli
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e7c1bd86b21195a9e351b705ff25dc66.svg
          fullname: Kiran Ali
          isHf: false
          isPro: false
          name: KiranAli
          type: user
        html: '<p>Now I''m running it on 2 V100 16GB and get the following error </p>

          <pre><code>return self.cos_cached[:seq_len, ...].to(x.device), self.sin_cached[:seq_len,
          ...].to(x.device)

          RuntimeError: CUDA error: uncorrectable ECC error encountered

          CUDA kernel errors might be asynchronously reported at some other API call,
          so the stacktrace below might be incorrect.

          For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

          Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

          </code></pre>

          <p>Memory of both GPUs quickly consumes to 16GB,</p>

          '
        raw: "Now I'm running it on 2 V100 16GB and get the following error \n\n \
          \   return self.cos_cached[:seq_len, ...].to(x.device), self.sin_cached[:seq_len,\
          \ ...].to(x.device)\n    RuntimeError: CUDA error: uncorrectable ECC error\
          \ encountered\n    CUDA kernel errors might be asynchronously reported at\
          \ some other API call, so the stacktrace below might be incorrect.\n   \
          \ For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n    Compile with\
          \ `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\nMemory of both\
          \ GPUs quickly consumes to 16GB,"
        updatedAt: '2023-04-17T07:52:34.793Z'
      numEdits: 2
      reactions: []
    id: 643cfa927ede13bc7b545e76
    type: comment
  author: KiranAli
  content: "Now I'm running it on 2 V100 16GB and get the following error \n\n   \
    \ return self.cos_cached[:seq_len, ...].to(x.device), self.sin_cached[:seq_len,\
    \ ...].to(x.device)\n    RuntimeError: CUDA error: uncorrectable ECC error encountered\n\
    \    CUDA kernel errors might be asynchronously reported at some other API call,\
    \ so the stacktrace below might be incorrect.\n    For debugging consider passing\
    \ CUDA_LAUNCH_BLOCKING=1.\n    Compile with `TORCH_USE_CUDA_DSA` to enable device-side\
    \ assertions.\n\nMemory of both GPUs quickly consumes to 16GB,"
  created_at: 2023-04-17 06:51:46+00:00
  edited: true
  hidden: false
  id: 643cfa927ede13bc7b545e76
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-17T12:42:48.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>That''s a hardware error, it seems.<br>Also, still not clear what
          model you''re using or what you are calling.</p>

          '
        raw: 'That''s a hardware error, it seems.

          Also, still not clear what model you''re using or what you are calling.'
        updatedAt: '2023-04-17T12:42:48.751Z'
      numEdits: 0
      reactions: []
    id: 643d3ec8bf8e4a061c786366
    type: comment
  author: srowen
  content: 'That''s a hardware error, it seems.

    Also, still not clear what model you''re using or what you are calling.'
  created_at: 2023-04-17 11:42:48+00:00
  edited: false
  hidden: false
  id: 643d3ec8bf8e4a061c786366
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e7c1bd86b21195a9e351b705ff25dc66.svg
      fullname: Kiran Ali
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KiranAli
      type: user
    createdAt: '2023-04-18T08:29:54.000Z'
    data:
      edited: false
      editors:
      - KiranAli
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e7c1bd86b21195a9e351b705ff25dc66.svg
          fullname: Kiran Ali
          isHf: false
          isPro: false
          name: KiranAli
          type: user
        html: '<p>I''m a newbie to this field, so I apologize if any query is pretty
          straightforward. I''m using Dolly 7b and have 2 GPUs of 16GB. Can I make
          use of both GPUs to deploy model 7b? Only dolly 3b performs well on GPU
          16GB</p>

          '
        raw: I'm a newbie to this field, so I apologize if any query is pretty straightforward.
          I'm using Dolly 7b and have 2 GPUs of 16GB. Can I make use of both GPUs
          to deploy model 7b? Only dolly 3b performs well on GPU 16GB
        updatedAt: '2023-04-18T08:29:54.717Z'
      numEdits: 0
      reactions: []
    id: 643e55025fc641a0bfc57e50
    type: comment
  author: KiranAli
  content: I'm a newbie to this field, so I apologize if any query is pretty straightforward.
    I'm using Dolly 7b and have 2 GPUs of 16GB. Can I make use of both GPUs to deploy
    model 7b? Only dolly 3b performs well on GPU 16GB
  created_at: 2023-04-18 07:29:54+00:00
  edited: false
  hidden: false
  id: 643e55025fc641a0bfc57e50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
      fullname: Matthew Hayes
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: matthayes
      type: user
    createdAt: '2023-04-18T08:50:56.000Z'
    data:
      edited: false
      editors:
      - matthayes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
          fullname: Matthew Hayes
          isHf: false
          isPro: false
          name: matthayes
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;KiranAli&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/KiranAli\">@<span class=\"\
          underline\">KiranAli</span></a></span>\n\n\t</span></span> you might be\
          \ able to.  If you follow examples in the model card where device_map is\
          \ set to \"auto\" then it should spread the model across both GPUs.  The\
          \ model card suggests using bfloat16.  This will save memory.  You can also\
          \ try load_in_8bit to further reduce memory.  See <a rel=\"nofollow\" href=\"\
          https://github.com/databrickslabs/dolly#a10-gpus\">https://github.com/databrickslabs/dolly#a10-gpus</a>\
          \ for more instructions.</p>\n"
        raw: '@KiranAli you might be able to.  If you follow examples in the model
          card where device_map is set to "auto" then it should spread the model across
          both GPUs.  The model card suggests using bfloat16.  This will save memory.  You
          can also try load_in_8bit to further reduce memory.  See https://github.com/databrickslabs/dolly#a10-gpus
          for more instructions.'
        updatedAt: '2023-04-18T08:50:56.392Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - KiranAli
    id: 643e59f0650a6a65d840b193
    type: comment
  author: matthayes
  content: '@KiranAli you might be able to.  If you follow examples in the model card
    where device_map is set to "auto" then it should spread the model across both
    GPUs.  The model card suggests using bfloat16.  This will save memory.  You can
    also try load_in_8bit to further reduce memory.  See https://github.com/databrickslabs/dolly#a10-gpus
    for more instructions.'
  created_at: 2023-04-18 07:50:56+00:00
  edited: false
  hidden: false
  id: 643e59f0650a6a65d840b193
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-19T19:09:08.000Z'
    data:
      status: closed
    id: 64403c544164a65ca12cc127
    type: status-change
  author: srowen
  created_at: 2023-04-19 18:09:08+00:00
  id: 64403c544164a65ca12cc127
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 23
repo_id: databricks/dolly-v2-12b
repo_type: model
status: closed
target_branch: null
title: It takes time to generate response
