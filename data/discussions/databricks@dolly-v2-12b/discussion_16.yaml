!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dfurman
conflicting_files: null
created_at: 2023-04-13 11:05:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
      fullname: Daniel Furman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dfurman
      type: user
    createdAt: '2023-04-13T12:05:58.000Z'
    data:
      edited: false
      editors:
      - dfurman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
          fullname: Daniel Furman
          isHf: false
          isPro: false
          name: dfurman
          type: user
        html: '<p>Why make false claims in the announcement of the model? Google has
          been doing this for years, the Flan paper came out in 2021. It seriously
          cuts your credibility among folks who have been in the field before 2023.</p>

          '
        raw: Why make false claims in the announcement of the model? Google has been
          doing this for years, the Flan paper came out in 2021. It seriously cuts
          your credibility among folks who have been in the field before 2023.
        updatedAt: '2023-04-13T12:05:58.231Z'
      numEdits: 0
      reactions: []
    id: 6437f02651c7ebfc813d89bd
    type: comment
  author: dfurman
  content: Why make false claims in the announcement of the model? Google has been
    doing this for years, the Flan paper came out in 2021. It seriously cuts your
    credibility among folks who have been in the field before 2023.
  created_at: 2023-04-13 11:05:58+00:00
  edited: false
  hidden: false
  id: 6437f02651c7ebfc813d89bd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-13T12:47:00.000Z'
    data:
      edited: true
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>I think the claim is specifically about "for commercial use" in
          the blog, if you read the rest of it. I agree this is an arguable claim,
          depending on views about what is clearly for commercial use or not. Also,
          is FLAN an instruction-following model? I think this is also really comparing
          to other much more similar models derived from LLaMa and OpenAI output.</p>

          '
        raw: I think the claim is specifically about "for commercial use" in the blog,
          if you read the rest of it. I agree this is an arguable claim, depending
          on views about what is clearly for commercial use or not. Also, is FLAN
          an instruction-following model? I think this is also really comparing to
          other much more similar models derived from LLaMa and OpenAI output.
        updatedAt: '2023-04-13T12:49:59.330Z'
      numEdits: 1
      reactions: []
    id: 6437f9c4f5311fdcf73ba5de
    type: comment
  author: srowen
  content: I think the claim is specifically about "for commercial use" in the blog,
    if you read the rest of it. I agree this is an arguable claim, depending on views
    about what is clearly for commercial use or not. Also, is FLAN an instruction-following
    model? I think this is also really comparing to other much more similar models
    derived from LLaMa and OpenAI output.
  created_at: 2023-04-13 11:47:00+00:00
  edited: true
  hidden: false
  id: 6437f9c4f5311fdcf73ba5de
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
      fullname: Daniel Furman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dfurman
      type: user
    createdAt: '2023-04-13T12:48:23.000Z'
    data:
      edited: true
      editors:
      - dfurman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
          fullname: Daniel Furman
          isHf: false
          isPro: false
          name: dfurman
          type: user
        html: '<p>^ <a href="https://huggingface.co/google/flan-t5-xxl">https://huggingface.co/google/flan-t5-xxl</a></p>

          <p>Google''s Flan-T5 models are apache 2.0 (commercial use ok), were released
          in 2021 (a decade ago in AI years), and the datasets employed are open-sourced
          right in the HF repo (unlike Dolly).</p>

          '
        raw: '^ https://huggingface.co/google/flan-t5-xxl


          Google''s Flan-T5 models are apache 2.0 (commercial use ok), were released
          in 2021 (a decade ago in AI years), and the datasets employed are open-sourced
          right in the HF repo (unlike Dolly).'
        updatedAt: '2023-04-13T12:49:37.324Z'
      numEdits: 2
      reactions: []
    id: 6437fa17f5311fdcf73ba8b9
    type: comment
  author: dfurman
  content: '^ https://huggingface.co/google/flan-t5-xxl


    Google''s Flan-T5 models are apache 2.0 (commercial use ok), were released in
    2021 (a decade ago in AI years), and the datasets employed are open-sourced right
    in the HF repo (unlike Dolly).'
  created_at: 2023-04-13 11:48:23+00:00
  edited: true
  hidden: false
  id: 6437fa17f5311fdcf73ba8b9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-13T12:51:32.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Yeah I agree, see my edit above.</p>

          '
        raw: Yeah I agree, see my edit above.
        updatedAt: '2023-04-13T12:51:32.469Z'
      numEdits: 0
      reactions: []
    id: 6437fad478e36ab7b68ab0aa
    type: comment
  author: srowen
  content: Yeah I agree, see my edit above.
  created_at: 2023-04-13 11:51:32+00:00
  edited: false
  hidden: false
  id: 6437fad478e36ab7b68ab0aa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
      fullname: Daniel Furman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dfurman
      type: user
    createdAt: '2023-04-13T12:54:47.000Z'
    data:
      edited: true
      editors:
      - dfurman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
          fullname: Daniel Furman
          isHf: false
          isPro: false
          name: dfurman
          type: user
        html: '<p>Yes, FLAN is an instruction-following model - check out the main
          picture in the FLAN repo. </p>

          <p>Anecdotally, flan-t5-xl (not even the biggest one) is doing better than
          this 12b dolly model in my instruction following prompts I typically test
          out (yes/no reasoning type questions).</p>

          '
        raw: "Yes, FLAN is an instruction-following model - check out the main picture\
          \ in the FLAN repo. \n\nAnecdotally, flan-t5-xl (not even the biggest one)\
          \ is doing better than this 12b dolly model in my instruction following\
          \ prompts I typically test out (yes/no reasoning type questions)."
        updatedAt: '2023-04-13T13:14:25.457Z'
      numEdits: 4
      reactions: []
    id: 6437fb979057a19b9fa2dec0
    type: comment
  author: dfurman
  content: "Yes, FLAN is an instruction-following model - check out the main picture\
    \ in the FLAN repo. \n\nAnecdotally, flan-t5-xl (not even the biggest one) is\
    \ doing better than this 12b dolly model in my instruction following prompts I\
    \ typically test out (yes/no reasoning type questions)."
  created_at: 2023-04-13 11:54:47+00:00
  edited: true
  hidden: false
  id: 6437fb979057a19b9fa2dec0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
      fullname: Daniel Furman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dfurman
      type: user
    createdAt: '2023-04-13T12:56:52.000Z'
    data:
      edited: false
      editors:
      - dfurman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
          fullname: Daniel Furman
          isHf: false
          isPro: false
          name: dfurman
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/mRTxhHNf4tPkSS2BqQ8Jm.png"><img
          alt="Screenshot 2023-04-13 at 8.56.41 AM.png" src="https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/mRTxhHNf4tPkSS2BqQ8Jm.png"></a></p>

          '
        raw: '![Screenshot 2023-04-13 at 8.56.41 AM.png](https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/mRTxhHNf4tPkSS2BqQ8Jm.png)'
        updatedAt: '2023-04-13T12:56:52.774Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - bayang
    id: 6437fc14f5311fdcf73bb95a
    type: comment
  author: dfurman
  content: '![Screenshot 2023-04-13 at 8.56.41 AM.png](https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/mRTxhHNf4tPkSS2BqQ8Jm.png)'
  created_at: 2023-04-13 11:56:52+00:00
  edited: false
  hidden: false
  id: 6437fc14f5311fdcf73bb95a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-13T13:22:05.000Z'
    data:
      edited: true
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>I think of it as text-to-text, and yeah it was also trained on instruction-following
          tasks among other things. I agree with you more than I don''t, personally.
          There is a useful claim here, that this is more openly usable in a way that
          a bunch of LLaMa derivatives are not, that part isn''t weird. But the framing
          of this seems over-broad. I''ll put this again to the people in charge of
          that messaging.</p>

          '
        raw: I think of it as text-to-text, and yeah it was also trained on instruction-following
          tasks among other things. I agree with you more than I don't, personally.
          There is a useful claim here, that this is more openly usable in a way that
          a bunch of LLaMa derivatives are not, that part isn't weird. But the framing
          of this seems over-broad. I'll put this again to the people in charge of
          that messaging.
        updatedAt: '2023-04-13T13:36:53.111Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - dfurman
    id: 643801fd94faafc1a2dfb12e
    type: comment
  author: srowen
  content: I think of it as text-to-text, and yeah it was also trained on instruction-following
    tasks among other things. I agree with you more than I don't, personally. There
    is a useful claim here, that this is more openly usable in a way that a bunch
    of LLaMa derivatives are not, that part isn't weird. But the framing of this seems
    over-broad. I'll put this again to the people in charge of that messaging.
  created_at: 2023-04-13 12:22:05+00:00
  edited: true
  hidden: false
  id: 643801fd94faafc1a2dfb12e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
      fullname: Daniel Furman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dfurman
      type: user
    createdAt: '2023-04-13T13:23:33.000Z'
    data:
      edited: false
      editors:
      - dfurman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
          fullname: Daniel Furman
          isHf: false
          isPro: false
          name: dfurman
          type: user
        html: '<p>That checks!</p>

          '
        raw: That checks!
        updatedAt: '2023-04-13T13:23:33.587Z'
      numEdits: 0
      reactions: []
    id: 643802556227bd68299e0441
    type: comment
  author: dfurman
  content: That checks!
  created_at: 2023-04-13 12:23:33+00:00
  edited: false
  hidden: false
  id: 643802556227bd68299e0441
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/14eaef2c64f6b9158e2473a8125b0401.svg
      fullname: Mike Conover
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mike-conover-db
      type: user
    createdAt: '2023-04-13T15:11:59.000Z'
    data:
      edited: false
      editors:
      - mike-conover-db
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/14eaef2c64f6b9158e2473a8125b0401.svg
          fullname: Mike Conover
          isHf: false
          isPro: false
          name: mike-conover-db
          type: user
        html: "<p>Hey Daniel, I\u2019m one of the creators of Dolly and wanted to\
          \ share some of our thinking on this. </p>\n<p>Flan-T5 is really powerful\
          \ and the Flan dataset particularly so. The thing I observe when using it\
          \ is for tasks like open ended content generation etc is that it\u2019s\
          \ very terse. I\u2019ve never been able to get it to write a multi paragraph\
          \ letter, for example.</p>\n<p>My hypothesis is that this reflects the composition\
          \ of the underlying completion dataset, which is as you mention composed\
          \ of a lot of benchmark-style responses, eg rate the sentiment, reply w\
          \ categories or selections from a multiple choice list.  To me it seems\
          \ like it\u2019s great on understanding oriented problems, but not really\
          \ performant for text generation broadly, which is one of the characteristics\
          \ I think about when I think of instruction following.</p>\n<p>Secondly,\
          \ I agree, and we debated how to say this without using a million hyphens,\
          \ but we worked to communicate that the Dolly dataset is the first human-generated\
          \ open instruction tuning corpus specifically designed to elicit this behavior.\
          \  To the best of my (admittedly limited) knowledge there are  other corpora\
          \ like OIG, Flan, p3, super natural instructions etc - but they all are\
          \ either synthetic in the style of self instruct, scraped from the web (as\
          \ in the case of much of the Flan data) or governed by restrictive licenses.</p>\n\
          <p>The last thing we want is to ruin a good time by claiming something that\u2019\
          s not true, and this is a big part of why we go to lengths to emphasize,\
          \ for example, that the model isn\u2019t state of the art.  That said, at\
          \ least for now I do believe this a first, but like any reasonable scientist\
          \ remain open to new information as it becomes available.</p>\n<p>Thanks\
          \ for your interest in the project, and hope you find it interesting and\
          \ useful. </p>\n<p>Take care,<br>Mike</p>\n"
        raw: "Hey Daniel, I\u2019m one of the creators of Dolly and wanted to share\
          \ some of our thinking on this. \n\nFlan-T5 is really powerful and the Flan\
          \ dataset particularly so. The thing I observe when using it is for tasks\
          \ like open ended content generation etc is that it\u2019s very terse. I\u2019\
          ve never been able to get it to write a multi paragraph letter, for example.\n\
          \nMy hypothesis is that this reflects the composition of the underlying\
          \ completion dataset, which is as you mention composed of a lot of benchmark-style\
          \ responses, eg rate the sentiment, reply w categories or selections from\
          \ a multiple choice list.  To me it seems like it\u2019s great on understanding\
          \ oriented problems, but not really performant for text generation broadly,\
          \ which is one of the characteristics I think about when I think of instruction\
          \ following.\n\nSecondly, I agree, and we debated how to say this without\
          \ using a million hyphens, but we worked to communicate that the Dolly dataset\
          \ is the first human-generated open instruction tuning corpus specifically\
          \ designed to elicit this behavior.  To the best of my (admittedly limited)\
          \ knowledge there are  other corpora like OIG, Flan, p3, super natural instructions\
          \ etc - but they all are either synthetic in the style of self instruct,\
          \ scraped from the web (as in the case of much of the Flan data) or governed\
          \ by restrictive licenses.\n\nThe last thing we want is to ruin a good time\
          \ by claiming something that\u2019s not true, and this is a big part of\
          \ why we go to lengths to emphasize, for example, that the model isn\u2019\
          t state of the art.  That said, at least for now I do believe this a first,\
          \ but like any reasonable scientist remain open to new information as it\
          \ becomes available.\n\nThanks for your interest in the project, and hope\
          \ you find it interesting and useful. \n\nTake care,\nMike"
        updatedAt: '2023-04-13T15:11:59.574Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - awaitz
        - matthayes
        - farhanhubble
    id: 64381bbf9057a19b9fa3f56a
    type: comment
  author: mike-conover-db
  content: "Hey Daniel, I\u2019m one of the creators of Dolly and wanted to share\
    \ some of our thinking on this. \n\nFlan-T5 is really powerful and the Flan dataset\
    \ particularly so. The thing I observe when using it is for tasks like open ended\
    \ content generation etc is that it\u2019s very terse. I\u2019ve never been able\
    \ to get it to write a multi paragraph letter, for example.\n\nMy hypothesis is\
    \ that this reflects the composition of the underlying completion dataset, which\
    \ is as you mention composed of a lot of benchmark-style responses, eg rate the\
    \ sentiment, reply w categories or selections from a multiple choice list.  To\
    \ me it seems like it\u2019s great on understanding oriented problems, but not\
    \ really performant for text generation broadly, which is one of the characteristics\
    \ I think about when I think of instruction following.\n\nSecondly, I agree, and\
    \ we debated how to say this without using a million hyphens, but we worked to\
    \ communicate that the Dolly dataset is the first human-generated open instruction\
    \ tuning corpus specifically designed to elicit this behavior.  To the best of\
    \ my (admittedly limited) knowledge there are  other corpora like OIG, Flan, p3,\
    \ super natural instructions etc - but they all are either synthetic in the style\
    \ of self instruct, scraped from the web (as in the case of much of the Flan data)\
    \ or governed by restrictive licenses.\n\nThe last thing we want is to ruin a\
    \ good time by claiming something that\u2019s not true, and this is a big part\
    \ of why we go to lengths to emphasize, for example, that the model isn\u2019\
    t state of the art.  That said, at least for now I do believe this a first, but\
    \ like any reasonable scientist remain open to new information as it becomes available.\n\
    \nThanks for your interest in the project, and hope you find it interesting and\
    \ useful. \n\nTake care,\nMike"
  created_at: 2023-04-13 14:11:59+00:00
  edited: false
  hidden: false
  id: 64381bbf9057a19b9fa3f56a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
      fullname: Daniel Furman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dfurman
      type: user
    createdAt: '2023-04-13T15:20:45.000Z'
    data:
      edited: false
      editors:
      - dfurman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
          fullname: Daniel Furman
          isHf: false
          isPro: false
          name: dfurman
          type: user
        html: '<p>Thanks for your response Mike. Sounds like you improved an aspect
          of instruction models - little different than claiming to be the first.</p>

          '
        raw: Thanks for your response Mike. Sounds like you improved an aspect of
          instruction models - little different than claiming to be the first.
        updatedAt: '2023-04-13T15:20:45.805Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - rragundez
    id: 64381dcd9057a19b9fa4062b
    type: comment
  author: dfurman
  content: Thanks for your response Mike. Sounds like you improved an aspect of instruction
    models - little different than claiming to be the first.
  created_at: 2023-04-13 14:20:45+00:00
  edited: false
  hidden: false
  id: 64381dcd9057a19b9fa4062b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dbf6bfbad259ebeae1ea9b44897b90c1.svg
      fullname: Chet Patel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chpatel2
      type: user
    createdAt: '2023-05-09T17:38:36.000Z'
    data:
      edited: false
      editors:
      - chpatel2
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dbf6bfbad259ebeae1ea9b44897b90c1.svg
          fullname: Chet Patel
          isHf: false
          isPro: false
          name: chpatel2
          type: user
        html: '<p>Is there a hosted version of this model for testing?</p>

          '
        raw: Is there a hosted version of this model for testing?
        updatedAt: '2023-05-09T17:38:36.300Z'
      numEdits: 0
      reactions: []
    id: 645a851c214503ad17a99aa4
    type: comment
  author: chpatel2
  content: Is there a hosted version of this model for testing?
  created_at: 2023-05-09 16:38:36+00:00
  edited: false
  hidden: false
  id: 645a851c214503ad17a99aa4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-09T17:42:17.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Not right now, but you can just load and use the model in python
          code as per the model card example</p>

          '
        raw: Not right now, but you can just load and use the model in python code
          as per the model card example
        updatedAt: '2023-05-09T17:42:17.820Z'
      numEdits: 0
      reactions: []
    id: 645a85f9dbf60d37335f80c2
    type: comment
  author: srowen
  content: Not right now, but you can just load and use the model in python code as
    per the model card example
  created_at: 2023-05-09 16:42:17+00:00
  edited: false
  hidden: false
  id: 645a85f9dbf60d37335f80c2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-09T17:42:38.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>(also please don''t attach to unrelated conversations)</p>

          '
        raw: (also please don't attach to unrelated conversations)
        updatedAt: '2023-05-09T17:42:38.164Z'
      numEdits: 0
      reactions: []
    id: 645a860e16dd9c07825eeafb
    type: comment
  author: srowen
  content: (also please don't attach to unrelated conversations)
  created_at: 2023-05-09 16:42:38+00:00
  edited: false
  hidden: false
  id: 645a860e16dd9c07825eeafb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9c864114f616cf6ee9d76aee633b01c4.svg
      fullname: BaYang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bayang
      type: user
    createdAt: '2023-06-04T04:22:44.000Z'
    data:
      edited: false
      editors:
      - bayang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9616334438323975
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9c864114f616cf6ee9d76aee633b01c4.svg
          fullname: BaYang
          isHf: false
          isPro: false
          name: bayang
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;dfurman&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/dfurman\">@<span class=\"\
          underline\">dfurman</span></a></span>\n\n\t</span></span> I can confirm\
          \ what you said above, on some tasks,<br>Flan resonated more than Dolly.\
          \ For my own case, using the Flan is enough and it only uses it for QA and\
          \ IR.<br>I'm on the way to fine-tuning it for a closed domain :)</p>\n"
        raw: "@dfurman I can confirm what you said above, on some tasks, \nFlan resonated\
          \ more than Dolly. For my own case, using the Flan is enough and it only\
          \ uses it for QA and IR.\nI'm on the way to fine-tuning it for a closed\
          \ domain :)"
        updatedAt: '2023-06-04T04:22:44.418Z'
      numEdits: 0
      reactions: []
    id: 647c11944d7c0c3fcce345cc
    type: comment
  author: bayang
  content: "@dfurman I can confirm what you said above, on some tasks, \nFlan resonated\
    \ more than Dolly. For my own case, using the Flan is enough and it only uses\
    \ it for QA and IR.\nI'm on the way to fine-tuning it for a closed domain :)"
  created_at: 2023-06-04 03:22:44+00:00
  edited: false
  hidden: false
  id: 647c11944d7c0c3fcce345cc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-06-10T02:36:01.000Z'
    data:
      status: closed
    id: 6483e1915da3b91e3c267bde
    type: status-change
  author: srowen
  created_at: 2023-06-10 01:36:01+00:00
  id: 6483e1915da3b91e3c267bde
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: databricks/dolly-v2-12b
repo_type: model
status: closed
target_branch: null
title: "\u201C Introducing the first open source, instruction-following LLM\u201D"
