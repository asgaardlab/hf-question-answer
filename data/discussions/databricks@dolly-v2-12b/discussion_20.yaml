!!python/object:huggingface_hub.community.DiscussionWithDetails
author: pho410
conflicting_files: null
created_at: 2023-04-13 16:40:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d89a311ce1271cd3d6940943a0253eda.svg
      fullname: Ryan Fortin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pho410
      type: user
    createdAt: '2023-04-13T17:40:14.000Z'
    data:
      edited: false
      editors:
      - pho410
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d89a311ce1271cd3d6940943a0253eda.svg
          fullname: Ryan Fortin
          isHf: false
          isPro: false
          name: pho410
          type: user
        html: '<p>What are the optimal settings for a Databricks cluster when running
          this model when loading the weights from huggingface? Currently using a
          Shared Compute cluster on 12.2 LTS ML (includes Apache Spark 3.3.2, GPU,
          Scala 2.12) with g4dn.8xlarge, but it seems like the model is running on
          CPU (10+ minutes on average for completion). I see for training, p4d.24xlarge
          is ideal, but I assume this isn''t the case if I''m not training the model
          myself. I''m using the code directly from the repo:</p>

          <p>from transformers import pipeline</p>

          <p>instruct_pipeline = pipeline(model="databricks/dolly-v2-12b", trust_remote_code=True,
          device_map="auto")</p>

          <p>Any help would be appreciated!</p>

          '
        raw: "What are the optimal settings for a Databricks cluster when running\
          \ this model when loading the weights from huggingface? Currently using\
          \ a Shared Compute cluster on 12.2 LTS ML (includes Apache Spark 3.3.2,\
          \ GPU, Scala 2.12) with g4dn.8xlarge, but it seems like the model is running\
          \ on CPU (10+ minutes on average for completion). I see for training, p4d.24xlarge\
          \ is ideal, but I assume this isn't the case if I'm not training the model\
          \ myself. I'm using the code directly from the repo:\r\n\r\nfrom transformers\
          \ import pipeline\r\n\r\ninstruct_pipeline = pipeline(model=\"databricks/dolly-v2-12b\"\
          , trust_remote_code=True, device_map=\"auto\")\r\n\r\nAny help would be\
          \ appreciated!"
        updatedAt: '2023-04-13T17:40:14.540Z'
      numEdits: 0
      reactions: []
    id: 64383e7ee95aa634ce76af0e
    type: comment
  author: pho410
  content: "What are the optimal settings for a Databricks cluster when running this\
    \ model when loading the weights from huggingface? Currently using a Shared Compute\
    \ cluster on 12.2 LTS ML (includes Apache Spark 3.3.2, GPU, Scala 2.12) with g4dn.8xlarge,\
    \ but it seems like the model is running on CPU (10+ minutes on average for completion).\
    \ I see for training, p4d.24xlarge is ideal, but I assume this isn't the case\
    \ if I'm not training the model myself. I'm using the code directly from the repo:\r\
    \n\r\nfrom transformers import pipeline\r\n\r\ninstruct_pipeline = pipeline(model=\"\
    databricks/dolly-v2-12b\", trust_remote_code=True, device_map=\"auto\")\r\n\r\n\
    Any help would be appreciated!"
  created_at: 2023-04-13 16:40:14+00:00
  edited: false
  hidden: false
  id: 64383e7ee95aa634ce76af0e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-13T18:49:26.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>What model, 12B? g4dn are 16GB T4, so yes it doesn''t fit on the
          GPU and you''re running mostly on the CPU.<br>You can get it to run on the
          T4 if you load in 8-bit instead.<br>You can also just use a smaller model,
          like the 6.9B param version of Dolly 2.</p>

          <p>I recommend A10 instances (g5). The 12B model works with 8-bit, and loads
          the smaller models just fine. Note you should add torch_dtype=torch.bfloat16
          for A10 or A100s.<br>A100s certainly work.</p>

          '
        raw: "What model, 12B? g4dn are 16GB T4, so yes it doesn't fit on the GPU\
          \ and you're running mostly on the CPU.\nYou can get it to run on the T4\
          \ if you load in 8-bit instead.\nYou can also just use a smaller model,\
          \ like the 6.9B param version of Dolly 2.\n\nI recommend A10 instances (g5).\
          \ The 12B model works with 8-bit, and loads the smaller models just fine.\
          \ Note you should add torch_dtype=torch.bfloat16 for A10 or A100s. \nA100s\
          \ certainly work."
        updatedAt: '2023-04-13T18:49:26.741Z'
      numEdits: 0
      reactions: []
    id: 64384eb6dca82729226f4479
    type: comment
  author: srowen
  content: "What model, 12B? g4dn are 16GB T4, so yes it doesn't fit on the GPU and\
    \ you're running mostly on the CPU.\nYou can get it to run on the T4 if you load\
    \ in 8-bit instead.\nYou can also just use a smaller model, like the 6.9B param\
    \ version of Dolly 2.\n\nI recommend A10 instances (g5). The 12B model works with\
    \ 8-bit, and loads the smaller models just fine. Note you should add torch_dtype=torch.bfloat16\
    \ for A10 or A100s. \nA100s certainly work."
  created_at: 2023-04-13 17:49:26+00:00
  edited: false
  hidden: false
  id: 64384eb6dca82729226f4479
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-19T19:08:33.000Z'
    data:
      status: closed
    id: 64403c31dbd88206a83d29c9
    type: status-change
  author: srowen
  created_at: 2023-04-19 18:08:33+00:00
  id: 64403c31dbd88206a83d29c9
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 20
repo_id: databricks/dolly-v2-12b
repo_type: model
status: closed
target_branch: null
title: Databricks Cluster Settings
