!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tmatup
conflicting_files: null
created_at: 2023-04-15 20:58:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/52fec936267d82a04c2a53e9546a48c8.svg
      fullname: tmatup
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tmatup
      type: user
    createdAt: '2023-04-15T21:58:19.000Z'
    data:
      edited: true
      editors:
      - tmatup
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/52fec936267d82a04c2a53e9546a48c8.svg
          fullname: tmatup
          isHf: false
          isPro: false
          name: tmatup
          type: user
        html: "<p><strong>Describe the issue</strong><br>I was trying to train dolly\
          \ on my box. It runs fine when doing the following in Jupyter Notebook,\
          \ but failed w/o detailed errors when run the script under DeepSpeed, what\
          \ could be the reason?</p>\n<p>I have the following details captured</p>\n\
          <pre><code>from transformers import AutoTokenizer, AutoModelForCausalLM\n\
          model_checkpoint = \"EleutherAI/gpt-j-6B\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\
          model = AutoModelForCausalLM.from_pretrained(model_checkpoint)\n</code></pre>\n\
          <p><strong>ds_report output</strong></p>\n<pre><code>DeepSpeed C++/CUDA\
          \ extension op report\nNOTE: Ops not installed will be just-in-time (JIT)\
          \ compiled at\n      runtime if needed. Op compatibility means that your\
          \ system\n      meet the required dependencies to JIT install the op.\n\n\
          JIT compiled ops requires ninja\nninja .................. [OKAY]\n\nop name\
          \ ................ installed .. compatible\n\n [WARNING]  async_io requires\
          \ the dev libaio .so object and headers but these were not found.\n [WARNING]\
          \  async_io: please install the libaio-dev package with apt\n [WARNING]\
          \  If libaio is already installed (perhaps from source), try setting the\
          \ CFLAGS and LDFLAGS environment variables to where it can be found.\nasync_io\
          \ ............... [NO] ....... [NO]\ncpu_adagrad ............ [NO] .......\
          \ [OKAY]\ncpu_adam ............... [NO] ....... [OKAY]\nfused_adam .............\
          \ [NO] ....... [OKAY]\nfused_lamb ............. [NO] ....... [OKAY]\nquantizer\
          \ .............. [NO] ....... [OKAY]\nrandom_ltd ............. [NO] .......\
          \ [OKAY]\n [WARNING]  please install triton==1.0.0 if you want to use sparse\
          \ attention\nsparse_attn ............ [NO] ....... [NO]\nspatial_inference\
          \ ...... [NO] ....... [OKAY]\ntransformer ............ [NO] ....... [OKAY]\n\
          stochastic_transformer . [NO] ....... [OKAY]\ntransformer_inference .. [NO]\
          \ ....... [OKAY]\nutils .................. [NO] ....... [OKAY]\n\nDeepSpeed\
          \ general environment info:\ntorch install path ............... ['/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/torch']\n\
          torch version .................... 1.13.1+cu117\ndeepspeed install path\
          \ ........... ['/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/deepspeed']\n\
          deepspeed info ................... 0.8.0, unknown, unknown\ntorch cuda version\
          \ ............... 11.7\ntorch hip version ................ None\nnvcc version\
          \ ..................... 11.1\ndeepspeed wheel compiled w. ...... torch 0.0,\
          \ cuda 0.0\n</code></pre>\n<p><strong>System info (please complete the following\
          \ information):</strong></p>\n<ul>\n<li>OS: Ubuntu 20.04 LTS</li>\n<li>GPU\
          \ count and types: one machines with x8 A6000s]</li>\n<li>Python version:\
          \ 3.7.16</li>\n<li>Transformer version: 4.25.1</li>\n</ul>\n<pre><code>(py37)\
          \ ms:~/root/auto$ pip show transformers\nName: transformers\nVersion: 4.25.1\n\
          Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n\
          Home-page: https://github.com/huggingface/transformers\nAuthor: The Hugging\
          \ Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n\
          Author-email: transformers@huggingface.co\nLicense: Apache\nLocation: /home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages\n\
          Requires: filelock, huggingface-hub, importlib-metadata, numpy, packaging,\
          \ pyyaml, regex, requests, tokenizers, tqdm\nRequired-by:\n</code></pre>\n\
          <p><strong>Launcher context</strong><br>Either ran deepspeed under command\
          \ prompt or from inside python script (via sh command)</p>\n<p><strong>Logging\
          \ output</strong></p>\n<pre><code>2023-04-15 13:53:08 INFO [training.trainer]\
          \ Loading tatsu-lab/alpaca dataset\n2023-04-15 13:53:09 WARNING [datasets.builder]\
          \ Using custom data configuration tatsu-lab--alpaca-9b55fb286e3c7ab6\nDownloading\
          \ and preparing dataset parquet/tatsu-lab--alpaca to /home/tmatup/.cache/huggingface/datasets/tatsu-lab___parquet/tatsu-lab--alpaca-9b55fb286e3c7ab6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n\
          Downloading data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00, 1639.04it/s]\nExtracting\
          \ data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00, 989.46it/s]\n\
          Dataset parquet downloaded and prepared to /home/tmatup/.cache/huggingface/datasets/tatsu-lab___parquet/tatsu-lab--alpaca-9b55fb286e3c7ab6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec.\
          \ Subsequent calls will reuse this data.\n100%|\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00,\
          \ 270.22it/s]\n2023-04-15 13:53:09 INFO [training.trainer] Found 52002 rows\n\
          100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          | 53/53 [00:00&lt;00:00, 113.92ba/s]\n100%|\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          | 51974/51974 [00:06&lt;00:00, 8382.97ex/s]\n2023-04-15 13:53:16 INFO [training.trainer]\
          \ Loading tokenizer for EleutherAI/gpt-j-6B\n2023-04-15 13:53:17 INFO [__main__]\
          \ Start training...\n2023-04-15 13:53:19 INFO [__main__] [2023-04-15 13:53:19,461]\
          \ [WARNING] [runner.py:186:fetch_hostfile] Unable to find hostfile, will\
          \ proceed with training with local resources only.\n\n2023-04-15 13:53:19\
          \ INFO [__main__] [2023-04-15 13:53:19,528] [INFO] [runner.py:548:main]\
          \ cmd = /home/tmatup/anaconda3/envs/py37/bin/python -u -m deepspeed.launcher.launch\
          \ --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1\
          \ --master_port=29500 --module --enable_each_rank_log=None training.trainer\
          \ --deepspeed /home/tmatup/root/dolly/config/ds_z3_bf16_config.json --epochs\
          \ 1 --local-output-dir /home/tmatup/models/dolly/training/dolly__1681591988\
          \ --per-device-train-batch-size 1 --per-device-eval-batch-size 1 --lr 1e-5\n\
          \n2023-04-15 13:53:21 INFO [__main__] [2023-04-15 13:53:21,907] [INFO] [launch.py:142:main]\
          \ WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}\n\n2023-04-15\
          \ 13:53:21 INFO [__main__] [2023-04-15 13:53:21,907] [INFO] [launch.py:149:main]\
          \ nnodes=1, num_local_procs=8, node_rank=0\n\n2023-04-15 13:53:21 INFO [__main__]\
          \ [2023-04-15 13:53:21,907] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(&lt;class\
          \ 'list'&gt;, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})\n\n2023-04-15 13:53:21\
          \ INFO [__main__] [2023-04-15 13:53:21,907] [INFO] [launch.py:162:main]\
          \ dist_world_size=8\n\n2023-04-15 13:53:21 INFO [__main__] [2023-04-15 13:53:21,907]\
          \ [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n\
          \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__]\
          \ Loading tokenizer for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR\
          \ [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading tokenizer for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__]\
          \ Loading tokenizer for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR\
          \ [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading tokenizer for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__]\
          \ Loading tokenizer for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR\
          \ [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading tokenizer for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__]\
          \ Loading tokenizer for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR\
          \ [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading tokenizer for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__]\
          \ Loading model for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR [__main__]\
          \ 2023-04-15 13:53:26 INFO [__main__] Loading model for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__]\
          \ Loading model for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:27 ERROR [__main__]\
          \ 2023-04-15 13:53:27 INFO [__main__] Loading model for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:27 ERROR [__main__] 2023-04-15 13:53:27 INFO [__main__]\
          \ Loading model for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:27 ERROR [__main__]\
          \ 2023-04-15 13:53:27 INFO [__main__] Loading model for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:27 ERROR [__main__] 2023-04-15 13:53:27 INFO [__main__]\
          \ Loading model for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:27 ERROR [__main__]\
          \ 2023-04-15 13:53:27 INFO [__main__] Loading model for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:54:52 INFO [__main__] [2023-04-15 13:54:52,905] [INFO] [launch.py:318:sigkill_handler]\
          \ Killing subprocess 1669300\n\n2023-04-15 13:54:54 INFO [__main__] [2023-04-15\
          \ 13:54:54,476] [INFO] [launch.py:318:sigkill_handler] Killing subprocess\
          \ 1669301\n\n2023-04-15 13:54:55 INFO [__main__] [2023-04-15 13:54:55,807]\
          \ [INFO] [launch.py:318:sigkill_handler] Killing subprocess 1669302\n\n\
          2023-04-15 13:54:57 INFO [__main__] [2023-04-15 13:54:57,577] [INFO] [launch.py:318:sigkill_handler]\
          \ Killing subprocess 1669303\n\n2023-04-15 13:54:59 INFO [__main__] [2023-04-15\
          \ 13:54:59,349] [INFO] [launch.py:318:sigkill_handler] Killing subprocess\
          \ 1669304\n\n2023-04-15 13:55:01 INFO [__main__] [2023-04-15 13:55:01,202]\
          \ [INFO] [launch.py:318:sigkill_handler] Killing subprocess 1669305\n\n\
          2023-04-15 13:55:02 INFO [__main__] [2023-04-15 13:55:02,690] [INFO] [launch.py:318:sigkill_handler]\
          \ Killing subprocess 1669306\n\n2023-04-15 13:55:04 INFO [__main__] [2023-04-15\
          \ 13:55:04,583] [INFO] [launch.py:318:sigkill_handler] Killing subprocess\
          \ 1669352\n\n2023-04-15 13:55:04 INFO [__main__] [2023-04-15 13:55:04,583]\
          \ [ERROR] [launch.py:324:sigkill_handler] ['/home/tmatup/anaconda3/envs/py37/bin/python',\
          \ '-u', '-m', 'training.trainer', '--local_rank=7', '--deepspeed', '/home/tmatup/root/dolly/config/ds_z3_bf16_config.json',\
          \ '--epochs', '1', '--local-output-dir', '/home/tmatup/models/dolly/training/dolly__1681591988',\
          \ '--per-device-train-batch-size', '1', '--per-device-eval-batch-size',\
          \ '1', '--lr', '1e-5'] exits with return code = -9\n\nTraceback (most recent\
          \ call last):\n  File \"train_dolly.py\", line 68, in &lt;module&gt;\n \
          \   _err=process_err\n  File \"/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/sh.py\"\
          , line 1524, in __call__\n    return RunningCommand(cmd, call_args, stdin,\
          \ stdout, stderr)\n  File \"/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/sh.py\"\
          , line 788, in __init__\n    self.wait()\n  File \"/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/sh.py\"\
          , line 845, in wait\n    self.handle_command_exit_code(exit_code)\n  File\
          \ \"/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/sh.py\"\
          , line 869, in handle_command_exit_code\n    raise exc\nsh.ErrorReturnCode_247:\n\
          \n  RAN: /home/tmatup/anaconda3/envs/py37/bin/deepspeed --num_gpus 8 --module\
          \ training.trainer --deepspeed /home/tmatup/root/dolly/config/ds_z3_bf16_config.json\
          \ --epochs 1 --local-output-dir /home/tmatup/models/dolly/training/dolly__1681591988\
          \ --per-device-train-batch-size 1 --per-device-eval-batch-size 1 --lr 1e-5\n\
          \n  STDOUT:\n\n\n  STDERR:\n</code></pre>\n"
        raw: "**Describe the issue**\nI was trying to train dolly on my box. It runs\
          \ fine when doing the following in Jupyter Notebook, but failed w/o detailed\
          \ errors when run the script under DeepSpeed, what could be the reason?\n\
          \nI have the following details captured\n\n```\nfrom transformers import\
          \ AutoTokenizer, AutoModelForCausalLM\nmodel_checkpoint = \"EleutherAI/gpt-j-6B\"\
          \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = AutoModelForCausalLM.from_pretrained(model_checkpoint)\n\
          ```\n\n**ds_report output**\n\n```\nDeepSpeed C++/CUDA extension op report\n\
          NOTE: Ops not installed will be just-in-time (JIT) compiled at\n      runtime\
          \ if needed. Op compatibility means that your system\n      meet the required\
          \ dependencies to JIT install the op.\n\nJIT compiled ops requires ninja\n\
          ninja .................. [OKAY]\n\nop name ................ installed ..\
          \ compatible\n\n [WARNING]  async_io requires the dev libaio .so object\
          \ and headers but these were not found.\n [WARNING]  async_io: please install\
          \ the libaio-dev package with apt\n [WARNING]  If libaio is already installed\
          \ (perhaps from source), try setting the CFLAGS and LDFLAGS environment\
          \ variables to where it can be found.\nasync_io ............... [NO] .......\
          \ [NO]\ncpu_adagrad ............ [NO] ....... [OKAY]\ncpu_adam ...............\
          \ [NO] ....... [OKAY]\nfused_adam ............. [NO] ....... [OKAY]\nfused_lamb\
          \ ............. [NO] ....... [OKAY]\nquantizer .............. [NO] .......\
          \ [OKAY]\nrandom_ltd ............. [NO] ....... [OKAY]\n [WARNING]  please\
          \ install triton==1.0.0 if you want to use sparse attention\nsparse_attn\
          \ ............ [NO] ....... [NO]\nspatial_inference ...... [NO] .......\
          \ [OKAY]\ntransformer ............ [NO] ....... [OKAY]\nstochastic_transformer\
          \ . [NO] ....... [OKAY]\ntransformer_inference .. [NO] ....... [OKAY]\n\
          utils .................. [NO] ....... [OKAY]\n\nDeepSpeed general environment\
          \ info:\ntorch install path ............... ['/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/torch']\n\
          torch version .................... 1.13.1+cu117\ndeepspeed install path\
          \ ........... ['/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/deepspeed']\n\
          deepspeed info ................... 0.8.0, unknown, unknown\ntorch cuda version\
          \ ............... 11.7\ntorch hip version ................ None\nnvcc version\
          \ ..................... 11.1\ndeepspeed wheel compiled w. ...... torch 0.0,\
          \ cuda 0.0\n```\n\n**System info (please complete the following information):**\n\
          \ - OS: Ubuntu 20.04 LTS\n - GPU count and types: one machines with x8 A6000s]\n\
          \ - Python version: 3.7.16\n - Transformer version: 4.25.1\n\n```\n(py37)\
          \ ms:~/root/auto$ pip show transformers\nName: transformers\nVersion: 4.25.1\n\
          Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n\
          Home-page: https://github.com/huggingface/transformers\nAuthor: The Hugging\
          \ Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n\
          Author-email: transformers@huggingface.co\nLicense: Apache\nLocation: /home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages\n\
          Requires: filelock, huggingface-hub, importlib-metadata, numpy, packaging,\
          \ pyyaml, regex, requests, tokenizers, tqdm\nRequired-by:\n```\n\n**Launcher\
          \ context**\nEither ran deepspeed under command prompt or from inside python\
          \ script (via sh command)\n\n**Logging output**\n\n```\n2023-04-15 13:53:08\
          \ INFO [training.trainer] Loading tatsu-lab/alpaca dataset\n2023-04-15 13:53:09\
          \ WARNING [datasets.builder] Using custom data configuration tatsu-lab--alpaca-9b55fb286e3c7ab6\n\
          Downloading and preparing dataset parquet/tatsu-lab--alpaca to /home/tmatup/.cache/huggingface/datasets/tatsu-lab___parquet/tatsu-lab--alpaca-9b55fb286e3c7ab6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n\
          Downloading data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 1639.04it/s]\nExtracting\
          \ data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 989.46it/s]\nDataset\
          \ parquet downloaded and prepared to /home/tmatup/.cache/huggingface/datasets/tatsu-lab___parquet/tatsu-lab--alpaca-9b55fb286e3c7ab6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec.\
          \ Subsequent calls will reuse this data.\n100%|\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,\
          \ 270.22it/s]\n2023-04-15 13:53:09 INFO [training.trainer] Found 52002 rows\n\
          100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          | 53/53 [00:00<00:00, 113.92ba/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51974/51974\
          \ [00:06<00:00, 8382.97ex/s]\n2023-04-15 13:53:16 INFO [training.trainer]\
          \ Loading tokenizer for EleutherAI/gpt-j-6B\n2023-04-15 13:53:17 INFO [__main__]\
          \ Start training...\n2023-04-15 13:53:19 INFO [__main__] [2023-04-15 13:53:19,461]\
          \ [WARNING] [runner.py:186:fetch_hostfile] Unable to find hostfile, will\
          \ proceed with training with local resources only.\n\n2023-04-15 13:53:19\
          \ INFO [__main__] [2023-04-15 13:53:19,528] [INFO] [runner.py:548:main]\
          \ cmd = /home/tmatup/anaconda3/envs/py37/bin/python -u -m deepspeed.launcher.launch\
          \ --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1\
          \ --master_port=29500 --module --enable_each_rank_log=None training.trainer\
          \ --deepspeed /home/tmatup/root/dolly/config/ds_z3_bf16_config.json --epochs\
          \ 1 --local-output-dir /home/tmatup/models/dolly/training/dolly__1681591988\
          \ --per-device-train-batch-size 1 --per-device-eval-batch-size 1 --lr 1e-5\n\
          \n2023-04-15 13:53:21 INFO [__main__] [2023-04-15 13:53:21,907] [INFO] [launch.py:142:main]\
          \ WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}\n\n2023-04-15\
          \ 13:53:21 INFO [__main__] [2023-04-15 13:53:21,907] [INFO] [launch.py:149:main]\
          \ nnodes=1, num_local_procs=8, node_rank=0\n\n2023-04-15 13:53:21 INFO [__main__]\
          \ [2023-04-15 13:53:21,907] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class\
          \ 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})\n\n2023-04-15 13:53:21\
          \ INFO [__main__] [2023-04-15 13:53:21,907] [INFO] [launch.py:162:main]\
          \ dist_world_size=8\n\n2023-04-15 13:53:21 INFO [__main__] [2023-04-15 13:53:21,907]\
          \ [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n\
          \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__]\
          \ Loading tokenizer for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR\
          \ [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading tokenizer for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__]\
          \ Loading tokenizer for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR\
          \ [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading tokenizer for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__]\
          \ Loading tokenizer for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR\
          \ [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading tokenizer for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__]\
          \ Loading tokenizer for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR\
          \ [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading tokenizer for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__]\
          \ Loading model for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR [__main__]\
          \ 2023-04-15 13:53:26 INFO [__main__] Loading model for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__]\
          \ Loading model for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:27 ERROR [__main__]\
          \ 2023-04-15 13:53:27 INFO [__main__] Loading model for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:27 ERROR [__main__] 2023-04-15 13:53:27 INFO [__main__]\
          \ Loading model for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:27 ERROR [__main__]\
          \ 2023-04-15 13:53:27 INFO [__main__] Loading model for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:53:27 ERROR [__main__] 2023-04-15 13:53:27 INFO [__main__]\
          \ Loading model for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:27 ERROR [__main__]\
          \ 2023-04-15 13:53:27 INFO [__main__] Loading model for EleutherAI/gpt-j-6B\n\
          \n2023-04-15 13:54:52 INFO [__main__] [2023-04-15 13:54:52,905] [INFO] [launch.py:318:sigkill_handler]\
          \ Killing subprocess 1669300\n\n2023-04-15 13:54:54 INFO [__main__] [2023-04-15\
          \ 13:54:54,476] [INFO] [launch.py:318:sigkill_handler] Killing subprocess\
          \ 1669301\n\n2023-04-15 13:54:55 INFO [__main__] [2023-04-15 13:54:55,807]\
          \ [INFO] [launch.py:318:sigkill_handler] Killing subprocess 1669302\n\n\
          2023-04-15 13:54:57 INFO [__main__] [2023-04-15 13:54:57,577] [INFO] [launch.py:318:sigkill_handler]\
          \ Killing subprocess 1669303\n\n2023-04-15 13:54:59 INFO [__main__] [2023-04-15\
          \ 13:54:59,349] [INFO] [launch.py:318:sigkill_handler] Killing subprocess\
          \ 1669304\n\n2023-04-15 13:55:01 INFO [__main__] [2023-04-15 13:55:01,202]\
          \ [INFO] [launch.py:318:sigkill_handler] Killing subprocess 1669305\n\n\
          2023-04-15 13:55:02 INFO [__main__] [2023-04-15 13:55:02,690] [INFO] [launch.py:318:sigkill_handler]\
          \ Killing subprocess 1669306\n\n2023-04-15 13:55:04 INFO [__main__] [2023-04-15\
          \ 13:55:04,583] [INFO] [launch.py:318:sigkill_handler] Killing subprocess\
          \ 1669352\n\n2023-04-15 13:55:04 INFO [__main__] [2023-04-15 13:55:04,583]\
          \ [ERROR] [launch.py:324:sigkill_handler] ['/home/tmatup/anaconda3/envs/py37/bin/python',\
          \ '-u', '-m', 'training.trainer', '--local_rank=7', '--deepspeed', '/home/tmatup/root/dolly/config/ds_z3_bf16_config.json',\
          \ '--epochs', '1', '--local-output-dir', '/home/tmatup/models/dolly/training/dolly__1681591988',\
          \ '--per-device-train-batch-size', '1', '--per-device-eval-batch-size',\
          \ '1', '--lr', '1e-5'] exits with return code = -9\n\nTraceback (most recent\
          \ call last):\n  File \"train_dolly.py\", line 68, in <module>\n    _err=process_err\n\
          \  File \"/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/sh.py\"\
          , line 1524, in __call__\n    return RunningCommand(cmd, call_args, stdin,\
          \ stdout, stderr)\n  File \"/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/sh.py\"\
          , line 788, in __init__\n    self.wait()\n  File \"/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/sh.py\"\
          , line 845, in wait\n    self.handle_command_exit_code(exit_code)\n  File\
          \ \"/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/sh.py\"\
          , line 869, in handle_command_exit_code\n    raise exc\nsh.ErrorReturnCode_247:\n\
          \n  RAN: /home/tmatup/anaconda3/envs/py37/bin/deepspeed --num_gpus 8 --module\
          \ training.trainer --deepspeed /home/tmatup/root/dolly/config/ds_z3_bf16_config.json\
          \ --epochs 1 --local-output-dir /home/tmatup/models/dolly/training/dolly__1681591988\
          \ --per-device-train-batch-size 1 --per-device-eval-batch-size 1 --lr 1e-5\n\
          \n  STDOUT:\n\n\n  STDERR:\n```"
        updatedAt: '2023-04-15T21:59:37.922Z'
      numEdits: 3
      reactions: []
    id: 643b1dfbb54b34655653bf7e
    type: comment
  author: tmatup
  content: "**Describe the issue**\nI was trying to train dolly on my box. It runs\
    \ fine when doing the following in Jupyter Notebook, but failed w/o detailed errors\
    \ when run the script under DeepSpeed, what could be the reason?\n\nI have the\
    \ following details captured\n\n```\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\
    model_checkpoint = \"EleutherAI/gpt-j-6B\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\
    model = AutoModelForCausalLM.from_pretrained(model_checkpoint)\n```\n\n**ds_report\
    \ output**\n\n```\nDeepSpeed C++/CUDA extension op report\nNOTE: Ops not installed\
    \ will be just-in-time (JIT) compiled at\n      runtime if needed. Op compatibility\
    \ means that your system\n      meet the required dependencies to JIT install\
    \ the op.\n\nJIT compiled ops requires ninja\nninja .................. [OKAY]\n\
    \nop name ................ installed .. compatible\n\n [WARNING]  async_io requires\
    \ the dev libaio .so object and headers but these were not found.\n [WARNING]\
    \  async_io: please install the libaio-dev package with apt\n [WARNING]  If libaio\
    \ is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS\
    \ environment variables to where it can be found.\nasync_io ............... [NO]\
    \ ....... [NO]\ncpu_adagrad ............ [NO] ....... [OKAY]\ncpu_adam ...............\
    \ [NO] ....... [OKAY]\nfused_adam ............. [NO] ....... [OKAY]\nfused_lamb\
    \ ............. [NO] ....... [OKAY]\nquantizer .............. [NO] ....... [OKAY]\n\
    random_ltd ............. [NO] ....... [OKAY]\n [WARNING]  please install triton==1.0.0\
    \ if you want to use sparse attention\nsparse_attn ............ [NO] ....... [NO]\n\
    spatial_inference ...... [NO] ....... [OKAY]\ntransformer ............ [NO] .......\
    \ [OKAY]\nstochastic_transformer . [NO] ....... [OKAY]\ntransformer_inference\
    \ .. [NO] ....... [OKAY]\nutils .................. [NO] ....... [OKAY]\n\nDeepSpeed\
    \ general environment info:\ntorch install path ............... ['/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/torch']\n\
    torch version .................... 1.13.1+cu117\ndeepspeed install path ...........\
    \ ['/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/deepspeed']\n\
    deepspeed info ................... 0.8.0, unknown, unknown\ntorch cuda version\
    \ ............... 11.7\ntorch hip version ................ None\nnvcc version\
    \ ..................... 11.1\ndeepspeed wheel compiled w. ...... torch 0.0, cuda\
    \ 0.0\n```\n\n**System info (please complete the following information):**\n -\
    \ OS: Ubuntu 20.04 LTS\n - GPU count and types: one machines with x8 A6000s]\n\
    \ - Python version: 3.7.16\n - Transformer version: 4.25.1\n\n```\n(py37) ms:~/root/auto$\
    \ pip show transformers\nName: transformers\nVersion: 4.25.1\nSummary: State-of-the-art\
    \ Machine Learning for JAX, PyTorch and TensorFlow\nHome-page: https://github.com/huggingface/transformers\n\
    Author: The Hugging Face team (past and future) with the help of all our contributors\
    \ (https://github.com/huggingface/transformers/graphs/contributors)\nAuthor-email:\
    \ transformers@huggingface.co\nLicense: Apache\nLocation: /home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages\n\
    Requires: filelock, huggingface-hub, importlib-metadata, numpy, packaging, pyyaml,\
    \ regex, requests, tokenizers, tqdm\nRequired-by:\n```\n\n**Launcher context**\n\
    Either ran deepspeed under command prompt or from inside python script (via sh\
    \ command)\n\n**Logging output**\n\n```\n2023-04-15 13:53:08 INFO [training.trainer]\
    \ Loading tatsu-lab/alpaca dataset\n2023-04-15 13:53:09 WARNING [datasets.builder]\
    \ Using custom data configuration tatsu-lab--alpaca-9b55fb286e3c7ab6\nDownloading\
    \ and preparing dataset parquet/tatsu-lab--alpaca to /home/tmatup/.cache/huggingface/datasets/tatsu-lab___parquet/tatsu-lab--alpaca-9b55fb286e3c7ab6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n\
    Downloading data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 1639.04it/s]\nExtracting data\
    \ files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 989.46it/s]\nDataset parquet\
    \ downloaded and prepared to /home/tmatup/.cache/huggingface/datasets/tatsu-lab___parquet/tatsu-lab--alpaca-9b55fb286e3c7ab6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec.\
    \ Subsequent calls will reuse this data.\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 270.22it/s]\n2023-04-15\
    \ 13:53:09 INFO [training.trainer] Found 52002 rows\n100%|\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588| 53/53 [00:00<00:00, 113.92ba/s]\n\
    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588| 51974/51974 [00:06<00:00, 8382.97ex/s]\n2023-04-15 13:53:16\
    \ INFO [training.trainer] Loading tokenizer for EleutherAI/gpt-j-6B\n2023-04-15\
    \ 13:53:17 INFO [__main__] Start training...\n2023-04-15 13:53:19 INFO [__main__]\
    \ [2023-04-15 13:53:19,461] [WARNING] [runner.py:186:fetch_hostfile] Unable to\
    \ find hostfile, will proceed with training with local resources only.\n\n2023-04-15\
    \ 13:53:19 INFO [__main__] [2023-04-15 13:53:19,528] [INFO] [runner.py:548:main]\
    \ cmd = /home/tmatup/anaconda3/envs/py37/bin/python -u -m deepspeed.launcher.launch\
    \ --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1\
    \ --master_port=29500 --module --enable_each_rank_log=None training.trainer --deepspeed\
    \ /home/tmatup/root/dolly/config/ds_z3_bf16_config.json --epochs 1 --local-output-dir\
    \ /home/tmatup/models/dolly/training/dolly__1681591988 --per-device-train-batch-size\
    \ 1 --per-device-eval-batch-size 1 --lr 1e-5\n\n2023-04-15 13:53:21 INFO [__main__]\
    \ [2023-04-15 13:53:21,907] [INFO] [launch.py:142:main] WORLD INFO DICT: {'localhost':\
    \ [0, 1, 2, 3, 4, 5, 6, 7]}\n\n2023-04-15 13:53:21 INFO [__main__] [2023-04-15\
    \ 13:53:21,907] [INFO] [launch.py:149:main] nnodes=1, num_local_procs=8, node_rank=0\n\
    \n2023-04-15 13:53:21 INFO [__main__] [2023-04-15 13:53:21,907] [INFO] [launch.py:161:main]\
    \ global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4,\
    \ 5, 6, 7]})\n\n2023-04-15 13:53:21 INFO [__main__] [2023-04-15 13:53:21,907]\
    \ [INFO] [launch.py:162:main] dist_world_size=8\n\n2023-04-15 13:53:21 INFO [__main__]\
    \ [2023-04-15 13:53:21,907] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n\
    \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading\
    \ tokenizer for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15\
    \ 13:53:26 INFO [__main__] Loading tokenizer for EleutherAI/gpt-j-6B\n\n2023-04-15\
    \ 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading tokenizer\
    \ for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26\
    \ INFO [__main__] Loading tokenizer for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26\
    \ ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading tokenizer for EleutherAI/gpt-j-6B\n\
    \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading\
    \ tokenizer for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15\
    \ 13:53:26 INFO [__main__] Loading tokenizer for EleutherAI/gpt-j-6B\n\n2023-04-15\
    \ 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading tokenizer\
    \ for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26\
    \ INFO [__main__] Loading model for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:26\
    \ ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading model for EleutherAI/gpt-j-6B\n\
    \n2023-04-15 13:53:26 ERROR [__main__] 2023-04-15 13:53:26 INFO [__main__] Loading\
    \ model for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:27 ERROR [__main__] 2023-04-15\
    \ 13:53:27 INFO [__main__] Loading model for EleutherAI/gpt-j-6B\n\n2023-04-15\
    \ 13:53:27 ERROR [__main__] 2023-04-15 13:53:27 INFO [__main__] Loading model\
    \ for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:27 ERROR [__main__] 2023-04-15 13:53:27\
    \ INFO [__main__] Loading model for EleutherAI/gpt-j-6B\n\n2023-04-15 13:53:27\
    \ ERROR [__main__] 2023-04-15 13:53:27 INFO [__main__] Loading model for EleutherAI/gpt-j-6B\n\
    \n2023-04-15 13:53:27 ERROR [__main__] 2023-04-15 13:53:27 INFO [__main__] Loading\
    \ model for EleutherAI/gpt-j-6B\n\n2023-04-15 13:54:52 INFO [__main__] [2023-04-15\
    \ 13:54:52,905] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 1669300\n\
    \n2023-04-15 13:54:54 INFO [__main__] [2023-04-15 13:54:54,476] [INFO] [launch.py:318:sigkill_handler]\
    \ Killing subprocess 1669301\n\n2023-04-15 13:54:55 INFO [__main__] [2023-04-15\
    \ 13:54:55,807] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 1669302\n\
    \n2023-04-15 13:54:57 INFO [__main__] [2023-04-15 13:54:57,577] [INFO] [launch.py:318:sigkill_handler]\
    \ Killing subprocess 1669303\n\n2023-04-15 13:54:59 INFO [__main__] [2023-04-15\
    \ 13:54:59,349] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 1669304\n\
    \n2023-04-15 13:55:01 INFO [__main__] [2023-04-15 13:55:01,202] [INFO] [launch.py:318:sigkill_handler]\
    \ Killing subprocess 1669305\n\n2023-04-15 13:55:02 INFO [__main__] [2023-04-15\
    \ 13:55:02,690] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 1669306\n\
    \n2023-04-15 13:55:04 INFO [__main__] [2023-04-15 13:55:04,583] [INFO] [launch.py:318:sigkill_handler]\
    \ Killing subprocess 1669352\n\n2023-04-15 13:55:04 INFO [__main__] [2023-04-15\
    \ 13:55:04,583] [ERROR] [launch.py:324:sigkill_handler] ['/home/tmatup/anaconda3/envs/py37/bin/python',\
    \ '-u', '-m', 'training.trainer', '--local_rank=7', '--deepspeed', '/home/tmatup/root/dolly/config/ds_z3_bf16_config.json',\
    \ '--epochs', '1', '--local-output-dir', '/home/tmatup/models/dolly/training/dolly__1681591988',\
    \ '--per-device-train-batch-size', '1', '--per-device-eval-batch-size', '1', '--lr',\
    \ '1e-5'] exits with return code = -9\n\nTraceback (most recent call last):\n\
    \  File \"train_dolly.py\", line 68, in <module>\n    _err=process_err\n  File\
    \ \"/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/sh.py\", line\
    \ 1524, in __call__\n    return RunningCommand(cmd, call_args, stdin, stdout,\
    \ stderr)\n  File \"/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/sh.py\"\
    , line 788, in __init__\n    self.wait()\n  File \"/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/sh.py\"\
    , line 845, in wait\n    self.handle_command_exit_code(exit_code)\n  File \"/home/tmatup/anaconda3/envs/py37/lib/python3.7/site-packages/sh.py\"\
    , line 869, in handle_command_exit_code\n    raise exc\nsh.ErrorReturnCode_247:\n\
    \n  RAN: /home/tmatup/anaconda3/envs/py37/bin/deepspeed --num_gpus 8 --module\
    \ training.trainer --deepspeed /home/tmatup/root/dolly/config/ds_z3_bf16_config.json\
    \ --epochs 1 --local-output-dir /home/tmatup/models/dolly/training/dolly__1681591988\
    \ --per-device-train-batch-size 1 --per-device-eval-batch-size 1 --lr 1e-5\n\n\
    \  STDOUT:\n\n\n  STDERR:\n```"
  created_at: 2023-04-15 20:58:19+00:00
  edited: true
  hidden: false
  id: 643b1dfbb54b34655653bf7e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
      fullname: Matthew Hayes
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: matthayes
      type: user
    createdAt: '2023-04-15T22:06:55.000Z'
    data:
      edited: false
      editors:
      - matthayes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
          fullname: Matthew Hayes
          isHf: false
          isPro: false
          name: matthayes
          type: user
        html: '<p>Do you know how much memory the GPUs have?  My first thought would
          be OOM.  You could try lowering the batch size and see if that helps.</p>

          '
        raw: Do you know how much memory the GPUs have?  My first thought would be
          OOM.  You could try lowering the batch size and see if that helps.
        updatedAt: '2023-04-15T22:06:55.796Z'
      numEdits: 0
      reactions: []
    id: 643b1fffacf5326d69ec1f84
    type: comment
  author: matthayes
  content: Do you know how much memory the GPUs have?  My first thought would be OOM.  You
    could try lowering the batch size and see if that helps.
  created_at: 2023-04-15 21:06:55+00:00
  edited: false
  hidden: false
  id: 643b1fffacf5326d69ec1f84
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/52fec936267d82a04c2a53e9546a48c8.svg
      fullname: tmatup
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tmatup
      type: user
    createdAt: '2023-04-16T05:59:53.000Z'
    data:
      edited: false
      editors:
      - tmatup
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/52fec936267d82a04c2a53e9546a48c8.svg
          fullname: tmatup
          isHf: false
          isPro: false
          name: tmatup
          type: user
        html: '<p>Totally 8 GPUs, each has 47GB. I tried to limit DeepSpeed to use
          only two of GPUs by doing <code>--include localhost:3,5</code>, it seems
          that DeepSpeed still tries to allocate memory from GPU 0 and GPU 1, both
          of which already has very limited memory left for other trainings going
          on.</p>

          '
        raw: Totally 8 GPUs, each has 47GB. I tried to limit DeepSpeed to use only
          two of GPUs by doing `--include localhost:3,5`, it seems that DeepSpeed
          still tries to allocate memory from GPU 0 and GPU 1, both of which already
          has very limited memory left for other trainings going on.
        updatedAt: '2023-04-16T05:59:53.732Z'
      numEdits: 0
      reactions: []
    id: 643b8ed918e9973bc824fb07
    type: comment
  author: tmatup
  content: Totally 8 GPUs, each has 47GB. I tried to limit DeepSpeed to use only two
    of GPUs by doing `--include localhost:3,5`, it seems that DeepSpeed still tries
    to allocate memory from GPU 0 and GPU 1, both of which already has very limited
    memory left for other trainings going on.
  created_at: 2023-04-16 04:59:53+00:00
  edited: false
  hidden: false
  id: 643b8ed918e9973bc824fb07
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
      fullname: Matthew Hayes
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: matthayes
      type: user
    createdAt: '2023-04-16T19:23:17.000Z'
    data:
      edited: false
      editors:
      - matthayes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
          fullname: Matthew Hayes
          isHf: false
          isPro: false
          name: matthayes
          type: user
        html: '<p>You might need to use all 8 GPUs.</p>

          '
        raw: You might need to use all 8 GPUs.
        updatedAt: '2023-04-16T19:23:17.014Z'
      numEdits: 0
      reactions: []
    id: 643c4b2525c7610a1cd71a30
    type: comment
  author: matthayes
  content: You might need to use all 8 GPUs.
  created_at: 2023-04-16 18:23:17+00:00
  edited: false
  hidden: false
  id: 643c4b2525c7610a1cd71a30
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-16T20:01:00.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Looks like they''re all being used: Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7<br>But
          if you have heterogeneous GPUs, it''s possible that it''s affecting deepspeed''s
          allocations, yeah. I haven''t looked into this. But here is some documentation
          about how it reasons about memory: <a href="https://huggingface.co/docs/transformers/main_classes/deepspeed#memory-requirements">https://huggingface.co/docs/transformers/main_classes/deepspeed#memory-requirements</a>
          May not be the issue, but may be that you have to configure HF or deepspeed
          differently to have it load on different GPUs. Or maybe exclude the small
          GPUs?</p>

          '
        raw: 'Looks like they''re all being used: Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

          But if you have heterogeneous GPUs, it''s possible that it''s affecting
          deepspeed''s allocations, yeah. I haven''t looked into this. But here is
          some documentation about how it reasons about memory: https://huggingface.co/docs/transformers/main_classes/deepspeed#memory-requirements
          May not be the issue, but may be that you have to configure HF or deepspeed
          differently to have it load on different GPUs. Or maybe exclude the small
          GPUs?'
        updatedAt: '2023-04-16T20:01:00.850Z'
      numEdits: 0
      reactions: []
    id: 643c53fc2d67f0ed22f9c900
    type: comment
  author: srowen
  content: 'Looks like they''re all being used: Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

    But if you have heterogeneous GPUs, it''s possible that it''s affecting deepspeed''s
    allocations, yeah. I haven''t looked into this. But here is some documentation
    about how it reasons about memory: https://huggingface.co/docs/transformers/main_classes/deepspeed#memory-requirements
    May not be the issue, but may be that you have to configure HF or deepspeed differently
    to have it load on different GPUs. Or maybe exclude the small GPUs?'
  created_at: 2023-04-16 19:01:00+00:00
  edited: false
  hidden: false
  id: 643c53fc2d67f0ed22f9c900
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/52fec936267d82a04c2a53e9546a48c8.svg
      fullname: tmatup
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tmatup
      type: user
    createdAt: '2023-04-16T21:19:48.000Z'
    data:
      edited: false
      editors:
      - tmatup
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/52fec936267d82a04c2a53e9546a48c8.svg
          fullname: tmatup
          isHf: false
          isPro: false
          name: tmatup
          type: user
        html: "<p>Yeah, <span data-props=\"{&quot;user&quot;:&quot;srowen&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/srowen\"\
          >@<span class=\"underline\">srowen</span></a></span>\n\n\t</span></span>,\
          \ that was from the earlier run. I tried limiting to the two GPUs having\
          \ enough memory later on and ran into a different memory allocation issue\
          \ as I stated in my last comment. I also tried exclude, didn't work. What's\
          \ baffled me is why it still always tries to allocate from GPU 0 and GPU\
          \ 1, ignoring the explicitly assigned GPUs 3 and 5.</p>\n"
        raw: Yeah, @srowen, that was from the earlier run. I tried limiting to the
          two GPUs having enough memory later on and ran into a different memory allocation
          issue as I stated in my last comment. I also tried exclude, didn't work.
          What's baffled me is why it still always tries to allocate from GPU 0 and
          GPU 1, ignoring the explicitly assigned GPUs 3 and 5.
        updatedAt: '2023-04-16T21:19:48.213Z'
      numEdits: 0
      reactions: []
    id: 643c66742d67f0ed22fa2f41
    type: comment
  author: tmatup
  content: Yeah, @srowen, that was from the earlier run. I tried limiting to the two
    GPUs having enough memory later on and ran into a different memory allocation
    issue as I stated in my last comment. I also tried exclude, didn't work. What's
    baffled me is why it still always tries to allocate from GPU 0 and GPU 1, ignoring
    the explicitly assigned GPUs 3 and 5.
  created_at: 2023-04-16 20:19:48+00:00
  edited: false
  hidden: false
  id: 643c66742d67f0ed22fa2f41
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-28T13:57:23.000Z'
    data:
      status: closed
    id: 644bd0c3194e124dacb1cb54
    type: status-change
  author: srowen
  created_at: 2023-04-28 12:57:23+00:00
  id: 644bd0c3194e124dacb1cb54
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 32
repo_id: databricks/dolly-v2-12b
repo_type: model
status: closed
target_branch: null
title: Failed loading tokenizer and model on training
