!!python/object:huggingface_hub.community.DiscussionWithDetails
author: xy-covey
conflicting_files: null
created_at: 2023-04-12 22:04:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1cc964f7d10c95f0337784b0423c0787.svg
      fullname: XY
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xy-covey
      type: user
    createdAt: '2023-04-12T23:04:10.000Z'
    data:
      edited: false
      editors:
      - xy-covey
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1cc964f7d10c95f0337784b0423c0787.svg
          fullname: XY
          isHf: false
          isPro: false
          name: xy-covey
          type: user
        html: '<p>I''m experimenting dolly with the aim to use it in the production.
          In my experiment, I provided a roughly 400 words resume and asked questions
          like how many years this candidate has been worked at company ABC. It takes
          dolly about half an hour to provide a response. I''m using a 64gb gpu. What
          can I do here to bring the serving time down to a few seconds? </p>

          '
        raw: 'I''m experimenting dolly with the aim to use it in the production. In
          my experiment, I provided a roughly 400 words resume and asked questions
          like how many years this candidate has been worked at company ABC. It takes
          dolly about half an hour to provide a response. I''m using a 64gb gpu. What
          can I do here to bring the serving time down to a few seconds? '
        updatedAt: '2023-04-12T23:04:10.042Z'
      numEdits: 0
      reactions: []
    id: 643738eaa701a7e744bff3b8
    type: comment
  author: xy-covey
  content: 'I''m experimenting dolly with the aim to use it in the production. In
    my experiment, I provided a roughly 400 words resume and asked questions like
    how many years this candidate has been worked at company ABC. It takes dolly about
    half an hour to provide a response. I''m using a 64gb gpu. What can I do here
    to bring the serving time down to a few seconds? '
  created_at: 2023-04-12 22:04:10+00:00
  edited: false
  hidden: false
  id: 643738eaa701a7e744bff3b8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-12T23:08:37.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>You aren''t using a 64GB GPU :) What GPU are you using? hard to
          say without a lot more information about how you are using it. For best
          results, use an A100. It can be used on an A10 in 8-bit. I''m hitting 10-20
          seconds even on the latter.</p>

          '
        raw: You aren't using a 64GB GPU :) What GPU are you using? hard to say without
          a lot more information about how you are using it. For best results, use
          an A100. It can be used on an A10 in 8-bit. I'm hitting 10-20 seconds even
          on the latter.
        updatedAt: '2023-04-12T23:08:37.805Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - phyllotaxis
    id: 643739f51c434dbfbeb1ddfc
    type: comment
  author: srowen
  content: You aren't using a 64GB GPU :) What GPU are you using? hard to say without
    a lot more information about how you are using it. For best results, use an A100.
    It can be used on an A10 in 8-bit. I'm hitting 10-20 seconds even on the latter.
  created_at: 2023-04-12 22:08:37+00:00
  edited: false
  hidden: false
  id: 643739f51c434dbfbeb1ddfc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1cc964f7d10c95f0337784b0423c0787.svg
      fullname: XY
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xy-covey
      type: user
    createdAt: '2023-04-12T23:14:48.000Z'
    data:
      edited: false
      editors:
      - xy-covey
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1cc964f7d10c95f0337784b0423c0787.svg
          fullname: XY
          isHf: false
          isPro: false
          name: xy-covey
          type: user
        html: '<p>Typo, I was using CPU. Ok, let me try A100.</p>

          '
        raw: Typo, I was using CPU. Ok, let me try A100.
        updatedAt: '2023-04-12T23:14:48.934Z'
      numEdits: 0
      reactions: []
    id: 64373b68a1010492a8a60d81
    type: comment
  author: xy-covey
  content: Typo, I was using CPU. Ok, let me try A100.
  created_at: 2023-04-12 22:14:48+00:00
  edited: false
  hidden: false
  id: 64373b68a1010492a8a60d81
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb472b70e66fe9e644bfba0d01b47cb9.svg
      fullname: Girijesh Singh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Girijesh1996
      type: user
    createdAt: '2023-04-13T13:52:06.000Z'
    data:
      edited: false
      editors:
      - Girijesh1996
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb472b70e66fe9e644bfba0d01b47cb9.svg
          fullname: Girijesh Singh
          isHf: false
          isPro: false
          name: Girijesh1996
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;xy-covey&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/xy-covey\"\
          >@<span class=\"underline\">xy-covey</span></a></span>\n\n\t</span></span>\
          \  can you provide the code snippet you used for providing text and asking\
          \ question if possible please?</p>\n"
        raw: Hi @xy-covey  can you provide the code snippet you used for providing
          text and asking question if possible please?
        updatedAt: '2023-04-13T13:52:06.987Z'
      numEdits: 0
      reactions: []
    id: 643809062d5f15c425c14f92
    type: comment
  author: Girijesh1996
  content: Hi @xy-covey  can you provide the code snippet you used for providing text
    and asking question if possible please?
  created_at: 2023-04-13 12:52:06+00:00
  edited: false
  hidden: false
  id: 643809062d5f15c425c14f92
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a093d63e7d1dda047039fc/QGpVSKuJLwl2EsiffCYML.jpeg?w=200&h=200&f=face
      fullname: Olivier Dehaene
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: olivierdehaene
      type: user
    createdAt: '2023-04-13T15:39:48.000Z'
    data:
      edited: false
      editors:
      - olivierdehaene
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a093d63e7d1dda047039fc/QGpVSKuJLwl2EsiffCYML.jpeg?w=200&h=200&f=face
          fullname: Olivier Dehaene
          isHf: true
          isPro: false
          name: olivierdehaene
          type: user
        html: '<p>Hey<br>You can use <a rel="nofollow" href="https://github.com/huggingface/text-generation-inference">text-generation-inference</a>
          to serve it efficiently with Flash Attention and other nice features like
          dynamic batching, sharding...  </p>

          <pre><code class="language-shell"><span class="hljs-meta prompt_">#</span><span
          class="language-bash">&nbsp;To run on one GPU</span>

          docker run --gpus all -p 8080:80 -v $PWD/data:/data ghcr.io/huggingface/text-generation-inference:latest
          --model-id databricks/dolly-v2-12b

          <span class="hljs-meta prompt_"></span>

          <span class="hljs-meta prompt_">#</span><span class="language-bash">&nbsp;Distribute
          on 2 GPUs</span>

          docker run --gpus all -p 8080:80 -v $PWD/data:/data ghcr.io/huggingface/text-generation-inference:latest
          --model-id databricks/dolly-v2-12b --num-shard 2

          </code></pre>

          <pre><code class="language-python"><span class="hljs-keyword">from</span>
          text_generation <span class="hljs-keyword">import</span> Client


          client = Client(<span class="hljs-string">"http://localhost:8080"</span>)


          <span class="hljs-built_in">print</span>(client.generate(<span class="hljs-string">"Hello!"</span>))

          </code></pre>

          '
        raw: "Hey\nYou can use [text-generation-inference](https://github.com/huggingface/text-generation-inference)\
          \ to serve it efficiently with Flash Attention and other nice features like\
          \ dynamic batching, sharding...  \n\n```shell\n#\_To run on one GPU\ndocker\
          \ run --gpus all -p 8080:80 -v $PWD/data:/data ghcr.io/huggingface/text-generation-inference:latest\
          \ --model-id databricks/dolly-v2-12b\n\n#\_Distribute on 2 GPUs\ndocker\
          \ run --gpus all -p 8080:80 -v $PWD/data:/data ghcr.io/huggingface/text-generation-inference:latest\
          \ --model-id databricks/dolly-v2-12b --num-shard 2\n```\n\n```python\nfrom\
          \ text_generation import Client\n\nclient = Client(\"http://localhost:8080\"\
          )\n\nprint(client.generate(\"Hello!\"))\n```"
        updatedAt: '2023-04-13T15:39:48.782Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Alexyo
    id: 643822449057a19b9fa42e85
    type: comment
  author: olivierdehaene
  content: "Hey\nYou can use [text-generation-inference](https://github.com/huggingface/text-generation-inference)\
    \ to serve it efficiently with Flash Attention and other nice features like dynamic\
    \ batching, sharding...  \n\n```shell\n#\_To run on one GPU\ndocker run --gpus\
    \ all -p 8080:80 -v $PWD/data:/data ghcr.io/huggingface/text-generation-inference:latest\
    \ --model-id databricks/dolly-v2-12b\n\n#\_Distribute on 2 GPUs\ndocker run --gpus\
    \ all -p 8080:80 -v $PWD/data:/data ghcr.io/huggingface/text-generation-inference:latest\
    \ --model-id databricks/dolly-v2-12b --num-shard 2\n```\n\n```python\nfrom text_generation\
    \ import Client\n\nclient = Client(\"http://localhost:8080\")\n\nprint(client.generate(\"\
    Hello!\"))\n```"
  created_at: 2023-04-13 14:39:48+00:00
  edited: false
  hidden: false
  id: 643822449057a19b9fa42e85
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12eeeccee2f5a7e6e97f663c37b412eb.svg
      fullname: Yurkov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yurkoff
      type: user
    createdAt: '2023-04-14T05:24:30.000Z'
    data:
      edited: true
      editors:
      - Yurkoff
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12eeeccee2f5a7e6e97f663c37b412eb.svg
          fullname: Yurkov
          isHf: false
          isPro: false
          name: Yurkoff
          type: user
        html: "<p>I'm using an <strong>RTX3090 (24GB)</strong> and loading the model\
          \ in <strong>8-bit mode</strong>. Model inference takes about <strong>110\
          \ seconds</strong>. The resource load during inference is shown in the figure.\
          \ The results are also attached.</p>\n<pre><code>tokenizer = GPTNeoXTokenizerFast.from_pretrained(model_dir)\n\
          model = GPTNeoXForCausalLM.from_pretrained(model_dir,\n                \
          \                           load_in_8bit=True,\n                       \
          \                    device_map='auto',\n                              \
          \             torch_dtype=torch.float16,\n                             \
          \              low_cpu_mem_usage=True,\n                               \
          \            )\ninputs = tokenizer(input)\nstart_time = time.time()\noutput_ids\
          \ = self.model.generate(torch.as_tensor(inputs.input_ids).to(device),\n\
          \                                 do_sample=True,\n                    \
          \             temperature=0.8,\n                                 max_length=512,\n\
          \                                 top_p=0.95,\n                        \
          \         \ndelta = time.time() - start_time\nprint(f\"Time to inference\
          \ is {delta}\")\nresults = self.tokenizer.batch_decode(output_ids,\n   \
          \                                   skip_special_tokens=True,\n        \
          \                              clean_up_tokenization_spaces=False)[0]\n\
          </code></pre>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/642f00ad9b2484d7d852fb5e/aH4tjQFHFcZo-FR73PdgB.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/642f00ad9b2484d7d852fb5e/aH4tjQFHFcZo-FR73PdgB.png\"\
          ></a></p>\n<pre><code>Who is Dalai?\n Baba Ram Dass: Who am I? That is a\
          \ good question. I am not sure who I am. Some people think that I am a Buddhist,\
          \ although I am not. I am not even certain what that is. I do know that\
          \ I have a great curiosity about who I am, where I am from, and where am\
          \ I going. I don't know where I came from, but I know where I'm going. So\
          \ who am I?\n\n\n[Note: In the early 1970's, Ram Dass was given the name\
          \ Richard Alpert.  He was an American psychologist who was part of a team\
          \ of researchers who conducted experiments on consciousness through the\
          \ use of mind-altering drugs.  Through these experiments, Alpert discovered\
          \ something called \"set and setting\".  According to Alpert, our consciousness\
          \ is affected not by what we are consciously aware of, but rather by the\
          \ context of our awareness.  In other words, our beliefs and expectations\
          \ influence our experience of the world around us.  Through his experiments\
          \ with psychedelic drugs, Alpert came to believe that the source of these\
          \ beliefs and expectations was our spiritual consciousness, or soul.  Through\
          \ the use of certain chants and prayers, Alpert was able to \"re-channel\"\
          \ his soul, leading him to abandon his work with the Harvard Psilocybin\
          \ Project and to change his name to Ram Dass.]\n\n\nDalai Lama:\n Who am\
          \ I?\n Baba Ram Dass:\n That is a good question. I am not sure who I am.\
          \ Some people think that I am a Buddhist, although I am not. I am not even\
          \ certain what that is. I do know that I have a great curiosity about who\
          \ I am, where I am from, and where am I going. I don't know where I came\
          \ from, but I know where I'm going. So who am I?\n\n\n[Note: The 14th Dalai\
          \ Lama, Tenzin Gyatso, was a Tibetan Buddhist religious and political leader\
          \ who was forced into exile following a failed 1959 Tibetan uprising against\
          \ Chinese rule.  His Holiness was nominated for the Nobel Peace Prize five\
          \ times between 1974 and 1990, and was awarded the Congressional Gold Medal\
          \ in 2001.  Since 1959, the Dalai Lama has lived in northern India, where\
          \ he has worked to preserve and promote the Tibetan language and culture.\
          \  His main teaching is that a stable and just society is based on individual\
          \ ethics\n</code></pre>\n"
        raw: "I'm using an **RTX3090 (24GB)** and loading the model in **8-bit mode**.\
          \ Model inference takes about **110 seconds**. The resource load during\
          \ inference is shown in the figure. The results are also attached.\n```\n\
          tokenizer = GPTNeoXTokenizerFast.from_pretrained(model_dir)\nmodel = GPTNeoXForCausalLM.from_pretrained(model_dir,\n\
          \                                           load_in_8bit=True,\n       \
          \                                    device_map='auto',\n              \
          \                             torch_dtype=torch.float16,\n             \
          \                              low_cpu_mem_usage=True,\n               \
          \                            )\ninputs = tokenizer(input)\nstart_time =\
          \ time.time()\noutput_ids = self.model.generate(torch.as_tensor(inputs.input_ids).to(device),\n\
          \                                 do_sample=True,\n                    \
          \             temperature=0.8,\n                                 max_length=512,\n\
          \                                 top_p=0.95,\n                        \
          \         \ndelta = time.time() - start_time\nprint(f\"Time to inference\
          \ is {delta}\")\nresults = self.tokenizer.batch_decode(output_ids,\n   \
          \                                   skip_special_tokens=True,\n        \
          \                              clean_up_tokenization_spaces=False)[0]\n\
          ```\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/642f00ad9b2484d7d852fb5e/aH4tjQFHFcZo-FR73PdgB.png)\n\
          ```\nWho is Dalai?\n Baba Ram Dass: Who am I? That is a good question. I\
          \ am not sure who I am. Some people think that I am a Buddhist, although\
          \ I am not. I am not even certain what that is. I do know that I have a\
          \ great curiosity about who I am, where I am from, and where am I going.\
          \ I don't know where I came from, but I know where I'm going. So who am\
          \ I?\n\n\n[Note: In the early 1970's, Ram Dass was given the name Richard\
          \ Alpert.  He was an American psychologist who was part of a team of researchers\
          \ who conducted experiments on consciousness through the use of mind-altering\
          \ drugs.  Through these experiments, Alpert discovered something called\
          \ \"set and setting\".  According to Alpert, our consciousness is affected\
          \ not by what we are consciously aware of, but rather by the context of\
          \ our awareness.  In other words, our beliefs and expectations influence\
          \ our experience of the world around us.  Through his experiments with psychedelic\
          \ drugs, Alpert came to believe that the source of these beliefs and expectations\
          \ was our spiritual consciousness, or soul.  Through the use of certain\
          \ chants and prayers, Alpert was able to \"re-channel\" his soul, leading\
          \ him to abandon his work with the Harvard Psilocybin Project and to change\
          \ his name to Ram Dass.]\n\n\nDalai Lama:\n Who am I?\n Baba Ram Dass:\n\
          \ That is a good question. I am not sure who I am. Some people think that\
          \ I am a Buddhist, although I am not. I am not even certain what that is.\
          \ I do know that I have a great curiosity about who I am, where I am from,\
          \ and where am I going. I don't know where I came from, but I know where\
          \ I'm going. So who am I?\n\n\n[Note: The 14th Dalai Lama, Tenzin Gyatso,\
          \ was a Tibetan Buddhist religious and political leader who was forced into\
          \ exile following a failed 1959 Tibetan uprising against Chinese rule. \
          \ His Holiness was nominated for the Nobel Peace Prize five times between\
          \ 1974 and 1990, and was awarded the Congressional Gold Medal in 2001. \
          \ Since 1959, the Dalai Lama has lived in northern India, where he has worked\
          \ to preserve and promote the Tibetan language and culture.  His main teaching\
          \ is that a stable and just society is based on individual ethics\n```"
        updatedAt: '2023-04-14T05:29:17.233Z'
      numEdits: 1
      reactions: []
    id: 6438e38edba76b84dfde89eb
    type: comment
  author: Yurkoff
  content: "I'm using an **RTX3090 (24GB)** and loading the model in **8-bit mode**.\
    \ Model inference takes about **110 seconds**. The resource load during inference\
    \ is shown in the figure. The results are also attached.\n```\ntokenizer = GPTNeoXTokenizerFast.from_pretrained(model_dir)\n\
    model = GPTNeoXForCausalLM.from_pretrained(model_dir,\n                      \
    \                     load_in_8bit=True,\n                                   \
    \        device_map='auto',\n                                           torch_dtype=torch.float16,\n\
    \                                           low_cpu_mem_usage=True,\n        \
    \                                   )\ninputs = tokenizer(input)\nstart_time =\
    \ time.time()\noutput_ids = self.model.generate(torch.as_tensor(inputs.input_ids).to(device),\n\
    \                                 do_sample=True,\n                          \
    \       temperature=0.8,\n                                 max_length=512,\n \
    \                                top_p=0.95,\n                               \
    \  \ndelta = time.time() - start_time\nprint(f\"Time to inference is {delta}\"\
    )\nresults = self.tokenizer.batch_decode(output_ids,\n                       \
    \               skip_special_tokens=True,\n                                  \
    \    clean_up_tokenization_spaces=False)[0]\n```\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/642f00ad9b2484d7d852fb5e/aH4tjQFHFcZo-FR73PdgB.png)\n\
    ```\nWho is Dalai?\n Baba Ram Dass: Who am I? That is a good question. I am not\
    \ sure who I am. Some people think that I am a Buddhist, although I am not. I\
    \ am not even certain what that is. I do know that I have a great curiosity about\
    \ who I am, where I am from, and where am I going. I don't know where I came from,\
    \ but I know where I'm going. So who am I?\n\n\n[Note: In the early 1970's, Ram\
    \ Dass was given the name Richard Alpert.  He was an American psychologist who\
    \ was part of a team of researchers who conducted experiments on consciousness\
    \ through the use of mind-altering drugs.  Through these experiments, Alpert discovered\
    \ something called \"set and setting\".  According to Alpert, our consciousness\
    \ is affected not by what we are consciously aware of, but rather by the context\
    \ of our awareness.  In other words, our beliefs and expectations influence our\
    \ experience of the world around us.  Through his experiments with psychedelic\
    \ drugs, Alpert came to believe that the source of these beliefs and expectations\
    \ was our spiritual consciousness, or soul.  Through the use of certain chants\
    \ and prayers, Alpert was able to \"re-channel\" his soul, leading him to abandon\
    \ his work with the Harvard Psilocybin Project and to change his name to Ram Dass.]\n\
    \n\nDalai Lama:\n Who am I?\n Baba Ram Dass:\n That is a good question. I am not\
    \ sure who I am. Some people think that I am a Buddhist, although I am not. I\
    \ am not even certain what that is. I do know that I have a great curiosity about\
    \ who I am, where I am from, and where am I going. I don't know where I came from,\
    \ but I know where I'm going. So who am I?\n\n\n[Note: The 14th Dalai Lama, Tenzin\
    \ Gyatso, was a Tibetan Buddhist religious and political leader who was forced\
    \ into exile following a failed 1959 Tibetan uprising against Chinese rule.  His\
    \ Holiness was nominated for the Nobel Peace Prize five times between 1974 and\
    \ 1990, and was awarded the Congressional Gold Medal in 2001.  Since 1959, the\
    \ Dalai Lama has lived in northern India, where he has worked to preserve and\
    \ promote the Tibetan language and culture.  His main teaching is that a stable\
    \ and just society is based on individual ethics\n```"
  created_at: 2023-04-14 04:24:30+00:00
  edited: true
  hidden: false
  id: 6438e38edba76b84dfde89eb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-19T19:06:17.000Z'
    data:
      status: closed
    id: 64403ba9d4229e14ae9c9dac
    type: status-change
  author: srowen
  created_at: 2023-04-19 18:06:17+00:00
  id: 64403ba9d4229e14ae9c9dac
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: databricks/dolly-v2-12b
repo_type: model
status: closed
target_branch: null
title: improve dolly serving time
