!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rj25
conflicting_files: null
created_at: 2023-10-04 11:50:46+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/900685e6956a5b871ed957768dbccafc.svg
      fullname: RAJAT KUMAR SINHA
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rj25
      type: user
    createdAt: '2023-10-04T12:50:46.000Z'
    data:
      edited: false
      editors:
      - rj25
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7013170123100281
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/900685e6956a5b871ed957768dbccafc.svg
          fullname: RAJAT KUMAR SINHA
          isHf: false
          isPro: false
          name: rj25
          type: user
        html: '<p>I have a dataframe(df) and want to give the whole "df" as context
          to Dolly-7B model and ask any questions from that dataset - it can be simple
          calculations or insights or aggregation etc.  </p>

          <p>import torch<br>from transformers import pipeline<br>from langchain import
          PromptTemplate, LLMChain<br>from langchain.llms import HuggingFacePipeline</p>

          <h1 id="load-the-dataframe">Load the dataframe</h1>

          <p>df = pd.read_csv("./Table.csv")</p>

          <p>generate_text = pipeline(model="databricks/dolly-v2-7b", torch_dtype=torch.bfloat16,
          trust_remote_code=True, device_map="auto", return_full_text=True)</p>

          <p>hf_pipeline = HuggingFacePipeline(pipeline=generate_text)</p>

          <p>I am new to language models, can anyone guide me how the code should
          be written further to ask questions to Dolly and it answer analyzing my
          dataframe. </p>

          <p>Thanks in advance!!</p>

          '
        raw: "I have a dataframe(df) and want to give the whole \"df\" as context\
          \ to Dolly-7B model and ask any questions from that dataset - it can be\
          \ simple calculations or insights or aggregation etc.  \r\n\r\nimport torch\r\
          \nfrom transformers import pipeline\r\nfrom langchain import PromptTemplate,\
          \ LLMChain\r\nfrom langchain.llms import HuggingFacePipeline\r\n\r\n# Load\
          \ the dataframe\r\ndf = pd.read_csv(\"./Table.csv\")\r\n\r\ngenerate_text\
          \ = pipeline(model=\"databricks/dolly-v2-7b\", torch_dtype=torch.bfloat16,\
          \ trust_remote_code=True, device_map=\"auto\", return_full_text=True)\r\n\
          \r\nhf_pipeline = HuggingFacePipeline(pipeline=generate_text)\r\n\r\nI am\
          \ new to language models, can anyone guide me how the code should be written\
          \ further to ask questions to Dolly and it answer analyzing my dataframe.\
          \ \r\n\r\nThanks in advance!!"
        updatedAt: '2023-10-04T12:50:46.164Z'
      numEdits: 0
      reactions: []
    id: 651d5fa6a9afacbd050b2c39
    type: comment
  author: rj25
  content: "I have a dataframe(df) and want to give the whole \"df\" as context to\
    \ Dolly-7B model and ask any questions from that dataset - it can be simple calculations\
    \ or insights or aggregation etc.  \r\n\r\nimport torch\r\nfrom transformers import\
    \ pipeline\r\nfrom langchain import PromptTemplate, LLMChain\r\nfrom langchain.llms\
    \ import HuggingFacePipeline\r\n\r\n# Load the dataframe\r\ndf = pd.read_csv(\"\
    ./Table.csv\")\r\n\r\ngenerate_text = pipeline(model=\"databricks/dolly-v2-7b\"\
    , torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\", return_full_text=True)\r\
    \n\r\nhf_pipeline = HuggingFacePipeline(pipeline=generate_text)\r\n\r\nI am new\
    \ to language models, can anyone guide me how the code should be written further\
    \ to ask questions to Dolly and it answer analyzing my dataframe. \r\n\r\nThanks\
    \ in advance!!"
  created_at: 2023-10-04 11:50:46+00:00
  edited: false
  hidden: false
  id: 651d5fa6a9afacbd050b2c39
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-10-12T19:02:00.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9778093695640564
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>This isn''t what this type of text-gen model does. See the model
          card for how you feed natural-language questions to it. You can try passing
          some CSV data in your text as context with your question, but I doubt it
          will work as you imagine.</p>

          '
        raw: This isn't what this type of text-gen model does. See the model card
          for how you feed natural-language questions to it. You can try passing some
          CSV data in your text as context with your question, but I doubt it will
          work as you imagine.
        updatedAt: '2023-10-12T19:02:00.563Z'
      numEdits: 0
      reactions: []
    id: 652842a89fe07b8cf370b957
    type: comment
  author: srowen
  content: This isn't what this type of text-gen model does. See the model card for
    how you feed natural-language questions to it. You can try passing some CSV data
    in your text as context with your question, but I doubt it will work as you imagine.
  created_at: 2023-10-12 18:02:00+00:00
  edited: false
  hidden: false
  id: 652842a89fe07b8cf370b957
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 90
repo_id: databricks/dolly-v2-12b
repo_type: model
status: open
target_branch: null
title: Use Dolly2.0 for Dataframe or Tabular Data.
