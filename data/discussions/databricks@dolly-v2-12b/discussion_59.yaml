!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Iamexperimenting
conflicting_files: null
created_at: 2023-05-01 01:03:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9c8ef28358d8ff81e6bc1dc4558de43d.svg
      fullname: IamexperimentingNow
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Iamexperimenting
      type: user
    createdAt: '2023-05-01T02:03:16.000Z'
    data:
      edited: false
      editors:
      - Iamexperimenting
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9c8ef28358d8ff81e6bc1dc4558de43d.svg
          fullname: IamexperimentingNow
          isHf: false
          isPro: false
          name: Iamexperimenting
          type: user
        html: '<p>Hi, can anyone help me on building question answering model using
          dolly? Or any other open source LLM? </p>

          <p>I have my data in pdf, txt format (unstructured format) I want to build
          conversational question answering model. Could you please provide me any
          relevant article? </p>

          <p>Like, how to build conversational question answering model using open
          source LLM from my data.</p>

          '
        raw: "Hi, can anyone help me on building question answering model using dolly?\
          \ Or any other open source LLM? \r\n\r\nI have my data in pdf, txt format\
          \ (unstructured format) I want to build conversational question answering\
          \ model. Could you please provide me any relevant article? \r\n\r\nLike,\
          \ how to build conversational question answering model using open source\
          \ LLM from my data."
        updatedAt: '2023-05-01T02:03:16.192Z'
      numEdits: 0
      reactions: []
    id: 644f1de4d6001776ed7ac9d4
    type: comment
  author: Iamexperimenting
  content: "Hi, can anyone help me on building question answering model using dolly?\
    \ Or any other open source LLM? \r\n\r\nI have my data in pdf, txt format (unstructured\
    \ format) I want to build conversational question answering model. Could you please\
    \ provide me any relevant article? \r\n\r\nLike, how to build conversational question\
    \ answering model using open source LLM from my data."
  created_at: 2023-05-01 01:03:16+00:00
  edited: false
  hidden: false
  id: 644f1de4d6001776ed7ac9d4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-01T02:12:54.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Sure, this is exactly what langchain is good for. It has question-answering
          chains that let you build this around a vector DB of text and an LLM.<br>We
          have an example that uses Dolly, though you could use any text-gen LLM.<br><a
          rel="nofollow" href="https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot">https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot</a></p>

          '
        raw: 'Sure, this is exactly what langchain is good for. It has question-answering
          chains that let you build this around a vector DB of text and an LLM.

          We have an example that uses Dolly, though you could use any text-gen LLM.

          https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot'
        updatedAt: '2023-05-01T02:12:54.635Z'
      numEdits: 0
      reactions: []
    id: 644f2026bf9683cba46f1da0
    type: comment
  author: srowen
  content: 'Sure, this is exactly what langchain is good for. It has question-answering
    chains that let you build this around a vector DB of text and an LLM.

    We have an example that uses Dolly, though you could use any text-gen LLM.

    https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot'
  created_at: 2023-05-01 01:12:54+00:00
  edited: false
  hidden: false
  id: 644f2026bf9683cba46f1da0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9c8ef28358d8ff81e6bc1dc4558de43d.svg
      fullname: IamexperimentingNow
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Iamexperimenting
      type: user
    createdAt: '2023-05-03T18:16:38.000Z'
    data:
      edited: false
      editors:
      - Iamexperimenting
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9c8ef28358d8ff81e6bc1dc4558de43d.svg
          fullname: IamexperimentingNow
          isHf: false
          isPro: false
          name: Iamexperimenting
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;srowen&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/srowen\">@<span class=\"\
          underline\">srowen</span></a></span>\n\n\t</span></span> thanks for the\
          \ example. I followed document and prepared \"question answer model with\
          \ my data\". I have a doubt,  how to do I  host it has an API? because I\
          \ don't know.  can you please provide me example?</p>\n"
        raw: '@srowen thanks for the example. I followed document and prepared "question
          answer model with my data". I have a doubt,  how to do I  host it has an
          API? because I don''t know.  can you please provide me example?'
        updatedAt: '2023-05-03T18:16:38.949Z'
      numEdits: 0
      reactions: []
    id: 6452a5065ac68a5b01a1ea1a
    type: comment
  author: Iamexperimenting
  content: '@srowen thanks for the example. I followed document and prepared "question
    answer model with my data". I have a doubt,  how to do I  host it has an API?
    because I don''t know.  can you please provide me example?'
  created_at: 2023-05-03 17:16:38+00:00
  edited: false
  hidden: false
  id: 6452a5065ac68a5b01a1ea1a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-03T18:38:45.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Many ways I''m sure. I''m familiar with MLflow, which helps track
          and then serve models. MLflow natively supports langchain and transformer
          models/chains, but, the support isn''t <em>quite</em> enough here because
          you need to bundle a vector DB like Chroma with your model too in this case,
          if you''re not running it separately. That''s fairly straightforward, just
          put the inference code into a class that generates predictions, and can
          load the vector DB from an artifact that was logged with the model. I don''t
          have a worked example, but it''s fairly easy to piece together. Then mlflow
          can serve it for you. Databricks has built-in serving built around MLflow
          too, but you don''t have to use that of course.</p>

          '
        raw: Many ways I'm sure. I'm familiar with MLflow, which helps track and then
          serve models. MLflow natively supports langchain and transformer models/chains,
          but, the support isn't _quite_ enough here because you need to bundle a
          vector DB like Chroma with your model too in this case, if you're not running
          it separately. That's fairly straightforward, just put the inference code
          into a class that generates predictions, and can load the vector DB from
          an artifact that was logged with the model. I don't have a worked example,
          but it's fairly easy to piece together. Then mlflow can serve it for you.
          Databricks has built-in serving built around MLflow too, but you don't have
          to use that of course.
        updatedAt: '2023-05-03T18:38:45.955Z'
      numEdits: 0
      reactions: []
    id: 6452aa353a794b2d9b12e430
    type: comment
  author: srowen
  content: Many ways I'm sure. I'm familiar with MLflow, which helps track and then
    serve models. MLflow natively supports langchain and transformer models/chains,
    but, the support isn't _quite_ enough here because you need to bundle a vector
    DB like Chroma with your model too in this case, if you're not running it separately.
    That's fairly straightforward, just put the inference code into a class that generates
    predictions, and can load the vector DB from an artifact that was logged with
    the model. I don't have a worked example, but it's fairly easy to piece together.
    Then mlflow can serve it for you. Databricks has built-in serving built around
    MLflow too, but you don't have to use that of course.
  created_at: 2023-05-03 17:38:45+00:00
  edited: false
  hidden: false
  id: 6452aa353a794b2d9b12e430
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9c8ef28358d8ff81e6bc1dc4558de43d.svg
      fullname: IamexperimentingNow
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Iamexperimenting
      type: user
    createdAt: '2023-05-03T21:52:39.000Z'
    data:
      edited: false
      editors:
      - Iamexperimenting
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9c8ef28358d8ff81e6bc1dc4558de43d.svg
          fullname: IamexperimentingNow
          isHf: false
          isPro: false
          name: Iamexperimenting
          type: user
        html: "<p>thanks very much <span data-props=\"{&quot;user&quot;:&quot;srowen&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/srowen\"\
          >@<span class=\"underline\">srowen</span></a></span>\n\n\t</span></span>\
          \ . I have few more general questions to clarify with you. </p>\n<ol>\n\
          <li>currently, I use my data(20 files) to create embedding from HuggingFaceEmbeddings.\
          \ Even if I have 2 millions files do I need to follow the same steps like\
          \ 1.create embedding from HuggingFaceEmbeddings, 2. do similarity test,\
          \ and 3. pass it to model?</li>\n<li>At what stage I need to retrain the\
          \ LLM? </li>\n<li>is it possible to retrain the LLM with my own data?</li>\n\
          <li>currently, your notebook show chromadb as vector db, In case if I want\
          \ to move it production how do I host it? where do I store all my data(embeddings)?\
          \ do I need to store all embedding in any database, if yes, could you please\
          \ recommend any?</li>\n<li>how do I evaluated dolly LLM with my data?</li>\n\
          <li>currently, I noticed dolly model with my data gives one wrong answer.\
          \ so, how do I correct the model? if it is other model like text classification\
          \ I would correct the label and retrain the model with corrected label.\
          \ how do I do it here?</li>\n</ol>\n"
        raw: "thanks very much @srowen . I have few more general questions to clarify\
          \ with you. \n1. currently, I use my data(20 files) to create embedding\
          \ from HuggingFaceEmbeddings. Even if I have 2 millions files do I need\
          \ to follow the same steps like 1.create embedding from HuggingFaceEmbeddings,\
          \ 2. do similarity test, and 3. pass it to model?\n2. At what stage I need\
          \ to retrain the LLM? \n3. is it possible to retrain the LLM with my own\
          \ data?\n4. currently, your notebook show chromadb as vector db, In case\
          \ if I want to move it production how do I host it? where do I store all\
          \ my data(embeddings)? do I need to store all embedding in any database,\
          \ if yes, could you please recommend any?\n5. how do I evaluated dolly LLM\
          \ with my data?\n6. currently, I noticed dolly model with my data gives\
          \ one wrong answer. so, how do I correct the model? if it is other model\
          \ like text classification I would correct the label and retrain the model\
          \ with corrected label. how do I do it here?"
        updatedAt: '2023-05-03T21:52:39.237Z'
      numEdits: 0
      reactions: []
    id: 6452d7a78fe6558e3285a16c
    type: comment
  author: Iamexperimenting
  content: "thanks very much @srowen . I have few more general questions to clarify\
    \ with you. \n1. currently, I use my data(20 files) to create embedding from HuggingFaceEmbeddings.\
    \ Even if I have 2 millions files do I need to follow the same steps like 1.create\
    \ embedding from HuggingFaceEmbeddings, 2. do similarity test, and 3. pass it\
    \ to model?\n2. At what stage I need to retrain the LLM? \n3. is it possible to\
    \ retrain the LLM with my own data?\n4. currently, your notebook show chromadb\
    \ as vector db, In case if I want to move it production how do I host it? where\
    \ do I store all my data(embeddings)? do I need to store all embedding in any\
    \ database, if yes, could you please recommend any?\n5. how do I evaluated dolly\
    \ LLM with my data?\n6. currently, I noticed dolly model with my data gives one\
    \ wrong answer. so, how do I correct the model? if it is other model like text\
    \ classification I would correct the label and retrain the model with corrected\
    \ label. how do I do it here?"
  created_at: 2023-05-03 20:52:39+00:00
  edited: false
  hidden: false
  id: 6452d7a78fe6558e3285a16c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-03T21:55:46.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>If you''re following the langchain question-answering chain pattern,
          you do need to create a vector DB with your text embedded into it. But langchain
          is doing much of the rest. You''ve tried the example? you can see what your
          code has to do.</p>

          <p>This pattern does not involve fine-tuning an LLM at all.</p>

          <p>You can simply bundle the chroma DB files and try to deploy them with
          your model. It''s fixed, won''t change, but that''s simple. Otherwise you
          set up a stand-alone vector DB service (not Chroma) and call that.</p>

          <p>Hard to say how to evaluate it. Depends on what you are doing.</p>

          <p>You can''t correct models directly. You can improve training data, maybe.</p>

          '
        raw: 'If you''re following the langchain question-answering chain pattern,
          you do need to create a vector DB with your text embedded into it. But langchain
          is doing much of the rest. You''ve tried the example? you can see what your
          code has to do.


          This pattern does not involve fine-tuning an LLM at all.


          You can simply bundle the chroma DB files and try to deploy them with your
          model. It''s fixed, won''t change, but that''s simple. Otherwise you set
          up a stand-alone vector DB service (not Chroma) and call that.


          Hard to say how to evaluate it. Depends on what you are doing.


          You can''t correct models directly. You can improve training data, maybe.'
        updatedAt: '2023-05-03T21:55:46.898Z'
      numEdits: 0
      reactions: []
    id: 6452d862a0c0a664a24bd26e
    type: comment
  author: srowen
  content: 'If you''re following the langchain question-answering chain pattern, you
    do need to create a vector DB with your text embedded into it. But langchain is
    doing much of the rest. You''ve tried the example? you can see what your code
    has to do.


    This pattern does not involve fine-tuning an LLM at all.


    You can simply bundle the chroma DB files and try to deploy them with your model.
    It''s fixed, won''t change, but that''s simple. Otherwise you set up a stand-alone
    vector DB service (not Chroma) and call that.


    Hard to say how to evaluate it. Depends on what you are doing.


    You can''t correct models directly. You can improve training data, maybe.'
  created_at: 2023-05-03 20:55:46+00:00
  edited: false
  hidden: false
  id: 6452d862a0c0a664a24bd26e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9c8ef28358d8ff81e6bc1dc4558de43d.svg
      fullname: IamexperimentingNow
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Iamexperimenting
      type: user
    createdAt: '2023-05-03T22:24:04.000Z'
    data:
      edited: false
      editors:
      - Iamexperimenting
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9c8ef28358d8ff81e6bc1dc4558de43d.svg
          fullname: IamexperimentingNow
          isHf: false
          isPro: false
          name: Iamexperimenting
          type: user
        html: "<p>thanks for your response again, <span data-props=\"{&quot;user&quot;:&quot;srowen&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/srowen\"\
          >@<span class=\"underline\">srowen</span></a></span>\n\n\t</span></span>\
          \ .</p>\n<p><code>Hard to say how to evaluate it. Depends on what you are\
          \ doing.</code> - I'm creating <code>question answer model using open-source\
          \ LLM from my unstructured text data</code></p>\n<p>I forgot to ask one\
          \ question. Do i need to use <code>torch.manual_seed(0)</code> for reproducibility(to\
          \ get same answer everytime?)</p>\n"
        raw: 'thanks for your response again, @srowen .


          `Hard to say how to evaluate it. Depends on what you are doing.` - I''m
          creating `question answer model using open-source LLM from my unstructured
          text data`


          I forgot to ask one question. Do i need to use `torch.manual_seed(0)` for
          reproducibility(to get same answer everytime?)'
        updatedAt: '2023-05-03T22:24:04.397Z'
      numEdits: 0
      reactions: []
    id: 6452df048fe6558e32868ac3
    type: comment
  author: Iamexperimenting
  content: 'thanks for your response again, @srowen .


    `Hard to say how to evaluate it. Depends on what you are doing.` - I''m creating
    `question answer model using open-source LLM from my unstructured text data`


    I forgot to ask one question. Do i need to use `torch.manual_seed(0)` for reproducibility(to
    get same answer everytime?)'
  created_at: 2023-05-03 21:24:04+00:00
  edited: false
  hidden: false
  id: 6452df048fe6558e32868ac3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-09T13:38:58.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>I would set do_sample=False for generation instead.</p>

          '
        raw: I would set do_sample=False for generation instead.
        updatedAt: '2023-05-09T13:38:58.418Z'
      numEdits: 0
      reactions: []
    id: 645a4cf23760da5b7fa5722a
    type: comment
  author: srowen
  content: I would set do_sample=False for generation instead.
  created_at: 2023-05-09 12:38:58+00:00
  edited: false
  hidden: false
  id: 645a4cf23760da5b7fa5722a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-10T13:25:13.000Z'
    data:
      status: closed
    id: 645b9b390120c98d16a77d20
    type: status-change
  author: srowen
  created_at: 2023-05-10 12:25:13+00:00
  id: 645b9b390120c98d16a77d20
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cf1f186b256e8bc8e939e71a7ee90d3e.svg
      fullname: Harsh Avinash
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheHarshAvinash
      type: user
    createdAt: '2023-05-29T06:59:05.000Z'
    data:
      edited: false
      editors:
      - TheHarshAvinash
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cf1f186b256e8bc8e939e71a7ee90d3e.svg
          fullname: Harsh Avinash
          isHf: false
          isPro: false
          name: TheHarshAvinash
          type: user
        html: '<p>Follow up question, so as a noob here I wanna to my best understanding
          "fine tune" ie I wanna teach the model a HUGH database of data and ask it
          questions to which it responds quickly</p>

          '
        raw: Follow up question, so as a noob here I wanna to my best understanding
          "fine tune" ie I wanna teach the model a HUGH database of data and ask it
          questions to which it responds quickly
        updatedAt: '2023-05-29T06:59:05.365Z'
      numEdits: 0
      reactions: []
    id: 64744d395ada8510bc39eea3
    type: comment
  author: TheHarshAvinash
  content: Follow up question, so as a noob here I wanna to my best understanding
    "fine tune" ie I wanna teach the model a HUGH database of data and ask it questions
    to which it responds quickly
  created_at: 2023-05-29 05:59:05+00:00
  edited: false
  hidden: false
  id: 64744d395ada8510bc39eea3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-29T12:16:00.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>I would not fine-tune for knowledge retrieval over a large amount
          of data. Store the text in a vector store, retrieve relevant text at runtime
          and send to the LLM. This is what the example here does: <a rel="nofollow"
          href="https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot">https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot</a></p>

          '
        raw: 'I would not fine-tune for knowledge retrieval over a large amount of
          data. Store the text in a vector store, retrieve relevant text at runtime
          and send to the LLM. This is what the example here does: https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot'
        updatedAt: '2023-05-29T12:16:00.559Z'
      numEdits: 0
      reactions: []
    id: 6474978082907acdddec46c8
    type: comment
  author: srowen
  content: 'I would not fine-tune for knowledge retrieval over a large amount of data.
    Store the text in a vector store, retrieve relevant text at runtime and send to
    the LLM. This is what the example here does: https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot'
  created_at: 2023-05-29 11:16:00+00:00
  edited: false
  hidden: false
  id: 6474978082907acdddec46c8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/951eda5f9516fac30c1c42542724c342.svg
      fullname: Syed Own Muhammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BlackData
      type: user
    createdAt: '2023-07-06T11:31:12.000Z'
    data:
      edited: false
      editors:
      - BlackData
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8172109127044678
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/951eda5f9516fac30c1c42542724c342.svg
          fullname: Syed Own Muhammad
          isHf: false
          isPro: false
          name: BlackData
          type: user
        html: '<p>Hi Mr.Srowen need your help. I have been trying to run the train_dolly
          file in databricks atmosphere. In command number 9 where deepspeed is being
          used. The error being displayed is that GPU resources are not being used.
          Can you guide me how I may make use of it using the databricks platform.
          Your help would be much appreciated.  Below provided is the error<br> File
          "/local_disk0/.ephemeral_nfs/envs/pythonEnv-084abc89-9a56-4220-a941-3e177a718272/bin/deepspeed",
          line 6, in <br>    main()<br>  File "/local_disk0/.ephemeral_nfs/envs/pythonEnv-084abc89-9a56-4220-a941-3e177a718272/lib/python3.10/site-packages/deepspeed/launcher/runner.py",
          line 411, in main<br>    raise RuntimeError("Unable to proceed, no GPU resources
          available")<br>RuntimeError: Unable to proceed, no GPU resources available</p>

          '
        raw: "Hi Mr.Srowen need your help. I have been trying to run the train_dolly\
          \ file in databricks atmosphere. In command number 9 where deepspeed is\
          \ being used. The error being displayed is that GPU resources are not being\
          \ used. Can you guide me how I may make use of it using the databricks platform.\
          \ Your help would be much appreciated.  Below provided is the error\n File\
          \ \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-084abc89-9a56-4220-a941-3e177a718272/bin/deepspeed\"\
          , line 6, in <module>\n    main()\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-084abc89-9a56-4220-a941-3e177a718272/lib/python3.10/site-packages/deepspeed/launcher/runner.py\"\
          , line 411, in main\n    raise RuntimeError(\"Unable to proceed, no GPU\
          \ resources available\")\nRuntimeError: Unable to proceed, no GPU resources\
          \ available"
        updatedAt: '2023-07-06T11:31:12.197Z'
      numEdits: 0
      reactions: []
    id: 64a6a6004664e85ad92e2e0b
    type: comment
  author: BlackData
  content: "Hi Mr.Srowen need your help. I have been trying to run the train_dolly\
    \ file in databricks atmosphere. In command number 9 where deepspeed is being\
    \ used. The error being displayed is that GPU resources are not being used. Can\
    \ you guide me how I may make use of it using the databricks platform. Your help\
    \ would be much appreciated.  Below provided is the error\n File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-084abc89-9a56-4220-a941-3e177a718272/bin/deepspeed\"\
    , line 6, in <module>\n    main()\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-084abc89-9a56-4220-a941-3e177a718272/lib/python3.10/site-packages/deepspeed/launcher/runner.py\"\
    , line 411, in main\n    raise RuntimeError(\"Unable to proceed, no GPU resources\
    \ available\")\nRuntimeError: Unable to proceed, no GPU resources available"
  created_at: 2023-07-06 10:31:12+00:00
  edited: false
  hidden: false
  id: 64a6a6004664e85ad92e2e0b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-07-06T12:21:19.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9676844477653503
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Looks like you did not run this on a GPU instance.</p>

          '
        raw: Looks like you did not run this on a GPU instance.
        updatedAt: '2023-07-06T12:21:19.713Z'
      numEdits: 0
      reactions: []
    id: 64a6b1bf34f4994fbc07ec1f
    type: comment
  author: srowen
  content: Looks like you did not run this on a GPU instance.
  created_at: 2023-07-06 11:21:19+00:00
  edited: false
  hidden: false
  id: 64a6b1bf34f4994fbc07ec1f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/951eda5f9516fac30c1c42542724c342.svg
      fullname: Syed Own Muhammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BlackData
      type: user
    createdAt: '2023-07-07T07:22:44.000Z'
    data:
      edited: false
      editors:
      - BlackData
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9313021302223206
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/951eda5f9516fac30c1c42542724c342.svg
          fullname: Syed Own Muhammad
          isHf: false
          isPro: false
          name: BlackData
          type: user
        html: '<blockquote>

          <p>Looks like you did not run this on a GPU instance.</p>

          </blockquote>

          <p>Really appreciate your reply , Could you further help me by letting me
          know how I may make use of the GPU instance.( I''m New to the interface
          databricks) </p>

          '
        raw: '> Looks like you did not run this on a GPU instance.


          Really appreciate your reply , Could you further help me by letting me know
          how I may make use of the GPU instance.( I''m New to the interface databricks) '
        updatedAt: '2023-07-07T07:22:44.733Z'
      numEdits: 0
      reactions: []
    id: 64a7bd441ce0239e0f855bf3
    type: comment
  author: BlackData
  content: '> Looks like you did not run this on a GPU instance.


    Really appreciate your reply , Could you further help me by letting me know how
    I may make use of the GPU instance.( I''m New to the interface databricks) '
  created_at: 2023-07-07 06:22:44+00:00
  edited: false
  hidden: false
  id: 64a7bd441ce0239e0f855bf3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f9548e8bc00995ae97c7aacc178ee44b.svg
      fullname: Dhruv Toshniwal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DhruvToshniwalARD
      type: user
    createdAt: '2023-07-12T16:22:14.000Z'
    data:
      edited: true
      editors:
      - DhruvToshniwalARD
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9786238670349121
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f9548e8bc00995ae97c7aacc178ee44b.svg
          fullname: Dhruv Toshniwal
          isHf: false
          isPro: false
          name: DhruvToshniwalARD
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Iamexperimenting&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Iamexperimenting\"\
          >@<span class=\"underline\">Iamexperimenting</span></a></span>\n\n\t</span></span>\
          \ is your code public? Would really like to take a look. I am trying to\
          \ build something similar.</p>\n"
        raw: '@Iamexperimenting is your code public? Would really like to take a look.
          I am trying to build something similar.'
        updatedAt: '2023-07-12T16:22:27.004Z'
      numEdits: 1
      reactions: []
    id: 64aed33681d41f5b9ad7179c
    type: comment
  author: DhruvToshniwalARD
  content: '@Iamexperimenting is your code public? Would really like to take a look.
    I am trying to build something similar.'
  created_at: 2023-07-12 15:22:14+00:00
  edited: true
  hidden: false
  id: 64aed33681d41f5b9ad7179c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 59
repo_id: databricks/dolly-v2-12b
repo_type: model
status: closed
target_branch: null
title: Question Answering model using dolly
