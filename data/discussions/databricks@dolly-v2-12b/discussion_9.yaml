!!python/object:huggingface_hub.community.DiscussionWithDetails
author: abhi24
conflicting_files: null
created_at: 2023-04-12 23:50:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
      fullname: Abhilash Sanap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhi24
      type: user
    createdAt: '2023-04-13T00:50:04.000Z'
    data:
      edited: true
      editors:
      - abhi24
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
          fullname: Abhilash Sanap
          isHf: false
          isPro: false
          name: abhi24
          type: user
        html: '<p>Hello good people of Databricks!</p>

          <p>I''m a grad student and trying out Dolly v2 for a summarization problem
          using an AWS EC2 instance. I have a limited budget for AWS so cannot afford
          to experiment much. Can you please guide me?</p>

          <ol>

          <li>What is the GPU requirement for running the model?</li>

          <li>The input prompts are going to longer (since it''s Summarization task).
          Would a longer input require higher memory?</li>

          </ol>

          <p>I have used dolly v1. It''s great but slow probably since I''m running
          it with 16 GB GPU provided by two Tesla M60s.<br>Thanks,<br>Abhilash</p>

          '
        raw: "Hello good people of Databricks!\n\nI'm a grad student and trying out\
          \ Dolly v2 for a summarization problem using an AWS EC2 instance. I have\
          \ a limited budget for AWS so cannot afford to experiment much. Can you\
          \ please guide me?\n1. What is the GPU requirement for running the model?\n\
          2. The input prompts are going to longer (since it's Summarization task).\
          \ Would a longer input require higher memory?\n\nI have used dolly v1. It's\
          \ great but slow probably since I'm running it with 16 GB GPU provided by\
          \ two Tesla M60s. \nThanks, \nAbhilash"
        updatedAt: '2023-04-13T00:51:15.693Z'
      numEdits: 1
      reactions: []
    id: 643751bc4aacf7bf787134ab
    type: comment
  author: abhi24
  content: "Hello good people of Databricks!\n\nI'm a grad student and trying out\
    \ Dolly v2 for a summarization problem using an AWS EC2 instance. I have a limited\
    \ budget for AWS so cannot afford to experiment much. Can you please guide me?\n\
    1. What is the GPU requirement for running the model?\n2. The input prompts are\
    \ going to longer (since it's Summarization task). Would a longer input require\
    \ higher memory?\n\nI have used dolly v1. It's great but slow probably since I'm\
    \ running it with 16 GB GPU provided by two Tesla M60s. \nThanks, \nAbhilash"
  created_at: 2023-04-12 23:50:04+00:00
  edited: true
  hidden: false
  id: 643751bc4aacf7bf787134ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-13T01:53:45.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Please see <a rel="nofollow" href="https://github.com/databrickslabs/dolly">https://github.com/databrickslabs/dolly</a><br>A100,
          though it can work on A10 in 8-bit.<br>Yes longer prompts require more memory.
          I think you really want at least an A10. M60s aren''t even really for deep
          learning, though would work with more memory maybe.</p>

          '
        raw: 'Please see https://github.com/databrickslabs/dolly

          A100, though it can work on A10 in 8-bit.

          Yes longer prompts require more memory. I think you really want at least
          an A10. M60s aren''t even really for deep learning, though would work with
          more memory maybe.'
        updatedAt: '2023-04-13T01:53:45.048Z'
      numEdits: 0
      reactions: []
    id: 643760a9369f6f907f5bff4e
    type: comment
  author: srowen
  content: 'Please see https://github.com/databrickslabs/dolly

    A100, though it can work on A10 in 8-bit.

    Yes longer prompts require more memory. I think you really want at least an A10.
    M60s aren''t even really for deep learning, though would work with more memory
    maybe.'
  created_at: 2023-04-13 00:53:45+00:00
  edited: false
  hidden: false
  id: 643760a9369f6f907f5bff4e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
      fullname: Abhilash Sanap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhi24
      type: user
    createdAt: '2023-04-13T02:12:05.000Z'
    data:
      edited: false
      editors:
      - abhi24
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
          fullname: Abhilash Sanap
          isHf: false
          isPro: false
          name: abhi24
          type: user
        html: '<p>Thank you! Helps a lot.</p>

          '
        raw: Thank you! Helps a lot.
        updatedAt: '2023-04-13T02:12:05.642Z'
      numEdits: 0
      reactions: []
    id: 643764f53cb6c4b5707b0cbc
    type: comment
  author: abhi24
  content: Thank you! Helps a lot.
  created_at: 2023-04-13 01:12:05+00:00
  edited: false
  hidden: false
  id: 643764f53cb6c4b5707b0cbc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
      fullname: Daniel Furman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dfurman
      type: user
    createdAt: '2023-04-13T03:42:31.000Z'
    data:
      edited: false
      editors:
      - dfurman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
          fullname: Daniel Furman
          isHf: false
          isPro: false
          name: dfurman
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;abhi24&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/abhi24\">@<span class=\"\
          underline\">abhi24</span></a></span>\n\n\t</span></span> you can load the\
          \ model on a Tesla T4 when using load_in_8bit=True, I was seeing around\
          \ 13 GB in VRAM usage after loading it in. This means you can either do\
          \ it in Google Colab or on any AWS instance with a basic GPU (like a Tesla\
          \ T4).</p>\n"
        raw: '@abhi24 you can load the model on a Tesla T4 when using load_in_8bit=True,
          I was seeing around 13 GB in VRAM usage after loading it in. This means
          you can either do it in Google Colab or on any AWS instance with a basic
          GPU (like a Tesla T4).'
        updatedAt: '2023-04-13T03:42:31.409Z'
      numEdits: 0
      reactions: []
    id: 64377a272c5801f1163d6a4e
    type: comment
  author: dfurman
  content: '@abhi24 you can load the model on a Tesla T4 when using load_in_8bit=True,
    I was seeing around 13 GB in VRAM usage after loading it in. This means you can
    either do it in Google Colab or on any AWS instance with a basic GPU (like a Tesla
    T4).'
  created_at: 2023-04-13 02:42:31+00:00
  edited: false
  hidden: false
  id: 64377a272c5801f1163d6a4e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6cec054b5b25602071cccda685e0e03e.svg
      fullname: Nicolas Chaillan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nicolaschaillan
      type: user
    createdAt: '2023-04-13T03:56:19.000Z'
    data:
      edited: false
      editors:
      - nicolaschaillan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6cec054b5b25602071cccda685e0e03e.svg
          fullname: Nicolas Chaillan
          isHf: false
          isPro: false
          name: nicolaschaillan
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;dfurman&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/dfurman\">@<span class=\"\
          underline\">dfurman</span></a></span>\n\n\t</span></span> where do you set\
          \ load_in_8bit? Is that in the config.json? Thanks!</p>\n"
        raw: '@dfurman where do you set load_in_8bit? Is that in the config.json?
          Thanks!'
        updatedAt: '2023-04-13T03:56:19.583Z'
      numEdits: 0
      reactions: []
    id: 64377d632c5801f1163d8290
    type: comment
  author: nicolaschaillan
  content: '@dfurman where do you set load_in_8bit? Is that in the config.json? Thanks!'
  created_at: 2023-04-13 02:56:19+00:00
  edited: false
  hidden: false
  id: 64377d632c5801f1163d8290
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ac8676fd1dea7860bc175e97453d0eca.svg
      fullname: Andre Broekman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KanonKop
      type: user
    createdAt: '2023-04-13T05:03:12.000Z'
    data:
      edited: true
      editors:
      - KanonKop
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ac8676fd1dea7860bc175e97453d0eca.svg
          fullname: Andre Broekman
          isHf: false
          isPro: false
          name: KanonKop
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;srowen&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/srowen\">@<span class=\"\
          underline\">srowen</span></a></span>\n\n\t</span></span>, I tried to run\
          \ the model on a workstation last night (8c Ryzen CPU, 32GB RAM and RTX3090\
          \ GPU). The model appears to load correctly, but the RAM quickly saturates\
          \ to 100% with the VRAM consumption idling on 2GB (Windows and background\
          \ apps). I am using the GPU version of torch and set the CUDA device ID\
          \ to force use of the GPU, torch also correctly identifies the CUDA device.\
          \ Is more RAM required either way to first load in the model, prior to model\
          \ being transferred to the GPU? Or is the model loaded into RAM either way\
          \ with the inference running solely on the GPU (i.e. time for a RAM upgrade\
          \ :) )?</p>\n"
        raw: '@srowen, I tried to run the model on a workstation last night (8c Ryzen
          CPU, 32GB RAM and RTX3090 GPU). The model appears to load correctly, but
          the RAM quickly saturates to 100% with the VRAM consumption idling on 2GB
          (Windows and background apps). I am using the GPU version of torch and set
          the CUDA device ID to force use of the GPU, torch also correctly identifies
          the CUDA device. Is more RAM required either way to first load in the model,
          prior to model being transferred to the GPU? Or is the model loaded into
          RAM either way with the inference running solely on the GPU (i.e. time for
          a RAM upgrade :) )?'
        updatedAt: '2023-04-13T05:04:31.215Z'
      numEdits: 2
      reactions: []
    id: 64378d1056ecca2228b08fd3
    type: comment
  author: KanonKop
  content: '@srowen, I tried to run the model on a workstation last night (8c Ryzen
    CPU, 32GB RAM and RTX3090 GPU). The model appears to load correctly, but the RAM
    quickly saturates to 100% with the VRAM consumption idling on 2GB (Windows and
    background apps). I am using the GPU version of torch and set the CUDA device
    ID to force use of the GPU, torch also correctly identifies the CUDA device. Is
    more RAM required either way to first load in the model, prior to model being
    transferred to the GPU? Or is the model loaded into RAM either way with the inference
    running solely on the GPU (i.e. time for a RAM upgrade :) )?'
  created_at: 2023-04-13 04:03:12+00:00
  edited: true
  hidden: false
  id: 64378d1056ecca2228b08fd3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
      fullname: Matthew Hayes
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: matthayes
      type: user
    createdAt: '2023-04-13T08:34:39.000Z'
    data:
      edited: false
      editors:
      - matthayes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
          fullname: Matthew Hayes
          isHf: false
          isPro: false
          name: matthayes
          type: user
        html: '<p>We''ve released some smaller models trained on the same data if
          you''d like to try them.  These are 2.8B and 6.9B parameter respectively,
          compared to the current model which is 12B parameters.</p>

          <p><a href="https://huggingface.co/databricks/dolly-v2-2-8b">https://huggingface.co/databricks/dolly-v2-2-8b</a><br><a
          href="https://huggingface.co/databricks/dolly-v2-6-9b">https://huggingface.co/databricks/dolly-v2-6-9b</a></p>

          '
        raw: 'We''ve released some smaller models trained on the same data if you''d
          like to try them.  These are 2.8B and 6.9B parameter respectively, compared
          to the current model which is 12B parameters.


          https://huggingface.co/databricks/dolly-v2-2-8b

          https://huggingface.co/databricks/dolly-v2-6-9b'
        updatedAt: '2023-04-13T08:34:39.090Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\U0001F44D"
        users:
        - JakubKubajek
        - ryvik
        - KanonKop
        - makevoid
        - proteusiq
      - count: 5
        reaction: "\u2764\uFE0F"
        users:
        - Gley
        - moritzwilksch
        - makevoid
        - proteusiq
        - Nik3398
    id: 6437be9f94faafc1a2dd7bcc
    type: comment
  author: matthayes
  content: 'We''ve released some smaller models trained on the same data if you''d
    like to try them.  These are 2.8B and 6.9B parameter respectively, compared to
    the current model which is 12B parameters.


    https://huggingface.co/databricks/dolly-v2-2-8b

    https://huggingface.co/databricks/dolly-v2-6-9b'
  created_at: 2023-04-13 07:34:39+00:00
  edited: false
  hidden: false
  id: 6437be9f94faafc1a2dd7bcc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
      fullname: Daniel Furman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dfurman
      type: user
    createdAt: '2023-04-13T12:03:44.000Z'
    data:
      edited: false
      editors:
      - dfurman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62afc20ca5bd7cef3e1ab3f4/h1cNaEshcUDc-XrycEp6o.jpeg?w=200&h=200&f=face
          fullname: Daniel Furman
          isHf: false
          isPro: false
          name: dfurman
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;nicolaschaillan&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/nicolaschaillan\"\
          >@<span class=\"underline\">nicolaschaillan</span></a></span>\n\n\t</span></span>:</p>\n\
          <p>AutoModelForCausalLM.from_pretrained(\"databricks/dolly-v2-6-9b\", device_map=\"\
          auto\", load_in_8bit=True)</p>\n"
        raw: '@nicolaschaillan:


          AutoModelForCausalLM.from_pretrained("databricks/dolly-v2-6-9b", device_map="auto",
          load_in_8bit=True)'
        updatedAt: '2023-04-13T12:03:44.465Z'
      numEdits: 0
      reactions: []
    id: 6437efa040bf2c4964f5bcc4
    type: comment
  author: dfurman
  content: '@nicolaschaillan:


    AutoModelForCausalLM.from_pretrained("databricks/dolly-v2-6-9b", device_map="auto",
    load_in_8bit=True)'
  created_at: 2023-04-13 11:03:44+00:00
  edited: false
  hidden: false
  id: 6437efa040bf2c4964f5bcc4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9a15c8e95110e8f3a7d9471a88a0c93b.svg
      fullname: Jacob Goss
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jacobgoss
      type: user
    createdAt: '2023-04-13T13:44:01.000Z'
    data:
      edited: true
      editors:
      - jacobgoss
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9a15c8e95110e8f3a7d9471a88a0c93b.svg
          fullname: Jacob Goss
          isHf: false
          isPro: false
          name: jacobgoss
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;KanonKop&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/KanonKop\">@<span class=\"\
          underline\">KanonKop</span></a></span>\n\n\t</span></span> I have been able\
          \ to load and run the 12b model on a g5d.2xlarge instance on AWS which has\
          \ 32GB RAM and an A10 GPU.</p>\n<p>with:<br><code>tokenizer = AutoTokenizer.from_pretrained(\"\
          databricks/dolly-v2-12b\")</code><br><code>model = AutoModelForCausalLM.from_pretrained(\"\
          databricks/dolly-v2-12b\", device_map='auto', load_in_8bit=True)</code></p>\n\
          <p>When loading in the model it leaked a couple of GB into swap but then\
          \ dumped the model into the GPU and RAM usage went down to below 10GB</p>\n"
        raw: '@KanonKop I have been able to load and run the 12b model on a g5d.2xlarge
          instance on AWS which has 32GB RAM and an A10 GPU.


          with:

          ```tokenizer = AutoTokenizer.from_pretrained("databricks/dolly-v2-12b")```

          ```model = AutoModelForCausalLM.from_pretrained("databricks/dolly-v2-12b",
          device_map=''auto'', load_in_8bit=True)```


          When loading in the model it leaked a couple of GB into swap but then dumped
          the model into the GPU and RAM usage went down to below 10GB'
        updatedAt: '2023-04-13T13:44:23.794Z'
      numEdits: 1
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - vladmakes
        - brianadityagdp
        - Dayyan
        - Vikramank
      - count: 2
        reaction: "\U0001F92F"
        users:
        - jaklan
        - Dayyan
    id: 64380721f6a7e4778bb30e39
    type: comment
  author: jacobgoss
  content: '@KanonKop I have been able to load and run the 12b model on a g5d.2xlarge
    instance on AWS which has 32GB RAM and an A10 GPU.


    with:

    ```tokenizer = AutoTokenizer.from_pretrained("databricks/dolly-v2-12b")```

    ```model = AutoModelForCausalLM.from_pretrained("databricks/dolly-v2-12b", device_map=''auto'',
    load_in_8bit=True)```


    When loading in the model it leaked a couple of GB into swap but then dumped the
    model into the GPU and RAM usage went down to below 10GB'
  created_at: 2023-04-13 12:44:01+00:00
  edited: true
  hidden: false
  id: 64380721f6a7e4778bb30e39
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-13T13:49:07.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;dfurman&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/dfurman\">@<span class=\"\
          underline\">dfurman</span></a></span>\n\n\t</span></span> good to know 12b\
          \ works on the T4! I hadn't tried that yet. The smaller models Matt just\
          \ put out should be totally viable on these GPUs without 8-bit.</p>\n"
        raw: '@dfurman good to know 12b works on the T4! I hadn''t tried that yet.
          The smaller models Matt just put out should be totally viable on these GPUs
          without 8-bit.'
        updatedAt: '2023-04-13T13:49:07.604Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - dfurman
    id: 643808536227bd68299e39ce
    type: comment
  author: srowen
  content: '@dfurman good to know 12b works on the T4! I hadn''t tried that yet. The
    smaller models Matt just put out should be totally viable on these GPUs without
    8-bit.'
  created_at: 2023-04-13 12:49:07+00:00
  edited: false
  hidden: false
  id: 643808536227bd68299e39ce
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ac8676fd1dea7860bc175e97453d0eca.svg
      fullname: Andre Broekman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KanonKop
      type: user
    createdAt: '2023-04-14T05:27:20.000Z'
    data:
      edited: false
      editors:
      - KanonKop
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ac8676fd1dea7860bc175e97453d0eca.svg
          fullname: Andre Broekman
          isHf: false
          isPro: false
          name: KanonKop
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;jacobgoss&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/jacobgoss\">@<span class=\"\
          underline\">jacobgoss</span></a></span>\n\n\t</span></span> thanks for the\
          \ feedback, the reduced parameter model worked correctly, will try to rerun\
          \ the full 12b model with 8-bit quantization soon.</p>\n"
        raw: '@jacobgoss thanks for the feedback, the reduced parameter model worked
          correctly, will try to rerun the full 12b model with 8-bit quantization
          soon.'
        updatedAt: '2023-04-14T05:27:20.768Z'
      numEdits: 0
      reactions: []
    id: 6438e43807583375d7828ac0
    type: comment
  author: KanonKop
  content: '@jacobgoss thanks for the feedback, the reduced parameter model worked
    correctly, will try to rerun the full 12b model with 8-bit quantization soon.'
  created_at: 2023-04-14 04:27:20+00:00
  edited: false
  hidden: false
  id: 6438e43807583375d7828ac0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
      fullname: Yucca
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jaklan
      type: user
    createdAt: '2023-04-16T17:20:22.000Z'
    data:
      edited: true
      editors:
      - jaklan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
          fullname: Yucca
          isHf: false
          isPro: false
          name: jaklan
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;jacobgoss&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/jacobgoss\">@<span class=\"\
          underline\">jacobgoss</span></a></span>\n\n\t</span></span> If that's a\
          \ Linux host,  maybe it helps if you turn the swap off with:<br>$ sudo swapoff\
          \ -a</p>\n"
        raw: '@jacobgoss If that''s a Linux host,  maybe it helps if you turn the
          swap off with:

          $ sudo swapoff -a'
        updatedAt: '2023-04-16T17:23:34.132Z'
      numEdits: 1
      reactions: []
    id: 643c2e565ff72e5a4ea02fa2
    type: comment
  author: jaklan
  content: '@jacobgoss If that''s a Linux host,  maybe it helps if you turn the swap
    off with:

    $ sudo swapoff -a'
  created_at: 2023-04-16 16:20:22+00:00
  edited: true
  hidden: false
  id: 643c2e565ff72e5a4ea02fa2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
      fullname: Yucca
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jaklan
      type: user
    createdAt: '2023-04-16T17:26:00.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
          fullname: Yucca
          isHf: false
          isPro: false
          name: jaklan
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-04-20T05:23:48.557Z'
      numEdits: 0
      reactions: []
    id: 643c2fa8e3a7bbe2cf3ccf01
    type: comment
  author: jaklan
  content: This comment has been hidden
  created_at: 2023-04-16 16:26:00+00:00
  edited: true
  hidden: true
  id: 643c2fa8e3a7bbe2cf3ccf01
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1b68ddf81387ee74a25e83d986638c66.svg
      fullname: Jay Liang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jayliang701
      type: user
    createdAt: '2023-04-19T07:25:59.000Z'
    data:
      edited: false
      editors:
      - jayliang701
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1b68ddf81387ee74a25e83d986638c66.svg
          fullname: Jay Liang
          isHf: false
          isPro: false
          name: jayliang701
          type: user
        html: '<p>I can''t run <code>12b</code> and <code>7b</code> model in Google
          Cloud GPU instance with <code>T4/7.5G Mem/100 G disk</code>, and using the
          image <code>Debian 10 based Deep Learning VM with , M107, Base CUDA 11.3,
          Deep Learning VM Image with CUDA 11.3 preinstalled</code></p>

          <p>Always fails by MemoryError. So frustrating .</p>

          <p>Anyone works as expected?</p>

          '
        raw: 'I can''t run `12b` and `7b` model in Google Cloud GPU instance with
          `T4/7.5G Mem/100 G disk`, and using the image `Debian 10 based Deep Learning
          VM with , M107, Base CUDA 11.3, Deep Learning VM Image with CUDA 11.3 preinstalled`


          Always fails by MemoryError. So frustrating .


          Anyone works as expected?'
        updatedAt: '2023-04-19T07:25:59.957Z'
      numEdits: 0
      reactions: []
    id: 643f9787c54114df11c4ce47
    type: comment
  author: jayliang701
  content: 'I can''t run `12b` and `7b` model in Google Cloud GPU instance with `T4/7.5G
    Mem/100 G disk`, and using the image `Debian 10 based Deep Learning VM with ,
    M107, Base CUDA 11.3, Deep Learning VM Image with CUDA 11.3 preinstalled`


    Always fails by MemoryError. So frustrating .


    Anyone works as expected?'
  created_at: 2023-04-19 06:25:59+00:00
  edited: false
  hidden: false
  id: 643f9787c54114df11c4ce47
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-19T10:29:26.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>This is documented in the repo <a rel="nofollow" href="https://github.com/databrickslabs/dolly#training-on-other-instances">https://github.com/databrickslabs/dolly#training-on-other-instances</a><br>A
          T4 isn''t nearly enough, and 7.5GB mem won''t work.<br>You want an A100
          for the largest model, and there are notes there for smaller GPUs</p>

          '
        raw: 'This is documented in the repo https://github.com/databrickslabs/dolly#training-on-other-instances

          A T4 isn''t nearly enough, and 7.5GB mem won''t work.

          You want an A100 for the largest model, and there are notes there for smaller
          GPUs'
        updatedAt: '2023-04-19T10:29:26.763Z'
      numEdits: 0
      reactions: []
    id: 643fc2866fd05d823065341b
    type: comment
  author: srowen
  content: 'This is documented in the repo https://github.com/databrickslabs/dolly#training-on-other-instances

    A T4 isn''t nearly enough, and 7.5GB mem won''t work.

    You want an A100 for the largest model, and there are notes there for smaller
    GPUs'
  created_at: 2023-04-19 09:29:26+00:00
  edited: false
  hidden: false
  id: 643fc2866fd05d823065341b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-19T19:06:33.000Z'
    data:
      status: closed
    id: 64403bb9dbd88206a83d1d41
    type: status-change
  author: srowen
  created_at: 2023-04-19 18:06:33+00:00
  id: 64403bb9dbd88206a83d1d41
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
      fullname: Yucca
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jaklan
      type: user
    createdAt: '2023-04-20T03:49:02.000Z'
    data:
      edited: false
      editors:
      - jaklan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
          fullname: Yucca
          isHf: false
          isPro: false
          name: jaklan
          type: user
        html: '<p>What is Google Colab, how can it be used to run these models?</p>

          '
        raw: What is Google Colab, how can it be used to run these models?
        updatedAt: '2023-04-20T03:49:02.651Z'
      numEdits: 0
      reactions: []
    id: 6440b62e194b02fd309d1897
    type: comment
  author: jaklan
  content: What is Google Colab, how can it be used to run these models?
  created_at: 2023-04-20 02:49:02+00:00
  edited: false
  hidden: false
  id: 6440b62e194b02fd309d1897
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
      fullname: Yucca
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jaklan
      type: user
    createdAt: '2023-04-20T03:50:35.000Z'
    data:
      edited: false
      editors:
      - jaklan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
          fullname: Yucca
          isHf: false
          isPro: false
          name: jaklan
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;srowen&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/srowen\">@<span class=\"\
          underline\">srowen</span></a></span>\n\n\t</span></span> Why close this\
          \ discussion?</p>\n"
        raw: '@srowen Why close this discussion?'
        updatedAt: '2023-04-20T03:50:35.842Z'
      numEdits: 0
      reactions: []
    id: 6440b68b2113f7dfcb6045a1
    type: comment
  author: jaklan
  content: '@srowen Why close this discussion?'
  created_at: 2023-04-20 02:50:35+00:00
  edited: false
  hidden: false
  id: 6440b68b2113f7dfcb6045a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-20T04:05:06.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>I think the question is answered, no? you seem to be asking something
          unrelated, too. I''m not sure I understand</p>

          '
        raw: I think the question is answered, no? you seem to be asking something
          unrelated, too. I'm not sure I understand
        updatedAt: '2023-04-20T04:05:06.028Z'
      numEdits: 0
      reactions: []
    id: 6440b9f22113f7dfcb609b40
    type: comment
  author: srowen
  content: I think the question is answered, no? you seem to be asking something unrelated,
    too. I'm not sure I understand
  created_at: 2023-04-20 03:05:06+00:00
  edited: false
  hidden: false
  id: 6440b9f22113f7dfcb609b40
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
      fullname: Yucca
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jaklan
      type: user
    createdAt: '2023-04-20T04:06:47.000Z'
    data:
      edited: false
      editors:
      - jaklan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
          fullname: Yucca
          isHf: false
          isPro: false
          name: jaklan
          type: user
        html: "<h2 id=\"based-on-srowen-answers-the-minimum-gpu-requirement-to-even-run-this-model-is-a100-which-costs-10k-so-you-might-not-in-the-future-call-this-model-as-runnable-in-home-pc-i-bet-no-one-has-10k-gpu-in-home-pc\"\
          >Based on <span data-props=\"{&quot;user&quot;:&quot;srowen&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/srowen\">@<span class=\"\
          underline\">srowen</span></a></span>\n\n\t</span></span> answers the minimum\
          \ GPU requirement to even run this model is A100, which costs $10k+, so\
          \ you might not in the future call this model as \"runnable in home PC\"\
          , I bet no-one has $10k GPU in home PC.</h2>\n<h2 id=\"powering-many-of-these-applications-is-a-roughly-10000-chip-thats-become-one-of-the-most-critical-tools-in-the-artificial-intelligence-industry-the-nvidia-a100\"\
          >Powering many of these applications is a roughly $10,000 chip that\u2019\
          s become one of the most critical tools in the artificial intelligence industry:\
          \ The Nvidia A100.</h2>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/643c2cf686ab6dbe34efbcdb/M_kZ9D_PoE1sw_3RVyJNY.png\"\
          ><img alt=\"Screenshot_20230420-070226.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/643c2cf686ab6dbe34efbcdb/M_kZ9D_PoE1sw_3RVyJNY.png\"\
          ></a></p>\n"
        raw: "Based on @srowen answers the minimum GPU requirement to even run this\
          \ model is A100, which costs $10k+, so you might not in the future call\
          \ this model as \"runnable in home PC\", I bet no-one has $10k GPU in home\
          \ PC.\n----\nPowering many of these applications is a roughly $10,000 chip\
          \ that\u2019s become one of the most critical tools in the artificial intelligence\
          \ industry: The Nvidia A100.\n----\n![Screenshot_20230420-070226.png](https://cdn-uploads.huggingface.co/production/uploads/643c2cf686ab6dbe34efbcdb/M_kZ9D_PoE1sw_3RVyJNY.png)"
        updatedAt: '2023-04-20T04:06:47.842Z'
      numEdits: 0
      reactions: []
    id: 6440ba57194b02fd309d775a
    type: comment
  author: jaklan
  content: "Based on @srowen answers the minimum GPU requirement to even run this\
    \ model is A100, which costs $10k+, so you might not in the future call this model\
    \ as \"runnable in home PC\", I bet no-one has $10k GPU in home PC.\n----\nPowering\
    \ many of these applications is a roughly $10,000 chip that\u2019s become one\
    \ of the most critical tools in the artificial intelligence industry: The Nvidia\
    \ A100.\n----\n![Screenshot_20230420-070226.png](https://cdn-uploads.huggingface.co/production/uploads/643c2cf686ab6dbe34efbcdb/M_kZ9D_PoE1sw_3RVyJNY.png)"
  created_at: 2023-04-20 03:06:47+00:00
  edited: false
  hidden: false
  id: 6440ba57194b02fd309d775a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
      fullname: Yucca
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jaklan
      type: user
    createdAt: '2023-04-20T04:11:43.000Z'
    data:
      edited: false
      editors:
      - jaklan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
          fullname: Yucca
          isHf: false
          isPro: false
          name: jaklan
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;srowen&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/srowen\">@<span class=\"\
          underline\">srowen</span></a></span>\n\n\t</span></span>  1. Where is the\
          \ topic of this discussion answered?</p>\n<p><span data-props=\"{&quot;user&quot;:&quot;srowen&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/srowen\"\
          >@<span class=\"underline\">srowen</span></a></span>\n\n\t</span></span>\
          \ 2. So you are closing this because I am asking something unrelated? How\
          \ is asking about possible GPUs in which to run ths is unrelated,when the\
          \ topic is \"GPU requirements to run this model\"</p>\n<p><span data-props=\"\
          {&quot;user&quot;:&quot;srowen&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/srowen\">@<span class=\"underline\">srowen</span></a></span>\n\
          \n\t</span></span> 3. What you didn't understand, something wrong with language\
          \ or questions?</p>\n"
        raw: '@srowen  1. Where is the topic of this discussion answered?


          @srowen 2. So you are closing this because I am asking something unrelated?
          How is asking about possible GPUs in which to run ths is unrelated,when
          the topic is "GPU requirements to run this model"


          @srowen 3. What you didn''t understand, something wrong with language or
          questions?'
        updatedAt: '2023-04-20T04:11:43.912Z'
      numEdits: 0
      reactions: []
    id: 6440bb7f2113f7dfcb60bfac
    type: comment
  author: jaklan
  content: '@srowen  1. Where is the topic of this discussion answered?


    @srowen 2. So you are closing this because I am asking something unrelated? How
    is asking about possible GPUs in which to run ths is unrelated,when the topic
    is "GPU requirements to run this model"


    @srowen 3. What you didn''t understand, something wrong with language or questions?'
  created_at: 2023-04-20 03:11:43+00:00
  edited: false
  hidden: false
  id: 6440bb7f2113f7dfcb60bfac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
      fullname: Yucca
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jaklan
      type: user
    createdAt: '2023-04-20T04:18:25.000Z'
    data:
      edited: false
      editors:
      - jaklan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
          fullname: Yucca
          isHf: false
          isPro: false
          name: jaklan
          type: user
        html: '<p>Also, most of the comments in this discussion are about not being
          able to run any models, with any GPUs, or comments about failing to even
          run model,  no comments about successful runs and inferings from the model
          with any of the GPUs tyey are trying, and no successful training runs either.</p>

          <p>And you conclude this can be closed as resolved, seems that you couldn''t
          care less whether community is able to actually run and use these models
          or not.</p>

          '
        raw: 'Also, most of the comments in this discussion are about not being able
          to run any models, with any GPUs, or comments about failing to even run
          model,  no comments about successful runs and inferings from the model with
          any of the GPUs tyey are trying, and no successful training runs either.


          And you conclude this can be closed as resolved, seems that you couldn''t
          care less whether community is able to actually run and use these models
          or not.'
        updatedAt: '2023-04-20T04:18:25.990Z'
      numEdits: 0
      reactions: []
    id: 6440bd11f830989e0571a72f
    type: comment
  author: jaklan
  content: 'Also, most of the comments in this discussion are about not being able
    to run any models, with any GPUs, or comments about failing to even run model,  no
    comments about successful runs and inferings from the model with any of the GPUs
    tyey are trying, and no successful training runs either.


    And you conclude this can be closed as resolved, seems that you couldn''t care
    less whether community is able to actually run and use these models or not.'
  created_at: 2023-04-20 03:18:25+00:00
  edited: false
  hidden: false
  id: 6440bd11f830989e0571a72f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-20T04:21:55.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;jaklan&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/jaklan\">@<span class=\"\
          underline\">jaklan</span></a></span>\n\n\t</span></span> , slow your roll\
          \ there.<br>I think you're not reading the docs and discussion above. You\
          \ don't need an A100; you certainly do not buy one to start using this.\
          \ These are, obviously, available in the cloud. You can run the 12B model\
          \ on an A10 or V100 or a T4 (16GB) with 8bit. In fact, that's what was discussed\
          \ above. That's about all this thread is about. That's why I don't know\
          \ how to answer \"where is the answer\"<br>You're asking things like \"\
          what is Colab?\" which is unrelated, and then re-asking the same question.<br>It's\
          \ general best practice anywhere to just start new threads for different\
          \ questions, <em>if</em> your question isn't already answered.</p>\n"
        raw: 'Hey @jaklan , slow your roll there.

          I think you''re not reading the docs and discussion above. You don''t need
          an A100; you certainly do not buy one to start using this. These are, obviously,
          available in the cloud. You can run the 12B model on an A10 or V100 or a
          T4 (16GB) with 8bit. In fact, that''s what was discussed above. That''s
          about all this thread is about. That''s why I don''t know how to answer
          "where is the answer"

          You''re asking things like "what is Colab?" which is unrelated, and then
          re-asking the same question.

          It''s general best practice anywhere to just start new threads for different
          questions, _if_ your question isn''t already answered.'
        updatedAt: '2023-04-20T04:21:55.487Z'
      numEdits: 0
      reactions: []
    id: 6440bde304050d3970c78a01
    type: comment
  author: srowen
  content: 'Hey @jaklan , slow your roll there.

    I think you''re not reading the docs and discussion above. You don''t need an
    A100; you certainly do not buy one to start using this. These are, obviously,
    available in the cloud. You can run the 12B model on an A10 or V100 or a T4 (16GB)
    with 8bit. In fact, that''s what was discussed above. That''s about all this thread
    is about. That''s why I don''t know how to answer "where is the answer"

    You''re asking things like "what is Colab?" which is unrelated, and then re-asking
    the same question.

    It''s general best practice anywhere to just start new threads for different questions,
    _if_ your question isn''t already answered.'
  created_at: 2023-04-20 03:21:55+00:00
  edited: false
  hidden: false
  id: 6440bde304050d3970c78a01
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
      fullname: Yucca
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jaklan
      type: user
    createdAt: '2023-04-20T04:35:08.000Z'
    data:
      edited: true
      editors:
      - jaklan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
          fullname: Yucca
          isHf: false
          isPro: false
          name: jaklan
          type: user
        html: "<p>Why so abusive <span data-props=\"{&quot;user&quot;:&quot;srowen&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/srowen\"\
          >@<span class=\"underline\">srowen</span></a></span>\n\n\t</span></span>?</p>\n\
          <p>If you make claims about other accounts, you are stepping out of scope,\
          \ and you are constantly insulting, towards me specifically, closed this\
          \ discussion because I am asking wrong questions, and acting as an admin\
          \ who doesn't like that community comments or asks questions.</p>\n<p>Reporting\
          \ you for abuse!</p>\n"
        raw: 'Why so abusive @srowen?


          If you make claims about other accounts, you are stepping out of scope,
          and you are constantly insulting, towards me specifically, closed this discussion
          because I am asking wrong questions, and acting as an admin who doesn''t
          like that community comments or asks questions.


          Reporting you for abuse!'
        updatedAt: '2023-04-20T04:50:18.518Z'
      numEdits: 1
      reactions: []
    id: 6440c0fc2113f7dfcb615044
    type: comment
  author: jaklan
  content: 'Why so abusive @srowen?


    If you make claims about other accounts, you are stepping out of scope, and you
    are constantly insulting, towards me specifically, closed this discussion because
    I am asking wrong questions, and acting as an admin who doesn''t like that community
    comments or asks questions.


    Reporting you for abuse!'
  created_at: 2023-04-20 03:35:08+00:00
  edited: true
  hidden: false
  id: 6440c0fc2113f7dfcb615044
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-20T04:42:03.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>(This is actually Hugging Face.) I don''t understand your tone or
          complaint here. This isn''t your question that I answered and deemed finished.
          You added both the same, and a different, question after. Just don''t see
          any other way to read the timeline?<br>I am an ''admin'' for these repos.<br>"Closing"
          a discussion is like marking an issue resolved. I don''t get why that''s
          perceived as negative.<br>You are welcome to report whatever you want, but,
          I think the discussion speaks for itself.<br>I will not interact with you
          more on this. I will interact with normal boring civil threads that 99.9%
          of people manage here.</p>

          '
        raw: '(This is actually Hugging Face.) I don''t understand your tone or complaint
          here. This isn''t your question that I answered and deemed finished. You
          added both the same, and a different, question after. Just don''t see any
          other way to read the timeline?

          I am an ''admin'' for these repos.

          "Closing" a discussion is like marking an issue resolved. I don''t get why
          that''s perceived as negative.

          You are welcome to report whatever you want, but, I think the discussion
          speaks for itself.

          I will not interact with you more on this. I will interact with normal boring
          civil threads that 99.9% of people manage here.'
        updatedAt: '2023-04-20T04:42:03.359Z'
      numEdits: 0
      reactions: []
    id: 6440c29b04050d3970c80226
    type: comment
  author: srowen
  content: '(This is actually Hugging Face.) I don''t understand your tone or complaint
    here. This isn''t your question that I answered and deemed finished. You added
    both the same, and a different, question after. Just don''t see any other way
    to read the timeline?

    I am an ''admin'' for these repos.

    "Closing" a discussion is like marking an issue resolved. I don''t get why that''s
    perceived as negative.

    You are welcome to report whatever you want, but, I think the discussion speaks
    for itself.

    I will not interact with you more on this. I will interact with normal boring
    civil threads that 99.9% of people manage here.'
  created_at: 2023-04-20 03:42:03+00:00
  edited: false
  hidden: false
  id: 6440c29b04050d3970c80226
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
      fullname: Yucca
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jaklan
      type: user
    createdAt: '2023-04-20T04:45:59.000Z'
    data:
      edited: false
      editors:
      - jaklan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
          fullname: Yucca
          isHf: false
          isPro: false
          name: jaklan
          type: user
        html: '<blockquote>

          <p>I think the question is answered, no? you seem to be asking something
          unrelated, too. I''m not sure I understand</p>

          </blockquote>

          <p>No it isn''t.</p>

          <p>No, I am not asking something unrelated, I am asking something on topic:
          what is minimum GPU requirement to run this model, and how?</p>

          <p>If you don''t understand, why did you answer then, I didn''t ask you
          I asked the forum/community!</p>

          '
        raw: '> I think the question is answered, no? you seem to be asking something
          unrelated, too. I''m not sure I understand


          No it isn''t.


          No, I am not asking something unrelated, I am asking something on topic:
          what is minimum GPU requirement to run this model, and how?


          If you don''t understand, why did you answer then, I didn''t ask you I asked
          the forum/community!'
        updatedAt: '2023-04-20T04:45:59.190Z'
      numEdits: 0
      reactions: []
    id: 6440c387d42c82bc5b7d6ba2
    type: comment
  author: jaklan
  content: '> I think the question is answered, no? you seem to be asking something
    unrelated, too. I''m not sure I understand


    No it isn''t.


    No, I am not asking something unrelated, I am asking something on topic: what
    is minimum GPU requirement to run this model, and how?


    If you don''t understand, why did you answer then, I didn''t ask you I asked the
    forum/community!'
  created_at: 2023-04-20 03:45:59+00:00
  edited: false
  hidden: false
  id: 6440c387d42c82bc5b7d6ba2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-20T04:50:41.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Last time: <a href="https://huggingface.co/databricks/dolly-v2-12b/discussions/9#643fc2866fd05d823065341b">https://huggingface.co/databricks/dolly-v2-12b/discussions/9#643fc2866fd05d823065341b</a><br>I
          do feel it is appropriate to close discussions that have concluded, where
          further comments aren''t adding anything - re-asking what''s been answered,
          "me too", different questions. Of course, anyone is welcome to start a new
          discussion, hopefully not a duplicate. It keeps the list of active discussions
          clean, and keeps separate threads separate.<br>I understand the question,
          and your question. I don''t understand your puzzlement at the above.</p>

          '
        raw: 'Last time: https://huggingface.co/databricks/dolly-v2-12b/discussions/9#643fc2866fd05d823065341b

          I do feel it is appropriate to close discussions that have concluded, where
          further comments aren''t adding anything - re-asking what''s been answered,
          "me too", different questions. Of course, anyone is welcome to start a new
          discussion, hopefully not a duplicate. It keeps the list of active discussions
          clean, and keeps separate threads separate.

          I understand the question, and your question. I don''t understand your puzzlement
          at the above.'
        updatedAt: '2023-04-20T04:50:41.879Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - timesler
    id: 6440c4a1f830989e05725c75
    type: comment
  author: srowen
  content: 'Last time: https://huggingface.co/databricks/dolly-v2-12b/discussions/9#643fc2866fd05d823065341b

    I do feel it is appropriate to close discussions that have concluded, where further
    comments aren''t adding anything - re-asking what''s been answered, "me too",
    different questions. Of course, anyone is welcome to start a new discussion, hopefully
    not a duplicate. It keeps the list of active discussions clean, and keeps separate
    threads separate.

    I understand the question, and your question. I don''t understand your puzzlement
    at the above.'
  created_at: 2023-04-20 03:50:41+00:00
  edited: false
  hidden: false
  id: 6440c4a1f830989e05725c75
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
      fullname: Yucca
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jaklan
      type: user
    createdAt: '2023-04-20T05:19:57.000Z'
    data:
      edited: false
      editors:
      - jaklan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/86c838d1f74a6ccd5522dbcae1d28a09.svg
          fullname: Yucca
          isHf: false
          isPro: false
          name: jaklan
          type: user
        html: "<blockquote>\n<p>(This is actually Hugging Face.) I don't understand\
          \ your tone or complaint here. This isn't your question that I answered\
          \ and deemed finished. You added both the same, and a different, question\
          \ after. Just don't see any other way to read the timeline?<br>I am an 'admin'\
          \ for these repos.<br>\"Closing\" a discussion is like marking an issue\
          \ resolved. I don't get why that's perceived as negative.<br>You are welcome\
          \ to report whatever you want, but, I think the discussion speaks for itself.<br>I\
          \ will not interact with you more on this. I will interact with normal boring\
          \ civil threads that 99.9% of people manage here.</p>\n</blockquote>\n<hr>\n\
          <p>As you wish \U0001F4AA (because of # posts where <span data-props=\"\
          {&quot;user&quot;:&quot;srowen&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/srowen\">@<span class=\"underline\">srowen</span></a></span>\n\
          \n\t</span></span> claims I've done things which I haven't: haven't asked\
          \ unrelated questions, haven't re-asked them etc, and because of # posts\
          \ where <span data-props=\"{&quot;user&quot;:&quot;srowen&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/srowen\">@<span class=\"\
          underline\">srowen</span></a></span>\n\n\t</span></span> insults and attacks\
          \ me personally \u203C\uFE0F<br><a href=\"https://huggingface.co/databricks/dolly-v2-12b/discussions/47#6440c9417841867cd5b7a068\"\
          >https://huggingface.co/databricks/dolly-v2-12b/discussions/47#6440c9417841867cd5b7a068</a></p>\n"
        raw: "> (This is actually Hugging Face.) I don't understand your tone or complaint\
          \ here. This isn't your question that I answered and deemed finished. You\
          \ added both the same, and a different, question after. Just don't see any\
          \ other way to read the timeline?\n> I am an 'admin' for these repos.\n\
          > \"Closing\" a discussion is like marking an issue resolved. I don't get\
          \ why that's perceived as negative.\n> You are welcome to report whatever\
          \ you want, but, I think the discussion speaks for itself.\n> I will not\
          \ interact with you more on this. I will interact with normal boring civil\
          \ threads that 99.9% of people manage here.\n----\nAs you wish \U0001F4AA\
          \ (because of # posts where @srowen claims I've done things which I haven't:\
          \ haven't asked unrelated questions, haven't re-asked them etc, and because\
          \ of # posts where @srowen insults and attacks me personally \u203C\uFE0F\
          \nhttps://huggingface.co/databricks/dolly-v2-12b/discussions/47#6440c9417841867cd5b7a068"
        updatedAt: '2023-04-20T05:19:57.794Z'
      numEdits: 0
      reactions: []
    id: 6440cb7dfab821b49bc4fdc8
    type: comment
  author: jaklan
  content: "> (This is actually Hugging Face.) I don't understand your tone or complaint\
    \ here. This isn't your question that I answered and deemed finished. You added\
    \ both the same, and a different, question after. Just don't see any other way\
    \ to read the timeline?\n> I am an 'admin' for these repos.\n> \"Closing\" a discussion\
    \ is like marking an issue resolved. I don't get why that's perceived as negative.\n\
    > You are welcome to report whatever you want, but, I think the discussion speaks\
    \ for itself.\n> I will not interact with you more on this. I will interact with\
    \ normal boring civil threads that 99.9% of people manage here.\n----\nAs you\
    \ wish \U0001F4AA (because of # posts where @srowen claims I've done things which\
    \ I haven't: haven't asked unrelated questions, haven't re-asked them etc, and\
    \ because of # posts where @srowen insults and attacks me personally \u203C\uFE0F\
    \nhttps://huggingface.co/databricks/dolly-v2-12b/discussions/47#6440c9417841867cd5b7a068"
  created_at: 2023-04-20 04:19:57+00:00
  edited: false
  hidden: false
  id: 6440cb7dfab821b49bc4fdc8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660775548920-628d998a2b60ec0f336cc1eb.png?w=200&h=200&f=face
      fullname: Carl Silva
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: silvacarl
      type: user
    createdAt: '2023-04-28T15:24:05.000Z'
    data:
      edited: false
      editors:
      - silvacarl
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660775548920-628d998a2b60ec0f336cc1eb.png?w=200&h=200&f=face
          fullname: Carl Silva
          isHf: false
          isPro: true
          name: silvacarl
          type: user
        html: '<p>try one of these, you can pick any size you want according to your
          budget:</p>

          <p><a rel="nofollow" href="https://cloud.lambdalabs.com/">https://cloud.lambdalabs.com/</a><br><a
          rel="nofollow" href="https://cloud.coreweave.com/">https://cloud.coreweave.com/</a><br><a
          rel="nofollow" href="https://paperspace.com/">https://paperspace.com/</a></p>

          '
        raw: 'try one of these, you can pick any size you want according to your budget:


          https://cloud.lambdalabs.com/

          https://cloud.coreweave.com/

          https://paperspace.com/'
        updatedAt: '2023-04-28T15:24:05.718Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - jtruxon
    id: 644be515ed08a4fdf4d85fe6
    type: comment
  author: silvacarl
  content: 'try one of these, you can pick any size you want according to your budget:


    https://cloud.lambdalabs.com/

    https://cloud.coreweave.com/

    https://paperspace.com/'
  created_at: 2023-04-28 14:24:05+00:00
  edited: false
  hidden: false
  id: 644be515ed08a4fdf4d85fe6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: databricks/dolly-v2-12b
repo_type: model
status: closed
target_branch: null
title: GPU requirement for simply running the model
