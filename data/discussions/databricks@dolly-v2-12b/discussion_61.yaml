!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dalichuqiji
conflicting_files: null
created_at: 2023-05-02 22:44:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/559b42b0a874335829b7d0dcaf50104a.svg
      fullname: Wendi Lin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dalichuqiji
      type: user
    createdAt: '2023-05-02T23:44:06.000Z'
    data:
      edited: false
      editors:
      - dalichuqiji
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/559b42b0a874335829b7d0dcaf50104a.svg
          fullname: Wendi Lin
          isHf: false
          isPro: false
          name: dalichuqiji
          type: user
        html: '<p>I''m trying to do summarization of a long conversation. The instruction
          is like:<br>""" Here is the conversation of two people:<br>personA: hello,
          how are you doing?<br>personB: not bad. I''m asking a question for 1 min<br>personA:
          I''m answering for 2 mins<br>personB: blablabla(200 tokens)<br>personA:
          bablablabla(300 tokens)</p>

          <p>Summarize the conversation.<br>"""<br>with top_p 95%, top_k 0, max_tokens
          100. and with langchain code in the model card.</p>

          <p>I could understand LLM generate random answers. But how come Dollyv2
          generates identical text as input for at least 30% of the predictions? Is
          there an explanation for this? Sometimes , it only generates"personA: hello,
          how are you doing?personB: not" and truncate the sentence </p>

          <p>Often, the summaries are not that good as if the model fail to summarize
          what''s important or fail to understand the conversation totally, which
          is expected, and I''m hoping,  with fine-tuning, the results would be better.
          But I''m not sure the behavior of generate identical results  can be resolved
          by fine-tuning, as it looks like a bug to me.</p>

          '
        raw: "I'm trying to do summarization of a long conversation. The instruction\
          \ is like:\r\n\"\"\" Here is the conversation of two people:\r\npersonA:\
          \ hello, how are you doing?\r\npersonB: not bad. I'm asking a question for\
          \ 1 min\r\npersonA: I'm answering for 2 mins\r\npersonB: blablabla(200 tokens)\r\
          \npersonA: bablablabla(300 tokens)\r\n\r\nSummarize the conversation.\r\n\
          \"\"\"\r\nwith top_p 95%, top_k 0, max_tokens 100. and with langchain code\
          \ in the model card.\r\n\r\nI could understand LLM generate random answers.\
          \ But how come Dollyv2 generates identical text as input for at least 30%\
          \ of the predictions? Is there an explanation for this? Sometimes , it only\
          \ generates\"personA: hello, how are you doing?personB: not\" and truncate\
          \ the sentence \r\n\r\nOften, the summaries are not that good as if the\
          \ model fail to summarize what's important or fail to understand the conversation\
          \ totally, which is expected, and I'm hoping,  with fine-tuning, the results\
          \ would be better. But I'm not sure the behavior of generate identical results\
          \  can be resolved by fine-tuning, as it looks like a bug to me."
        updatedAt: '2023-05-02T23:44:06.332Z'
      numEdits: 0
      reactions: []
    id: 6451a04604397681bcfd0c92
    type: comment
  author: dalichuqiji
  content: "I'm trying to do summarization of a long conversation. The instruction\
    \ is like:\r\n\"\"\" Here is the conversation of two people:\r\npersonA: hello,\
    \ how are you doing?\r\npersonB: not bad. I'm asking a question for 1 min\r\n\
    personA: I'm answering for 2 mins\r\npersonB: blablabla(200 tokens)\r\npersonA:\
    \ bablablabla(300 tokens)\r\n\r\nSummarize the conversation.\r\n\"\"\"\r\nwith\
    \ top_p 95%, top_k 0, max_tokens 100. and with langchain code in the model card.\r\
    \n\r\nI could understand LLM generate random answers. But how come Dollyv2 generates\
    \ identical text as input for at least 30% of the predictions? Is there an explanation\
    \ for this? Sometimes , it only generates\"personA: hello, how are you doing?personB:\
    \ not\" and truncate the sentence \r\n\r\nOften, the summaries are not that good\
    \ as if the model fail to summarize what's important or fail to understand the\
    \ conversation totally, which is expected, and I'm hoping,  with fine-tuning,\
    \ the results would be better. But I'm not sure the behavior of generate identical\
    \ results  can be resolved by fine-tuning, as it looks like a bug to me."
  created_at: 2023-05-02 22:44:06+00:00
  edited: false
  hidden: false
  id: 6451a04604397681bcfd0c92
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-02T23:48:30.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>It''s not really trained on this type of input and response. There
          isn''t much signal in your input either. Have you tried increasing the repetition
          penalty and temperature?</p>

          '
        raw: It's not really trained on this type of input and response. There isn't
          much signal in your input either. Have you tried increasing the repetition
          penalty and temperature?
        updatedAt: '2023-05-02T23:48:30.369Z'
      numEdits: 0
      reactions: []
    id: 6451a14e5fb40b9f50b88dc7
    type: comment
  author: srowen
  content: It's not really trained on this type of input and response. There isn't
    much signal in your input either. Have you tried increasing the repetition penalty
    and temperature?
  created_at: 2023-05-02 22:48:30+00:00
  edited: false
  hidden: false
  id: 6451a14e5fb40b9f50b88dc7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/559b42b0a874335829b7d0dcaf50104a.svg
      fullname: Wendi Lin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dalichuqiji
      type: user
    createdAt: '2023-05-03T19:20:44.000Z'
    data:
      edited: false
      editors:
      - dalichuqiji
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/559b42b0a874335829b7d0dcaf50104a.svg
          fullname: Wendi Lin
          isHf: false
          isPro: false
          name: dalichuqiji
          type: user
        html: "<p>Thanks. one follow up question,  I think the bad_words_list might\
          \ help for my case, however I still see a large amount of bad words in the\
          \ output. Do you know how to do badwords with Dolly.<br>I followed the instruction\
          \ here <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/issues/14206\"\
          >https://github.com/huggingface/transformers/issues/14206</a>, and my code\
          \ is</p>\n<pre><code class=\"language-tokenizer\">....\n   generate_text\
          \ = InstructionTextGenerationPipeline(model=model,\n                   \
          \                                  tokenizer=tokenizer,bad_words_ids=tokenizer(bad_words_list).input_ids\n\
          </code></pre>\n"
        raw: "Thanks. one follow up question,  I think the bad_words_list might help\
          \ for my case, however I still see a large amount of bad words in the output.\
          \ Do you know how to do badwords with Dolly.\nI followed the instruction\
          \ here https://github.com/huggingface/transformers/issues/14206, and my\
          \ code is\n ```tokenizer = AutoTokenizer.from_pretrained(\"dolly\", add_prefix_space=True,\
          \  add_special_tokens=False)\n....\n    generate_text = InstructionTextGenerationPipeline(model=model,\n\
          \                                                      tokenizer=tokenizer,bad_words_ids=tokenizer(bad_words_list).input_ids\n\
          ```"
        updatedAt: '2023-05-03T19:20:44.235Z'
      numEdits: 0
      reactions: []
    id: 6452b40c8fe6558e3282022d
    type: comment
  author: dalichuqiji
  content: "Thanks. one follow up question,  I think the bad_words_list might help\
    \ for my case, however I still see a large amount of bad words in the output.\
    \ Do you know how to do badwords with Dolly.\nI followed the instruction here\
    \ https://github.com/huggingface/transformers/issues/14206, and my code is\n ```tokenizer\
    \ = AutoTokenizer.from_pretrained(\"dolly\", add_prefix_space=True,  add_special_tokens=False)\n\
    ....\n    generate_text = InstructionTextGenerationPipeline(model=model,\n   \
    \                                                   tokenizer=tokenizer,bad_words_ids=tokenizer(bad_words_list).input_ids\n\
    ```"
  created_at: 2023-05-03 18:20:44+00:00
  edited: false
  hidden: false
  id: 6452b40c8fe6558e3282022d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/559b42b0a874335829b7d0dcaf50104a.svg
      fullname: Wendi Lin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dalichuqiji
      type: user
    createdAt: '2023-05-05T18:09:39.000Z'
    data:
      status: closed
    id: 64554663a473375be575a85d
    type: status-change
  author: dalichuqiji
  created_at: 2023-05-05 17:09:39+00:00
  id: 64554663a473375be575a85d
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 61
repo_id: databricks/dolly-v2-12b
repo_type: model
status: closed
target_branch: null
title: generate identical text as input
