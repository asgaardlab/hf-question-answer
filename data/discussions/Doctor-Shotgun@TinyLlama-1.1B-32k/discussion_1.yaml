!!python/object:huggingface_hub.community.DiscussionWithDetails
author: streamerbtw1002
conflicting_files: null
created_at: 2024-01-04 13:26:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b33ddbfd6aa1dbcfa4a8c95066cdbc3a.svg
      fullname: James Phifer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: streamerbtw1002
      type: user
    createdAt: '2024-01-04T13:26:57.000Z'
    data:
      edited: false
      editors:
      - streamerbtw1002
      hidden: false
      identifiedLanguage:
        language: fa
        probability: 0.0742349922657013
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b33ddbfd6aa1dbcfa4a8c95066cdbc3a.svg
          fullname: James Phifer
          isHf: false
          isPro: false
          name: streamerbtw1002
          type: user
        html: '<p>''Get'' error</p>

          '
        raw: '''Get'' error'
        updatedAt: '2024-01-04T13:26:57.938Z'
      numEdits: 0
      reactions: []
    id: 6596b221b3a922756ccd6857
    type: comment
  author: streamerbtw1002
  content: '''Get'' error'
  created_at: 2024-01-04 13:26:57+00:00
  edited: false
  hidden: false
  id: 6596b221b3a922756ccd6857
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670736706483-632b9f9866f28bf34ae85487.jpeg?w=200&h=200&f=face
      fullname: Doctor Shotgun
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Doctor-Shotgun
      type: user
    createdAt: '2024-01-04T16:06:41.000Z'
    data:
      edited: false
      editors:
      - Doctor-Shotgun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9848160147666931
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670736706483-632b9f9866f28bf34ae85487.jpeg?w=200&h=200&f=face
          fullname: Doctor Shotgun
          isHf: false
          isPro: false
          name: Doctor-Shotgun
          type: user
        html: '<p>Nice, might need a little bit more info to help you with that one.</p>

          '
        raw: Nice, might need a little bit more info to help you with that one.
        updatedAt: '2024-01-04T16:06:41.942Z'
      numEdits: 0
      reactions: []
    id: 6596d7914dbb962b7c230ccd
    type: comment
  author: Doctor-Shotgun
  content: Nice, might need a little bit more info to help you with that one.
  created_at: 2024-01-04 16:06:41+00:00
  edited: false
  hidden: false
  id: 6596d7914dbb962b7c230ccd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7e32309ea33f1786f1597dfb4288144e.svg
      fullname: Matt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mattdlockyer
      type: user
    createdAt: '2024-01-05T23:09:02.000Z'
    data:
      edited: false
      editors:
      - mattdlockyer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.28570544719696045
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7e32309ea33f1786f1597dfb4288144e.svg
          fullname: Matt
          isHf: false
          isPro: false
          name: mattdlockyer
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/65866765085a5bce61f45282/XEot546vDqwHgxSx4GOij.jpeg"><img
          alt="Screenshot_20240105_150839_Brave.jpg" src="https://cdn-uploads.huggingface.co/production/uploads/65866765085a5bce61f45282/XEot546vDqwHgxSx4GOij.jpeg"></a></p>

          '
        raw: '

          ![Screenshot_20240105_150839_Brave.jpg](https://cdn-uploads.huggingface.co/production/uploads/65866765085a5bce61f45282/XEot546vDqwHgxSx4GOij.jpeg)

          '
        updatedAt: '2024-01-05T23:09:02.325Z'
      numEdits: 0
      reactions: []
    id: 65988c0ea3259bc41780f62d
    type: comment
  author: mattdlockyer
  content: '

    ![Screenshot_20240105_150839_Brave.jpg](https://cdn-uploads.huggingface.co/production/uploads/65866765085a5bce61f45282/XEot546vDqwHgxSx4GOij.jpeg)

    '
  created_at: 2024-01-05 23:09:02+00:00
  edited: false
  hidden: false
  id: 65988c0ea3259bc41780f62d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670736706483-632b9f9866f28bf34ae85487.jpeg?w=200&h=200&f=face
      fullname: Doctor Shotgun
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Doctor-Shotgun
      type: user
    createdAt: '2024-01-05T23:30:38.000Z'
    data:
      edited: false
      editors:
      - Doctor-Shotgun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9832533001899719
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670736706483-632b9f9866f28bf34ae85487.jpeg?w=200&h=200&f=face
          fullname: Doctor Shotgun
          isHf: false
          isPro: false
          name: Doctor-Shotgun
          type: user
        html: '<p>Oh, no idea. I don''t usually post models that are small enough
          to even use that feature. Let me know if you figure it out though!</p>

          '
        raw: Oh, no idea. I don't usually post models that are small enough to even
          use that feature. Let me know if you figure it out though!
        updatedAt: '2024-01-05T23:30:38.867Z'
      numEdits: 0
      reactions: []
    id: 6598911ebf533e3c0dd8c66d
    type: comment
  author: Doctor-Shotgun
  content: Oh, no idea. I don't usually post models that are small enough to even
    use that feature. Let me know if you figure it out though!
  created_at: 2024-01-05 23:30:38+00:00
  edited: false
  hidden: false
  id: 6598911ebf533e3c0dd8c66d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0001cd19aab8e61534ec277bd6a89c0.svg
      fullname: Louis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LouisML
      type: user
    createdAt: '2024-01-09T11:54:34.000Z'
    data:
      edited: false
      editors:
      - LouisML
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.45601198077201843
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0001cd19aab8e61534ec277bd6a89c0.svg
          fullname: Louis
          isHf: false
          isPro: false
          name: LouisML
          type: user
        html: '<p>I get the same error on my colab machine:</p>

          <p>Traceback (most recent call last):<br>  File "/usr/lib/python3.10/threading.py",
          line 1016, in _bootstrap_inner<br>    self.run()<br>  File "/usr/lib/python3.10/threading.py",
          line 953, in run<br>    self._target(*self._args, **self._kwargs)<br>  File
          "/usr/local/lib/python3.10/dist-packages/llmtuner/train/tuner.py", line
          27, in run_exp<br>    run_sft(model_args, data_args, training_args, finetuning_args,
          generating_args, callbacks)<br>  File "/usr/local/lib/python3.10/dist-packages/llmtuner/train/sft/workflow.py",
          line 29, in run_sft<br>    model, tokenizer = load_model_and_tokenizer(model_args,
          finetuning_args, training_args.do_train)<br>  File "/usr/local/lib/python3.10/dist-packages/llmtuner/model/loader.py",
          line 87, in load_model_and_tokenizer<br>    model = AutoModelForCausalLM.from_pretrained(<br>  File
          "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py",
          line 566, in from_pretrained<br>    return model_class.from_pretrained(<br>  File
          "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py",
          line 3374, in from_pretrained<br>    if metadata.get("format") == "pt":<br>AttributeError:
          ''NoneType'' object has no attribute ''get''</p>

          <p>Seems some metadata is missing?</p>

          '
        raw: "I get the same error on my colab machine:\n\nTraceback (most recent\
          \ call last):\n  File \"/usr/lib/python3.10/threading.py\", line 1016, in\
          \ _bootstrap_inner\n    self.run()\n  File \"/usr/lib/python3.10/threading.py\"\
          , line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File\
          \ \"/usr/local/lib/python3.10/dist-packages/llmtuner/train/tuner.py\", line\
          \ 27, in run_exp\n    run_sft(model_args, data_args, training_args, finetuning_args,\
          \ generating_args, callbacks)\n  File \"/usr/local/lib/python3.10/dist-packages/llmtuner/train/sft/workflow.py\"\
          , line 29, in run_sft\n    model, tokenizer = load_model_and_tokenizer(model_args,\
          \ finetuning_args, training_args.do_train)\n  File \"/usr/local/lib/python3.10/dist-packages/llmtuner/model/loader.py\"\
          , line 87, in load_model_and_tokenizer\n    model = AutoModelForCausalLM.from_pretrained(\n\
          \  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\"\
          , line 566, in from_pretrained\n    return model_class.from_pretrained(\n\
          \  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\"\
          , line 3374, in from_pretrained\n    if metadata.get(\"format\") == \"pt\"\
          :\nAttributeError: 'NoneType' object has no attribute 'get'\n\nSeems some\
          \ metadata is missing?"
        updatedAt: '2024-01-09T11:54:34.849Z'
      numEdits: 0
      reactions: []
    id: 659d33facb185df11903aa3e
    type: comment
  author: LouisML
  content: "I get the same error on my colab machine:\n\nTraceback (most recent call\
    \ last):\n  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n\
    \    self.run()\n  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n\
    \    self._target(*self._args, **self._kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/llmtuner/train/tuner.py\"\
    , line 27, in run_exp\n    run_sft(model_args, data_args, training_args, finetuning_args,\
    \ generating_args, callbacks)\n  File \"/usr/local/lib/python3.10/dist-packages/llmtuner/train/sft/workflow.py\"\
    , line 29, in run_sft\n    model, tokenizer = load_model_and_tokenizer(model_args,\
    \ finetuning_args, training_args.do_train)\n  File \"/usr/local/lib/python3.10/dist-packages/llmtuner/model/loader.py\"\
    , line 87, in load_model_and_tokenizer\n    model = AutoModelForCausalLM.from_pretrained(\n\
    \  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\"\
    , line 566, in from_pretrained\n    return model_class.from_pretrained(\n  File\
    \ \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\",\
    \ line 3374, in from_pretrained\n    if metadata.get(\"format\") == \"pt\":\n\
    AttributeError: 'NoneType' object has no attribute 'get'\n\nSeems some metadata\
    \ is missing?"
  created_at: 2024-01-09 11:54:34+00:00
  edited: false
  hidden: false
  id: 659d33facb185df11903aa3e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0001cd19aab8e61534ec277bd6a89c0.svg
      fullname: Louis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LouisML
      type: user
    createdAt: '2024-01-09T16:46:13.000Z'
    data:
      edited: false
      editors:
      - LouisML
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9560090899467468
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0001cd19aab8e61534ec277bd6a89c0.svg
          fullname: Louis
          isHf: false
          isPro: false
          name: LouisML
          type: user
        html: '<p>something related to the safetensors format I guess. It seems the
          code doesn''t recognize the pytorch format</p>

          '
        raw: something related to the safetensors format I guess. It seems the code
          doesn't recognize the pytorch format
        updatedAt: '2024-01-09T16:46:13.030Z'
      numEdits: 0
      reactions: []
    id: 659d7855aa29d05820a5963d
    type: comment
  author: LouisML
  content: something related to the safetensors format I guess. It seems the code
    doesn't recognize the pytorch format
  created_at: 2024-01-09 16:46:13+00:00
  edited: false
  hidden: false
  id: 659d7855aa29d05820a5963d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0001cd19aab8e61534ec277bd6a89c0.svg
      fullname: Louis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LouisML
      type: user
    createdAt: '2024-01-09T17:06:59.000Z'
    data:
      edited: false
      editors:
      - LouisML
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5856838822364807
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0001cd19aab8e61534ec277bd6a89c0.svg
          fullname: Louis
          isHf: false
          isPro: false
          name: LouisML
          type: user
        html: "<p>To fix it:</p>\n<pre><code>import safetensors\nfrom safetensors.torch\
          \ import save_file\n\ntensors = dict()\nwith safetensors.safe_open(safetensors_path,\
          \ framework=\"pt\") as f:\n    for key in f.keys():\n        tensors[key]\
          \ = f.get_tensor(key)\n\nsave_file(tensors, safetensors_path, metadata={'format':\
          \ 'pt'})\n</code></pre>\n<p>cf: <a href=\"https://huggingface.co/SeaLLMs/SeaLLM-7B-Hybrid/discussions/2#65752144412ee70185d49ff5\"\
          >https://huggingface.co/SeaLLMs/SeaLLM-7B-Hybrid/discussions/2#65752144412ee70185d49ff5</a></p>\n"
        raw: "To fix it:\n\n```\nimport safetensors\nfrom safetensors.torch import\
          \ save_file\n\ntensors = dict()\nwith safetensors.safe_open(safetensors_path,\
          \ framework=\"pt\") as f:\n    for key in f.keys():\n        tensors[key]\
          \ = f.get_tensor(key)\n\nsave_file(tensors, safetensors_path, metadata={'format':\
          \ 'pt'})\n```\n\ncf: https://huggingface.co/SeaLLMs/SeaLLM-7B-Hybrid/discussions/2#65752144412ee70185d49ff5"
        updatedAt: '2024-01-09T17:06:59.670Z'
      numEdits: 0
      reactions: []
    id: 659d7d33e08ffb4dbe5a5d76
    type: comment
  author: LouisML
  content: "To fix it:\n\n```\nimport safetensors\nfrom safetensors.torch import save_file\n\
    \ntensors = dict()\nwith safetensors.safe_open(safetensors_path, framework=\"\
    pt\") as f:\n    for key in f.keys():\n        tensors[key] = f.get_tensor(key)\n\
    \nsave_file(tensors, safetensors_path, metadata={'format': 'pt'})\n```\n\ncf:\
    \ https://huggingface.co/SeaLLMs/SeaLLM-7B-Hybrid/discussions/2#65752144412ee70185d49ff5"
  created_at: 2024-01-09 17:06:59+00:00
  edited: false
  hidden: false
  id: 659d7d33e08ffb4dbe5a5d76
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670736706483-632b9f9866f28bf34ae85487.jpeg?w=200&h=200&f=face
      fullname: Doctor Shotgun
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Doctor-Shotgun
      type: user
    createdAt: '2024-01-10T05:05:10.000Z'
    data:
      edited: true
      editors:
      - Doctor-Shotgun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9379275441169739
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670736706483-632b9f9866f28bf34ae85487.jpeg?w=200&h=200&f=face
          fullname: Doctor Shotgun
          isHf: false
          isPro: false
          name: Doctor-Shotgun
          type: user
        html: "<p>Interesting find. I converted the pytorch bin to safetensors using\
          \ a script - and while the resulting file is able to be used directly for\
          \ inference in exllamav2, and is able to be successfully quantized, I did\
          \ notice that it failed to load when trying to do further training (and\
          \ I had to use the pytorch_model.bin instead for my finetune).</p>\n<p>EDIT:\
          \ For reference, this was the script used for conversion:</p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">import</span> torch\n\
          <span class=\"hljs-keyword\">import</span> argparse, os, glob, sys\n<span\
          \ class=\"hljs-keyword\">from</span> safetensors.torch <span class=\"hljs-keyword\"\
          >import</span> save_file\n\nparser = argparse.ArgumentParser(description=<span\
          \ class=\"hljs-string\">\"Convert .bin/.pt files to .safetensors\"</span>)\n\
          parser.add_argument(<span class=\"hljs-string\">\"input_files\"</span>,\
          \ nargs=<span class=\"hljs-string\">'+'</span>, <span class=\"hljs-built_in\"\
          >type</span>=<span class=\"hljs-built_in\">str</span>, <span class=\"hljs-built_in\"\
          >help</span>=<span class=\"hljs-string\">\"Input file(s)\"</span>)\nargs\
          \ = parser.parse_args()\n\n<span class=\"hljs-keyword\">for</span> file\
          \ <span class=\"hljs-keyword\">in</span> args.input_files:\n    <span class=\"\
          hljs-built_in\">print</span>(<span class=\"hljs-string\">f\" -- Loading\
          \ <span class=\"hljs-subst\">{file}</span>...\"</span>)\n    state_dict\
          \ = torch.load(file, map_location=<span class=\"hljs-string\">\"cpu\"</span>)\n\
          \n    out_file = os.path.splitext(file)[<span class=\"hljs-number\">0</span>]\
          \ + <span class=\"hljs-string\">\".safetensors\"</span>\n    <span class=\"\
          hljs-built_in\">print</span>(<span class=\"hljs-string\">f\" -- Saving <span\
          \ class=\"hljs-subst\">{out_file}</span>...\"</span>)\n    save_file(state_dict,\
          \ out_file)\n</code></pre>\n<p>Which appears to not save the metadata.</p>\n"
        raw: "Interesting find. I converted the pytorch bin to safetensors using a\
          \ script - and while the resulting file is able to be used directly for\
          \ inference in exllamav2, and is able to be successfully quantized, I did\
          \ notice that it failed to load when trying to do further training (and\
          \ I had to use the pytorch_model.bin instead for my finetune).\n\nEDIT:\
          \ For reference, this was the script used for conversion:\n```python\nimport\
          \ torch\nimport argparse, os, glob, sys\nfrom safetensors.torch import save_file\n\
          \nparser = argparse.ArgumentParser(description=\"Convert .bin/.pt files\
          \ to .safetensors\")\nparser.add_argument(\"input_files\", nargs='+', type=str,\
          \ help=\"Input file(s)\")\nargs = parser.parse_args()\n\nfor file in args.input_files:\n\
          \    print(f\" -- Loading {file}...\")\n    state_dict = torch.load(file,\
          \ map_location=\"cpu\")\n\n    out_file = os.path.splitext(file)[0] + \"\
          .safetensors\"\n    print(f\" -- Saving {out_file}...\")\n    save_file(state_dict,\
          \ out_file)\n```\nWhich appears to not save the metadata."
        updatedAt: '2024-01-10T05:11:33.755Z'
      numEdits: 2
      reactions: []
    id: 659e2586f2e0e03e45962e3f
    type: comment
  author: Doctor-Shotgun
  content: "Interesting find. I converted the pytorch bin to safetensors using a script\
    \ - and while the resulting file is able to be used directly for inference in\
    \ exllamav2, and is able to be successfully quantized, I did notice that it failed\
    \ to load when trying to do further training (and I had to use the pytorch_model.bin\
    \ instead for my finetune).\n\nEDIT: For reference, this was the script used for\
    \ conversion:\n```python\nimport torch\nimport argparse, os, glob, sys\nfrom safetensors.torch\
    \ import save_file\n\nparser = argparse.ArgumentParser(description=\"Convert .bin/.pt\
    \ files to .safetensors\")\nparser.add_argument(\"input_files\", nargs='+', type=str,\
    \ help=\"Input file(s)\")\nargs = parser.parse_args()\n\nfor file in args.input_files:\n\
    \    print(f\" -- Loading {file}...\")\n    state_dict = torch.load(file, map_location=\"\
    cpu\")\n\n    out_file = os.path.splitext(file)[0] + \".safetensors\"\n    print(f\"\
    \ -- Saving {out_file}...\")\n    save_file(state_dict, out_file)\n```\nWhich\
    \ appears to not save the metadata."
  created_at: 2024-01-10 05:05:10+00:00
  edited: true
  hidden: false
  id: 659e2586f2e0e03e45962e3f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Doctor-Shotgun/TinyLlama-1.1B-32k
repo_type: model
status: open
target_branch: null
title: Error
