!!python/object:huggingface_hub.community.DiscussionWithDetails
author: AuraM
conflicting_files: null
created_at: 2022-07-23 01:14:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ab85205580d51775701dcb383e67466b.svg
      fullname: Aurora Mier
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AuraM
      type: user
    createdAt: '2022-07-23T02:14:24.000Z'
    data:
      edited: false
      editors:
      - AuraM
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ab85205580d51775701dcb383e67466b.svg
          fullname: Aurora Mier
          isHf: false
          isPro: false
          name: AuraM
          type: user
        html: '<p>I started training this model a month ago and it was running perfect,
          however in the last two weeks I got the error in the LORA fine-tuning example,
          I am really a novice and I have no idea how to correct it and there is not
          much information on the internet.  If someone has the same error and could
          tell me how to correct it I would appreciate it. It gives this error:</p>

          <p>RuntimeError: The output 0 of DequantizeAndLinearBackward is a view and
          is being modified inplace. This view was created inside a Custom Function
          (or because an input was returned as-is) and the autograd logic to handle
          view+inplace would override the custom backward associated with the Custom
          Function, resulting in incorrect gradients. This behavior is prohibited.
          You can fix this by cloning the output of the Custom Function. </p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1658542457543-62cc579473b2512b8167e6b1.png"><img
          alt="Captura.PNG" src="https://cdn-uploads.huggingface.co/production/uploads/1658542457543-62cc579473b2512b8167e6b1.png"></a></p>

          '
        raw: "I started training this model a month ago and it was running perfect,\
          \ however in the last two weeks I got the error in the LORA fine-tuning\
          \ example, I am really a novice and I have no idea how to correct it and\
          \ there is not much information on the internet.  If someone has the same\
          \ error and could tell me how to correct it I would appreciate it. It gives\
          \ this error:\r\n\r\nRuntimeError: The output 0 of DequantizeAndLinearBackward\
          \ is a view and is being modified inplace. This view was created inside\
          \ a Custom Function (or because an input was returned as-is) and the autograd\
          \ logic to handle view+inplace would override the custom backward associated\
          \ with the Custom Function, resulting in incorrect gradients. This behavior\
          \ is prohibited. You can fix this by cloning the output of the Custom Function.\
          \ \r\n\r\n\r\n![Captura.PNG](https://cdn-uploads.huggingface.co/production/uploads/1658542457543-62cc579473b2512b8167e6b1.png)\r\
          \n\r\n\r\n\r\n\r\n"
        updatedAt: '2022-07-23T02:14:24.823Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - debin
        - Jordancole21
        - mrm8488
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - debin
        - Jordancole21
    id: 62db5980bc4b32ce3e660404
    type: comment
  author: AuraM
  content: "I started training this model a month ago and it was running perfect,\
    \ however in the last two weeks I got the error in the LORA fine-tuning example,\
    \ I am really a novice and I have no idea how to correct it and there is not much\
    \ information on the internet.  If someone has the same error and could tell me\
    \ how to correct it I would appreciate it. It gives this error:\r\n\r\nRuntimeError:\
    \ The output 0 of DequantizeAndLinearBackward is a view and is being modified\
    \ inplace. This view was created inside a Custom Function (or because an input\
    \ was returned as-is) and the autograd logic to handle view+inplace would override\
    \ the custom backward associated with the Custom Function, resulting in incorrect\
    \ gradients. This behavior is prohibited. You can fix this by cloning the output\
    \ of the Custom Function. \r\n\r\n\r\n![Captura.PNG](https://cdn-uploads.huggingface.co/production/uploads/1658542457543-62cc579473b2512b8167e6b1.png)\r\
    \n\r\n\r\n\r\n\r\n"
  created_at: 2022-07-23 01:14:24+00:00
  edited: false
  hidden: false
  id: 62db5980bc4b32ce3e660404
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/874cda0398d2ac741cb6300c5ed54460.svg
      fullname: Krrish Dholakia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: krrishD
      type: user
    createdAt: '2022-08-06T19:28:37.000Z'
    data:
      edited: false
      editors:
      - krrishD
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/874cda0398d2ac741cb6300c5ed54460.svg
          fullname: Krrish Dholakia
          isHf: false
          isPro: false
          name: krrishD
          type: user
        html: '<p>+1</p>

          '
        raw: '+1'
        updatedAt: '2022-08-06T19:28:37.600Z'
      numEdits: 0
      reactions: []
    id: 62eec0e5fc07299a3c56cc0c
    type: comment
  author: krrishD
  content: '+1'
  created_at: 2022-08-06 18:28:37+00:00
  edited: false
  hidden: false
  id: 62eec0e5fc07299a3c56cc0c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f19fda1617538d1945ff949f34039672.svg
      fullname: Jordan Cole
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Jordancole21
      type: user
    createdAt: '2022-08-07T03:29:25.000Z'
    data:
      edited: false
      editors:
      - Jordancole21
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f19fda1617538d1945ff949f34039672.svg
          fullname: Jordan Cole
          isHf: false
          isPro: false
          name: Jordancole21
          type: user
        html: '<p>I''m getting this error as well.  Not entirely sure how to fix it.
          Is there anyone in the community who can chime in on this?</p>

          '
        raw: I'm getting this error as well.  Not entirely sure how to fix it. Is
          there anyone in the community who can chime in on this?
        updatedAt: '2022-08-07T03:29:25.735Z'
      numEdits: 0
      reactions: []
    id: 62ef31953896ca5fbf76c841
    type: comment
  author: Jordancole21
  content: I'm getting this error as well.  Not entirely sure how to fix it. Is there
    anyone in the community who can chime in on this?
  created_at: 2022-08-07 02:29:25+00:00
  edited: false
  hidden: false
  id: 62ef31953896ca5fbf76c841
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5e4318d616b09a31220980d6/24rMJ_vPh3gW9ZEmj64xr.png?w=200&h=200&f=face
      fullname: Manuel Romero
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: mrm8488
      type: user
    createdAt: '2022-08-10T09:58:43.000Z'
    data:
      edited: false
      editors:
      - mrm8488
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5e4318d616b09a31220980d6/24rMJ_vPh3gW9ZEmj64xr.png?w=200&h=200&f=face
          fullname: Manuel Romero
          isHf: false
          isPro: true
          name: mrm8488
          type: user
        html: '<p>Getting the same here!</p>

          '
        raw: Getting the same here!
        updatedAt: '2022-08-10T09:58:43.890Z'
      numEdits: 0
      reactions: []
    id: 62f381537017a2dc33b1bca9
    type: comment
  author: mrm8488
  content: Getting the same here!
  created_at: 2022-08-10 08:58:43+00:00
  edited: false
  hidden: false
  id: 62f381537017a2dc33b1bca9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640134437444-609baae0fe087f3d04cf0481.jpeg?w=200&h=200&f=face
      fullname: Yozh
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: justheuristic
      type: user
    createdAt: '2022-08-10T10:35:18.000Z'
    data:
      edited: false
      editors:
      - justheuristic
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640134437444-609baae0fe087f3d04cf0481.jpeg?w=200&h=200&f=face
          fullname: Yozh
          isHf: false
          isPro: false
          name: justheuristic
          type: user
        html: '<p>I''m afraid that the real error message is somewhere in the "8 frames"
          section.</p>

          <p>On the bright side, i believe this code was superceded by YounesBelkada
          and TimDettmers 8bit integration that works with all models.<br>Please check
          the code: <a rel="nofollow" href="https://github.com/huggingface/transformers/pull/17901">https://github.com/huggingface/transformers/pull/17901</a><br>and
          the usage example <a rel="nofollow" href="https://colab.research.google.com/drive/1qOjXfQIAULfKvZqwCen8-MoWKGdSatZ4#scrollTo=W8tQtyjp75O">https://colab.research.google.com/drive/1qOjXfQIAULfKvZqwCen8-MoWKGdSatZ4#scrollTo=W8tQtyjp75O</a></p>

          '
        raw: 'I''m afraid that the real error message is somewhere in the "8 frames"
          section.


          On the bright side, i believe this code was superceded by YounesBelkada
          and TimDettmers 8bit integration that works with all models.

          Please check the code: https://github.com/huggingface/transformers/pull/17901

          and the usage example https://colab.research.google.com/drive/1qOjXfQIAULfKvZqwCen8-MoWKGdSatZ4#scrollTo=W8tQtyjp75O'
        updatedAt: '2022-08-10T10:35:18.519Z'
      numEdits: 0
      reactions: []
    id: 62f389e6eb50f1aa8bb91bbe
    type: comment
  author: justheuristic
  content: 'I''m afraid that the real error message is somewhere in the "8 frames"
    section.


    On the bright side, i believe this code was superceded by YounesBelkada and TimDettmers
    8bit integration that works with all models.

    Please check the code: https://github.com/huggingface/transformers/pull/17901

    and the usage example https://colab.research.google.com/drive/1qOjXfQIAULfKvZqwCen8-MoWKGdSatZ4#scrollTo=W8tQtyjp75O'
  created_at: 2022-08-10 09:35:18+00:00
  edited: false
  hidden: false
  id: 62f389e6eb50f1aa8bb91bbe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b9e47a2bf15ad2674fa3faf8eabf1aa0.svg
      fullname: Mukesh Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MukeshSharma
      type: user
    createdAt: '2022-09-03T10:01:49.000Z'
    data:
      edited: false
      editors:
      - MukeshSharma
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b9e47a2bf15ad2674fa3faf8eabf1aa0.svg
          fullname: Mukesh Sharma
          isHf: false
          isPro: false
          name: MukeshSharma
          type: user
        html: '<p>The solution to this problem  is , you have to put the output  provided
          by ( DequantizeAndLinearBackward)in some other new variable , and return
          that variable instead of output  .The problem will be fixed</p>

          '
        raw: The solution to this problem  is , you have to put the output  provided
          by ( DequantizeAndLinearBackward)in some other new variable , and return
          that variable instead of output  .The problem will be fixed
        updatedAt: '2022-09-03T10:01:49.139Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - mrm8488
        - justheuristic
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - mrm8488
        - justheuristic
    id: 6313260d17838d05194bca3e
    type: comment
  author: MukeshSharma
  content: The solution to this problem  is , you have to put the output  provided
    by ( DequantizeAndLinearBackward)in some other new variable , and return that
    variable instead of output  .The problem will be fixed
  created_at: 2022-09-03 09:01:49+00:00
  edited: false
  hidden: false
  id: 6313260d17838d05194bca3e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f19fda1617538d1945ff949f34039672.svg
      fullname: Jordan Cole
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Jordancole21
      type: user
    createdAt: '2022-09-04T06:37:41.000Z'
    data:
      edited: false
      editors:
      - Jordancole21
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f19fda1617538d1945ff949f34039672.svg
          fullname: Jordan Cole
          isHf: false
          isPro: false
          name: Jordancole21
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;MukeshSharma&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/MukeshSharma\"\
          >@<span class=\"underline\">MukeshSharma</span></a></span>\n\n\t</span></span>\
          \ Sorry I'm still a bit lost, would you mind showing an example of how you\
          \ did it?</p>\n"
        raw: '@MukeshSharma Sorry I''m still a bit lost, would you mind showing an
          example of how you did it?'
        updatedAt: '2022-09-04T06:37:41.762Z'
      numEdits: 0
      reactions: []
    id: 631447b5d8dc27b2f7efc7a3
    type: comment
  author: Jordancole21
  content: '@MukeshSharma Sorry I''m still a bit lost, would you mind showing an example
    of how you did it?'
  created_at: 2022-09-04 05:37:41+00:00
  edited: false
  hidden: false
  id: 631447b5d8dc27b2f7efc7a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/07f2c638e17e91e54aaf403b4d847428.svg
      fullname: 'Peter Mills '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: petermills
      type: user
    createdAt: '2022-09-20T09:57:50.000Z'
    data:
      edited: true
      editors:
      - petermills
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/07f2c638e17e91e54aaf403b4d847428.svg
          fullname: 'Peter Mills '
          isHf: false
          isPro: false
          name: petermills
          type: user
        html: "<p>This seems to work for me:</p>\n<pre><code>class FrozenBNBLinear(nn.Module):\n\
          ...\n    def forward(self, input):\n        output = DequantizeAndLinear.apply(input,\
          \ self.weight, self.absmax, self.code, self.bias)\n        output = output.clone()\
          \  ###Add this line\n        if self.adapter:\n            output += self.adapter(input)\n\
          \        return output\n...\n</code></pre>\n<p>I may be speaking too soon,\
          \ but training has started at least.</p>\n<p>update: worked fine!</p>\n"
        raw: "This seems to work for me:\n```\nclass FrozenBNBLinear(nn.Module):\n\
          ...\n    def forward(self, input):\n        output = DequantizeAndLinear.apply(input,\
          \ self.weight, self.absmax, self.code, self.bias)\n        output = output.clone()\
          \  ###Add this line\n        if self.adapter:\n            output += self.adapter(input)\n\
          \        return output\n...\n ```\n\nI may be speaking too soon, but training\
          \ has started at least.\n\nupdate: worked fine!"
        updatedAt: '2022-09-20T10:17:16.216Z'
      numEdits: 1
      reactions:
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - Jordancole21
        - Rapid21
        - Benan
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Rapid21
    id: 63298e9eac912acfeb1842d2
    type: comment
  author: petermills
  content: "This seems to work for me:\n```\nclass FrozenBNBLinear(nn.Module):\n...\n\
    \    def forward(self, input):\n        output = DequantizeAndLinear.apply(input,\
    \ self.weight, self.absmax, self.code, self.bias)\n        output = output.clone()\
    \  ###Add this line\n        if self.adapter:\n            output += self.adapter(input)\n\
    \        return output\n...\n ```\n\nI may be speaking too soon, but training\
    \ has started at least.\n\nupdate: worked fine!"
  created_at: 2022-09-20 08:57:50+00:00
  edited: true
  hidden: false
  id: 63298e9eac912acfeb1842d2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f19fda1617538d1945ff949f34039672.svg
      fullname: Jordan Cole
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Jordancole21
      type: user
    createdAt: '2022-09-24T04:57:18.000Z'
    data:
      edited: false
      editors:
      - Jordancole21
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f19fda1617538d1945ff949f34039672.svg
          fullname: Jordan Cole
          isHf: false
          isPro: false
          name: Jordancole21
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;petermills&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/petermills\">@<span class=\"\
          underline\">petermills</span></a></span>\n\n\t</span></span> Thank you so\
          \ much!</p>\n"
        raw: '@petermills Thank you so much!'
        updatedAt: '2022-09-24T04:57:18.489Z'
      numEdits: 0
      reactions: []
    id: 632e8e2e0c40e873c7e139a6
    type: comment
  author: Jordancole21
  content: '@petermills Thank you so much!'
  created_at: 2022-09-24 03:57:18+00:00
  edited: false
  hidden: false
  id: 632e8e2e0c40e873c7e139a6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: hivemind/gpt-j-6B-8bit
repo_type: model
status: open
target_branch: null
title: Error at the moment of training
