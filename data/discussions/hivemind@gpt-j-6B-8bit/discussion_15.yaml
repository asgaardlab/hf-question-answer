!!python/object:huggingface_hub.community.DiscussionWithDetails
author: alerio
conflicting_files: null
created_at: 2023-05-17 19:00:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1647628522691-61fee4f28c2eb991da50d2d2.jpeg?w=200&h=200&f=face
      fullname: Changye Li
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alerio
      type: user
    createdAt: '2023-05-17T20:00:11.000Z'
    data:
      edited: false
      editors:
      - alerio
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1647628522691-61fee4f28c2eb991da50d2d2.jpeg?w=200&h=200&f=face
          fullname: Changye Li
          isHf: false
          isPro: false
          name: alerio
          type: user
        html: "<p>Hi, I was trying to download the model and tokenizer via the following\
          \ code</p>\n<pre><code class=\"language-python\">model_name = <span class=\"\
          hljs-string\">\"hivemind/gpt-j-6B-8bit\"</span>\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\
          tokenizer.pad_token = tokenizer.eos_token\nmodel = AutoModelForCausalLM.from_pretrained(\n\
          \    model_name, \n     load_in_8bit=<span class=\"hljs-literal\">True</span>,\
          \ <span class=\"hljs-comment\"># <span class=\"hljs-doctag\">NOTE:</span>\
          \ load GPT-2 with 8 bit did not work</span>\n     device_map={<span class=\"\
          hljs-string\">''</span>:torch.cuda.current_device()},\n    )\n</code></pre>\n\
          <p>But I got the this error: Can't load tokenizer for 'hivemind/gpt-j-6B-8bit'.\
          \ If you were trying to load it from '<a href=\"https://huggingface.co/models'\"\
          >https://huggingface.co/models'</a>, make sure you don't have a local directory\
          \ with the same name. Otherwise, make sure 'hivemind/gpt-j-6B-8bit' is the\
          \ correct path to a directory containing all relevant files for a GPT2TokenizerFast\
          \ tokenizer.</p>\n<p>Any help will be appreciated! </p>\n"
        raw: "Hi, I was trying to download the model and tokenizer via the following\
          \ code\r\n\r\n```python\r\nmodel_name = \"hivemind/gpt-j-6B-8bit\"\r\ntokenizer\
          \ = AutoTokenizer.from_pretrained(model_name)\r\ntokenizer.pad_token = tokenizer.eos_token\r\
          \nmodel = AutoModelForCausalLM.from_pretrained(\r\n    model_name, \r\n\
          \     load_in_8bit=True, # NOTE: load GPT-2 with 8 bit did not work\r\n\
          \     device_map={'':torch.cuda.current_device()},\r\n    )\r\n```\r\n\r\
          \nBut I got the this error: Can't load tokenizer for 'hivemind/gpt-j-6B-8bit'.\
          \ If you were trying to load it from 'https://huggingface.co/models', make\
          \ sure you don't have a local directory with the same name. Otherwise, make\
          \ sure 'hivemind/gpt-j-6B-8bit' is the correct path to a directory containing\
          \ all relevant files for a GPT2TokenizerFast tokenizer.\r\n\r\nAny help\
          \ will be appreciated! "
        updatedAt: '2023-05-17T20:00:11.242Z'
      numEdits: 0
      reactions: []
    id: 6465324b611ae99d14d3eccc
    type: comment
  author: alerio
  content: "Hi, I was trying to download the model and tokenizer via the following\
    \ code\r\n\r\n```python\r\nmodel_name = \"hivemind/gpt-j-6B-8bit\"\r\ntokenizer\
    \ = AutoTokenizer.from_pretrained(model_name)\r\ntokenizer.pad_token = tokenizer.eos_token\r\
    \nmodel = AutoModelForCausalLM.from_pretrained(\r\n    model_name, \r\n     load_in_8bit=True,\
    \ # NOTE: load GPT-2 with 8 bit did not work\r\n     device_map={'':torch.cuda.current_device()},\r\
    \n    )\r\n```\r\n\r\nBut I got the this error: Can't load tokenizer for 'hivemind/gpt-j-6B-8bit'.\
    \ If you were trying to load it from 'https://huggingface.co/models', make sure\
    \ you don't have a local directory with the same name. Otherwise, make sure 'hivemind/gpt-j-6B-8bit'\
    \ is the correct path to a directory containing all relevant files for a GPT2TokenizerFast\
    \ tokenizer.\r\n\r\nAny help will be appreciated! "
  created_at: 2023-05-17 19:00:11+00:00
  edited: false
  hidden: false
  id: 6465324b611ae99d14d3eccc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6446be9a15a27291ef8bea10/9_gywXgzL9Jk3MYLdX9RG.jpeg?w=200&h=200&f=face
      fullname: interstellarninja
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: interstellarninja
      type: user
    createdAt: '2023-05-18T04:52:21.000Z'
    data:
      edited: true
      editors:
      - interstellarninja
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6446be9a15a27291ef8bea10/9_gywXgzL9Jk3MYLdX9RG.jpeg?w=200&h=200&f=face
          fullname: interstellarninja
          isHf: false
          isPro: false
          name: interstellarninja
          type: user
        html: '<p>Hey Alerio, I tried the following code from this example: <a rel="nofollow"
          href="https://colab.research.google.com/drive/1qOjXfQIAULfKvZqwCen8-MoWKGdSatZ4#scrollTo=W8tQtyjp75O">https://colab.research.google.com/drive/1qOjXfQIAULfKvZqwCen8-MoWKGdSatZ4#scrollTo=W8tQtyjp75O</a></p>

          <pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer


          model_name = "hivemind/gpt-j-6B-8bit"

          model_8bit = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto",
          load_in_8bit=True)

          tokenizer = AutoTokenizer.from_pretrained(model_name)

          </code></pre>

          <p>But I still get the following error:</p>

          <pre><code>NameError: name ''init_empty_weights'' is not defined

          </code></pre>

          '
        raw: 'Hey Alerio, I tried the following code from this example: https://colab.research.google.com/drive/1qOjXfQIAULfKvZqwCen8-MoWKGdSatZ4#scrollTo=W8tQtyjp75O


          ```

          from transformers import AutoModelForCausalLM, AutoTokenizer


          model_name = "hivemind/gpt-j-6B-8bit"

          model_8bit = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto",
          load_in_8bit=True)

          tokenizer = AutoTokenizer.from_pretrained(model_name)

          ```


          But I still get the following error:

          ```

          NameError: name ''init_empty_weights'' is not defined

          ```'
        updatedAt: '2023-05-18T04:58:41.695Z'
      numEdits: 6
      reactions: []
    id: 6465af056ceebdc7fd94fa0d
    type: comment
  author: interstellarninja
  content: 'Hey Alerio, I tried the following code from this example: https://colab.research.google.com/drive/1qOjXfQIAULfKvZqwCen8-MoWKGdSatZ4#scrollTo=W8tQtyjp75O


    ```

    from transformers import AutoModelForCausalLM, AutoTokenizer


    model_name = "hivemind/gpt-j-6B-8bit"

    model_8bit = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto",
    load_in_8bit=True)

    tokenizer = AutoTokenizer.from_pretrained(model_name)

    ```


    But I still get the following error:

    ```

    NameError: name ''init_empty_weights'' is not defined

    ```'
  created_at: 2023-05-18 03:52:21+00:00
  edited: true
  hidden: false
  id: 6465af056ceebdc7fd94fa0d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6446be9a15a27291ef8bea10/9_gywXgzL9Jk3MYLdX9RG.jpeg?w=200&h=200&f=face
      fullname: interstellarninja
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: interstellarninja
      type: user
    createdAt: '2023-05-18T05:13:23.000Z'
    data:
      edited: false
      editors:
      - interstellarninja
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6446be9a15a27291ef8bea10/9_gywXgzL9Jk3MYLdX9RG.jpeg?w=200&h=200&f=face
          fullname: interstellarninja
          isHf: false
          isPro: false
          name: interstellarninja
          type: user
        html: "<p>BTW following works but crashes because of OOM:</p>\n<pre><code>class\
          \ GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n\
          \    def __init__(self, config):\n        super().__init__(config)\n   \
          \     convert_to_int8(self)\n\ngpt = GPTJForCausalLM.from_pretrained(\"\
          hivemind/gpt-j-6B-8bit\", low_cpu_mem_usage=True)\n</code></pre>\n"
        raw: "BTW following works but crashes because of OOM:\n\n```\nclass GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n\
          \    def __init__(self, config):\n        super().__init__(config)\n   \
          \     convert_to_int8(self)\n\ngpt = GPTJForCausalLM.from_pretrained(\"\
          hivemind/gpt-j-6B-8bit\", low_cpu_mem_usage=True)\n```"
        updatedAt: '2023-05-18T05:13:23.726Z'
      numEdits: 0
      reactions: []
    id: 6465b3f386e668ad22ee1455
    type: comment
  author: interstellarninja
  content: "BTW following works but crashes because of OOM:\n\n```\nclass GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n\
    \    def __init__(self, config):\n        super().__init__(config)\n        convert_to_int8(self)\n\
    \ngpt = GPTJForCausalLM.from_pretrained(\"hivemind/gpt-j-6B-8bit\", low_cpu_mem_usage=True)\n\
    ```"
  created_at: 2023-05-18 04:13:23+00:00
  edited: false
  hidden: false
  id: 6465b3f386e668ad22ee1455
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 15
repo_id: hivemind/gpt-j-6B-8bit
repo_type: model
status: open
target_branch: null
title: Can't download the tokenizer
