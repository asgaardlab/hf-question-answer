!!python/object:huggingface_hub.community.DiscussionWithDetails
author: eniora
conflicting_files: null
created_at: 2023-10-07 16:37:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dbf2e9bd0c0df4741ba87a6c2c51ea5c.svg
      fullname: revo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eniora
      type: user
    createdAt: '2023-10-07T17:37:58.000Z'
    data:
      edited: true
      editors:
      - eniora
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6173158288002014
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dbf2e9bd0c0df4741ba87a6c2c51ea5c.svg
          fullname: revo
          isHf: false
          isPro: false
          name: eniora
          type: user
        html: '<p>Hello, I am using A1111 (latest with the most recent controlnet
          version)<br>I downloaded the ip-adapter-plus_sdxl_vit-h.bin file but it
          doesn''t appear in the Controlnet model list until I rename it to .pth and
          when I do so, I get error when I press generate:</p>

          <p>Error running process: C:\stable-diffusion-webui\extensions\sd-webui-controlnet\scripts\controlnet.py<br>    Traceback
          (most recent call last):<br>      File "C:\stable-diffusion-webui\modules\scripts.py",
          line 619, in process<br>        script.process(p, *script_args)<br>      File
          "C:\stable-diffusion-webui\extensions\sd-webui-controlnet\scripts\controlnet.py",
          line 977, in process<br>        self.controlnet_hack(p)<br>      File "C:\stable-diffusion-webui\extensions\sd-webui-controlnet\scripts\controlnet.py",
          line 966, in controlnet_hack<br>        self.controlnet_main_entry(p)<br>      File
          "C:\stable-diffusion-webui\extensions\sd-webui-controlnet\scripts\controlnet.py",
          line 688, in controlnet_main_entry<br>        model_net = Script.load_control_model(p,
          unet, unit.model)<br>      File "C:\stable-diffusion-webui\extensions\sd-webui-controlnet\scripts\controlnet.py",
          line 321, in load_control_model<br>        model_net = Script.build_control_model(p,
          unet, model)<br>      File "C:\stable-diffusion-webui\extensions\sd-webui-controlnet\scripts\controlnet.py",
          line 350, in build_control_model<br>        network = build_model_by_guess(state_dict,
          unet, model_path)<br>      File "C:\stable-diffusion-webui\extensions\sd-webui-controlnet\scripts\controlnet_model_guess.py",
          line 233, in build_model_by_guess<br>        network = PlugableIPAdapter(state_dict,
          channel, plus)<br>      File "C:\stable-diffusion-webui\extensions\sd-webui-controlnet\scripts\controlmodel_ipadapter.py",
          line 299, in <strong>init</strong><br>        self.ipadapter = IPAdapterModel(state_dict,
          clip_embeddings_dim=clip_embeddings_dim, is_plus=is_plus)<br>      File
          "C:\stable-diffusion-webui\extensions\sd-webui-controlnet\scripts\controlmodel_ipadapter.py",
          line 191, in <strong>init</strong><br>        self.load_ip_adapter(state_dict)<br>      File
          "C:\stable-diffusion-webui\extensions\sd-webui-controlnet\scripts\controlmodel_ipadapter.py",
          line 194, in load_ip_adapter<br>        self.image_proj_model.load_state_dict(state_dict["image_proj"])<br>      File
          "c:\stable-diffusion-webui\venv\lib\site-packages\torch\nn\modules\module.py",
          line 2041, in load_state_dict<br>        raise RuntimeError(''Error(s) in
          loading state_dict for {}:\n\t{}''.format(<br>    RuntimeError: Error(s)
          in loading state_dict for Resampler:<br>        size mismatch for latents:
          copying a param with shape torch.Size([1, 16, 1280]) from checkpoint, the
          shape in current model is torch.Size([1, 16, 2048]).<br>        size mismatch
          for proj_in.weight: copying a param with shape torch.Size([1280, 1280])
          from checkpoint, the shape in current model is torch.Size([2048, 1280]).<br>        size
          mismatch for proj_in.bias: copying a param with shape torch.Size([1280])
          from checkpoint, the shape in current model is torch.Size([2048]).<br>        size
          mismatch for proj_out.weight: copying a param with shape torch.Size([2048,
          1280]) from checkpoint, the shape in current model is torch.Size([2048,
          2048]).<br>        size mismatch for layers.0.0.norm1.weight: copying a
          param with shape torch.Size([1280]) from checkpoint, the shape in current
          model is torch.Size([2048]).<br>        size mismatch for layers.0.0.norm1.bias:
          copying a param with shape torch.Size([1280]) from checkpoint, the shape
          in current model is torch.Size([2048]).<br>        size mismatch for layers.0.0.norm2.weight:
          copying a param with shape torch.Size([1280]) from checkpoint, the shape
          in current model is torch.Size([2048]).<br>        size mismatch for layers.0.0.norm2.bias:
          copying a param with shape torch.Size([1280]) from checkpoint, the shape
          in current model is torch.Size([2048]).<br>        size mismatch for layers.0.0.to_q.weight:
          copying a param with shape torch.Size([1280, 1280]) from checkpoint, the
          shape in current model is torch.Size([768, 2048]).<br>        size mismatch
          for layers.0.0.to_kv.weight: copying a param with shape torch.Size([2560,
          1280]) from checkpoint, the shape in current model is torch.Size([1536,
          2048]).<br>        size mismatch for layers.0.0.to_out.weight: copying a
          param with shape torch.Size([1280, 1280]) from checkpoint, the shape in
          current model is torch.Size([2048, 768]).<br>        size mismatch for layers.0.1.0.weight:
          copying a param with shape torch.Size([1280]) from checkpoint, the shape
          in current model is torch.Size([2048]).<br>        size mismatch for layers.0.1.0.bias:
          copying a param with shape torch.Size([1280]) from checkpoint, the shape
          in current model is torch.Size([2048]).<br>        size mismatch for layers.0.1.1.weight:
          copying a param with shape torch.Size([5120, 1280]) from checkpoint, the
          shape in current model is torch.Size([8192, 2048]).<br>        size mismatch
          for layers.0.1.3.weight: copying a param with shape torch.Size([1280, 5120])
          from checkpoint, the shape in current model is torch.Size([2048, 8192]).<br>        size
          mismatch for layers.1.0.norm1.weight: copying a param with shape torch.Size([1280])
          from checkpoint, the shape in current model is torch.Size([2048]).<br>        size
          mismatch for layers.1.0.norm1.bias: copying a param with shape torch.Size([1280])
          from checkpoint, the shape in current model is torch.Size([2048]).<br>        size
          mismatch for layers.1.0.norm2.weight: copying a param with shape torch.Size([1280])
          from checkpoint, the shape in current model is torch.Size([2048]).<br>        size
          mismatch for layers.1.0.norm2.bias: copying a param with shape torch.Size([1280])
          from checkpoint, the shape in current model is torch.Size([2048]).<br>        size
          mismatch for layers.1.0.to_q.weight: copying a param with shape torch.Size([1280,
          1280]) from checkpoint, the shape in current model is torch.Size([768, 2048]).<br>        size
          mismatch for layers.1.0.to_kv.weight: copying a param with shape torch.Size([2560,
          1280]) from checkpoint, the shape in current model is torch.Size([1536,
          2048]).<br>        size mismatch for layers.1.0.to_out.weight: copying a
          param with shape torch.Size([1280, 1280]) from checkpoint, the shape in
          current model is torch.Size([2048, 768]).<br>        size mismatch for layers.1.1.0.weight:
          copying a param with shape torch.Size([1280]) from checkpoint, the shape
          in current model is torch.Size([2048]).<br>        size mismatch for layers.1.1.0.bias:
          copying a param with shape torch.Size([1280]) from checkpoint, the shape
          in current model is torch.Size([2048]).<br>        size mismatch for layers.1.1.1.weight:
          copying a param with shape torch.Size([5120, 1280]) from checkpoint, the
          shape in current model is torch.Size([8192, 2048]).<br>        size mismatch
          for layers.1.1.3.weight: copying a param with shape torch.Size([1280, 5120])
          from checkpoint, the shape in current model is torch.Size([2048, 8192]).<br>        size
          mismatch for layers.2.0.norm1.weight: copying a param with shape torch.Size([1280])
          from checkpoint, the shape in current model is torch.Size([2048]).<br>        size
          mismatch for layers.2.0.norm1.bias: copying a param with shape torch.Size([1280])
          from checkpoint, the shape in current model is torch.Size([2048]).<br>        size
          mismatch for layers.2.0.norm2.weight: copying a param with shape torch.Size([1280])
          from checkpoint, the shape in current model is torch.Size([2048]).<br>        size
          mismatch for layers.2.0.norm2.bias: copying a param with shape torch.Size([1280])
          from checkpoint, the shape in current model is torch.Size([2048]).<br>        size
          mismatch for layers.2.0.to_q.weight: copying a param with shape torch.Size([1280,
          1280]) from checkpoint, the shape in current model is torch.Size([768, 2048]).<br>        size
          mismatch for layers.2.0.to_kv.weight: copying a param with shape torch.Size([2560,
          1280]) from checkpoint, the shape in current model is torch.Size([1536,
          2048]).<br>        size mismatch for layers.2.0.to_out.weight: copying a
          param with shape torch.Size([1280, 1280]) from checkpoint, the shape in
          current model is torch.Size([2048, 768]).<br>        size mismatch for layers.2.1.0.weight:
          copying a param with shape torch.Size([1280]) from checkpoint, the shape
          in current model is torch.Size([2048]).<br>        size mismatch for layers.2.1.0.bias:
          copying a param with shape torch.Size([1280]) from checkpoint, the shape
          in current model is torch.Size([2048]).<br>        size mismatch for layers.2.1.1.weight:
          copying a param with shape torch.Size([5120, 1280]) from checkpoint, the
          shape in current model is torch.Size([8192, 2048]).<br>        size mismatch
          for layers.2.1.3.weight: copying a param with shape torch.Size([1280, 5120])
          from checkpoint, the shape in current model is torch.Size([2048, 8192]).<br>        size
          mismatch for layers.3.0.norm1.weight: copying a param with shape torch.Size([1280])
          from checkpoint, the shape in current model is torch.Size([2048]).<br>        size
          mismatch for layers.3.0.norm1.bias: copying a param with shape torch.Size([1280])
          from checkpoint, the shape in current model is torch.Size([2048]).<br>        size
          mismatch for layers.3.0.norm2.weight: copying a param with shape torch.Size([1280])
          from checkpoint, the shape in current model is torch.Size([2048]).<br>        size
          mismatch for layers.3.0.norm2.bias: copying a param with shape torch.Size([1280])
          from checkpoint, the shape in current model is torch.Size([2048]).<br>        size
          mismatch for layers.3.0.to_q.weight: copying a param with shape torch.Size([1280,
          1280]) from checkpoint, the shape in current model is torch.Size([768, 2048]).<br>        size
          mismatch for layers.3.0.to_kv.weight: copying a param with shape torch.Size([2560,
          1280]) from checkpoint, the shape in current model is torch.Size([1536,
          2048]).<br>        size mismatch for layers.3.0.to_out.weight: copying a
          param with shape torch.Size([1280, 1280]) from checkpoint, the shape in
          current model is torch.Size([2048, 768]).<br>        size mismatch for layers.3.1.0.weight:
          copying a param with shape torch.Size([1280]) from checkpoint, the shape
          in current model is torch.Size([2048]).<br>        size mismatch for layers.3.1.0.bias:
          copying a param with shape torch.Size([1280]) from checkpoint, the shape
          in current model is torch.Size([2048]).<br>        size mismatch for layers.3.1.1.weight:
          copying a param with shape torch.Size([5120, 1280]) from checkpoint, the
          shape in current model is torch.Size([8192, 2048]).<br>        size mismatch
          for layers.3.1.3.weight: copying a param with shape torch.Size([1280, 5120])
          from checkpoint, the shape in current model is torch.Size([2048, 8192]).</p>

          <p>I tried using SDXL VAE and tried on automatic, tried without refiner
          or hi-res fix and always the same error.</p>

          <p>Thanks in advance.</p>

          '
        raw: "Hello, I am using A1111 (latest with the most recent controlnet version)\n\
          I downloaded the ip-adapter-plus_sdxl_vit-h.bin file but it doesn't appear\
          \ in the Controlnet model list until I rename it to .pth and when I do so,\
          \ I get error when I press generate:\n\nError running process: C:\\stable-diffusion-webui\\\
          extensions\\sd-webui-controlnet\\scripts\\controlnet.py\n    Traceback (most\
          \ recent call last):\n      File \"C:\\stable-diffusion-webui\\modules\\\
          scripts.py\", line 619, in process\n        script.process(p, *script_args)\n\
          \      File \"C:\\stable-diffusion-webui\\extensions\\sd-webui-controlnet\\\
          scripts\\controlnet.py\", line 977, in process\n        self.controlnet_hack(p)\n\
          \      File \"C:\\stable-diffusion-webui\\extensions\\sd-webui-controlnet\\\
          scripts\\controlnet.py\", line 966, in controlnet_hack\n        self.controlnet_main_entry(p)\n\
          \      File \"C:\\stable-diffusion-webui\\extensions\\sd-webui-controlnet\\\
          scripts\\controlnet.py\", line 688, in controlnet_main_entry\n        model_net\
          \ = Script.load_control_model(p, unet, unit.model)\n      File \"C:\\stable-diffusion-webui\\\
          extensions\\sd-webui-controlnet\\scripts\\controlnet.py\", line 321, in\
          \ load_control_model\n        model_net = Script.build_control_model(p,\
          \ unet, model)\n      File \"C:\\stable-diffusion-webui\\extensions\\sd-webui-controlnet\\\
          scripts\\controlnet.py\", line 350, in build_control_model\n        network\
          \ = build_model_by_guess(state_dict, unet, model_path)\n      File \"C:\\\
          stable-diffusion-webui\\extensions\\sd-webui-controlnet\\scripts\\controlnet_model_guess.py\"\
          , line 233, in build_model_by_guess\n        network = PlugableIPAdapter(state_dict,\
          \ channel, plus)\n      File \"C:\\stable-diffusion-webui\\extensions\\\
          sd-webui-controlnet\\scripts\\controlmodel_ipadapter.py\", line 299, in\
          \ __init__\n        self.ipadapter = IPAdapterModel(state_dict, clip_embeddings_dim=clip_embeddings_dim,\
          \ is_plus=is_plus)\n      File \"C:\\stable-diffusion-webui\\extensions\\\
          sd-webui-controlnet\\scripts\\controlmodel_ipadapter.py\", line 191, in\
          \ __init__\n        self.load_ip_adapter(state_dict)\n      File \"C:\\\
          stable-diffusion-webui\\extensions\\sd-webui-controlnet\\scripts\\controlmodel_ipadapter.py\"\
          , line 194, in load_ip_adapter\n        self.image_proj_model.load_state_dict(state_dict[\"\
          image_proj\"])\n      File \"c:\\stable-diffusion-webui\\venv\\lib\\site-packages\\\
          torch\\nn\\modules\\module.py\", line 2041, in load_state_dict\n       \
          \ raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\
          \    RuntimeError: Error(s) in loading state_dict for Resampler:\n     \
          \   size mismatch for latents: copying a param with shape torch.Size([1,\
          \ 16, 1280]) from checkpoint, the shape in current model is torch.Size([1,\
          \ 16, 2048]).\n        size mismatch for proj_in.weight: copying a param\
          \ with shape torch.Size([1280, 1280]) from checkpoint, the shape in current\
          \ model is torch.Size([2048, 1280]).\n        size mismatch for proj_in.bias:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for proj_out.weight:\
          \ copying a param with shape torch.Size([2048, 1280]) from checkpoint, the\
          \ shape in current model is torch.Size([2048, 2048]).\n        size mismatch\
          \ for layers.0.0.norm1.weight: copying a param with shape torch.Size([1280])\
          \ from checkpoint, the shape in current model is torch.Size([2048]).\n \
          \       size mismatch for layers.0.0.norm1.bias: copying a param with shape\
          \ torch.Size([1280]) from checkpoint, the shape in current model is torch.Size([2048]).\n\
          \        size mismatch for layers.0.0.norm2.weight: copying a param with\
          \ shape torch.Size([1280]) from checkpoint, the shape in current model is\
          \ torch.Size([2048]).\n        size mismatch for layers.0.0.norm2.bias:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.0.0.to_q.weight:\
          \ copying a param with shape torch.Size([1280, 1280]) from checkpoint, the\
          \ shape in current model is torch.Size([768, 2048]).\n        size mismatch\
          \ for layers.0.0.to_kv.weight: copying a param with shape torch.Size([2560,\
          \ 1280]) from checkpoint, the shape in current model is torch.Size([1536,\
          \ 2048]).\n        size mismatch for layers.0.0.to_out.weight: copying a\
          \ param with shape torch.Size([1280, 1280]) from checkpoint, the shape in\
          \ current model is torch.Size([2048, 768]).\n        size mismatch for layers.0.1.0.weight:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.0.1.0.bias:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.0.1.1.weight:\
          \ copying a param with shape torch.Size([5120, 1280]) from checkpoint, the\
          \ shape in current model is torch.Size([8192, 2048]).\n        size mismatch\
          \ for layers.0.1.3.weight: copying a param with shape torch.Size([1280,\
          \ 5120]) from checkpoint, the shape in current model is torch.Size([2048,\
          \ 8192]).\n        size mismatch for layers.1.0.norm1.weight: copying a\
          \ param with shape torch.Size([1280]) from checkpoint, the shape in current\
          \ model is torch.Size([2048]).\n        size mismatch for layers.1.0.norm1.bias:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.1.0.norm2.weight:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.1.0.norm2.bias:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.1.0.to_q.weight:\
          \ copying a param with shape torch.Size([1280, 1280]) from checkpoint, the\
          \ shape in current model is torch.Size([768, 2048]).\n        size mismatch\
          \ for layers.1.0.to_kv.weight: copying a param with shape torch.Size([2560,\
          \ 1280]) from checkpoint, the shape in current model is torch.Size([1536,\
          \ 2048]).\n        size mismatch for layers.1.0.to_out.weight: copying a\
          \ param with shape torch.Size([1280, 1280]) from checkpoint, the shape in\
          \ current model is torch.Size([2048, 768]).\n        size mismatch for layers.1.1.0.weight:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.1.1.0.bias:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.1.1.1.weight:\
          \ copying a param with shape torch.Size([5120, 1280]) from checkpoint, the\
          \ shape in current model is torch.Size([8192, 2048]).\n        size mismatch\
          \ for layers.1.1.3.weight: copying a param with shape torch.Size([1280,\
          \ 5120]) from checkpoint, the shape in current model is torch.Size([2048,\
          \ 8192]).\n        size mismatch for layers.2.0.norm1.weight: copying a\
          \ param with shape torch.Size([1280]) from checkpoint, the shape in current\
          \ model is torch.Size([2048]).\n        size mismatch for layers.2.0.norm1.bias:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.2.0.norm2.weight:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.2.0.norm2.bias:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.2.0.to_q.weight:\
          \ copying a param with shape torch.Size([1280, 1280]) from checkpoint, the\
          \ shape in current model is torch.Size([768, 2048]).\n        size mismatch\
          \ for layers.2.0.to_kv.weight: copying a param with shape torch.Size([2560,\
          \ 1280]) from checkpoint, the shape in current model is torch.Size([1536,\
          \ 2048]).\n        size mismatch for layers.2.0.to_out.weight: copying a\
          \ param with shape torch.Size([1280, 1280]) from checkpoint, the shape in\
          \ current model is torch.Size([2048, 768]).\n        size mismatch for layers.2.1.0.weight:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.2.1.0.bias:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.2.1.1.weight:\
          \ copying a param with shape torch.Size([5120, 1280]) from checkpoint, the\
          \ shape in current model is torch.Size([8192, 2048]).\n        size mismatch\
          \ for layers.2.1.3.weight: copying a param with shape torch.Size([1280,\
          \ 5120]) from checkpoint, the shape in current model is torch.Size([2048,\
          \ 8192]).\n        size mismatch for layers.3.0.norm1.weight: copying a\
          \ param with shape torch.Size([1280]) from checkpoint, the shape in current\
          \ model is torch.Size([2048]).\n        size mismatch for layers.3.0.norm1.bias:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.3.0.norm2.weight:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.3.0.norm2.bias:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.3.0.to_q.weight:\
          \ copying a param with shape torch.Size([1280, 1280]) from checkpoint, the\
          \ shape in current model is torch.Size([768, 2048]).\n        size mismatch\
          \ for layers.3.0.to_kv.weight: copying a param with shape torch.Size([2560,\
          \ 1280]) from checkpoint, the shape in current model is torch.Size([1536,\
          \ 2048]).\n        size mismatch for layers.3.0.to_out.weight: copying a\
          \ param with shape torch.Size([1280, 1280]) from checkpoint, the shape in\
          \ current model is torch.Size([2048, 768]).\n        size mismatch for layers.3.1.0.weight:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.3.1.0.bias:\
          \ copying a param with shape torch.Size([1280]) from checkpoint, the shape\
          \ in current model is torch.Size([2048]).\n        size mismatch for layers.3.1.1.weight:\
          \ copying a param with shape torch.Size([5120, 1280]) from checkpoint, the\
          \ shape in current model is torch.Size([8192, 2048]).\n        size mismatch\
          \ for layers.3.1.3.weight: copying a param with shape torch.Size([1280,\
          \ 5120]) from checkpoint, the shape in current model is torch.Size([2048,\
          \ 8192]).\n\nI tried using SDXL VAE and tried on automatic, tried without\
          \ refiner or hi-res fix and always the same error.\n\nThanks in advance."
        updatedAt: '2023-10-07T17:39:14.997Z'
      numEdits: 1
      reactions: []
    id: 65219776a56398128b36afc1
    type: comment
  author: eniora
  content: "Hello, I am using A1111 (latest with the most recent controlnet version)\n\
    I downloaded the ip-adapter-plus_sdxl_vit-h.bin file but it doesn't appear in\
    \ the Controlnet model list until I rename it to .pth and when I do so, I get\
    \ error when I press generate:\n\nError running process: C:\\stable-diffusion-webui\\\
    extensions\\sd-webui-controlnet\\scripts\\controlnet.py\n    Traceback (most recent\
    \ call last):\n      File \"C:\\stable-diffusion-webui\\modules\\scripts.py\"\
    , line 619, in process\n        script.process(p, *script_args)\n      File \"\
    C:\\stable-diffusion-webui\\extensions\\sd-webui-controlnet\\scripts\\controlnet.py\"\
    , line 977, in process\n        self.controlnet_hack(p)\n      File \"C:\\stable-diffusion-webui\\\
    extensions\\sd-webui-controlnet\\scripts\\controlnet.py\", line 966, in controlnet_hack\n\
    \        self.controlnet_main_entry(p)\n      File \"C:\\stable-diffusion-webui\\\
    extensions\\sd-webui-controlnet\\scripts\\controlnet.py\", line 688, in controlnet_main_entry\n\
    \        model_net = Script.load_control_model(p, unet, unit.model)\n      File\
    \ \"C:\\stable-diffusion-webui\\extensions\\sd-webui-controlnet\\scripts\\controlnet.py\"\
    , line 321, in load_control_model\n        model_net = Script.build_control_model(p,\
    \ unet, model)\n      File \"C:\\stable-diffusion-webui\\extensions\\sd-webui-controlnet\\\
    scripts\\controlnet.py\", line 350, in build_control_model\n        network =\
    \ build_model_by_guess(state_dict, unet, model_path)\n      File \"C:\\stable-diffusion-webui\\\
    extensions\\sd-webui-controlnet\\scripts\\controlnet_model_guess.py\", line 233,\
    \ in build_model_by_guess\n        network = PlugableIPAdapter(state_dict, channel,\
    \ plus)\n      File \"C:\\stable-diffusion-webui\\extensions\\sd-webui-controlnet\\\
    scripts\\controlmodel_ipadapter.py\", line 299, in __init__\n        self.ipadapter\
    \ = IPAdapterModel(state_dict, clip_embeddings_dim=clip_embeddings_dim, is_plus=is_plus)\n\
    \      File \"C:\\stable-diffusion-webui\\extensions\\sd-webui-controlnet\\scripts\\\
    controlmodel_ipadapter.py\", line 191, in __init__\n        self.load_ip_adapter(state_dict)\n\
    \      File \"C:\\stable-diffusion-webui\\extensions\\sd-webui-controlnet\\scripts\\\
    controlmodel_ipadapter.py\", line 194, in load_ip_adapter\n        self.image_proj_model.load_state_dict(state_dict[\"\
    image_proj\"])\n      File \"c:\\stable-diffusion-webui\\venv\\lib\\site-packages\\\
    torch\\nn\\modules\\module.py\", line 2041, in load_state_dict\n        raise\
    \ RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n    RuntimeError:\
    \ Error(s) in loading state_dict for Resampler:\n        size mismatch for latents:\
    \ copying a param with shape torch.Size([1, 16, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([1, 16, 2048]).\n        size mismatch for proj_in.weight:\
    \ copying a param with shape torch.Size([1280, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([2048, 1280]).\n        size mismatch for proj_in.bias:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for proj_out.weight:\
    \ copying a param with shape torch.Size([2048, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([2048, 2048]).\n        size mismatch for layers.0.0.norm1.weight:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.0.0.norm1.bias:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.0.0.norm2.weight:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.0.0.norm2.bias:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.0.0.to_q.weight:\
    \ copying a param with shape torch.Size([1280, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([768, 2048]).\n        size mismatch for layers.0.0.to_kv.weight:\
    \ copying a param with shape torch.Size([2560, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([1536, 2048]).\n        size mismatch for layers.0.0.to_out.weight:\
    \ copying a param with shape torch.Size([1280, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([2048, 768]).\n        size mismatch for layers.0.1.0.weight:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.0.1.0.bias:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.0.1.1.weight:\
    \ copying a param with shape torch.Size([5120, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([8192, 2048]).\n        size mismatch for layers.0.1.3.weight:\
    \ copying a param with shape torch.Size([1280, 5120]) from checkpoint, the shape\
    \ in current model is torch.Size([2048, 8192]).\n        size mismatch for layers.1.0.norm1.weight:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.1.0.norm1.bias:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.1.0.norm2.weight:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.1.0.norm2.bias:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.1.0.to_q.weight:\
    \ copying a param with shape torch.Size([1280, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([768, 2048]).\n        size mismatch for layers.1.0.to_kv.weight:\
    \ copying a param with shape torch.Size([2560, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([1536, 2048]).\n        size mismatch for layers.1.0.to_out.weight:\
    \ copying a param with shape torch.Size([1280, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([2048, 768]).\n        size mismatch for layers.1.1.0.weight:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.1.1.0.bias:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.1.1.1.weight:\
    \ copying a param with shape torch.Size([5120, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([8192, 2048]).\n        size mismatch for layers.1.1.3.weight:\
    \ copying a param with shape torch.Size([1280, 5120]) from checkpoint, the shape\
    \ in current model is torch.Size([2048, 8192]).\n        size mismatch for layers.2.0.norm1.weight:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.2.0.norm1.bias:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.2.0.norm2.weight:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.2.0.norm2.bias:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.2.0.to_q.weight:\
    \ copying a param with shape torch.Size([1280, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([768, 2048]).\n        size mismatch for layers.2.0.to_kv.weight:\
    \ copying a param with shape torch.Size([2560, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([1536, 2048]).\n        size mismatch for layers.2.0.to_out.weight:\
    \ copying a param with shape torch.Size([1280, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([2048, 768]).\n        size mismatch for layers.2.1.0.weight:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.2.1.0.bias:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.2.1.1.weight:\
    \ copying a param with shape torch.Size([5120, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([8192, 2048]).\n        size mismatch for layers.2.1.3.weight:\
    \ copying a param with shape torch.Size([1280, 5120]) from checkpoint, the shape\
    \ in current model is torch.Size([2048, 8192]).\n        size mismatch for layers.3.0.norm1.weight:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.3.0.norm1.bias:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.3.0.norm2.weight:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.3.0.norm2.bias:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.3.0.to_q.weight:\
    \ copying a param with shape torch.Size([1280, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([768, 2048]).\n        size mismatch for layers.3.0.to_kv.weight:\
    \ copying a param with shape torch.Size([2560, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([1536, 2048]).\n        size mismatch for layers.3.0.to_out.weight:\
    \ copying a param with shape torch.Size([1280, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([2048, 768]).\n        size mismatch for layers.3.1.0.weight:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.3.1.0.bias:\
    \ copying a param with shape torch.Size([1280]) from checkpoint, the shape in\
    \ current model is torch.Size([2048]).\n        size mismatch for layers.3.1.1.weight:\
    \ copying a param with shape torch.Size([5120, 1280]) from checkpoint, the shape\
    \ in current model is torch.Size([8192, 2048]).\n        size mismatch for layers.3.1.3.weight:\
    \ copying a param with shape torch.Size([1280, 5120]) from checkpoint, the shape\
    \ in current model is torch.Size([2048, 8192]).\n\nI tried using SDXL VAE and\
    \ tried on automatic, tried without refiner or hi-res fix and always the same\
    \ error.\n\nThanks in advance."
  created_at: 2023-10-07 16:37:58+00:00
  edited: true
  hidden: false
  id: 65219776a56398128b36afc1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6319b24609baf858241f026c/nBucmn2eT498BLq0MNcqo.png?w=200&h=200&f=face
      fullname: xiaohu
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: h94
      type: user
    createdAt: '2023-10-08T03:08:16.000Z'
    data:
      edited: false
      editors:
      - h94
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6747654676437378
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6319b24609baf858241f026c/nBucmn2eT498BLq0MNcqo.png?w=200&h=200&f=face
          fullname: xiaohu
          isHf: false
          isPro: false
          name: h94
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;eniora&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/eniora\">@<span class=\"\
          underline\">eniora</span></a></span>\n\n\t</span></span> hi, you can use\
          \ comfyui: <a rel=\"nofollow\" href=\"https://github.com/laksjdjf/IPAdapter-ComfyUI\"\
          >https://github.com/laksjdjf/IPAdapter-ComfyUI</a> or <a rel=\"nofollow\"\
          \ href=\"https://github.com/cubiq/ComfyUI_IPAdapter_plus\">https://github.com/cubiq/ComfyUI_IPAdapter_plus</a>.\
          \ webui now don't support it</p>\n"
        raw: '@eniora hi, you can use comfyui: https://github.com/laksjdjf/IPAdapter-ComfyUI
          or https://github.com/cubiq/ComfyUI_IPAdapter_plus. webui now don''t support
          it'
        updatedAt: '2023-10-08T03:08:16.502Z'
      numEdits: 0
      reactions: []
    id: 65221d208fc4884992d8ca90
    type: comment
  author: h94
  content: '@eniora hi, you can use comfyui: https://github.com/laksjdjf/IPAdapter-ComfyUI
    or https://github.com/cubiq/ComfyUI_IPAdapter_plus. webui now don''t support it'
  created_at: 2023-10-08 02:08:16+00:00
  edited: false
  hidden: false
  id: 65221d208fc4884992d8ca90
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dbf2e9bd0c0df4741ba87a6c2c51ea5c.svg
      fullname: revo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eniora
      type: user
    createdAt: '2023-10-08T08:36:47.000Z'
    data:
      edited: false
      editors:
      - eniora
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7204886674880981
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dbf2e9bd0c0df4741ba87a6c2c51ea5c.svg
          fullname: revo
          isHf: false
          isPro: false
          name: eniora
          type: user
        html: '<p>OK thank you!</p>

          '
        raw: OK thank you!
        updatedAt: '2023-10-08T08:36:47.135Z'
      numEdits: 0
      reactions: []
    id: 65226a1fe3419abdcf77fc68
    type: comment
  author: eniora
  content: OK thank you!
  created_at: 2023-10-08 07:36:47+00:00
  edited: false
  hidden: false
  id: 65226a1fe3419abdcf77fc68
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e4f315d9b4500c7fe3a979356df89f4f.svg
      fullname: reuben
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: reubensrandom
      type: user
    createdAt: '2023-10-10T17:30:16.000Z'
    data:
      edited: false
      editors:
      - reubensrandom
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9651413559913635
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e4f315d9b4500c7fe3a979356df89f4f.svg
          fullname: reuben
          isHf: false
          isPro: false
          name: reubensrandom
          type: user
        html: '<p>are there any plans to support AUTO1111 in the future?</p>

          '
        raw: are there any plans to support AUTO1111 in the future?
        updatedAt: '2023-10-10T17:30:16.779Z'
      numEdits: 0
      reactions: []
    id: 65258a2839fd3599e85ec1d8
    type: comment
  author: reubensrandom
  content: are there any plans to support AUTO1111 in the future?
  created_at: 2023-10-10 16:30:16+00:00
  edited: false
  hidden: false
  id: 65258a2839fd3599e85ec1d8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6319b24609baf858241f026c/nBucmn2eT498BLq0MNcqo.png?w=200&h=200&f=face
      fullname: xiaohu
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: h94
      type: user
    createdAt: '2023-10-12T03:49:55.000Z'
    data:
      edited: false
      editors:
      - h94
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8290994763374329
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6319b24609baf858241f026c/nBucmn2eT498BLq0MNcqo.png?w=200&h=200&f=face
          fullname: xiaohu
          isHf: false
          isPro: false
          name: h94
          type: user
        html: '<blockquote>

          <p>are there any plans to support AUTO1111 in the future?</p>

          </blockquote>

          <p>hi, you can track this <a rel="nofollow" href="https://github.com/Mikubill/sd-webui-controlnet/pull/2158">https://github.com/Mikubill/sd-webui-controlnet/pull/2158</a></p>

          '
        raw: '> are there any plans to support AUTO1111 in the future?


          hi, you can track this https://github.com/Mikubill/sd-webui-controlnet/pull/2158'
        updatedAt: '2023-10-12T03:49:55.118Z'
      numEdits: 0
      reactions: []
    id: 65276ce3f335459cc0b9f411
    type: comment
  author: h94
  content: '> are there any plans to support AUTO1111 in the future?


    hi, you can track this https://github.com/Mikubill/sd-webui-controlnet/pull/2158'
  created_at: 2023-10-12 02:49:55+00:00
  edited: false
  hidden: false
  id: 65276ce3f335459cc0b9f411
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a60ee46fb8987e8bb9ce17/MRuRUS9SORsErazoKZ5KH.jpeg?w=200&h=200&f=face
      fullname: "Herv\xE9 Fulchiron"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: herve76
      type: user
    createdAt: '2023-11-04T21:01:44.000Z'
    data:
      edited: false
      editors:
      - herve76
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9723800420761108
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a60ee46fb8987e8bb9ce17/MRuRUS9SORsErazoKZ5KH.jpeg?w=200&h=200&f=face
          fullname: "Herv\xE9 Fulchiron"
          isHf: false
          isPro: false
          name: herve76
          type: user
        html: '<p>I have the same issue. any solution?</p>

          '
        raw: I have the same issue. any solution?
        updatedAt: '2023-11-04T21:01:44.811Z'
      numEdits: 0
      reactions: []
    id: 6546b13896c46859c2e2a6b4
    type: comment
  author: herve76
  content: I have the same issue. any solution?
  created_at: 2023-11-04 20:01:44+00:00
  edited: false
  hidden: false
  id: 6546b13896c46859c2e2a6b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6319b24609baf858241f026c/nBucmn2eT498BLq0MNcqo.png?w=200&h=200&f=face
      fullname: xiaohu
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: h94
      type: user
    createdAt: '2023-11-05T10:23:50.000Z'
    data:
      edited: false
      editors:
      - h94
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5407731533050537
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6319b24609baf858241f026c/nBucmn2eT498BLq0MNcqo.png?w=200&h=200&f=face
          fullname: xiaohu
          isHf: false
          isPro: false
          name: h94
          type: user
        html: '<p>hi, you should follow <a href="https://huggingface.co/h94/IP-Adapter#ip-adapter-for-sdxl-10">https://huggingface.co/h94/IP-Adapter#ip-adapter-for-sdxl-10</a>,
          and use the right image encoder model.</p>

          '
        raw: hi, you should follow https://huggingface.co/h94/IP-Adapter#ip-adapter-for-sdxl-10,
          and use the right image encoder model.
        updatedAt: '2023-11-05T10:23:50.670Z'
      numEdits: 0
      reactions: []
    id: 65476d3644867327205fd89c
    type: comment
  author: h94
  content: hi, you should follow https://huggingface.co/h94/IP-Adapter#ip-adapter-for-sdxl-10,
    and use the right image encoder model.
  created_at: 2023-11-05 10:23:50+00:00
  edited: false
  hidden: false
  id: 65476d3644867327205fd89c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dbf2e9bd0c0df4741ba87a6c2c51ea5c.svg
      fullname: revo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eniora
      type: user
    createdAt: '2023-11-05T17:12:30.000Z'
    data:
      edited: false
      editors:
      - eniora
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8042404651641846
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dbf2e9bd0c0df4741ba87a6c2c51ea5c.svg
          fullname: revo
          isHf: false
          isPro: false
          name: eniora
          type: user
        html: '<p>It works fine now with the latest CN Web UI updates. Thanks h94
          and everyone.</p>

          '
        raw: It works fine now with the latest CN Web UI updates. Thanks h94 and everyone.
        updatedAt: '2023-11-05T17:12:30.309Z'
      numEdits: 0
      reactions: []
    id: 6547ccfe2fe2a1e68697560e
    type: comment
  author: eniora
  content: It works fine now with the latest CN Web UI updates. Thanks h94 and everyone.
  created_at: 2023-11-05 17:12:30+00:00
  edited: false
  hidden: false
  id: 6547ccfe2fe2a1e68697560e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6e11759ec016c3cf399435ee1bc1c35b.svg
      fullname: ya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ill777
      type: user
    createdAt: '2023-11-15T09:32:47.000Z'
    data:
      edited: false
      editors:
      - Ill777
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9857601523399353
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6e11759ec016c3cf399435ee1bc1c35b.svg
          fullname: ya
          isHf: false
          isPro: false
          name: Ill777
          type: user
        html: '<p>Hey, eniora how did you manage to make it work in webui?, the ip
          adapter doesn''t appear to me.</p>

          '
        raw: Hey, eniora how did you manage to make it work in webui?, the ip adapter
          doesn't appear to me.
        updatedAt: '2023-11-15T09:32:47.729Z'
      numEdits: 0
      reactions: []
    id: 6554903f7e560e21b2294ada
    type: comment
  author: Ill777
  content: Hey, eniora how did you manage to make it work in webui?, the ip adapter
    doesn't appear to me.
  created_at: 2023-11-15 09:32:47+00:00
  edited: false
  hidden: false
  id: 6554903f7e560e21b2294ada
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: h94/IP-Adapter
repo_type: model
status: open
target_branch: null
title: ip-adapter-plus_sdxl_vit-h gives error when used with any SDXL checkpoint
