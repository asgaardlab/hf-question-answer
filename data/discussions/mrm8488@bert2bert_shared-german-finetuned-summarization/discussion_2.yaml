!!python/object:huggingface_hub.community.DiscussionWithDetails
author: JingFan
conflicting_files: null
created_at: 2022-07-01 13:31:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acae1030bf660b3baa1837ee1566879f.svg
      fullname: Jing Fan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JingFan
      type: user
    createdAt: '2022-07-01T14:31:31.000Z'
    data:
      edited: false
      editors:
      - JingFan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acae1030bf660b3baa1837ee1566879f.svg
          fullname: Jing Fan
          isHf: false
          isPro: false
          name: JingFan
          type: user
        html: "<p>Hi there,</p>\n<p>my colleague <span data-props=\"{&quot;user&quot;:&quot;dennlinger&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/dennlinger\"\
          >@<span class=\"underline\">dennlinger</span></a></span>\n\n\t</span></span>\
          \  and I are from the Institute of Computer Science at Heidelberg University,\
          \ currently investigating the performance of German abstractive summarizers.\
          \ We are very interested in your model and we have tested your model with\
          \ the <a href=\"https://huggingface.co/datasets/mlsum\">MLSUM Test set</a>\
          \ (all samples). We found that our results (see table below) are slightly\
          \ better than the <a href=\"https://huggingface.co/mrm8488/bert2bert_shared-german-finetuned-summarization\"\
          >results you reported in the model card</a>.</p>\n<div class=\"max-w-full\
          \ overflow-auto\">\n\t<table>\n\t\t<thead><tr>\n<th>Parameters</th>\n<th>Rouge2-precsion(mid)</th>\n\
          <th>Rouge2-recall(mid)</th>\n<th>Rouge2-F1(mid)</th>\n</tr>\n\n\t\t</thead><tbody><tr>\n\
          <td>MLSUM (max_length=354, min_length=13, do_sample=false, truncation=True)</td>\n\
          <td>0.3334</td>\n<td>0.3422</td>\n<td>0.3347</td>\n</tr>\n</tbody>\n\t</table>\n\
          </div>\n<p>Besides, we have some further questions related to your model:</p>\n\
          <ol>\n<li>In the <a href=\"https://huggingface.co/mrm8488/bert2bert_shared-german-finetuned-summarization\"\
          >model page</a>, we can not find any information about the evaluation parameters.\
          \ Can you specify the hyperparameter choices that you used for the evaluation\
          \ process?</li>\n<li>You have trained your model for 18 epochs, which seems\
          \ extremely long (given the dataset size). Have you evaluated the validation\
          \ loss at all? Despite setting the <code>eval_steps</code>, <code>do_eval</code>\
          \ is still set to <code>False</code>, which makes it unclear whether evaluation\
          \ was performed during training.</li>\n<li>We checked the first five articles\
          \ in the test set and found that the summaries primarily (4/5 articles)\
          \ consist of copies of the leading sentences of the reference articles.\
          \ Also, the example summary output in the <a href=\"https://huggingface.co/mrm8488/bert2bert_shared-german-finetuned-summarization\"\
          >model page</a> is just the first two sentences of the source text. Are\
          \ you aware of this problem?</li>\n</ol>\n<p>Thank you in advance for your\
          \ response and input!</p>\n<p>Best wishes,</p>\n<p>Dennis and Jing</p>\n"
        raw: "Hi there,\r\n\r\nmy colleague @dennlinger  and I are from the Institute\
          \ of Computer Science at Heidelberg University, currently investigating\
          \ the performance of German abstractive summarizers. We are very interested\
          \ in your model and we have tested your model with the [MLSUM Test set](https://huggingface.co/datasets/mlsum)\
          \ (all samples). We found that our results (see table below) are slightly\
          \ better than the [results you reported in the model card](https://huggingface.co/mrm8488/bert2bert_shared-german-finetuned-summarization).\r\
          \n\r\n| Parameters | Rouge2-precsion(mid) |Rouge2-recall(mid) |Rouge2-F1(mid)\
          \ |\r\n| ------ | ------ |------ |------ |\r\n| MLSUM (max_length=354, min_length=13,\
          \ do_sample=false, truncation=True) | 0.3334 | 0.3422 | 0.3347|\r\n\r\n\r\
          \nBesides, we have some further questions related to your model:\r\n\r\n\
          1. In the [model page](https://huggingface.co/mrm8488/bert2bert_shared-german-finetuned-summarization),\
          \ we can not find any information about the evaluation parameters. Can you\
          \ specify the hyperparameter choices that you used for the evaluation process?\r\
          \n2. You have trained your model for 18 epochs, which seems extremely long\
          \ (given the dataset size). Have you evaluated the validation loss at all?\
          \ Despite setting the `eval_steps`, `do_eval` is still set to `False`, which\
          \ makes it unclear whether evaluation was performed during training.\r\n\
          3. We checked the first five articles in the test set and found that the\
          \ summaries primarily (4/5 articles) consist of copies of the leading sentences\
          \ of the reference articles. Also, the example summary output in the [model\
          \ page](https://huggingface.co/mrm8488/bert2bert_shared-german-finetuned-summarization)\
          \ is just the first two sentences of the source text. Are you aware of this\
          \ problem?\r\n\r\nThank you in advance for your response and input!\r\n\r\
          \nBest wishes,\r\n\r\nDennis and Jing"
        updatedAt: '2022-07-01T14:31:31.828Z'
      numEdits: 0
      reactions: []
    id: 62bf054349f5bf961ce3fe04
    type: comment
  author: JingFan
  content: "Hi there,\r\n\r\nmy colleague @dennlinger  and I are from the Institute\
    \ of Computer Science at Heidelberg University, currently investigating the performance\
    \ of German abstractive summarizers. We are very interested in your model and\
    \ we have tested your model with the [MLSUM Test set](https://huggingface.co/datasets/mlsum)\
    \ (all samples). We found that our results (see table below) are slightly better\
    \ than the [results you reported in the model card](https://huggingface.co/mrm8488/bert2bert_shared-german-finetuned-summarization).\r\
    \n\r\n| Parameters | Rouge2-precsion(mid) |Rouge2-recall(mid) |Rouge2-F1(mid)\
    \ |\r\n| ------ | ------ |------ |------ |\r\n| MLSUM (max_length=354, min_length=13,\
    \ do_sample=false, truncation=True) | 0.3334 | 0.3422 | 0.3347|\r\n\r\n\r\nBesides,\
    \ we have some further questions related to your model:\r\n\r\n1. In the [model\
    \ page](https://huggingface.co/mrm8488/bert2bert_shared-german-finetuned-summarization),\
    \ we can not find any information about the evaluation parameters. Can you specify\
    \ the hyperparameter choices that you used for the evaluation process?\r\n2. You\
    \ have trained your model for 18 epochs, which seems extremely long (given the\
    \ dataset size). Have you evaluated the validation loss at all? Despite setting\
    \ the `eval_steps`, `do_eval` is still set to `False`, which makes it unclear\
    \ whether evaluation was performed during training.\r\n3. We checked the first\
    \ five articles in the test set and found that the summaries primarily (4/5 articles)\
    \ consist of copies of the leading sentences of the reference articles. Also,\
    \ the example summary output in the [model page](https://huggingface.co/mrm8488/bert2bert_shared-german-finetuned-summarization)\
    \ is just the first two sentences of the source text. Are you aware of this problem?\r\
    \n\r\nThank you in advance for your response and input!\r\n\r\nBest wishes,\r\n\
    \r\nDennis and Jing"
  created_at: 2022-07-01 13:31:31+00:00
  edited: false
  hidden: false
  id: 62bf054349f5bf961ce3fe04
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: mrm8488/bert2bert_shared-german-finetuned-summarization
repo_type: model
status: open
target_branch: null
title: Slightly better results than the reported results and some questions about
  the model
