!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hammad93
conflicting_files: null
created_at: 2023-12-12 14:03:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
      fullname: hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hammad93
      type: user
    createdAt: '2023-12-12T14:03:53.000Z'
    data:
      edited: true
      editors:
      - hammad93
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8997191190719604
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
          fullname: hammad
          isHf: false
          isPro: false
          name: hammad93
          type: user
        html: '<p>I tried to start a chatbot with multiple versions of this model
          using the llama.cpp server the mixtral support version on a kaggle notebook.
          the script runs ok and there is enough memory and vram for this version
          of the model  on the 2X T4 GPU notebook but for some reason the chat bot
          responses are really weird, it keeps getting stuck on the same responses
          no matter what prompt I use, and it doesn''t seem to understand the prompts.
          i''m not sure what''s causing the weird responses. Also I''m using the default
          values for the parameters. I tried changing the temperature multiple times
          but it doesn''t affect the responses.</p>

          <p>Kaggle notebook repo link: <a rel="nofollow" href="https://github.com/mth93/mixtral_llama_cpp/blob/main/llama-cpp-ngrok-api-mixtral.ipynb">https://github.com/mth93/mixtral_llama_cpp/blob/main/llama-cpp-ngrok-api-mixtral.ipynb</a></p>

          <p>Versions:<br>mixtral-8x7b-instruct-v0.1.Q2_K.gguf<br>mixtral-8x7b-instruct-v0.1.Q3_K_M.gguf<br>mixtral-8x7b-instruct-v0.1.Q4_0.gguf<br>mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf<br>i
          tried using the other files but due to the model size there is not enough
          vram on kaggle notebooks free version.</p>

          <p>I''m a beginner at AI and using LLMs and I don''t understand the difference
          between the different quantized versions and how that affects performance,
          If anyone can explain that or provide resources that would be really appreciated.</p>

          <p>PS: please let me know if you need me to provide more details or clear
          out anything as English isn''t my first language.</p>

          <p>Thanks,</p>

          '
        raw: 'I tried to start a chatbot with multiple versions of this model using
          the llama.cpp server the mixtral support version on a kaggle notebook. the
          script runs ok and there is enough memory and vram for this version of the
          model  on the 2X T4 GPU notebook but for some reason the chat bot responses
          are really weird, it keeps getting stuck on the same responses no matter
          what prompt I use, and it doesn''t seem to understand the prompts. i''m
          not sure what''s causing the weird responses. Also I''m using the default
          values for the parameters. I tried changing the temperature multiple times
          but it doesn''t affect the responses.


          Kaggle notebook repo link: https://github.com/mth93/mixtral_llama_cpp/blob/main/llama-cpp-ngrok-api-mixtral.ipynb


          Versions:

          mixtral-8x7b-instruct-v0.1.Q2_K.gguf

          mixtral-8x7b-instruct-v0.1.Q3_K_M.gguf

          mixtral-8x7b-instruct-v0.1.Q4_0.gguf

          mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf

          i tried using the other files but due to the model size there is not enough
          vram on kaggle notebooks free version.


          I''m a beginner at AI and using LLMs and I don''t understand the difference
          between the different quantized versions and how that affects performance,
          If anyone can explain that or provide resources that would be really appreciated.


          PS: please let me know if you need me to provide more details or clear out
          anything as English isn''t my first language.


          Thanks,

          '
        updatedAt: '2023-12-12T19:39:19.986Z'
      numEdits: 4
      reactions: []
    id: 6578684976b6de797808c394
    type: comment
  author: hammad93
  content: 'I tried to start a chatbot with multiple versions of this model using
    the llama.cpp server the mixtral support version on a kaggle notebook. the script
    runs ok and there is enough memory and vram for this version of the model  on
    the 2X T4 GPU notebook but for some reason the chat bot responses are really weird,
    it keeps getting stuck on the same responses no matter what prompt I use, and
    it doesn''t seem to understand the prompts. i''m not sure what''s causing the
    weird responses. Also I''m using the default values for the parameters. I tried
    changing the temperature multiple times but it doesn''t affect the responses.


    Kaggle notebook repo link: https://github.com/mth93/mixtral_llama_cpp/blob/main/llama-cpp-ngrok-api-mixtral.ipynb


    Versions:

    mixtral-8x7b-instruct-v0.1.Q2_K.gguf

    mixtral-8x7b-instruct-v0.1.Q3_K_M.gguf

    mixtral-8x7b-instruct-v0.1.Q4_0.gguf

    mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf

    i tried using the other files but due to the model size there is not enough vram
    on kaggle notebooks free version.


    I''m a beginner at AI and using LLMs and I don''t understand the difference between
    the different quantized versions and how that affects performance, If anyone can
    explain that or provide resources that would be really appreciated.


    PS: please let me know if you need me to provide more details or clear out anything
    as English isn''t my first language.


    Thanks,

    '
  created_at: 2023-12-12 14:03:53+00:00
  edited: true
  hidden: false
  id: 6578684976b6de797808c394
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-12-12T14:42:33.000Z'
    data:
      edited: false
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8655543327331543
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>Use llamacpp version .<br>It works on CPU and GPU even partially
          on GPU </p>

          '
        raw: 'Use llamacpp version .

          It works on CPU and GPU even partially on GPU '
        updatedAt: '2023-12-12T14:42:33.104Z'
      numEdits: 0
      reactions: []
    id: 657871596db22fc06cad5c39
    type: comment
  author: mirek190
  content: 'Use llamacpp version .

    It works on CPU and GPU even partially on GPU '
  created_at: 2023-12-12 14:42:33+00:00
  edited: false
  hidden: false
  id: 657871596db22fc06cad5c39
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
      fullname: hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hammad93
      type: user
    createdAt: '2023-12-12T15:11:47.000Z'
    data:
      edited: true
      editors:
      - hammad93
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8778061866760254
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
          fullname: hammad
          isHf: false
          isPro: false
          name: hammad93
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mirek190&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mirek190\">@<span class=\"\
          underline\">mirek190</span></a></span>\n\n\t</span></span> i'm already using\
          \ the mixtral branch on the llamacpp github repo and it work. the problem\
          \ is with the responses. i'll add some screenshots on the parameter values\
          \ and the responses</p>\n"
        raw: '@mirek190 i''m already using the mixtral branch on the llamacpp github
          repo and it work. the problem is with the responses. i''ll add some screenshots
          on the parameter values and the responses'
        updatedAt: '2023-12-12T15:17:44.820Z'
      numEdits: 2
      reactions: []
    id: 65787833ee40482b5c43cf08
    type: comment
  author: hammad93
  content: '@mirek190 i''m already using the mixtral branch on the llamacpp github
    repo and it work. the problem is with the responses. i''ll add some screenshots
    on the parameter values and the responses'
  created_at: 2023-12-12 15:11:47+00:00
  edited: true
  hidden: false
  id: 65787833ee40482b5c43cf08
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-12-12T15:22:21.000Z'
    data:
      edited: true
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9361587762832642
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>Have you used a proper template ?<br>And what quantitation did you
          use ?<br>I''m testing minimum q4k_m and also chat version is shitty. Try
          instruct version which is much better .</p>

          '
        raw: 'Have you used a proper template ?

          And what quantitation did you use ?

          I''m testing minimum q4k_m and also chat version is shitty. Try instruct
          version which is much better .'
        updatedAt: '2023-12-12T15:23:31.665Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - hammad93
    id: 65787aad3ceeb2f07810c715
    type: comment
  author: mirek190
  content: 'Have you used a proper template ?

    And what quantitation did you use ?

    I''m testing minimum q4k_m and also chat version is shitty. Try instruct version
    which is much better .'
  created_at: 2023-12-12 15:22:21+00:00
  edited: true
  hidden: false
  id: 65787aad3ceeb2f07810c715
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
      fullname: hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hammad93
      type: user
    createdAt: '2023-12-12T15:25:56.000Z'
    data:
      edited: false
      editors:
      - hammad93
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9318543672561646
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
          fullname: hammad
          isHf: false
          isPro: false
          name: hammad93
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mirek190&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mirek190\">@<span class=\"\
          underline\">mirek190</span></a></span>\n\n\t</span></span> I think that\
          \ might be the problem. i'm trying to use it as a regular chatbot with no\
          \ template and the responses are really shitty and awkward. where can i\
          \ find a proper template for mixtral.<br>i'm currently trying out this version:\
          \     mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf</p>\n<p>thanks a lot for helping\
          \ out man its really appreciated.</p>\n"
        raw: '@mirek190 I think that might be the problem. i''m trying to use it as
          a regular chatbot with no template and the responses are really shitty and
          awkward. where can i find a proper template for mixtral.

          i''m currently trying out this version:     mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf


          thanks a lot for helping out man its really appreciated.'
        updatedAt: '2023-12-12T15:25:56.374Z'
      numEdits: 0
      reactions: []
    id: 65787b844d989b0a68a28954
    type: comment
  author: hammad93
  content: '@mirek190 I think that might be the problem. i''m trying to use it as
    a regular chatbot with no template and the responses are really shitty and awkward.
    where can i find a proper template for mixtral.

    i''m currently trying out this version:     mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf


    thanks a lot for helping out man its really appreciated.'
  created_at: 2023-12-12 15:25:56+00:00
  edited: false
  hidden: false
  id: 65787b844d989b0a68a28954
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-12-12T16:15:18.000Z'
    data:
      edited: false
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7402234077453613
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>Under llamacpp for that model template is </p>

          <pre><code>--in-prefix " &lt;s&gt;[INST] " --in-suffix " [/INST] "

          </code></pre>

          <p>add this to command line </p>

          '
        raw: "Under llamacpp for that model template is \n\n````\n--in-prefix \" <s>[INST]\
          \ \" --in-suffix \" [/INST] \"\n````\n\nadd this to command line "
        updatedAt: '2023-12-12T16:15:18.603Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - hammad93
        - ztime
    id: 65788716411e14898ba41a78
    type: comment
  author: mirek190
  content: "Under llamacpp for that model template is \n\n````\n--in-prefix \" <s>[INST]\
    \ \" --in-suffix \" [/INST] \"\n````\n\nadd this to command line "
  created_at: 2023-12-12 16:15:18+00:00
  edited: false
  hidden: false
  id: 65788716411e14898ba41a78
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
      fullname: hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hammad93
      type: user
    createdAt: '2023-12-12T17:10:16.000Z'
    data:
      edited: false
      editors:
      - hammad93
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6000963449478149
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
          fullname: hammad
          isHf: false
          isPro: false
          name: hammad93
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mirek190&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mirek190\">@<span class=\"\
          underline\">mirek190</span></a></span>\n\n\t</span></span> how to use the\
          \ same options with server instead of main? </p>\n"
        raw: '@mirek190 how to use the same options with server instead of main? '
        updatedAt: '2023-12-12T17:10:16.700Z'
      numEdits: 0
      reactions: []
    id: 657893f8d54197901f6cf0d8
    type: comment
  author: hammad93
  content: '@mirek190 how to use the same options with server instead of main? '
  created_at: 2023-12-12 17:10:16+00:00
  edited: false
  hidden: false
  id: 657893f8d54197901f6cf0d8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/de21d4ad8b77920d91a1f8a47e4c24bc.svg
      fullname: 'Morpheus Sandman '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: morph3v5
      type: user
    createdAt: '2023-12-12T19:13:28.000Z'
    data:
      edited: false
      editors:
      - morph3v5
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9857094883918762
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/de21d4ad8b77920d91a1f8a47e4c24bc.svg
          fullname: 'Morpheus Sandman '
          isHf: false
          isPro: false
          name: morph3v5
          type: user
        html: '<p>Server isn''t working yet. I just pulled latest from branch <code>mixtral</code>
          and tried the instruct model with main and server. Main seems to work fine.</p>

          '
        raw: Server isn't working yet. I just pulled latest from branch `mixtral`
          and tried the instruct model with main and server. Main seems to work fine.
        updatedAt: '2023-12-12T19:13:28.736Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - hammad93
        - Hanssep123
    id: 6578b0d8c37954680acb15a5
    type: comment
  author: morph3v5
  content: Server isn't working yet. I just pulled latest from branch `mixtral` and
    tried the instruct model with main and server. Main seems to work fine.
  created_at: 2023-12-12 19:13:28+00:00
  edited: false
  hidden: false
  id: 6578b0d8c37954680acb15a5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
      fullname: hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hammad93
      type: user
    createdAt: '2023-12-12T19:31:25.000Z'
    data:
      edited: true
      editors:
      - hammad93
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9729562997817993
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
          fullname: hammad
          isHf: false
          isPro: false
          name: hammad93
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;morph3v5&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/morph3v5\">@<span class=\"\
          underline\">morph3v5</span></a></span>\n\n\t</span></span> i tested out\
          \ main too it works fine. the problem is main doesn't serve an OAI compatible\
          \ api as far as i know. ill post back if i find a solution for this</p>\n"
        raw: '@morph3v5 i tested out main too it works fine. the problem is main doesn''t
          serve an OAI compatible api as far as i know. ill post back if i find a
          solution for this'
        updatedAt: '2023-12-12T19:31:41.016Z'
      numEdits: 1
      reactions: []
    id: 6578b50d283d91841368baef
    type: comment
  author: hammad93
  content: '@morph3v5 i tested out main too it works fine. the problem is main doesn''t
    serve an OAI compatible api as far as i know. ill post back if i find a solution
    for this'
  created_at: 2023-12-12 19:31:25+00:00
  edited: true
  hidden: false
  id: 6578b50d283d91841368baef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-12-12T19:52:35.000Z'
    data:
      edited: false
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.41187554597854614
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>...or just wait till llamacpp get official release ;) </p>

          '
        raw: '...or just wait till llamacpp get official release ;) '
        updatedAt: '2023-12-12T19:52:35.940Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - hammad93
    id: 6578ba039999746238b6bc50
    type: comment
  author: mirek190
  content: '...or just wait till llamacpp get official release ;) '
  created_at: 2023-12-12 19:52:35+00:00
  edited: false
  hidden: false
  id: 6578ba039999746238b6bc50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
      fullname: hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hammad93
      type: user
    createdAt: '2023-12-12T20:06:11.000Z'
    data:
      edited: false
      editors:
      - hammad93
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.980590283870697
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
          fullname: hammad
          isHf: false
          isPro: false
          name: hammad93
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mirek190&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mirek190\">@<span class=\"\
          underline\">mirek190</span></a></span>\n\n\t</span></span> most likely that's\
          \ what's going to happen. I'm just way too excited to try this model with\
          \ autogen \U0001F602\U0001F602</p>\n"
        raw: "@mirek190 most likely that's what's going to happen. I'm just way too\
          \ excited to try this model with autogen \U0001F602\U0001F602"
        updatedAt: '2023-12-12T20:06:11.421Z'
      numEdits: 0
      reactions: []
    id: 6578bd33ee40482b5c520d4c
    type: comment
  author: hammad93
  content: "@mirek190 most likely that's what's going to happen. I'm just way too\
    \ excited to try this model with autogen \U0001F602\U0001F602"
  created_at: 2023-12-12 20:06:11+00:00
  edited: false
  hidden: false
  id: 6578bd33ee40482b5c520d4c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/653cd3049107029eb004f968/G1A2zca8Yi_ii2YJtHHht.png?w=200&h=200&f=face
      fullname: "Rickard Ed\xE9n"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: neph1
      type: user
    createdAt: '2023-12-13T06:42:08.000Z'
    data:
      edited: true
      editors:
      - neph1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9391215443611145
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/653cd3049107029eb004f968/G1A2zca8Yi_ii2YJtHHht.png?w=200&h=200&f=face
          fullname: "Rickard Ed\xE9n"
          isHf: false
          isPro: false
          name: neph1
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;morph3v5&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/morph3v5\"\
          >@<span class=\"underline\">morph3v5</span></a></span>\n\n\t</span></span>\
          \ i tested out main too it works fine. the problem is main doesn't serve\
          \ an OAI compatible api as far as i know. ill post back if i find a solution\
          \ for this</p>\n</blockquote>\n<p>I've run this with the server from <a\
          \ rel=\"nofollow\" href=\"https://github.com/ggerganov/llama.cpp/pull/4406\"\
          >https://github.com/ggerganov/llama.cpp/pull/4406</a> (mixtral branch) chatting\
          \ through the built in interface. Excellent results. (I've tried temps of\
          \ 0.2 and 0.7).<br>There's also an OAI api example in examples/server/api_like_OAI.py</p>\n"
        raw: '> @morph3v5 i tested out main too it works fine. the problem is main
          doesn''t serve an OAI compatible api as far as i know. ill post back if
          i find a solution for this


          I''ve run this with the server from https://github.com/ggerganov/llama.cpp/pull/4406
          (mixtral branch) chatting through the built in interface. Excellent results.
          (I''ve tried temps of 0.2 and 0.7).

          There''s also an OAI api example in examples/server/api_like_OAI.py

          '
        updatedAt: '2023-12-13T06:43:16.834Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - hammad93
    id: 6579524090df9d85fb8fc1a2
    type: comment
  author: neph1
  content: '> @morph3v5 i tested out main too it works fine. the problem is main doesn''t
    serve an OAI compatible api as far as i know. ill post back if i find a solution
    for this


    I''ve run this with the server from https://github.com/ggerganov/llama.cpp/pull/4406
    (mixtral branch) chatting through the built in interface. Excellent results. (I''ve
    tried temps of 0.2 and 0.7).

    There''s also an OAI api example in examples/server/api_like_OAI.py

    '
  created_at: 2023-12-13 06:42:08+00:00
  edited: true
  hidden: false
  id: 6579524090df9d85fb8fc1a2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
      fullname: hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hammad93
      type: user
    createdAt: '2023-12-13T08:20:56.000Z'
    data:
      edited: false
      editors:
      - hammad93
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7963532209396362
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
          fullname: hammad
          isHf: false
          isPro: false
          name: hammad93
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;neph1&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/neph1\">@<span class=\"\
          underline\">neph1</span></a></span>\n\n\t</span></span> how did you add\
          \ the prompt template to the server?</p>\n"
        raw: '@neph1 how did you add the prompt template to the server?'
        updatedAt: '2023-12-13T08:20:56.091Z'
      numEdits: 0
      reactions: []
    id: 6579696823b2859ba27a5676
    type: comment
  author: hammad93
  content: '@neph1 how did you add the prompt template to the server?'
  created_at: 2023-12-13 08:20:56+00:00
  edited: false
  hidden: false
  id: 6579696823b2859ba27a5676
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
      fullname: hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hammad93
      type: user
    createdAt: '2023-12-13T10:29:21.000Z'
    data:
      edited: false
      editors:
      - hammad93
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8376246690750122
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
          fullname: hammad
          isHf: false
          isPro: false
          name: hammad93
          type: user
        html: '<p>is it possible to get llama.cpp to work on TPU instead of GPU </p>

          '
        raw: 'is it possible to get llama.cpp to work on TPU instead of GPU '
        updatedAt: '2023-12-13T10:29:21.783Z'
      numEdits: 0
      reactions: []
    id: 657987818ea89d1df79ce438
    type: comment
  author: hammad93
  content: 'is it possible to get llama.cpp to work on TPU instead of GPU '
  created_at: 2023-12-13 10:29:21+00:00
  edited: false
  hidden: false
  id: 657987818ea89d1df79ce438
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/653cd3049107029eb004f968/G1A2zca8Yi_ii2YJtHHht.png?w=200&h=200&f=face
      fullname: "Rickard Ed\xE9n"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: neph1
      type: user
    createdAt: '2023-12-13T11:19:44.000Z'
    data:
      edited: false
      editors:
      - neph1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9922844171524048
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/653cd3049107029eb004f968/G1A2zca8Yi_ii2YJtHHht.png?w=200&h=200&f=face
          fullname: "Rickard Ed\xE9n"
          isHf: false
          isPro: false
          name: neph1
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;hammad93&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/hammad93\"\
          >@<span class=\"underline\">hammad93</span></a></span>\n\n\t</span></span>\
          \ </p>\n</blockquote>\n<p>I just built it, and it worked.</p>\n"
        raw: "> @hammad93 \n\nI just built it, and it worked."
        updatedAt: '2023-12-13T11:19:44.044Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - hammad93
    id: 657993501e0e383c6f90158f
    type: comment
  author: neph1
  content: "> @hammad93 \n\nI just built it, and it worked."
  created_at: 2023-12-13 11:19:44+00:00
  edited: false
  hidden: false
  id: 657993501e0e383c6f90158f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
      fullname: hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hammad93
      type: user
    createdAt: '2023-12-13T11:25:21.000Z'
    data:
      edited: false
      editors:
      - hammad93
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9535496830940247
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
          fullname: hammad
          isHf: false
          isPro: false
          name: hammad93
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;neph1&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/neph1\">@<span class=\"\
          underline\">neph1</span></a></span>\n\n\t</span></span> what's the difference\
          \ between this pull request and the already merged mixtral branch?</p>\n"
        raw: '@neph1 what''s the difference between this pull request and the already
          merged mixtral branch?'
        updatedAt: '2023-12-13T11:25:21.144Z'
      numEdits: 0
      reactions: []
    id: 657994a12f03cfb1b5521e11
    type: comment
  author: hammad93
  content: '@neph1 what''s the difference between this pull request and the already
    merged mixtral branch?'
  created_at: 2023-12-13 11:25:21+00:00
  edited: false
  hidden: false
  id: 657994a12f03cfb1b5521e11
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/653cd3049107029eb004f968/G1A2zca8Yi_ii2YJtHHht.png?w=200&h=200&f=face
      fullname: "Rickard Ed\xE9n"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: neph1
      type: user
    createdAt: '2023-12-13T11:52:29.000Z'
    data:
      edited: true
      editors:
      - neph1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9828835129737854
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/653cd3049107029eb004f968/G1A2zca8Yi_ii2YJtHHht.png?w=200&h=200&f=face
          fullname: "Rickard Ed\xE9n"
          isHf: false
          isPro: false
          name: neph1
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;hammad93&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/hammad93\">@<span class=\"\
          underline\">hammad93</span></a></span>\n\n\t</span></span><br>I don't think\
          \ there's been a merge to master, yet. If you're talking about <a rel=\"\
          nofollow\" href=\"https://github.com/ggerganov/llama.cpp/pull/4428\">https://github.com/ggerganov/llama.cpp/pull/4428</a>,\
          \ it was merged to the \"main\" mixtral branch.</p>\n<p>Edit: But now the\
          \ mixtral branch has been merged to master.</p>\n"
        raw: "@hammad93 \nI don't think there's been a merge to master, yet. If you're\
          \ talking about https://github.com/ggerganov/llama.cpp/pull/4428, it was\
          \ merged to the \"main\" mixtral branch.\n\nEdit: But now the mixtral branch\
          \ has been merged to master."
        updatedAt: '2023-12-13T13:18:27.959Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - hammad93
    id: 65799afdd842fd986175d146
    type: comment
  author: neph1
  content: "@hammad93 \nI don't think there's been a merge to master, yet. If you're\
    \ talking about https://github.com/ggerganov/llama.cpp/pull/4428, it was merged\
    \ to the \"main\" mixtral branch.\n\nEdit: But now the mixtral branch has been\
    \ merged to master."
  created_at: 2023-12-13 11:52:29+00:00
  edited: true
  hidden: false
  id: 65799afdd842fd986175d146
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/148da5aa39abc223315fc5bdb91be5f7.svg
      fullname: Hans
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hanssep123
      type: user
    createdAt: '2023-12-14T10:44:59.000Z'
    data:
      edited: true
      editors:
      - Hanssep123
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.73788982629776
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/148da5aa39abc223315fc5bdb91be5f7.svg
          fullname: Hans
          isHf: false
          isPro: false
          name: Hanssep123
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mirek190&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mirek190\">@<span class=\"\
          underline\">mirek190</span></a></span>\n\n\t</span></span><br>How can i\
          \ add this ---&gt;    --in-prefix \" <s>[INST] \" --in-suffix \" [/INST]\
          \ \" to the server of llamacpp? i get a error, only works with main.</s></p><s>\n\
          <p>Hmm iam confused on the readme page from TheBloke the Template is [INST]\
          \ {prompt} [/INST] yours is \" <s>[INST] {prompt} \"[/INST]\" witch one\
          \ is the correct one?</s></p><s>\n<p>WTF? whats up with the line over the\
          \ text?</p>\n</s></s>"
        raw: "@mirek190 \nHow can i add this --->    --in-prefix \" <s>[INST] \" --in-suffix\
          \ \" [/INST] \" to the server of llamacpp? i get a error, only works with\
          \ main.\n\nHmm iam confused on the readme page from TheBloke the Template\
          \ is [INST] {prompt} [/INST] yours is \" <s>[INST] {prompt} \"[/INST]\"\
          \ witch one is the correct one?\n\nWTF? whats up with the line over the\
          \ text?"
        updatedAt: '2023-12-14T10:55:09.116Z'
      numEdits: 2
      reactions: []
    id: 657adcab10609bba2714f192
    type: comment
  author: Hanssep123
  content: "@mirek190 \nHow can i add this --->    --in-prefix \" <s>[INST] \" --in-suffix\
    \ \" [/INST] \" to the server of llamacpp? i get a error, only works with main.\n\
    \nHmm iam confused on the readme page from TheBloke the Template is [INST] {prompt}\
    \ [/INST] yours is \" <s>[INST] {prompt} \"[/INST]\" witch one is the correct\
    \ one?\n\nWTF? whats up with the line over the text?"
  created_at: 2023-12-14 10:44:59+00:00
  edited: true
  hidden: false
  id: 657adcab10609bba2714f192
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-12-14T11:30:19.000Z'
    data:
      edited: false
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6671464443206787
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>Read again the main page to this message model looking for llamacpp
          ... you can add this after -p parameter.</p>

          '
        raw: Read again the main page to this message model looking for llamacpp ...
          you can add this after -p parameter.
        updatedAt: '2023-12-14T11:30:19.198Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Hanssep123
    id: 657ae74b2fc59b67786365bc
    type: comment
  author: mirek190
  content: Read again the main page to this message model looking for llamacpp ...
    you can add this after -p parameter.
  created_at: 2023-12-14 11:30:19+00:00
  edited: false
  hidden: false
  id: 657ae74b2fc59b67786365bc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/148da5aa39abc223315fc5bdb91be5f7.svg
      fullname: Hans
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hanssep123
      type: user
    createdAt: '2023-12-14T13:15:41.000Z'
    data:
      edited: false
      editors:
      - Hanssep123
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.20008358359336853
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/148da5aa39abc223315fc5bdb91be5f7.svg
          fullname: Hans
          isHf: false
          isPro: false
          name: Hanssep123
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mirek190&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mirek190\">@<span class=\"\
          underline\">mirek190</span></a></span>\n\n\t</span></span><br>Thank you!\
          \ </p>\n"
        raw: "@mirek190 \nThank you! "
        updatedAt: '2023-12-14T13:15:41.031Z'
      numEdits: 0
      reactions: []
    id: 657afffd5c6f0b1f36d2d252
    type: comment
  author: Hanssep123
  content: "@mirek190 \nThank you! "
  created_at: 2023-12-14 13:15:41+00:00
  edited: false
  hidden: false
  id: 657afffd5c6f0b1f36d2d252
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
      fullname: hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hammad93
      type: user
    createdAt: '2023-12-16T10:49:00.000Z'
    data:
      edited: false
      editors:
      - hammad93
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.36380213499069214
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef17e599a5f973f0dcab1b577cb50fdb.svg
          fullname: hammad
          isHf: false
          isPro: false
          name: hammad93
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;neph1&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/neph1\">@<span class=\"\
          underline\">neph1</span></a></span>\n\n\t</span></span> thank you !</p>\n"
        raw: '@neph1 thank you !'
        updatedAt: '2023-12-16T10:49:00.432Z'
      numEdits: 0
      reactions: []
    id: 657d809c869d5bb0e5585315
    type: comment
  author: hammad93
  content: '@neph1 thank you !'
  created_at: 2023-12-16 10:49:00+00:00
  edited: false
  hidden: false
  id: 657d809c869d5bb0e5585315
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF
repo_type: model
status: open
target_branch: null
title: chatbot giving weird responses
