!!python/object:huggingface_hub.community.DiscussionWithDetails
author: NickyNicky
conflicting_files: null
created_at: 2023-09-28 07:47:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ab1fba948e86cce23e8ab573f12ff04.svg
      fullname: Nicky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NickyNicky
      type: user
    createdAt: '2023-09-28T08:47:57.000Z'
    data:
      edited: false
      editors:
      - NickyNicky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.41080763936042786
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ab1fba948e86cce23e8ab573f12ff04.svg
          fullname: Nicky
          isHf: false
          isPro: false
          name: NickyNicky
          type: user
        html: '<p>same title ^|</p>

          '
        raw: same title ^|
        updatedAt: '2023-09-28T08:47:57.036Z'
      numEdits: 0
      reactions: []
    id: 65153dbd9dd53fc6f29a3d65
    type: comment
  author: NickyNicky
  content: same title ^|
  created_at: 2023-09-28 07:47:57+00:00
  edited: false
  hidden: false
  id: 65153dbd9dd53fc6f29a3d65
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b02c7468be2b66d56208aad4dd4a5aba.svg
      fullname: Ishaan Gupta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: IshaanGupta2311
      type: user
    createdAt: '2023-09-28T11:38:46.000Z'
    data:
      edited: false
      editors:
      - IshaanGupta2311
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9778990149497986
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b02c7468be2b66d56208aad4dd4a5aba.svg
          fullname: Ishaan Gupta
          isHf: false
          isPro: false
          name: IshaanGupta2311
          type: user
        html: '<p>same ques, i want to explore an application of these 7B models that
          i have been thinking about for quite some time</p>

          '
        raw: 'same ques, i want to explore an application of these 7B models that
          i have been thinking about for quite some time

          '
        updatedAt: '2023-09-28T11:38:46.674Z'
      numEdits: 0
      reactions: []
    id: 651565c6a8e0052b0c3e7758
    type: comment
  author: IshaanGupta2311
  content: 'same ques, i want to explore an application of these 7B models that i
    have been thinking about for quite some time

    '
  created_at: 2023-09-28 10:38:46+00:00
  edited: false
  hidden: false
  id: 651565c6a8e0052b0c3e7758
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e596a89d174967c591c60de2b723e1ad.svg
      fullname: Mohamed Naji Aboo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NajiAboo
      type: user
    createdAt: '2023-09-28T13:36:12.000Z'
    data:
      edited: false
      editors:
      - NajiAboo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9189116954803467
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e596a89d174967c591c60de2b723e1ad.svg
          fullname: Mohamed Naji Aboo
          isHf: false
          isPro: false
          name: NajiAboo
          type: user
        html: '<p>looking for same</p>

          '
        raw: looking for same
        updatedAt: '2023-09-28T13:36:12.163Z'
      numEdits: 0
      reactions: []
    id: 6515814cbc063171985a84a5
    type: comment
  author: NajiAboo
  content: looking for same
  created_at: 2023-09-28 12:36:12+00:00
  edited: false
  hidden: false
  id: 6515814cbc063171985a84a5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638ee0b22cc490759feb38e9/_Z8o0r80_jN43GpRen5sp.jpeg?w=200&h=200&f=face
      fullname: LazerTC
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lazycuber
      type: user
    createdAt: '2023-09-28T14:32:51.000Z'
    data:
      edited: false
      editors:
      - Lazycuber
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8878549933433533
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638ee0b22cc490759feb38e9/_Z8o0r80_jN43GpRen5sp.jpeg?w=200&h=200&f=face
          fullname: LazerTC
          isHf: false
          isPro: false
          name: Lazycuber
          type: user
        html: '<p>still experimenting with colab finetuning... </p>

          '
        raw: 'still experimenting with colab finetuning... '
        updatedAt: '2023-09-28T14:32:51.177Z'
      numEdits: 0
      reactions: []
    id: 65158e934eb20107d0183670
    type: comment
  author: Lazycuber
  content: 'still experimenting with colab finetuning... '
  created_at: 2023-09-28 13:32:51+00:00
  edited: false
  hidden: false
  id: 65158e934eb20107d0183670
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660775548920-628d998a2b60ec0f336cc1eb.png?w=200&h=200&f=face
      fullname: Carl Silva
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: silvacarl
      type: user
    createdAt: '2023-09-28T15:19:15.000Z'
    data:
      edited: false
      editors:
      - silvacarl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9901259541511536
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660775548920-628d998a2b60ec0f336cc1eb.png?w=200&h=200&f=face
          fullname: Carl Silva
          isHf: false
          isPro: true
          name: silvacarl
          type: user
        html: '<p>looking for same here as well.  so far its amazing...</p>

          '
        raw: looking for same here as well.  so far its amazing...
        updatedAt: '2023-09-28T15:19:15.322Z'
      numEdits: 0
      reactions: []
    id: 651599736f8a6fa0d97cb950
    type: comment
  author: silvacarl
  content: looking for same here as well.  so far its amazing...
  created_at: 2023-09-28 14:19:15+00:00
  edited: false
  hidden: false
  id: 651599736f8a6fa0d97cb950
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6d7bad95a60c27e5962187cbf6fa5fe6.svg
      fullname: Nathan Dahlberg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nadahlberg
      type: user
    createdAt: '2023-09-28T18:25:06.000Z'
    data:
      edited: false
      editors:
      - nadahlberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4533718228340149
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6d7bad95a60c27e5962187cbf6fa5fe6.svg
          fullname: Nathan Dahlberg
          isHf: false
          isPro: false
          name: nadahlberg
          type: user
        html: "<p>Seems to be mostly working with the default <a rel=\"nofollow\"\
          \ href=\"https://github.com/artidoro/qlora/blob/main/qlora.py\">qlora.py\
          \ script</a> with one small change.  </p>\n<p>This line was causing trouble\
          \ because mistral's model.config.pad_token_id returns None:</p>\n<pre><code>\"\
          unk_token\": tokenizer.convert_ids_to_tokens(\n     model.config.pad_token_id\
          \ if model.config.pad_token_id != -1 else tokenizer.pad_token_id\n),\n</code></pre>\n\
          <p>Adding a None check seems to fix:</p>\n<pre><code>\"unk_token\": tokenizer.convert_ids_to_tokens(\n\
          \    model.config.pad_token_id if \n    model.config.pad_token_id is not\
          \ None and model.config.pad_token_id != -1 \n    else tokenizer.pad_token_id\n\
          ),\n</code></pre>\n"
        raw: "Seems to be mostly working with the default [qlora.py script](https://github.com/artidoro/qlora/blob/main/qlora.py)\
          \ with one small change.  \n\nThis line was causing trouble because mistral's\
          \ model.config.pad_token_id returns None:\n```\n\"unk_token\": tokenizer.convert_ids_to_tokens(\n\
          \     model.config.pad_token_id if model.config.pad_token_id != -1 else\
          \ tokenizer.pad_token_id\n),\n```\n\nAdding a None check seems to fix:\n\
          ```\n\"unk_token\": tokenizer.convert_ids_to_tokens(\n    model.config.pad_token_id\
          \ if \n    model.config.pad_token_id is not None and model.config.pad_token_id\
          \ != -1 \n    else tokenizer.pad_token_id\n),\n```"
        updatedAt: '2023-09-28T18:25:06.126Z'
      numEdits: 0
      reactions: []
    id: 6515c502284e2201d78a6c3d
    type: comment
  author: nadahlberg
  content: "Seems to be mostly working with the default [qlora.py script](https://github.com/artidoro/qlora/blob/main/qlora.py)\
    \ with one small change.  \n\nThis line was causing trouble because mistral's\
    \ model.config.pad_token_id returns None:\n```\n\"unk_token\": tokenizer.convert_ids_to_tokens(\n\
    \     model.config.pad_token_id if model.config.pad_token_id != -1 else tokenizer.pad_token_id\n\
    ),\n```\n\nAdding a None check seems to fix:\n```\n\"unk_token\": tokenizer.convert_ids_to_tokens(\n\
    \    model.config.pad_token_id if \n    model.config.pad_token_id is not None\
    \ and model.config.pad_token_id != -1 \n    else tokenizer.pad_token_id\n),\n\
    ```"
  created_at: 2023-09-28 17:25:06+00:00
  edited: false
  hidden: false
  id: 6515c502284e2201d78a6c3d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660775548920-628d998a2b60ec0f336cc1eb.png?w=200&h=200&f=face
      fullname: Carl Silva
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: silvacarl
      type: user
    createdAt: '2023-09-28T20:14:29.000Z'
    data:
      edited: true
      editors:
      - silvacarl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9768639802932739
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660775548920-628d998a2b60ec0f336cc1eb.png?w=200&h=200&f=face
          fullname: Carl Silva
          isHf: false
          isPro: true
          name: silvacarl
          type: user
        html: '<p>thx.  i am not even sure yet if it needs fine tuning, we are running
          a bunch of tests on it.</p>

          <p>it seems to be the best 7B model we have ever seen.  it may outperform
          13B and possibly 70B models for certain use cases.</p>

          '
        raw: 'thx.  i am not even sure yet if it needs fine tuning, we are running
          a bunch of tests on it.


          it seems to be the best 7B model we have ever seen.  it may outperform 13B
          and possibly 70B models for certain use cases.'
        updatedAt: '2023-09-28T20:14:58.099Z'
      numEdits: 1
      reactions: []
    id: 6515dea5bc06317198672764
    type: comment
  author: silvacarl
  content: 'thx.  i am not even sure yet if it needs fine tuning, we are running a
    bunch of tests on it.


    it seems to be the best 7B model we have ever seen.  it may outperform 13B and
    possibly 70B models for certain use cases.'
  created_at: 2023-09-28 19:14:29+00:00
  edited: true
  hidden: false
  id: 6515dea5bc06317198672764
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ab1fba948e86cce23e8ab573f12ff04.svg
      fullname: Nicky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NickyNicky
      type: user
    createdAt: '2023-09-29T03:43:21.000Z'
    data:
      edited: true
      editors:
      - NickyNicky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8231678605079651
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ab1fba948e86cce23e8ab573f12ff04.svg
          fullname: Nicky
          isHf: false
          isPro: false
          name: NickyNicky
          type: user
        html: '<p>it''s very fast.</p>

          <p>use:<br>-When flash attention 2 is used and with an inference of approximately
          600 tokens &lt;20 seconds if I remember correctly.<br>-Without flash attention
          2, inferences from 100 tokens take +440 seconds.</p>

          <p>fine-tune (SFTTrainer):<br>-gpu a100 colab 40GB<br>-for a 15k dataset
          it takes approximately 1H<br>-14 credits 1H<br>-per_device_train_batch_size=
          6 ----&gt;&gt;&gt; use gpu 36GB</p>

          '
        raw: 'it''s very fast.


          use:

          -When flash attention 2 is used and with an inference of approximately 600
          tokens <20 seconds if I remember correctly.

          -Without flash attention 2, inferences from 100 tokens take +440 seconds.


          fine-tune (SFTTrainer):

          -gpu a100 colab 40GB

          -for a 15k dataset it takes approximately 1H

          -14 credits 1H

          -per_device_train_batch_size= 6 ---->>> use gpu 36GB'
        updatedAt: '2023-09-29T03:45:48.926Z'
      numEdits: 2
      reactions: []
    id: 651647d9d93a51ceda2f02e7
    type: comment
  author: NickyNicky
  content: 'it''s very fast.


    use:

    -When flash attention 2 is used and with an inference of approximately 600 tokens
    <20 seconds if I remember correctly.

    -Without flash attention 2, inferences from 100 tokens take +440 seconds.


    fine-tune (SFTTrainer):

    -gpu a100 colab 40GB

    -for a 15k dataset it takes approximately 1H

    -14 credits 1H

    -per_device_train_batch_size= 6 ---->>> use gpu 36GB'
  created_at: 2023-09-29 02:43:21+00:00
  edited: true
  hidden: false
  id: 651647d9d93a51ceda2f02e7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638ee0b22cc490759feb38e9/_Z8o0r80_jN43GpRen5sp.jpeg?w=200&h=200&f=face
      fullname: LazerTC
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lazycuber
      type: user
    createdAt: '2023-09-29T06:43:50.000Z'
    data:
      edited: false
      editors:
      - Lazycuber
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9248453378677368
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638ee0b22cc490759feb38e9/_Z8o0r80_jN43GpRen5sp.jpeg?w=200&h=200&f=face
          fullname: LazerTC
          isHf: false
          isPro: false
          name: Lazycuber
          type: user
        html: '<p>Anyone made a colab notebook for finetuning?</p>

          '
        raw: Anyone made a colab notebook for finetuning?
        updatedAt: '2023-09-29T06:43:50.196Z'
      numEdits: 0
      reactions:
      - count: 13
        reaction: "\U0001F44D"
        users:
        - mnwato
        - dgkatz123
        - nicolasdec
        - smutchler
        - marekk
        - grasool
        - NickyNicky
        - cerebrock
        - ysdj
        - iftach-avital
        - JoshuaCAlpuerto
        - empaner
        - chanderbalaji
    id: 65167226c33a8b1919701c2f
    type: comment
  author: Lazycuber
  content: Anyone made a colab notebook for finetuning?
  created_at: 2023-09-29 05:43:50+00:00
  edited: false
  hidden: false
  id: 65167226c33a8b1919701c2f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/726f837319ddd18534104e2f3ed0e4cb.svg
      fullname: Steven Jin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sscpr
      type: user
    createdAt: '2023-10-01T00:18:47.000Z'
    data:
      edited: false
      editors:
      - sscpr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.925211489200592
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/726f837319ddd18534104e2f3ed0e4cb.svg
          fullname: Steven Jin
          isHf: false
          isPro: false
          name: sscpr
          type: user
        html: '<blockquote>

          <p>Seems to be mostly working with the default <a rel="nofollow" href="https://github.com/artidoro/qlora/blob/main/qlora.py">qlora.py
          script</a> with one small change.  </p>

          </blockquote>

          <p>using this script and your change seems to work but I had to repull in
          the latest transformers version 4.34 to get it to work</p>

          '
        raw: "> Seems to be mostly working with the default [qlora.py script](https://github.com/artidoro/qlora/blob/main/qlora.py)\
          \ with one small change.  \n\n\nusing this script and your change seems\
          \ to work but I had to repull in the latest transformers version 4.34 to\
          \ get it to work\n"
        updatedAt: '2023-10-01T00:18:47.627Z'
      numEdits: 0
      reactions: []
    id: 6518bae729af405887c70405
    type: comment
  author: sscpr
  content: "> Seems to be mostly working with the default [qlora.py script](https://github.com/artidoro/qlora/blob/main/qlora.py)\
    \ with one small change.  \n\n\nusing this script and your change seems to work\
    \ but I had to repull in the latest transformers version 4.34 to get it to work\n"
  created_at: 2023-09-30 23:18:47+00:00
  edited: false
  hidden: false
  id: 6518bae729af405887c70405
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/452074cb947ed07f173263edf6beefac.svg
      fullname: m
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NickM2002
      type: user
    createdAt: '2023-10-02T12:37:59.000Z'
    data:
      edited: false
      editors:
      - NickM2002
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9403306841850281
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/452074cb947ed07f173263edf6beefac.svg
          fullname: m
          isHf: false
          isPro: false
          name: NickM2002
          type: user
        html: "<blockquote>\n<blockquote>\n<p>Seems to be mostly working with the\
          \ default <a rel=\"nofollow\" href=\"https://github.com/artidoro/qlora/blob/main/qlora.py\"\
          >qlora.py script</a> with one small change.  </p>\n</blockquote>\n<p>using\
          \ this script and your change seems to work but I had to repull in the latest\
          \ transformers version 4.34 to get it to work</p>\n</blockquote>\n<p>I also\
          \ had to repull transformers with<br>\u201C<br>pip install git+<a rel=\"\
          nofollow\" href=\"https://github.com/huggingface/transformers\">https://github.com/huggingface/transformers</a><br>\u201C\
          </p>\n"
        raw: "> > Seems to be mostly working with the default [qlora.py script](https://github.com/artidoro/qlora/blob/main/qlora.py)\
          \ with one small change.  \n> \n> \n> using this script and your change\
          \ seems to work but I had to repull in the latest transformers version 4.34\
          \ to get it to work\n\nI also had to repull transformers with\n\u201C\n\
          pip install git+https://github.com/huggingface/transformers\n\u201C"
        updatedAt: '2023-10-02T12:37:59.529Z'
      numEdits: 0
      reactions: []
    id: 651ab9a79e0bf1e7f8303020
    type: comment
  author: NickM2002
  content: "> > Seems to be mostly working with the default [qlora.py script](https://github.com/artidoro/qlora/blob/main/qlora.py)\
    \ with one small change.  \n> \n> \n> using this script and your change seems\
    \ to work but I had to repull in the latest transformers version 4.34 to get it\
    \ to work\n\nI also had to repull transformers with\n\u201C\npip install git+https://github.com/huggingface/transformers\n\
    \u201C"
  created_at: 2023-10-02 11:37:59+00:00
  edited: false
  hidden: false
  id: 651ab9a79e0bf1e7f8303020
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9aecf03f75e9a4bde777ea965a660a5e.svg
      fullname: Rafa Raul
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ysdj
      type: user
    createdAt: '2023-10-03T18:05:45.000Z'
    data:
      edited: false
      editors:
      - ysdj
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6624422669410706
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9aecf03f75e9a4bde777ea965a660a5e.svg
          fullname: Rafa Raul
          isHf: false
          isPro: false
          name: ysdj
          type: user
        html: '<blockquote>

          <p>Anyone made a colab notebook for finetuning?</p>

          </blockquote>

          <p><a rel="nofollow" href="https://github.com/Vasanthengineer4949/NLP-Projects-NHV/blob/main/LLMs%20Related/Finetune%20Mistral/Finetune_Mistral.ipynb">https://github.com/Vasanthengineer4949/NLP-Projects-NHV/blob/main/LLMs%20Related/Finetune%20Mistral/Finetune_Mistral.ipynb</a></p>

          '
        raw: '> Anyone made a colab notebook for finetuning?


          https://github.com/Vasanthengineer4949/NLP-Projects-NHV/blob/main/LLMs%20Related/Finetune%20Mistral/Finetune_Mistral.ipynb'
        updatedAt: '2023-10-03T18:05:45.198Z'
      numEdits: 0
      reactions: []
    id: 651c57f9c51efebee16e70fa
    type: comment
  author: ysdj
  content: '> Anyone made a colab notebook for finetuning?


    https://github.com/Vasanthengineer4949/NLP-Projects-NHV/blob/main/LLMs%20Related/Finetune%20Mistral/Finetune_Mistral.ipynb'
  created_at: 2023-10-03 17:05:45+00:00
  edited: false
  hidden: false
  id: 651c57f9c51efebee16e70fa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0f7f6a327106967df207bf6fb9d379a.svg
      fullname: TG
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: QendelG
      type: user
    createdAt: '2023-10-05T05:20:19.000Z'
    data:
      edited: true
      editors:
      - QendelG
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2675173878669739
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0f7f6a327106967df207bf6fb9d379a.svg
          fullname: TG
          isHf: false
          isPro: false
          name: QendelG
          type: user
        html: '<p>Step-by-step guide to finetune on QA Dataset: <a rel="nofollow"
          href="https://medium.com/@qendelai/fine-tuning-mistral-7b-instruct-model-in-colab-a-beginners-guide-0f7bebccf11c">https://medium.com/me/stats/post/0f7bebccf11c</a></p>

          '
        raw: 'Step-by-step guide to finetune on QA Dataset: [https://medium.com/me/stats/post/0f7bebccf11c](https://medium.com/@qendelai/fine-tuning-mistral-7b-instruct-model-in-colab-a-beginners-guide-0f7bebccf11c)'
        updatedAt: '2023-10-05T12:53:29.986Z'
      numEdits: 4
      reactions: []
    id: 651e4793946621ac64978fc9
    type: comment
  author: QendelG
  content: 'Step-by-step guide to finetune on QA Dataset: [https://medium.com/me/stats/post/0f7bebccf11c](https://medium.com/@qendelai/fine-tuning-mistral-7b-instruct-model-in-colab-a-beginners-guide-0f7bebccf11c)'
  created_at: 2023-10-05 04:20:19+00:00
  edited: true
  hidden: false
  id: 651e4793946621ac64978fc9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ab1fba948e86cce23e8ab573f12ff04.svg
      fullname: Nicky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NickyNicky
      type: user
    createdAt: '2023-10-05T06:08:11.000Z'
    data:
      edited: false
      editors:
      - NickyNicky
      hidden: false
      identifiedLanguage:
        language: et
        probability: 0.06273137778043747
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ab1fba948e86cce23e8ab573f12ff04.svg
          fullname: Nicky
          isHf: false
          isPro: false
          name: NickyNicky
          type: user
        html: '<p>haha error 404</p>

          '
        raw: haha error 404
        updatedAt: '2023-10-05T06:08:11.735Z'
      numEdits: 0
      reactions: []
    id: 651e52cb815d3d1b617c9f1e
    type: comment
  author: NickyNicky
  content: haha error 404
  created_at: 2023-10-05 05:08:11+00:00
  edited: false
  hidden: false
  id: 651e52cb815d3d1b617c9f1e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0f7f6a327106967df207bf6fb9d379a.svg
      fullname: TG
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: QendelG
      type: user
    createdAt: '2023-10-05T12:54:18.000Z'
    data:
      edited: false
      editors:
      - QendelG
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.39166495203971863
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0f7f6a327106967df207bf6fb9d379a.svg
          fullname: TG
          isHf: false
          isPro: false
          name: QendelG
          type: user
        html: "<p>it is updated <span data-props=\"{&quot;user&quot;:&quot;NickyNicky&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/NickyNicky\"\
          >@<span class=\"underline\">NickyNicky</span></a></span>\n\n\t</span></span>\
          \ </p>\n<p>Here: <a rel=\"nofollow\" href=\"https://medium.com/@qendelai/fine-tuning-mistral-7b-instruct-model-in-colab-a-beginners-guide-0f7bebccf11c\"\
          >https://medium.com/@qendelai/fine-tuning-mistral-7b-instruct-model-in-colab-a-beginners-guide-0f7bebccf11c</a></p>\n"
        raw: "it is updated @NickyNicky \n\nHere: https://medium.com/@qendelai/fine-tuning-mistral-7b-instruct-model-in-colab-a-beginners-guide-0f7bebccf11c"
        updatedAt: '2023-10-05T12:54:18.428Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - NickyNicky
    id: 651eb1fadc02de2e0e374fd0
    type: comment
  author: QendelG
  content: "it is updated @NickyNicky \n\nHere: https://medium.com/@qendelai/fine-tuning-mistral-7b-instruct-model-in-colab-a-beginners-guide-0f7bebccf11c"
  created_at: 2023-10-05 11:54:18+00:00
  edited: false
  hidden: false
  id: 651eb1fadc02de2e0e374fd0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: mistralai/Mistral-7B-Instruct-v0.1
repo_type: model
status: open
target_branch: null
title: How to fine tune ?
