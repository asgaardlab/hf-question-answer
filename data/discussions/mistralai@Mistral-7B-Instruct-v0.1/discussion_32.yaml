!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TikaToka
conflicting_files: null
created_at: 2023-10-02 14:49:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d718103a43d660912afd6d7756fc3ad6.svg
      fullname: Joochan Kim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TikaToka
      type: user
    createdAt: '2023-10-02T15:49:37.000Z'
    data:
      edited: false
      editors:
      - TikaToka
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9488244652748108
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d718103a43d660912afd6d7756fc3ad6.svg
          fullname: Joochan Kim
          isHf: false
          isPro: false
          name: TikaToka
          type: user
        html: '<p>Hello mistralai team, Thank you for sharing amazing work!<br>I am
          hoping to use the model for my research, and I have some question.</p>

          <p>For llama-2 like models often able to inject custom system prompt, but
          it looks like there are no information about it.<br>Is there a way to give
          custom system prompt to mistral?</p>

          '
        raw: "Hello mistralai team, Thank you for sharing amazing work!\r\nI am hoping\
          \ to use the model for my research, and I have some question.\r\n\r\nFor\
          \ llama-2 like models often able to inject custom system prompt, but it\
          \ looks like there are no information about it.\r\nIs there a way to give\
          \ custom system prompt to mistral?"
        updatedAt: '2023-10-02T15:49:37.498Z'
      numEdits: 0
      reactions: []
    id: 651ae69177d6b4b1ea4db015
    type: comment
  author: TikaToka
  content: "Hello mistralai team, Thank you for sharing amazing work!\r\nI am hoping\
    \ to use the model for my research, and I have some question.\r\n\r\nFor llama-2\
    \ like models often able to inject custom system prompt, but it looks like there\
    \ are no information about it.\r\nIs there a way to give custom system prompt\
    \ to mistral?"
  created_at: 2023-10-02 14:49:37+00:00
  edited: false
  hidden: false
  id: 651ae69177d6b4b1ea4db015
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/42bd81f3ca47f23a9a2d147043cbc5ed.svg
      fullname: katyarmal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sakshat98
      type: user
    createdAt: '2023-10-05T15:58:20.000Z'
    data:
      edited: false
      editors:
      - sakshat98
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.923151969909668
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/42bd81f3ca47f23a9a2d147043cbc5ed.svg
          fullname: katyarmal
          isHf: false
          isPro: false
          name: sakshat98
          type: user
        html: '<p>I am looking for the same. Please update once you find something.</p>

          '
        raw: I am looking for the same. Please update once you find something.
        updatedAt: '2023-10-05T15:58:20.104Z'
      numEdits: 0
      reactions: []
    id: 651edd1c5ff73c3cec46268e
    type: comment
  author: sakshat98
  content: I am looking for the same. Please update once you find something.
  created_at: 2023-10-05 14:58:20+00:00
  edited: false
  hidden: false
  id: 651edd1c5ff73c3cec46268e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c71878c87bce36d3193ea9e13ad23722.svg
      fullname: Venkata Bhanu Teja Pallakonda
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pvbhanuteja
      type: user
    createdAt: '2023-10-12T19:40:35.000Z'
    data:
      edited: false
      editors:
      - pvbhanuteja
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5813604593276978
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c71878c87bce36d3193ea9e13ad23722.svg
          fullname: Venkata Bhanu Teja Pallakonda
          isHf: false
          isPro: false
          name: pvbhanuteja
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sakshat98&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/sakshat98\">@<span class=\"\
          underline\">sakshat98</span></a></span>\n\n\t</span></span>  <span data-props=\"\
          {&quot;user&quot;:&quot;TikaToka&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/TikaToka\">@<span class=\"underline\">TikaToka</span></a></span>\n\
          \n\t</span></span> </p>\n<p>Use this</p>\n<p><s>[INST] System Prompt + Instruction\
          \ [/INST] Model answer</s>[INST] Follow-up instruction [/INST]</p>\n<p>From\
          \ their official site. </p>\n<p><a rel=\"nofollow\" href=\"https://docs.mistral.ai/usage/guardrailing\"\
          >https://docs.mistral.ai/usage/guardrailing</a></p>\n<p>If you want it for\
          \ gradio. I wrote a formatting function. Remove/add accordingly. </p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">def</span>\
          \ <span class=\"hljs-title function_\">format_chat_prompt_mistral</span>(<span\
          \ class=\"hljs-params\">message: <span class=\"hljs-built_in\">str</span>,\
          \ chat_history, instructions: <span class=\"hljs-built_in\">str</span></span>)\
          \ -&gt; <span class=\"hljs-built_in\">str</span>:\n    <span class=\"hljs-keyword\"\
          >if</span> <span class=\"hljs-built_in\">len</span>(chat_history) == <span\
          \ class=\"hljs-number\">0</span>:\n        <span class=\"hljs-comment\"\
          ># If chat_history is empty, return instructions and message</span>\n  \
          \      prompt = <span class=\"hljs-string\">f\"&lt;s&gt;[INST] <span class=\"\
          hljs-subst\">{instructions}</span> Hi [/INST] Hello! how can I help you&lt;/s&gt;[INST]\
          \ <span class=\"hljs-subst\">{message}</span> [/INST]\"</span>\n       \
          \ <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\"\
          >\"sending this prompt\\n==============\\n\"</span>,prompt,<span class=\"\
          hljs-string\">'\\n---------\\n'</span>)\n        <span class=\"hljs-keyword\"\
          >return</span> prompt\n    <span class=\"hljs-keyword\">else</span>:\n \
          \       <span class=\"hljs-comment\"># Initialize chat history text with\
          \ the first user message and instructions</span>\n        user_message,\
          \ bot_message = chat_history[<span class=\"hljs-number\">0</span>]\n   \
          \     chat_history_text = <span class=\"hljs-string\">f\"&lt;s&gt;[INST]\
          \ <span class=\"hljs-subst\">{instructions}</span> <span class=\"hljs-subst\"\
          >{user_message}</span> [/INST] <span class=\"hljs-subst\">{bot_message}</span>&lt;/s&gt;\"\
          </span>\n\n        <span class=\"hljs-comment\"># Use a list comprehension\
          \ to build the rest of the chat history text</span>\n        chat_history_text\
          \ += <span class=\"hljs-string\">\"\"</span>.join(<span class=\"hljs-string\"\
          >f\"[INST] <span class=\"hljs-subst\">{user_message}</span> [/INST] <span\
          \ class=\"hljs-subst\">{bot_message}</span>&lt;/s&gt;\"</span> <span class=\"\
          hljs-keyword\">for</span> user_message, bot_message <span class=\"hljs-keyword\"\
          >in</span> chat_history[<span class=\"hljs-number\">1</span>:])\n</code></pre>\n"
        raw: "@sakshat98  @TikaToka \n\nUse this\n\n<s>[INST] System Prompt + Instruction\
          \ [/INST] Model answer</s>[INST] Follow-up instruction [/INST]\n\nFrom their\
          \ official site. \n\nhttps://docs.mistral.ai/usage/guardrailing\n\nIf you\
          \ want it for gradio. I wrote a formatting function. Remove/add accordingly.\
          \ \n\n```python\ndef format_chat_prompt_mistral(message: str, chat_history,\
          \ instructions: str) -> str:\n    if len(chat_history) == 0:\n        #\
          \ If chat_history is empty, return instructions and message\n        prompt\
          \ = f\"<s>[INST] {instructions} Hi [/INST] Hello! how can I help you</s>[INST]\
          \ {message} [/INST]\"\n        print(\"sending this prompt\\n==============\\\
          n\",prompt,'\\n---------\\n')\n        return prompt\n    else:\n      \
          \  # Initialize chat history text with the first user message and instructions\n\
          \        user_message, bot_message = chat_history[0]\n        chat_history_text\
          \ = f\"<s>[INST] {instructions} {user_message} [/INST] {bot_message}</s>\"\
          \n\n        # Use a list comprehension to build the rest of the chat history\
          \ text\n        chat_history_text += \"\".join(f\"[INST] {user_message}\
          \ [/INST] {bot_message}</s>\" for user_message, bot_message in chat_history[1:])\n"
        updatedAt: '2023-10-12T19:40:35.264Z'
      numEdits: 0
      reactions: []
    id: 65284bb322296ad01282c0c7
    type: comment
  author: pvbhanuteja
  content: "@sakshat98  @TikaToka \n\nUse this\n\n<s>[INST] System Prompt + Instruction\
    \ [/INST] Model answer</s>[INST] Follow-up instruction [/INST]\n\nFrom their official\
    \ site. \n\nhttps://docs.mistral.ai/usage/guardrailing\n\nIf you want it for gradio.\
    \ I wrote a formatting function. Remove/add accordingly. \n\n```python\ndef format_chat_prompt_mistral(message:\
    \ str, chat_history, instructions: str) -> str:\n    if len(chat_history) == 0:\n\
    \        # If chat_history is empty, return instructions and message\n       \
    \ prompt = f\"<s>[INST] {instructions} Hi [/INST] Hello! how can I help you</s>[INST]\
    \ {message} [/INST]\"\n        print(\"sending this prompt\\n==============\\\
    n\",prompt,'\\n---------\\n')\n        return prompt\n    else:\n        # Initialize\
    \ chat history text with the first user message and instructions\n        user_message,\
    \ bot_message = chat_history[0]\n        chat_history_text = f\"<s>[INST] {instructions}\
    \ {user_message} [/INST] {bot_message}</s>\"\n\n        # Use a list comprehension\
    \ to build the rest of the chat history text\n        chat_history_text += \"\"\
    .join(f\"[INST] {user_message} [/INST] {bot_message}</s>\" for user_message, bot_message\
    \ in chat_history[1:])\n"
  created_at: 2023-10-12 18:40:35+00:00
  edited: false
  hidden: false
  id: 65284bb322296ad01282c0c7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660312628256-60ba519750effef3a58beac3.png?w=200&h=200&f=face
      fullname: Matthew Carrigan
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Rocketknight1
      type: user
    createdAt: '2023-10-16T18:24:01.000Z'
    data:
      edited: false
      editors:
      - Rocketknight1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.38524115085601807
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660312628256-60ba519750effef3a58beac3.png?w=200&h=200&f=face
          fullname: Matthew Carrigan
          isHf: true
          isPro: false
          name: Rocketknight1
          type: user
        html: "<p>Hi all, the <code>tokenizer.apply_chat_template()</code> method\
          \ can handle this for you:</p>\n<pre><code class=\"language-python\">messages\
          \ = [\n    {<span class=\"hljs-string\">\"role\"</span>: <span class=\"\
          hljs-string\">\"system\"</span>, <span class=\"hljs-string\">\"content\"\
          </span>: <span class=\"hljs-string\">\"System message here\"</span>},\n\
          \    {<span class=\"hljs-string\">\"role\"</span>: <span class=\"hljs-string\"\
          >\"user\"</span>, <span class=\"hljs-string\">\"content:\"</span> <span\
          \ class=\"hljs-string\">\"User message here\"</span>}\n]\nprompt = tokenizer.apply_chat_template(messages)\n\
          </code></pre>\n<p>You can see the <a href=\"https://huggingface.co/docs/transformers/main/chat_templating\"\
          >documentation on chat templates</a> for more information.</p>\n"
        raw: "Hi all, the `tokenizer.apply_chat_template()` method can handle this\
          \ for you:\n\n```python\nmessages = [\n    {\"role\": \"system\", \"content\"\
          : \"System message here\"},\n    {\"role\": \"user\", \"content:\" \"User\
          \ message here\"}\n]\nprompt = tokenizer.apply_chat_template(messages)\n\
          ```\n\nYou can see the [documentation on chat templates](https://huggingface.co/docs/transformers/main/chat_templating)\
          \ for more information."
        updatedAt: '2023-10-16T18:24:01.830Z'
      numEdits: 0
      reactions: []
    id: 652d7fc1265c78f1f8a428d2
    type: comment
  author: Rocketknight1
  content: "Hi all, the `tokenizer.apply_chat_template()` method can handle this for\
    \ you:\n\n```python\nmessages = [\n    {\"role\": \"system\", \"content\": \"\
    System message here\"},\n    {\"role\": \"user\", \"content:\" \"User message\
    \ here\"}\n]\nprompt = tokenizer.apply_chat_template(messages)\n```\n\nYou can\
    \ see the [documentation on chat templates](https://huggingface.co/docs/transformers/main/chat_templating)\
    \ for more information."
  created_at: 2023-10-16 17:24:01+00:00
  edited: false
  hidden: false
  id: 652d7fc1265c78f1f8a428d2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d718103a43d660912afd6d7756fc3ad6.svg
      fullname: Joochan Kim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TikaToka
      type: user
    createdAt: '2023-10-17T13:56:15.000Z'
    data:
      edited: true
      editors:
      - TikaToka
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.86594158411026
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d718103a43d660912afd6d7756fc3ad6.svg
          fullname: Joochan Kim
          isHf: false
          isPro: false
          name: TikaToka
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Rocketknight1&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Rocketknight1\"\
          >@<span class=\"underline\">Rocketknight1</span></a></span>\n\n\t</span></span>\
          \ <span data-props=\"{&quot;user&quot;:&quot;pvbhanuteja&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/pvbhanuteja\">@<span\
          \ class=\"underline\">pvbhanuteja</span></a></span>\n\n\t</span></span>\
          \  Thank you for sharing the answer!<br>But I also want to ask how for huggingface\
          \ inference api?</p>\n"
        raw: '@Rocketknight1 @pvbhanuteja  Thank you for sharing the answer!

          But I also want to ask how for huggingface inference api?'
        updatedAt: '2023-10-17T13:56:38.935Z'
      numEdits: 1
      reactions: []
    id: 652e927f0af36fdc87262c21
    type: comment
  author: TikaToka
  content: '@Rocketknight1 @pvbhanuteja  Thank you for sharing the answer!

    But I also want to ask how for huggingface inference api?'
  created_at: 2023-10-17 12:56:15+00:00
  edited: true
  hidden: false
  id: 652e927f0af36fdc87262c21
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c71878c87bce36d3193ea9e13ad23722.svg
      fullname: Venkata Bhanu Teja Pallakonda
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pvbhanuteja
      type: user
    createdAt: '2023-10-18T16:28:04.000Z'
    data:
      edited: false
      editors:
      - pvbhanuteja
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5258995890617371
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c71878c87bce36d3193ea9e13ad23722.svg
          fullname: Venkata Bhanu Teja Pallakonda
          isHf: false
          isPro: false
          name: pvbhanuteja
          type: user
        html: "<blockquote>\n<p>Hi all, the <code>tokenizer.apply_chat_template()</code>\
          \ method can handle this for you:</p>\n<pre><code class=\"language-python\"\
          >messages = [\n    {<span class=\"hljs-string\">\"role\"</span>: <span class=\"\
          hljs-string\">\"system\"</span>, <span class=\"hljs-string\">\"content\"\
          </span>: <span class=\"hljs-string\">\"System message here\"</span>},\n\
          \    {<span class=\"hljs-string\">\"role\"</span>: <span class=\"hljs-string\"\
          >\"user\"</span>, <span class=\"hljs-string\">\"content:\"</span> <span\
          \ class=\"hljs-string\">\"User message here\"</span>}\n]\nprompt = tokenizer.apply_chat_template(messages)\n\
          </code></pre>\n<p>You can see the <a href=\"https://huggingface.co/docs/transformers/main/chat_templating\"\
          >documentation on chat templates</a> for more information.</p>\n</blockquote>\n\
          <p>This is incorrect.  tokenizer.apply_chat_template will look chat_template\
          \ key value from here at <a href=\"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/blob/main/tokenizer_config.json\"\
          >https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/blob/main/tokenizer_config.json</a>\
          \ </p>\n<p>The format at chat_template doesn't incline with the actual mistral\
          \ website. <a rel=\"nofollow\" href=\"https://docs.mistral.ai/usage/guardrailing\"\
          >https://docs.mistral.ai/usage/guardrailing</a> I will try to open a PR\
          \ and make changes to the chat template accordingly. </p>\n"
        raw: "> Hi all, the `tokenizer.apply_chat_template()` method can handle this\
          \ for you:\n> \n> ```python\n> messages = [\n>     {\"role\": \"system\"\
          , \"content\": \"System message here\"},\n>     {\"role\": \"user\", \"\
          content:\" \"User message here\"}\n> ]\n> prompt = tokenizer.apply_chat_template(messages)\n\
          > ```\n> \n> You can see the [documentation on chat templates](https://huggingface.co/docs/transformers/main/chat_templating)\
          \ for more information.\n\nThis is incorrect.  tokenizer.apply_chat_template\
          \ will look chat_template key value from here at https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/blob/main/tokenizer_config.json\
          \ \n\nThe format at chat_template doesn't incline with the actual mistral\
          \ website. https://docs.mistral.ai/usage/guardrailing I will try to open\
          \ a PR and make changes to the chat template accordingly. "
        updatedAt: '2023-10-18T16:28:04.058Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - eliseobao
    id: 6530079418a2161da7365143
    type: comment
  author: pvbhanuteja
  content: "> Hi all, the `tokenizer.apply_chat_template()` method can handle this\
    \ for you:\n> \n> ```python\n> messages = [\n>     {\"role\": \"system\", \"content\"\
    : \"System message here\"},\n>     {\"role\": \"user\", \"content:\" \"User message\
    \ here\"}\n> ]\n> prompt = tokenizer.apply_chat_template(messages)\n> ```\n> \n\
    > You can see the [documentation on chat templates](https://huggingface.co/docs/transformers/main/chat_templating)\
    \ for more information.\n\nThis is incorrect.  tokenizer.apply_chat_template will\
    \ look chat_template key value from here at https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/blob/main/tokenizer_config.json\
    \ \n\nThe format at chat_template doesn't incline with the actual mistral website.\
    \ https://docs.mistral.ai/usage/guardrailing I will try to open a PR and make\
    \ changes to the chat template accordingly. "
  created_at: 2023-10-18 15:28:04+00:00
  edited: false
  hidden: false
  id: 6530079418a2161da7365143
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 32
repo_id: mistralai/Mistral-7B-Instruct-v0.1
repo_type: model
status: open
target_branch: null
title: Possibilities injecting custom system into mistral?
