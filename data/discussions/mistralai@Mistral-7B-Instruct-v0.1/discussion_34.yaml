!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Tapendra
conflicting_files: null
created_at: 2023-10-02 17:03:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8b5a0e04fde4337091d47c1636d94486.svg
      fullname: Tapendra Baduwal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tapendra
      type: user
    createdAt: '2023-10-02T18:03:05.000Z'
    data:
      edited: false
      editors:
      - Tapendra
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3205702006816864
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8b5a0e04fde4337091d47c1636d94486.svg
          fullname: Tapendra Baduwal
          isHf: false
          isPro: false
          name: Tapendra
          type: user
        html: '<p>While training with SFTTrainer<br>trainer = SFTTrainer(<br>    model=model,<br>    train_dataset=dataset,<br>    peft_config=peft_config,<br>    dataset_text_field="text",<br>    max_seq_length=max_seq_length,<br>    tokenizer=tokenizer,<br>    args=training_arguments,<br>    packing=packing,<br>)</p>

          <h1 id="train-model">Train model</h1>

          <p>trainer.train()</p>

          '
        raw: "While training with SFTTrainer\r\ntrainer = SFTTrainer(\r\n    model=model,\r\
          \n    train_dataset=dataset,\r\n    peft_config=peft_config,\r\n    dataset_text_field=\"\
          text\",\r\n    max_seq_length=max_seq_length,\r\n    tokenizer=tokenizer,\r\
          \n    args=training_arguments,\r\n    packing=packing,\r\n)\r\n\r\n# Train\
          \ model\r\ntrainer.train()"
        updatedAt: '2023-10-02T18:03:05.586Z'
      numEdits: 0
      reactions: []
    id: 651b05d9b60bfe79714d224e
    type: comment
  author: Tapendra
  content: "While training with SFTTrainer\r\ntrainer = SFTTrainer(\r\n    model=model,\r\
    \n    train_dataset=dataset,\r\n    peft_config=peft_config,\r\n    dataset_text_field=\"\
    text\",\r\n    max_seq_length=max_seq_length,\r\n    tokenizer=tokenizer,\r\n\
    \    args=training_arguments,\r\n    packing=packing,\r\n)\r\n\r\n# Train model\r\
    \ntrainer.train()"
  created_at: 2023-10-02 17:03:05+00:00
  edited: false
  hidden: false
  id: 651b05d9b60bfe79714d224e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638ae4bcf6a0bc48582c4239/LlixeQbFoK0p47FQpa7lz.png?w=200&h=200&f=face
      fullname: Harper Carroll
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: harpercarroll
      type: user
    createdAt: '2023-10-02T18:09:34.000Z'
    data:
      edited: false
      editors:
      - harpercarroll
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4199749231338501
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638ae4bcf6a0bc48582c4239/LlixeQbFoK0p47FQpa7lz.png?w=200&h=200&f=face
          fullname: Harper Carroll
          isHf: false
          isPro: false
          name: harpercarroll
          type: user
        html: '<p>see if this helps: <a href="https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions/23#6518110742097d8c5907f822">https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions/23#6518110742097d8c5907f822</a></p>

          '
        raw: 'see if this helps: https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions/23#6518110742097d8c5907f822'
        updatedAt: '2023-10-02T18:09:34.116Z'
      numEdits: 0
      reactions: []
    id: 651b075ea7b14e4c9d5a1687
    type: comment
  author: harpercarroll
  content: 'see if this helps: https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions/23#6518110742097d8c5907f822'
  created_at: 2023-10-02 17:09:34+00:00
  edited: false
  hidden: false
  id: 651b075ea7b14e4c9d5a1687
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8b5a0e04fde4337091d47c1636d94486.svg
      fullname: Tapendra Baduwal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tapendra
      type: user
    createdAt: '2023-10-02T19:24:04.000Z'
    data:
      edited: false
      editors:
      - Tapendra
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8377882242202759
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8b5a0e04fde4337091d47c1636d94486.svg
          fullname: Tapendra Baduwal
          isHf: false
          isPro: false
          name: Tapendra
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;harpercarroll&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/harpercarroll\"\
          >@<span class=\"underline\">harpercarroll</span></a></span>\n\n\t</span></span>\
          \ What is the minimum requirement of System RAM, GPU RAM to inference the\
          \ bitsandbytes nf4 ,use_4bit = True train model.  I train  model of bnb_4bit_quant_type\
          \ = \"nf4\" after training model size is same like 15GB. How we can reduce\
          \ model Size ?</p>\n"
        raw: '@harpercarroll What is the minimum requirement of System RAM, GPU RAM
          to inference the bitsandbytes nf4 ,use_4bit = True train model.  I train  model
          of bnb_4bit_quant_type = "nf4" after training model size is same like 15GB.
          How we can reduce model Size ?

          '
        updatedAt: '2023-10-02T19:24:04.807Z'
      numEdits: 0
      reactions: []
    id: 651b18d40010bbb6701c1942
    type: comment
  author: Tapendra
  content: '@harpercarroll What is the minimum requirement of System RAM, GPU RAM
    to inference the bitsandbytes nf4 ,use_4bit = True train model.  I train  model
    of bnb_4bit_quant_type = "nf4" after training model size is same like 15GB. How
    we can reduce model Size ?

    '
  created_at: 2023-10-02 18:24:04+00:00
  edited: false
  hidden: false
  id: 651b18d40010bbb6701c1942
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0f7f6a327106967df207bf6fb9d379a.svg
      fullname: TG
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: QendelG
      type: user
    createdAt: '2023-10-05T05:15:54.000Z'
    data:
      edited: true
      editors:
      - QendelG
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5383711457252502
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0f7f6a327106967df207bf6fb9d379a.svg
          fullname: TG
          isHf: false
          isPro: false
          name: QendelG
          type: user
        html: '<p>This will help: <a rel="nofollow" href="https://medium.com/@qendelai/fine-tuning-mistral-7b-instruct-model-in-colab-a-beginners-guide-0f7bebccf11c">https://medium.com/@qendelai/fine-tuning-mistral-7b-instruct-model-in-colab-a-beginners-guide-0f7bebccf11c</a></p>

          '
        raw: 'This will help: https://medium.com/@qendelai/fine-tuning-mistral-7b-instruct-model-in-colab-a-beginners-guide-0f7bebccf11c'
        updatedAt: '2023-10-05T05:24:11.771Z'
      numEdits: 1
      reactions: []
    id: 651e468ae3320c80818733e5
    type: comment
  author: QendelG
  content: 'This will help: https://medium.com/@qendelai/fine-tuning-mistral-7b-instruct-model-in-colab-a-beginners-guide-0f7bebccf11c'
  created_at: 2023-10-05 04:15:54+00:00
  edited: true
  hidden: false
  id: 651e468ae3320c80818733e5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 34
repo_id: mistralai/Mistral-7B-Instruct-v0.1
repo_type: model
status: open
target_branch: null
title: 'ValueError: Please specify `target_modules` in `peft_config`'
