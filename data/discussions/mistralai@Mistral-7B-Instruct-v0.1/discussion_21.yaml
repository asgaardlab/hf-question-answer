!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Tilakraj0308
conflicting_files: null
created_at: 2023-09-29 05:26:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/142a391d1518394c58270588d301fb71.svg
      fullname: Tilak raj choubey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tilakraj0308
      type: user
    createdAt: '2023-09-29T06:26:51.000Z'
    data:
      edited: false
      editors:
      - Tilakraj0308
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4866087734699249
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/142a391d1518394c58270588d301fb71.svg
          fullname: Tilak raj choubey
          isHf: false
          isPro: false
          name: Tilakraj0308
          type: user
        html: '<p>Got an error something like:<br>.cache\huggingface\hub\models--mistralai--Mistral-7B-Instruct-v0.1\snapshots\d635d39671aaceec5ef84b745bc21625b324b7f8\pytorch_model-00001-of-00002.bin''.
          If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set
          from_tf=True.</p>

          '
        raw: "Got an error something like:\r\n.cache\\huggingface\\hub\\models--mistralai--Mistral-7B-Instruct-v0.1\\\
          snapshots\\d635d39671aaceec5ef84b745bc21625b324b7f8\\pytorch_model-00001-of-00002.bin'.\
          \ If you tried to load a PyTorch model from a TF 2.0 checkpoint, please\
          \ set from_tf=True."
        updatedAt: '2023-09-29T06:26:51.492Z'
      numEdits: 0
      reactions: []
    id: 65166e2bca07b26143b0cf81
    type: comment
  author: Tilakraj0308
  content: "Got an error something like:\r\n.cache\\huggingface\\hub\\models--mistralai--Mistral-7B-Instruct-v0.1\\\
    snapshots\\d635d39671aaceec5ef84b745bc21625b324b7f8\\pytorch_model-00001-of-00002.bin'.\
    \ If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True."
  created_at: 2023-09-29 05:26:51+00:00
  edited: false
  hidden: false
  id: 65166e2bca07b26143b0cf81
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5b9e8ea5c67b9316b3fa03dc2ba07b89.svg
      fullname: Peppe Clavelli
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 19Peppe95
      type: user
    createdAt: '2023-10-03T15:53:54.000Z'
    data:
      edited: false
      editors:
      - 19Peppe95
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9827293753623962
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5b9e8ea5c67b9316b3fa03dc2ba07b89.svg
          fullname: Peppe Clavelli
          isHf: false
          isPro: false
          name: 19Peppe95
          type: user
        html: '<p>I have the same issue, any news?</p>

          '
        raw: 'I have the same issue, any news?

          '
        updatedAt: '2023-10-03T15:53:54.745Z'
      numEdits: 0
      reactions: []
    id: 651c39124921f5da9c3dea46
    type: comment
  author: 19Peppe95
  content: 'I have the same issue, any news?

    '
  created_at: 2023-10-03 14:53:54+00:00
  edited: false
  hidden: false
  id: 651c39124921f5da9c3dea46
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/142a391d1518394c58270588d301fb71.svg
      fullname: Tilak raj choubey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tilakraj0308
      type: user
    createdAt: '2023-10-03T16:31:28.000Z'
    data:
      edited: false
      editors:
      - Tilakraj0308
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9200571775436401
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/142a391d1518394c58270588d301fb71.svg
          fullname: Tilak raj choubey
          isHf: false
          isPro: false
          name: Tilakraj0308
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;19Peppe95&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/19Peppe95\">@<span class=\"\
          underline\">19Peppe95</span></a></span>\n\n\t</span></span> The error is\
          \ because system is running out of RAM to load the model in one go.<br>You\
          \ can use CTransformers to load the model or can try GGUF model versions\
          \ of your model which is basically much smaller version of it.<br>Gist -\
          \ Use GGUF version of this model <a href=\"https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF\"\
          >https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF</a><br>and\
          \ use CTransformers to load it from the dowloads and run the program, hopefully\
          \ it should work.</p>\n"
        raw: '@19Peppe95 The error is because system is running out of RAM to load
          the model in one go.

          You can use CTransformers to load the model or can try GGUF model versions
          of your model which is basically much smaller version of it.

          Gist - Use GGUF version of this model https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF

          and use CTransformers to load it from the dowloads and run the program,
          hopefully it should work.'
        updatedAt: '2023-10-03T16:31:28.710Z'
      numEdits: 0
      reactions: []
    id: 651c41e024223a547a96c898
    type: comment
  author: Tilakraj0308
  content: '@19Peppe95 The error is because system is running out of RAM to load the
    model in one go.

    You can use CTransformers to load the model or can try GGUF model versions of
    your model which is basically much smaller version of it.

    Gist - Use GGUF version of this model https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF

    and use CTransformers to load it from the dowloads and run the program, hopefully
    it should work.'
  created_at: 2023-10-03 15:31:28+00:00
  edited: false
  hidden: false
  id: 651c41e024223a547a96c898
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/631c7a0fe65cd7f686d52856/_A1RXNvyotvhd_3NsA7YB.jpeg?w=200&h=200&f=face
      fullname: Starlento
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Starlento
      type: user
    createdAt: '2023-10-13T13:18:48.000Z'
    data:
      edited: true
      editors:
      - Starlento
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.937776505947113
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/631c7a0fe65cd7f686d52856/_A1RXNvyotvhd_3NsA7YB.jpeg?w=200&h=200&f=face
          fullname: Starlento
          isHf: false
          isPro: false
          name: Starlento
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;19Peppe95&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/19Peppe95\"\
          >@<span class=\"underline\">19Peppe95</span></a></span>\n\n\t</span></span>\
          \ The error is because system is running out of RAM to load the model in\
          \ one go.<br>You can use CTransformers to load the model or can try GGUF\
          \ model versions of your model which is basically much smaller version of\
          \ it.<br>Gist - Use GGUF version of this model <a href=\"https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF\"\
          >https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF</a><br>and\
          \ use CTransformers to load it from the dowloads and run the program, hopefully\
          \ it should work.</p>\n</blockquote>\n<p><del>I also have the RAM issue.\
          \ But it is werid that the model is only 14GB in totally and I have 64GB\
          \ RAM and 24GB VRAM available.</del><br>Just found out that there was a\
          \ download issue, the bins are broken so the memory usage when loading the\
          \ files became uncontrollable.</p>\n"
        raw: '> @19Peppe95 The error is because system is running out of RAM to load
          the model in one go.

          > You can use CTransformers to load the model or can try GGUF model versions
          of your model which is basically much smaller version of it.

          > Gist - Use GGUF version of this model https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF

          > and use CTransformers to load it from the dowloads and run the program,
          hopefully it should work.


          ~I also have the RAM issue. But it is werid that the model is only 14GB
          in totally and I have 64GB RAM and 24GB VRAM available.~

          Just found out that there was a download issue, the bins are broken so the
          memory usage when loading the files became uncontrollable.

          '
        updatedAt: '2023-10-17T00:40:03.583Z'
      numEdits: 1
      reactions: []
    id: 652943b8b7997da858bfff98
    type: comment
  author: Starlento
  content: '> @19Peppe95 The error is because system is running out of RAM to load
    the model in one go.

    > You can use CTransformers to load the model or can try GGUF model versions of
    your model which is basically much smaller version of it.

    > Gist - Use GGUF version of this model https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF

    > and use CTransformers to load it from the dowloads and run the program, hopefully
    it should work.


    ~I also have the RAM issue. But it is werid that the model is only 14GB in totally
    and I have 64GB RAM and 24GB VRAM available.~

    Just found out that there was a download issue, the bins are broken so the memory
    usage when loading the files became uncontrollable.

    '
  created_at: 2023-10-13 12:18:48+00:00
  edited: true
  hidden: false
  id: 652943b8b7997da858bfff98
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/142a391d1518394c58270588d301fb71.svg
      fullname: Tilak raj choubey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tilakraj0308
      type: user
    createdAt: '2023-10-16T10:33:15.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/142a391d1518394c58270588d301fb71.svg
          fullname: Tilak raj choubey
          isHf: false
          isPro: false
          name: Tilakraj0308
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-10-16T10:35:22.861Z'
      numEdits: 1
      reactions: []
    id: 652d116b03fdab13ae759997
    type: comment
  author: Tilakraj0308
  content: This comment has been hidden
  created_at: 2023-10-16 09:33:15+00:00
  edited: true
  hidden: true
  id: 652d116b03fdab13ae759997
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/142a391d1518394c58270588d301fb71.svg
      fullname: Tilak raj choubey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tilakraj0308
      type: user
    createdAt: '2023-10-16T10:35:06.000Z'
    data:
      status: closed
    id: 652d11da9ac52bf7b9a4d94a
    type: status-change
  author: Tilakraj0308
  created_at: 2023-10-16 09:35:06+00:00
  id: 652d11da9ac52bf7b9a4d94a
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
      fullname: Lysandre
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lysandre
      type: user
    createdAt: '2023-10-16T18:11:46.000Z'
    data:
      edited: false
      editors:
      - lysandre
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7968193292617798
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
          fullname: Lysandre
          isHf: true
          isPro: false
          name: lysandre
          type: user
        html: "<p>cc <span data-props=\"{&quot;user&quot;:&quot;ybelkada&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ybelkada\"\
          >@<span class=\"underline\">ybelkada</span></a></span>\n\n\t</span></span>\
          \ regarding low-memory methods to load larger models</p>\n"
        raw: cc @ybelkada regarding low-memory methods to load larger models
        updatedAt: '2023-10-16T18:11:46.954Z'
      numEdits: 0
      reactions: []
    id: 652d7ce21d12768fffeb4d20
    type: comment
  author: lysandre
  content: cc @ybelkada regarding low-memory methods to load larger models
  created_at: 2023-10-16 17:11:46+00:00
  edited: false
  hidden: false
  id: 652d7ce21d12768fffeb4d20
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-10-16T19:28:20.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9217805862426758
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: '<p>Hi everyone<br>In case you are facing CPU OOM issues while loading
          the model please consider using sharded models with small shards, for this
          model I would recommend using this repository: <a href="https://huggingface.co/bn22/Mistral-7B-Instruct-v0.1-sharded">https://huggingface.co/bn22/Mistral-7B-Instruct-v0.1-sharded</a></p>

          '
        raw: 'Hi everyone

          In case you are facing CPU OOM issues while loading the model please consider
          using sharded models with small shards, for this model I would recommend
          using this repository: https://huggingface.co/bn22/Mistral-7B-Instruct-v0.1-sharded'
        updatedAt: '2023-10-16T19:28:20.948Z'
      numEdits: 0
      reactions: []
    id: 652d8ed4c3424254ba675893
    type: comment
  author: ybelkada
  content: 'Hi everyone

    In case you are facing CPU OOM issues while loading the model please consider
    using sharded models with small shards, for this model I would recommend using
    this repository: https://huggingface.co/bn22/Mistral-7B-Instruct-v0.1-sharded'
  created_at: 2023-10-16 18:28:20+00:00
  edited: false
  hidden: false
  id: 652d8ed4c3424254ba675893
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 21
repo_id: mistralai/Mistral-7B-Instruct-v0.1
repo_type: model
status: closed
target_branch: null
title: Unable to load checkpoint shards
