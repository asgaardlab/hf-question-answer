!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Lvegna
conflicting_files: null
created_at: 2022-09-26 12:37:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e493dc9a9c6295377b8de8b20d2dd078.svg
      fullname: Logan Vegna
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lvegna
      type: user
    createdAt: '2022-09-26T13:37:02.000Z'
    data:
      edited: true
      editors:
      - Lvegna
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e493dc9a9c6295377b8de8b20d2dd078.svg
          fullname: Logan Vegna
          isHf: false
          isPro: false
          name: Lvegna
          type: user
        html: '<p>No matter which combination of pasted code from a Facebook/wav2vec2
          blog I use the model outputs are always gibberish and WER does not improve
          in training. This is especially strange since earlier last week everything
          seemed to be working (at least when using the pre-trained model for inference),
          but now without changing anything all I get is gibberish. I even created
          a whole new python install on a different machine and got the same results.
          Here is an example of some of the code I pasted and the results I am getting:</p>

          <pre><code>

          import soundfile as sf

          import torch

          from datasets import load_dataset

          from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor


          # load pretrained model

          processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")

          model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-base-960h")



          librispeech_samples_ds = load_dataset("patrickvonplaten/librispeech_asr_dummy",
          "clean", split="validation")


          # load audio

          audio_input, sample_rate = sf.read(librispeech_samples_ds[0]["file"])


          # pad input values and return pt tensor

          input_values = processor(audio_input, sampling_rate=sample_rate, return_tensors="pt").input_values


          # INFERENCE


          # retrieve logits &amp; take argmax

          logits = model(input_values).logits

          predicted_ids = torch.argmax(logits, dim=-1)


          # transcribe

          transcription = processor.decode(predicted_ids[0])


          print(transcription)

          </code></pre>

          <p>====================<br>Output below<br>====================</p>

          <blockquote>

          <blockquote>

          <blockquote>

          <p>kuk_aktkckwrk[PAD]klk_dktkcwkrk_arthcrkskqkbaktkdcrkbykrthcru_zkzdcrmkdksakakckarks
          zr''kckrkswcrfkdkskzkrktkbrk''kckdkmkbkucrkhk_akrkfkbakqkckdkrk</p>

          </blockquote>

          </blockquote>

          </blockquote>

          '
        raw: 'No matter which combination of pasted code from a Facebook/wav2vec2
          blog I use the model outputs are always gibberish and WER does not improve
          in training. This is especially strange since earlier last week everything
          seemed to be working (at least when using the pre-trained model for inference),
          but now without changing anything all I get is gibberish. I even created
          a whole new python install on a different machine and got the same results.
          Here is an example of some of the code I pasted and the results I am getting:


          ```


          import soundfile as sf

          import torch

          from datasets import load_dataset

          from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor


          # load pretrained model

          processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")

          model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-base-960h")



          librispeech_samples_ds = load_dataset("patrickvonplaten/librispeech_asr_dummy",
          "clean", split="validation")


          # load audio

          audio_input, sample_rate = sf.read(librispeech_samples_ds[0]["file"])


          # pad input values and return pt tensor

          input_values = processor(audio_input, sampling_rate=sample_rate, return_tensors="pt").input_values


          # INFERENCE


          # retrieve logits & take argmax

          logits = model(input_values).logits

          predicted_ids = torch.argmax(logits, dim=-1)


          # transcribe

          transcription = processor.decode(predicted_ids[0])


          print(transcription)

          ```

          ====================

          Output below

          ====================

          >>>kuk_aktkckwrk[PAD]klk_dktkcwkrk_arthcrkskqkbaktkdcrkbykrthcru_zkzdcrmkdksakakckarks
          zr''kckrkswcrfkdkskzkrktkbrk''kckdkmkbkucrkhk_akrkfkbakqkckdkrk'
        updatedAt: '2022-09-26T13:38:37.168Z'
      numEdits: 1
      reactions: []
    id: 6331aafe9e3604f3f1816bbf
    type: comment
  author: Lvegna
  content: 'No matter which combination of pasted code from a Facebook/wav2vec2 blog
    I use the model outputs are always gibberish and WER does not improve in training.
    This is especially strange since earlier last week everything seemed to be working
    (at least when using the pre-trained model for inference), but now without changing
    anything all I get is gibberish. I even created a whole new python install on
    a different machine and got the same results. Here is an example of some of the
    code I pasted and the results I am getting:


    ```


    import soundfile as sf

    import torch

    from datasets import load_dataset

    from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor


    # load pretrained model

    processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")

    model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-base-960h")



    librispeech_samples_ds = load_dataset("patrickvonplaten/librispeech_asr_dummy",
    "clean", split="validation")


    # load audio

    audio_input, sample_rate = sf.read(librispeech_samples_ds[0]["file"])


    # pad input values and return pt tensor

    input_values = processor(audio_input, sampling_rate=sample_rate, return_tensors="pt").input_values


    # INFERENCE


    # retrieve logits & take argmax

    logits = model(input_values).logits

    predicted_ids = torch.argmax(logits, dim=-1)


    # transcribe

    transcription = processor.decode(predicted_ids[0])


    print(transcription)

    ```

    ====================

    Output below

    ====================

    >>>kuk_aktkckwrk[PAD]klk_dktkcwkrk_arthcrkskqkbaktkdcrkbykrthcru_zkzdcrmkdksakakckarks
    zr''kckrkswcrfkdkskzkrktkbrk''kckdkmkbkucrkhk_akrkfkbakqkckdkrk'
  created_at: 2022-09-26 12:37:02+00:00
  edited: true
  hidden: false
  id: 6331aafe9e3604f3f1816bbf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e493dc9a9c6295377b8de8b20d2dd078.svg
      fullname: Logan Vegna
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lvegna
      type: user
    createdAt: '2022-09-26T13:53:57.000Z'
    data:
      edited: false
      editors:
      - Lvegna
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e493dc9a9c6295377b8de8b20d2dd078.svg
          fullname: Logan Vegna
          isHf: false
          isPro: false
          name: Lvegna
          type: user
        html: '<p>Just for reference this code works perfectly on google colab and
          outputs "A MAN SAID TO THE UNIVERSE SIR I EXIST"</p>

          '
        raw: Just for reference this code works perfectly on google colab and outputs
          "A MAN SAID TO THE UNIVERSE SIR I EXIST"
        updatedAt: '2022-09-26T13:53:57.548Z'
      numEdits: 0
      reactions: []
    id: 6331aef5acb6472115ada2a3
    type: comment
  author: Lvegna
  content: Just for reference this code works perfectly on google colab and outputs
    "A MAN SAID TO THE UNIVERSE SIR I EXIST"
  created_at: 2022-09-26 12:53:57+00:00
  edited: false
  hidden: false
  id: 6331aef5acb6472115ada2a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e493dc9a9c6295377b8de8b20d2dd078.svg
      fullname: Logan Vegna
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lvegna
      type: user
    createdAt: '2022-09-26T18:07:03.000Z'
    data:
      edited: false
      editors:
      - Lvegna
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e493dc9a9c6295377b8de8b20d2dd078.svg
          fullname: Logan Vegna
          isHf: false
          isPro: false
          name: Lvegna
          type: user
        html: "<p>I have further determined that running this bit of code in my training\
          \ step is what is causing the output corruption. Everything works until\
          \ this bit of code is ran for the first time then every python file in the\
          \ directory where that bit of code is ran starts outputting gibberish. </p>\n\
          <pre><code>trainer = Trainer(\n    model=model,\n    data_collator=data_collator,\n\
          \    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=atco2[\"\
          train\"],\n    eval_dataset=atco2[\"test\"],\n    tokenizer=processor.feature_extractor,\n\
          )\n</code></pre>\n"
        raw: "I have further determined that running this bit of code in my training\
          \ step is what is causing the output corruption. Everything works until\
          \ this bit of code is ran for the first time then every python file in the\
          \ directory where that bit of code is ran starts outputting gibberish. \n\
          \n```\ntrainer = Trainer(\n    model=model,\n    data_collator=data_collator,\n\
          \    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=atco2[\"\
          train\"],\n    eval_dataset=atco2[\"test\"],\n    tokenizer=processor.feature_extractor,\n\
          )\n```"
        updatedAt: '2022-09-26T18:07:03.532Z'
      numEdits: 0
      reactions: []
    id: 6331ea474db0a767bbee23ac
    type: comment
  author: Lvegna
  content: "I have further determined that running this bit of code in my training\
    \ step is what is causing the output corruption. Everything works until this bit\
    \ of code is ran for the first time then every python file in the directory where\
    \ that bit of code is ran starts outputting gibberish. \n\n```\ntrainer = Trainer(\n\
    \    model=model,\n    data_collator=data_collator,\n    args=training_args,\n\
    \    compute_metrics=compute_metrics,\n    train_dataset=atco2[\"train\"],\n \
    \   eval_dataset=atco2[\"test\"],\n    tokenizer=processor.feature_extractor,\n\
    )\n```"
  created_at: 2022-09-26 17:07:03+00:00
  edited: false
  hidden: false
  id: 6331ea474db0a767bbee23ac
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: facebook/wav2vec2-base-960h
repo_type: model
status: open
target_branch: null
title: Gibberish model outputs on all models and processors
