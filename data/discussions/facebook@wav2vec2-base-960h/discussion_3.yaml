!!python/object:huggingface_hub.community.DiscussionWithDetails
author: abramovi
conflicting_files: null
created_at: 2022-07-29 13:13:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7008d4dc28f25ded36586089828f2129.svg
      fullname: Mo Aram
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abramovi
      type: user
    createdAt: '2022-07-29T14:13:56.000Z'
    data:
      edited: false
      editors:
      - abramovi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7008d4dc28f25ded36586089828f2129.svg
          fullname: Mo Aram
          isHf: false
          isPro: false
          name: abramovi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;patrickvonplaten&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/patrickvonplaten\"\
          >@<span class=\"underline\">patrickvonplaten</span></a></span>\n\n\t</span></span>\
          \ is it possible to use this mode for fine tune? </p>\n<p>I used your example\
          \ - <a href=\"https://huggingface.co/blog/fine-tune-wav2vec2-english\">https://huggingface.co/blog/fine-tune-wav2vec2-english</a>\
          \ when I just change the model from Wav2vec2-base to Wav2vec2-base-960h\
          \ </p>\n<p>WER stays on 1 </p>\n<p>Should I use model vocab to data-prep?</p>\n\
          <p>What do I do wrong?</p>\n"
        raw: "Hey @patrickvonplaten is it possible to use this mode for fine tune?\
          \ \r\n\r\nI used your example - https://huggingface.co/blog/fine-tune-wav2vec2-english\
          \ when I just change the model from Wav2vec2-base to Wav2vec2-base-960h\
          \ \r\n\r\nWER stays on 1 \r\n\r\nShould I use model vocab to data-prep?\r\
          \n\r\nWhat do I do wrong?"
        updatedAt: '2022-07-29T14:13:56.627Z'
      numEdits: 0
      reactions: []
    id: 62e3eb246eb3595031ebb8a9
    type: comment
  author: abramovi
  content: "Hey @patrickvonplaten is it possible to use this mode for fine tune? \r\
    \n\r\nI used your example - https://huggingface.co/blog/fine-tune-wav2vec2-english\
    \ when I just change the model from Wav2vec2-base to Wav2vec2-base-960h \r\n\r\
    \nWER stays on 1 \r\n\r\nShould I use model vocab to data-prep?\r\n\r\nWhat do\
    \ I do wrong?"
  created_at: 2022-07-29 13:13:56+00:00
  edited: false
  hidden: false
  id: 62e3eb246eb3595031ebb8a9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
      fullname: Lysandre
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lysandre
      type: user
    createdAt: '2022-08-01T06:35:39.000Z'
    data:
      edited: false
      editors:
      - lysandre
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
          fullname: Lysandre
          isHf: true
          isPro: false
          name: lysandre
          type: user
        html: "<p>I believe <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ has experience training such models</p>\n"
        raw: I believe @sanchit-gandhi has experience training such models
        updatedAt: '2022-08-01T06:35:39.799Z'
      numEdits: 0
      reactions: []
    id: 62e7743bcf8d1bbea136c21c
    type: comment
  author: lysandre
  content: I believe @sanchit-gandhi has experience training such models
  created_at: 2022-08-01 05:35:39+00:00
  edited: false
  hidden: false
  id: 62e7743bcf8d1bbea136c21c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2022-08-01T09:45:27.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;abramovi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/abramovi\"\
          >@<span class=\"underline\">abramovi</span></a></span>\n\n\t</span></span>!\
          \ </p>\n<p>This model takes the pre-trained checkpoint <a href=\"https://huggingface.co/facebook/wav2vec2-base\"\
          >facebook/wav2vec2-base</a> and fine-tunes on 960h of data from the <a href=\"\
          https://huggingface.co/datasets/librispeech_asr\">LibriSpeech ASR corpus</a>.\
          \ It is generally not advised to use this checkpoint for fine-tuning: this\
          \ model has a tokenizer and classification layer that are purposed built\
          \ for the LibriSpeech corpus. If training on a different dataset, you need\
          \ to build the tokenizer from scratch and fine-tune the model on your dataset\
          \ of choice.</p>\n<p>You should follow the steps listed in the blog for\
          \ building the tokenizer - the vocabulary in this checkpoint is purpose\
          \ built for the LibriSpeech corpus, not timit.</p>\n"
        raw: "Hey @abramovi! \n\nThis model takes the pre-trained checkpoint [facebook/wav2vec2-base](https://huggingface.co/facebook/wav2vec2-base)\
          \ and fine-tunes on 960h of data from the [LibriSpeech ASR corpus](https://huggingface.co/datasets/librispeech_asr).\
          \ It is generally not advised to use this checkpoint for fine-tuning: this\
          \ model has a tokenizer and classification layer that are purposed built\
          \ for the LibriSpeech corpus. If training on a different dataset, you need\
          \ to build the tokenizer from scratch and fine-tune the model on your dataset\
          \ of choice.\n\nYou should follow the steps listed in the blog for building\
          \ the tokenizer - the vocabulary in this checkpoint is purpose built for\
          \ the LibriSpeech corpus, not timit."
        updatedAt: '2022-08-01T09:45:27.681Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - patrickvonplaten
        - abramovi
    id: 62e7a0b7ae8b00c198ba1dbe
    type: comment
  author: sanchit-gandhi
  content: "Hey @abramovi! \n\nThis model takes the pre-trained checkpoint [facebook/wav2vec2-base](https://huggingface.co/facebook/wav2vec2-base)\
    \ and fine-tunes on 960h of data from the [LibriSpeech ASR corpus](https://huggingface.co/datasets/librispeech_asr).\
    \ It is generally not advised to use this checkpoint for fine-tuning: this model\
    \ has a tokenizer and classification layer that are purposed built for the LibriSpeech\
    \ corpus. If training on a different dataset, you need to build the tokenizer\
    \ from scratch and fine-tune the model on your dataset of choice.\n\nYou should\
    \ follow the steps listed in the blog for building the tokenizer - the vocabulary\
    \ in this checkpoint is purpose built for the LibriSpeech corpus, not timit."
  created_at: 2022-08-01 08:45:27+00:00
  edited: false
  hidden: false
  id: 62e7a0b7ae8b00c198ba1dbe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7008d4dc28f25ded36586089828f2129.svg
      fullname: Mo Aram
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abramovi
      type: user
    createdAt: '2022-08-08T15:30:54.000Z'
    data:
      edited: false
      editors:
      - abramovi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7008d4dc28f25ded36586089828f2129.svg
          fullname: Mo Aram
          isHf: false
          isPro: false
          name: abramovi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span><br>Thank\
          \ you so much for your answer - between the line  I understand that for\
          \ fine-tune on my own data it is better to use one of the base models (facebook/wav2vec2-base,\
          \ facebook/wav2vec2-large)</p>\n<p>Am I right ?</p>\n"
        raw: "Hey @sanchit-gandhi \nThank you so much for your answer - between the\
          \ line  I understand that for fine-tune on my own data it is better to use\
          \ one of the base models (facebook/wav2vec2-base, facebook/wav2vec2-large)\n\
          \nAm I right ?"
        updatedAt: '2022-08-08T15:30:54.313Z'
      numEdits: 0
      reactions: []
    id: 62f12c2e3e0991a8ab121bfe
    type: comment
  author: abramovi
  content: "Hey @sanchit-gandhi \nThank you so much for your answer - between the\
    \ line  I understand that for fine-tune on my own data it is better to use one\
    \ of the base models (facebook/wav2vec2-base, facebook/wav2vec2-large)\n\nAm I\
    \ right ?"
  created_at: 2022-08-08 14:30:54+00:00
  edited: false
  hidden: false
  id: 62f12c2e3e0991a8ab121bfe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2022-08-08T16:21:08.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;abramovi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/abramovi\"\
          >@<span class=\"underline\">abramovi</span></a></span>\n\n\t</span></span>!</p>\n\
          <p>That's right! Either one of the pre-trained checkpoints (<a href=\"https://huggingface.co/facebook/wav2vec2-base\"\
          >facebook/wav2vec2-base</a> or <a href=\"https://huggingface.co/facebook/wav2vec2-large-lv60\"\
          >facebook/wav2vev2-large-lv60</a>) would be suitable for fine-tuning. The\
          \ choice comes down to your constraints (runtime, memory etc). Hope that\
          \ answers your question!</p>\n"
        raw: 'Hey @abramovi!


          That''s right! Either one of the pre-trained checkpoints ([facebook/wav2vec2-base](https://huggingface.co/facebook/wav2vec2-base)
          or [facebook/wav2vev2-large-lv60](https://huggingface.co/facebook/wav2vec2-large-lv60))
          would be suitable for fine-tuning. The choice comes down to your constraints
          (runtime, memory etc). Hope that answers your question!'
        updatedAt: '2022-08-08T16:21:08.055Z'
      numEdits: 0
      reactions: []
    id: 62f137f483a1555a2bbe1a1d
    type: comment
  author: sanchit-gandhi
  content: 'Hey @abramovi!


    That''s right! Either one of the pre-trained checkpoints ([facebook/wav2vec2-base](https://huggingface.co/facebook/wav2vec2-base)
    or [facebook/wav2vev2-large-lv60](https://huggingface.co/facebook/wav2vec2-large-lv60))
    would be suitable for fine-tuning. The choice comes down to your constraints (runtime,
    memory etc). Hope that answers your question!'
  created_at: 2022-08-08 15:21:08+00:00
  edited: false
  hidden: false
  id: 62f137f483a1555a2bbe1a1d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/37f8ff1137050a03f7d7703bb75c966f.svg
      fullname: Srichand Vishnu S
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vishfeb27
      type: user
    createdAt: '2022-08-09T07:45:33.000Z'
    data:
      edited: true
      editors:
      - Vishfeb27
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/37f8ff1137050a03f7d7703bb75c966f.svg
          fullname: Srichand Vishnu S
          isHf: false
          isPro: false
          name: Vishfeb27
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>,<br>I\
          \ have a query in similar aspect too. Consider i have wav2vec2-base-960h\
          \ model and i would want the model to work for different accent such as\
          \ Arabic/Indian Accent so if i use the dataset of indian/arabic voice on\
          \ base model then it wont work for US accent (960h of librispeech) right\
          \ so to tackle it, only option is to finetune on wav2vec2-base-960h but\
          \ WER stays in 1. So my question is should we take base model and train\
          \ with 960h+indian accent dataset+Arabic accent or is there any option to\
          \ resume training with new dataset from checkpoint. </p>\n<p>Just to cross\
          \ verify i took  wav2vec2-base-960h and used the same tokenizer of wav2vec2-base-960h\
          \ to fine tune timit dataset but WER is still staying at 1, did i miss anything?\
          \ </p>\n"
        raw: "Hey @sanchit-gandhi, \nI have a query in similar aspect too. Consider\
          \ i have wav2vec2-base-960h model and i would want the model to work for\
          \ different accent such as Arabic/Indian Accent so if i use the dataset\
          \ of indian/arabic voice on base model then it wont work for US accent (960h\
          \ of librispeech) right so to tackle it, only option is to finetune on wav2vec2-base-960h\
          \ but WER stays in 1. So my question is should we take base model and train\
          \ with 960h+indian accent dataset+Arabic accent or is there any option to\
          \ resume training with new dataset from checkpoint. \n\nJust to cross verify\
          \ i took  wav2vec2-base-960h and used the same tokenizer of wav2vec2-base-960h\
          \ to fine tune timit dataset but WER is still staying at 1, did i miss anything? "
        updatedAt: '2022-08-09T07:47:04.355Z'
      numEdits: 1
      reactions: []
    id: 62f2109de9eb1e714d094b2d
    type: comment
  author: Vishfeb27
  content: "Hey @sanchit-gandhi, \nI have a query in similar aspect too. Consider\
    \ i have wav2vec2-base-960h model and i would want the model to work for different\
    \ accent such as Arabic/Indian Accent so if i use the dataset of indian/arabic\
    \ voice on base model then it wont work for US accent (960h of librispeech) right\
    \ so to tackle it, only option is to finetune on wav2vec2-base-960h but WER stays\
    \ in 1. So my question is should we take base model and train with 960h+indian\
    \ accent dataset+Arabic accent or is there any option to resume training with\
    \ new dataset from checkpoint. \n\nJust to cross verify i took  wav2vec2-base-960h\
    \ and used the same tokenizer of wav2vec2-base-960h to fine tune timit dataset\
    \ but WER is still staying at 1, did i miss anything? "
  created_at: 2022-08-09 06:45:33+00:00
  edited: true
  hidden: false
  id: 62f2109de9eb1e714d094b2d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2022-08-09T14:56:07.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Vishfeb27&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Vishfeb27\"\
          >@<span class=\"underline\">Vishfeb27</span></a></span>\n\n\t</span></span>\
          \ </p>\n<p>To clarify, you wish to fine-tune a model that handles both:\
          \ LibriSpeech ASR data (US speakers reading audiobooks aloud) and speakers\
          \ with an Arabic/Indian accent? Or just the latter?</p>\n<p>The checkpoint\
          \ <a href=\"https://huggingface.co/facebook/wav2vec2-base-960h/discussions/3#62f2109de9eb1e714d094b2d\"\
          >facebook/wav2vec2-base-960h</a> is fine-tuned on 960h Librispeech ASR data.\
          \ Consequently, it already has a tokenizer built for the <strong>LibriSpeech\
          \ ASR corpus</strong>. This tokenizer is built on <strong>upper-case</strong>\
          \ characters. The blog fine-tunes a system on TIMIT using <strong>lower-case</strong>\
          \ characters only. Comparing the two vocabularies, they are indeed the same,\
          \ with the exception that the wav2vec2 tokenizer is upper-case characters,\
          \ and the TIMIT vocabulary lower-case character. You will need to match\
          \ one to the other to fine-tune the system on lower-case text only. Assuming\
          \ you are using the official wav2vec2 tokenizer from this repo, you can\
          \ either:</p>\n<ol>\n<li>Set <code>tokenizer.do_lower_case = True</code>\
          \ (converts all input strings to uppercase prior to tokenization)</li>\n\
          <li>Normalise all the training data text to upper case:</li>\n</ol>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">import</span> re\n\
          chars_to_ignore_regex = <span class=\"hljs-string\">'[\\,\\?\\.\\!\\-\\\
          ;\\:\\\"]'</span>\n\n<span class=\"hljs-keyword\">def</span> <span class=\"\
          hljs-title function_\">remove_special_characters</span>(<span class=\"hljs-params\"\
          >batch</span>):\n    batch[<span class=\"hljs-string\">\"text\"</span>]\
          \ = re.sub(chars_to_ignore_regex, <span class=\"hljs-string\">''</span>,\
          \ batch[<span class=\"hljs-string\">\"text\"</span>]).upper()\n    <span\
          \ class=\"hljs-keyword\">return</span> batch\n\ntimit = timit.<span class=\"\
          hljs-built_in\">map</span>(remove_special_characters)\n</code></pre>\n"
        raw: "Hey @Vishfeb27 \n\nTo clarify, you wish to fine-tune a model that handles\
          \ both: LibriSpeech ASR data (US speakers reading audiobooks aloud) and\
          \ speakers with an Arabic/Indian accent? Or just the latter?\n\nThe checkpoint\
          \ [facebook/wav2vec2-base-960h](https://huggingface.co/facebook/wav2vec2-base-960h/discussions/3#62f2109de9eb1e714d094b2d)\
          \ is fine-tuned on 960h Librispeech ASR data. Consequently, it already has\
          \ a tokenizer built for the **LibriSpeech ASR corpus**. This tokenizer is\
          \ built on **upper-case** characters. The blog fine-tunes a system on TIMIT\
          \ using **lower-case** characters only. Comparing the two vocabularies,\
          \ they are indeed the same, with the exception that the wav2vec2 tokenizer\
          \ is upper-case characters, and the TIMIT vocabulary lower-case character.\
          \ You will need to match one to the other to fine-tune the system on lower-case\
          \ text only. Assuming you are using the official wav2vec2 tokenizer from\
          \ this repo, you can either:\n1. Set `tokenizer.do_lower_case = True` (converts\
          \ all input strings to uppercase prior to tokenization)\n2. Normalise all\
          \ the training data text to upper case:\n\n```python\nimport re\nchars_to_ignore_regex\
          \ = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'\n\ndef remove_special_characters(batch):\n\
          \    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"\
          ]).upper()\n    return batch\n\ntimit = timit.map(remove_special_characters)\n\
          ```"
        updatedAt: '2022-08-09T14:56:07.367Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - abramovi
    id: 62f2758719ab6b96a2748c0a
    type: comment
  author: sanchit-gandhi
  content: "Hey @Vishfeb27 \n\nTo clarify, you wish to fine-tune a model that handles\
    \ both: LibriSpeech ASR data (US speakers reading audiobooks aloud) and speakers\
    \ with an Arabic/Indian accent? Or just the latter?\n\nThe checkpoint [facebook/wav2vec2-base-960h](https://huggingface.co/facebook/wav2vec2-base-960h/discussions/3#62f2109de9eb1e714d094b2d)\
    \ is fine-tuned on 960h Librispeech ASR data. Consequently, it already has a tokenizer\
    \ built for the **LibriSpeech ASR corpus**. This tokenizer is built on **upper-case**\
    \ characters. The blog fine-tunes a system on TIMIT using **lower-case** characters\
    \ only. Comparing the two vocabularies, they are indeed the same, with the exception\
    \ that the wav2vec2 tokenizer is upper-case characters, and the TIMIT vocabulary\
    \ lower-case character. You will need to match one to the other to fine-tune the\
    \ system on lower-case text only. Assuming you are using the official wav2vec2\
    \ tokenizer from this repo, you can either:\n1. Set `tokenizer.do_lower_case =\
    \ True` (converts all input strings to uppercase prior to tokenization)\n2. Normalise\
    \ all the training data text to upper case:\n\n```python\nimport re\nchars_to_ignore_regex\
    \ = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'\n\ndef remove_special_characters(batch):\n \
    \   batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).upper()\n\
    \    return batch\n\ntimit = timit.map(remove_special_characters)\n```"
  created_at: 2022-08-09 13:56:07+00:00
  edited: false
  hidden: false
  id: 62f2758719ab6b96a2748c0a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/37f8ff1137050a03f7d7703bb75c966f.svg
      fullname: Srichand Vishnu S
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vishfeb27
      type: user
    createdAt: '2022-08-09T15:33:16.000Z'
    data:
      edited: false
      editors:
      - Vishfeb27
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/37f8ff1137050a03f7d7703bb75c966f.svg
          fullname: Srichand Vishnu S
          isHf: false
          isPro: false
          name: Vishfeb27
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ ,</p>\n<p>Thanks for the solution for finetuning Timid. </p>\n<p>I wish\
          \ to fine-tune a model that handles both: LibriSpeech ASR data (US speakers\
          \ reading audiobooks aloud) and speakers with an Arabic/Indian accent. Consider\
          \ i have the indian/arabic accent voice data from Commonvoice and i would\
          \ require the model to work well for US accent as well as Arabic/Indian\
          \ accent, so do you suggest to finetune Arabic/Indian accent on the checkpoint\
          \ facebook/wav2vec2-base-960h since the vocab is same or it needs a pretraining\
          \ step?</p>\n"
        raw: "Hey @sanchit-gandhi ,\n\nThanks for the solution for finetuning Timid.\
          \ \n\nI wish to fine-tune a model that handles both: LibriSpeech ASR data\
          \ (US speakers reading audiobooks aloud) and speakers with an Arabic/Indian\
          \ accent. Consider i have the indian/arabic accent voice data from Commonvoice\
          \ and i would require the model to work well for US accent as well as Arabic/Indian\
          \ accent, so do you suggest to finetune Arabic/Indian accent on the checkpoint\
          \ facebook/wav2vec2-base-960h since the vocab is same or it needs a pretraining\
          \ step?"
        updatedAt: '2022-08-09T15:33:16.399Z'
      numEdits: 0
      reactions: []
    id: 62f27e3c94fe062ca9af47ed
    type: comment
  author: Vishfeb27
  content: "Hey @sanchit-gandhi ,\n\nThanks for the solution for finetuning Timid.\
    \ \n\nI wish to fine-tune a model that handles both: LibriSpeech ASR data (US\
    \ speakers reading audiobooks aloud) and speakers with an Arabic/Indian accent.\
    \ Consider i have the indian/arabic accent voice data from Commonvoice and i would\
    \ require the model to work well for US accent as well as Arabic/Indian accent,\
    \ so do you suggest to finetune Arabic/Indian accent on the checkpoint facebook/wav2vec2-base-960h\
    \ since the vocab is same or it needs a pretraining step?"
  created_at: 2022-08-09 14:33:16+00:00
  edited: false
  hidden: false
  id: 62f27e3c94fe062ca9af47ed
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2022-08-12T17:01:37.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Vishfeb27&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Vishfeb27\"\
          >@<span class=\"underline\">Vishfeb27</span></a></span>\n\n\t</span></span>,</p>\n\
          <p>If you can match the vocabularies for both datasets it might work. Note\
          \ that with Common Voice, the text is cased and has punctuation. For LibriSpeech,\
          \ the text is all upper-cased and has no punctuation. You'll need to define/adapt\
          \ your tokenizer accordingly. Either you build a tokenizer on the combined\
          \ vocabulary of both datasets and fine-tune the wav2vec2-base model from\
          \ scratch. Or, you remove all punctuation from Common Voice, lower case\
          \ the text, and fine-tune wav2vec2-base-960h.</p>\n"
        raw: 'Hey @Vishfeb27,


          If you can match the vocabularies for both datasets it might work. Note
          that with Common Voice, the text is cased and has punctuation. For LibriSpeech,
          the text is all upper-cased and has no punctuation. You''ll need to define/adapt
          your tokenizer accordingly. Either you build a tokenizer on the combined
          vocabulary of both datasets and fine-tune the wav2vec2-base model from scratch.
          Or, you remove all punctuation from Common Voice, lower case the text, and
          fine-tune wav2vec2-base-960h.'
        updatedAt: '2022-08-12T17:01:37.433Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - abramovi
    id: 62f6877104e5e02f82ae1ad3
    type: comment
  author: sanchit-gandhi
  content: 'Hey @Vishfeb27,


    If you can match the vocabularies for both datasets it might work. Note that with
    Common Voice, the text is cased and has punctuation. For LibriSpeech, the text
    is all upper-cased and has no punctuation. You''ll need to define/adapt your tokenizer
    accordingly. Either you build a tokenizer on the combined vocabulary of both datasets
    and fine-tune the wav2vec2-base model from scratch. Or, you remove all punctuation
    from Common Voice, lower case the text, and fine-tune wav2vec2-base-960h.'
  created_at: 2022-08-12 16:01:37+00:00
  edited: false
  hidden: false
  id: 62f6877104e5e02f82ae1ad3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/37f8ff1137050a03f7d7703bb75c966f.svg
      fullname: Srichand Vishnu S
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vishfeb27
      type: user
    createdAt: '2022-08-16T08:36:38.000Z'
    data:
      edited: false
      editors:
      - Vishfeb27
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/37f8ff1137050a03f7d7703bb75c966f.svg
          fullname: Srichand Vishnu S
          isHf: false
          isPro: false
          name: Vishfeb27
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ , Thank you soo much for your response. This helps!</p>\n"
        raw: '@sanchit-gandhi , Thank you soo much for your response. This helps!'
        updatedAt: '2022-08-16T08:36:38.364Z'
      numEdits: 0
      reactions: []
    id: 62fb5716a80632fbd4778641
    type: comment
  author: Vishfeb27
  content: '@sanchit-gandhi , Thank you soo much for your response. This helps!'
  created_at: 2022-08-16 07:36:38+00:00
  edited: false
  hidden: false
  id: 62fb5716a80632fbd4778641
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/82237ef147b03263a74d3377287ba27a.svg
      fullname: Rishi Lulla
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Rishilulla
      type: user
    createdAt: '2023-01-05T07:25:37.000Z'
    data:
      edited: false
      editors:
      - Rishilulla
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/82237ef147b03263a74d3377287ba27a.svg
          fullname: Rishi Lulla
          isHf: false
          isPro: false
          name: Rishilulla
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>,</p>\n\
          <p>I used the facebook/wav2vec2-base-960h and tested its performance on\
          \ custom voice recording. It worked decently (let's call this test 1). To\
          \ improve the performance, I fine tuned facebook/wav2vec2-base-960h on the\
          \ same recoding I tested on during test 1. Also, to make sure everything\
          \ was working fine, I used the same data for training and testing. I expected\
          \ the performance to improve since I trained on custom data. However, it\
          \ deteriorated. It's not even as good as it was during test 1.  In fact\
          \ now it is not even predicting one word correctly. I am not able to figure\
          \ out what went wrong. Can you help me with this?</p>\n"
        raw: 'Hi @sanchit-gandhi,


          I used the facebook/wav2vec2-base-960h and tested its performance on custom
          voice recording. It worked decently (let''s call this test 1). To improve
          the performance, I fine tuned facebook/wav2vec2-base-960h on the same recoding
          I tested on during test 1. Also, to make sure everything was working fine,
          I used the same data for training and testing. I expected the performance
          to improve since I trained on custom data. However, it deteriorated. It''s
          not even as good as it was during test 1.  In fact now it is not even predicting
          one word correctly. I am not able to figure out what went wrong. Can you
          help me with this?'
        updatedAt: '2023-01-05T07:25:37.569Z'
      numEdits: 0
      reactions: []
    id: 63b67b71b24a3784b0682769
    type: comment
  author: Rishilulla
  content: 'Hi @sanchit-gandhi,


    I used the facebook/wav2vec2-base-960h and tested its performance on custom voice
    recording. It worked decently (let''s call this test 1). To improve the performance,
    I fine tuned facebook/wav2vec2-base-960h on the same recoding I tested on during
    test 1. Also, to make sure everything was working fine, I used the same data for
    training and testing. I expected the performance to improve since I trained on
    custom data. However, it deteriorated. It''s not even as good as it was during
    test 1.  In fact now it is not even predicting one word correctly. I am not able
    to figure out what went wrong. Can you help me with this?'
  created_at: 2023-01-05 07:25:37+00:00
  edited: false
  hidden: false
  id: 63b67b71b24a3784b0682769
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-01-05T16:29:49.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Rishilulla&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Rishilulla\"\
          >@<span class=\"underline\">Rishilulla</span></a></span>\n\n\t</span></span>!\
          \ Do you have any additional details about the custom dataset? Such as language,\
          \ accent, text formatting (upper or lower-case, with or without punctuation)?\
          \ Given the model worked on reasonably well in the zero-shot setting, I'm\
          \ assuming that you didn't create a new tokenizer, but rather leveraged\
          \ the pre-trained one directly?</p>\n"
        raw: Hey @Rishilulla! Do you have any additional details about the custom
          dataset? Such as language, accent, text formatting (upper or lower-case,
          with or without punctuation)? Given the model worked on reasonably well
          in the zero-shot setting, I'm assuming that you didn't create a new tokenizer,
          but rather leveraged the pre-trained one directly?
        updatedAt: '2023-01-05T16:29:49.196Z'
      numEdits: 0
      reactions: []
    id: 63b6fafd0d21367c0f634557
    type: comment
  author: sanchit-gandhi
  content: Hey @Rishilulla! Do you have any additional details about the custom dataset?
    Such as language, accent, text formatting (upper or lower-case, with or without
    punctuation)? Given the model worked on reasonably well in the zero-shot setting,
    I'm assuming that you didn't create a new tokenizer, but rather leveraged the
    pre-trained one directly?
  created_at: 2023-01-05 16:29:49+00:00
  edited: false
  hidden: false
  id: 63b6fafd0d21367c0f634557
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/82237ef147b03263a74d3377287ba27a.svg
      fullname: Rishi Lulla
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Rishilulla
      type: user
    createdAt: '2023-01-05T16:49:11.000Z'
    data:
      edited: false
      editors:
      - Rishilulla
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/82237ef147b03263a74d3377287ba27a.svg
          fullname: Rishi Lulla
          isHf: false
          isPro: false
          name: Rishilulla
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>!<br>I\
          \ am using self recorded English data just to test things out. After reading\
          \ the comments here, I did change the text to upper case and since I am\
          \ referring \"<a href=\"https://huggingface.co/blog/fine-tune-wav2vec2-english&quot;\"\
          >https://huggingface.co/blog/fine-tune-wav2vec2-english\"</a> this article,\
          \ I created a new tokenizer.<br>I realized I had not changed the number\
          \ of epochs and that's why the performance was not great. I have increased\
          \ it now and its WIP.<br>Also, wanted to understand some basics about fine\
          \ tuning. So if I am fine tuning 'facebook/wav2vec2-base-960h' and I think\
          \ the only thing that is missing is domain specific words, all I need to\
          \ do is fine tune the pre-trained model with domain specific words, correct?\
          \ Post which, the domain specific words would be taken care by the custom\
          \ data and everything else by the  'facebook/wav2vec2-base-960h'. Is my\
          \ understanding correct?</p>\n"
        raw: "Hi @sanchit-gandhi!\nI am using self recorded English data just to test\
          \ things out. After reading the comments here, I did change the text to\
          \ upper case and since I am referring \"https://huggingface.co/blog/fine-tune-wav2vec2-english\"\
          \ this article, I created a new tokenizer. \nI realized I had not changed\
          \ the number of epochs and that's why the performance was not great. I have\
          \ increased it now and its WIP. \nAlso, wanted to understand some basics\
          \ about fine tuning. So if I am fine tuning 'facebook/wav2vec2-base-960h'\
          \ and I think the only thing that is missing is domain specific words, all\
          \ I need to do is fine tune the pre-trained model with domain specific words,\
          \ correct? Post which, the domain specific words would be taken care by\
          \ the custom data and everything else by the  'facebook/wav2vec2-base-960h'.\
          \ Is my understanding correct?"
        updatedAt: '2023-01-05T16:49:11.124Z'
      numEdits: 0
      reactions: []
    id: 63b6ff870d21367c0f638f2d
    type: comment
  author: Rishilulla
  content: "Hi @sanchit-gandhi!\nI am using self recorded English data just to test\
    \ things out. After reading the comments here, I did change the text to upper\
    \ case and since I am referring \"https://huggingface.co/blog/fine-tune-wav2vec2-english\"\
    \ this article, I created a new tokenizer. \nI realized I had not changed the\
    \ number of epochs and that's why the performance was not great. I have increased\
    \ it now and its WIP. \nAlso, wanted to understand some basics about fine tuning.\
    \ So if I am fine tuning 'facebook/wav2vec2-base-960h' and I think the only thing\
    \ that is missing is domain specific words, all I need to do is fine tune the\
    \ pre-trained model with domain specific words, correct? Post which, the domain\
    \ specific words would be taken care by the custom data and everything else by\
    \ the  'facebook/wav2vec2-base-960h'. Is my understanding correct?"
  created_at: 2023-01-05 16:49:11+00:00
  edited: false
  hidden: false
  id: 63b6ff870d21367c0f638f2d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/82237ef147b03263a74d3377287ba27a.svg
      fullname: Rishi Lulla
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Rishilulla
      type: user
    createdAt: '2023-01-06T06:12:40.000Z'
    data:
      edited: false
      editors:
      - Rishilulla
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/82237ef147b03263a74d3377287ba27a.svg
          fullname: Rishi Lulla
          isHf: false
          isPro: false
          name: Rishilulla
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>,<br>The\
          \ training is completed and have attached the results. The results seem\
          \ promising, but when I am evaluating it on test data, I am getting WER\
          \ as 100%. Not sure where I am going wrong.</p>\n<p><a rel=\"nofollow\"\
          \ href=\"https://cdn-uploads.huggingface.co/production/uploads/1672985495998-63b2df3b677046a142859b54.png\"\
          ><img alt=\"training_result.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/1672985495998-63b2df3b677046a142859b54.png\"\
          ></a></p>\n"
        raw: 'Hi @sanchit-gandhi,

          The training is completed and have attached the results. The results seem
          promising, but when I am evaluating it on test data, I am getting WER as
          100%. Not sure where I am going wrong.


          ![training_result.png](https://cdn-uploads.huggingface.co/production/uploads/1672985495998-63b2df3b677046a142859b54.png)'
        updatedAt: '2023-01-06T06:12:40.156Z'
      numEdits: 0
      reactions: []
    id: 63b7bbd80c4c99dba59503ef
    type: comment
  author: Rishilulla
  content: 'Hi @sanchit-gandhi,

    The training is completed and have attached the results. The results seem promising,
    but when I am evaluating it on test data, I am getting WER as 100%. Not sure where
    I am going wrong.


    ![training_result.png](https://cdn-uploads.huggingface.co/production/uploads/1672985495998-63b2df3b677046a142859b54.png)'
  created_at: 2023-01-06 06:12:40+00:00
  edited: false
  hidden: false
  id: 63b7bbd80c4c99dba59503ef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-01-13T11:16:50.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Rishilulla&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Rishilulla\"\
          >@<span class=\"underline\">Rishilulla</span></a></span>\n\n\t</span></span>!\
          \ Thanks for the additional details and sorry about the late reply here!</p>\n\
          <p>Just a note on the tokenizer: if you want to directly leverage the pre-trained\
          \ tokenizer, you should ensure that all of your training data is i) English,\
          \ ii) upper-cased and iii) without punctuation. If you create a new tokenizer\
          \ according to the aforementioned blog post, the format of your training\
          \ data is unconstrained: you will build a new tokenizer from your training\
          \ data, so the tokenizer will be matched to the format of your dataset implicitly.\
          \ Therefore, your training data can take any form and your tokenizer will\
          \ be built accordingly. However, it is recommended to single-case the data\
          \ and optionally remove punctuation to improve the speech recognition performance\
          \ of the Wav2Vec2 CTC model (this simplifies the task of speech recognition,\
          \ thus improving downstream performance).</p>\n<p>For the best performance\
          \ with fine-tuning, you should ensure that your training dataset is <em>in\
          \ domain</em> with your test set. If there is domain specific vocabulary\
          \ in your test set that you want your model to be able to handle, you should\
          \ ensure that the training dataset is from the same distribution of data.\
          \ The pre-trained <code>facebook/wav2vec2-base-960h</code> model is trained\
          \ on the LibriSpeech 960h dataset, a corpus of narrated audio books. Thus,\
          \ it performs well on data drawn from this distribution, but not necessarily\
          \ on data from other distributions. This is why we need additional fine-tuning\
          \ data to boost the model's performance on our specific domain.</p>\n<p>It\
          \ looks like you got some quite nice results for fine-tuning! What hyper\
          \ parameters were you using? You might benefit from increasing the amount\
          \ of <em>regularisation</em> if your dataset is small (<em>c.f.</em> <a\
          \ rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/blob/b210c83a78022226ce48402cd67d8c8da7afbd8d/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py#L556\"\
          >https://github.com/huggingface/transformers/blob/b210c83a78022226ce48402cd67d8c8da7afbd8d/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py#L556</a>).</p>\n\
          <p>Do you have a reproducible code-snippet for your evaluation on test data?\
          \ If you're able to share this I can take a look as to why the model is\
          \ performing poorly! \U0001F917</p>\n"
        raw: "Hey @Rishilulla! Thanks for the additional details and sorry about the\
          \ late reply here!\n\nJust a note on the tokenizer: if you want to directly\
          \ leverage the pre-trained tokenizer, you should ensure that all of your\
          \ training data is i) English, ii) upper-cased and iii) without punctuation.\
          \ If you create a new tokenizer according to the aforementioned blog post,\
          \ the format of your training data is unconstrained: you will build a new\
          \ tokenizer from your training data, so the tokenizer will be matched to\
          \ the format of your dataset implicitly. Therefore, your training data can\
          \ take any form and your tokenizer will be built accordingly. However, it\
          \ is recommended to single-case the data and optionally remove punctuation\
          \ to improve the speech recognition performance of the Wav2Vec2 CTC model\
          \ (this simplifies the task of speech recognition, thus improving downstream\
          \ performance).\n\nFor the best performance with fine-tuning, you should\
          \ ensure that your training dataset is _in domain_ with your test set. If\
          \ there is domain specific vocabulary in your test set that you want your\
          \ model to be able to handle, you should ensure that the training dataset\
          \ is from the same distribution of data. The pre-trained `facebook/wav2vec2-base-960h`\
          \ model is trained on the LibriSpeech 960h dataset, a corpus of narrated\
          \ audio books. Thus, it performs well on data drawn from this distribution,\
          \ but not necessarily on data from other distributions. This is why we need\
          \ additional fine-tuning data to boost the model's performance on our specific\
          \ domain.\n\nIt looks like you got some quite nice results for fine-tuning!\
          \ What hyper parameters were you using? You might benefit from increasing\
          \ the amount of _regularisation_ if your dataset is small (_c.f._ https://github.com/huggingface/transformers/blob/b210c83a78022226ce48402cd67d8c8da7afbd8d/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py#L556).\n\
          \nDo you have a reproducible code-snippet for your evaluation on test data?\
          \ If you're able to share this I can take a look as to why the model is\
          \ performing poorly! \U0001F917"
        updatedAt: '2023-01-13T11:17:33.735Z'
      numEdits: 1
      reactions: []
    id: 63c13da294b28327f0e678f5
    type: comment
  author: sanchit-gandhi
  content: "Hey @Rishilulla! Thanks for the additional details and sorry about the\
    \ late reply here!\n\nJust a note on the tokenizer: if you want to directly leverage\
    \ the pre-trained tokenizer, you should ensure that all of your training data\
    \ is i) English, ii) upper-cased and iii) without punctuation. If you create a\
    \ new tokenizer according to the aforementioned blog post, the format of your\
    \ training data is unconstrained: you will build a new tokenizer from your training\
    \ data, so the tokenizer will be matched to the format of your dataset implicitly.\
    \ Therefore, your training data can take any form and your tokenizer will be built\
    \ accordingly. However, it is recommended to single-case the data and optionally\
    \ remove punctuation to improve the speech recognition performance of the Wav2Vec2\
    \ CTC model (this simplifies the task of speech recognition, thus improving downstream\
    \ performance).\n\nFor the best performance with fine-tuning, you should ensure\
    \ that your training dataset is _in domain_ with your test set. If there is domain\
    \ specific vocabulary in your test set that you want your model to be able to\
    \ handle, you should ensure that the training dataset is from the same distribution\
    \ of data. The pre-trained `facebook/wav2vec2-base-960h` model is trained on the\
    \ LibriSpeech 960h dataset, a corpus of narrated audio books. Thus, it performs\
    \ well on data drawn from this distribution, but not necessarily on data from\
    \ other distributions. This is why we need additional fine-tuning data to boost\
    \ the model's performance on our specific domain.\n\nIt looks like you got some\
    \ quite nice results for fine-tuning! What hyper parameters were you using? You\
    \ might benefit from increasing the amount of _regularisation_ if your dataset\
    \ is small (_c.f._ https://github.com/huggingface/transformers/blob/b210c83a78022226ce48402cd67d8c8da7afbd8d/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py#L556).\n\
    \nDo you have a reproducible code-snippet for your evaluation on test data? If\
    \ you're able to share this I can take a look as to why the model is performing\
    \ poorly! \U0001F917"
  created_at: 2023-01-13 11:16:50+00:00
  edited: true
  hidden: false
  id: 63c13da294b28327f0e678f5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: facebook/wav2vec2-base-960h
repo_type: model
status: open
target_branch: null
title: 'WER stays on 1 when fine tune '
