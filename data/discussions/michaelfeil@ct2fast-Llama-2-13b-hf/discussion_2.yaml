!!python/object:huggingface_hub.community.DiscussionWithDetails
author: limcheekin
conflicting_files: null
created_at: 2023-07-21 08:44:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/24a8c63c897efdd980ef9d4805cbff7b.svg
      fullname: Lim Chee Kin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: limcheekin
      type: user
    createdAt: '2023-07-21T09:44:02.000Z'
    data:
      edited: false
      editors:
      - limcheekin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8427057266235352
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/24a8c63c897efdd980ef9d4805cbff7b.svg
          fullname: Lim Chee Kin
          isHf: false
          isPro: false
          name: limcheekin
          type: user
        html: '<p>Hi there,</p>

          <p>Look like the converted model doesn''t support the prompt format the
          model being trained for.</p>

          <p>Please see the following code of the prompt format:<br><a href="https://huggingface.co/spaces/huggingface-projects/llama-2-13b-chat/blob/main/model.py#L24">https://huggingface.co/spaces/huggingface-projects/llama-2-13b-chat/blob/main/model.py#L24</a></p>

          <p>Any idea how to make the converted model work with the specific prompt
          format above?</p>

          <p>Thanks.</p>

          <p>Best regards.</p>

          '
        raw: "Hi there,\r\n\r\nLook like the converted model doesn't support the prompt\
          \ format the model being trained for.\r\n\r\nPlease see the following code\
          \ of the prompt format:\r\nhttps://huggingface.co/spaces/huggingface-projects/llama-2-13b-chat/blob/main/model.py#L24\r\
          \n\r\nAny idea how to make the converted model work with the specific prompt\
          \ format above?\r\n\r\nThanks.\r\n\r\nBest regards."
        updatedAt: '2023-07-21T09:44:02.433Z'
      numEdits: 0
      reactions: []
    id: 64ba536288a26e8981abcc7a
    type: comment
  author: limcheekin
  content: "Hi there,\r\n\r\nLook like the converted model doesn't support the prompt\
    \ format the model being trained for.\r\n\r\nPlease see the following code of\
    \ the prompt format:\r\nhttps://huggingface.co/spaces/huggingface-projects/llama-2-13b-chat/blob/main/model.py#L24\r\
    \n\r\nAny idea how to make the converted model work with the specific prompt format\
    \ above?\r\n\r\nThanks.\r\n\r\nBest regards."
  created_at: 2023-07-21 08:44:02+00:00
  edited: false
  hidden: false
  id: 64ba536288a26e8981abcc7a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
      fullname: Michael
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: michaelfeil
      type: user
    createdAt: '2023-07-21T15:04:14.000Z'
    data:
      edited: false
      editors:
      - michaelfeil
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8496840596199036
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
          fullname: Michael
          isHf: false
          isPro: false
          name: michaelfeil
          type: user
        html: "<p>I think you got some key concepts wrong here. High level: The highlighted\
          \ function formats a chat dict to a string. The model\u2018s tokenizer supports\
          \ tokenisation of strings.</p>\n<p>Detailed: If you got you wrong here,\
          \ what explicitly is not supported here? Any tokenisation issues?</p>\n"
        raw: "I think you got some key concepts wrong here. High level: The highlighted\
          \ function formats a chat dict to a string. The model\u2018s tokenizer supports\
          \ tokenisation of strings.\n\nDetailed: If you got you wrong here, what\
          \ explicitly is not supported here? Any tokenisation issues?"
        updatedAt: '2023-07-21T15:04:14.478Z'
      numEdits: 0
      reactions: []
    id: 64ba9e6e77dd483716b3d69f
    type: comment
  author: michaelfeil
  content: "I think you got some key concepts wrong here. High level: The highlighted\
    \ function formats a chat dict to a string. The model\u2018s tokenizer supports\
    \ tokenisation of strings.\n\nDetailed: If you got you wrong here, what explicitly\
    \ is not supported here? Any tokenisation issues?"
  created_at: 2023-07-21 14:04:14+00:00
  edited: false
  hidden: false
  id: 64ba9e6e77dd483716b3d69f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
      fullname: Michael
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: michaelfeil
      type: user
    createdAt: '2023-07-21T15:05:16.000Z'
    data:
      edited: false
      editors:
      - michaelfeil
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8522316217422485
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
          fullname: Michael
          isHf: false
          isPro: false
          name: michaelfeil
          type: user
        html: '<p>Note, this model is the base model, not the finetuned one for chat</p>

          '
        raw: Note, this model is the base model, not the finetuned one for chat
        updatedAt: '2023-07-21T15:05:16.708Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - limcheekin
    id: 64ba9eac838da64e69094f3a
    type: comment
  author: michaelfeil
  content: Note, this model is the base model, not the finetuned one for chat
  created_at: 2023-07-21 14:05:16+00:00
  edited: false
  hidden: false
  id: 64ba9eac838da64e69094f3a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/24a8c63c897efdd980ef9d4805cbff7b.svg
      fullname: Lim Chee Kin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: limcheekin
      type: user
    createdAt: '2023-07-22T05:42:54.000Z'
    data:
      edited: false
      editors:
      - limcheekin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9152910113334656
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/24a8c63c897efdd980ef9d4805cbff7b.svg
          fullname: Lim Chee Kin
          isHf: false
          isPro: false
          name: limcheekin
          type: user
        html: '<p>Sorry for the silly mistake. I used the prompt in a wrong model.</p>

          <p>Thanks for the heads up.</p>

          '
        raw: 'Sorry for the silly mistake. I used the prompt in a wrong model.


          Thanks for the heads up.'
        updatedAt: '2023-07-22T05:42:54.380Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - michaelfeil
      relatedEventId: 64bb6c5e9f94ea2554cc48d3
    id: 64bb6c5e9f94ea2554cc48d1
    type: comment
  author: limcheekin
  content: 'Sorry for the silly mistake. I used the prompt in a wrong model.


    Thanks for the heads up.'
  created_at: 2023-07-22 04:42:54+00:00
  edited: false
  hidden: false
  id: 64bb6c5e9f94ea2554cc48d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/24a8c63c897efdd980ef9d4805cbff7b.svg
      fullname: Lim Chee Kin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: limcheekin
      type: user
    createdAt: '2023-07-22T05:42:54.000Z'
    data:
      status: closed
    id: 64bb6c5e9f94ea2554cc48d3
    type: status-change
  author: limcheekin
  created_at: 2023-07-22 04:42:54+00:00
  id: 64bb6c5e9f94ea2554cc48d3
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: michaelfeil/ct2fast-Llama-2-13b-hf
repo_type: model
status: closed
target_branch: null
title: Prompt format support
