!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Fazzie
conflicting_files: null
created_at: 2023-08-25 07:14:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2cb4f3cfcf2bc117e40dc90b81ece689.svg
      fullname: Fazzie
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Fazzie
      type: user
    createdAt: '2023-08-25T08:14:21.000Z'
    data:
      edited: false
      editors:
      - Fazzie
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5323241949081421
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2cb4f3cfcf2bc117e40dc90b81ece689.svg
          fullname: Fazzie
          isHf: false
          isPro: false
          name: Fazzie
          type: user
        html: '<p>Get Error</p>

          <p>OSError: Unable to load weights from pytorch checkpoint file for ''/mnt/bd/fazzie-data/models/CodeLlama-7b-hf/pytorch_model-00001-of-00002.bin''
          at ''/mnt/bd/fazzie-data/models/CodeLlama-7b-hf/pytorch_model-00001-of-00002.bin''.
          If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set
          from_tf=True.</p>

          <p>Here is the code</p>

          <pre><code>from transformers import AutoTokenizer, AutoModelForCausalLM

          import transformers

          import torch


          model = "./models/CodeLlama-7b-hf"


          tokenizer = AutoTokenizer.from_pretrained(model)


          model = AutoModelForCausalLM.from_pretrained(model)

          </code></pre>

          '
        raw: "Get Error\r\n\r\nOSError: Unable to load weights from pytorch checkpoint\
          \ file for '/mnt/bd/fazzie-data/models/CodeLlama-7b-hf/pytorch_model-00001-of-00002.bin'\
          \ at '/mnt/bd/fazzie-data/models/CodeLlama-7b-hf/pytorch_model-00001-of-00002.bin'.\
          \ If you tried to load a PyTorch model from a TF 2.0 checkpoint, please\
          \ set from_tf=True.\r\n\r\nHere is the code\r\n\r\n```\r\nfrom transformers\
          \ import AutoTokenizer, AutoModelForCausalLM\r\nimport transformers\r\n\
          import torch\r\n\r\nmodel = \"./models/CodeLlama-7b-hf\"\r\n\r\ntokenizer\
          \ = AutoTokenizer.from_pretrained(model)\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(model)\r\
          \n\r\n```"
        updatedAt: '2023-08-25T08:14:21.533Z'
      numEdits: 0
      reactions: []
    id: 64e862dd0973fdd28a24c0bd
    type: comment
  author: Fazzie
  content: "Get Error\r\n\r\nOSError: Unable to load weights from pytorch checkpoint\
    \ file for '/mnt/bd/fazzie-data/models/CodeLlama-7b-hf/pytorch_model-00001-of-00002.bin'\
    \ at '/mnt/bd/fazzie-data/models/CodeLlama-7b-hf/pytorch_model-00001-of-00002.bin'.\
    \ If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True.\r\
    \n\r\nHere is the code\r\n\r\n```\r\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\r\
    \nimport transformers\r\nimport torch\r\n\r\nmodel = \"./models/CodeLlama-7b-hf\"\
    \r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model)\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(model)\r\
    \n\r\n```"
  created_at: 2023-08-25 07:14:21+00:00
  edited: false
  hidden: false
  id: 64e862dd0973fdd28a24c0bd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2cb4f3cfcf2bc117e40dc90b81ece689.svg
      fullname: Fazzie
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Fazzie
      type: user
    createdAt: '2023-08-25T08:19:46.000Z'
    data:
      edited: false
      editors:
      - Fazzie
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8235275149345398
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2cb4f3cfcf2bc117e40dc90b81ece689.svg
          fullname: Fazzie
          isHf: false
          isPro: false
          name: Fazzie
          type: user
        html: '<p>and I have installed the latest transformers by</p>

          <p>pip install git+<a rel="nofollow" href="https://github.com/huggingface/transformers.git@refs/pull/25740/head">https://github.com/huggingface/transformers.git@refs/pull/25740/head</a>
          accelerate</p>

          '
        raw: 'and I have installed the latest transformers by


          pip install git+https://github.com/huggingface/transformers.git@refs/pull/25740/head
          accelerate

          '
        updatedAt: '2023-08-25T08:19:46.541Z'
      numEdits: 0
      reactions: []
    id: 64e86422db3767299867213f
    type: comment
  author: Fazzie
  content: 'and I have installed the latest transformers by


    pip install git+https://github.com/huggingface/transformers.git@refs/pull/25740/head
    accelerate

    '
  created_at: 2023-08-25 07:19:46+00:00
  edited: false
  hidden: false
  id: 64e86422db3767299867213f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
      fullname: Pedro Cuenca
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: pcuenq
      type: user
    createdAt: '2023-08-25T11:01:24.000Z'
    data:
      edited: false
      editors:
      - pcuenq
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9594203233718872
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
          fullname: Pedro Cuenca
          isHf: true
          isPro: false
          name: pcuenq
          type: user
        html: '<p>You might have downloaded the repo when it was in an incomplete
          state, as we are still making changes to it. Does <code>AutoModelForCausalLM.from_pretrained("codellama/CodeLlama-7b-hf")</code>
          work for you now? It should download the <code>safetensors</code> files
          we recently uploaded.</p>

          '
        raw: You might have downloaded the repo when it was in an incomplete state,
          as we are still making changes to it. Does `AutoModelForCausalLM.from_pretrained("codellama/CodeLlama-7b-hf")`
          work for you now? It should download the `safetensors` files we recently
          uploaded.
        updatedAt: '2023-08-25T11:01:24.301Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - Fazzie
    id: 64e88a041a359d016c0cf83d
    type: comment
  author: pcuenq
  content: You might have downloaded the repo when it was in an incomplete state,
    as we are still making changes to it. Does `AutoModelForCausalLM.from_pretrained("codellama/CodeLlama-7b-hf")`
    work for you now? It should download the `safetensors` files we recently uploaded.
  created_at: 2023-08-25 10:01:24+00:00
  edited: false
  hidden: false
  id: 64e88a041a359d016c0cf83d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6032802e1f993496bc14d9e3/w6hr-DEQot4VVkoyRIBiy.png?w=200&h=200&f=face
      fullname: Omar Sanseviero
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: osanseviero
      type: user
    createdAt: '2023-09-04T07:48:58.000Z'
    data:
      status: closed
    id: 64f58beae8f27f20a063e1fb
    type: status-change
  author: osanseviero
  created_at: 2023-09-04 06:48:58+00:00
  id: 64f58beae8f27f20a063e1fb
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: codellama/CodeLlama-7b-hf
repo_type: model
status: closed
target_branch: null
title: Load model fail
