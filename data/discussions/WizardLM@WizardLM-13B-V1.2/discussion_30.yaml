!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dblakely
conflicting_files: null
created_at: 2024-01-10 22:46:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4953583350c1ba32d7821715add891fe.svg
      fullname: Derrick Blakely
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dblakely
      type: user
    createdAt: '2024-01-10T22:46:08.000Z'
    data:
      edited: false
      editors:
      - dblakely
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6000666618347168
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4953583350c1ba32d7821715add891fe.svg
          fullname: Derrick Blakely
          isHf: false
          isPro: false
          name: dblakely
          type: user
        html: "<p>Hi, when I load the tokenizer for this model, it appears the BOS\
          \ and EOS tokens are the same (both are set to the EOS token). </p>\n<p>Example:</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-meta\">&gt;&gt;&gt;\
          \ </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"\
          hljs-keyword\">import</span> AutoTokenizer\n<span class=\"hljs-meta\">&gt;&gt;&gt;\
          \ </span>model_name = <span class=\"hljs-string\">\"WizardLM/WizardLM-13B-V1.2\"\
          </span>\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)\n\
          <span class=\"hljs-meta\">&gt;&gt;&gt; </span>tokenizer.bos_token\n<span\
          \ class=\"hljs-string\">'&lt;/s&gt;'</span>      <span class=\"hljs-comment\"\
          ># &lt;-- this is the EOS token, not the BOS token</span>\n<span class=\"\
          hljs-meta\">&gt;&gt;&gt; </span>tokenizer.bos_token_id\n<span class=\"hljs-number\"\
          >2</span>\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>tokenizer.eos_token\n\
          <span class=\"hljs-string\">'&lt;/s&gt;'</span>\n<span class=\"hljs-meta\"\
          >&gt;&gt;&gt; </span>tokenizer.eos_token_id\n<span class=\"hljs-number\"\
          >2</span>\n</code></pre>\n<p>You can see this as well when you tokenize\
          \ something:</p>\n<pre><code class=\"language-python\"><span class=\"hljs-meta\"\
          >&gt;&gt;&gt; </span>tokenizer.decode(tokenizer(<span class=\"hljs-string\"\
          >\"This is an input\"</span>).input_ids)\n<span class=\"hljs-string\">'&lt;/s&gt;\
          \ This is an input'</span>\n</code></pre>\n<p>Looking at the <code>special_tokens_map.json</code>\
          \ file, you can see:</p>\n<pre><code class=\"language-json\"><span class=\"\
          hljs-punctuation\">{</span>\n  <span class=\"hljs-attr\">\"bos_token\"</span><span\
          \ class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"&lt;/s&gt;\"\
          </span><span class=\"hljs-punctuation\">,</span>\n  <span class=\"hljs-attr\"\
          >\"eos_token\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"\
          hljs-string\">\"&lt;/s&gt;\"</span><span class=\"hljs-punctuation\">,</span>\n\
          \  <span class=\"hljs-attr\">\"pad_token\"</span><span class=\"hljs-punctuation\"\
          >:</span> <span class=\"hljs-string\">\"&lt;unk&gt;\"</span><span class=\"\
          hljs-punctuation\">,</span>\n  <span class=\"hljs-attr\">\"unk_token\"</span><span\
          \ class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"&lt;/s&gt;\"\
          </span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre>\n<p>Is\
          \ this the typo? The <code>bos_token</code> should be set to <code>\"&lt;s&gt;\"\
          </code> instead should it not?</p>\n"
        raw: "Hi, when I load the tokenizer for this model, it appears the BOS and\
          \ EOS tokens are the same (both are set to the EOS token). \r\n\r\nExample:\r\
          \n```python\r\n>>> from transformers import AutoTokenizer\r\n>>> model_name\
          \ = \"WizardLM/WizardLM-13B-V1.2\"\r\n>>> tokenizer = AutoTokenizer.from_pretrained(model_name)\r\
          \n>>> tokenizer.bos_token\r\n'</s>'      # <-- this is the EOS token, not\
          \ the BOS token\r\n>>> tokenizer.bos_token_id\r\n2\r\n>>> tokenizer.eos_token\r\
          \n'</s>'\r\n>>> tokenizer.eos_token_id\r\n2\r\n```\r\n\r\nYou can see this\
          \ as well when you tokenize something:\r\n```python\r\n>>> tokenizer.decode(tokenizer(\"\
          This is an input\").input_ids)\r\n'</s> This is an input'\r\n```\r\n\r\n\
          Looking at the `special_tokens_map.json` file, you can see:\r\n\r\n```json\r\
          \n{\r\n  \"bos_token\": \"</s>\",\r\n  \"eos_token\": \"</s>\",\r\n  \"\
          pad_token\": \"<unk>\",\r\n  \"unk_token\": \"</s>\"\r\n}\r\n```\r\n\r\n\
          Is this the typo? The `bos_token` should be set to `\"<s>\"` instead should\
          \ it not?"
        updatedAt: '2024-01-10T22:46:08.752Z'
      numEdits: 0
      reactions: []
    id: 659f1e30e98a198ba7e7e10a
    type: comment
  author: dblakely
  content: "Hi, when I load the tokenizer for this model, it appears the BOS and EOS\
    \ tokens are the same (both are set to the EOS token). \r\n\r\nExample:\r\n```python\r\
    \n>>> from transformers import AutoTokenizer\r\n>>> model_name = \"WizardLM/WizardLM-13B-V1.2\"\
    \r\n>>> tokenizer = AutoTokenizer.from_pretrained(model_name)\r\n>>> tokenizer.bos_token\r\
    \n'</s>'      # <-- this is the EOS token, not the BOS token\r\n>>> tokenizer.bos_token_id\r\
    \n2\r\n>>> tokenizer.eos_token\r\n'</s>'\r\n>>> tokenizer.eos_token_id\r\n2\r\n\
    ```\r\n\r\nYou can see this as well when you tokenize something:\r\n```python\r\
    \n>>> tokenizer.decode(tokenizer(\"This is an input\").input_ids)\r\n'</s> This\
    \ is an input'\r\n```\r\n\r\nLooking at the `special_tokens_map.json` file, you\
    \ can see:\r\n\r\n```json\r\n{\r\n  \"bos_token\": \"</s>\",\r\n  \"eos_token\"\
    : \"</s>\",\r\n  \"pad_token\": \"<unk>\",\r\n  \"unk_token\": \"</s>\"\r\n}\r\
    \n```\r\n\r\nIs this the typo? The `bos_token` should be set to `\"<s>\"` instead\
    \ should it not?"
  created_at: 2024-01-10 22:46:08+00:00
  edited: false
  hidden: false
  id: 659f1e30e98a198ba7e7e10a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 30
repo_id: WizardLM/WizardLM-13B-V1.2
repo_type: model
status: open
target_branch: null
title: BOS is actually the EOS token by default
