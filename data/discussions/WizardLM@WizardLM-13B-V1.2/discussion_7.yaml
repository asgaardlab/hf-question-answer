!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Satya93
conflicting_files: null
created_at: 2023-07-29 13:18:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a1f35d36f235ab6987526943c7c51d7a.svg
      fullname: Gordon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Satya93
      type: user
    createdAt: '2023-07-29T14:18:54.000Z'
    data:
      edited: false
      editors:
      - Satya93
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4364579916000366
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a1f35d36f235ab6987526943c7c51d7a.svg
          fullname: Gordon
          isHf: false
          isPro: false
          name: Satya93
          type: user
        html: '<p>I get this error using the newest transformers 4.31.0 on my RTX
          4090. I am loading the model like this:</p>

          <p>tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=False)<br>model
          = AutoModelForCausalLM.from_pretrained(model_dir,torch_dtype=torch.float16,
          low_cpu_mem_usage=True, device_map="auto")</p>

          <p>Any ideas?</p>

          '
        raw: "I get this error using the newest transformers 4.31.0 on my RTX 4090.\
          \ I am loading the model like this:\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model_dir,\
          \ use_fast=False)\r\nmodel = AutoModelForCausalLM.from_pretrained(model_dir,torch_dtype=torch.float16,\
          \ low_cpu_mem_usage=True, device_map=\"auto\")\r\n\r\nAny ideas?"
        updatedAt: '2023-07-29T14:18:54.700Z'
      numEdits: 0
      reactions: []
    id: 64c51fce1d44fc06afd74368
    type: comment
  author: Satya93
  content: "I get this error using the newest transformers 4.31.0 on my RTX 4090.\
    \ I am loading the model like this:\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model_dir,\
    \ use_fast=False)\r\nmodel = AutoModelForCausalLM.from_pretrained(model_dir,torch_dtype=torch.float16,\
    \ low_cpu_mem_usage=True, device_map=\"auto\")\r\n\r\nAny ideas?"
  created_at: 2023-07-29 13:18:54+00:00
  edited: false
  hidden: false
  id: 64c51fce1d44fc06afd74368
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: WizardLM/WizardLM-13B-V1.2
repo_type: model
status: open
target_branch: null
title: 'RuntimeError: probability tensor contains either `inf`, `nan` or element <
  0'
