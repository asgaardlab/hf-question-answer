!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jq460494839
conflicting_files: null
created_at: 2023-11-06 09:04:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6522183194f3a1a209fd3172/ee5r1_yvocbTYxeB139jn.png?w=200&h=200&f=face
      fullname: jq
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jq460494839
      type: user
    createdAt: '2023-11-06T09:04:10.000Z'
    data:
      edited: true
      editors:
      - jq460494839
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.43049120903015137
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6522183194f3a1a209fd3172/ee5r1_yvocbTYxeB139jn.png?w=200&h=200&f=face
          fullname: jq
          isHf: false
          isPro: false
          name: jq460494839
          type: user
        html: "<p>I'm not sure if there's something wrong with the tokenizer and I'm\
          \ getting the WARNING: tokenization mismatch: 501 vs. 503 when fine-tuning\
          \ the model with fastchat. #turn = 1. (ignored)<br>when fine-tuning the\
          \ model with fastchat</p>\n<p>python=3.9<br>transformers=4.34.1<br>fastchat=currently\
          \ master branch</p>\n<p>command\uFF1A<br>torchrun --nproc_per_node=2 --master_port=20001\
          \ fastchat/train/train.py <br>    --model_name_or_path /opt/jq/big_models/Yi-6B/\
          \  <br>    --data_path /opt/jq/nlp_data/evol-instruct-chinese-subset.json\
          \ <br>    --fp16 True <br>    --output_dir output_Yi <br>    --num_train_epochs\
          \ 2 <br>    --per_device_train_batch_size 8 <br>    --per_device_eval_batch_size\
          \ 1 <br>    --gradient_accumulation_steps 1 <br>    --evaluation_strategy\
          \ \"no\" <br>    --save_strategy \"steps\" <br>    --save_steps 2000 <br>\
          \    --save_total_limit 200 <br>    --learning_rate 5e-5 <br>    --weight_decay\
          \ 0. <br>    --lr_scheduler_type \"cosine\" <br>    --logging_steps 1 <br>\
          \    --fsdp \"full_shard auto_wrap\" <br>    --model_max_length 512 <br>\
          \    --gradient_checkpointing True <br>    --lazy_preprocess True</p>\n\
          <p>log\uFF1A<br>WARNING: tokenization mismatch: 501 vs. 503. #turn = 1.\
          \ (ignored)<br>WARNING: tokenization mismatch: 232 vs. 234. #turn = 1. (ignored)<br>WARNING:\
          \ tokenization mismatch: 329 vs. 331. #turn = 1. (ignored)<br>{'loss': 0.0,\
          \ 'learning_rate': 4.9918228349595606e-05, 'epoch': 0.05}<br>  3%|\u258C\
          \                     | 190/7378 [09:17&lt;5:51:33,  2.93s/it]WARNING: tokenization\
          \ mismatch: 288 vs. 290. #turn = 1. (ignored)<br>WARNING: tokenization mismatch:\
          \ 339 vs. 341. #turn = 1. (ignored)<br>WARNING: tokenization mismatch: 300\
          \ vs. 302. #turn = 1. (ignored)<br>WARNING: tokenization mismatch: 274 vs.\
          \ 276. #turn = 1. (ignored)<br>WARNING: tokenization mismatch: 171 vs. 173.\
          \ #turn = 1. (ignored)</p>\n"
        raw: "I'm not sure if there's something wrong with the tokenizer and I'm getting\
          \ the WARNING: tokenization mismatch: 501 vs. 503 when fine-tuning the model\
          \ with fastchat. #turn = 1. (ignored)\nwhen fine-tuning the model with fastchat\n\
          \npython=3.9\ntransformers=4.34.1\nfastchat=currently master branch\n\n\
          command\uFF1A\ntorchrun --nproc_per_node=2 --master_port=20001 fastchat/train/train.py\
          \ \\\n    --model_name_or_path /opt/jq/big_models/Yi-6B/  \\\n    --data_path\
          \ /opt/jq/nlp_data/evol-instruct-chinese-subset.json \\\n    --fp16 True\
          \ \\\n    --output_dir output_Yi \\\n    --num_train_epochs 2 \\\n    --per_device_train_batch_size\
          \ 8 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps\
          \ 1 \\\n    --evaluation_strategy \"no\" \\\n    --save_strategy \"steps\"\
          \ \\\n    --save_steps 2000 \\\n    --save_total_limit 200 \\\n    --learning_rate\
          \ 5e-5 \\\n    --weight_decay 0. \\\n    --lr_scheduler_type \"cosine\"\
          \ \\\n    --logging_steps 1 \\\n    --fsdp \"full_shard auto_wrap\" \\\n\
          \    --model_max_length 512 \\\n    --gradient_checkpointing True \\\n \
          \   --lazy_preprocess True\n\nlog\uFF1A\nWARNING: tokenization mismatch:\
          \ 501 vs. 503. #turn = 1. (ignored)\nWARNING: tokenization mismatch: 232\
          \ vs. 234. #turn = 1. (ignored)\nWARNING: tokenization mismatch: 329 vs.\
          \ 331. #turn = 1. (ignored)\n{'loss': 0.0, 'learning_rate': 4.9918228349595606e-05,\
          \ 'epoch': 0.05}\n  3%|\u258C                     | 190/7378 [09:17<5:51:33,\
          \  2.93s/it]WARNING: tokenization mismatch: 288 vs. 290. #turn = 1. (ignored)\n\
          WARNING: tokenization mismatch: 339 vs. 341. #turn = 1. (ignored)\nWARNING:\
          \ tokenization mismatch: 300 vs. 302. #turn = 1. (ignored)\nWARNING: tokenization\
          \ mismatch: 274 vs. 276. #turn = 1. (ignored)\nWARNING: tokenization mismatch:\
          \ 171 vs. 173. #turn = 1. (ignored)"
        updatedAt: '2023-11-06T09:05:45.387Z'
      numEdits: 1
      reactions: []
    id: 6548ac0a92d9b890bbb4b13d
    type: comment
  author: jq460494839
  content: "I'm not sure if there's something wrong with the tokenizer and I'm getting\
    \ the WARNING: tokenization mismatch: 501 vs. 503 when fine-tuning the model with\
    \ fastchat. #turn = 1. (ignored)\nwhen fine-tuning the model with fastchat\n\n\
    python=3.9\ntransformers=4.34.1\nfastchat=currently master branch\n\ncommand\uFF1A\
    \ntorchrun --nproc_per_node=2 --master_port=20001 fastchat/train/train.py \\\n\
    \    --model_name_or_path /opt/jq/big_models/Yi-6B/  \\\n    --data_path /opt/jq/nlp_data/evol-instruct-chinese-subset.json\
    \ \\\n    --fp16 True \\\n    --output_dir output_Yi \\\n    --num_train_epochs\
    \ 2 \\\n    --per_device_train_batch_size 8 \\\n    --per_device_eval_batch_size\
    \ 1 \\\n    --gradient_accumulation_steps 1 \\\n    --evaluation_strategy \"no\"\
    \ \\\n    --save_strategy \"steps\" \\\n    --save_steps 2000 \\\n    --save_total_limit\
    \ 200 \\\n    --learning_rate 5e-5 \\\n    --weight_decay 0. \\\n    --lr_scheduler_type\
    \ \"cosine\" \\\n    --logging_steps 1 \\\n    --fsdp \"full_shard auto_wrap\"\
    \ \\\n    --model_max_length 512 \\\n    --gradient_checkpointing True \\\n  \
    \  --lazy_preprocess True\n\nlog\uFF1A\nWARNING: tokenization mismatch: 501 vs.\
    \ 503. #turn = 1. (ignored)\nWARNING: tokenization mismatch: 232 vs. 234. #turn\
    \ = 1. (ignored)\nWARNING: tokenization mismatch: 329 vs. 331. #turn = 1. (ignored)\n\
    {'loss': 0.0, 'learning_rate': 4.9918228349595606e-05, 'epoch': 0.05}\n  3%|\u258C\
    \                     | 190/7378 [09:17<5:51:33,  2.93s/it]WARNING: tokenization\
    \ mismatch: 288 vs. 290. #turn = 1. (ignored)\nWARNING: tokenization mismatch:\
    \ 339 vs. 341. #turn = 1. (ignored)\nWARNING: tokenization mismatch: 300 vs. 302.\
    \ #turn = 1. (ignored)\nWARNING: tokenization mismatch: 274 vs. 276. #turn = 1.\
    \ (ignored)\nWARNING: tokenization mismatch: 171 vs. 173. #turn = 1. (ignored)"
  created_at: 2023-11-06 09:04:10+00:00
  edited: true
  hidden: false
  id: 6548ac0a92d9b890bbb4b13d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/WTAS-SnQ_rnriMPGSMkrH.jpeg?w=200&h=200&f=face
      fullname: FancyZhao
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: FancyZhao
      type: user
    createdAt: '2023-11-06T10:32:20.000Z'
    data:
      edited: false
      editors:
      - FancyZhao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9656819105148315
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/WTAS-SnQ_rnriMPGSMkrH.jpeg?w=200&h=200&f=face
          fullname: FancyZhao
          isHf: false
          isPro: false
          name: FancyZhao
          type: user
        html: '<p>Could you post it at <a rel="nofollow" href="https://github.com/01-ai/Yi/issues">https://github.com/01-ai/Yi/issues</a>
          ?<br>Our team member will look into it with you together.</p>

          '
        raw: 'Could you post it at https://github.com/01-ai/Yi/issues ?

          Our team member will look into it with you together.'
        updatedAt: '2023-11-06T10:32:20.297Z'
      numEdits: 0
      reactions: []
    id: 6548c0b4e70ffa3c0753887f
    type: comment
  author: FancyZhao
  content: 'Could you post it at https://github.com/01-ai/Yi/issues ?

    Our team member will look into it with you together.'
  created_at: 2023-11-06 10:32:20+00:00
  edited: false
  hidden: false
  id: 6548c0b4e70ffa3c0753887f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6522183194f3a1a209fd3172/ee5r1_yvocbTYxeB139jn.png?w=200&h=200&f=face
      fullname: jq
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jq460494839
      type: user
    createdAt: '2023-11-06T11:16:48.000Z'
    data:
      edited: true
      editors:
      - jq460494839
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7143703103065491
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6522183194f3a1a209fd3172/ee5r1_yvocbTYxeB139jn.png?w=200&h=200&f=face
          fullname: jq
          isHf: false
          isPro: false
          name: jq460494839
          type: user
        html: "<p>yeah\uFF0Cmay cause by this<br><a rel=\"nofollow\" href=\"https://github.com/01-ai/Yi/issues/24\"\
          >https://github.com/01-ai/Yi/issues/24</a><br>we got the same question</p>\n"
        raw: "yeah\uFF0Cmay cause by this \nhttps://github.com/01-ai/Yi/issues/24\n\
          we got the same question"
        updatedAt: '2023-11-06T11:17:57.810Z'
      numEdits: 1
      reactions: []
    id: 6548cb208db75bfe5dadbbf3
    type: comment
  author: jq460494839
  content: "yeah\uFF0Cmay cause by this \nhttps://github.com/01-ai/Yi/issues/24\n\
    we got the same question"
  created_at: 2023-11-06 11:16:48+00:00
  edited: true
  hidden: false
  id: 6548cb208db75bfe5dadbbf3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/WTAS-SnQ_rnriMPGSMkrH.jpeg?w=200&h=200&f=face
      fullname: FancyZhao
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: FancyZhao
      type: user
    createdAt: '2023-11-16T03:54:06.000Z'
    data:
      status: closed
    id: 6555925ef0cf8603f374810a
    type: status-change
  author: FancyZhao
  created_at: 2023-11-16 03:54:06+00:00
  id: 6555925ef0cf8603f374810a
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: 01-ai/Yi-6B
repo_type: model
status: closed
target_branch: null
title: tokenization mismatch
