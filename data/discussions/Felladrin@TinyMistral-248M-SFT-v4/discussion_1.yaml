!!python/object:huggingface_hub.community.DiscussionWithDetails
author: stormchaser
conflicting_files: null
created_at: 2023-11-18 14:12:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a585cbfcd1f335b70c101458f7c0b002.svg
      fullname: abubakar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: stormchaser
      type: user
    createdAt: '2023-11-18T14:12:16.000Z'
    data:
      edited: false
      editors:
      - stormchaser
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.985007643699646
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a585cbfcd1f335b70c101458f7c0b002.svg
          fullname: abubakar
          isHf: false
          isPro: false
          name: stormchaser
          type: user
        html: '<p>hi! just wanted to know what is this for, what best is it for in
          your opinion? thanks.</p>

          '
        raw: hi! just wanted to know what is this for, what best is it for in your
          opinion? thanks.
        updatedAt: '2023-11-18T14:12:16.859Z'
      numEdits: 0
      reactions: []
    id: 6558c64043c6fb21e491cfb4
    type: comment
  author: stormchaser
  content: hi! just wanted to know what is this for, what best is it for in your opinion?
    thanks.
  created_at: 2023-11-18 14:12:16+00:00
  edited: false
  hidden: false
  id: 6558c64043c6fb21e491cfb4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6454aff9273f649830234978/cvVV08YHJpJx9xWVZqgVW.jpeg?w=200&h=200&f=face
      fullname: Victor Nogueira
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Felladrin
      type: user
    createdAt: '2023-11-18T14:34:24.000Z'
    data:
      edited: true
      editors:
      - Felladrin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9423291087150574
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6454aff9273f649830234978/cvVV08YHJpJx9xWVZqgVW.jpeg?w=200&h=200&f=face
          fullname: Victor Nogueira
          isHf: false
          isPro: false
          name: Felladrin
          type: user
        html: "<p>Thanks for your interest <span data-props=\"{&quot;user&quot;:&quot;stormchaser&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/stormchaser\"\
          >@<span class=\"underline\">stormchaser</span></a></span>\n\n\t</span></span>!</p>\n\
          <p>This one is not good at anything yet, unfortunately. It's just a prototype\
          \ for checking if the base model could be trained to follow instructions.\
          \ But with the small data it was trained, there isn't much to do with it,\
          \ unless confirming that it can be changed to follow instructions. Fortunately,\
          \ I have another version of it under training, that will be more useful.\
          \ (It may finish its training tomorrow)</p>\n<p>The reason behind those\
          \ super-small models is <a rel=\"nofollow\" href=\"https://xenova.github.io/transformers.js\"\
          >https://xenova.github.io/transformers.js</a> - When we run those models\
          \ directly in the browser, we're limited by their format and sizes. So for\
          \ this library in particular, we convert the model to ONNX format, using\
          \ 8-bit quantization, which is still big. To run in a desktop browser, the\
          \ file has to be smaller than 1GB. And to run in a mobile browser, we need\
          \ to keep it under 150MB.</p>\n<p>It's hard to find small text-generation\
          \ models with good outputs, but they exist; check <a href=\"https://huggingface.co/MBZUAI/LaMini-Flan-T5-248M\"\
          >MBZUAI/LaMini-Flan-T5-248M</a>, which is a successful small instruction-tuned\
          \ model. I've been using it in <a href=\"https://huggingface.co/spaces/Felladrin/MiniSearch\"\
          >MiniSearch</a>, for browsers that don't support WebGPU.</p>\n"
        raw: 'Thanks for your interest @stormchaser!


          This one is not good at anything yet, unfortunately. It''s just a prototype
          for checking if the base model could be trained to follow instructions.
          But with the small data it was trained, there isn''t much to do with it,
          unless confirming that it can be changed to follow instructions. Fortunately,
          I have another version of it under training, that will be more useful. (It
          may finish its training tomorrow)


          The reason behind those super-small models is https://xenova.github.io/transformers.js
          - When we run those models directly in the browser, we''re limited by their
          format and sizes. So for this library in particular, we convert the model
          to ONNX format, using 8-bit quantization, which is still big. To run in
          a desktop browser, the file has to be smaller than 1GB. And to run in a
          mobile browser, we need to keep it under 150MB.


          It''s hard to find small text-generation models with good outputs, but they
          exist; check [MBZUAI/LaMini-Flan-T5-248M](https://huggingface.co/MBZUAI/LaMini-Flan-T5-248M),
          which is a successful small instruction-tuned model. I''ve been using it
          in [MiniSearch](https://huggingface.co/spaces/Felladrin/MiniSearch), for
          browsers that don''t support WebGPU.'
        updatedAt: '2023-11-18T15:30:53.450Z'
      numEdits: 3
      reactions:
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - afrideva
        - flexai
        - stormchaser
    id: 6558cb70f6103195fd60c417
    type: comment
  author: Felladrin
  content: 'Thanks for your interest @stormchaser!


    This one is not good at anything yet, unfortunately. It''s just a prototype for
    checking if the base model could be trained to follow instructions. But with the
    small data it was trained, there isn''t much to do with it, unless confirming
    that it can be changed to follow instructions. Fortunately, I have another version
    of it under training, that will be more useful. (It may finish its training tomorrow)


    The reason behind those super-small models is https://xenova.github.io/transformers.js
    - When we run those models directly in the browser, we''re limited by their format
    and sizes. So for this library in particular, we convert the model to ONNX format,
    using 8-bit quantization, which is still big. To run in a desktop browser, the
    file has to be smaller than 1GB. And to run in a mobile browser, we need to keep
    it under 150MB.


    It''s hard to find small text-generation models with good outputs, but they exist;
    check [MBZUAI/LaMini-Flan-T5-248M](https://huggingface.co/MBZUAI/LaMini-Flan-T5-248M),
    which is a successful small instruction-tuned model. I''ve been using it in [MiniSearch](https://huggingface.co/spaces/Felladrin/MiniSearch),
    for browsers that don''t support WebGPU.'
  created_at: 2023-11-18 14:34:24+00:00
  edited: true
  hidden: false
  id: 6558cb70f6103195fd60c417
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6454aff9273f649830234978/cvVV08YHJpJx9xWVZqgVW.jpeg?w=200&h=200&f=face
      fullname: Victor Nogueira
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Felladrin
      type: user
    createdAt: '2023-11-18T14:42:20.000Z'
    data:
      edited: false
      editors:
      - Felladrin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9129480123519897
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6454aff9273f649830234978/cvVV08YHJpJx9xWVZqgVW.jpeg?w=200&h=200&f=face
          fullname: Victor Nogueira
          isHf: false
          isPro: false
          name: Felladrin
          type: user
        html: '<p><a href="https://huggingface.co/Felladrin/llama2_xs_460M_experimental_evol_instruct">Felladrin/llama2_xs_460M_experimental_evol_instruct</a>
          has been published a few hours ago.<br>It has double the size but has been
          trained with a larger instruction dataset.<br>It''s better than TinyMistral-248M-Alpaca,
          if you want to try it.</p>

          '
        raw: '[Felladrin/llama2_xs_460M_experimental_evol_instruct](https://huggingface.co/Felladrin/llama2_xs_460M_experimental_evol_instruct)
          has been published a few hours ago.

          It has double the size but has been trained with a larger instruction dataset.

          It''s better than TinyMistral-248M-Alpaca, if you want to try it.'
        updatedAt: '2023-11-18T14:42:20.614Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - flexai
        - stormchaser
    id: 6558cd4ced8df83128092315
    type: comment
  author: Felladrin
  content: '[Felladrin/llama2_xs_460M_experimental_evol_instruct](https://huggingface.co/Felladrin/llama2_xs_460M_experimental_evol_instruct)
    has been published a few hours ago.

    It has double the size but has been trained with a larger instruction dataset.

    It''s better than TinyMistral-248M-Alpaca, if you want to try it.'
  created_at: 2023-11-18 14:42:20+00:00
  edited: false
  hidden: false
  id: 6558cd4ced8df83128092315
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/YeFyz1AZVcCRsyNHHtwJG.jpeg?w=200&h=200&f=face
      fullname: Sebastian Gabarain
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Locutusque
      type: user
    createdAt: '2023-11-18T18:30:20.000Z'
    data:
      edited: false
      editors:
      - Locutusque
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9815652966499329
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/YeFyz1AZVcCRsyNHHtwJG.jpeg?w=200&h=200&f=face
          fullname: Sebastian Gabarain
          isHf: false
          isPro: false
          name: Locutusque
          type: user
        html: '<p>Hello there!</p>

          <p>I just wanted to share that my intention with the base model (I am the
          creator) was to demonstrate that we don''t absolutely need trillion-scale
          datasets and that language models can be pretrained on a single GPU. Even
          though the model''s performance isn''t quite there yet, I''m optimistic
          that it will get better as more training is done. I think it''ll take about
          another 5 days to wrap up this phase. After that, I''m looking forward to
          fully fine-tuning it on an instruction dataset (possibly a large one). </p>

          '
        raw: 'Hello there!


          I just wanted to share that my intention with the base model (I am the creator)
          was to demonstrate that we don''t absolutely need trillion-scale datasets
          and that language models can be pretrained on a single GPU. Even though
          the model''s performance isn''t quite there yet, I''m optimistic that it
          will get better as more training is done. I think it''ll take about another
          5 days to wrap up this phase. After that, I''m looking forward to fully
          fine-tuning it on an instruction dataset (possibly a large one). '
        updatedAt: '2023-11-18T18:30:20.004Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\u2764\uFE0F"
        users:
        - Felladrin
        - stormchaser
        - Qwoook
        - Sigmally
        - afrideva
    id: 655902bcefc0fb7bed7e443c
    type: comment
  author: Locutusque
  content: 'Hello there!


    I just wanted to share that my intention with the base model (I am the creator)
    was to demonstrate that we don''t absolutely need trillion-scale datasets and
    that language models can be pretrained on a single GPU. Even though the model''s
    performance isn''t quite there yet, I''m optimistic that it will get better as
    more training is done. I think it''ll take about another 5 days to wrap up this
    phase. After that, I''m looking forward to fully fine-tuning it on an instruction
    dataset (possibly a large one). '
  created_at: 2023-11-18 18:30:20+00:00
  edited: false
  hidden: false
  id: 655902bcefc0fb7bed7e443c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a3c7ca5f0292ef711d78f303517db897.svg
      fullname: SirKlabin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sirclavin
      type: user
    createdAt: '2023-11-24T13:52:07.000Z'
    data:
      edited: false
      editors:
      - Sirclavin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9688877463340759
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a3c7ca5f0292ef711d78f303517db897.svg
          fullname: SirKlabin
          isHf: false
          isPro: false
          name: Sirclavin
          type: user
        html: '<p>Great work, keep it up</p>

          '
        raw: 'Great work, keep it up

          '
        updatedAt: '2023-11-24T13:52:07.435Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - stormchaser
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Felladrin
    id: 6560aa8784a9fbe322990b13
    type: comment
  author: Sirclavin
  content: 'Great work, keep it up

    '
  created_at: 2023-11-24 13:52:07+00:00
  edited: false
  hidden: false
  id: 6560aa8784a9fbe322990b13
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6454aff9273f649830234978/cvVV08YHJpJx9xWVZqgVW.jpeg?w=200&h=200&f=face
      fullname: Victor Nogueira
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Felladrin
      type: user
    createdAt: '2023-12-11T19:26:00.000Z'
    data:
      edited: true
      editors:
      - Felladrin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9561523199081421
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6454aff9273f649830234978/cvVV08YHJpJx9xWVZqgVW.jpeg?w=200&h=200&f=face
          fullname: Victor Nogueira
          isHf: false
          isPro: false
          name: Felladrin
          type: user
        html: '<p>Hello everyone!</p>

          <p>Since the content of this discussion is now outdated, I will be closing
          it. However, I suggest that everyone keep an eye on the list of models that
          are derived from TinyMistral-248M, which can be found at <a href="https://huggingface.co/models?other=base_model:Locutusque/TinyMistral-248M">https://huggingface.co/models?other=base_model:Locutusque/TinyMistral-248M</a>.</p>

          <p>I hope to see more and more derivatives, as this model is exceptional
          considering its size!</p>

          '
        raw: 'Hello everyone!


          Since the content of this discussion is now outdated, I will be closing
          it. However, I suggest that everyone keep an eye on the list of models that
          are derived from TinyMistral-248M, which can be found at <https://huggingface.co/models?other=base_model:Locutusque/TinyMistral-248M>.


          I hope to see more and more derivatives, as this model is exceptional considering
          its size!'
        updatedAt: '2023-12-11T20:22:33.498Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - afrideva
        - stormchaser
      relatedEventId: 65776248fa9905f972cae7b1
    id: 65776248fa9905f972cae7ac
    type: comment
  author: Felladrin
  content: 'Hello everyone!


    Since the content of this discussion is now outdated, I will be closing it. However,
    I suggest that everyone keep an eye on the list of models that are derived from
    TinyMistral-248M, which can be found at <https://huggingface.co/models?other=base_model:Locutusque/TinyMistral-248M>.


    I hope to see more and more derivatives, as this model is exceptional considering
    its size!'
  created_at: 2023-12-11 19:26:00+00:00
  edited: true
  hidden: false
  id: 65776248fa9905f972cae7ac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6454aff9273f649830234978/cvVV08YHJpJx9xWVZqgVW.jpeg?w=200&h=200&f=face
      fullname: Victor Nogueira
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Felladrin
      type: user
    createdAt: '2023-12-11T19:26:00.000Z'
    data:
      status: closed
    id: 65776248fa9905f972cae7b1
    type: status-change
  author: Felladrin
  created_at: 2023-12-11 19:26:00+00:00
  id: 65776248fa9905f972cae7b1
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Felladrin/TinyMistral-248M-SFT-v4
repo_type: model
status: closed
target_branch: null
title: whats this for?
