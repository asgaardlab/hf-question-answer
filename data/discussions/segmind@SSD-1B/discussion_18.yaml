!!python/object:huggingface_hub.community.DiscussionWithDetails
author: crapthings
conflicting_files: null
created_at: 2023-10-28 06:51:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ffbed556c373d95be74c2b2daf7ac09d.svg
      fullname: zhang hong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: crapthings
      type: user
    createdAt: '2023-10-28T07:51:54.000Z'
    data:
      edited: false
      editors:
      - crapthings
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4621642529964447
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ffbed556c373d95be74c2b2daf7ac09d.svg
          fullname: zhang hong
          isHf: false
          isPro: false
          name: crapthings
          type: user
        html: "<pre><code>pip install git+https://github.com/huggingface/diffusers\n\
          pip install transformers accelerate safetensors\nfrom diffusers import StableDiffusionXLPipeline\n\
          import torch\npipe = StableDiffusionXLPipeline.from_pretrained(\"segmind/SSD-1B\"\
          , torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\npipe.to(\"\
          cuda\")\n# if using torch &lt; 2.0\n# pipe.enable_xformers_memory_efficient_attention()\n\
          prompt = \"An astronaut riding a green horse\" # Your prompt here\nneg_prompt\
          \ = \"ugly, blurry, poor quality\" # Negative prompt here\nimage = pipe(prompt=prompt,\
          \ negative_prompt=neg_prompt).images[0]\n</code></pre>\n<pre><code>The config\
          \ attributes {'reverse_transformer_layers_per_block': [[4, 4, 10], [2, 1,\
          \ 1], 1]} were passed to UNet2DConditionModel, but are not expected and\
          \ will be ignored. Please verify your config.json configuration file.\n\
          ---------------------------------------------------------------------------\n\
          TypeError                                 Traceback (most recent call last)\n\
          Cell In[13], line 1\n----&gt; 1 pipe = StableDiffusionXLPipeline.from_pretrained(\"\
          segmind/SSD-1B\", torch_dtype=torch.float16, use_safetensors=True, variant=\"\
          fp16\")\n\nFile /opt/conda/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py:1105,\
          \ in DiffusionPipeline.from_pretrained(cls, pretrained_model_name_or_path,\
          \ **kwargs)\n   1102     loaded_sub_model = passed_class_obj[name]\n   1103\
          \ else:\n   1104     # load sub model\n-&gt; 1105     loaded_sub_model =\
          \ load_sub_model(\n   1106         library_name=library_name,\n   1107 \
          \        class_name=class_name,\n   1108         importable_classes=importable_classes,\n\
          \   1109         pipelines=pipelines,\n   1110         is_pipeline_module=is_pipeline_module,\n\
          \   1111         pipeline_class=pipeline_class,\n   1112         torch_dtype=torch_dtype,\n\
          \   1113         provider=provider,\n   1114         sess_options=sess_options,\n\
          \   1115         device_map=device_map,\n   1116         max_memory=max_memory,\n\
          \   1117         offload_folder=offload_folder,\n   1118         offload_state_dict=offload_state_dict,\n\
          \   1119         model_variants=model_variants,\n   1120         name=name,\n\
          \   1121         from_flax=from_flax,\n   1122         variant=variant,\n\
          \   1123         low_cpu_mem_usage=low_cpu_mem_usage,\n   1124         cached_folder=cached_folder,\n\
          \   1125     )\n   1126     logger.info(\n   1127         f\"Loaded {name}\
          \ as {class_name} from `{name}` subfolder of {pretrained_model_name_or_path}.\"\
          \n   1128     )\n   1130 init_kwargs[name] = loaded_sub_model  # UNet(...),\
          \ # DiffusionSchedule(...)\n\nFile /opt/conda/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py:472,\
          \ in load_sub_model(library_name, class_name, importable_classes, pipelines,\
          \ is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options,\
          \ device_map, max_memory, offload_folder, offload_state_dict, model_variants,\
          \ name, from_flax, variant, low_cpu_mem_usage, cached_folder)\n    470 #\
          \ check if the module is in a subdirectory\n    471 if os.path.isdir(os.path.join(cached_folder,\
          \ name)):\n--&gt; 472     loaded_sub_model = load_method(os.path.join(cached_folder,\
          \ name), **loading_kwargs)\n    473 else:\n    474     # else load from\
          \ the root directory\n    475     loaded_sub_model = load_method(cached_folder,\
          \ **loading_kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:636,\
          \ in ModelMixin.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\n\
          \    633 if low_cpu_mem_usage:\n    634     # Instantiate model with empty\
          \ weights\n    635     with accelerate.init_empty_weights():\n--&gt; 636\
          \         model = cls.from_config(config, **unused_kwargs)\n    638    \
          \ # if device_map is None, load the state dict and move the params from\
          \ meta device to the cpu\n    639     if device_map is None:\n\nFile /opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:254,\
          \ in ConfigMixin.from_config(cls, config, return_unused_kwargs, **kwargs)\n\
          \    251         init_dict[deprecated_kwarg] = unused_kwargs.pop(deprecated_kwarg)\n\
          \    253 # Return model and optionally state and/or unused_kwargs\n--&gt;\
          \ 254 model = cls(**init_dict)\n    256 # make sure to also save config\
          \ parameters that might be used for compatible classes\n    257 model.register_to_config(**hidden_dict)\n\
          \nFile /opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:636,\
          \ in register_to_config.&lt;locals&gt;.inner_init(self, *args, **kwargs)\n\
          \    634 new_kwargs = {**config_init_kwargs, **new_kwargs}\n    635 getattr(self,\
          \ \"register_to_config\")(**new_kwargs)\n--&gt; 636 init(self, *args, **init_kwargs)\n\
          \nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/unet_2d_condition.py:440,\
          \ in UNet2DConditionModel.__init__(self, sample_size, in_channels, out_channels,\
          \ center_input_sample, flip_sin_to_cos, freq_shift, down_block_types, mid_block_type,\
          \ up_block_types, only_cross_attention, block_out_channels, layers_per_block,\
          \ downsample_padding, mid_block_scale_factor, dropout, act_fn, norm_num_groups,\
          \ norm_eps, cross_attention_dim, transformer_layers_per_block, encoder_hid_dim,\
          \ encoder_hid_dim_type, attention_head_dim, num_attention_heads, dual_cross_attention,\
          \ use_linear_projection, class_embed_type, addition_embed_type, addition_time_embed_dim,\
          \ num_class_embeds, upcast_attention, resnet_time_scale_shift, resnet_skip_time_act,\
          \ resnet_out_scale_factor, time_embedding_type, time_embedding_dim, time_embedding_act_fn,\
          \ timestep_post_act, time_cond_proj_dim, conv_in_kernel, conv_out_kernel,\
          \ projection_class_embeddings_input_dim, attention_type, class_embeddings_concat,\
          \ mid_block_only_cross_attention, cross_attention_norm, addition_embed_type_num_heads)\n\
          \    437     output_channel = block_out_channels[i]\n    438     is_final_block\
          \ = i == len(block_out_channels) - 1\n--&gt; 440     down_block = get_down_block(\n\
          \    441         down_block_type,\n    442         num_layers=layers_per_block[i],\n\
          \    443         transformer_layers_per_block=transformer_layers_per_block[i],\n\
          \    444         in_channels=input_channel,\n    445         out_channels=output_channel,\n\
          \    446         temb_channels=blocks_time_embed_dim,\n    447         add_downsample=not\
          \ is_final_block,\n    448         resnet_eps=norm_eps,\n    449       \
          \  resnet_act_fn=act_fn,\n    450         resnet_groups=norm_num_groups,\n\
          \    451         cross_attention_dim=cross_attention_dim[i],\n    452  \
          \       num_attention_heads=num_attention_heads[i],\n    453         downsample_padding=downsample_padding,\n\
          \    454         dual_cross_attention=dual_cross_attention,\n    455   \
          \      use_linear_projection=use_linear_projection,\n    456         only_cross_attention=only_cross_attention[i],\n\
          \    457         upcast_attention=upcast_attention,\n    458         resnet_time_scale_shift=resnet_time_scale_shift,\n\
          \    459         attention_type=attention_type,\n    460         resnet_skip_time_act=resnet_skip_time_act,\n\
          \    461         resnet_out_scale_factor=resnet_out_scale_factor,\n    462\
          \         cross_attention_norm=cross_attention_norm,\n    463         attention_head_dim=attention_head_dim[i]\
          \ if attention_head_dim[i] is not None else output_channel,\n    464   \
          \      dropout=dropout,\n    465     )\n    466     self.down_blocks.append(down_block)\n\
          \    468 # mid\n\nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py:119,\
          \ in get_down_block(down_block_type, num_layers, in_channels, out_channels,\
          \ temb_channels, add_downsample, resnet_eps, resnet_act_fn, transformer_layers_per_block,\
          \ num_attention_heads, resnet_groups, cross_attention_dim, downsample_padding,\
          \ dual_cross_attention, use_linear_projection, only_cross_attention, upcast_attention,\
          \ resnet_time_scale_shift, attention_type, resnet_skip_time_act, resnet_out_scale_factor,\
          \ cross_attention_norm, attention_head_dim, downsample_type, dropout)\n\
          \    117     if cross_attention_dim is None:\n    118         raise ValueError(\"\
          cross_attention_dim must be specified for CrossAttnDownBlock2D\")\n--&gt;\
          \ 119     return CrossAttnDownBlock2D(\n    120         num_layers=num_layers,\n\
          \    121         transformer_layers_per_block=transformer_layers_per_block,\n\
          \    122         in_channels=in_channels,\n    123         out_channels=out_channels,\n\
          \    124         temb_channels=temb_channels,\n    125         dropout=dropout,\n\
          \    126         add_downsample=add_downsample,\n    127         resnet_eps=resnet_eps,\n\
          \    128         resnet_act_fn=resnet_act_fn,\n    129         resnet_groups=resnet_groups,\n\
          \    130         downsample_padding=downsample_padding,\n    131       \
          \  cross_attention_dim=cross_attention_dim,\n    132         num_attention_heads=num_attention_heads,\n\
          \    133         dual_cross_attention=dual_cross_attention,\n    134   \
          \      use_linear_projection=use_linear_projection,\n    135         only_cross_attention=only_cross_attention,\n\
          \    136         upcast_attention=upcast_attention,\n    137         resnet_time_scale_shift=resnet_time_scale_shift,\n\
          \    138         attention_type=attention_type,\n    139     )\n    140\
          \ elif down_block_type == \"SimpleCrossAttnDownBlock2D\":\n    141     if\
          \ cross_attention_dim is None:\n\nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py:1001,\
          \ in CrossAttnDownBlock2D.__init__(self, in_channels, out_channels, temb_channels,\
          \ dropout, num_layers, transformer_layers_per_block, resnet_eps, resnet_time_scale_shift,\
          \ resnet_act_fn, resnet_groups, resnet_pre_norm, num_attention_heads, cross_attention_dim,\
          \ output_scale_factor, downsample_padding, add_downsample, dual_cross_attention,\
          \ use_linear_projection, only_cross_attention, upcast_attention, attention_type)\n\
          \    985 resnets.append(\n    986     ResnetBlock2D(\n    987         in_channels=in_channels,\n\
          \   (...)\n    997     )\n    998 )\n    999 if not dual_cross_attention:\n\
          \   1000     attentions.append(\n-&gt; 1001         Transformer2DModel(\n\
          \   1002             num_attention_heads,\n   1003             out_channels\
          \ // num_attention_heads,\n   1004             in_channels=out_channels,\n\
          \   1005             num_layers=transformer_layers_per_block,\n   1006 \
          \            cross_attention_dim=cross_attention_dim,\n   1007         \
          \    norm_num_groups=resnet_groups,\n   1008             use_linear_projection=use_linear_projection,\n\
          \   1009             only_cross_attention=only_cross_attention,\n   1010\
          \             upcast_attention=upcast_attention,\n   1011             attention_type=attention_type,\n\
          \   1012         )\n   1013     )\n   1014 else:\n   1015     attentions.append(\n\
          \   1016         DualTransformer2DModel(\n   1017             num_attention_heads,\n\
          \   (...)\n   1023         )\n   1024     )\n\nFile /opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:636,\
          \ in register_to_config.&lt;locals&gt;.inner_init(self, *args, **kwargs)\n\
          \    634 new_kwargs = {**config_init_kwargs, **new_kwargs}\n    635 getattr(self,\
          \ \"register_to_config\")(**new_kwargs)\n--&gt; 636 init(self, *args, **init_kwargs)\n\
          \nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/transformer_2d.py:191,\
          \ in Transformer2DModel.__init__(self, num_attention_heads, attention_head_dim,\
          \ in_channels, out_channels, num_layers, dropout, norm_num_groups, cross_attention_dim,\
          \ attention_bias, sample_size, num_vector_embeds, patch_size, activation_fn,\
          \ num_embeds_ada_norm, use_linear_projection, only_cross_attention, double_self_attention,\
          \ upcast_attention, norm_type, norm_elementwise_affine, attention_type)\n\
          \    164     self.pos_embed = PatchEmbed(\n    165         height=sample_size,\n\
          \    166         width=sample_size,\n   (...)\n    169         embed_dim=inner_dim,\n\
          \    170     )\n    172 # 3. Define transformers blocks\n    173 self.transformer_blocks\
          \ = nn.ModuleList(\n    174     [\n    175         BasicTransformerBlock(\n\
          \    176             inner_dim,\n    177             num_attention_heads,\n\
          \    178             attention_head_dim,\n    179             dropout=dropout,\n\
          \    180             cross_attention_dim=cross_attention_dim,\n    181 \
          \            activation_fn=activation_fn,\n    182             num_embeds_ada_norm=num_embeds_ada_norm,\n\
          \    183             attention_bias=attention_bias,\n    184           \
          \  only_cross_attention=only_cross_attention,\n    185             double_self_attention=double_self_attention,\n\
          \    186             upcast_attention=upcast_attention,\n    187       \
          \      norm_type=norm_type,\n    188             norm_elementwise_affine=norm_elementwise_affine,\n\
          \    189             attention_type=attention_type,\n    190         )\n\
          --&gt; 191         for d in range(num_layers)\n    192     ]\n    193 )\n\
          \    195 # 4. Define output layers\n    196 self.out_channels = in_channels\
          \ if out_channels is None else out_channels\n\nTypeError: 'list' object\
          \ cannot be interpreted as an integer\n</code></pre>\n"
        raw: "```\r\npip install git+https://github.com/huggingface/diffusers\r\n\
          pip install transformers accelerate safetensors\r\nfrom diffusers import\
          \ StableDiffusionXLPipeline\r\nimport torch\r\npipe = StableDiffusionXLPipeline.from_pretrained(\"\
          segmind/SSD-1B\", torch_dtype=torch.float16, use_safetensors=True, variant=\"\
          fp16\")\r\npipe.to(\"cuda\")\r\n# if using torch < 2.0\r\n# pipe.enable_xformers_memory_efficient_attention()\r\
          \nprompt = \"An astronaut riding a green horse\" # Your prompt here\r\n\
          neg_prompt = \"ugly, blurry, poor quality\" # Negative prompt here\r\nimage\
          \ = pipe(prompt=prompt, negative_prompt=neg_prompt).images[0]\r\n```\r\n\
          \r\n\r\n```\r\nThe config attributes {'reverse_transformer_layers_per_block':\
          \ [[4, 4, 10], [2, 1, 1], 1]} were passed to UNet2DConditionModel, but are\
          \ not expected and will be ignored. Please verify your config.json configuration\
          \ file.\r\n---------------------------------------------------------------------------\r\
          \nTypeError                                 Traceback (most recent call\
          \ last)\r\nCell In[13], line 1\r\n----> 1 pipe = StableDiffusionXLPipeline.from_pretrained(\"\
          segmind/SSD-1B\", torch_dtype=torch.float16, use_safetensors=True, variant=\"\
          fp16\")\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py:1105,\
          \ in DiffusionPipeline.from_pretrained(cls, pretrained_model_name_or_path,\
          \ **kwargs)\r\n   1102     loaded_sub_model = passed_class_obj[name]\r\n\
          \   1103 else:\r\n   1104     # load sub model\r\n-> 1105     loaded_sub_model\
          \ = load_sub_model(\r\n   1106         library_name=library_name,\r\n  \
          \ 1107         class_name=class_name,\r\n   1108         importable_classes=importable_classes,\r\
          \n   1109         pipelines=pipelines,\r\n   1110         is_pipeline_module=is_pipeline_module,\r\
          \n   1111         pipeline_class=pipeline_class,\r\n   1112         torch_dtype=torch_dtype,\r\
          \n   1113         provider=provider,\r\n   1114         sess_options=sess_options,\r\
          \n   1115         device_map=device_map,\r\n   1116         max_memory=max_memory,\r\
          \n   1117         offload_folder=offload_folder,\r\n   1118         offload_state_dict=offload_state_dict,\r\
          \n   1119         model_variants=model_variants,\r\n   1120         name=name,\r\
          \n   1121         from_flax=from_flax,\r\n   1122         variant=variant,\r\
          \n   1123         low_cpu_mem_usage=low_cpu_mem_usage,\r\n   1124      \
          \   cached_folder=cached_folder,\r\n   1125     )\r\n   1126     logger.info(\r\
          \n   1127         f\"Loaded {name} as {class_name} from `{name}` subfolder\
          \ of {pretrained_model_name_or_path}.\"\r\n   1128     )\r\n   1130 init_kwargs[name]\
          \ = loaded_sub_model  # UNet(...), # DiffusionSchedule(...)\r\n\r\nFile\
          \ /opt/conda/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py:472,\
          \ in load_sub_model(library_name, class_name, importable_classes, pipelines,\
          \ is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options,\
          \ device_map, max_memory, offload_folder, offload_state_dict, model_variants,\
          \ name, from_flax, variant, low_cpu_mem_usage, cached_folder)\r\n    470\
          \ # check if the module is in a subdirectory\r\n    471 if os.path.isdir(os.path.join(cached_folder,\
          \ name)):\r\n--> 472     loaded_sub_model = load_method(os.path.join(cached_folder,\
          \ name), **loading_kwargs)\r\n    473 else:\r\n    474     # else load from\
          \ the root directory\r\n    475     loaded_sub_model = load_method(cached_folder,\
          \ **loading_kwargs)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:636,\
          \ in ModelMixin.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\r\
          \n    633 if low_cpu_mem_usage:\r\n    634     # Instantiate model with\
          \ empty weights\r\n    635     with accelerate.init_empty_weights():\r\n\
          --> 636         model = cls.from_config(config, **unused_kwargs)\r\n   \
          \ 638     # if device_map is None, load the state dict and move the params\
          \ from meta device to the cpu\r\n    639     if device_map is None:\r\n\r\
          \nFile /opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:254,\
          \ in ConfigMixin.from_config(cls, config, return_unused_kwargs, **kwargs)\r\
          \n    251         init_dict[deprecated_kwarg] = unused_kwargs.pop(deprecated_kwarg)\r\
          \n    253 # Return model and optionally state and/or unused_kwargs\r\n-->\
          \ 254 model = cls(**init_dict)\r\n    256 # make sure to also save config\
          \ parameters that might be used for compatible classes\r\n    257 model.register_to_config(**hidden_dict)\r\
          \n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:636,\
          \ in register_to_config.<locals>.inner_init(self, *args, **kwargs)\r\n \
          \   634 new_kwargs = {**config_init_kwargs, **new_kwargs}\r\n    635 getattr(self,\
          \ \"register_to_config\")(**new_kwargs)\r\n--> 636 init(self, *args, **init_kwargs)\r\
          \n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/unet_2d_condition.py:440,\
          \ in UNet2DConditionModel.__init__(self, sample_size, in_channels, out_channels,\
          \ center_input_sample, flip_sin_to_cos, freq_shift, down_block_types, mid_block_type,\
          \ up_block_types, only_cross_attention, block_out_channels, layers_per_block,\
          \ downsample_padding, mid_block_scale_factor, dropout, act_fn, norm_num_groups,\
          \ norm_eps, cross_attention_dim, transformer_layers_per_block, encoder_hid_dim,\
          \ encoder_hid_dim_type, attention_head_dim, num_attention_heads, dual_cross_attention,\
          \ use_linear_projection, class_embed_type, addition_embed_type, addition_time_embed_dim,\
          \ num_class_embeds, upcast_attention, resnet_time_scale_shift, resnet_skip_time_act,\
          \ resnet_out_scale_factor, time_embedding_type, time_embedding_dim, time_embedding_act_fn,\
          \ timestep_post_act, time_cond_proj_dim, conv_in_kernel, conv_out_kernel,\
          \ projection_class_embeddings_input_dim, attention_type, class_embeddings_concat,\
          \ mid_block_only_cross_attention, cross_attention_norm, addition_embed_type_num_heads)\r\
          \n    437     output_channel = block_out_channels[i]\r\n    438     is_final_block\
          \ = i == len(block_out_channels) - 1\r\n--> 440     down_block = get_down_block(\r\
          \n    441         down_block_type,\r\n    442         num_layers=layers_per_block[i],\r\
          \n    443         transformer_layers_per_block=transformer_layers_per_block[i],\r\
          \n    444         in_channels=input_channel,\r\n    445         out_channels=output_channel,\r\
          \n    446         temb_channels=blocks_time_embed_dim,\r\n    447      \
          \   add_downsample=not is_final_block,\r\n    448         resnet_eps=norm_eps,\r\
          \n    449         resnet_act_fn=act_fn,\r\n    450         resnet_groups=norm_num_groups,\r\
          \n    451         cross_attention_dim=cross_attention_dim[i],\r\n    452\
          \         num_attention_heads=num_attention_heads[i],\r\n    453       \
          \  downsample_padding=downsample_padding,\r\n    454         dual_cross_attention=dual_cross_attention,\r\
          \n    455         use_linear_projection=use_linear_projection,\r\n    456\
          \         only_cross_attention=only_cross_attention[i],\r\n    457     \
          \    upcast_attention=upcast_attention,\r\n    458         resnet_time_scale_shift=resnet_time_scale_shift,\r\
          \n    459         attention_type=attention_type,\r\n    460         resnet_skip_time_act=resnet_skip_time_act,\r\
          \n    461         resnet_out_scale_factor=resnet_out_scale_factor,\r\n \
          \   462         cross_attention_norm=cross_attention_norm,\r\n    463  \
          \       attention_head_dim=attention_head_dim[i] if attention_head_dim[i]\
          \ is not None else output_channel,\r\n    464         dropout=dropout,\r\
          \n    465     )\r\n    466     self.down_blocks.append(down_block)\r\n \
          \   468 # mid\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py:119,\
          \ in get_down_block(down_block_type, num_layers, in_channels, out_channels,\
          \ temb_channels, add_downsample, resnet_eps, resnet_act_fn, transformer_layers_per_block,\
          \ num_attention_heads, resnet_groups, cross_attention_dim, downsample_padding,\
          \ dual_cross_attention, use_linear_projection, only_cross_attention, upcast_attention,\
          \ resnet_time_scale_shift, attention_type, resnet_skip_time_act, resnet_out_scale_factor,\
          \ cross_attention_norm, attention_head_dim, downsample_type, dropout)\r\n\
          \    117     if cross_attention_dim is None:\r\n    118         raise ValueError(\"\
          cross_attention_dim must be specified for CrossAttnDownBlock2D\")\r\n-->\
          \ 119     return CrossAttnDownBlock2D(\r\n    120         num_layers=num_layers,\r\
          \n    121         transformer_layers_per_block=transformer_layers_per_block,\r\
          \n    122         in_channels=in_channels,\r\n    123         out_channels=out_channels,\r\
          \n    124         temb_channels=temb_channels,\r\n    125         dropout=dropout,\r\
          \n    126         add_downsample=add_downsample,\r\n    127         resnet_eps=resnet_eps,\r\
          \n    128         resnet_act_fn=resnet_act_fn,\r\n    129         resnet_groups=resnet_groups,\r\
          \n    130         downsample_padding=downsample_padding,\r\n    131    \
          \     cross_attention_dim=cross_attention_dim,\r\n    132         num_attention_heads=num_attention_heads,\r\
          \n    133         dual_cross_attention=dual_cross_attention,\r\n    134\
          \         use_linear_projection=use_linear_projection,\r\n    135      \
          \   only_cross_attention=only_cross_attention,\r\n    136         upcast_attention=upcast_attention,\r\
          \n    137         resnet_time_scale_shift=resnet_time_scale_shift,\r\n \
          \   138         attention_type=attention_type,\r\n    139     )\r\n    140\
          \ elif down_block_type == \"SimpleCrossAttnDownBlock2D\":\r\n    141   \
          \  if cross_attention_dim is None:\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py:1001,\
          \ in CrossAttnDownBlock2D.__init__(self, in_channels, out_channels, temb_channels,\
          \ dropout, num_layers, transformer_layers_per_block, resnet_eps, resnet_time_scale_shift,\
          \ resnet_act_fn, resnet_groups, resnet_pre_norm, num_attention_heads, cross_attention_dim,\
          \ output_scale_factor, downsample_padding, add_downsample, dual_cross_attention,\
          \ use_linear_projection, only_cross_attention, upcast_attention, attention_type)\r\
          \n    985 resnets.append(\r\n    986     ResnetBlock2D(\r\n    987     \
          \    in_channels=in_channels,\r\n   (...)\r\n    997     )\r\n    998 )\r\
          \n    999 if not dual_cross_attention:\r\n   1000     attentions.append(\r\
          \n-> 1001         Transformer2DModel(\r\n   1002             num_attention_heads,\r\
          \n   1003             out_channels // num_attention_heads,\r\n   1004  \
          \           in_channels=out_channels,\r\n   1005             num_layers=transformer_layers_per_block,\r\
          \n   1006             cross_attention_dim=cross_attention_dim,\r\n   1007\
          \             norm_num_groups=resnet_groups,\r\n   1008             use_linear_projection=use_linear_projection,\r\
          \n   1009             only_cross_attention=only_cross_attention,\r\n   1010\
          \             upcast_attention=upcast_attention,\r\n   1011            \
          \ attention_type=attention_type,\r\n   1012         )\r\n   1013     )\r\
          \n   1014 else:\r\n   1015     attentions.append(\r\n   1016         DualTransformer2DModel(\r\
          \n   1017             num_attention_heads,\r\n   (...)\r\n   1023      \
          \   )\r\n   1024     )\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:636,\
          \ in register_to_config.<locals>.inner_init(self, *args, **kwargs)\r\n \
          \   634 new_kwargs = {**config_init_kwargs, **new_kwargs}\r\n    635 getattr(self,\
          \ \"register_to_config\")(**new_kwargs)\r\n--> 636 init(self, *args, **init_kwargs)\r\
          \n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/transformer_2d.py:191,\
          \ in Transformer2DModel.__init__(self, num_attention_heads, attention_head_dim,\
          \ in_channels, out_channels, num_layers, dropout, norm_num_groups, cross_attention_dim,\
          \ attention_bias, sample_size, num_vector_embeds, patch_size, activation_fn,\
          \ num_embeds_ada_norm, use_linear_projection, only_cross_attention, double_self_attention,\
          \ upcast_attention, norm_type, norm_elementwise_affine, attention_type)\r\
          \n    164     self.pos_embed = PatchEmbed(\r\n    165         height=sample_size,\r\
          \n    166         width=sample_size,\r\n   (...)\r\n    169         embed_dim=inner_dim,\r\
          \n    170     )\r\n    172 # 3. Define transformers blocks\r\n    173 self.transformer_blocks\
          \ = nn.ModuleList(\r\n    174     [\r\n    175         BasicTransformerBlock(\r\
          \n    176             inner_dim,\r\n    177             num_attention_heads,\r\
          \n    178             attention_head_dim,\r\n    179             dropout=dropout,\r\
          \n    180             cross_attention_dim=cross_attention_dim,\r\n    181\
          \             activation_fn=activation_fn,\r\n    182             num_embeds_ada_norm=num_embeds_ada_norm,\r\
          \n    183             attention_bias=attention_bias,\r\n    184        \
          \     only_cross_attention=only_cross_attention,\r\n    185            \
          \ double_self_attention=double_self_attention,\r\n    186             upcast_attention=upcast_attention,\r\
          \n    187             norm_type=norm_type,\r\n    188             norm_elementwise_affine=norm_elementwise_affine,\r\
          \n    189             attention_type=attention_type,\r\n    190        \
          \ )\r\n--> 191         for d in range(num_layers)\r\n    192     ]\r\n \
          \   193 )\r\n    195 # 4. Define output layers\r\n    196 self.out_channels\
          \ = in_channels if out_channels is None else out_channels\r\n\r\nTypeError:\
          \ 'list' object cannot be interpreted as an integer\r\n```"
        updatedAt: '2023-10-28T07:51:54.808Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - eycab
    id: 653cbd9a8a67c542eed5a643
    type: comment
  author: crapthings
  content: "```\r\npip install git+https://github.com/huggingface/diffusers\r\npip\
    \ install transformers accelerate safetensors\r\nfrom diffusers import StableDiffusionXLPipeline\r\
    \nimport torch\r\npipe = StableDiffusionXLPipeline.from_pretrained(\"segmind/SSD-1B\"\
    , torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\r\npipe.to(\"\
    cuda\")\r\n# if using torch < 2.0\r\n# pipe.enable_xformers_memory_efficient_attention()\r\
    \nprompt = \"An astronaut riding a green horse\" # Your prompt here\r\nneg_prompt\
    \ = \"ugly, blurry, poor quality\" # Negative prompt here\r\nimage = pipe(prompt=prompt,\
    \ negative_prompt=neg_prompt).images[0]\r\n```\r\n\r\n\r\n```\r\nThe config attributes\
    \ {'reverse_transformer_layers_per_block': [[4, 4, 10], [2, 1, 1], 1]} were passed\
    \ to UNet2DConditionModel, but are not expected and will be ignored. Please verify\
    \ your config.json configuration file.\r\n---------------------------------------------------------------------------\r\
    \nTypeError                                 Traceback (most recent call last)\r\
    \nCell In[13], line 1\r\n----> 1 pipe = StableDiffusionXLPipeline.from_pretrained(\"\
    segmind/SSD-1B\", torch_dtype=torch.float16, use_safetensors=True, variant=\"\
    fp16\")\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py:1105,\
    \ in DiffusionPipeline.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\r\
    \n   1102     loaded_sub_model = passed_class_obj[name]\r\n   1103 else:\r\n \
    \  1104     # load sub model\r\n-> 1105     loaded_sub_model = load_sub_model(\r\
    \n   1106         library_name=library_name,\r\n   1107         class_name=class_name,\r\
    \n   1108         importable_classes=importable_classes,\r\n   1109         pipelines=pipelines,\r\
    \n   1110         is_pipeline_module=is_pipeline_module,\r\n   1111         pipeline_class=pipeline_class,\r\
    \n   1112         torch_dtype=torch_dtype,\r\n   1113         provider=provider,\r\
    \n   1114         sess_options=sess_options,\r\n   1115         device_map=device_map,\r\
    \n   1116         max_memory=max_memory,\r\n   1117         offload_folder=offload_folder,\r\
    \n   1118         offload_state_dict=offload_state_dict,\r\n   1119         model_variants=model_variants,\r\
    \n   1120         name=name,\r\n   1121         from_flax=from_flax,\r\n   1122\
    \         variant=variant,\r\n   1123         low_cpu_mem_usage=low_cpu_mem_usage,\r\
    \n   1124         cached_folder=cached_folder,\r\n   1125     )\r\n   1126   \
    \  logger.info(\r\n   1127         f\"Loaded {name} as {class_name} from `{name}`\
    \ subfolder of {pretrained_model_name_or_path}.\"\r\n   1128     )\r\n   1130\
    \ init_kwargs[name] = loaded_sub_model  # UNet(...), # DiffusionSchedule(...)\r\
    \n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py:472,\
    \ in load_sub_model(library_name, class_name, importable_classes, pipelines, is_pipeline_module,\
    \ pipeline_class, torch_dtype, provider, sess_options, device_map, max_memory,\
    \ offload_folder, offload_state_dict, model_variants, name, from_flax, variant,\
    \ low_cpu_mem_usage, cached_folder)\r\n    470 # check if the module is in a subdirectory\r\
    \n    471 if os.path.isdir(os.path.join(cached_folder, name)):\r\n--> 472    \
    \ loaded_sub_model = load_method(os.path.join(cached_folder, name), **loading_kwargs)\r\
    \n    473 else:\r\n    474     # else load from the root directory\r\n    475\
    \     loaded_sub_model = load_method(cached_folder, **loading_kwargs)\r\n\r\n\
    File /opt/conda/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:636,\
    \ in ModelMixin.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\r\
    \n    633 if low_cpu_mem_usage:\r\n    634     # Instantiate model with empty\
    \ weights\r\n    635     with accelerate.init_empty_weights():\r\n--> 636    \
    \     model = cls.from_config(config, **unused_kwargs)\r\n    638     # if device_map\
    \ is None, load the state dict and move the params from meta device to the cpu\r\
    \n    639     if device_map is None:\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:254,\
    \ in ConfigMixin.from_config(cls, config, return_unused_kwargs, **kwargs)\r\n\
    \    251         init_dict[deprecated_kwarg] = unused_kwargs.pop(deprecated_kwarg)\r\
    \n    253 # Return model and optionally state and/or unused_kwargs\r\n--> 254\
    \ model = cls(**init_dict)\r\n    256 # make sure to also save config parameters\
    \ that might be used for compatible classes\r\n    257 model.register_to_config(**hidden_dict)\r\
    \n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:636,\
    \ in register_to_config.<locals>.inner_init(self, *args, **kwargs)\r\n    634\
    \ new_kwargs = {**config_init_kwargs, **new_kwargs}\r\n    635 getattr(self, \"\
    register_to_config\")(**new_kwargs)\r\n--> 636 init(self, *args, **init_kwargs)\r\
    \n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/unet_2d_condition.py:440,\
    \ in UNet2DConditionModel.__init__(self, sample_size, in_channels, out_channels,\
    \ center_input_sample, flip_sin_to_cos, freq_shift, down_block_types, mid_block_type,\
    \ up_block_types, only_cross_attention, block_out_channels, layers_per_block,\
    \ downsample_padding, mid_block_scale_factor, dropout, act_fn, norm_num_groups,\
    \ norm_eps, cross_attention_dim, transformer_layers_per_block, encoder_hid_dim,\
    \ encoder_hid_dim_type, attention_head_dim, num_attention_heads, dual_cross_attention,\
    \ use_linear_projection, class_embed_type, addition_embed_type, addition_time_embed_dim,\
    \ num_class_embeds, upcast_attention, resnet_time_scale_shift, resnet_skip_time_act,\
    \ resnet_out_scale_factor, time_embedding_type, time_embedding_dim, time_embedding_act_fn,\
    \ timestep_post_act, time_cond_proj_dim, conv_in_kernel, conv_out_kernel, projection_class_embeddings_input_dim,\
    \ attention_type, class_embeddings_concat, mid_block_only_cross_attention, cross_attention_norm,\
    \ addition_embed_type_num_heads)\r\n    437     output_channel = block_out_channels[i]\r\
    \n    438     is_final_block = i == len(block_out_channels) - 1\r\n--> 440   \
    \  down_block = get_down_block(\r\n    441         down_block_type,\r\n    442\
    \         num_layers=layers_per_block[i],\r\n    443         transformer_layers_per_block=transformer_layers_per_block[i],\r\
    \n    444         in_channels=input_channel,\r\n    445         out_channels=output_channel,\r\
    \n    446         temb_channels=blocks_time_embed_dim,\r\n    447         add_downsample=not\
    \ is_final_block,\r\n    448         resnet_eps=norm_eps,\r\n    449         resnet_act_fn=act_fn,\r\
    \n    450         resnet_groups=norm_num_groups,\r\n    451         cross_attention_dim=cross_attention_dim[i],\r\
    \n    452         num_attention_heads=num_attention_heads[i],\r\n    453     \
    \    downsample_padding=downsample_padding,\r\n    454         dual_cross_attention=dual_cross_attention,\r\
    \n    455         use_linear_projection=use_linear_projection,\r\n    456    \
    \     only_cross_attention=only_cross_attention[i],\r\n    457         upcast_attention=upcast_attention,\r\
    \n    458         resnet_time_scale_shift=resnet_time_scale_shift,\r\n    459\
    \         attention_type=attention_type,\r\n    460         resnet_skip_time_act=resnet_skip_time_act,\r\
    \n    461         resnet_out_scale_factor=resnet_out_scale_factor,\r\n    462\
    \         cross_attention_norm=cross_attention_norm,\r\n    463         attention_head_dim=attention_head_dim[i]\
    \ if attention_head_dim[i] is not None else output_channel,\r\n    464       \
    \  dropout=dropout,\r\n    465     )\r\n    466     self.down_blocks.append(down_block)\r\
    \n    468 # mid\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py:119,\
    \ in get_down_block(down_block_type, num_layers, in_channels, out_channels, temb_channels,\
    \ add_downsample, resnet_eps, resnet_act_fn, transformer_layers_per_block, num_attention_heads,\
    \ resnet_groups, cross_attention_dim, downsample_padding, dual_cross_attention,\
    \ use_linear_projection, only_cross_attention, upcast_attention, resnet_time_scale_shift,\
    \ attention_type, resnet_skip_time_act, resnet_out_scale_factor, cross_attention_norm,\
    \ attention_head_dim, downsample_type, dropout)\r\n    117     if cross_attention_dim\
    \ is None:\r\n    118         raise ValueError(\"cross_attention_dim must be specified\
    \ for CrossAttnDownBlock2D\")\r\n--> 119     return CrossAttnDownBlock2D(\r\n\
    \    120         num_layers=num_layers,\r\n    121         transformer_layers_per_block=transformer_layers_per_block,\r\
    \n    122         in_channels=in_channels,\r\n    123         out_channels=out_channels,\r\
    \n    124         temb_channels=temb_channels,\r\n    125         dropout=dropout,\r\
    \n    126         add_downsample=add_downsample,\r\n    127         resnet_eps=resnet_eps,\r\
    \n    128         resnet_act_fn=resnet_act_fn,\r\n    129         resnet_groups=resnet_groups,\r\
    \n    130         downsample_padding=downsample_padding,\r\n    131         cross_attention_dim=cross_attention_dim,\r\
    \n    132         num_attention_heads=num_attention_heads,\r\n    133        \
    \ dual_cross_attention=dual_cross_attention,\r\n    134         use_linear_projection=use_linear_projection,\r\
    \n    135         only_cross_attention=only_cross_attention,\r\n    136      \
    \   upcast_attention=upcast_attention,\r\n    137         resnet_time_scale_shift=resnet_time_scale_shift,\r\
    \n    138         attention_type=attention_type,\r\n    139     )\r\n    140 elif\
    \ down_block_type == \"SimpleCrossAttnDownBlock2D\":\r\n    141     if cross_attention_dim\
    \ is None:\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py:1001,\
    \ in CrossAttnDownBlock2D.__init__(self, in_channels, out_channels, temb_channels,\
    \ dropout, num_layers, transformer_layers_per_block, resnet_eps, resnet_time_scale_shift,\
    \ resnet_act_fn, resnet_groups, resnet_pre_norm, num_attention_heads, cross_attention_dim,\
    \ output_scale_factor, downsample_padding, add_downsample, dual_cross_attention,\
    \ use_linear_projection, only_cross_attention, upcast_attention, attention_type)\r\
    \n    985 resnets.append(\r\n    986     ResnetBlock2D(\r\n    987         in_channels=in_channels,\r\
    \n   (...)\r\n    997     )\r\n    998 )\r\n    999 if not dual_cross_attention:\r\
    \n   1000     attentions.append(\r\n-> 1001         Transformer2DModel(\r\n  \
    \ 1002             num_attention_heads,\r\n   1003             out_channels //\
    \ num_attention_heads,\r\n   1004             in_channels=out_channels,\r\n  \
    \ 1005             num_layers=transformer_layers_per_block,\r\n   1006       \
    \      cross_attention_dim=cross_attention_dim,\r\n   1007             norm_num_groups=resnet_groups,\r\
    \n   1008             use_linear_projection=use_linear_projection,\r\n   1009\
    \             only_cross_attention=only_cross_attention,\r\n   1010          \
    \   upcast_attention=upcast_attention,\r\n   1011             attention_type=attention_type,\r\
    \n   1012         )\r\n   1013     )\r\n   1014 else:\r\n   1015     attentions.append(\r\
    \n   1016         DualTransformer2DModel(\r\n   1017             num_attention_heads,\r\
    \n   (...)\r\n   1023         )\r\n   1024     )\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:636,\
    \ in register_to_config.<locals>.inner_init(self, *args, **kwargs)\r\n    634\
    \ new_kwargs = {**config_init_kwargs, **new_kwargs}\r\n    635 getattr(self, \"\
    register_to_config\")(**new_kwargs)\r\n--> 636 init(self, *args, **init_kwargs)\r\
    \n\r\nFile /opt/conda/lib/python3.10/site-packages/diffusers/models/transformer_2d.py:191,\
    \ in Transformer2DModel.__init__(self, num_attention_heads, attention_head_dim,\
    \ in_channels, out_channels, num_layers, dropout, norm_num_groups, cross_attention_dim,\
    \ attention_bias, sample_size, num_vector_embeds, patch_size, activation_fn, num_embeds_ada_norm,\
    \ use_linear_projection, only_cross_attention, double_self_attention, upcast_attention,\
    \ norm_type, norm_elementwise_affine, attention_type)\r\n    164     self.pos_embed\
    \ = PatchEmbed(\r\n    165         height=sample_size,\r\n    166         width=sample_size,\r\
    \n   (...)\r\n    169         embed_dim=inner_dim,\r\n    170     )\r\n    172\
    \ # 3. Define transformers blocks\r\n    173 self.transformer_blocks = nn.ModuleList(\r\
    \n    174     [\r\n    175         BasicTransformerBlock(\r\n    176         \
    \    inner_dim,\r\n    177             num_attention_heads,\r\n    178       \
    \      attention_head_dim,\r\n    179             dropout=dropout,\r\n    180\
    \             cross_attention_dim=cross_attention_dim,\r\n    181            \
    \ activation_fn=activation_fn,\r\n    182             num_embeds_ada_norm=num_embeds_ada_norm,\r\
    \n    183             attention_bias=attention_bias,\r\n    184             only_cross_attention=only_cross_attention,\r\
    \n    185             double_self_attention=double_self_attention,\r\n    186\
    \             upcast_attention=upcast_attention,\r\n    187             norm_type=norm_type,\r\
    \n    188             norm_elementwise_affine=norm_elementwise_affine,\r\n   \
    \ 189             attention_type=attention_type,\r\n    190         )\r\n--> 191\
    \         for d in range(num_layers)\r\n    192     ]\r\n    193 )\r\n    195\
    \ # 4. Define output layers\r\n    196 self.out_channels = in_channels if out_channels\
    \ is None else out_channels\r\n\r\nTypeError: 'list' object cannot be interpreted\
    \ as an integer\r\n```"
  created_at: 2023-10-28 06:51:54+00:00
  edited: false
  hidden: false
  id: 653cbd9a8a67c542eed5a643
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639362039694ec0d025f194d/jmQetjDK3ISH_IQb7SBGC.png?w=200&h=200&f=face
      fullname: Vishnu V Jaddipal
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Icar
      type: user
    createdAt: '2023-10-28T08:03:15.000Z'
    data:
      edited: false
      editors:
      - Icar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7919660210609436
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639362039694ec0d025f194d/jmQetjDK3ISH_IQb7SBGC.png?w=200&h=200&f=face
          fullname: Vishnu V Jaddipal
          isHf: false
          isPro: false
          name: Icar
          type: user
        html: '<p>Please <code>pip uninstall diffusers</code> and then<br><code>pip
          install git+https://github.com/huggingface/diffusers</code></p>

          '
        raw: 'Please ```pip uninstall diffusers``` and then

          ```pip install git+https://github.com/huggingface/diffusers```'
        updatedAt: '2023-10-28T08:03:15.039Z'
      numEdits: 0
      reactions: []
    id: 653cc0436d28265c85a131a4
    type: comment
  author: Icar
  content: 'Please ```pip uninstall diffusers``` and then

    ```pip install git+https://github.com/huggingface/diffusers```'
  created_at: 2023-10-28 07:03:15+00:00
  edited: false
  hidden: false
  id: 653cc0436d28265c85a131a4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bd13b506810b1f325a65519c3f87d5f1.svg
      fullname: eycab
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eycab
      type: user
    createdAt: '2023-10-28T08:07:35.000Z'
    data:
      edited: false
      editors:
      - eycab
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7661435008049011
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bd13b506810b1f325a65519c3f87d5f1.svg
          fullname: eycab
          isHf: false
          isPro: false
          name: eycab
          type: user
        html: '<p>I Tried,but caught the same bug.</p>

          <blockquote>

          <p>Please <code>pip uninstall diffusers</code> and then<br><code>pip install
          git+https://github.com/huggingface/diffusers</code></p>

          </blockquote>

          '
        raw: 'I Tried,but caught the same bug.

          > Please ```pip uninstall diffusers``` and then

          > ```pip install git+https://github.com/huggingface/diffusers```


          '
        updatedAt: '2023-10-28T08:07:35.698Z'
      numEdits: 0
      reactions: []
    id: 653cc147394886efebfbe9eb
    type: comment
  author: eycab
  content: 'I Tried,but caught the same bug.

    > Please ```pip uninstall diffusers``` and then

    > ```pip install git+https://github.com/huggingface/diffusers```


    '
  created_at: 2023-10-28 07:07:35+00:00
  edited: false
  hidden: false
  id: 653cc147394886efebfbe9eb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639362039694ec0d025f194d/jmQetjDK3ISH_IQb7SBGC.png?w=200&h=200&f=face
      fullname: Vishnu V Jaddipal
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Icar
      type: user
    createdAt: '2023-10-28T08:34:19.000Z'
    data:
      edited: false
      editors:
      - Icar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8490338921546936
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639362039694ec0d025f194d/jmQetjDK3ISH_IQb7SBGC.png?w=200&h=200&f=face
          fullname: Vishnu V Jaddipal
          isHf: false
          isPro: false
          name: Icar
          type: user
        html: '<blockquote>

          <p>I Tried,but caught the same bug.</p>

          <blockquote>

          <p>Please <code>pip uninstall diffusers</code> and then<br><code>pip install
          git+https://github.com/huggingface/diffusers</code></p>

          </blockquote>

          </blockquote>

          <p>Very odd. This issue occurs if you are not having the latest source install.
          Could you please check your diffusers version and make sure its  the <code>0.22.0.dev0</code>
          version?</p>

          '
        raw: '> I Tried,but caught the same bug.

          > > Please ```pip uninstall diffusers``` and then

          > > ```pip install git+https://github.com/huggingface/diffusers```


          Very odd. This issue occurs if you are not having the latest source install.
          Could you please check your diffusers version and make sure its  the ```0.22.0.dev0```
          version?'
        updatedAt: '2023-10-28T08:34:19.868Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - eycab
    id: 653cc78b3fc9c706fa5c27bf
    type: comment
  author: Icar
  content: '> I Tried,but caught the same bug.

    > > Please ```pip uninstall diffusers``` and then

    > > ```pip install git+https://github.com/huggingface/diffusers```


    Very odd. This issue occurs if you are not having the latest source install. Could
    you please check your diffusers version and make sure its  the ```0.22.0.dev0```
    version?'
  created_at: 2023-10-28 07:34:19+00:00
  edited: false
  hidden: false
  id: 653cc78b3fc9c706fa5c27bf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bd13b506810b1f325a65519c3f87d5f1.svg
      fullname: eycab
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eycab
      type: user
    createdAt: '2023-10-28T09:30:56.000Z'
    data:
      edited: true
      editors:
      - eycab
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.19902946054935455
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bd13b506810b1f325a65519c3f87d5f1.svg
          fullname: eycab
          isHf: false
          isPro: false
          name: eycab
          type: user
        html: '<p>yes,it is.<br>diffusers                     0.22.0.dev0</p>

          <p>However, after I updated to the newest which is also named 0.22.0.dev0,
          the bug was gone.<br>Thanks for Icar''s regards.</p>

          '
        raw: 'yes,it is.

          diffusers                     0.22.0.dev0


          However, after I updated to the newest which is also named 0.22.0.dev0,
          the bug was gone.

          Thanks for Icar''s regards.'
        updatedAt: '2023-10-28T09:40:54.738Z'
      numEdits: 1
      reactions: []
    id: 653cd4d06d28265c85a34b86
    type: comment
  author: eycab
  content: 'yes,it is.

    diffusers                     0.22.0.dev0


    However, after I updated to the newest which is also named 0.22.0.dev0, the bug
    was gone.

    Thanks for Icar''s regards.'
  created_at: 2023-10-28 08:30:56+00:00
  edited: true
  hidden: false
  id: 653cd4d06d28265c85a34b86
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639362039694ec0d025f194d/jmQetjDK3ISH_IQb7SBGC.png?w=200&h=200&f=face
      fullname: Vishnu V Jaddipal
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Icar
      type: user
    createdAt: '2023-10-28T10:25:18.000Z'
    data:
      edited: false
      editors:
      - Icar
      hidden: false
      identifiedLanguage:
        language: es
        probability: 0.2832965552806854
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639362039694ec0d025f194d/jmQetjDK3ISH_IQb7SBGC.png?w=200&h=200&f=face
          fullname: Vishnu V Jaddipal
          isHf: false
          isPro: false
          name: Icar
          type: user
        html: '<p>No problem!</p>

          '
        raw: No problem!
        updatedAt: '2023-10-28T10:25:18.557Z'
      numEdits: 0
      reactions: []
      relatedEventId: 653ce18e89f7466f2c8ca2be
    id: 653ce18e89f7466f2c8ca2bc
    type: comment
  author: Icar
  content: No problem!
  created_at: 2023-10-28 09:25:18+00:00
  edited: false
  hidden: false
  id: 653ce18e89f7466f2c8ca2bc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639362039694ec0d025f194d/jmQetjDK3ISH_IQb7SBGC.png?w=200&h=200&f=face
      fullname: Vishnu V Jaddipal
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Icar
      type: user
    createdAt: '2023-10-28T10:25:18.000Z'
    data:
      status: closed
    id: 653ce18e89f7466f2c8ca2be
    type: status-change
  author: Icar
  created_at: 2023-10-28 09:25:18+00:00
  id: 653ce18e89f7466f2c8ca2be
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: segmind/SSD-1B
repo_type: model
status: closed
target_branch: null
title: 'TypeError: ''list'' object cannot be interpreted as an integer'
