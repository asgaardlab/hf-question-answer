!!python/object:huggingface_hub.community.DiscussionWithDetails
author: daniel5984
conflicting_files: null
created_at: 2023-10-24 22:09:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668300209549-63061a12d70693fdf1c99376.png?w=200&h=200&f=face
      fullname: Snek
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: daniel5984
      type: user
    createdAt: '2023-10-24T23:09:08.000Z'
    data:
      edited: true
      editors:
      - daniel5984
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5098622441291809
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668300209549-63061a12d70693fdf1c99376.png?w=200&h=200&f=face
          fullname: Snek
          isHf: false
          isPro: false
          name: daniel5984
          type: user
        html: "<p>i get this error when loading</p>\n<p><a rel=\"nofollow\" href=\"\
          https://cdn-uploads.huggingface.co/production/uploads/63061a12d70693fdf1c99376/EjTH1zf58L-yGOBLhE99H.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/63061a12d70693fdf1c99376/EjTH1zf58L-yGOBLhE99H.png\"\
          ></a></p>\n<p>full error</p>\n<pre><code>The config attributes {'reverse_transformer_layers_per_block':\
          \ [[4, 4, 10], [2, 1, 1], 1]} were passed to UNet2DConditionModel, but are\
          \ not expected and will be ignored. Please verify your config.json configuration\
          \ file.\n---------------------------------------------------------------------------\n\
          TypeError                                 Traceback (most recent call last)\n\
          Cell In[17], line 3\n      1 from diffusers import StableDiffusionXLPipeline\n\
          \      2 import torch\n----&gt; 3 pipe = StableDiffusionXLPipeline.from_pretrained(\"\
          segmind/SSD-1B\", torch_dtype=torch.float16, use_safetensors=True, variant=\"\
          fp16\")\n      4 pipe.to(\"cuda\")\n      6 #model_path = \"/notebooks/lora-trained-xl/pytorch_lora_weights.safetensors\"\
          \n      7 #pipe.unet.load_attn_procs(model_path)\n      8 #pipe.to(\"cuda\"\
          )\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py:1105,\
          \ in DiffusionPipeline.from_pretrained(cls, pretrained_model_name_or_path,\
          \ **kwargs)\n   1102     loaded_sub_model = passed_class_obj[name]\n   1103\
          \ else:\n   1104     # load sub model\n-&gt; 1105     loaded_sub_model =\
          \ load_sub_model(\n   1106         library_name=library_name,\n   1107 \
          \        class_name=class_name,\n   1108         importable_classes=importable_classes,\n\
          \   1109         pipelines=pipelines,\n   1110         is_pipeline_module=is_pipeline_module,\n\
          \   1111         pipeline_class=pipeline_class,\n   1112         torch_dtype=torch_dtype,\n\
          \   1113         provider=provider,\n   1114         sess_options=sess_options,\n\
          \   1115         device_map=device_map,\n   1116         max_memory=max_memory,\n\
          \   1117         offload_folder=offload_folder,\n   1118         offload_state_dict=offload_state_dict,\n\
          \   1119         model_variants=model_variants,\n   1120         name=name,\n\
          \   1121         from_flax=from_flax,\n   1122         variant=variant,\n\
          \   1123         low_cpu_mem_usage=low_cpu_mem_usage,\n   1124         cached_folder=cached_folder,\n\
          \   1125     )\n   1126     logger.info(\n   1127         f\"Loaded {name}\
          \ as {class_name} from `{name}` subfolder of {pretrained_model_name_or_path}.\"\
          \n   1128     )\n   1130 init_kwargs[name] = loaded_sub_model  # UNet(...),\
          \ # DiffusionSchedule(...)\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py:472,\
          \ in load_sub_model(library_name, class_name, importable_classes, pipelines,\
          \ is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options,\
          \ device_map, max_memory, offload_folder, offload_state_dict, model_variants,\
          \ name, from_flax, variant, low_cpu_mem_usage, cached_folder)\n    470 #\
          \ check if the module is in a subdirectory\n    471 if os.path.isdir(os.path.join(cached_folder,\
          \ name)):\n--&gt; 472     loaded_sub_model = load_method(os.path.join(cached_folder,\
          \ name), **loading_kwargs)\n    473 else:\n    474     # else load from\
          \ the root directory\n    475     loaded_sub_model = load_method(cached_folder,\
          \ **loading_kwargs)\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/modeling_utils.py:636,\
          \ in ModelMixin.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\n\
          \    633 if low_cpu_mem_usage:\n    634     # Instantiate model with empty\
          \ weights\n    635     with accelerate.init_empty_weights():\n--&gt; 636\
          \         model = cls.from_config(config, **unused_kwargs)\n    638    \
          \ # if device_map is None, load the state dict and move the params from\
          \ meta device to the cpu\n    639     if device_map is None:\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:254,\
          \ in ConfigMixin.from_config(cls, config, return_unused_kwargs, **kwargs)\n\
          \    251         init_dict[deprecated_kwarg] = unused_kwargs.pop(deprecated_kwarg)\n\
          \    253 # Return model and optionally state and/or unused_kwargs\n--&gt;\
          \ 254 model = cls(**init_dict)\n    256 # make sure to also save config\
          \ parameters that might be used for compatible classes\n    257 model.register_to_config(**hidden_dict)\n\
          \nFile /usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:636,\
          \ in register_to_config.&lt;locals&gt;.inner_init(self, *args, **kwargs)\n\
          \    634 new_kwargs = {**config_init_kwargs, **new_kwargs}\n    635 getattr(self,\
          \ \"register_to_config\")(**new_kwargs)\n--&gt; 636 init(self, *args, **init_kwargs)\n\
          \nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/unet_2d_condition.py:440,\
          \ in UNet2DConditionModel.__init__(self, sample_size, in_channels, out_channels,\
          \ center_input_sample, flip_sin_to_cos, freq_shift, down_block_types, mid_block_type,\
          \ up_block_types, only_cross_attention, block_out_channels, layers_per_block,\
          \ downsample_padding, mid_block_scale_factor, dropout, act_fn, norm_num_groups,\
          \ norm_eps, cross_attention_dim, transformer_layers_per_block, encoder_hid_dim,\
          \ encoder_hid_dim_type, attention_head_dim, num_attention_heads, dual_cross_attention,\
          \ use_linear_projection, class_embed_type, addition_embed_type, addition_time_embed_dim,\
          \ num_class_embeds, upcast_attention, resnet_time_scale_shift, resnet_skip_time_act,\
          \ resnet_out_scale_factor, time_embedding_type, time_embedding_dim, time_embedding_act_fn,\
          \ timestep_post_act, time_cond_proj_dim, conv_in_kernel, conv_out_kernel,\
          \ projection_class_embeddings_input_dim, attention_type, class_embeddings_concat,\
          \ mid_block_only_cross_attention, cross_attention_norm, addition_embed_type_num_heads)\n\
          \    437     output_channel = block_out_channels[i]\n    438     is_final_block\
          \ = i == len(block_out_channels) - 1\n--&gt; 440     down_block = get_down_block(\n\
          \    441         down_block_type,\n    442         num_layers=layers_per_block[i],\n\
          \    443         transformer_layers_per_block=transformer_layers_per_block[i],\n\
          \    444         in_channels=input_channel,\n    445         out_channels=output_channel,\n\
          \    446         temb_channels=blocks_time_embed_dim,\n    447         add_downsample=not\
          \ is_final_block,\n    448         resnet_eps=norm_eps,\n    449       \
          \  resnet_act_fn=act_fn,\n    450         resnet_groups=norm_num_groups,\n\
          \    451         cross_attention_dim=cross_attention_dim[i],\n    452  \
          \       num_attention_heads=num_attention_heads[i],\n    453         downsample_padding=downsample_padding,\n\
          \    454         dual_cross_attention=dual_cross_attention,\n    455   \
          \      use_linear_projection=use_linear_projection,\n    456         only_cross_attention=only_cross_attention[i],\n\
          \    457         upcast_attention=upcast_attention,\n    458         resnet_time_scale_shift=resnet_time_scale_shift,\n\
          \    459         attention_type=attention_type,\n    460         resnet_skip_time_act=resnet_skip_time_act,\n\
          \    461         resnet_out_scale_factor=resnet_out_scale_factor,\n    462\
          \         cross_attention_norm=cross_attention_norm,\n    463         attention_head_dim=attention_head_dim[i]\
          \ if attention_head_dim[i] is not None else output_channel,\n    464   \
          \      dropout=dropout,\n    465     )\n    466     self.down_blocks.append(down_block)\n\
          \    468 # mid\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/unet_2d_blocks.py:119,\
          \ in get_down_block(down_block_type, num_layers, in_channels, out_channels,\
          \ temb_channels, add_downsample, resnet_eps, resnet_act_fn, transformer_layers_per_block,\
          \ num_attention_heads, resnet_groups, cross_attention_dim, downsample_padding,\
          \ dual_cross_attention, use_linear_projection, only_cross_attention, upcast_attention,\
          \ resnet_time_scale_shift, attention_type, resnet_skip_time_act, resnet_out_scale_factor,\
          \ cross_attention_norm, attention_head_dim, downsample_type, dropout)\n\
          \    117     if cross_attention_dim is None:\n    118         raise ValueError(\"\
          cross_attention_dim must be specified for CrossAttnDownBlock2D\")\n--&gt;\
          \ 119     return CrossAttnDownBlock2D(\n    120         num_layers=num_layers,\n\
          \    121         transformer_layers_per_block=transformer_layers_per_block,\n\
          \    122         in_channels=in_channels,\n    123         out_channels=out_channels,\n\
          \    124         temb_channels=temb_channels,\n    125         dropout=dropout,\n\
          \    126         add_downsample=add_downsample,\n    127         resnet_eps=resnet_eps,\n\
          \    128         resnet_act_fn=resnet_act_fn,\n    129         resnet_groups=resnet_groups,\n\
          \    130         downsample_padding=downsample_padding,\n    131       \
          \  cross_attention_dim=cross_attention_dim,\n    132         num_attention_heads=num_attention_heads,\n\
          \    133         dual_cross_attention=dual_cross_attention,\n    134   \
          \      use_linear_projection=use_linear_projection,\n    135         only_cross_attention=only_cross_attention,\n\
          \    136         upcast_attention=upcast_attention,\n    137         resnet_time_scale_shift=resnet_time_scale_shift,\n\
          \    138         attention_type=attention_type,\n    139     )\n    140\
          \ elif down_block_type == \"SimpleCrossAttnDownBlock2D\":\n    141     if\
          \ cross_attention_dim is None:\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/unet_2d_blocks.py:1001,\
          \ in CrossAttnDownBlock2D.__init__(self, in_channels, out_channels, temb_channels,\
          \ dropout, num_layers, transformer_layers_per_block, resnet_eps, resnet_time_scale_shift,\
          \ resnet_act_fn, resnet_groups, resnet_pre_norm, num_attention_heads, cross_attention_dim,\
          \ output_scale_factor, downsample_padding, add_downsample, dual_cross_attention,\
          \ use_linear_projection, only_cross_attention, upcast_attention, attention_type)\n\
          \    985 resnets.append(\n    986     ResnetBlock2D(\n    987         in_channels=in_channels,\n\
          \   (...)\n    997     )\n    998 )\n    999 if not dual_cross_attention:\n\
          \   1000     attentions.append(\n-&gt; 1001         Transformer2DModel(\n\
          \   1002             num_attention_heads,\n   1003             out_channels\
          \ // num_attention_heads,\n   1004             in_channels=out_channels,\n\
          \   1005             num_layers=transformer_layers_per_block,\n   1006 \
          \            cross_attention_dim=cross_attention_dim,\n   1007         \
          \    norm_num_groups=resnet_groups,\n   1008             use_linear_projection=use_linear_projection,\n\
          \   1009             only_cross_attention=only_cross_attention,\n   1010\
          \             upcast_attention=upcast_attention,\n   1011             attention_type=attention_type,\n\
          \   1012         )\n   1013     )\n   1014 else:\n   1015     attentions.append(\n\
          \   1016         DualTransformer2DModel(\n   1017             num_attention_heads,\n\
          \   (...)\n   1023         )\n   1024     )\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:636,\
          \ in register_to_config.&lt;locals&gt;.inner_init(self, *args, **kwargs)\n\
          \    634 new_kwargs = {**config_init_kwargs, **new_kwargs}\n    635 getattr(self,\
          \ \"register_to_config\")(**new_kwargs)\n--&gt; 636 init(self, *args, **init_kwargs)\n\
          \nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/transformer_2d.py:191,\
          \ in Transformer2DModel.__init__(self, num_attention_heads, attention_head_dim,\
          \ in_channels, out_channels, num_layers, dropout, norm_num_groups, cross_attention_dim,\
          \ attention_bias, sample_size, num_vector_embeds, patch_size, activation_fn,\
          \ num_embeds_ada_norm, use_linear_projection, only_cross_attention, double_self_attention,\
          \ upcast_attention, norm_type, norm_elementwise_affine, attention_type)\n\
          \    164     self.pos_embed = PatchEmbed(\n    165         height=sample_size,\n\
          \    166         width=sample_size,\n   (...)\n    169         embed_dim=inner_dim,\n\
          \    170     )\n    172 # 3. Define transformers blocks\n    173 self.transformer_blocks\
          \ = nn.ModuleList(\n    174     [\n    175         BasicTransformerBlock(\n\
          \    176             inner_dim,\n    177             num_attention_heads,\n\
          \    178             attention_head_dim,\n    179             dropout=dropout,\n\
          \    180             cross_attention_dim=cross_attention_dim,\n    181 \
          \            activation_fn=activation_fn,\n    182             num_embeds_ada_norm=num_embeds_ada_norm,\n\
          \    183             attention_bias=attention_bias,\n    184           \
          \  only_cross_attention=only_cross_attention,\n    185             double_self_attention=double_self_attention,\n\
          \    186             upcast_attention=upcast_attention,\n    187       \
          \      norm_type=norm_type,\n    188             norm_elementwise_affine=norm_elementwise_affine,\n\
          \    189             attention_type=attention_type,\n    190         )\n\
          --&gt; 191         for d in range(num_layers)\n    192     ]\n    193 )\n\
          \    195 # 4. Define output layers\n    196 self.out_channels = in_channels\
          \ if out_channels is None else out_channels\n\nTypeError: 'list' object\
          \ cannot be interpreted as an integer\n</code></pre>\n"
        raw: "i get this error when loading\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63061a12d70693fdf1c99376/EjTH1zf58L-yGOBLhE99H.png)\n\
          \nfull error\n```\nThe config attributes {'reverse_transformer_layers_per_block':\
          \ [[4, 4, 10], [2, 1, 1], 1]} were passed to UNet2DConditionModel, but are\
          \ not expected and will be ignored. Please verify your config.json configuration\
          \ file.\n---------------------------------------------------------------------------\n\
          TypeError                                 Traceback (most recent call last)\n\
          Cell In[17], line 3\n      1 from diffusers import StableDiffusionXLPipeline\n\
          \      2 import torch\n----> 3 pipe = StableDiffusionXLPipeline.from_pretrained(\"\
          segmind/SSD-1B\", torch_dtype=torch.float16, use_safetensors=True, variant=\"\
          fp16\")\n      4 pipe.to(\"cuda\")\n      6 #model_path = \"/notebooks/lora-trained-xl/pytorch_lora_weights.safetensors\"\
          \n      7 #pipe.unet.load_attn_procs(model_path)\n      8 #pipe.to(\"cuda\"\
          )\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py:1105,\
          \ in DiffusionPipeline.from_pretrained(cls, pretrained_model_name_or_path,\
          \ **kwargs)\n   1102     loaded_sub_model = passed_class_obj[name]\n   1103\
          \ else:\n   1104     # load sub model\n-> 1105     loaded_sub_model = load_sub_model(\n\
          \   1106         library_name=library_name,\n   1107         class_name=class_name,\n\
          \   1108         importable_classes=importable_classes,\n   1109       \
          \  pipelines=pipelines,\n   1110         is_pipeline_module=is_pipeline_module,\n\
          \   1111         pipeline_class=pipeline_class,\n   1112         torch_dtype=torch_dtype,\n\
          \   1113         provider=provider,\n   1114         sess_options=sess_options,\n\
          \   1115         device_map=device_map,\n   1116         max_memory=max_memory,\n\
          \   1117         offload_folder=offload_folder,\n   1118         offload_state_dict=offload_state_dict,\n\
          \   1119         model_variants=model_variants,\n   1120         name=name,\n\
          \   1121         from_flax=from_flax,\n   1122         variant=variant,\n\
          \   1123         low_cpu_mem_usage=low_cpu_mem_usage,\n   1124         cached_folder=cached_folder,\n\
          \   1125     )\n   1126     logger.info(\n   1127         f\"Loaded {name}\
          \ as {class_name} from `{name}` subfolder of {pretrained_model_name_or_path}.\"\
          \n   1128     )\n   1130 init_kwargs[name] = loaded_sub_model  # UNet(...),\
          \ # DiffusionSchedule(...)\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py:472,\
          \ in load_sub_model(library_name, class_name, importable_classes, pipelines,\
          \ is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options,\
          \ device_map, max_memory, offload_folder, offload_state_dict, model_variants,\
          \ name, from_flax, variant, low_cpu_mem_usage, cached_folder)\n    470 #\
          \ check if the module is in a subdirectory\n    471 if os.path.isdir(os.path.join(cached_folder,\
          \ name)):\n--> 472     loaded_sub_model = load_method(os.path.join(cached_folder,\
          \ name), **loading_kwargs)\n    473 else:\n    474     # else load from\
          \ the root directory\n    475     loaded_sub_model = load_method(cached_folder,\
          \ **loading_kwargs)\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/modeling_utils.py:636,\
          \ in ModelMixin.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\n\
          \    633 if low_cpu_mem_usage:\n    634     # Instantiate model with empty\
          \ weights\n    635     with accelerate.init_empty_weights():\n--> 636  \
          \       model = cls.from_config(config, **unused_kwargs)\n    638     #\
          \ if device_map is None, load the state dict and move the params from meta\
          \ device to the cpu\n    639     if device_map is None:\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:254,\
          \ in ConfigMixin.from_config(cls, config, return_unused_kwargs, **kwargs)\n\
          \    251         init_dict[deprecated_kwarg] = unused_kwargs.pop(deprecated_kwarg)\n\
          \    253 # Return model and optionally state and/or unused_kwargs\n--> 254\
          \ model = cls(**init_dict)\n    256 # make sure to also save config parameters\
          \ that might be used for compatible classes\n    257 model.register_to_config(**hidden_dict)\n\
          \nFile /usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:636,\
          \ in register_to_config.<locals>.inner_init(self, *args, **kwargs)\n   \
          \ 634 new_kwargs = {**config_init_kwargs, **new_kwargs}\n    635 getattr(self,\
          \ \"register_to_config\")(**new_kwargs)\n--> 636 init(self, *args, **init_kwargs)\n\
          \nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/unet_2d_condition.py:440,\
          \ in UNet2DConditionModel.__init__(self, sample_size, in_channels, out_channels,\
          \ center_input_sample, flip_sin_to_cos, freq_shift, down_block_types, mid_block_type,\
          \ up_block_types, only_cross_attention, block_out_channels, layers_per_block,\
          \ downsample_padding, mid_block_scale_factor, dropout, act_fn, norm_num_groups,\
          \ norm_eps, cross_attention_dim, transformer_layers_per_block, encoder_hid_dim,\
          \ encoder_hid_dim_type, attention_head_dim, num_attention_heads, dual_cross_attention,\
          \ use_linear_projection, class_embed_type, addition_embed_type, addition_time_embed_dim,\
          \ num_class_embeds, upcast_attention, resnet_time_scale_shift, resnet_skip_time_act,\
          \ resnet_out_scale_factor, time_embedding_type, time_embedding_dim, time_embedding_act_fn,\
          \ timestep_post_act, time_cond_proj_dim, conv_in_kernel, conv_out_kernel,\
          \ projection_class_embeddings_input_dim, attention_type, class_embeddings_concat,\
          \ mid_block_only_cross_attention, cross_attention_norm, addition_embed_type_num_heads)\n\
          \    437     output_channel = block_out_channels[i]\n    438     is_final_block\
          \ = i == len(block_out_channels) - 1\n--> 440     down_block = get_down_block(\n\
          \    441         down_block_type,\n    442         num_layers=layers_per_block[i],\n\
          \    443         transformer_layers_per_block=transformer_layers_per_block[i],\n\
          \    444         in_channels=input_channel,\n    445         out_channels=output_channel,\n\
          \    446         temb_channels=blocks_time_embed_dim,\n    447         add_downsample=not\
          \ is_final_block,\n    448         resnet_eps=norm_eps,\n    449       \
          \  resnet_act_fn=act_fn,\n    450         resnet_groups=norm_num_groups,\n\
          \    451         cross_attention_dim=cross_attention_dim[i],\n    452  \
          \       num_attention_heads=num_attention_heads[i],\n    453         downsample_padding=downsample_padding,\n\
          \    454         dual_cross_attention=dual_cross_attention,\n    455   \
          \      use_linear_projection=use_linear_projection,\n    456         only_cross_attention=only_cross_attention[i],\n\
          \    457         upcast_attention=upcast_attention,\n    458         resnet_time_scale_shift=resnet_time_scale_shift,\n\
          \    459         attention_type=attention_type,\n    460         resnet_skip_time_act=resnet_skip_time_act,\n\
          \    461         resnet_out_scale_factor=resnet_out_scale_factor,\n    462\
          \         cross_attention_norm=cross_attention_norm,\n    463         attention_head_dim=attention_head_dim[i]\
          \ if attention_head_dim[i] is not None else output_channel,\n    464   \
          \      dropout=dropout,\n    465     )\n    466     self.down_blocks.append(down_block)\n\
          \    468 # mid\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/unet_2d_blocks.py:119,\
          \ in get_down_block(down_block_type, num_layers, in_channels, out_channels,\
          \ temb_channels, add_downsample, resnet_eps, resnet_act_fn, transformer_layers_per_block,\
          \ num_attention_heads, resnet_groups, cross_attention_dim, downsample_padding,\
          \ dual_cross_attention, use_linear_projection, only_cross_attention, upcast_attention,\
          \ resnet_time_scale_shift, attention_type, resnet_skip_time_act, resnet_out_scale_factor,\
          \ cross_attention_norm, attention_head_dim, downsample_type, dropout)\n\
          \    117     if cross_attention_dim is None:\n    118         raise ValueError(\"\
          cross_attention_dim must be specified for CrossAttnDownBlock2D\")\n--> 119\
          \     return CrossAttnDownBlock2D(\n    120         num_layers=num_layers,\n\
          \    121         transformer_layers_per_block=transformer_layers_per_block,\n\
          \    122         in_channels=in_channels,\n    123         out_channels=out_channels,\n\
          \    124         temb_channels=temb_channels,\n    125         dropout=dropout,\n\
          \    126         add_downsample=add_downsample,\n    127         resnet_eps=resnet_eps,\n\
          \    128         resnet_act_fn=resnet_act_fn,\n    129         resnet_groups=resnet_groups,\n\
          \    130         downsample_padding=downsample_padding,\n    131       \
          \  cross_attention_dim=cross_attention_dim,\n    132         num_attention_heads=num_attention_heads,\n\
          \    133         dual_cross_attention=dual_cross_attention,\n    134   \
          \      use_linear_projection=use_linear_projection,\n    135         only_cross_attention=only_cross_attention,\n\
          \    136         upcast_attention=upcast_attention,\n    137         resnet_time_scale_shift=resnet_time_scale_shift,\n\
          \    138         attention_type=attention_type,\n    139     )\n    140\
          \ elif down_block_type == \"SimpleCrossAttnDownBlock2D\":\n    141     if\
          \ cross_attention_dim is None:\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/unet_2d_blocks.py:1001,\
          \ in CrossAttnDownBlock2D.__init__(self, in_channels, out_channels, temb_channels,\
          \ dropout, num_layers, transformer_layers_per_block, resnet_eps, resnet_time_scale_shift,\
          \ resnet_act_fn, resnet_groups, resnet_pre_norm, num_attention_heads, cross_attention_dim,\
          \ output_scale_factor, downsample_padding, add_downsample, dual_cross_attention,\
          \ use_linear_projection, only_cross_attention, upcast_attention, attention_type)\n\
          \    985 resnets.append(\n    986     ResnetBlock2D(\n    987         in_channels=in_channels,\n\
          \   (...)\n    997     )\n    998 )\n    999 if not dual_cross_attention:\n\
          \   1000     attentions.append(\n-> 1001         Transformer2DModel(\n \
          \  1002             num_attention_heads,\n   1003             out_channels\
          \ // num_attention_heads,\n   1004             in_channels=out_channels,\n\
          \   1005             num_layers=transformer_layers_per_block,\n   1006 \
          \            cross_attention_dim=cross_attention_dim,\n   1007         \
          \    norm_num_groups=resnet_groups,\n   1008             use_linear_projection=use_linear_projection,\n\
          \   1009             only_cross_attention=only_cross_attention,\n   1010\
          \             upcast_attention=upcast_attention,\n   1011             attention_type=attention_type,\n\
          \   1012         )\n   1013     )\n   1014 else:\n   1015     attentions.append(\n\
          \   1016         DualTransformer2DModel(\n   1017             num_attention_heads,\n\
          \   (...)\n   1023         )\n   1024     )\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:636,\
          \ in register_to_config.<locals>.inner_init(self, *args, **kwargs)\n   \
          \ 634 new_kwargs = {**config_init_kwargs, **new_kwargs}\n    635 getattr(self,\
          \ \"register_to_config\")(**new_kwargs)\n--> 636 init(self, *args, **init_kwargs)\n\
          \nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/transformer_2d.py:191,\
          \ in Transformer2DModel.__init__(self, num_attention_heads, attention_head_dim,\
          \ in_channels, out_channels, num_layers, dropout, norm_num_groups, cross_attention_dim,\
          \ attention_bias, sample_size, num_vector_embeds, patch_size, activation_fn,\
          \ num_embeds_ada_norm, use_linear_projection, only_cross_attention, double_self_attention,\
          \ upcast_attention, norm_type, norm_elementwise_affine, attention_type)\n\
          \    164     self.pos_embed = PatchEmbed(\n    165         height=sample_size,\n\
          \    166         width=sample_size,\n   (...)\n    169         embed_dim=inner_dim,\n\
          \    170     )\n    172 # 3. Define transformers blocks\n    173 self.transformer_blocks\
          \ = nn.ModuleList(\n    174     [\n    175         BasicTransformerBlock(\n\
          \    176             inner_dim,\n    177             num_attention_heads,\n\
          \    178             attention_head_dim,\n    179             dropout=dropout,\n\
          \    180             cross_attention_dim=cross_attention_dim,\n    181 \
          \            activation_fn=activation_fn,\n    182             num_embeds_ada_norm=num_embeds_ada_norm,\n\
          \    183             attention_bias=attention_bias,\n    184           \
          \  only_cross_attention=only_cross_attention,\n    185             double_self_attention=double_self_attention,\n\
          \    186             upcast_attention=upcast_attention,\n    187       \
          \      norm_type=norm_type,\n    188             norm_elementwise_affine=norm_elementwise_affine,\n\
          \    189             attention_type=attention_type,\n    190         )\n\
          --> 191         for d in range(num_layers)\n    192     ]\n    193 )\n \
          \   195 # 4. Define output layers\n    196 self.out_channels = in_channels\
          \ if out_channels is None else out_channels\n\nTypeError: 'list' object\
          \ cannot be interpreted as an integer\n```"
        updatedAt: '2023-10-24T23:13:37.924Z'
      numEdits: 1
      reactions: []
    id: 65384e947439190e9983dadf
    type: comment
  author: daniel5984
  content: "i get this error when loading\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63061a12d70693fdf1c99376/EjTH1zf58L-yGOBLhE99H.png)\n\
    \nfull error\n```\nThe config attributes {'reverse_transformer_layers_per_block':\
    \ [[4, 4, 10], [2, 1, 1], 1]} were passed to UNet2DConditionModel, but are not\
    \ expected and will be ignored. Please verify your config.json configuration file.\n\
    ---------------------------------------------------------------------------\n\
    TypeError                                 Traceback (most recent call last)\n\
    Cell In[17], line 3\n      1 from diffusers import StableDiffusionXLPipeline\n\
    \      2 import torch\n----> 3 pipe = StableDiffusionXLPipeline.from_pretrained(\"\
    segmind/SSD-1B\", torch_dtype=torch.float16, use_safetensors=True, variant=\"\
    fp16\")\n      4 pipe.to(\"cuda\")\n      6 #model_path = \"/notebooks/lora-trained-xl/pytorch_lora_weights.safetensors\"\
    \n      7 #pipe.unet.load_attn_procs(model_path)\n      8 #pipe.to(\"cuda\")\n\
    \nFile /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py:1105,\
    \ in DiffusionPipeline.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\n\
    \   1102     loaded_sub_model = passed_class_obj[name]\n   1103 else:\n   1104\
    \     # load sub model\n-> 1105     loaded_sub_model = load_sub_model(\n   1106\
    \         library_name=library_name,\n   1107         class_name=class_name,\n\
    \   1108         importable_classes=importable_classes,\n   1109         pipelines=pipelines,\n\
    \   1110         is_pipeline_module=is_pipeline_module,\n   1111         pipeline_class=pipeline_class,\n\
    \   1112         torch_dtype=torch_dtype,\n   1113         provider=provider,\n\
    \   1114         sess_options=sess_options,\n   1115         device_map=device_map,\n\
    \   1116         max_memory=max_memory,\n   1117         offload_folder=offload_folder,\n\
    \   1118         offload_state_dict=offload_state_dict,\n   1119         model_variants=model_variants,\n\
    \   1120         name=name,\n   1121         from_flax=from_flax,\n   1122   \
    \      variant=variant,\n   1123         low_cpu_mem_usage=low_cpu_mem_usage,\n\
    \   1124         cached_folder=cached_folder,\n   1125     )\n   1126     logger.info(\n\
    \   1127         f\"Loaded {name} as {class_name} from `{name}` subfolder of {pretrained_model_name_or_path}.\"\
    \n   1128     )\n   1130 init_kwargs[name] = loaded_sub_model  # UNet(...), #\
    \ DiffusionSchedule(...)\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py:472,\
    \ in load_sub_model(library_name, class_name, importable_classes, pipelines, is_pipeline_module,\
    \ pipeline_class, torch_dtype, provider, sess_options, device_map, max_memory,\
    \ offload_folder, offload_state_dict, model_variants, name, from_flax, variant,\
    \ low_cpu_mem_usage, cached_folder)\n    470 # check if the module is in a subdirectory\n\
    \    471 if os.path.isdir(os.path.join(cached_folder, name)):\n--> 472     loaded_sub_model\
    \ = load_method(os.path.join(cached_folder, name), **loading_kwargs)\n    473\
    \ else:\n    474     # else load from the root directory\n    475     loaded_sub_model\
    \ = load_method(cached_folder, **loading_kwargs)\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/modeling_utils.py:636,\
    \ in ModelMixin.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\n\
    \    633 if low_cpu_mem_usage:\n    634     # Instantiate model with empty weights\n\
    \    635     with accelerate.init_empty_weights():\n--> 636         model = cls.from_config(config,\
    \ **unused_kwargs)\n    638     # if device_map is None, load the state dict and\
    \ move the params from meta device to the cpu\n    639     if device_map is None:\n\
    \nFile /usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:254,\
    \ in ConfigMixin.from_config(cls, config, return_unused_kwargs, **kwargs)\n  \
    \  251         init_dict[deprecated_kwarg] = unused_kwargs.pop(deprecated_kwarg)\n\
    \    253 # Return model and optionally state and/or unused_kwargs\n--> 254 model\
    \ = cls(**init_dict)\n    256 # make sure to also save config parameters that\
    \ might be used for compatible classes\n    257 model.register_to_config(**hidden_dict)\n\
    \nFile /usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:636,\
    \ in register_to_config.<locals>.inner_init(self, *args, **kwargs)\n    634 new_kwargs\
    \ = {**config_init_kwargs, **new_kwargs}\n    635 getattr(self, \"register_to_config\"\
    )(**new_kwargs)\n--> 636 init(self, *args, **init_kwargs)\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/unet_2d_condition.py:440,\
    \ in UNet2DConditionModel.__init__(self, sample_size, in_channels, out_channels,\
    \ center_input_sample, flip_sin_to_cos, freq_shift, down_block_types, mid_block_type,\
    \ up_block_types, only_cross_attention, block_out_channels, layers_per_block,\
    \ downsample_padding, mid_block_scale_factor, dropout, act_fn, norm_num_groups,\
    \ norm_eps, cross_attention_dim, transformer_layers_per_block, encoder_hid_dim,\
    \ encoder_hid_dim_type, attention_head_dim, num_attention_heads, dual_cross_attention,\
    \ use_linear_projection, class_embed_type, addition_embed_type, addition_time_embed_dim,\
    \ num_class_embeds, upcast_attention, resnet_time_scale_shift, resnet_skip_time_act,\
    \ resnet_out_scale_factor, time_embedding_type, time_embedding_dim, time_embedding_act_fn,\
    \ timestep_post_act, time_cond_proj_dim, conv_in_kernel, conv_out_kernel, projection_class_embeddings_input_dim,\
    \ attention_type, class_embeddings_concat, mid_block_only_cross_attention, cross_attention_norm,\
    \ addition_embed_type_num_heads)\n    437     output_channel = block_out_channels[i]\n\
    \    438     is_final_block = i == len(block_out_channels) - 1\n--> 440     down_block\
    \ = get_down_block(\n    441         down_block_type,\n    442         num_layers=layers_per_block[i],\n\
    \    443         transformer_layers_per_block=transformer_layers_per_block[i],\n\
    \    444         in_channels=input_channel,\n    445         out_channels=output_channel,\n\
    \    446         temb_channels=blocks_time_embed_dim,\n    447         add_downsample=not\
    \ is_final_block,\n    448         resnet_eps=norm_eps,\n    449         resnet_act_fn=act_fn,\n\
    \    450         resnet_groups=norm_num_groups,\n    451         cross_attention_dim=cross_attention_dim[i],\n\
    \    452         num_attention_heads=num_attention_heads[i],\n    453        \
    \ downsample_padding=downsample_padding,\n    454         dual_cross_attention=dual_cross_attention,\n\
    \    455         use_linear_projection=use_linear_projection,\n    456       \
    \  only_cross_attention=only_cross_attention[i],\n    457         upcast_attention=upcast_attention,\n\
    \    458         resnet_time_scale_shift=resnet_time_scale_shift,\n    459   \
    \      attention_type=attention_type,\n    460         resnet_skip_time_act=resnet_skip_time_act,\n\
    \    461         resnet_out_scale_factor=resnet_out_scale_factor,\n    462   \
    \      cross_attention_norm=cross_attention_norm,\n    463         attention_head_dim=attention_head_dim[i]\
    \ if attention_head_dim[i] is not None else output_channel,\n    464         dropout=dropout,\n\
    \    465     )\n    466     self.down_blocks.append(down_block)\n    468 # mid\n\
    \nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/unet_2d_blocks.py:119,\
    \ in get_down_block(down_block_type, num_layers, in_channels, out_channels, temb_channels,\
    \ add_downsample, resnet_eps, resnet_act_fn, transformer_layers_per_block, num_attention_heads,\
    \ resnet_groups, cross_attention_dim, downsample_padding, dual_cross_attention,\
    \ use_linear_projection, only_cross_attention, upcast_attention, resnet_time_scale_shift,\
    \ attention_type, resnet_skip_time_act, resnet_out_scale_factor, cross_attention_norm,\
    \ attention_head_dim, downsample_type, dropout)\n    117     if cross_attention_dim\
    \ is None:\n    118         raise ValueError(\"cross_attention_dim must be specified\
    \ for CrossAttnDownBlock2D\")\n--> 119     return CrossAttnDownBlock2D(\n    120\
    \         num_layers=num_layers,\n    121         transformer_layers_per_block=transformer_layers_per_block,\n\
    \    122         in_channels=in_channels,\n    123         out_channels=out_channels,\n\
    \    124         temb_channels=temb_channels,\n    125         dropout=dropout,\n\
    \    126         add_downsample=add_downsample,\n    127         resnet_eps=resnet_eps,\n\
    \    128         resnet_act_fn=resnet_act_fn,\n    129         resnet_groups=resnet_groups,\n\
    \    130         downsample_padding=downsample_padding,\n    131         cross_attention_dim=cross_attention_dim,\n\
    \    132         num_attention_heads=num_attention_heads,\n    133         dual_cross_attention=dual_cross_attention,\n\
    \    134         use_linear_projection=use_linear_projection,\n    135       \
    \  only_cross_attention=only_cross_attention,\n    136         upcast_attention=upcast_attention,\n\
    \    137         resnet_time_scale_shift=resnet_time_scale_shift,\n    138   \
    \      attention_type=attention_type,\n    139     )\n    140 elif down_block_type\
    \ == \"SimpleCrossAttnDownBlock2D\":\n    141     if cross_attention_dim is None:\n\
    \nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/unet_2d_blocks.py:1001,\
    \ in CrossAttnDownBlock2D.__init__(self, in_channels, out_channels, temb_channels,\
    \ dropout, num_layers, transformer_layers_per_block, resnet_eps, resnet_time_scale_shift,\
    \ resnet_act_fn, resnet_groups, resnet_pre_norm, num_attention_heads, cross_attention_dim,\
    \ output_scale_factor, downsample_padding, add_downsample, dual_cross_attention,\
    \ use_linear_projection, only_cross_attention, upcast_attention, attention_type)\n\
    \    985 resnets.append(\n    986     ResnetBlock2D(\n    987         in_channels=in_channels,\n\
    \   (...)\n    997     )\n    998 )\n    999 if not dual_cross_attention:\n  \
    \ 1000     attentions.append(\n-> 1001         Transformer2DModel(\n   1002  \
    \           num_attention_heads,\n   1003             out_channels // num_attention_heads,\n\
    \   1004             in_channels=out_channels,\n   1005             num_layers=transformer_layers_per_block,\n\
    \   1006             cross_attention_dim=cross_attention_dim,\n   1007       \
    \      norm_num_groups=resnet_groups,\n   1008             use_linear_projection=use_linear_projection,\n\
    \   1009             only_cross_attention=only_cross_attention,\n   1010     \
    \        upcast_attention=upcast_attention,\n   1011             attention_type=attention_type,\n\
    \   1012         )\n   1013     )\n   1014 else:\n   1015     attentions.append(\n\
    \   1016         DualTransformer2DModel(\n   1017             num_attention_heads,\n\
    \   (...)\n   1023         )\n   1024     )\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:636,\
    \ in register_to_config.<locals>.inner_init(self, *args, **kwargs)\n    634 new_kwargs\
    \ = {**config_init_kwargs, **new_kwargs}\n    635 getattr(self, \"register_to_config\"\
    )(**new_kwargs)\n--> 636 init(self, *args, **init_kwargs)\n\nFile /usr/local/lib/python3.10/dist-packages/diffusers/models/transformer_2d.py:191,\
    \ in Transformer2DModel.__init__(self, num_attention_heads, attention_head_dim,\
    \ in_channels, out_channels, num_layers, dropout, norm_num_groups, cross_attention_dim,\
    \ attention_bias, sample_size, num_vector_embeds, patch_size, activation_fn, num_embeds_ada_norm,\
    \ use_linear_projection, only_cross_attention, double_self_attention, upcast_attention,\
    \ norm_type, norm_elementwise_affine, attention_type)\n    164     self.pos_embed\
    \ = PatchEmbed(\n    165         height=sample_size,\n    166         width=sample_size,\n\
    \   (...)\n    169         embed_dim=inner_dim,\n    170     )\n    172 # 3. Define\
    \ transformers blocks\n    173 self.transformer_blocks = nn.ModuleList(\n    174\
    \     [\n    175         BasicTransformerBlock(\n    176             inner_dim,\n\
    \    177             num_attention_heads,\n    178             attention_head_dim,\n\
    \    179             dropout=dropout,\n    180             cross_attention_dim=cross_attention_dim,\n\
    \    181             activation_fn=activation_fn,\n    182             num_embeds_ada_norm=num_embeds_ada_norm,\n\
    \    183             attention_bias=attention_bias,\n    184             only_cross_attention=only_cross_attention,\n\
    \    185             double_self_attention=double_self_attention,\n    186   \
    \          upcast_attention=upcast_attention,\n    187             norm_type=norm_type,\n\
    \    188             norm_elementwise_affine=norm_elementwise_affine,\n    189\
    \             attention_type=attention_type,\n    190         )\n--> 191     \
    \    for d in range(num_layers)\n    192     ]\n    193 )\n    195 # 4. Define\
    \ output layers\n    196 self.out_channels = in_channels if out_channels is None\
    \ else out_channels\n\nTypeError: 'list' object cannot be interpreted as an integer\n\
    ```"
  created_at: 2023-10-24 22:09:08+00:00
  edited: true
  hidden: false
  id: 65384e947439190e9983dadf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e1c5a40ab1b97014b2303c897aa584e2.svg
      fullname: DanielTan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: danielthx
      type: user
    createdAt: '2023-10-25T00:45:35.000Z'
    data:
      edited: false
      editors:
      - danielthx
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7623562812805176
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e1c5a40ab1b97014b2303c897aa584e2.svg
          fullname: DanielTan
          isHf: false
          isPro: false
          name: danielthx
          type: user
        html: '<p>must use pip install git+<a rel="nofollow" href="https://github.com/huggingface/diffusers">https://github.com/huggingface/diffusers</a><br>cannot
          use pip install diffusers</p>

          '
        raw: 'must use pip install git+https://github.com/huggingface/diffusers

          cannot use pip install diffusers'
        updatedAt: '2023-10-25T00:45:35.693Z'
      numEdits: 0
      reactions: []
    id: 6538652fe0b42ac89d496950
    type: comment
  author: danielthx
  content: 'must use pip install git+https://github.com/huggingface/diffusers

    cannot use pip install diffusers'
  created_at: 2023-10-24 23:45:35+00:00
  edited: false
  hidden: false
  id: 6538652fe0b42ac89d496950
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639362039694ec0d025f194d/jmQetjDK3ISH_IQb7SBGC.png?w=200&h=200&f=face
      fullname: Vishnu V Jaddipal
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Icar
      type: user
    createdAt: '2023-10-25T01:47:36.000Z'
    data:
      edited: false
      editors:
      - Icar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.771486222743988
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639362039694ec0d025f194d/jmQetjDK3ISH_IQb7SBGC.png?w=200&h=200&f=face
          fullname: Vishnu V Jaddipal
          isHf: false
          isPro: false
          name: Icar
          type: user
        html: '<p>Like danielthx says, you must use a diffusers source install.</p>

          <pre><code>pip install git+https://github.com/huggingface/diffusers

          </code></pre>

          '
        raw: 'Like danielthx says, you must use a diffusers source install.

          ```

          pip install git+https://github.com/huggingface/diffusers

          ```'
        updatedAt: '2023-10-25T01:47:36.786Z'
      numEdits: 0
      reactions: []
    id: 653873b86d1c2659e103fbd9
    type: comment
  author: Icar
  content: 'Like danielthx says, you must use a diffusers source install.

    ```

    pip install git+https://github.com/huggingface/diffusers

    ```'
  created_at: 2023-10-25 00:47:36+00:00
  edited: false
  hidden: false
  id: 653873b86d1c2659e103fbd9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639362039694ec0d025f194d/jmQetjDK3ISH_IQb7SBGC.png?w=200&h=200&f=face
      fullname: Vishnu V Jaddipal
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Icar
      type: user
    createdAt: '2023-10-25T13:18:45.000Z'
    data:
      status: closed
    id: 653915b52ddab2beff132935
    type: status-change
  author: Icar
  created_at: 2023-10-25 12:18:45+00:00
  id: 653915b52ddab2beff132935
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: segmind/SSD-1B
repo_type: model
status: closed
target_branch: null
title: diffusers not working
