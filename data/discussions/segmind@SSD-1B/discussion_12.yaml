!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jffacevedo
conflicting_files: null
created_at: 2023-10-26 23:36:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/mtJ2EYlsF1CwKXed7o8TB.jpeg?w=200&h=200&f=face
      fullname: Juan Acevedo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jffacevedo
      type: user
    createdAt: '2023-10-27T00:36:43.000Z'
    data:
      edited: false
      editors:
      - jffacevedo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8979986310005188
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/mtJ2EYlsF1CwKXed7o8TB.jpeg?w=200&h=200&f=face
          fullname: Juan Acevedo
          isHf: false
          isPro: false
          name: jffacevedo
          type: user
        html: '<p>Thanks for this model, it works great!</p>

          <p>Can we create LoRAs with this model? Meaning, will the diffusers LoRA
          training code work with this model?</p>

          '
        raw: "Thanks for this model, it works great!\r\n\r\nCan we create LoRAs with\
          \ this model? Meaning, will the diffusers LoRA training code work with this\
          \ model?"
        updatedAt: '2023-10-27T00:36:43.273Z'
      numEdits: 0
      reactions: []
    id: 653b061b42bfd8801c45869c
    type: comment
  author: jffacevedo
  content: "Thanks for this model, it works great!\r\n\r\nCan we create LoRAs with\
    \ this model? Meaning, will the diffusers LoRA training code work with this model?"
  created_at: 2023-10-26 23:36:43+00:00
  edited: false
  hidden: false
  id: 653b061b42bfd8801c45869c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62f8ca074588fe31f4361dae/F2k343TPD7KVfW3P26IRs.jpeg?w=200&h=200&f=face
      fullname: Yatharth Gupta
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Warlord-K
      type: user
    createdAt: '2023-10-27T02:47:45.000Z'
    data:
      edited: false
      editors:
      - Warlord-K
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8689435720443726
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62f8ca074588fe31f4361dae/F2k343TPD7KVfW3P26IRs.jpeg?w=200&h=200&f=face
          fullname: Yatharth Gupta
          isHf: false
          isPro: false
          name: Warlord-K
          type: user
        html: '<p>Yes, All the Diffusers Training scripts are fully supported with
          SSD-1B!</p>

          '
        raw: Yes, All the Diffusers Training scripts are fully supported with SSD-1B!
        updatedAt: '2023-10-27T02:47:45.624Z'
      numEdits: 0
      reactions: []
    id: 653b24d17721c7df134b5628
    type: comment
  author: Warlord-K
  content: Yes, All the Diffusers Training scripts are fully supported with SSD-1B!
  created_at: 2023-10-27 01:47:45+00:00
  edited: false
  hidden: false
  id: 653b24d17721c7df134b5628
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1732106613b89ea94b3f189bb73349d0.svg
      fullname: tin tin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tintwotin
      type: user
    createdAt: '2023-10-27T08:19:03.000Z'
    data:
      edited: false
      editors:
      - tintwotin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7511448860168457
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1732106613b89ea94b3f189bb73349d0.svg
          fullname: tin tin
          isHf: false
          isPro: false
          name: tintwotin
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;jffacevedo&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/jffacevedo\">@<span class=\"\
          underline\">jffacevedo</span></a></span>\n\n\t</span></span> If you create\
          \ a LoRA for this model, please share it, so I can test if the Diffusers\
          \ LoRA loading code will support loading LoRAs on SSD-1B<br>(I'm on 6 GB\
          \ VRAM and LoRA training is not possible for me)</p>\n"
        raw: '@jffacevedo If you create a LoRA for this model, please share it, so
          I can test if the Diffusers LoRA loading code will support loading LoRAs
          on SSD-1B

          (I''m on 6 GB VRAM and LoRA training is not possible for me)'
        updatedAt: '2023-10-27T08:19:03.982Z'
      numEdits: 0
      reactions: []
    id: 653b727786b88947d5d5a052
    type: comment
  author: tintwotin
  content: '@jffacevedo If you create a LoRA for this model, please share it, so I
    can test if the Diffusers LoRA loading code will support loading LoRAs on SSD-1B

    (I''m on 6 GB VRAM and LoRA training is not possible for me)'
  created_at: 2023-10-27 07:19:03+00:00
  edited: false
  hidden: false
  id: 653b727786b88947d5d5a052
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/mtJ2EYlsF1CwKXed7o8TB.jpeg?w=200&h=200&f=face
      fullname: Juan Acevedo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jffacevedo
      type: user
    createdAt: '2023-10-27T16:34:35.000Z'
    data:
      edited: false
      editors:
      - jffacevedo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.941699206829071
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/mtJ2EYlsF1CwKXed7o8TB.jpeg?w=200&h=200&f=face
          fullname: Juan Acevedo
          isHf: false
          isPro: false
          name: jffacevedo
          type: user
        html: '<p>Thank you, I"ll give it a try and share the results. </p>

          '
        raw: 'Thank you, I"ll give it a try and share the results. '
        updatedAt: '2023-10-27T16:34:35.183Z'
      numEdits: 0
      reactions: []
    id: 653be69be819da8e0b459455
    type: comment
  author: jffacevedo
  content: 'Thank you, I"ll give it a try and share the results. '
  created_at: 2023-10-27 15:34:35+00:00
  edited: false
  hidden: false
  id: 653be69be819da8e0b459455
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62f8ca074588fe31f4361dae/F2k343TPD7KVfW3P26IRs.jpeg?w=200&h=200&f=face
      fullname: Yatharth Gupta
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Warlord-K
      type: user
    createdAt: '2023-11-06T04:25:23.000Z'
    data:
      edited: false
      editors:
      - Warlord-K
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.908394455909729
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62f8ca074588fe31f4361dae/F2k343TPD7KVfW3P26IRs.jpeg?w=200&h=200&f=face
          fullname: Yatharth Gupta
          isHf: false
          isPro: false
          name: Warlord-K
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;jffacevedo&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/jffacevedo\">@<span class=\"\
          underline\">jffacevedo</span></a></span>\n\n\t</span></span> Were you able\
          \ to train the LoRA successfully? </p>\n"
        raw: '@jffacevedo Were you able to train the LoRA successfully? '
        updatedAt: '2023-11-06T04:25:23.600Z'
      numEdits: 0
      reactions: []
    id: 65486ab3470b4b8b3f16a133
    type: comment
  author: Warlord-K
  content: '@jffacevedo Were you able to train the LoRA successfully? '
  created_at: 2023-11-06 04:25:23+00:00
  edited: false
  hidden: false
  id: 65486ab3470b4b8b3f16a133
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/mtJ2EYlsF1CwKXed7o8TB.jpeg?w=200&h=200&f=face
      fullname: Juan Acevedo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jffacevedo
      type: user
    createdAt: '2023-11-07T01:56:31.000Z'
    data:
      edited: false
      editors:
      - jffacevedo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.34987694025039673
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/mtJ2EYlsF1CwKXed7o8TB.jpeg?w=200&h=200&f=face
          fullname: Juan Acevedo
          isHf: false
          isPro: false
          name: jffacevedo
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Warlord-K&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Warlord-K\">@<span class=\"\
          underline\">Warlord-K</span></a></span>\n\n\t</span></span> I was able to\
          \ train successfully, but the validation step of the script failed with\
          \ <code>RuntimeError: Input type (c10::Half) and bias type (float) should\
          \ be the same</code>.  It still saved the checkpoints, here is after 2 epochs.</p>\n\
          <p>With LoRA</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/fC9tcz3lwD4cdXeoz6vqz.png\"\
          ><img alt=\"pokemon_lora.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/fC9tcz3lwD4cdXeoz6vqz.png\"\
          ></a></p>\n<p>Without LoRA</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/8CC8ZueBjEVPOoAkVjwUl.png\"\
          ><img alt=\"pokemon.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/8CC8ZueBjEVPOoAkVjwUl.png\"\
          ></a></p>\n<p>See the full logs below:</p>\n<pre><code class=\"language-bash\"\
          >accelerate launch train_\ntext_to_image_lora_sdxl.py   --pretrained_model_name_or_path=<span\
          \ class=\"hljs-variable\">$MODEL_NAME</span>  --dataset_name=<span class=\"\
          hljs-variable\">$DATASET_NAME</span> \n--caption_column=<span class=\"hljs-string\"\
          >\"text\"</span>   --resolution=1024 --random_flip   --train_batch_size=1\
          \   --num_train_epochs=2\n --checkpointing_steps=500   --learning_rate=1e-04\
          \ --lr_scheduler=<span class=\"hljs-string\">\"constant\"</span> --lr_warmup_steps=0\
          \   --mi\nxed_precision=<span class=\"hljs-string\">\"fp16\"</span>   --seed=42\
          \   --output_dir=<span class=\"hljs-string\">\"sd-pokemon-model-lora-sdxl\"\
          </span>   --validation_prompt=<span class=\"hljs-string\">\"cut</span>\n\
          <span class=\"hljs-string\">e dragon creature\"</span>\nThe following values\
          \ were not passed to `accelerate launch` and had defaults used instead:\n\
          \        `--num_processes` was <span class=\"hljs-built_in\">set</span>\
          \ to a value of `1`\n        `--num_machines` was <span class=\"hljs-built_in\"\
          >set</span> to a value of `1`\n        `--mixed_precision` was <span class=\"\
          hljs-built_in\">set</span> to a value of `<span class=\"hljs-string\">'no'</span>`\n\
          \        `--dynamo_backend` was <span class=\"hljs-built_in\">set</span>\
          \ to a value of `<span class=\"hljs-string\">'no'</span>`\nTo avoid this\
          \ warning pass <span class=\"hljs-keyword\">in</span> values <span class=\"\
          hljs-keyword\">for</span> each of the problematic parameters or run `accelerate\
          \ config`.\n11/07/2023 01:01:10 - INFO - __main__ - Distributed environment:\
          \ NO\nNum processes: 1\nProcess index: 0\nLocal process index: 0\nDevice:\
          \ cuda\n\nMixed precision <span class=\"hljs-built_in\">type</span>: fp16\n\
          \nYou are using a model of <span class=\"hljs-built_in\">type</span> clip_text_model\
          \ to instantiate a model of <span class=\"hljs-built_in\">type</span> .\
          \ This is not supported <span class=\"hljs-keyword\">for</span> all configurations\
          \ of models and can yield errors.\nYou are using a model of <span class=\"\
          hljs-built_in\">type</span> clip_text_model to instantiate a model of <span\
          \ class=\"hljs-built_in\">type</span> . This is not supported <span class=\"\
          hljs-keyword\">for</span> all configurations of models and can yield errors.\n\
          {<span class=\"hljs-string\">'dynamic_thresholding_ratio'</span>, <span\
          \ class=\"hljs-string\">'variance_type'</span>, <span class=\"hljs-string\"\
          >'thresholding'</span>, <span class=\"hljs-string\">'clip_sample_range'</span>}\
          \ was not found <span class=\"hljs-keyword\">in</span> config. Values will\
          \ be initialized to default values.\nDownloading model.safetensors: 100%|\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 492M/492M [00:02&lt;00:00,\
          \ 220MB/s]\nDownloading model.safetensors: 100%|\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588| 2.78G/2.78G [01:10&lt;00:00, 39.7MB/s]\nDownloading (\u2026\
          )ch_model.safetensors: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588| 335M/335M [00:01&lt;00:00, 200MB/s]\n\
          Downloading (\u2026)ch_model.safetensors: 100%|\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.33G/5.33G [00:23&lt;00:00,\
          \ 230MB/s]\n{<span class=\"hljs-string\">'attention_type'</span>, <span\
          \ class=\"hljs-string\">'dropout'</span>} was not found <span class=\"hljs-keyword\"\
          >in</span> config. Values will be initialized to default values.\nDownloading\
          \ readme: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.80k/1.80k [00:00&lt;00:00,\
          \ 11.8MB/s]\nDownloading metadata: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588| 731/731 [00:00&lt;00:00, 5.92MB/s]\nDownloading data: 100%|\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588| 99.7M/99.7M [00:02&lt;00:00, 39.7MB/s]\n\
          Downloading data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          | 1/1 [00:02&lt;00:00,  2.51s/it]\nExtracting data files: 100%|\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00, 1508.74it/s]\nGenerating\
          \ train <span class=\"hljs-built_in\">split</span>: 100%|\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588| 833/833 [00:00&lt;00:00, 2920.80 examples/s]\n\
          11/07/2023 01:03:08 - INFO - __main__ - ***** Running training *****\n11/07/2023\
          \ 01:03:08 - INFO - __main__ -   Num examples = 833\n11/07/2023 01:03:08\
          \ - INFO - __main__ -   Num Epochs = 2\n11/07/2023 01:03:08 - INFO - __main__\
          \ -   Instantaneous batch size per device = 1\n11/07/2023 01:03:08 - INFO\
          \ - __main__ -   Total train batch size (w. parallel, distributed &amp;\
          \ accumulation) = 1\n11/07/2023 01:03:08 - INFO - __main__ -   Gradient\
          \ Accumulation steps = 1\n11/07/2023 01:03:08 - INFO - __main__ -   Total\
          \ optimization steps = 1666\nSteps:  30%|\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588                                         \
          \             | 500/1666 [08:46&lt;20:27,  1.05s/it, lr=0.0001, step_loss=0.00503]11/07/2023\
          \ 01:11:55 - INFO - accelerate.accelerator - Saving current state to sd-pokemon-model-lora-sdxl/checkpoint-500\n\
          Model weights saved <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-500/pytorch_lora_weights.safetensors\n\
          11/07/2023 01:11:55 - INFO - accelerate.checkpointing - Optimizer state\
          \ saved <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-500/optimizer.bin\n\
          11/07/2023 01:11:55 - INFO - accelerate.checkpointing - Scheduler state\
          \ saved <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-500/scheduler.bin\n\
          11/07/2023 01:11:55 - INFO - accelerate.checkpointing - Gradient scaler\
          \ state saved <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-500/scaler.pt\n\
          11/07/2023 01:11:55 - INFO - accelerate.checkpointing - Random states saved\
          \ <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-500/random_states_0.pkl\n\
          11/07/2023 01:11:55 - INFO - __main__ - Saved state to sd-pokemon-model-lora-sdxl/checkpoint-500\n\
          Steps:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u258C                                      | 833/1666\
          \ [14:36&lt;14:27,  1.04s/it, lr=0.0001, step_loss=0.00567]11/07/2023 01:17:45\
          \ - INFO - __main__ - Running validation... \n Generating 4 images with\
          \ prompt: cute dragon creature.\n{<span class=\"hljs-string\">'add_watermarker'</span>}\
          \ was not found <span class=\"hljs-keyword\">in</span> config. Values will\
          \ be initialized to default values.\n                                  \
          \                                                                      \
          \                                                 Loaded scheduler as EulerDiscreteScheduler\
          \ from `scheduler` subfolder of segmind/SSD-1B.                        \
          \                     | 0/7 [00:00&lt;?, ?it/s]\nLoaded tokenizer_2 as CLIPTokenizer\
          \ from `tokenizer_2` subfolder of segmind/SSD-1B.\nLoaded tokenizer as CLIPTokenizer\
          \ from `tokenizer` subfolder of segmind/SSD-1B.\nLoading pipeline components...:\
          \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588| 7/7 [00:00&lt;00:00, 53.80it/s]\nSteps:  60%|\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258A           \
          \                    | 1000/1666 [18:46&lt;11:39,  1.05s/it, lr=0.0001,\
          \ step_loss=0.105]11/07/2023 01:21:55 - INFO - accelerate.accelerator -\
          \ Saving current state to sd-pokemon-model-lora-sdxl/checkpoint-1000\nModel\
          \ weights saved <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-1000/pytorch_lora_weights.safetensors\n\
          11/07/2023 01:21:55 - INFO - accelerate.checkpointing - Optimizer state\
          \ saved <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-1000/optimizer.bin\n\
          11/07/2023 01:21:55 - INFO - accelerate.checkpointing - Scheduler state\
          \ saved <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-1000/scheduler.bin\n\
          11/07/2023 01:21:55 - INFO - accelerate.checkpointing - Gradient scaler\
          \ state saved <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-1000/scaler.pt\n\
          11/07/2023 01:21:55 - INFO - accelerate.checkpointing - Random states saved\
          \ <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-1000/random_states_0.pkl\n\
          11/07/2023 01:21:55 - INFO - __main__ - Saved state to sd-pokemon-model-lora-sdxl/checkpoint-1000\n\
          Steps:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258E\
          \       | 1500/1666 [27:31&lt;02:53,  1.05s/it, lr=0.0001, step_loss=0.0159]11/07/2023\
          \ 01:30:40 - INFO - accelerate.accelerator - Saving current state to sd-pokemon-model-lora-sdxl/checkpoint-1500\n\
          Model weights saved <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-1500/pytorch_lora_weights.safetensors\n\
          11/07/2023 01:30:40 - INFO - accelerate.checkpointing - Optimizer state\
          \ saved <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-1500/optimizer.bin\n\
          11/07/2023 01:30:40 - INFO - accelerate.checkpointing - Scheduler state\
          \ saved <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-1500/scheduler.bin\n\
          11/07/2023 01:30:40 - INFO - accelerate.checkpointing - Gradient scaler\
          \ state saved <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-1500/scaler.pt\n\
          11/07/2023 01:30:40 - INFO - accelerate.checkpointing - Random states saved\
          \ <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/checkpoint-1500/random_states_0.pkl\n\
          11/07/2023 01:30:40 - INFO - __main__ - Saved state to sd-pokemon-model-lora-sdxl/checkpoint-1500\n\
          Steps: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1666/1666 [30:26&lt;00:00,\
          \  1.04s/it, lr=0.0001, step_loss=0.126]11/07/2023 01:33:35 - INFO - __main__\
          \ - Running validation... \n Generating 4 images with prompt: cute dragon\
          \ creature.\n{<span class=\"hljs-string\">'add_watermarker'</span>} was\
          \ not found <span class=\"hljs-keyword\">in</span> config. Values will be\
          \ initialized to default values.\n                                     \
          \                                                                      \
          \                                              Loaded scheduler as EulerDiscreteScheduler\
          \ from `scheduler` subfolder of segmind/SSD-1B.                        \
          \                     | 0/7 [00:00&lt;?, ?it/s]\nLoaded tokenizer_2 as CLIPTokenizer\
          \ from `tokenizer_2` subfolder of segmind/SSD-1B.\nLoaded tokenizer as CLIPTokenizer\
          \ from `tokenizer` subfolder of segmind/SSD-1B.\nLoading pipeline components...:\
          \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588| 7/7 [00:00&lt;00:00, 60.59it/s]\nModel weights\
          \ saved <span class=\"hljs-keyword\">in</span> sd-pokemon-model-lora-sdxl/pytorch_lora_weights.safetensors\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u258C            | 6/7 [00:00&lt;00:00, 52.13it/s]\n\
          {<span class=\"hljs-string\">'add_watermarker'</span>} was not found <span\
          \ class=\"hljs-keyword\">in</span> config. Values will be initialized to\
          \ default values.\n                                                    \
          \                                                                      \
          \                               Loaded scheduler as EulerDiscreteScheduler\
          \ from `scheduler` subfolder of segmind/SSD-1B.                        \
          \                     | 0/7 [00:00&lt;?, ?it/s]\nLoaded text_encoder as\
          \ CLIPTextModel from `text_encoder` subfolder of segmind/SSD-1B.\n     \
          \                                                                      \
          \                                                                      \
          \        Loaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder\
          \ of segmind/SSD-1B.                                          | 3/7 [00:00&lt;00:00,\
          \  9.52it/s]\n{<span class=\"hljs-string\">'attention_type'</span>, <span\
          \ class=\"hljs-string\">'dropout'</span>} was not found <span class=\"hljs-keyword\"\
          >in</span> config. Values will be initialized to default values.\nLoaded\
          \ unet as UNet2DConditionModel from `unet` subfolder of segmind/SSD-1B.\n\
          \                                                                      \
          \                                                                      \
          \             Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder\
          \ of segmind/SSD-1B.\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u258F                        | 5/7 [00:02&lt;00:01,  1.89it/s]\nLoaded\
          \ text_encoder_2 as CLIPTextModelWithProjection from `text_encoder_2` subfolder\
          \ of segmind/SSD-1B.\nLoading pipeline components...: 100%|\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          | 7/7 [00:03&lt;00:00,  1.93it/s]\nLoading unet.ine components...: 100%|\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588| 7/7 [00:03&lt;00:00,  1.69it/s]\n100%|\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588| 25/25 [00:06&lt;00:00,  3.72it/s]\nTraceback\
          \ (most recent call last):\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 25/25 [00:06&lt;00:00,\
          \  3.71it/s]\n  File <span class=\"hljs-string\">\"/home/jfacevedo_google_com/diffusers/examples/text_to_image/train_text_to_image_lora_sdxl.py\"\
          </span>, line 1265, <span class=\"hljs-keyword\">in</span> &lt;module&gt;\n\
          \    main(args)\n  File <span class=\"hljs-string\">\"/home/jfacevedo_google_com/diffusers/examples/text_to_image/train_text_to_image_lora_sdxl.py\"\
          </span>, line 1224, <span class=\"hljs-keyword\">in</span> main\n    images\
          \ = [\n  File <span class=\"hljs-string\">\"/home/jfacevedo_google_com/diffusers/examples/text_to_image/train_text_to_image_lora_sdxl.py\"\
          </span>, line 1225, <span class=\"hljs-keyword\">in</span> &lt;listcomp&gt;\n\
          \    pipeline(args.validation_prompt, num_inference_steps=25, generator=generator).images[0]\n\
          \  File <span class=\"hljs-string\">\"/opt/conda/envs/sdxl/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          </span>, line 115, <span class=\"hljs-keyword\">in</span> decorate_context\n\
          \    <span class=\"hljs-built_in\">return</span> func(*args, **kwargs)\n\
          \  File <span class=\"hljs-string\">\"/opt/conda/envs/sdxl/lib/python3.10/site-packages/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py\"\
          </span>, line 1057, <span class=\"hljs-keyword\">in</span> __call__\n  \
          \  image = self.vae.decode(latents / self.vae.config.scaling_factor, return_dict=False)[0]\n\
          \  File <span class=\"hljs-string\">\"/opt/conda/envs/sdxl/lib/python3.10/site-packages/diffusers/utils/accelerate_utils.py\"\
          </span>, line 46, <span class=\"hljs-keyword\">in</span> wrapper\n    <span\
          \ class=\"hljs-built_in\">return</span> method(self, *args, **kwargs)\n\
          \  File <span class=\"hljs-string\">\"/opt/conda/envs/sdxl/lib/python3.10/site-packages/diffusers/models/autoencoder_kl.py\"\
          </span>, line 316, <span class=\"hljs-keyword\">in</span> decode\n    decoded\
          \ = self._decode(z).sample\n  File <span class=\"hljs-string\">\"/opt/conda/envs/sdxl/lib/python3.10/site-packages/diffusers/models/autoencoder_kl.py\"\
          </span>, line 288, <span class=\"hljs-keyword\">in</span> _decode\n    z\
          \ = self.post_quant_conv(z)\n  File <span class=\"hljs-string\">\"/opt/conda/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          </span>, line 1501, <span class=\"hljs-keyword\">in</span> _call_impl\n\
          \    <span class=\"hljs-built_in\">return</span> forward_call(*args, **kwargs)\n\
          \  File <span class=\"hljs-string\">\"/opt/conda/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/conv.py\"\
          </span>, line 463, <span class=\"hljs-keyword\">in</span> forward\n    <span\
          \ class=\"hljs-built_in\">return</span> self._conv_forward(input, self.weight,\
          \ self.bias)\n  File <span class=\"hljs-string\">\"/opt/conda/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/conv.py\"\
          </span>, line 459, <span class=\"hljs-keyword\">in</span> _conv_forward\n\
          \    <span class=\"hljs-built_in\">return</span> F.conv2d(input, weight,\
          \ bias, self.stride,\nRuntimeError: Input <span class=\"hljs-built_in\"\
          >type</span> (c10::Half) and bias <span class=\"hljs-built_in\">type</span>\
          \ (<span class=\"hljs-built_in\">float</span>) should be the same\nSteps:\
          \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1666/1666 [31:52&lt;00:00, \
          \ 1.15s/it, lr=0.0001, step_loss=0.126]\nTraceback (most recent call last):\n\
          \  File <span class=\"hljs-string\">\"/opt/conda/envs/sdxl/bin/accelerate\"\
          </span>, line 8, <span class=\"hljs-keyword\">in</span> &lt;module&gt;\n\
          \    sys.exit(main())\n  File <span class=\"hljs-string\">\"/opt/conda/envs/sdxl/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\"\
          </span>, line 45, <span class=\"hljs-keyword\">in</span> main\n    args.func(args)\n\
          \  File <span class=\"hljs-string\">\"/opt/conda/envs/sdxl/lib/python3.10/site-packages/accelerate/commands/launch.py\"\
          </span>, line 986, <span class=\"hljs-keyword\">in</span> launch_command\n\
          \    simple_launcher(args)\n  File <span class=\"hljs-string\">\"/opt/conda/envs/sdxl/lib/python3.10/site-packages/accelerate/commands/launch.py\"\
          </span>, line 628, <span class=\"hljs-keyword\">in</span> simple_launcher\n\
          \    raise subprocess.CalledProcessError(returncode=process.returncode,\
          \ cmd=cmd)\nsubprocess.CalledProcessError: Command <span class=\"hljs-string\"\
          >'['</span>/opt/conda/envs/sdxl/bin/python3.10<span class=\"hljs-string\"\
          >', '</span>train_text_to_image_lora_sdxl.py<span class=\"hljs-string\"\
          >', '</span>--pretrained_model_name_or_path=segmind/SSD-1B<span class=\"\
          hljs-string\">', '</span>--dataset_name=lambdalabs/pokemon-blip-captions<span\
          \ class=\"hljs-string\">', '</span>--caption_column=text<span class=\"hljs-string\"\
          >', '</span>--resolution=1024<span class=\"hljs-string\">', '</span>--random_flip<span\
          \ class=\"hljs-string\">', '</span>--train_batch_size=1<span class=\"hljs-string\"\
          >', '</span>--num_train_epochs=2<span class=\"hljs-string\">', '</span>--checkpointing_steps=500<span\
          \ class=\"hljs-string\">', '</span>--learning_rate=1e-04<span class=\"hljs-string\"\
          >', '</span>--lr_scheduler=constant<span class=\"hljs-string\">', '</span>--lr_warmup_steps=0<span\
          \ class=\"hljs-string\">', '</span>--mixed_precision=fp16<span class=\"\
          hljs-string\">', '</span>--seed=42<span class=\"hljs-string\">', '</span>--output_dir=sd-pokemon-model-lora-sdxl<span\
          \ class=\"hljs-string\">', '</span>--validation_prompt=cute dragon creature<span\
          \ class=\"hljs-string\">']'</span> returned non-zero <span class=\"hljs-built_in\"\
          >exit</span> status 1.\n</code></pre>\n"
        raw: "@Warlord-K I was able to train successfully, but the validation step\
          \ of the script failed with `RuntimeError: Input type (c10::Half) and bias\
          \ type (float) should be the same`.  It still saved the checkpoints, here\
          \ is after 2 epochs.\n\nWith LoRA\n\n![pokemon_lora.png](https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/fC9tcz3lwD4cdXeoz6vqz.png)\n\
          \nWithout LoRA\n\n\n![pokemon.png](https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/8CC8ZueBjEVPOoAkVjwUl.png)\n\
          \n\nSee the full logs below:\n\n```bash\naccelerate launch train_\ntext_to_image_lora_sdxl.py\
          \   --pretrained_model_name_or_path=$MODEL_NAME  --dataset_name=$DATASET_NAME\
          \ \n--caption_column=\"text\"   --resolution=1024 --random_flip   --train_batch_size=1\
          \   --num_train_epochs=2\n --checkpointing_steps=500   --learning_rate=1e-04\
          \ --lr_scheduler=\"constant\" --lr_warmup_steps=0   --mi\nxed_precision=\"\
          fp16\"   --seed=42   --output_dir=\"sd-pokemon-model-lora-sdxl\"   --validation_prompt=\"\
          cut\ne dragon creature\"\nThe following values were not passed to `accelerate\
          \ launch` and had defaults used instead:\n        `--num_processes` was\
          \ set to a value of `1`\n        `--num_machines` was set to a value of\
          \ `1`\n        `--mixed_precision` was set to a value of `'no'`\n      \
          \  `--dynamo_backend` was set to a value of `'no'`\nTo avoid this warning\
          \ pass in values for each of the problematic parameters or run `accelerate\
          \ config`.\n11/07/2023 01:01:10 - INFO - __main__ - Distributed environment:\
          \ NO\nNum processes: 1\nProcess index: 0\nLocal process index: 0\nDevice:\
          \ cuda\n\nMixed precision type: fp16\n\nYou are using a model of type clip_text_model\
          \ to instantiate a model of type . This is not supported for all configurations\
          \ of models and can yield errors.\nYou are using a model of type clip_text_model\
          \ to instantiate a model of type . This is not supported for all configurations\
          \ of models and can yield errors.\n{'dynamic_thresholding_ratio', 'variance_type',\
          \ 'thresholding', 'clip_sample_range'} was not found in config. Values will\
          \ be initialized to default values.\nDownloading model.safetensors: 100%|\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 492M/492M [00:02<00:00,\
          \ 220MB/s]\nDownloading model.safetensors: 100%|\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588| 2.78G/2.78G [01:10<00:00, 39.7MB/s]\nDownloading (\u2026)ch_model.safetensors:\
          \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588| 335M/335M [00:01<00:00, 200MB/s]\nDownloading\
          \ (\u2026)ch_model.safetensors: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.33G/5.33G [00:23<00:00, 230MB/s]\n\
          {'attention_type', 'dropout'} was not found in config. Values will be initialized\
          \ to default values.\nDownloading readme: 100%|\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          | 1.80k/1.80k [00:00<00:00, 11.8MB/s]\nDownloading metadata: 100%|\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588| 731/731 [00:00<00:00, 5.92MB/s]\n\
          Downloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 99.7M/99.7M\
          \ [00:02<00:00, 39.7MB/s]\nDownloading data files: 100%|\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.51s/it]\nExtracting\
          \ data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,\
          \ 1508.74it/s]\nGenerating train split: 100%|\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588| 833/833 [00:00<00:00, 2920.80 examples/s]\n11/07/2023 01:03:08\
          \ - INFO - __main__ - ***** Running training *****\n11/07/2023 01:03:08\
          \ - INFO - __main__ -   Num examples = 833\n11/07/2023 01:03:08 - INFO -\
          \ __main__ -   Num Epochs = 2\n11/07/2023 01:03:08 - INFO - __main__ - \
          \  Instantaneous batch size per device = 1\n11/07/2023 01:03:08 - INFO -\
          \ __main__ -   Total train batch size (w. parallel, distributed & accumulation)\
          \ = 1\n11/07/2023 01:03:08 - INFO - __main__ -   Gradient Accumulation steps\
          \ = 1\n11/07/2023 01:03:08 - INFO - __main__ -   Total optimization steps\
          \ = 1666\nSteps:  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588                                                      | 500/1666\
          \ [08:46<20:27,  1.05s/it, lr=0.0001, step_loss=0.00503]11/07/2023 01:11:55\
          \ - INFO - accelerate.accelerator - Saving current state to sd-pokemon-model-lora-sdxl/checkpoint-500\n\
          Model weights saved in sd-pokemon-model-lora-sdxl/checkpoint-500/pytorch_lora_weights.safetensors\n\
          11/07/2023 01:11:55 - INFO - accelerate.checkpointing - Optimizer state\
          \ saved in sd-pokemon-model-lora-sdxl/checkpoint-500/optimizer.bin\n11/07/2023\
          \ 01:11:55 - INFO - accelerate.checkpointing - Scheduler state saved in\
          \ sd-pokemon-model-lora-sdxl/checkpoint-500/scheduler.bin\n11/07/2023 01:11:55\
          \ - INFO - accelerate.checkpointing - Gradient scaler state saved in sd-pokemon-model-lora-sdxl/checkpoint-500/scaler.pt\n\
          11/07/2023 01:11:55 - INFO - accelerate.checkpointing - Random states saved\
          \ in sd-pokemon-model-lora-sdxl/checkpoint-500/random_states_0.pkl\n11/07/2023\
          \ 01:11:55 - INFO - __main__ - Saved state to sd-pokemon-model-lora-sdxl/checkpoint-500\n\
          Steps:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u258C                                      | 833/1666\
          \ [14:36<14:27,  1.04s/it, lr=0.0001, step_loss=0.00567]11/07/2023 01:17:45\
          \ - INFO - __main__ - Running validation... \n Generating 4 images with\
          \ prompt: cute dragon creature.\n{'add_watermarker'} was not found in config.\
          \ Values will be initialized to default values.\n                      \
          \                                                                      \
          \                                                             Loaded scheduler\
          \ as EulerDiscreteScheduler from `scheduler` subfolder of segmind/SSD-1B.\
          \                                             | 0/7 [00:00<?, ?it/s]\nLoaded\
          \ tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of segmind/SSD-1B.\n\
          Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/SSD-1B.\n\
          Loading pipeline components...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:00<00:00,\
          \ 53.80it/s]\nSteps:  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u258A                               | 1000/1666 [18:46<11:39,\
          \  1.05s/it, lr=0.0001, step_loss=0.105]11/07/2023 01:21:55 - INFO - accelerate.accelerator\
          \ - Saving current state to sd-pokemon-model-lora-sdxl/checkpoint-1000\n\
          Model weights saved in sd-pokemon-model-lora-sdxl/checkpoint-1000/pytorch_lora_weights.safetensors\n\
          11/07/2023 01:21:55 - INFO - accelerate.checkpointing - Optimizer state\
          \ saved in sd-pokemon-model-lora-sdxl/checkpoint-1000/optimizer.bin\n11/07/2023\
          \ 01:21:55 - INFO - accelerate.checkpointing - Scheduler state saved in\
          \ sd-pokemon-model-lora-sdxl/checkpoint-1000/scheduler.bin\n11/07/2023 01:21:55\
          \ - INFO - accelerate.checkpointing - Gradient scaler state saved in sd-pokemon-model-lora-sdxl/checkpoint-1000/scaler.pt\n\
          11/07/2023 01:21:55 - INFO - accelerate.checkpointing - Random states saved\
          \ in sd-pokemon-model-lora-sdxl/checkpoint-1000/random_states_0.pkl\n11/07/2023\
          \ 01:21:55 - INFO - __main__ - Saved state to sd-pokemon-model-lora-sdxl/checkpoint-1000\n\
          Steps:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258E\
          \       | 1500/1666 [27:31<02:53,  1.05s/it, lr=0.0001, step_loss=0.0159]11/07/2023\
          \ 01:30:40 - INFO - accelerate.accelerator - Saving current state to sd-pokemon-model-lora-sdxl/checkpoint-1500\n\
          Model weights saved in sd-pokemon-model-lora-sdxl/checkpoint-1500/pytorch_lora_weights.safetensors\n\
          11/07/2023 01:30:40 - INFO - accelerate.checkpointing - Optimizer state\
          \ saved in sd-pokemon-model-lora-sdxl/checkpoint-1500/optimizer.bin\n11/07/2023\
          \ 01:30:40 - INFO - accelerate.checkpointing - Scheduler state saved in\
          \ sd-pokemon-model-lora-sdxl/checkpoint-1500/scheduler.bin\n11/07/2023 01:30:40\
          \ - INFO - accelerate.checkpointing - Gradient scaler state saved in sd-pokemon-model-lora-sdxl/checkpoint-1500/scaler.pt\n\
          11/07/2023 01:30:40 - INFO - accelerate.checkpointing - Random states saved\
          \ in sd-pokemon-model-lora-sdxl/checkpoint-1500/random_states_0.pkl\n11/07/2023\
          \ 01:30:40 - INFO - __main__ - Saved state to sd-pokemon-model-lora-sdxl/checkpoint-1500\n\
          Steps: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1666/1666 [30:26<00:00,\
          \  1.04s/it, lr=0.0001, step_loss=0.126]11/07/2023 01:33:35 - INFO - __main__\
          \ - Running validation... \n Generating 4 images with prompt: cute dragon\
          \ creature.\n{'add_watermarker'} was not found in config. Values will be\
          \ initialized to default values.\n                                     \
          \                                                                      \
          \                                              Loaded scheduler as EulerDiscreteScheduler\
          \ from `scheduler` subfolder of segmind/SSD-1B.                        \
          \                     | 0/7 [00:00<?, ?it/s]\nLoaded tokenizer_2 as CLIPTokenizer\
          \ from `tokenizer_2` subfolder of segmind/SSD-1B.\nLoaded tokenizer as CLIPTokenizer\
          \ from `tokenizer` subfolder of segmind/SSD-1B.\nLoading pipeline components...:\
          \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588| 7/7 [00:00<00:00, 60.59it/s]\nModel weights saved\
          \ in sd-pokemon-model-lora-sdxl/pytorch_lora_weights.safetensors\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u258C            | 6/7 [00:00<00:00, 52.13it/s]\n{'add_watermarker'}\
          \ was not found in config. Values will be initialized to default values.\n\
          \                                                                      \
          \                                                                      \
          \             Loaded scheduler as EulerDiscreteScheduler from `scheduler`\
          \ subfolder of segmind/SSD-1B.                                         \
          \    | 0/7 [00:00<?, ?it/s]\nLoaded text_encoder as CLIPTextModel from `text_encoder`\
          \ subfolder of segmind/SSD-1B.\n                                       \
          \                                                                      \
          \                                            Loaded tokenizer_2 as CLIPTokenizer\
          \ from `tokenizer_2` subfolder of segmind/SSD-1B.                      \
          \                    | 3/7 [00:00<00:00,  9.52it/s]\n{'attention_type',\
          \ 'dropout'} was not found in config. Values will be initialized to default\
          \ values.\nLoaded unet as UNet2DConditionModel from `unet` subfolder of\
          \ segmind/SSD-1B.\n                                                    \
          \                                                                      \
          \                               Loaded tokenizer as CLIPTokenizer from `tokenizer`\
          \ subfolder of segmind/SSD-1B.\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u258F                        | 5/7 [00:02<00:01,  1.89it/s]\n\
          Loaded text_encoder_2 as CLIPTextModelWithProjection from `text_encoder_2`\
          \ subfolder of segmind/SSD-1B.\nLoading pipeline components...: 100%|\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588| 7/7 [00:03<00:00,  1.93it/s]\nLoading unet.ine components...:\
          \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588| 7/7 [00:03<00:00,  1.69it/s]\n100%|\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588| 25/25 [00:06<00:00,  3.72it/s]\n\
          Traceback (most recent call last):\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 25/25 [00:06<00:00,\
          \  3.71it/s]\n  File \"/home/jfacevedo_google_com/diffusers/examples/text_to_image/train_text_to_image_lora_sdxl.py\"\
          , line 1265, in <module>\n    main(args)\n  File \"/home/jfacevedo_google_com/diffusers/examples/text_to_image/train_text_to_image_lora_sdxl.py\"\
          , line 1224, in main\n    images = [\n  File \"/home/jfacevedo_google_com/diffusers/examples/text_to_image/train_text_to_image_lora_sdxl.py\"\
          , line 1225, in <listcomp>\n    pipeline(args.validation_prompt, num_inference_steps=25,\
          \ generator=generator).images[0]\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py\"\
          , line 1057, in __call__\n    image = self.vae.decode(latents / self.vae.config.scaling_factor,\
          \ return_dict=False)[0]\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/diffusers/utils/accelerate_utils.py\"\
          , line 46, in wrapper\n    return method(self, *args, **kwargs)\n  File\
          \ \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/diffusers/models/autoencoder_kl.py\"\
          , line 316, in decode\n    decoded = self._decode(z).sample\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/diffusers/models/autoencoder_kl.py\"\
          , line 288, in _decode\n    z = self.post_quant_conv(z)\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/conv.py\"\
          , line 463, in forward\n    return self._conv_forward(input, self.weight,\
          \ self.bias)\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/conv.py\"\
          , line 459, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\n\
          RuntimeError: Input type (c10::Half) and bias type (float) should be the\
          \ same\nSteps: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1666/1666 [31:52<00:00,\
          \  1.15s/it, lr=0.0001, step_loss=0.126]\nTraceback (most recent call last):\n\
          \  File \"/opt/conda/envs/sdxl/bin/accelerate\", line 8, in <module>\n \
          \   sys.exit(main())\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\"\
          , line 45, in main\n    args.func(args)\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/accelerate/commands/launch.py\"\
          , line 986, in launch_command\n    simple_launcher(args)\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/accelerate/commands/launch.py\"\
          , line 628, in simple_launcher\n    raise subprocess.CalledProcessError(returncode=process.returncode,\
          \ cmd=cmd)\nsubprocess.CalledProcessError: Command '['/opt/conda/envs/sdxl/bin/python3.10',\
          \ 'train_text_to_image_lora_sdxl.py', '--pretrained_model_name_or_path=segmind/SSD-1B',\
          \ '--dataset_name=lambdalabs/pokemon-blip-captions', '--caption_column=text',\
          \ '--resolution=1024', '--random_flip', '--train_batch_size=1', '--num_train_epochs=2',\
          \ '--checkpointing_steps=500', '--learning_rate=1e-04', '--lr_scheduler=constant',\
          \ '--lr_warmup_steps=0', '--mixed_precision=fp16', '--seed=42', '--output_dir=sd-pokemon-model-lora-sdxl',\
          \ '--validation_prompt=cute dragon creature']' returned non-zero exit status\
          \ 1.\n```"
        updatedAt: '2023-11-07T01:56:31.907Z'
      numEdits: 0
      reactions: []
    id: 6549994f2470619efe7d8795
    type: comment
  author: jffacevedo
  content: "@Warlord-K I was able to train successfully, but the validation step of\
    \ the script failed with `RuntimeError: Input type (c10::Half) and bias type (float)\
    \ should be the same`.  It still saved the checkpoints, here is after 2 epochs.\n\
    \nWith LoRA\n\n![pokemon_lora.png](https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/fC9tcz3lwD4cdXeoz6vqz.png)\n\
    \nWithout LoRA\n\n\n![pokemon.png](https://cdn-uploads.huggingface.co/production/uploads/64db82b81855ce11cd5b0471/8CC8ZueBjEVPOoAkVjwUl.png)\n\
    \n\nSee the full logs below:\n\n```bash\naccelerate launch train_\ntext_to_image_lora_sdxl.py\
    \   --pretrained_model_name_or_path=$MODEL_NAME  --dataset_name=$DATASET_NAME\
    \ \n--caption_column=\"text\"   --resolution=1024 --random_flip   --train_batch_size=1\
    \   --num_train_epochs=2\n --checkpointing_steps=500   --learning_rate=1e-04 --lr_scheduler=\"\
    constant\" --lr_warmup_steps=0   --mi\nxed_precision=\"fp16\"   --seed=42   --output_dir=\"\
    sd-pokemon-model-lora-sdxl\"   --validation_prompt=\"cut\ne dragon creature\"\n\
    The following values were not passed to `accelerate launch` and had defaults used\
    \ instead:\n        `--num_processes` was set to a value of `1`\n        `--num_machines`\
    \ was set to a value of `1`\n        `--mixed_precision` was set to a value of\
    \ `'no'`\n        `--dynamo_backend` was set to a value of `'no'`\nTo avoid this\
    \ warning pass in values for each of the problematic parameters or run `accelerate\
    \ config`.\n11/07/2023 01:01:10 - INFO - __main__ - Distributed environment: NO\n\
    Num processes: 1\nProcess index: 0\nLocal process index: 0\nDevice: cuda\n\nMixed\
    \ precision type: fp16\n\nYou are using a model of type clip_text_model to instantiate\
    \ a model of type . This is not supported for all configurations of models and\
    \ can yield errors.\nYou are using a model of type clip_text_model to instantiate\
    \ a model of type . This is not supported for all configurations of models and\
    \ can yield errors.\n{'dynamic_thresholding_ratio', 'variance_type', 'thresholding',\
    \ 'clip_sample_range'} was not found in config. Values will be initialized to\
    \ default values.\nDownloading model.safetensors: 100%|\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588| 492M/492M [00:02<00:00, 220MB/s]\nDownloading model.safetensors:\
    \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588| 2.78G/2.78G [01:10<00:00, 39.7MB/s]\nDownloading\
    \ (\u2026)ch_model.safetensors: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588| 335M/335M [00:01<00:00, 200MB/s]\nDownloading (\u2026\
    )ch_model.safetensors: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    | 5.33G/5.33G [00:23<00:00, 230MB/s]\n{'attention_type', 'dropout'} was not found\
    \ in config. Values will be initialized to default values.\nDownloading readme:\
    \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    | 1.80k/1.80k [00:00<00:00, 11.8MB/s]\nDownloading metadata: 100%|\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 731/731\
    \ [00:00<00:00, 5.92MB/s]\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 99.7M/99.7M [00:02<00:00,\
    \ 39.7MB/s]\nDownloading data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02<00:00,  2.51s/it]\n\
    Extracting data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 1508.74it/s]\nGenerating train\
    \ split: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588| 833/833 [00:00<00:00, 2920.80 examples/s]\n11/07/2023\
    \ 01:03:08 - INFO - __main__ - ***** Running training *****\n11/07/2023 01:03:08\
    \ - INFO - __main__ -   Num examples = 833\n11/07/2023 01:03:08 - INFO - __main__\
    \ -   Num Epochs = 2\n11/07/2023 01:03:08 - INFO - __main__ -   Instantaneous\
    \ batch size per device = 1\n11/07/2023 01:03:08 - INFO - __main__ -   Total train\
    \ batch size (w. parallel, distributed & accumulation) = 1\n11/07/2023 01:03:08\
    \ - INFO - __main__ -   Gradient Accumulation steps = 1\n11/07/2023 01:03:08 -\
    \ INFO - __main__ -   Total optimization steps = 1666\nSteps:  30%|\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                             \
    \                         | 500/1666 [08:46<20:27,  1.05s/it, lr=0.0001, step_loss=0.00503]11/07/2023\
    \ 01:11:55 - INFO - accelerate.accelerator - Saving current state to sd-pokemon-model-lora-sdxl/checkpoint-500\n\
    Model weights saved in sd-pokemon-model-lora-sdxl/checkpoint-500/pytorch_lora_weights.safetensors\n\
    11/07/2023 01:11:55 - INFO - accelerate.checkpointing - Optimizer state saved\
    \ in sd-pokemon-model-lora-sdxl/checkpoint-500/optimizer.bin\n11/07/2023 01:11:55\
    \ - INFO - accelerate.checkpointing - Scheduler state saved in sd-pokemon-model-lora-sdxl/checkpoint-500/scheduler.bin\n\
    11/07/2023 01:11:55 - INFO - accelerate.checkpointing - Gradient scaler state\
    \ saved in sd-pokemon-model-lora-sdxl/checkpoint-500/scaler.pt\n11/07/2023 01:11:55\
    \ - INFO - accelerate.checkpointing - Random states saved in sd-pokemon-model-lora-sdxl/checkpoint-500/random_states_0.pkl\n\
    11/07/2023 01:11:55 - INFO - __main__ - Saved state to sd-pokemon-model-lora-sdxl/checkpoint-500\n\
    Steps:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u258C                                      | 833/1666 [14:36<14:27,  1.04s/it,\
    \ lr=0.0001, step_loss=0.00567]11/07/2023 01:17:45 - INFO - __main__ - Running\
    \ validation... \n Generating 4 images with prompt: cute dragon creature.\n{'add_watermarker'}\
    \ was not found in config. Values will be initialized to default values.\n   \
    \                                                                            \
    \                                                                          Loaded\
    \ scheduler as EulerDiscreteScheduler from `scheduler` subfolder of segmind/SSD-1B.\
    \                                             | 0/7 [00:00<?, ?it/s]\nLoaded tokenizer_2\
    \ as CLIPTokenizer from `tokenizer_2` subfolder of segmind/SSD-1B.\nLoaded tokenizer\
    \ as CLIPTokenizer from `tokenizer` subfolder of segmind/SSD-1B.\nLoading pipeline\
    \ components...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7\
    \ [00:00<00:00, 53.80it/s]\nSteps:  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u258A                               | 1000/1666 [18:46<11:39,  1.05s/it, lr=0.0001,\
    \ step_loss=0.105]11/07/2023 01:21:55 - INFO - accelerate.accelerator - Saving\
    \ current state to sd-pokemon-model-lora-sdxl/checkpoint-1000\nModel weights saved\
    \ in sd-pokemon-model-lora-sdxl/checkpoint-1000/pytorch_lora_weights.safetensors\n\
    11/07/2023 01:21:55 - INFO - accelerate.checkpointing - Optimizer state saved\
    \ in sd-pokemon-model-lora-sdxl/checkpoint-1000/optimizer.bin\n11/07/2023 01:21:55\
    \ - INFO - accelerate.checkpointing - Scheduler state saved in sd-pokemon-model-lora-sdxl/checkpoint-1000/scheduler.bin\n\
    11/07/2023 01:21:55 - INFO - accelerate.checkpointing - Gradient scaler state\
    \ saved in sd-pokemon-model-lora-sdxl/checkpoint-1000/scaler.pt\n11/07/2023 01:21:55\
    \ - INFO - accelerate.checkpointing - Random states saved in sd-pokemon-model-lora-sdxl/checkpoint-1000/random_states_0.pkl\n\
    11/07/2023 01:21:55 - INFO - __main__ - Saved state to sd-pokemon-model-lora-sdxl/checkpoint-1000\n\
    Steps:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u258E       | 1500/1666 [27:31<02:53,  1.05s/it,\
    \ lr=0.0001, step_loss=0.0159]11/07/2023 01:30:40 - INFO - accelerate.accelerator\
    \ - Saving current state to sd-pokemon-model-lora-sdxl/checkpoint-1500\nModel\
    \ weights saved in sd-pokemon-model-lora-sdxl/checkpoint-1500/pytorch_lora_weights.safetensors\n\
    11/07/2023 01:30:40 - INFO - accelerate.checkpointing - Optimizer state saved\
    \ in sd-pokemon-model-lora-sdxl/checkpoint-1500/optimizer.bin\n11/07/2023 01:30:40\
    \ - INFO - accelerate.checkpointing - Scheduler state saved in sd-pokemon-model-lora-sdxl/checkpoint-1500/scheduler.bin\n\
    11/07/2023 01:30:40 - INFO - accelerate.checkpointing - Gradient scaler state\
    \ saved in sd-pokemon-model-lora-sdxl/checkpoint-1500/scaler.pt\n11/07/2023 01:30:40\
    \ - INFO - accelerate.checkpointing - Random states saved in sd-pokemon-model-lora-sdxl/checkpoint-1500/random_states_0.pkl\n\
    11/07/2023 01:30:40 - INFO - __main__ - Saved state to sd-pokemon-model-lora-sdxl/checkpoint-1500\n\
    Steps: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588| 1666/1666 [30:26<00:00,  1.04s/it, lr=0.0001, step_loss=0.126]11/07/2023\
    \ 01:33:35 - INFO - __main__ - Running validation... \n Generating 4 images with\
    \ prompt: cute dragon creature.\n{'add_watermarker'} was not found in config.\
    \ Values will be initialized to default values.\n                            \
    \                                                                            \
    \                                                 Loaded scheduler as EulerDiscreteScheduler\
    \ from `scheduler` subfolder of segmind/SSD-1B.                              \
    \               | 0/7 [00:00<?, ?it/s]\nLoaded tokenizer_2 as CLIPTokenizer from\
    \ `tokenizer_2` subfolder of segmind/SSD-1B.\nLoaded tokenizer as CLIPTokenizer\
    \ from `tokenizer` subfolder of segmind/SSD-1B.\nLoading pipeline components...:\
    \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:00<00:00,\
    \ 60.59it/s]\nModel weights saved in sd-pokemon-model-lora-sdxl/pytorch_lora_weights.safetensors\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u258C            | 6/7 [00:00<00:00, 52.13it/s]\n{'add_watermarker'}\
    \ was not found in config. Values will be initialized to default values.\n   \
    \                                                                            \
    \                                                                          Loaded\
    \ scheduler as EulerDiscreteScheduler from `scheduler` subfolder of segmind/SSD-1B.\
    \                                             | 0/7 [00:00<?, ?it/s]\nLoaded text_encoder\
    \ as CLIPTextModel from `text_encoder` subfolder of segmind/SSD-1B.\n        \
    \                                                                            \
    \                                                                     Loaded tokenizer_2\
    \ as CLIPTokenizer from `tokenizer_2` subfolder of segmind/SSD-1B.           \
    \                               | 3/7 [00:00<00:00,  9.52it/s]\n{'attention_type',\
    \ 'dropout'} was not found in config. Values will be initialized to default values.\n\
    Loaded unet as UNet2DConditionModel from `unet` subfolder of segmind/SSD-1B.\n\
    \                                                                            \
    \                                                                            \
    \ Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of segmind/SSD-1B.\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258F                        | 5/7\
    \ [00:02<00:01,  1.89it/s]\nLoaded text_encoder_2 as CLIPTextModelWithProjection\
    \ from `text_encoder_2` subfolder of segmind/SSD-1B.\nLoading pipeline components...:\
    \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:03<00:00,\
    \  1.93it/s]\nLoading unet.ine components...: 100%|\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588| 7/7 [00:03<00:00,  1.69it/s]\n100%|\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 25/25 [00:06<00:00,\
    \  3.72it/s]\nTraceback (most recent call last):\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588| 25/25 [00:06<00:00,  3.71it/s]\n  File \"/home/jfacevedo_google_com/diffusers/examples/text_to_image/train_text_to_image_lora_sdxl.py\"\
    , line 1265, in <module>\n    main(args)\n  File \"/home/jfacevedo_google_com/diffusers/examples/text_to_image/train_text_to_image_lora_sdxl.py\"\
    , line 1224, in main\n    images = [\n  File \"/home/jfacevedo_google_com/diffusers/examples/text_to_image/train_text_to_image_lora_sdxl.py\"\
    , line 1225, in <listcomp>\n    pipeline(args.validation_prompt, num_inference_steps=25,\
    \ generator=generator).images[0]\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py\"\
    , line 1057, in __call__\n    image = self.vae.decode(latents / self.vae.config.scaling_factor,\
    \ return_dict=False)[0]\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/diffusers/utils/accelerate_utils.py\"\
    , line 46, in wrapper\n    return method(self, *args, **kwargs)\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/diffusers/models/autoencoder_kl.py\"\
    , line 316, in decode\n    decoded = self._decode(z).sample\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/diffusers/models/autoencoder_kl.py\"\
    , line 288, in _decode\n    z = self.post_quant_conv(z)\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /opt/conda/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/conv.py\",\
    \ line 463, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n\
    \  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/torch/nn/modules/conv.py\"\
    , line 459, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\n\
    RuntimeError: Input type (c10::Half) and bias type (float) should be the same\n\
    Steps: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588| 1666/1666 [31:52<00:00,  1.15s/it, lr=0.0001, step_loss=0.126]\n\
    Traceback (most recent call last):\n  File \"/opt/conda/envs/sdxl/bin/accelerate\"\
    , line 8, in <module>\n    sys.exit(main())\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\"\
    , line 45, in main\n    args.func(args)\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/accelerate/commands/launch.py\"\
    , line 986, in launch_command\n    simple_launcher(args)\n  File \"/opt/conda/envs/sdxl/lib/python3.10/site-packages/accelerate/commands/launch.py\"\
    , line 628, in simple_launcher\n    raise subprocess.CalledProcessError(returncode=process.returncode,\
    \ cmd=cmd)\nsubprocess.CalledProcessError: Command '['/opt/conda/envs/sdxl/bin/python3.10',\
    \ 'train_text_to_image_lora_sdxl.py', '--pretrained_model_name_or_path=segmind/SSD-1B',\
    \ '--dataset_name=lambdalabs/pokemon-blip-captions', '--caption_column=text',\
    \ '--resolution=1024', '--random_flip', '--train_batch_size=1', '--num_train_epochs=2',\
    \ '--checkpointing_steps=500', '--learning_rate=1e-04', '--lr_scheduler=constant',\
    \ '--lr_warmup_steps=0', '--mixed_precision=fp16', '--seed=42', '--output_dir=sd-pokemon-model-lora-sdxl',\
    \ '--validation_prompt=cute dragon creature']' returned non-zero exit status 1.\n\
    ```"
  created_at: 2023-11-07 01:56:31+00:00
  edited: false
  hidden: false
  id: 6549994f2470619efe7d8795
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62f8ca074588fe31f4361dae/F2k343TPD7KVfW3P26IRs.jpeg?w=200&h=200&f=face
      fullname: Yatharth Gupta
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Warlord-K
      type: user
    createdAt: '2023-11-07T07:38:30.000Z'
    data:
      edited: false
      editors:
      - Warlord-K
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9672591090202332
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62f8ca074588fe31f4361dae/F2k343TPD7KVfW3P26IRs.jpeg?w=200&h=200&f=face
          fullname: Yatharth Gupta
          isHf: false
          isPro: false
          name: Warlord-K
          type: user
        html: '<p>Something might have gone wrong in the training, We''ll try the
          same and get back to you, Thanks for reporting!</p>

          '
        raw: Something might have gone wrong in the training, We'll try the same and
          get back to you, Thanks for reporting!
        updatedAt: '2023-11-07T07:38:30.849Z'
      numEdits: 0
      reactions: []
    id: 6549e976a899f8b4343a73b0
    type: comment
  author: Warlord-K
  content: Something might have gone wrong in the training, We'll try the same and
    get back to you, Thanks for reporting!
  created_at: 2023-11-07 07:38:30+00:00
  edited: false
  hidden: false
  id: 6549e976a899f8b4343a73b0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b4272bc964e5103cc68e8c797b3a568d.svg
      fullname: Paul
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: inb4devops
      type: user
    createdAt: '2023-11-08T07:40:53.000Z'
    data:
      edited: true
      editors:
      - inb4devops
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8817555904388428
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b4272bc964e5103cc68e8c797b3a568d.svg
          fullname: Paul
          isHf: false
          isPro: false
          name: inb4devops
          type: user
        html: '<p>I also tried to train a LoRA for SSD-1B but I''m getting this error
          (Missing key(s) in state_dict): <a rel="nofollow" href="https://github.com/bmaltais/kohya_ss/issues/1665">https://github.com/bmaltais/kohya_ss/issues/1665</a></p>

          <p>Is this related to kohya_ss or the model? </p>

          '
        raw: 'I also tried to train a LoRA for SSD-1B but I''m getting this error
          (Missing key(s) in state_dict): https://github.com/bmaltais/kohya_ss/issues/1665


          Is this related to kohya_ss or the model? '
        updatedAt: '2023-11-08T07:49:06.840Z'
      numEdits: 1
      reactions: []
    id: 654b3b85e4ce07c7d7a5a4c9
    type: comment
  author: inb4devops
  content: 'I also tried to train a LoRA for SSD-1B but I''m getting this error (Missing
    key(s) in state_dict): https://github.com/bmaltais/kohya_ss/issues/1665


    Is this related to kohya_ss or the model? '
  created_at: 2023-11-08 07:40:53+00:00
  edited: true
  hidden: false
  id: 654b3b85e4ce07c7d7a5a4c9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639362039694ec0d025f194d/jmQetjDK3ISH_IQb7SBGC.png?w=200&h=200&f=face
      fullname: Vishnu V Jaddipal
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Icar
      type: user
    createdAt: '2023-11-08T07:45:58.000Z'
    data:
      edited: true
      editors:
      - Icar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9851426482200623
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639362039694ec0d025f194d/jmQetjDK3ISH_IQb7SBGC.png?w=200&h=200&f=face
          fullname: Vishnu V Jaddipal
          isHf: false
          isPro: false
          name: Icar
          type: user
        html: '<p>Have you tried updating Kohya? It seems like it didn''t recognize
          the model and expects a larger state_dict.</p>

          '
        raw: Have you tried updating Kohya? It seems like it didn't recognize the
          model and expects a larger state_dict.
        updatedAt: '2023-11-08T07:46:20.341Z'
      numEdits: 1
      reactions: []
    id: 654b3cb66a46bad8c01f2999
    type: comment
  author: Icar
  content: Have you tried updating Kohya? It seems like it didn't recognize the model
    and expects a larger state_dict.
  created_at: 2023-11-08 07:45:58+00:00
  edited: true
  hidden: false
  id: 654b3cb66a46bad8c01f2999
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b4272bc964e5103cc68e8c797b3a568d.svg
      fullname: Paul
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: inb4devops
      type: user
    createdAt: '2023-11-08T08:25:00.000Z'
    data:
      edited: false
      editors:
      - inb4devops
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9783859848976135
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b4272bc964e5103cc68e8c797b3a568d.svg
          fullname: Paul
          isHf: false
          isPro: false
          name: inb4devops
          type: user
        html: '<blockquote>

          <p>Have you tried updating Kohya? It seems like it didn''t recognize the
          model and expects a larger state_dict.</p>

          </blockquote>

          <p>yeah, I just rechecked and my clone is up to date. </p>

          '
        raw: '> Have you tried updating Kohya? It seems like it didn''t recognize
          the model and expects a larger state_dict.


          yeah, I just rechecked and my clone is up to date. '
        updatedAt: '2023-11-08T08:25:00.612Z'
      numEdits: 0
      reactions: []
    id: 654b45dcfc2ecdff06388a60
    type: comment
  author: inb4devops
  content: '> Have you tried updating Kohya? It seems like it didn''t recognize the
    model and expects a larger state_dict.


    yeah, I just rechecked and my clone is up to date. '
  created_at: 2023-11-08 08:25:00+00:00
  edited: false
  hidden: false
  id: 654b45dcfc2ecdff06388a60
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/da8d30986be67766a83dd80c3866a6f1.svg
      fullname: MOHAMMED HUZAIF AHMED
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: huzaif-ahmed
      type: user
    createdAt: '2023-11-22T04:40:38.000Z'
    data:
      edited: false
      editors:
      - huzaif-ahmed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9835734367370605
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/da8d30986be67766a83dd80c3866a6f1.svg
          fullname: MOHAMMED HUZAIF AHMED
          isHf: false
          isPro: false
          name: huzaif-ahmed
          type: user
        html: '<p>how can i train this model for multiple images of different people
          example a person named has his all pics in p1 folder ,and a person named
          p2 has all his pics in p2 how do i do it now i want my model to give the
          accurate pics when i say p1 and p2</p>

          '
        raw: 'how can i train this model for multiple images of different people example
          a person named has his all pics in p1 folder ,and a person named p2 has
          all his pics in p2 how do i do it now i want my model to give the accurate
          pics when i say p1 and p2


          '
        updatedAt: '2023-11-22T04:40:38.228Z'
      numEdits: 0
      reactions: []
    id: 655d8646caa21067cd9f9171
    type: comment
  author: huzaif-ahmed
  content: 'how can i train this model for multiple images of different people example
    a person named has his all pics in p1 folder ,and a person named p2 has all his
    pics in p2 how do i do it now i want my model to give the accurate pics when i
    say p1 and p2


    '
  created_at: 2023-11-22 04:40:38+00:00
  edited: false
  hidden: false
  id: 655d8646caa21067cd9f9171
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62f8ca074588fe31f4361dae/F2k343TPD7KVfW3P26IRs.jpeg?w=200&h=200&f=face
      fullname: Yatharth Gupta
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Warlord-K
      type: user
    createdAt: '2023-11-22T09:20:54.000Z'
    data:
      edited: false
      editors:
      - Warlord-K
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.744524359703064
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62f8ca074588fe31f4361dae/F2k343TPD7KVfW3P26IRs.jpeg?w=200&h=200&f=face
          fullname: Yatharth Gupta
          isHf: false
          isPro: false
          name: Warlord-K
          type: user
        html: '<p>You can use the dreambooth lora training script available in diffusers</p>

          '
        raw: You can use the dreambooth lora training script available in diffusers
        updatedAt: '2023-11-22T09:20:54.364Z'
      numEdits: 0
      reactions: []
    id: 655dc7f6d00cca1e3aceb350
    type: comment
  author: Warlord-K
  content: You can use the dreambooth lora training script available in diffusers
  created_at: 2023-11-22 09:20:54+00:00
  edited: false
  hidden: false
  id: 655dc7f6d00cca1e3aceb350
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: segmind/SSD-1B
repo_type: model
status: open
target_branch: null
title: LoRA
