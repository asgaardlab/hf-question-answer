!!python/object:huggingface_hub.community.DiscussionWithDetails
author: CED6688
conflicting_files: null
created_at: 2023-12-03 21:03:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5053132265d28d00489cd279e5435281.svg
      fullname: Clayton Donley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CED6688
      type: user
    createdAt: '2023-12-03T21:03:34.000Z'
    data:
      edited: false
      editors:
      - CED6688
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9887993335723877
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5053132265d28d00489cd279e5435281.svg
          fullname: Clayton Donley
          isHf: false
          isPro: false
          name: CED6688
          type: user
        html: '<p>Not sure if anyone else has noticed, but this model seems to return  at
          the end of most generations. In fact, I almost never see &lt;|im_end|&gt;
          token despite using ChatML prompting. Note that for this mode,  is not even
          a listed special token.</p>

          <p>That said, this seems to be the case with many Yi-34b fine-tunes, which
          also require adding  as an explicit stopping string.</p>

          '
        raw: "Not sure if anyone else has noticed, but this model seems to return\
          \ </s> at the end of most generations. In fact, I almost never see <|im_end|>\
          \ token despite using ChatML prompting. Note that for this mode, </s> is\
          \ not even a listed special token.\r\n\r\nThat said, this seems to be the\
          \ case with many Yi-34b fine-tunes, which also require adding </s> as an\
          \ explicit stopping string."
        updatedAt: '2023-12-03T21:03:34.789Z'
      numEdits: 0
      reactions: []
    id: 656ced269496f21be892eac7
    type: comment
  author: CED6688
  content: "Not sure if anyone else has noticed, but this model seems to return </s>\
    \ at the end of most generations. In fact, I almost never see <|im_end|> token\
    \ despite using ChatML prompting. Note that for this mode, </s> is not even a\
    \ listed special token.\r\n\r\nThat said, this seems to be the case with many\
    \ Yi-34b fine-tunes, which also require adding </s> as an explicit stopping string."
  created_at: 2023-12-03 21:03:34+00:00
  edited: false
  hidden: false
  id: 656ced269496f21be892eac7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f54abfaa4be54e61c1052720eb498703.svg
      fullname: "Jos\xE9phus Cheung"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JosephusCheung
      type: user
    createdAt: '2023-12-04T02:11:03.000Z'
    data:
      edited: false
      editors:
      - JosephusCheung
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9888978004455566
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f54abfaa4be54e61c1052720eb498703.svg
          fullname: "Jos\xE9phus Cheung"
          isHf: false
          isPro: false
          name: JosephusCheung
          type: user
        html: '<p>It is as expected, which is the same of all the CausalLM models.<br>And
          I think only EOS token  as EOS is possible, not &lt;|im_end|&gt;</p>

          '
        raw: 'It is as expected, which is the same of all the CausalLM models.

          And I think only EOS token </s> as EOS is possible, not <|im_end|>'
        updatedAt: '2023-12-04T02:11:03.887Z'
      numEdits: 0
      reactions: []
    id: 656d3537e8bf55919ab8b90f
    type: comment
  author: JosephusCheung
  content: 'It is as expected, which is the same of all the CausalLM models.

    And I think only EOS token </s> as EOS is possible, not <|im_end|>'
  created_at: 2023-12-04 02:11:03+00:00
  edited: false
  hidden: false
  id: 656d3537e8bf55919ab8b90f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/f54abfaa4be54e61c1052720eb498703.svg
      fullname: "Jos\xE9phus Cheung"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JosephusCheung
      type: user
    createdAt: '2023-12-04T02:11:06.000Z'
    data:
      status: closed
    id: 656d353ac56388a9851b2799
    type: status-change
  author: JosephusCheung
  created_at: 2023-12-04 02:11:06+00:00
  id: 656d353ac56388a9851b2799
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: CausalLM/34B-preview
repo_type: model
status: closed
target_branch: null
title: Includes </s> in most replies despite ChatML prompting
