!!python/object:huggingface_hub.community.DiscussionWithDetails
author: fahadh4ilyas
conflicting_files: null
created_at: 2023-09-28 04:25:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bccdd2bb6c11d0315bd96da90eb46297.svg
      fullname: Fahadh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fahadh4ilyas
      type: user
    createdAt: '2023-09-28T05:25:04.000Z'
    data:
      edited: false
      editors:
      - fahadh4ilyas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6282538771629333
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bccdd2bb6c11d0315bd96da90eb46297.svg
          fullname: Fahadh
          isHf: false
          isPro: false
          name: fahadh4ilyas
          type: user
        html: '<p>I''m trying to load the model using text generation web ui but the
          result is always repeated "\n" everytime I ask it short like "Give me explanation
          about AI!". I load it with this params:</p>

          <pre><code>python server.py --verbose --model-menu --loader transformers
          --load-in-4bit --compute_dtype float16 --quant_type nf4 --use_double_quant
          --listen

          </code></pre>

          <p>Is there something that I do wrong here?</p>

          '
        raw: "I'm trying to load the model using text generation web ui but the result\
          \ is always repeated \"\\n\" everytime I ask it short like \"Give me explanation\
          \ about AI!\". I load it with this params:\r\n\r\n```\r\npython server.py\
          \ --verbose --model-menu --loader transformers --load-in-4bit --compute_dtype\
          \ float16 --quant_type nf4 --use_double_quant --listen\r\n```\r\n\r\nIs\
          \ there something that I do wrong here?"
        updatedAt: '2023-09-28T05:25:04.835Z'
      numEdits: 0
      reactions: []
    id: 65150e3068414f3480df239b
    type: comment
  author: fahadh4ilyas
  content: "I'm trying to load the model using text generation web ui but the result\
    \ is always repeated \"\\n\" everytime I ask it short like \"Give me explanation\
    \ about AI!\". I load it with this params:\r\n\r\n```\r\npython server.py --verbose\
    \ --model-menu --loader transformers --load-in-4bit --compute_dtype float16 --quant_type\
    \ nf4 --use_double_quant --listen\r\n```\r\n\r\nIs there something that I do wrong\
    \ here?"
  created_at: 2023-09-28 04:25:04+00:00
  edited: false
  hidden: false
  id: 65150e3068414f3480df239b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653710384819-62919485a29097b211bc7b83.png?w=200&h=200&f=face
      fullname: YukangChen
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Yukang
      type: user
    createdAt: '2023-09-28T13:15:07.000Z'
    data:
      edited: false
      editors:
      - Yukang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9200313687324524
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653710384819-62919485a29097b211bc7b83.png?w=200&h=200&f=face
          fullname: YukangChen
          isHf: false
          isPro: false
          name: Yukang
          type: user
        html: '<p>Hi,</p>

          <p>I think it might be better that if you ask question following the prompt
          format during the supervised fine-tuning.<br><a rel="nofollow" href="https://github.com/dvlab-research/LongLoRA/blob/5056749a37833c1303129ddff3fde6ee26dfe86f/demo.py#L161">https://github.com/dvlab-research/LongLoRA/blob/5056749a37833c1303129ddff3fde6ee26dfe86f/demo.py#L161</a></p>

          <p>In addition, I think this might be caused from the reason that the model
          has been fine-tuned to fit the long context inputs, and its capacity on
          short context might be influence. Because we used the position interpolation
          (<a rel="nofollow" href="https://arxiv.org/abs/2306.15595">https://arxiv.org/abs/2306.15595</a>)
          for position embedding. Its limitation on short text is a known issue. </p>

          <p>Regards,<br>Yukang Chen</p>

          '
        raw: "Hi,\n\nI think it might be better that if you ask question following\
          \ the prompt format during the supervised fine-tuning.\nhttps://github.com/dvlab-research/LongLoRA/blob/5056749a37833c1303129ddff3fde6ee26dfe86f/demo.py#L161\n\
          \nIn addition, I think this might be caused from the reason that the model\
          \ has been fine-tuned to fit the long context inputs, and its capacity on\
          \ short context might be influence. Because we used the position interpolation\
          \ (https://arxiv.org/abs/2306.15595) for position embedding. Its limitation\
          \ on short text is a known issue. \n\n\n\nRegards,\nYukang Chen"
        updatedAt: '2023-09-28T13:15:07.699Z'
      numEdits: 0
      reactions: []
    id: 65157c5b908423a70b92e8f0
    type: comment
  author: Yukang
  content: "Hi,\n\nI think it might be better that if you ask question following the\
    \ prompt format during the supervised fine-tuning.\nhttps://github.com/dvlab-research/LongLoRA/blob/5056749a37833c1303129ddff3fde6ee26dfe86f/demo.py#L161\n\
    \nIn addition, I think this might be caused from the reason that the model has\
    \ been fine-tuned to fit the long context inputs, and its capacity on short context\
    \ might be influence. Because we used the position interpolation (https://arxiv.org/abs/2306.15595)\
    \ for position embedding. Its limitation on short text is a known issue. \n\n\n\
    \nRegards,\nYukang Chen"
  created_at: 2023-09-28 12:15:07+00:00
  edited: false
  hidden: false
  id: 65157c5b908423a70b92e8f0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bccdd2bb6c11d0315bd96da90eb46297.svg
      fullname: Fahadh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fahadh4ilyas
      type: user
    createdAt: '2023-09-28T13:22:38.000Z'
    data:
      edited: true
      editors:
      - fahadh4ilyas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8982778787612915
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bccdd2bb6c11d0315bd96da90eb46297.svg
          fullname: Fahadh
          isHf: false
          isPro: false
          name: fahadh4ilyas
          type: user
        html: '<p>Oh, thank you for the explanation. So this model is limited to only
          for long input?</p>

          <p>You also said that you use position interpolation to fine tune your model,
          but your github script didn''t show anything about position interpolation.
          Instead you use attention shifting. Or do you mean attention shifting is
          a position interpolation?</p>

          '
        raw: 'Oh, thank you for the explanation. So this model is limited to only
          for long input?


          You also said that you use position interpolation to fine tune your model,
          but your github script didn''t show anything about position interpolation.
          Instead you use attention shifting. Or do you mean attention shifting is
          a position interpolation?'
        updatedAt: '2023-09-28T13:27:22.558Z'
      numEdits: 1
      reactions: []
    id: 65157e1ec661dc405bbe7eb3
    type: comment
  author: fahadh4ilyas
  content: 'Oh, thank you for the explanation. So this model is limited to only for
    long input?


    You also said that you use position interpolation to fine tune your model, but
    your github script didn''t show anything about position interpolation. Instead
    you use attention shifting. Or do you mean attention shifting is a position interpolation?'
  created_at: 2023-09-28 12:22:38+00:00
  edited: true
  hidden: false
  id: 65157e1ec661dc405bbe7eb3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653710384819-62919485a29097b211bc7b83.png?w=200&h=200&f=face
      fullname: YukangChen
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Yukang
      type: user
    createdAt: '2023-09-29T08:00:18.000Z'
    data:
      edited: false
      editors:
      - Yukang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.930256187915802
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653710384819-62919485a29097b211bc7b83.png?w=200&h=200&f=face
          fullname: YukangChen
          isHf: false
          isPro: false
          name: Yukang
          type: user
        html: '<p>Hi,</p>

          <p>I think it should be not good at very short input. I have tested the
          input with hundreds of tokens, it can provide a reasonable answers. In addition,
          the shorter ones are bad, like the question you do.</p>

          <p>We have included the position interpolation. Please refer to the lines
          below. It is introduced in this work (<a rel="nofollow" href="https://arxiv.org/abs/2306.15595">https://arxiv.org/abs/2306.15595</a>).
          </p>

          <p><a rel="nofollow" href="https://github.com/dvlab-research/LongLoRA/blob/5056749a37833c1303129ddff3fde6ee26dfe86f/demo.py#L220">https://github.com/dvlab-research/LongLoRA/blob/5056749a37833c1303129ddff3fde6ee26dfe86f/demo.py#L220</a></p>

          <p>Regards,<br>Yukang Chen</p>

          '
        raw: "Hi,\n\nI think it should be not good at very short input. I have tested\
          \ the input with hundreds of tokens, it can provide a reasonable answers.\
          \ In addition, the shorter ones are bad, like the question you do.\n\nWe\
          \ have included the position interpolation. Please refer to the lines below.\
          \ It is introduced in this work (https://arxiv.org/abs/2306.15595). \n\n\
          https://github.com/dvlab-research/LongLoRA/blob/5056749a37833c1303129ddff3fde6ee26dfe86f/demo.py#L220\n\
          \n\nRegards,\nYukang Chen"
        updatedAt: '2023-09-29T08:00:18.572Z'
      numEdits: 0
      reactions: []
    id: 651684121e7e8096c674d284
    type: comment
  author: Yukang
  content: "Hi,\n\nI think it should be not good at very short input. I have tested\
    \ the input with hundreds of tokens, it can provide a reasonable answers. In addition,\
    \ the shorter ones are bad, like the question you do.\n\nWe have included the\
    \ position interpolation. Please refer to the lines below. It is introduced in\
    \ this work (https://arxiv.org/abs/2306.15595). \n\nhttps://github.com/dvlab-research/LongLoRA/blob/5056749a37833c1303129ddff3fde6ee26dfe86f/demo.py#L220\n\
    \n\nRegards,\nYukang Chen"
  created_at: 2023-09-29 07:00:18+00:00
  edited: false
  hidden: false
  id: 651684121e7e8096c674d284
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bccdd2bb6c11d0315bd96da90eb46297.svg
      fullname: Fahadh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fahadh4ilyas
      type: user
    createdAt: '2023-09-29T08:03:01.000Z'
    data:
      edited: false
      editors:
      - fahadh4ilyas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9743520021438599
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bccdd2bb6c11d0315bd96da90eb46297.svg
          fullname: Fahadh
          isHf: false
          isPro: false
          name: fahadh4ilyas
          type: user
        html: '<p>Ah, maybe that is the reason why the answer is always "\n". That
          makes sense. Okay thank you for the clarification...</p>

          '
        raw: Ah, maybe that is the reason why the answer is always "\n". That makes
          sense. Okay thank you for the clarification...
        updatedAt: '2023-09-29T08:03:01.117Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Yukang
      relatedEventId: 651684b5a546159af999e19a
    id: 651684b5a546159af999e195
    type: comment
  author: fahadh4ilyas
  content: Ah, maybe that is the reason why the answer is always "\n". That makes
    sense. Okay thank you for the clarification...
  created_at: 2023-09-29 07:03:01+00:00
  edited: false
  hidden: false
  id: 651684b5a546159af999e195
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/bccdd2bb6c11d0315bd96da90eb46297.svg
      fullname: Fahadh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fahadh4ilyas
      type: user
    createdAt: '2023-09-29T08:03:01.000Z'
    data:
      status: closed
    id: 651684b5a546159af999e19a
    type: status-change
  author: fahadh4ilyas
  created_at: 2023-09-29 07:03:01+00:00
  id: 651684b5a546159af999e19a
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Yukang/Llama-2-13b-chat-longlora-32k-sft
repo_type: model
status: closed
target_branch: null
title: Why this model kept generating \n when loaded with text generation web ui?
