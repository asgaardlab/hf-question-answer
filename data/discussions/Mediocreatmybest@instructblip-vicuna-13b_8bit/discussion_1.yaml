!!python/object:huggingface_hub.community.DiscussionWithDetails
author: manzonif
conflicting_files: null
created_at: 2023-08-06 17:25:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e593120f0184651471397f5b34d9b39f.svg
      fullname: Fausto Manzoni
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: manzonif
      type: user
    createdAt: '2023-08-06T18:25:04.000Z'
    data:
      edited: false
      editors:
      - manzonif
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6092432141304016
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e593120f0184651471397f5b34d9b39f.svg
          fullname: Fausto Manzoni
          isHf: false
          isPro: false
          name: manzonif
          type: user
        html: '<p>Hi, I''m trying to use your quantized version but i''m stuck on
          the following error.<br>"Input type (float) and bias type (struct c10::Half)
          should be the same"<br>In "outputs = model.generate("</p>

          <p>I guess some kind of normalization is needed. can you help me? This is
          my code:<br>from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration<br>import
          torch<br>from PIL import Image<br>import requests</p>

          <p>model = InstructBlipForConditionalGeneration.from_pretrained("Mediocreatmybest/instructblip-vicuna-13b_8bit")<br>processor
          = InstructBlipProcessor.from_pretrained("Mediocreatmybest/instructblip-vicuna-13b_8bit")</p>

          <p>device = "cuda" if torch.cuda.is_available() else "cpu"</p>

          <p>url = "<a rel="nofollow" href="https://raw.githubusercontent.com/salesforce/LAVIS/main/docs/_static/Confusing-Pictures.jpg&quot;">https://raw.githubusercontent.com/salesforce/LAVIS/main/docs/_static/Confusing-Pictures.jpg"</a><br>image
          = Image.open(requests.get(url, stream=True).raw).convert("RGB")<br>prompt
          = "What is unusual about this image?"<br>inputs = processor(images=image,
          text=prompt, return_tensors="pt").to(device)</p>

          <p>outputs = model.generate(<br>        **inputs,<br>        do_sample=False,<br>        num_beams=5,<br>        max_length=256,<br>        min_length=1,<br>        top_p=0.9,<br>        repetition_penalty=1.5,<br>        length_penalty=1.0,<br>        temperature=1,<br>)<br>generated_text
          = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()<br>print(generated_text)</p>

          '
        raw: "Hi, I'm trying to use your quantized version but i'm stuck on the following\
          \ error.\r\n\"Input type (float) and bias type (struct c10::Half) should\
          \ be the same\"\r\nIn \"outputs = model.generate(\"\r\n\r\nI guess some\
          \ kind of normalization is needed. can you help me? This is my code:\r\n\
          from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\r\
          \nimport torch\r\nfrom PIL import Image\r\nimport requests\r\n\r\nmodel\
          \ = InstructBlipForConditionalGeneration.from_pretrained(\"Mediocreatmybest/instructblip-vicuna-13b_8bit\"\
          )\r\nprocessor = InstructBlipProcessor.from_pretrained(\"Mediocreatmybest/instructblip-vicuna-13b_8bit\"\
          )\r\n\r\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n\
          \r\nurl = \"https://raw.githubusercontent.com/salesforce/LAVIS/main/docs/_static/Confusing-Pictures.jpg\"\
          \r\nimage = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\"\
          )\r\nprompt = \"What is unusual about this image?\"\r\ninputs = processor(images=image,\
          \ text=prompt, return_tensors=\"pt\").to(device)\r\n\r\noutputs = model.generate(\r\
          \n        **inputs,\r\n        do_sample=False,\r\n        num_beams=5,\r\
          \n        max_length=256,\r\n        min_length=1,\r\n        top_p=0.9,\r\
          \n        repetition_penalty=1.5,\r\n        length_penalty=1.0,\r\n   \
          \     temperature=1,\r\n)\r\ngenerated_text = processor.batch_decode(outputs,\
          \ skip_special_tokens=True)[0].strip()\r\nprint(generated_text)"
        updatedAt: '2023-08-06T18:25:04.107Z'
      numEdits: 0
      reactions: []
    id: 64cfe5801ed6649d708d506b
    type: comment
  author: manzonif
  content: "Hi, I'm trying to use your quantized version but i'm stuck on the following\
    \ error.\r\n\"Input type (float) and bias type (struct c10::Half) should be the\
    \ same\"\r\nIn \"outputs = model.generate(\"\r\n\r\nI guess some kind of normalization\
    \ is needed. can you help me? This is my code:\r\nfrom transformers import InstructBlipProcessor,\
    \ InstructBlipForConditionalGeneration\r\nimport torch\r\nfrom PIL import Image\r\
    \nimport requests\r\n\r\nmodel = InstructBlipForConditionalGeneration.from_pretrained(\"\
    Mediocreatmybest/instructblip-vicuna-13b_8bit\")\r\nprocessor = InstructBlipProcessor.from_pretrained(\"\
    Mediocreatmybest/instructblip-vicuna-13b_8bit\")\r\n\r\ndevice = \"cuda\" if torch.cuda.is_available()\
    \ else \"cpu\"\r\n\r\nurl = \"https://raw.githubusercontent.com/salesforce/LAVIS/main/docs/_static/Confusing-Pictures.jpg\"\
    \r\nimage = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\r\n\
    prompt = \"What is unusual about this image?\"\r\ninputs = processor(images=image,\
    \ text=prompt, return_tensors=\"pt\").to(device)\r\n\r\noutputs = model.generate(\r\
    \n        **inputs,\r\n        do_sample=False,\r\n        num_beams=5,\r\n  \
    \      max_length=256,\r\n        min_length=1,\r\n        top_p=0.9,\r\n    \
    \    repetition_penalty=1.5,\r\n        length_penalty=1.0,\r\n        temperature=1,\r\
    \n)\r\ngenerated_text = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\r\
    \nprint(generated_text)"
  created_at: 2023-08-06 17:25:04+00:00
  edited: false
  hidden: false
  id: 64cfe5801ed6649d708d506b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e593120f0184651471397f5b34d9b39f.svg
      fullname: Fausto Manzoni
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: manzonif
      type: user
    createdAt: '2023-08-06T19:44:11.000Z'
    data:
      edited: false
      editors:
      - manzonif
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5540488958358765
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e593120f0184651471397f5b34d9b39f.svg
          fullname: Fausto Manzoni
          isHf: false
          isPro: false
          name: manzonif
          type: user
        html: '<p>Sorry, solved reading your code.<br><a rel="nofollow" href="https://github.com/mediocreatmybest/gaslightingeveryone/blob/eb4208dcec12749a0534435106ec561d0b928a2b/Scripts/working/func_transformers.py#L16">https://github.com/mediocreatmybest/gaslightingeveryone/blob/eb4208dcec12749a0534435106ec561d0b928a2b/Scripts/working/func_transformers.py#L16</a></p>

          '
        raw: 'Sorry, solved reading your code.

          https://github.com/mediocreatmybest/gaslightingeveryone/blob/eb4208dcec12749a0534435106ec561d0b928a2b/Scripts/working/func_transformers.py#L16'
        updatedAt: '2023-08-06T19:44:11.774Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Mediocreatmybest
    id: 64cff80b9cff73820382e2f8
    type: comment
  author: manzonif
  content: 'Sorry, solved reading your code.

    https://github.com/mediocreatmybest/gaslightingeveryone/blob/eb4208dcec12749a0534435106ec561d0b928a2b/Scripts/working/func_transformers.py#L16'
  created_at: 2023-08-06 18:44:11+00:00
  edited: false
  hidden: false
  id: 64cff80b9cff73820382e2f8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676512038653-63074ea3cb09c0a90429ce3b.png?w=200&h=200&f=face
      fullname: Sir Mediocre Jr, Esq.
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Mediocreatmybest
      type: user
    createdAt: '2023-08-21T11:45:42.000Z'
    data:
      edited: false
      editors:
      - Mediocreatmybest
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9631420969963074
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676512038653-63074ea3cb09c0a90429ce3b.png?w=200&h=200&f=face
          fullname: Sir Mediocre Jr, Esq.
          isHf: false
          isPro: false
          name: Mediocreatmybest
          type: user
        html: '<p>Awesome, sorry missed the question due to notifications. Glad you
          got it working :) </p>

          '
        raw: "Awesome, sorry missed the question due to notifications. Glad you got\
          \ it working :) \n\n"
        updatedAt: '2023-08-21T11:45:42.359Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64e34e6624809d7fa0f8c07e
    id: 64e34e6624809d7fa0f8c07d
    type: comment
  author: Mediocreatmybest
  content: "Awesome, sorry missed the question due to notifications. Glad you got\
    \ it working :) \n\n"
  created_at: 2023-08-21 10:45:42+00:00
  edited: false
  hidden: false
  id: 64e34e6624809d7fa0f8c07d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676512038653-63074ea3cb09c0a90429ce3b.png?w=200&h=200&f=face
      fullname: Sir Mediocre Jr, Esq.
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Mediocreatmybest
      type: user
    createdAt: '2023-08-21T11:45:42.000Z'
    data:
      status: closed
    id: 64e34e6624809d7fa0f8c07e
    type: status-change
  author: Mediocreatmybest
  created_at: 2023-08-21 10:45:42+00:00
  id: 64e34e6624809d7fa0f8c07e
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Mediocreatmybest/instructblip-vicuna-13b_8bit
repo_type: model
status: closed
target_branch: null
title: Input type (float) and bias type (struct c10::Half) should be the same
