!!python/object:huggingface_hub.community.DiscussionWithDetails
author: gianlucav128
conflicting_files: null
created_at: 2023-05-09 08:11:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5faa040e320f427d31b4434f6a0fd16a.svg
      fullname: Gianluca Cavallaro
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gianlucav128
      type: user
    createdAt: '2023-05-09T09:11:11.000Z'
    data:
      edited: false
      editors:
      - gianlucav128
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5faa040e320f427d31b4434f6a0fd16a.svg
          fullname: Gianluca Cavallaro
          isHf: false
          isPro: false
          name: gianlucav128
          type: user
        html: "<p>I was trying the Colab Notebook: in particular, I modified the script\
          \ in order to generate an image for a list of prompts.<br>At first everything\
          \ went well, but then the runtime disconnected, probably because GPU usage\
          \ limits have been exceeded (I have the free version of Colab). Since then,\
          \ with the same exact code, I got a ZeroDivisionError when I try to generate\
          \ the images, in particular when the Text Embedding model is loaded. The\
          \ error is the following:</p>\n<pre><code>\u2502 /usr/local/lib/python3.10/dist-packages/accelerate/big_modeling.py:466\
          \ in                        \u2502\n\u2502 load_checkpoint_and_dispatch\
          \                                                                     \u2502\
          \n\u2502                                                               \
          \                                   \u2502\n\u2502   463 \u2502   \u2502\
          \   \u2502   \"'sequential'.\"                                         \
          \                       \u2502\n\u2502   464 \u2502   \u2502   )       \
          \                                                                      \
          \     \u2502\n\u2502   465 \u2502   if device_map != \"sequential\":   \
          \                                                      \u2502\n\u2502 \u2771\
          \ 466 \u2502   \u2502   max_memory = get_balanced_memory(              \
          \                                    \u2502\n\u2502   467 \u2502   \u2502\
          \   \u2502   model,                                                    \
          \                     \u2502\n\u2502   468 \u2502   \u2502   \u2502   max_memory=max_memory,\
          \                                                         \u2502\n\u2502\
          \   469 \u2502   \u2502   \u2502   no_split_module_classes=no_split_module_classes,\
          \                               \u2502\n\u2502                         \
          \                                                                      \
          \   \u2502\n\u2502 /usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:526\
          \ in get_balanced_memory  \u2502\n\u2502                               \
          \                                                                   \u2502\
          \n\u2502    523 \u2502   module_sizes = {n: v for n, v in module_sizes.items()\
          \ if n not in leaves}             \u2502\n\u2502    524 \u2502   # Once\
          \ removed, leaves are the final modules.                               \
          \          \u2502\n\u2502    525 \u2502   leaves = [n for n in module_sizes\
          \ if len([p for p in module_sizes if n == \"\" or p.st  \u2502\n\u2502 \u2771\
          \  526 \u2502   mean_leaves = int(sum([module_sizes[n] for n in leaves])\
          \ / len(leaves))               \u2502\n\u2502    527 \u2502   buffer = int(1.25\
          \ * max(buffer, mean_leaves))                                         \u2502\
          \n\u2502    528 \u2502   per_gpu += buffer \n\nZeroDivisionError: division\
          \ by zero\n</code></pre>\n<p>Has anyone idea how to fix this?</p>\n"
        raw: "I was trying the Colab Notebook: in particular, I modified the script\
          \ in order to generate an image for a list of prompts.\r\nAt first everything\
          \ went well, but then the runtime disconnected, probably because GPU usage\
          \ limits have been exceeded (I have the free version of Colab). Since then,\
          \ with the same exact code, I got a ZeroDivisionError when I try to generate\
          \ the images, in particular when the Text Embedding model is loaded. The\
          \ error is the following:\r\n\r\n```\r\n\u2502 /usr/local/lib/python3.10/dist-packages/accelerate/big_modeling.py:466\
          \ in                        \u2502\r\n\u2502 load_checkpoint_and_dispatch\
          \                                                                     \u2502\
          \r\n\u2502                                                             \
          \                                     \u2502\r\n\u2502   463 \u2502   \u2502\
          \   \u2502   \"'sequential'.\"                                         \
          \                       \u2502\r\n\u2502   464 \u2502   \u2502   )     \
          \                                                                      \
          \       \u2502\r\n\u2502   465 \u2502   if device_map != \"sequential\"\
          :                                                         \u2502\r\n\u2502\
          \ \u2771 466 \u2502   \u2502   max_memory = get_balanced_memory(       \
          \                                           \u2502\r\n\u2502   467 \u2502\
          \   \u2502   \u2502   model,                                           \
          \                              \u2502\r\n\u2502   468 \u2502   \u2502  \
          \ \u2502   max_memory=max_memory,                                      \
          \                   \u2502\r\n\u2502   469 \u2502   \u2502   \u2502   no_split_module_classes=no_split_module_classes,\
          \                               \u2502\r\n\u2502                       \
          \                                                                      \
          \     \u2502\r\n\u2502 /usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:526\
          \ in get_balanced_memory  \u2502\r\n\u2502                             \
          \                                                                     \u2502\
          \r\n\u2502    523 \u2502   module_sizes = {n: v for n, v in module_sizes.items()\
          \ if n not in leaves}             \u2502\r\n\u2502    524 \u2502   # Once\
          \ removed, leaves are the final modules.                               \
          \          \u2502\r\n\u2502    525 \u2502   leaves = [n for n in module_sizes\
          \ if len([p for p in module_sizes if n == \"\" or p.st  \u2502\r\n\u2502\
          \ \u2771  526 \u2502   mean_leaves = int(sum([module_sizes[n] for n in leaves])\
          \ / len(leaves))               \u2502\r\n\u2502    527 \u2502   buffer =\
          \ int(1.25 * max(buffer, mean_leaves))                                 \
          \        \u2502\r\n\u2502    528 \u2502   per_gpu += buffer \r\n\r\nZeroDivisionError:\
          \ division by zero\r\n```\r\n\r\nHas anyone idea how to fix this?"
        updatedAt: '2023-05-09T09:11:11.523Z'
      numEdits: 0
      reactions: []
    id: 645a0e2fc70a926dc46b9a9e
    type: comment
  author: gianlucav128
  content: "I was trying the Colab Notebook: in particular, I modified the script\
    \ in order to generate an image for a list of prompts.\r\nAt first everything\
    \ went well, but then the runtime disconnected, probably because GPU usage limits\
    \ have been exceeded (I have the free version of Colab). Since then, with the\
    \ same exact code, I got a ZeroDivisionError when I try to generate the images,\
    \ in particular when the Text Embedding model is loaded. The error is the following:\r\
    \n\r\n```\r\n\u2502 /usr/local/lib/python3.10/dist-packages/accelerate/big_modeling.py:466\
    \ in                        \u2502\r\n\u2502 load_checkpoint_and_dispatch    \
    \                                                                 \u2502\r\n\u2502\
    \                                                                            \
    \                      \u2502\r\n\u2502   463 \u2502   \u2502   \u2502   \"'sequential'.\"\
    \                                                                \u2502\r\n\u2502\
    \   464 \u2502   \u2502   )                                                  \
    \                                \u2502\r\n\u2502   465 \u2502   if device_map\
    \ != \"sequential\":                                                         \u2502\
    \r\n\u2502 \u2771 466 \u2502   \u2502   max_memory = get_balanced_memory(    \
    \                                              \u2502\r\n\u2502   467 \u2502 \
    \  \u2502   \u2502   model,                                                  \
    \                       \u2502\r\n\u2502   468 \u2502   \u2502   \u2502   max_memory=max_memory,\
    \                                                         \u2502\r\n\u2502   469\
    \ \u2502   \u2502   \u2502   no_split_module_classes=no_split_module_classes,\
    \                               \u2502\r\n\u2502                             \
    \                                                                     \u2502\r\
    \n\u2502 /usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:526\
    \ in get_balanced_memory  \u2502\r\n\u2502                                   \
    \                                                               \u2502\r\n\u2502\
    \    523 \u2502   module_sizes = {n: v for n, v in module_sizes.items() if n not\
    \ in leaves}             \u2502\r\n\u2502    524 \u2502   # Once removed, leaves\
    \ are the final modules.                                         \u2502\r\n\u2502\
    \    525 \u2502   leaves = [n for n in module_sizes if len([p for p in module_sizes\
    \ if n == \"\" or p.st  \u2502\r\n\u2502 \u2771  526 \u2502   mean_leaves = int(sum([module_sizes[n]\
    \ for n in leaves]) / len(leaves))               \u2502\r\n\u2502    527 \u2502\
    \   buffer = int(1.25 * max(buffer, mean_leaves))                            \
    \             \u2502\r\n\u2502    528 \u2502   per_gpu += buffer \r\n\r\nZeroDivisionError:\
    \ division by zero\r\n```\r\n\r\nHas anyone idea how to fix this?"
  created_at: 2023-05-09 08:11:11+00:00
  edited: false
  hidden: false
  id: 645a0e2fc70a926dc46b9a9e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/88cfe5a91b7abf8c9c2a0c1a7ab199b8.svg
      fullname: Matthew Berman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: matthewberman
      type: user
    createdAt: '2023-05-09T17:42:02.000Z'
    data:
      edited: false
      editors:
      - matthewberman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/88cfe5a91b7abf8c9c2a0c1a7ab199b8.svg
          fullname: Matthew Berman
          isHf: false
          isPro: false
          name: matthewberman
          type: user
        html: '<p>I got this error as well.</p>

          '
        raw: I got this error as well.
        updatedAt: '2023-05-09T17:42:02.446Z'
      numEdits: 0
      reactions: []
    id: 645a85eaff3871a77cb8788c
    type: comment
  author: matthewberman
  content: I got this error as well.
  created_at: 2023-05-09 16:42:02+00:00
  edited: false
  hidden: false
  id: 645a85eaff3871a77cb8788c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7a3969626dfc2acedee7d44921bf3191.svg
      fullname: LanceaKing
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LanceaKing
      type: user
    createdAt: '2023-05-10T03:31:25.000Z'
    data:
      edited: false
      editors:
      - LanceaKing
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7a3969626dfc2acedee7d44921bf3191.svg
          fullname: LanceaKing
          isHf: false
          isPro: false
          name: LanceaKing
          type: user
        html: '<p>I got the same issue.</p>

          '
        raw: I got the same issue.
        updatedAt: '2023-05-10T03:31:25.256Z'
      numEdits: 0
      reactions: []
    id: 645b100d52c5b0d1559826db
    type: comment
  author: LanceaKing
  content: I got the same issue.
  created_at: 2023-05-10 02:31:25+00:00
  edited: false
  hidden: false
  id: 645b100d52c5b0d1559826db
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5faa040e320f427d31b4434f6a0fd16a.svg
      fullname: Gianluca Cavallaro
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gianlucav128
      type: user
    createdAt: '2023-05-12T08:52:53.000Z'
    data:
      edited: false
      editors:
      - gianlucav128
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5faa040e320f427d31b4434f6a0fd16a.svg
          fullname: Gianluca Cavallaro
          isHf: false
          isPro: false
          name: gianlucav128
          type: user
        html: '<p>Thanks to a user on GitHub I was able to find a fairly reckless
          temporary workaround to the problem. I modified <code>modeling.py</code>
          to be:</p>

          <p><code>mean_leaves = int(sum([module_sizes[n] for n in leaves]) / ( len(leaves)
          or 1) )</code> </p>

          <p>Now I''m able to generate images without problems.</p>

          '
        raw: "Thanks to a user on GitHub I was able to find a fairly reckless temporary\
          \ workaround to the problem. I modified `modeling.py` to be:\n\n`mean_leaves\
          \ = int(sum([module_sizes[n] for n in leaves]) / ( len(leaves) or 1) )`\
          \ \n\nNow I'm able to generate images without problems."
        updatedAt: '2023-05-12T08:52:53.457Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - thenewguysfriend
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - thenewguysfriend
      - count: 1
        reaction: "\U0001F91D"
        users:
        - thenewguysfriend
    id: 645dfe6506166ed4d9e2d05e
    type: comment
  author: gianlucav128
  content: "Thanks to a user on GitHub I was able to find a fairly reckless temporary\
    \ workaround to the problem. I modified `modeling.py` to be:\n\n`mean_leaves =\
    \ int(sum([module_sizes[n] for n in leaves]) / ( len(leaves) or 1) )` \n\nNow\
    \ I'm able to generate images without problems."
  created_at: 2023-05-12 07:52:53+00:00
  edited: false
  hidden: false
  id: 645dfe6506166ed4d9e2d05e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/bzhuONwK5bsGn4YTWqDNw.jpeg?w=200&h=200&f=face
      fullname: Chirita Cristian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Bgeorge
      type: user
    createdAt: '2023-05-19T08:10:55.000Z'
    data:
      edited: false
      editors:
      - Bgeorge
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/bzhuONwK5bsGn4YTWqDNw.jpeg?w=200&h=200&f=face
          fullname: Chirita Cristian
          isHf: false
          isPro: false
          name: Bgeorge
          type: user
        html: '<p>Cause: the upgrade to accelerate~=0.20 cause the error</p>

          <p>Solution 1 was tested with  accelerate~=0.18</p>

          <p>Solution 1:<br>replace:</p>

          <p>! pip install --upgrade \ accelerate~=0.18</p>

          <p>with </p>

          <p>! pip install accelerate~=0.18</p>

          <p>Solution 2 not recommended:<br>#!pip install git+<a rel="nofollow" href="https://github.com/huggingface/accelerate">https://github.com/huggingface/accelerate</a></p>

          <p>Solution 3:<br>wait a couple of weeks  until accelerate patched version
          is installed via! pip install --upgrade \ accelerate~=0.18</p>

          '
        raw: "Cause: the upgrade to accelerate~=0.20 cause the error\n\nSolution 1\
          \ was tested with  accelerate~=0.18\n\nSolution 1:\nreplace:\n\n! pip install\
          \ --upgrade \\ accelerate~=0.18\n\nwith \n\n! pip install accelerate~=0.18\n\
          \nSolution 2 not recommended:\n#!pip install git+https://github.com/huggingface/accelerate\n\
          \nSolution 3:\nwait a couple of weeks  until accelerate patched version\
          \ is installed via! pip install --upgrade \\ accelerate~=0.18"
        updatedAt: '2023-05-19T08:10:55.933Z'
      numEdits: 0
      reactions: []
    id: 64672f0fab75d9cb3c4185df
    type: comment
  author: Bgeorge
  content: "Cause: the upgrade to accelerate~=0.20 cause the error\n\nSolution 1 was\
    \ tested with  accelerate~=0.18\n\nSolution 1:\nreplace:\n\n! pip install --upgrade\
    \ \\ accelerate~=0.18\n\nwith \n\n! pip install accelerate~=0.18\n\nSolution 2\
    \ not recommended:\n#!pip install git+https://github.com/huggingface/accelerate\n\
    \nSolution 3:\nwait a couple of weeks  until accelerate patched version is installed\
    \ via! pip install --upgrade \\ accelerate~=0.18"
  created_at: 2023-05-19 07:10:55+00:00
  edited: false
  hidden: false
  id: 64672f0fab75d9cb3c4185df
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 20
repo_id: DeepFloyd/IF-I-XL-v1.0
repo_type: model
status: open
target_branch: null
title: ZeroDivisionError while loading pretrained models
