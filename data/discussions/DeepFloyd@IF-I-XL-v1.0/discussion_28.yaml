!!python/object:huggingface_hub.community.DiscussionWithDetails
author: karthick18
conflicting_files: null
created_at: 2023-10-25 12:08:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0cd5e6be4c0c90c9cd966674d6e6e1a3.svg
      fullname: rajendran
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: karthick18
      type: user
    createdAt: '2023-10-25T13:08:44.000Z'
    data:
      edited: false
      editors:
      - karthick18
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4149033725261688
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0cd5e6be4c0c90c9cd966674d6e6e1a3.svg
          fullname: rajendran
          isHf: false
          isPro: false
          name: karthick18
          type: user
        html: '<p>UnboundLocalError                         Traceback (most recent
          call last)<br>Cell In[4], line 6<br>      3 import torch<br>      5 # stage
          1<br>----&gt; 6 stage_1 = DiffusionPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0",
          variant="fp16", torch_dtype=torch.float16)<br>      7 stage_1.enable_xformers_memory_efficient_attention()  #
          remove line if torch.<strong>version</strong> &gt;= 2.0.0<br>      8 stage_1.enable_model_cpu_offload()</p>

          <p>File ~/anaconda3/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:1105,
          in DiffusionPipeline.from_pretrained(cls, pretrained_model_name_or_path,
          **kwargs)<br>   1102     loaded_sub_model = passed_class_obj[name]<br>   1103
          else:<br>   1104     # load sub model<br>-&gt; 1105     loaded_sub_model
          = load_sub_model(<br>   1106         library_name=library_name,<br>   1107         class_name=class_name,<br>   1108         importable_classes=importable_classes,<br>   1109         pipelines=pipelines,<br>   1110         is_pipeline_module=is_pipeline_module,<br>   1111         pipeline_class=pipeline_class,<br>   1112         torch_dtype=torch_dtype,<br>   1113         provider=provider,<br>   1114         sess_options=sess_options,<br>   1115         device_map=device_map,<br>   1116         max_memory=max_memory,<br>   1117         offload_folder=offload_folder,<br>   1118         offload_state_dict=offload_state_dict,<br>   1119         model_variants=model_variants,<br>   1120         name=name,<br>   1121         from_flax=from_flax,<br>   1122         variant=variant,<br>   1123         low_cpu_mem_usage=low_cpu_mem_usage,<br>   1124         cached_folder=cached_folder,<br>   1125     )<br>   1126     logger.info(<br>   1127         f"Loaded
          {name} as {class_name} from <code>{name}</code> subfolder of {pretrained_model_name_or_path}."<br>   1128     )<br>   1130
          init_kwargs[name] = loaded_sub_model  # UNet(...), # DiffusionSchedule(...)</p>

          <p>File ~/anaconda3/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:472,
          in load_sub_model(library_name, class_name, importable_classes, pipelines,
          is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options,
          device_map, max_memory, offload_folder, offload_state_dict, model_variants,
          name, from_flax, variant, low_cpu_mem_usage, cached_folder)<br>    470 #
          check if the module is in a subdirectory<br>    471 if os.path.isdir(os.path.join(cached_folder,
          name)):<br>--&gt; 472     loaded_sub_model = load_method(os.path.join(cached_folder,
          name), **loading_kwargs)<br>    473 else:<br>    474     # else load from
          the root directory<br>    475     loaded_sub_model = load_method(cached_folder,
          **loading_kwargs)</p>

          <p>File ~/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1854,
          in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,
          cache_dir, force_download, local_files_only, token, revision, *init_inputs,
          **kwargs)<br>   1851     else:<br>   1852         logger.info(f"loading
          file {file_path} from cache at {resolved_vocab_files[file_id]}")<br>-&gt;
          1854 return cls._from_pretrained(<br>   1855     resolved_vocab_files,<br>   1856     pretrained_model_name_or_path,<br>   1857     init_configuration,<br>   1858     *init_inputs,<br>   1859     token=token,<br>   1860     cache_dir=cache_dir,<br>   1861     local_files_only=local_files_only,<br>   1862     _commit_hash=commit_hash,<br>   1863     _is_local=is_local,<br>   1864     **kwargs,<br>   1865
          )</p>

          <p>File ~/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2017,
          in PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path,
          init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local,
          *init_inputs, **kwargs)<br>   2015 # Instantiate tokenizer.<br>   2016 try:<br>-&gt;
          2017     tokenizer = cls(*init_inputs, **init_kwargs)<br>   2018 except
          OSError:<br>   2019     raise OSError(<br>   2020         "Unable to load
          vocabulary from file. "<br>   2021         "Please check that the provided
          vocabulary is accessible and not corrupted."<br>   2022     )</p>

          <p>File ~/anaconda3/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5.py:194,
          in T5Tokenizer.<strong>init</strong>(self, vocab_file, eos_token, unk_token,
          pad_token, extra_ids, additional_special_tokens, sp_model_kwargs, legacy,
          **kwargs)<br>    191 self.vocab_file = vocab_file<br>    192 self._extra_ids
          = extra_ids<br>--&gt; 194 self.sp_model = self.get_spm_processor()</p>

          <p>File ~/anaconda3/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5.py:200,
          in T5Tokenizer.get_spm_processor(self)<br>    198 with open(self.vocab_file,
          "rb") as f:<br>    199     sp_model = f.read()<br>--&gt; 200     model_pb2
          = import_protobuf()<br>    201     model = model_pb2.ModelProto.FromString(sp_model)<br>    202     if
          not self.legacy:</p>

          <p>File ~/anaconda3/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:40,
          in import_protobuf()<br>     38     else:<br>     39         from transformers.utils
          import sentencepiece_model_pb2_new as sentencepiece_model_pb2<br>---&gt;
          40 return sentencepiece_model_pb2</p>

          <p>UnboundLocalError: cannot access local variable ''sentencepiece_model_pb2''
          where it is not associated with a value</p>

          '
        raw: "UnboundLocalError                         Traceback (most recent call\
          \ last)\r\nCell In[4], line 6\r\n      3 import torch\r\n      5 # stage\
          \ 1\r\n----> 6 stage_1 = DiffusionPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\"\
          , variant=\"fp16\", torch_dtype=torch.float16)\r\n      7 stage_1.enable_xformers_memory_efficient_attention()\
          \  # remove line if torch.__version__ >= 2.0.0\r\n      8 stage_1.enable_model_cpu_offload()\r\
          \n\r\nFile ~/anaconda3/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:1105,\
          \ in DiffusionPipeline.from_pretrained(cls, pretrained_model_name_or_path,\
          \ **kwargs)\r\n   1102     loaded_sub_model = passed_class_obj[name]\r\n\
          \   1103 else:\r\n   1104     # load sub model\r\n-> 1105     loaded_sub_model\
          \ = load_sub_model(\r\n   1106         library_name=library_name,\r\n  \
          \ 1107         class_name=class_name,\r\n   1108         importable_classes=importable_classes,\r\
          \n   1109         pipelines=pipelines,\r\n   1110         is_pipeline_module=is_pipeline_module,\r\
          \n   1111         pipeline_class=pipeline_class,\r\n   1112         torch_dtype=torch_dtype,\r\
          \n   1113         provider=provider,\r\n   1114         sess_options=sess_options,\r\
          \n   1115         device_map=device_map,\r\n   1116         max_memory=max_memory,\r\
          \n   1117         offload_folder=offload_folder,\r\n   1118         offload_state_dict=offload_state_dict,\r\
          \n   1119         model_variants=model_variants,\r\n   1120         name=name,\r\
          \n   1121         from_flax=from_flax,\r\n   1122         variant=variant,\r\
          \n   1123         low_cpu_mem_usage=low_cpu_mem_usage,\r\n   1124      \
          \   cached_folder=cached_folder,\r\n   1125     )\r\n   1126     logger.info(\r\
          \n   1127         f\"Loaded {name} as {class_name} from `{name}` subfolder\
          \ of {pretrained_model_name_or_path}.\"\r\n   1128     )\r\n   1130 init_kwargs[name]\
          \ = loaded_sub_model  # UNet(...), # DiffusionSchedule(...)\r\n\r\nFile\
          \ ~/anaconda3/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:472,\
          \ in load_sub_model(library_name, class_name, importable_classes, pipelines,\
          \ is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options,\
          \ device_map, max_memory, offload_folder, offload_state_dict, model_variants,\
          \ name, from_flax, variant, low_cpu_mem_usage, cached_folder)\r\n    470\
          \ # check if the module is in a subdirectory\r\n    471 if os.path.isdir(os.path.join(cached_folder,\
          \ name)):\r\n--> 472     loaded_sub_model = load_method(os.path.join(cached_folder,\
          \ name), **loading_kwargs)\r\n    473 else:\r\n    474     # else load from\
          \ the root directory\r\n    475     loaded_sub_model = load_method(cached_folder,\
          \ **loading_kwargs)\r\n\r\nFile ~/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1854,\
          \ in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,\
          \ cache_dir, force_download, local_files_only, token, revision, *init_inputs,\
          \ **kwargs)\r\n   1851     else:\r\n   1852         logger.info(f\"loading\
          \ file {file_path} from cache at {resolved_vocab_files[file_id]}\")\r\n\
          -> 1854 return cls._from_pretrained(\r\n   1855     resolved_vocab_files,\r\
          \n   1856     pretrained_model_name_or_path,\r\n   1857     init_configuration,\r\
          \n   1858     *init_inputs,\r\n   1859     token=token,\r\n   1860     cache_dir=cache_dir,\r\
          \n   1861     local_files_only=local_files_only,\r\n   1862     _commit_hash=commit_hash,\r\
          \n   1863     _is_local=is_local,\r\n   1864     **kwargs,\r\n   1865 )\r\
          \n\r\nFile ~/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2017,\
          \ in PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files,\
          \ pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only,\
          \ _commit_hash, _is_local, *init_inputs, **kwargs)\r\n   2015 # Instantiate\
          \ tokenizer.\r\n   2016 try:\r\n-> 2017     tokenizer = cls(*init_inputs,\
          \ **init_kwargs)\r\n   2018 except OSError:\r\n   2019     raise OSError(\r\
          \n   2020         \"Unable to load vocabulary from file. \"\r\n   2021 \
          \        \"Please check that the provided vocabulary is accessible and not\
          \ corrupted.\"\r\n   2022     )\r\n\r\nFile ~/anaconda3/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5.py:194,\
          \ in T5Tokenizer.__init__(self, vocab_file, eos_token, unk_token, pad_token,\
          \ extra_ids, additional_special_tokens, sp_model_kwargs, legacy, **kwargs)\r\
          \n    191 self.vocab_file = vocab_file\r\n    192 self._extra_ids = extra_ids\r\
          \n--> 194 self.sp_model = self.get_spm_processor()\r\n\r\nFile ~/anaconda3/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5.py:200,\
          \ in T5Tokenizer.get_spm_processor(self)\r\n    198 with open(self.vocab_file,\
          \ \"rb\") as f:\r\n    199     sp_model = f.read()\r\n--> 200     model_pb2\
          \ = import_protobuf()\r\n    201     model = model_pb2.ModelProto.FromString(sp_model)\r\
          \n    202     if not self.legacy:\r\n\r\nFile ~/anaconda3/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:40,\
          \ in import_protobuf()\r\n     38     else:\r\n     39         from transformers.utils\
          \ import sentencepiece_model_pb2_new as sentencepiece_model_pb2\r\n--->\
          \ 40 return sentencepiece_model_pb2\r\n\r\nUnboundLocalError: cannot access\
          \ local variable 'sentencepiece_model_pb2' where it is not associated with\
          \ a value\r\n"
        updatedAt: '2023-10-25T13:08:44.711Z'
      numEdits: 0
      reactions: []
    id: 6539135ce9cbac8f4207287e
    type: comment
  author: karthick18
  content: "UnboundLocalError                         Traceback (most recent call\
    \ last)\r\nCell In[4], line 6\r\n      3 import torch\r\n      5 # stage 1\r\n\
    ----> 6 stage_1 = DiffusionPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\"\
    , variant=\"fp16\", torch_dtype=torch.float16)\r\n      7 stage_1.enable_xformers_memory_efficient_attention()\
    \  # remove line if torch.__version__ >= 2.0.0\r\n      8 stage_1.enable_model_cpu_offload()\r\
    \n\r\nFile ~/anaconda3/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:1105,\
    \ in DiffusionPipeline.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\r\
    \n   1102     loaded_sub_model = passed_class_obj[name]\r\n   1103 else:\r\n \
    \  1104     # load sub model\r\n-> 1105     loaded_sub_model = load_sub_model(\r\
    \n   1106         library_name=library_name,\r\n   1107         class_name=class_name,\r\
    \n   1108         importable_classes=importable_classes,\r\n   1109         pipelines=pipelines,\r\
    \n   1110         is_pipeline_module=is_pipeline_module,\r\n   1111         pipeline_class=pipeline_class,\r\
    \n   1112         torch_dtype=torch_dtype,\r\n   1113         provider=provider,\r\
    \n   1114         sess_options=sess_options,\r\n   1115         device_map=device_map,\r\
    \n   1116         max_memory=max_memory,\r\n   1117         offload_folder=offload_folder,\r\
    \n   1118         offload_state_dict=offload_state_dict,\r\n   1119         model_variants=model_variants,\r\
    \n   1120         name=name,\r\n   1121         from_flax=from_flax,\r\n   1122\
    \         variant=variant,\r\n   1123         low_cpu_mem_usage=low_cpu_mem_usage,\r\
    \n   1124         cached_folder=cached_folder,\r\n   1125     )\r\n   1126   \
    \  logger.info(\r\n   1127         f\"Loaded {name} as {class_name} from `{name}`\
    \ subfolder of {pretrained_model_name_or_path}.\"\r\n   1128     )\r\n   1130\
    \ init_kwargs[name] = loaded_sub_model  # UNet(...), # DiffusionSchedule(...)\r\
    \n\r\nFile ~/anaconda3/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:472,\
    \ in load_sub_model(library_name, class_name, importable_classes, pipelines, is_pipeline_module,\
    \ pipeline_class, torch_dtype, provider, sess_options, device_map, max_memory,\
    \ offload_folder, offload_state_dict, model_variants, name, from_flax, variant,\
    \ low_cpu_mem_usage, cached_folder)\r\n    470 # check if the module is in a subdirectory\r\
    \n    471 if os.path.isdir(os.path.join(cached_folder, name)):\r\n--> 472    \
    \ loaded_sub_model = load_method(os.path.join(cached_folder, name), **loading_kwargs)\r\
    \n    473 else:\r\n    474     # else load from the root directory\r\n    475\
    \     loaded_sub_model = load_method(cached_folder, **loading_kwargs)\r\n\r\n\
    File ~/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1854,\
    \ in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,\
    \ cache_dir, force_download, local_files_only, token, revision, *init_inputs,\
    \ **kwargs)\r\n   1851     else:\r\n   1852         logger.info(f\"loading file\
    \ {file_path} from cache at {resolved_vocab_files[file_id]}\")\r\n-> 1854 return\
    \ cls._from_pretrained(\r\n   1855     resolved_vocab_files,\r\n   1856     pretrained_model_name_or_path,\r\
    \n   1857     init_configuration,\r\n   1858     *init_inputs,\r\n   1859    \
    \ token=token,\r\n   1860     cache_dir=cache_dir,\r\n   1861     local_files_only=local_files_only,\r\
    \n   1862     _commit_hash=commit_hash,\r\n   1863     _is_local=is_local,\r\n\
    \   1864     **kwargs,\r\n   1865 )\r\n\r\nFile ~/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2017,\
    \ in PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path,\
    \ init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local,\
    \ *init_inputs, **kwargs)\r\n   2015 # Instantiate tokenizer.\r\n   2016 try:\r\
    \n-> 2017     tokenizer = cls(*init_inputs, **init_kwargs)\r\n   2018 except OSError:\r\
    \n   2019     raise OSError(\r\n   2020         \"Unable to load vocabulary from\
    \ file. \"\r\n   2021         \"Please check that the provided vocabulary is accessible\
    \ and not corrupted.\"\r\n   2022     )\r\n\r\nFile ~/anaconda3/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5.py:194,\
    \ in T5Tokenizer.__init__(self, vocab_file, eos_token, unk_token, pad_token, extra_ids,\
    \ additional_special_tokens, sp_model_kwargs, legacy, **kwargs)\r\n    191 self.vocab_file\
    \ = vocab_file\r\n    192 self._extra_ids = extra_ids\r\n--> 194 self.sp_model\
    \ = self.get_spm_processor()\r\n\r\nFile ~/anaconda3/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5.py:200,\
    \ in T5Tokenizer.get_spm_processor(self)\r\n    198 with open(self.vocab_file,\
    \ \"rb\") as f:\r\n    199     sp_model = f.read()\r\n--> 200     model_pb2 =\
    \ import_protobuf()\r\n    201     model = model_pb2.ModelProto.FromString(sp_model)\r\
    \n    202     if not self.legacy:\r\n\r\nFile ~/anaconda3/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:40,\
    \ in import_protobuf()\r\n     38     else:\r\n     39         from transformers.utils\
    \ import sentencepiece_model_pb2_new as sentencepiece_model_pb2\r\n---> 40 return\
    \ sentencepiece_model_pb2\r\n\r\nUnboundLocalError: cannot access local variable\
    \ 'sentencepiece_model_pb2' where it is not associated with a value\r\n"
  created_at: 2023-10-25 12:08:44+00:00
  edited: false
  hidden: false
  id: 6539135ce9cbac8f4207287e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 28
repo_id: DeepFloyd/IF-I-XL-v1.0
repo_type: model
status: open
target_branch: null
title: Getting the below error
