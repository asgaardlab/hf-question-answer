!!python/object:huggingface_hub.community.DiscussionWithDetails
author: YameiW
conflicting_files: null
created_at: 2022-09-28 15:52:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0164cdfb83c7e0861b7eb20c85134535.svg
      fullname: YameiWang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YameiW
      type: user
    createdAt: '2022-09-28T16:52:37.000Z'
    data:
      edited: false
      editors:
      - YameiW
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0164cdfb83c7e0861b7eb20c85134535.svg
          fullname: YameiWang
          isHf: false
          isPro: false
          name: YameiW
          type: user
        html: "<p>Hello there,</p>\n<p>I am working on word embedding and was wondering\
          \ if there is a way to obtain a single vector for multi-token units in Chinese.\
          \ For instance, how to get one vector for the Chinese word \"\u516C\u65A4\
          \"  rather than two separate vectors for each of the characters. </p>\n\
          <p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/1664383921723-632366bd92e07e3ca204229e.png\"\
          ><img alt=\"Screen Shot 2022-09-28 at 12.51.30 PM.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/1664383921723-632366bd92e07e3ca204229e.png\"\
          ></a></p>\n"
        raw: "Hello there,\r\n\r\nI am working on word embedding and was wondering\
          \ if there is a way to obtain a single vector for multi-token units in Chinese.\
          \ For instance, how to get one vector for the Chinese word \"\u516C\u65A4\
          \"  rather than two separate vectors for each of the characters. \r\n\r\n\
          ![Screen Shot 2022-09-28 at 12.51.30 PM.png](https://cdn-uploads.huggingface.co/production/uploads/1664383921723-632366bd92e07e3ca204229e.png)\r\
          \n\r\n"
        updatedAt: '2022-09-28T16:52:37.878Z'
      numEdits: 0
      reactions: []
    id: 63347bd5259c518276eb5475
    type: comment
  author: YameiW
  content: "Hello there,\r\n\r\nI am working on word embedding and was wondering if\
    \ there is a way to obtain a single vector for multi-token units in Chinese. For\
    \ instance, how to get one vector for the Chinese word \"\u516C\u65A4\"  rather\
    \ than two separate vectors for each of the characters. \r\n\r\n![Screen Shot\
    \ 2022-09-28 at 12.51.30 PM.png](https://cdn-uploads.huggingface.co/production/uploads/1664383921723-632366bd92e07e3ca204229e.png)\r\
    \n\r\n"
  created_at: 2022-09-28 15:52:37+00:00
  edited: false
  hidden: false
  id: 63347bd5259c518276eb5475
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: uer/albert-base-chinese-cluecorpussmall
repo_type: model
status: open
target_branch: null
title: How to deal with multi-token units in embedding?
