!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Moneymaker2023
conflicting_files: null
created_at: 2023-10-26 18:39:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/03f824e744a48612fada28cda1a28540.svg
      fullname: Catalin Ciocea
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Moneymaker2023
      type: user
    createdAt: '2023-10-26T19:39:12.000Z'
    data:
      edited: false
      editors:
      - Moneymaker2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.965093731880188
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/03f824e744a48612fada28cda1a28540.svg
          fullname: Catalin Ciocea
          isHf: false
          isPro: false
          name: Moneymaker2023
          type: user
        html: '<p>If it is possible please tell me how to do it. I''m a novice looking
          for help. Thank you very much!</p>

          '
        raw: If it is possible please tell me how to do it. I'm a novice looking for
          help. Thank you very much!
        updatedAt: '2023-10-26T19:39:12.594Z'
      numEdits: 0
      reactions: []
    id: 653ac0609d53a3f85149dd46
    type: comment
  author: Moneymaker2023
  content: If it is possible please tell me how to do it. I'm a novice looking for
    help. Thank you very much!
  created_at: 2023-10-26 18:39:12+00:00
  edited: false
  hidden: false
  id: 653ac0609d53a3f85149dd46
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a3bb1cd0d8c2c2169f0b88/eT2TS0IlQbZtz-F_zHLz9.jpeg?w=200&h=200&f=face
      fullname: Joseph Pollack
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Tonic
      type: user
    createdAt: '2023-10-26T19:48:07.000Z'
    data:
      edited: true
      editors:
      - Tonic
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7648761868476868
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a3bb1cd0d8c2c2169f0b88/eT2TS0IlQbZtz-F_zHLz9.jpeg?w=200&h=200&f=face
          fullname: Joseph Pollack
          isHf: false
          isPro: false
          name: Tonic
          type: user
        html: '<p>not really "merge" , but basically "yes" , you will use torch adapters
          instead.</p>

          <p>You can use the model simply duplicate this space on a A10G : <a href="https://huggingface.co/spaces/pseudolab/MistralMED_Chat">https://huggingface.co/spaces/pseudo</a></p>

          '
        raw: 'not really "merge" , but basically "yes" , you will use torch adapters
          instead.


          You can use the model simply duplicate this space on a A10G : [https://huggingface.co/spaces/pseudo](https://huggingface.co/spaces/pseudolab/MistralMED_Chat)'
        updatedAt: '2023-10-26T19:49:21.967Z'
      numEdits: 1
      reactions: []
    id: 653ac2775cd715dafdbdcc52
    type: comment
  author: Tonic
  content: 'not really "merge" , but basically "yes" , you will use torch adapters
    instead.


    You can use the model simply duplicate this space on a A10G : [https://huggingface.co/spaces/pseudo](https://huggingface.co/spaces/pseudolab/MistralMED_Chat)'
  created_at: 2023-10-26 18:48:07+00:00
  edited: true
  hidden: false
  id: 653ac2775cd715dafdbdcc52
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a3bb1cd0d8c2c2169f0b88/eT2TS0IlQbZtz-F_zHLz9.jpeg?w=200&h=200&f=face
      fullname: Joseph Pollack
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Tonic
      type: user
    createdAt: '2023-10-26T19:50:26.000Z'
    data:
      edited: true
      editors:
      - Tonic
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9263749718666077
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a3bb1cd0d8c2c2169f0b88/eT2TS0IlQbZtz-F_zHLz9.jpeg?w=200&h=200&f=face
          fullname: Joseph Pollack
          isHf: false
          isPro: false
          name: Tonic
          type: user
        html: '<p>Or you can duplicate this space <a href="https://huggingface.co/spaces/tonic/mistralmed_chat">tonic/mistralmed_chat</a>.
          see the files Tab for the files and you can also clone this repository and
          run it locally. Hope this helps ! </p>

          '
        raw: 'Or you can duplicate this space [tonic/mistralmed_chat](https://huggingface.co/spaces/tonic/mistralmed_chat).
          see the files Tab for the files and you can also clone this repository and
          run it locally. Hope this helps ! '
        updatedAt: '2023-10-26T19:52:08.888Z'
      numEdits: 1
      reactions: []
    id: 653ac302ddaf1b38ca868997
    type: comment
  author: Tonic
  content: 'Or you can duplicate this space [tonic/mistralmed_chat](https://huggingface.co/spaces/tonic/mistralmed_chat).
    see the files Tab for the files and you can also clone this repository and run
    it locally. Hope this helps ! '
  created_at: 2023-10-26 18:50:26+00:00
  edited: true
  hidden: false
  id: 653ac302ddaf1b38ca868997
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/03f824e744a48612fada28cda1a28540.svg
      fullname: Catalin Ciocea
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Moneymaker2023
      type: user
    createdAt: '2023-10-27T07:30:58.000Z'
    data:
      edited: false
      editors:
      - Moneymaker2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9248652458190918
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/03f824e744a48612fada28cda1a28540.svg
          fullname: Catalin Ciocea
          isHf: false
          isPro: false
          name: Moneymaker2023
          type: user
        html: '<p>Thanks for answer. I have a laptop with 16 gb ram and Nvidia RTX
          4500 (6gb vram) . I want to use the model locally and If I quantise a mistral
          model .guff in 2 bites it works locally. But I want to quantise the finetuned
          model of yours ..so I need it to be merged in one model first then to quantise
          it so that it fit in my laptop and use it locally. Please if you know tell
          me how to merge it in one model (the finetune of yours with original mistral)
          . If I ask noob questions please forgive my ignorance . I''m just a noob
          amazed by AI and it''s opportunities :) . </p>

          '
        raw: 'Thanks for answer. I have a laptop with 16 gb ram and Nvidia RTX 4500
          (6gb vram) . I want to use the model locally and If I quantise a mistral
          model .guff in 2 bites it works locally. But I want to quantise the finetuned
          model of yours ..so I need it to be merged in one model first then to quantise
          it so that it fit in my laptop and use it locally. Please if you know tell
          me how to merge it in one model (the finetune of yours with original mistral)
          . If I ask noob questions please forgive my ignorance . I''m just a noob
          amazed by AI and it''s opportunities :) . '
        updatedAt: '2023-10-27T07:30:58.368Z'
      numEdits: 0
      reactions: []
    id: 653b67325f1703225b3ad169
    type: comment
  author: Moneymaker2023
  content: 'Thanks for answer. I have a laptop with 16 gb ram and Nvidia RTX 4500
    (6gb vram) . I want to use the model locally and If I quantise a mistral model
    .guff in 2 bites it works locally. But I want to quantise the finetuned model
    of yours ..so I need it to be merged in one model first then to quantise it so
    that it fit in my laptop and use it locally. Please if you know tell me how to
    merge it in one model (the finetune of yours with original mistral) . If I ask
    noob questions please forgive my ignorance . I''m just a noob amazed by AI and
    it''s opportunities :) . '
  created_at: 2023-10-27 06:30:58+00:00
  edited: false
  hidden: false
  id: 653b67325f1703225b3ad169
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: Tonic/mistralmed
repo_type: model
status: open
target_branch: null
title: Is it possible to merge the finetuned version with the original mistral model
  into one model ?
