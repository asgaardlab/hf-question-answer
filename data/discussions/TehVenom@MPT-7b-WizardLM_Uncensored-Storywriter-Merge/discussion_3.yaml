!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mpasila
conflicting_files: null
created_at: 2023-05-13 17:53:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7e5ccbc0dac5c1e16bdddd489802d363.svg
      fullname: minipasila
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mpasila
      type: user
    createdAt: '2023-05-13T18:53:12.000Z'
    data:
      edited: false
      editors:
      - mpasila
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7e5ccbc0dac5c1e16bdddd489802d363.svg
          fullname: minipasila
          isHf: false
          isPro: false
          name: mpasila
          type: user
        html: '<p>I tried doing it myself but ran into problems when using this: <a
          rel="nofollow" href="https://github.com/0cc4m/GPTQ-for-LLaMa">https://github.com/0cc4m/GPTQ-for-LLaMa</a>
          (it adds support for mpt models)</p>

          '
        raw: 'I tried doing it myself but ran into problems when using this: https://github.com/0cc4m/GPTQ-for-LLaMa
          (it adds support for mpt models)'
        updatedAt: '2023-05-13T18:53:12.004Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - bluesongcurls
        - mirek190
        - RiggityWrckd
    id: 645fdc98a40b7e364c426390
    type: comment
  author: mpasila
  content: 'I tried doing it myself but ran into problems when using this: https://github.com/0cc4m/GPTQ-for-LLaMa
    (it adds support for mpt models)'
  created_at: 2023-05-13 17:53:12+00:00
  edited: false
  hidden: false
  id: 645fdc98a40b7e364c426390
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-05-16T01:43:49.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> ?</p>\n"
        raw: '@TheBloke ?'
        updatedAt: '2023-05-16T01:43:49.081Z'
      numEdits: 0
      reactions: []
    id: 6462dfd5cce92c7d88310bf3
    type: comment
  author: ehartford
  content: '@TheBloke ?'
  created_at: 2023-05-16 00:43:49+00:00
  edited: false
  hidden: false
  id: 6462dfd5cce92c7d88310bf3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ad8daf7101b78ae4226f3ade0d64bbe6.svg
      fullname: Riggity Wrckd
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RiggityWrckd
      type: user
    createdAt: '2023-05-18T19:03:22.000Z'
    data:
      edited: true
      editors:
      - RiggityWrckd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ad8daf7101b78ae4226f3ade0d64bbe6.svg
          fullname: Riggity Wrckd
          isHf: false
          isPro: false
          name: RiggityWrckd
          type: user
        html: '<p>I was looking into this as well.  I tried to use main GPTQ-for-llama
          to quant it (this model just sounds a million times more promising than
          the original) but I''m getting errors because it is not a llama model.  I
          saw that like a week ago the Occam released a quanted version, so it is
          doable (<a href="https://huggingface.co/OccamRazor/mpt-7b-storywriter-4bit-128g">https://huggingface.co/OccamRazor/mpt-7b-storywriter-4bit-128g</a>).
          I just don''t know how.  I also looked through occam''s github with his
          version of koboldai and originally just didn''t see his GPTQ implementation.  </p>

          <p>Anyway, now that I see mpasila''s link I''m going to try that route.  I
          have data right now too so if it works I would be happy to upload a working
          model.  Maybe thebloke will beat me to it hah</p>

          <p>Edit: I tried every which way to make the GPTQ that was linked above
          work.  Does anyone have the sauce.  I even tried the gptneox which at least
          failed different way (cuda memory over run).  When I tried to run with llama
          version it screws up every time talking about the tokenizer not being compatable
          with the neox style tokenizer.</p>

          <p>I also tried installing the two different ways. The old way with the
          conda env and the new way by making a new conda env and then running the
          pip install git command they have listed on the repo.  Couldn''t get the
          pip install way to work at all.</p>

          '
        raw: "I was looking into this as well.  I tried to use main GPTQ-for-llama\
          \ to quant it (this model just sounds a million times more promising than\
          \ the original) but I'm getting errors because it is not a llama model.\
          \  I saw that like a week ago the Occam released a quanted version, so it\
          \ is doable (https://huggingface.co/OccamRazor/mpt-7b-storywriter-4bit-128g).\
          \ I just don't know how.  I also looked through occam's github with his\
          \ version of koboldai and originally just didn't see his GPTQ implementation.\
          \  \n\nAnyway, now that I see mpasila's link I'm going to try that route.\
          \  I have data right now too so if it works I would be happy to upload a\
          \ working model.  Maybe thebloke will beat me to it hah\n\nEdit: I tried\
          \ every which way to make the GPTQ that was linked above work.  Does anyone\
          \ have the sauce.  I even tried the gptneox which at least failed different\
          \ way (cuda memory over run).  When I tried to run with llama version it\
          \ screws up every time talking about the tokenizer not being compatable\
          \ with the neox style tokenizer.\n\nI also tried installing the two different\
          \ ways. The old way with the conda env and the new way by making a new conda\
          \ env and then running the pip install git command they have listed on the\
          \ repo.  Couldn't get the pip install way to work at all."
        updatedAt: '2023-05-18T20:57:18.329Z'
      numEdits: 3
      reactions: []
    id: 6466767a3b99ed9970ff6ef9
    type: comment
  author: RiggityWrckd
  content: "I was looking into this as well.  I tried to use main GPTQ-for-llama to\
    \ quant it (this model just sounds a million times more promising than the original)\
    \ but I'm getting errors because it is not a llama model.  I saw that like a week\
    \ ago the Occam released a quanted version, so it is doable (https://huggingface.co/OccamRazor/mpt-7b-storywriter-4bit-128g).\
    \ I just don't know how.  I also looked through occam's github with his version\
    \ of koboldai and originally just didn't see his GPTQ implementation.  \n\nAnyway,\
    \ now that I see mpasila's link I'm going to try that route.  I have data right\
    \ now too so if it works I would be happy to upload a working model.  Maybe thebloke\
    \ will beat me to it hah\n\nEdit: I tried every which way to make the GPTQ that\
    \ was linked above work.  Does anyone have the sauce.  I even tried the gptneox\
    \ which at least failed different way (cuda memory over run).  When I tried to\
    \ run with llama version it screws up every time talking about the tokenizer not\
    \ being compatable with the neox style tokenizer.\n\nI also tried installing the\
    \ two different ways. The old way with the conda env and the new way by making\
    \ a new conda env and then running the pip install git command they have listed\
    \ on the repo.  Couldn't get the pip install way to work at all."
  created_at: 2023-05-18 18:03:22+00:00
  edited: true
  hidden: false
  id: 6466767a3b99ed9970ff6ef9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-18T20:58:54.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I will have a look tomorrow if I have the time</p>

          '
        raw: I will have a look tomorrow if I have the time
        updatedAt: '2023-05-18T20:58:54.808Z'
      numEdits: 0
      reactions:
      - count: 6
        reaction: "\U0001F44D"
        users:
        - mpasila
        - pixelmelt
        - morka
        - Renegadesoffun
        - AIDesignerTester
        - Caustic
    id: 6466918e9c627c78f8700d9a
    type: comment
  author: TheBloke
  content: I will have a look tomorrow if I have the time
  created_at: 2023-05-18 19:58:54+00:00
  edited: false
  hidden: false
  id: 6466918e9c627c78f8700d9a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6448573b30fa4ecb85e2d184/Rn2MWykBh5BfOEZ2z0Vgi.png?w=200&h=200&f=face
      fullname: Ray Hernandez
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: perlthoughts
      type: user
    createdAt: '2023-05-21T20:45:09.000Z'
    data:
      edited: false
      editors:
      - perlthoughts
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6448573b30fa4ecb85e2d184/Rn2MWykBh5BfOEZ2z0Vgi.png?w=200&h=200&f=face
          fullname: Ray Hernandez
          isHf: false
          isPro: false
          name: perlthoughts
          type: user
        html: '<p>so if i had to guess we need that layer mapping...</p>

          '
        raw: so if i had to guess we need that layer mapping...
        updatedAt: '2023-05-21T20:45:09.932Z'
      numEdits: 0
      reactions: []
    id: 646a82d5f51b56a285c370c5
    type: comment
  author: perlthoughts
  content: so if i had to guess we need that layer mapping...
  created_at: 2023-05-21 19:45:09+00:00
  edited: false
  hidden: false
  id: 646a82d5f51b56a285c370c5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5c0d30f466356dd57ac1d863a7259693.svg
      fullname: Gideon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AIDesignerTester
      type: user
    createdAt: '2023-06-14T14:41:04.000Z'
    data:
      edited: false
      editors:
      - AIDesignerTester
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8124439716339111
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5c0d30f466356dd57ac1d863a7259693.svg
          fullname: Gideon
          isHf: false
          isPro: false
          name: AIDesignerTester
          type: user
        html: "<p>Looking forward to it! <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ Thanks! :D</p>\n"
        raw: Looking forward to it! @TheBloke Thanks! :D
        updatedAt: '2023-06-14T14:41:04.382Z'
      numEdits: 0
      reactions: []
    id: 6489d180cc462063538a2f9a
    type: comment
  author: AIDesignerTester
  content: Looking forward to it! @TheBloke Thanks! :D
  created_at: 2023-06-14 13:41:04+00:00
  edited: false
  hidden: false
  id: 6489d180cc462063538a2f9a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/43f1f158c74ed7caeb3918d55b23dd85.svg
      fullname: terry drake
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: drakkuza
      type: user
    createdAt: '2023-07-21T01:00:42.000Z'
    data:
      edited: false
      editors:
      - drakkuza
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.501924991607666
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/43f1f158c74ed7caeb3918d55b23dd85.svg
          fullname: terry drake
          isHf: false
          isPro: false
          name: drakkuza
          type: user
        html: "<p>any luck <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ </p>\n"
        raw: 'any luck @TheBloke '
        updatedAt: '2023-07-21T01:00:42.585Z'
      numEdits: 0
      reactions: []
    id: 64b9d8ba62c0bfc57391aec0
    type: comment
  author: drakkuza
  content: 'any luck @TheBloke '
  created_at: 2023-07-21 00:00:42+00:00
  edited: false
  hidden: false
  id: 64b9d8ba62c0bfc57391aec0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TehVenom/MPT-7b-WizardLM_Uncensored-Storywriter-Merge
repo_type: model
status: open
target_branch: null
title: 4 bit version?
