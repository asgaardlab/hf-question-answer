!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ShaneTian
conflicting_files: null
created_at: 2023-10-25 06:25:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660138927470-62e37ac7a0be7413eb879b0a.jpeg?w=200&h=200&f=face
      fullname: Shane Tian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShaneTian
      type: user
    createdAt: '2023-10-25T07:25:56.000Z'
    data:
      edited: false
      editors:
      - ShaneTian
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.804369330406189
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660138927470-62e37ac7a0be7413eb879b0a.jpeg?w=200&h=200&f=face
          fullname: Shane Tian
          isHf: false
          isPro: false
          name: ShaneTian
          type: user
        html: '<p>Why does Code-Llama-34B not support infilling mode, i.e. FIM</p>

          '
        raw: Why does Code-Llama-34B not support infilling mode, i.e. FIM
        updatedAt: '2023-10-25T07:25:56.196Z'
      numEdits: 0
      reactions: []
    id: 6538c3049d7dd331b2a0fee8
    type: comment
  author: ShaneTian
  content: Why does Code-Llama-34B not support infilling mode, i.e. FIM
  created_at: 2023-10-25 06:25:56+00:00
  edited: false
  hidden: false
  id: 6538c3049d7dd331b2a0fee8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
      fullname: Pedro Cuenca
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: pcuenq
      type: user
    createdAt: '2023-10-25T07:43:11.000Z'
    data:
      edited: false
      editors:
      - pcuenq
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8857942819595337
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
          fullname: Pedro Cuenca
          isHf: true
          isPro: false
          name: pcuenq
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;ShaneTian&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ShaneTian\"\
          >@<span class=\"underline\">ShaneTian</span></a></span>\n\n\t</span></span>!\
          \ It's because the large model was not trained for that task. See the <a\
          \ rel=\"nofollow\" href=\"https://ai.meta.com/blog/code-llama-large-language-model-coding/\"\
          >original announcement post</a> for details.</p>\n"
        raw: Hi @ShaneTian! It's because the large model was not trained for that
          task. See the [original announcement post](https://ai.meta.com/blog/code-llama-large-language-model-coding/)
          for details.
        updatedAt: '2023-10-25T07:43:11.761Z'
      numEdits: 0
      reactions: []
    id: 6538c70f61d44e23f3e4d27c
    type: comment
  author: pcuenq
  content: Hi @ShaneTian! It's because the large model was not trained for that task.
    See the [original announcement post](https://ai.meta.com/blog/code-llama-large-language-model-coding/)
    for details.
  created_at: 2023-10-25 06:43:11+00:00
  edited: false
  hidden: false
  id: 6538c70f61d44e23f3e4d27c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: codellama/CodeLlama-34b-hf
repo_type: model
status: open
target_branch: null
title: Why does Code-Llama-34B not support infilling mode, i.e. FIM
