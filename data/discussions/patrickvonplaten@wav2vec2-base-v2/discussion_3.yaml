!!python/object:huggingface_hub.community.DiscussionWithDetails
author: huutuongtu
conflicting_files: null
created_at: 2023-10-10 23:45:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9d940746a9e8a5f4775d8d8c9a13cd4c.svg
      fullname: Huu Tuong Tu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: huutuongtu
      type: user
    createdAt: '2023-10-11T00:45:38.000Z'
    data:
      edited: false
      editors:
      - huutuongtu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8467450737953186
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9d940746a9e8a5f4775d8d8c9a13cd4c.svg
          fullname: Huu Tuong Tu
          isHf: false
          isPro: false
          name: huutuongtu
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;patrickvonplaten&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/patrickvonplaten\"\
          >@<span class=\"underline\">patrickvonplaten</span></a></span>\n\n\t</span></span>,\
          \ I am training wav2vec2 with my own unlabeled datasets (about 300h) following\
          \ this code: <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-pretraining\"\
          >https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-pretraining</a><br>My\
          \ settings:<br>max_train_steps = 120000<br>num_warmup_steps= 32000<br>lr\
          \ = 0.001<br>batch_size = 2<br>I don't know when I train, contrastive loss\
          \ and grad_norm quickly decrease and equal zero (in about 400-500 steps).\
          \ Do you have any idea for fix this? Thank you</p>\n"
        raw: "Hello @patrickvonplaten, I am training wav2vec2 with my own unlabeled\
          \ datasets (about 300h) following this code: https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-pretraining\r\
          \nMy settings:\r\nmax_train_steps = 120000\r\nnum_warmup_steps= 32000\r\n\
          lr = 0.001\r\nbatch_size = 2\r\nI don't know when I train, contrastive loss\
          \ and grad_norm quickly decrease and equal zero (in about 400-500 steps).\
          \ Do you have any idea for fix this? Thank you"
        updatedAt: '2023-10-11T00:45:38.641Z'
      numEdits: 0
      reactions: []
    id: 6525f03227bc44de70fe89a7
    type: comment
  author: huutuongtu
  content: "Hello @patrickvonplaten, I am training wav2vec2 with my own unlabeled\
    \ datasets (about 300h) following this code: https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-pretraining\r\
    \nMy settings:\r\nmax_train_steps = 120000\r\nnum_warmup_steps= 32000\r\nlr =\
    \ 0.001\r\nbatch_size = 2\r\nI don't know when I train, contrastive loss and grad_norm\
    \ quickly decrease and equal zero (in about 400-500 steps). Do you have any idea\
    \ for fix this? Thank you"
  created_at: 2023-10-10 23:45:38+00:00
  edited: false
  hidden: false
  id: 6525f03227bc44de70fe89a7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: patrickvonplaten/wav2vec2-base-v2
repo_type: model
status: open
target_branch: null
title: About train Wav2Vec2-PreTraining
