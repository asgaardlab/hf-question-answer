!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Hovav
conflicting_files: null
created_at: 2023-06-01 07:43:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9eafd4502ec168eacf4eb765875e9f8b.svg
      fullname: Schreiber
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hovav
      type: user
    createdAt: '2023-06-01T08:43:05.000Z'
    data:
      edited: false
      editors:
      - Hovav
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9eafd4502ec168eacf4eb765875e9f8b.svg
          fullname: Schreiber
          isHf: false
          isPro: false
          name: Hovav
          type: user
        html: '<p>Hi, i''m trying to use the text-generation-webui api to run the
          model. The line i''m running: python server.py --api --api-blocking-port
          8827 --api-streaming-port 8815 --model TheBloke_guanaco-65B-GPTQ --wbits
          4 --chat .<br>It loads the model correctl, i''m connecting to api but when
          i''m trying to send prompt it gives the message:<br>  File "/home/users/<em>/</em>/text-generation-webui/repositories/GPTQ-for-LLaMa/quant.py",
          line 426, in forward<br>    quant_cuda.vecquant4matmul(x, self.qweight,
          y, self.scales, self.qzeros, self.groupsize)<br>TypeError: vecquant4matmul():
          incompatible function arguments. The following argument types are supported:<br>    1.
          (arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor,
          arg4: torch.Tensor, arg5: torch.Tensor) -&gt; None</p>

          <p>When im running the model using the webui everything works good.</p>

          <p>Any advice? Thanks!</p>

          '
        raw: "Hi, i'm trying to use the text-generation-webui api to run the model.\
          \ The line i'm running: python server.py --api --api-blocking-port 8827\
          \ --api-streaming-port 8815 --model TheBloke_guanaco-65B-GPTQ --wbits 4\
          \ --chat .\r\nIt loads the model correctl, i'm connecting to api but when\
          \ i'm trying to send prompt it gives the message: \r\n  File \"/home/users/*/*/text-generation-webui/repositories/GPTQ-for-LLaMa/quant.py\"\
          , line 426, in forward\r\n    quant_cuda.vecquant4matmul(x, self.qweight,\
          \ y, self.scales, self.qzeros, self.groupsize)\r\nTypeError: vecquant4matmul():\
          \ incompatible function arguments. The following argument types are supported:\r\
          \n    1. (arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3:\
          \ torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor) -> None\r\n\r\n\
          When im running the model using the webui everything works good.\r\n\r\n\
          Any advice? Thanks!\r\n\r\n"
        updatedAt: '2023-06-01T08:43:05.245Z'
      numEdits: 0
      reactions: []
    id: 64785a197b370854241ac951
    type: comment
  author: Hovav
  content: "Hi, i'm trying to use the text-generation-webui api to run the model.\
    \ The line i'm running: python server.py --api --api-blocking-port 8827 --api-streaming-port\
    \ 8815 --model TheBloke_guanaco-65B-GPTQ --wbits 4 --chat .\r\nIt loads the model\
    \ correctl, i'm connecting to api but when i'm trying to send prompt it gives\
    \ the message: \r\n  File \"/home/users/*/*/text-generation-webui/repositories/GPTQ-for-LLaMa/quant.py\"\
    , line 426, in forward\r\n    quant_cuda.vecquant4matmul(x, self.qweight, y, self.scales,\
    \ self.qzeros, self.groupsize)\r\nTypeError: vecquant4matmul(): incompatible function\
    \ arguments. The following argument types are supported:\r\n    1. (arg0: torch.Tensor,\
    \ arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor,\
    \ arg5: torch.Tensor) -> None\r\n\r\nWhen im running the model using the webui\
    \ everything works good.\r\n\r\nAny advice? Thanks!\r\n\r\n"
  created_at: 2023-06-01 07:43:05+00:00
  edited: false
  hidden: false
  id: 64785a197b370854241ac951
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-01T08:44:56.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Firstly just checking you have 48GB of VRAM available? If not, I
          wouldn''t recommend using this model.</p>

          <p>If so, then this error looks to be because of some issues with your GPTQ-for-LLaMa
          install.  How have you installed text-generation-webui and GPTQ-for-LLaMa?  Did
          you recently try upgrading or changing GPTQ-for-LLaMa?</p>

          '
        raw: 'Firstly just checking you have 48GB of VRAM available? If not, I wouldn''t
          recommend using this model.


          If so, then this error looks to be because of some issues with your GPTQ-for-LLaMa
          install.  How have you installed text-generation-webui and GPTQ-for-LLaMa?  Did
          you recently try upgrading or changing GPTQ-for-LLaMa?'
        updatedAt: '2023-06-01T08:44:56.591Z'
      numEdits: 0
      reactions: []
    id: 64785a881f9756aa89cc5d66
    type: comment
  author: TheBloke
  content: 'Firstly just checking you have 48GB of VRAM available? If not, I wouldn''t
    recommend using this model.


    If so, then this error looks to be because of some issues with your GPTQ-for-LLaMa
    install.  How have you installed text-generation-webui and GPTQ-for-LLaMa?  Did
    you recently try upgrading or changing GPTQ-for-LLaMa?'
  created_at: 2023-06-01 07:44:56+00:00
  edited: false
  hidden: false
  id: 64785a881f9756aa89cc5d66
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9eafd4502ec168eacf4eb765875e9f8b.svg
      fullname: Schreiber
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hovav
      type: user
    createdAt: '2023-06-01T08:57:15.000Z'
    data:
      edited: false
      editors:
      - Hovav
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9eafd4502ec168eacf4eb765875e9f8b.svg
          fullname: Schreiber
          isHf: false
          isPro: false
          name: Hovav
          type: user
        html: '<p>Yes, I have more then 48GB of VRAM. When i''m accessing the textgen
          webui and loading the model using 4bit everything works correctly, I can
          send prompts and it generates the text so I don''t think its environment
          problem. I''ve installed the text gen webui using the one-click installer
          for linux. For testing the api I''m using the script api-example-chat.py
          in the text-generation-webui folder. The api working good for other models
          but not for the guanaco-65B-GPTQ. Maybe its configuration problem?</p>

          '
        raw: Yes, I have more then 48GB of VRAM. When i'm accessing the textgen webui
          and loading the model using 4bit everything works correctly, I can send
          prompts and it generates the text so I don't think its environment problem.
          I've installed the text gen webui using the one-click installer for linux.
          For testing the api I'm using the script api-example-chat.py in the text-generation-webui
          folder. The api working good for other models but not for the guanaco-65B-GPTQ.
          Maybe its configuration problem?
        updatedAt: '2023-06-01T08:57:15.260Z'
      numEdits: 0
      reactions: []
    id: 64785d6b159a889d001fd5b3
    type: comment
  author: Hovav
  content: Yes, I have more then 48GB of VRAM. When i'm accessing the textgen webui
    and loading the model using 4bit everything works correctly, I can send prompts
    and it generates the text so I don't think its environment problem. I've installed
    the text gen webui using the one-click installer for linux. For testing the api
    I'm using the script api-example-chat.py in the text-generation-webui folder.
    The api working good for other models but not for the guanaco-65B-GPTQ. Maybe
    its configuration problem?
  created_at: 2023-06-01 07:57:15+00:00
  edited: false
  hidden: false
  id: 64785d6b159a889d001fd5b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9eafd4502ec168eacf4eb765875e9f8b.svg
      fullname: Schreiber
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hovav
      type: user
    createdAt: '2023-06-01T10:28:04.000Z'
    data:
      edited: false
      editors:
      - Hovav
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9eafd4502ec168eacf4eb765875e9f8b.svg
          fullname: Schreiber
          isHf: false
          isPro: false
          name: Hovav
          type: user
        html: '<p>Sorry, it seems it was environment problem after all. I reinstalled
          it and now it worked. Thanks for the quick reply!</p>

          '
        raw: Sorry, it seems it was environment problem after all. I reinstalled it
          and now it worked. Thanks for the quick reply!
        updatedAt: '2023-06-01T10:28:04.088Z'
      numEdits: 0
      reactions: []
    id: 647872b4ad83f3939b4a09bf
    type: comment
  author: Hovav
  content: Sorry, it seems it was environment problem after all. I reinstalled it
    and now it worked. Thanks for the quick reply!
  created_at: 2023-06-01 09:28:04+00:00
  edited: false
  hidden: false
  id: 647872b4ad83f3939b4a09bf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-01T10:29:42.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Great, glad it''s working</p>

          '
        raw: Great, glad it's working
        updatedAt: '2023-06-01T10:29:42.829Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Kaizen55
    id: 647873169c1f42c1f4dc19ab
    type: comment
  author: TheBloke
  content: Great, glad it's working
  created_at: 2023-06-01 09:29:42+00:00
  edited: false
  hidden: false
  id: 647873169c1f42c1f4dc19ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6fe2cf1a94ba2d755820bbaa40e66671.svg
      fullname: Satyam Gupta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sat7166
      type: user
    createdAt: '2023-08-03T05:25:11.000Z'
    data:
      edited: false
      editors:
      - sat7166
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.911687970161438
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6fe2cf1a94ba2d755820bbaa40e66671.svg
          fullname: Satyam Gupta
          isHf: false
          isPro: false
          name: sat7166
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Hovav&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Hovav\">@<span class=\"\
          underline\">Hovav</span></a></span>\n\n\t</span></span> , I am very new\
          \ to text-gen web UI. Is it possible to load my local models as API keys,\
          \ like Open Ai keys?<br>For example, I've been following many tutorials,\
          \ and most of them use open_ai keys, I instead want to use my local models\
          \ instead. Is there a way to do this?</p>\n<p>If possible, please point\
          \ me towards articles/blogs/tutorials that do this.<br>Thanks.</p>\n"
        raw: "@Hovav , I am very new to text-gen web UI. Is it possible to load my\
          \ local models as API keys, like Open Ai keys?\nFor example, I've been following\
          \ many tutorials, and most of them use open_ai keys, I instead want to use\
          \ my local models instead. Is there a way to do this?\n\nIf possible, please\
          \ point me towards articles/blogs/tutorials that do this. \nThanks."
        updatedAt: '2023-08-03T05:25:11.038Z'
      numEdits: 0
      reactions: []
    id: 64cb3a3776200ec80fec6bc3
    type: comment
  author: sat7166
  content: "@Hovav , I am very new to text-gen web UI. Is it possible to load my local\
    \ models as API keys, like Open Ai keys?\nFor example, I've been following many\
    \ tutorials, and most of them use open_ai keys, I instead want to use my local\
    \ models instead. Is there a way to do this?\n\nIf possible, please point me towards\
    \ articles/blogs/tutorials that do this. \nThanks."
  created_at: 2023-08-03 04:25:11+00:00
  edited: false
  hidden: false
  id: 64cb3a3776200ec80fec6bc3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-08-05T09:51:24.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9356187582015991
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Sat7166&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Sat7166\">@<span class=\"\
          underline\">Sat7166</span></a></span>\n\n\t</span></span> yes it's possible.\
          \ text-generation-webui has its own API which you can use.  And it has an\
          \ extension which provides an OpenAI compatible API - ie you can hit text-generation-webui\
          \ using exactly the same code as you would hit OpenAI.  Check the text-generation-webui\
          \ Github for more details</p>\n<p>I can't find any tutorials on it, but\
          \ there's info in their Github and people discussing it in various places,\
          \ so you can try Googling for more info</p>\n"
        raw: '@Sat7166 yes it''s possible. text-generation-webui has its own API which
          you can use.  And it has an extension which provides an OpenAI compatible
          API - ie you can hit text-generation-webui using exactly the same code as
          you would hit OpenAI.  Check the text-generation-webui Github for more details


          I can''t find any tutorials on it, but there''s info in their Github and
          people discussing it in various places, so you can try Googling for more
          info'
        updatedAt: '2023-08-05T09:51:24.749Z'
      numEdits: 0
      reactions: []
    id: 64ce1b9c7e20ec9ea08805d6
    type: comment
  author: TheBloke
  content: '@Sat7166 yes it''s possible. text-generation-webui has its own API which
    you can use.  And it has an extension which provides an OpenAI compatible API
    - ie you can hit text-generation-webui using exactly the same code as you would
    hit OpenAI.  Check the text-generation-webui Github for more details


    I can''t find any tutorials on it, but there''s info in their Github and people
    discussing it in various places, so you can try Googling for more info'
  created_at: 2023-08-05 08:51:24+00:00
  edited: false
  hidden: false
  id: 64ce1b9c7e20ec9ea08805d6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6fe2cf1a94ba2d755820bbaa40e66671.svg
      fullname: Satyam Gupta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sat7166
      type: user
    createdAt: '2023-08-06T08:55:46.000Z'
    data:
      edited: false
      editors:
      - sat7166
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9817267656326294
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6fe2cf1a94ba2d755820bbaa40e66671.svg
          fullname: Satyam Gupta
          isHf: false
          isPro: false
          name: sat7166
          type: user
        html: "<p>Thanks for your reply <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ , I'll check it out.<br>Also, I wanted to thank you for your work. I am\
          \ new to LLMs, but I like them very, very much. I've never really been so\
          \ hyper-focused on anything before, and I love this feeling of working on\
          \ new LLM-related projects.<br>You are a big part in helping me develop\
          \ this as I have a m1 pro setup, and GGML versions are really my saviour\
          \ here xD.<br>Though I'd be very happy if you could point me towards online\
          \ resources where I could learn more about LLM's, what makes them tick and\
          \ how to optimize them in the right way. I have of course read through a\
          \ lot of articles but it gets kinda overwhelming sometimes.<br>Thanks</p>\n"
        raw: 'Thanks for your reply @TheBloke , I''ll check it out.

          Also, I wanted to thank you for your work. I am new to LLMs, but I like
          them very, very much. I''ve never really been so hyper-focused on anything
          before, and I love this feeling of working on new LLM-related projects.

          You are a big part in helping me develop this as I have a m1 pro setup,
          and GGML versions are really my saviour here xD.

          Though I''d be very happy if you could point me towards online resources
          where I could learn more about LLM''s, what makes them tick and how to optimize
          them in the right way. I have of course read through a lot of articles but
          it gets kinda overwhelming sometimes.

          Thanks'
        updatedAt: '2023-08-06T08:55:46.989Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - ahtripleblind
    id: 64cf60129e9ca8123da12925
    type: comment
  author: sat7166
  content: 'Thanks for your reply @TheBloke , I''ll check it out.

    Also, I wanted to thank you for your work. I am new to LLMs, but I like them very,
    very much. I''ve never really been so hyper-focused on anything before, and I
    love this feeling of working on new LLM-related projects.

    You are a big part in helping me develop this as I have a m1 pro setup, and GGML
    versions are really my saviour here xD.

    Though I''d be very happy if you could point me towards online resources where
    I could learn more about LLM''s, what makes them tick and how to optimize them
    in the right way. I have of course read through a lot of articles but it gets
    kinda overwhelming sometimes.

    Thanks'
  created_at: 2023-08-06 07:55:46+00:00
  edited: false
  hidden: false
  id: 64cf60129e9ca8123da12925
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c8f85d56e1830a40cf6cf2e967cc07df.svg
      fullname: Adam
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ahtripleblind
      type: user
    createdAt: '2023-08-08T20:45:28.000Z'
    data:
      edited: false
      editors:
      - ahtripleblind
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8413241505622864
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c8f85d56e1830a40cf6cf2e967cc07df.svg
          fullname: Adam
          isHf: false
          isPro: false
          name: ahtripleblind
          type: user
        html: '<p>Hi Sat some extra info on the API messaging supported can be found
          here: <a rel="nofollow" href="https://github.com/oobabooga/text-generation-webui/blob/main/api-examples/api-example-chat-stream.py">https://github.com/oobabooga/text-generation-webui/blob/main/api-examples/api-example-chat-stream.py</a></p>

          <p>I am also looking for some more info on it and will post as i come across
          it!</p>

          '
        raw: 'Hi Sat some extra info on the API messaging supported can be found here:
          https://github.com/oobabooga/text-generation-webui/blob/main/api-examples/api-example-chat-stream.py


          I am also looking for some more info on it and will post as i come across
          it!'
        updatedAt: '2023-08-08T20:45:28.629Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F91D"
        users:
        - mrmegadream
        - sat7166
    id: 64d2a968afaeb11208ea439e
    type: comment
  author: ahtripleblind
  content: 'Hi Sat some extra info on the API messaging supported can be found here:
    https://github.com/oobabooga/text-generation-webui/blob/main/api-examples/api-example-chat-stream.py


    I am also looking for some more info on it and will post as i come across it!'
  created_at: 2023-08-08 19:45:28+00:00
  edited: false
  hidden: false
  id: 64d2a968afaeb11208ea439e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6fe2cf1a94ba2d755820bbaa40e66671.svg
      fullname: Satyam Gupta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sat7166
      type: user
    createdAt: '2023-08-09T10:53:01.000Z'
    data:
      edited: false
      editors:
      - sat7166
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7053481340408325
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6fe2cf1a94ba2d755820bbaa40e66671.svg
          fullname: Satyam Gupta
          isHf: false
          isPro: false
          name: sat7166
          type: user
        html: '<p>@ ahtripleblind, thanks :-)</p>

          '
        raw: '@ ahtripleblind, thanks :-)'
        updatedAt: '2023-08-09T10:53:01.549Z'
      numEdits: 0
      reactions: []
    id: 64d3700d3ce34445f5df9510
    type: comment
  author: sat7166
  content: '@ ahtripleblind, thanks :-)'
  created_at: 2023-08-09 09:53:01+00:00
  edited: false
  hidden: false
  id: 64d3700d3ce34445f5df9510
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9d49386f0635fd04b1a8138985a72000.svg
      fullname: Bhargav
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: flake9
      type: user
    createdAt: '2023-08-21T12:38:41.000Z'
    data:
      edited: false
      editors:
      - flake9
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8147401809692383
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9d49386f0635fd04b1a8138985a72000.svg
          fullname: Bhargav
          isHf: false
          isPro: false
          name: flake9
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Hovav&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Hovav\">@<span class=\"\
          underline\">Hovav</span></a></span>\n\n\t</span></span> i am implementing\
          \ kind of similar use case. Are you running this on Runpod?</p>\n"
        raw: '@Hovav i am implementing kind of similar use case. Are you running this
          on Runpod?'
        updatedAt: '2023-08-21T12:38:41.471Z'
      numEdits: 0
      reactions: []
    id: 64e35ad1623074ac85ecdcee
    type: comment
  author: flake9
  content: '@Hovav i am implementing kind of similar use case. Are you running this
    on Runpod?'
  created_at: 2023-08-21 11:38:41+00:00
  edited: false
  hidden: false
  id: 64e35ad1623074ac85ecdcee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/84861731fce8e3d0308780ebaf11850f.svg
      fullname: Adam
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kaizen55
      type: user
    createdAt: '2023-08-21T12:40:35.000Z'
    data:
      edited: false
      editors:
      - Kaizen55
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8077491521835327
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/84861731fce8e3d0308780ebaf11850f.svg
          fullname: Adam
          isHf: false
          isPro: false
          name: Kaizen55
          type: user
        html: '<p>As a side note I ended up using huggingface chatui. The documentation
          is a lot better defined and clear </p>

          <p>Best of luck!!</p>

          '
        raw: "As a side note I ended up using huggingface chatui. The documentation\
          \ is a lot better defined and clear \n\n\nBest of luck!!"
        updatedAt: '2023-08-21T12:40:35.330Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - ahtripleblind
        - sat7166
    id: 64e35b4352a2eece10a89c67
    type: comment
  author: Kaizen55
  content: "As a side note I ended up using huggingface chatui. The documentation\
    \ is a lot better defined and clear \n\n\nBest of luck!!"
  created_at: 2023-08-21 11:40:35+00:00
  edited: false
  hidden: false
  id: 64e35b4352a2eece10a89c67
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: TheBloke/guanaco-65B-GPTQ
repo_type: model
status: open
target_branch: null
title: Using the text-generation-webui api  with the model
