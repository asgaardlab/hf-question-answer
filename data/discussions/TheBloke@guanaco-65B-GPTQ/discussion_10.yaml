!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rafa9
conflicting_files: null
created_at: 2023-06-03 20:30:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/04b2b2e284c9479a4e4a1ab6df5f526c.svg
      fullname: Rafa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rafa9
      type: user
    createdAt: '2023-06-03T21:30:09.000Z'
    data:
      edited: true
      editors:
      - rafa9
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5159051418304443
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/04b2b2e284c9479a4e4a1ab6df5f526c.svg
          fullname: Rafa
          isHf: false
          isPro: false
          name: rafa9
          type: user
        html: "<p>The model loads successfully on runpod but when entering a prompt\
          \ it gives this error:<br><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ </p>\n<p>Stacktrace:</p>\n<pre><code>Traceback (most recent call last):\n\
          \  File \"/root/text-generation-webui/modules/callbacks.py\", line 73, in\
          \ gentask\n    ret = self.mfunc(callback=_callback, **self.kwargs)\n  File\
          \ \"/root/text-generation-webui/modules/text_generation.py\", line 286,\
          \ in generate_with_callback\n    shared.model.generate(**kwargs)\n  File\
          \ \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\"\
          , line 1568, in generate\n    return self.sample(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\"\
          , line 2615, in sample\n    outputs = self(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\",\
          \ line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\"\
          , line 687, in forward\n    outputs = self.model(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\"\
          , line 577, in forward\n    layer_outputs = decoder_layer(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\",\
          \ line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\"\
          , line 292, in forward\n    hidden_states, self_attn_weights, present_key_value\
          \ = self.self_attn(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\",\
          \ line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\"\
          , line 194, in forward\n    query_states = self.q_proj(hidden_states).view(bsz,\
          \ q_len, self.num_heads, self.head_dim).transpose(1, 2)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\",\
          \ line 160, in new_forward\n    args, kwargs = module._hf_hook.pre_forward(module,\
          \ *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\"\
          , line 280, in pre_forward\n    set_module_tensor_to_device(module, name,\
          \ self.execution_device, value=self.weights_map[name])\n  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/offload.py\"\
          , line 123, in __getitem__\n    return self.dataset[f\"{self.prefix}{key}\"\
          ]\n  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/offload.py\"\
          , line 170, in __getitem__\n    weight_info = self.index[key]\nKeyError:\
          \ 'model.layers.16.self_attn.q_proj.wf1'\n</code></pre>\n"
        raw: "The model loads successfully on runpod but when entering a prompt it\
          \ gives this error:\n@TheBloke \n\nStacktrace:\n```\nTraceback (most recent\
          \ call last):\n  File \"/root/text-generation-webui/modules/callbacks.py\"\
          , line 73, in gentask\n    ret = self.mfunc(callback=_callback, **self.kwargs)\n\
          \  File \"/root/text-generation-webui/modules/text_generation.py\", line\
          \ 286, in generate_with_callback\n    shared.model.generate(**kwargs)\n\
          \  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\"\
          , line 1568, in generate\n    return self.sample(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\"\
          , line 2615, in sample\n    outputs = self(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\",\
          \ line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\"\
          , line 687, in forward\n    outputs = self.model(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\"\
          , line 577, in forward\n    layer_outputs = decoder_layer(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\",\
          \ line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\"\
          , line 292, in forward\n    hidden_states, self_attn_weights, present_key_value\
          \ = self.self_attn(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\",\
          \ line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\"\
          , line 194, in forward\n    query_states = self.q_proj(hidden_states).view(bsz,\
          \ q_len, self.num_heads, self.head_dim).transpose(1, 2)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\",\
          \ line 160, in new_forward\n    args, kwargs = module._hf_hook.pre_forward(module,\
          \ *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\"\
          , line 280, in pre_forward\n    set_module_tensor_to_device(module, name,\
          \ self.execution_device, value=self.weights_map[name])\n  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/offload.py\"\
          , line 123, in __getitem__\n    return self.dataset[f\"{self.prefix}{key}\"\
          ]\n  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/offload.py\"\
          , line 170, in __getitem__\n    weight_info = self.index[key]\nKeyError:\
          \ 'model.layers.16.self_attn.q_proj.wf1'\n```"
        updatedAt: '2023-06-03T21:30:28.685Z'
      numEdits: 1
      reactions: []
    id: 647bb0e16a79fbf5e99893dc
    type: comment
  author: rafa9
  content: "The model loads successfully on runpod but when entering a prompt it gives\
    \ this error:\n@TheBloke \n\nStacktrace:\n```\nTraceback (most recent call last):\n\
    \  File \"/root/text-generation-webui/modules/callbacks.py\", line 73, in gentask\n\
    \    ret = self.mfunc(callback=_callback, **self.kwargs)\n  File \"/root/text-generation-webui/modules/text_generation.py\"\
    , line 286, in generate_with_callback\n    shared.model.generate(**kwargs)\n \
    \ File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\"\
    , line 1568, in generate\n    return self.sample(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\"\
    , line 2615, in sample\n    outputs = self(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\", line 165, in new_forward\n\
    \    output = old_forward(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\"\
    , line 687, in forward\n    outputs = self.model(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\"\
    , line 577, in forward\n    layer_outputs = decoder_layer(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\", line 165, in new_forward\n\
    \    output = old_forward(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\"\
    , line 292, in forward\n    hidden_states, self_attn_weights, present_key_value\
    \ = self.self_attn(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\", line 165, in new_forward\n\
    \    output = old_forward(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\"\
    , line 194, in forward\n    query_states = self.q_proj(hidden_states).view(bsz,\
    \ q_len, self.num_heads, self.head_dim).transpose(1, 2)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\", line 160, in new_forward\n\
    \    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)\n  File\
    \ \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\", line 280, in\
    \ pre_forward\n    set_module_tensor_to_device(module, name, self.execution_device,\
    \ value=self.weights_map[name])\n  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/offload.py\"\
    , line 123, in __getitem__\n    return self.dataset[f\"{self.prefix}{key}\"]\n\
    \  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/offload.py\"\
    , line 170, in __getitem__\n    weight_info = self.index[key]\nKeyError: 'model.layers.16.self_attn.q_proj.wf1'\n\
    ```"
  created_at: 2023-06-03 20:30:09+00:00
  edited: true
  hidden: false
  id: 647bb0e16a79fbf5e99893dc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-04T10:26:25.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9247481822967529
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Can you try the download again to confirm it downloaded successfully
          - sometimes those downloads abort half way through.  The text-gen-ui downloader
          will automatically resume from where it left off, so it won''t have to dowloand
          the whole thing again.</p>

          <p>Let me know if you still get the error after re-downloading.</p>

          '
        raw: 'Can you try the download again to confirm it downloaded successfully
          - sometimes those downloads abort half way through.  The text-gen-ui downloader
          will automatically resume from where it left off, so it won''t have to dowloand
          the whole thing again.


          Let me know if you still get the error after re-downloading.'
        updatedAt: '2023-06-04T10:26:25.787Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - rafa9
    id: 647c66d160dfe0f35d4d7159
    type: comment
  author: TheBloke
  content: 'Can you try the download again to confirm it downloaded successfully -
    sometimes those downloads abort half way through.  The text-gen-ui downloader
    will automatically resume from where it left off, so it won''t have to dowloand
    the whole thing again.


    Let me know if you still get the error after re-downloading.'
  created_at: 2023-06-04 09:26:25+00:00
  edited: false
  hidden: false
  id: 647c66d160dfe0f35d4d7159
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/04b2b2e284c9479a4e4a1ab6df5f526c.svg
      fullname: Rafa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rafa9
      type: user
    createdAt: '2023-06-04T20:39:11.000Z'
    data:
      edited: false
      editors:
      - rafa9
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9713582396507263
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/04b2b2e284c9479a4e4a1ab6df5f526c.svg
          fullname: Rafa
          isHf: false
          isPro: false
          name: rafa9
          type: user
        html: '<p>Thanks I tried downloading again and it worked!</p>

          '
        raw: Thanks I tried downloading again and it worked!
        updatedAt: '2023-06-04T20:39:11.353Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Ichsan2895
    id: 647cf66f83c62f3249260c08
    type: comment
  author: rafa9
  content: Thanks I tried downloading again and it worked!
  created_at: 2023-06-04 19:39:11+00:00
  edited: false
  hidden: false
  id: 647cf66f83c62f3249260c08
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/04b2b2e284c9479a4e4a1ab6df5f526c.svg
      fullname: Rafa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rafa9
      type: user
    createdAt: '2023-06-04T20:39:16.000Z'
    data:
      status: closed
    id: 647cf6741c0644de8d3286e9
    type: status-change
  author: rafa9
  created_at: 2023-06-04 19:39:16+00:00
  id: 647cf6741c0644de8d3286e9
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: TheBloke/guanaco-65B-GPTQ
repo_type: model
status: closed
target_branch: null
title: 'Getting KeyError: ''model.layers.16.self_attn.q_proj.wf1'' on trying to prompt
  on Runpod'
