!!python/object:huggingface_hub.community.DiscussionWithDetails
author: matthewberman
conflicting_files: null
created_at: 2023-05-29 20:02:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/88cfe5a91b7abf8c9c2a0c1a7ab199b8.svg
      fullname: Matthew Berman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: matthewberman
      type: user
    createdAt: '2023-05-29T21:02:24.000Z'
    data:
      edited: false
      editors:
      - matthewberman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/88cfe5a91b7abf8c9c2a0c1a7ab199b8.svg
          fullname: Matthew Berman
          isHf: false
          isPro: false
          name: matthewberman
          type: user
        html: "<p>I tried following the instructions but keep running into an issue\
          \ on runpod:</p>\n<p>Traceback (most recent call last):<br>File \u201C/workspace/text-generation-webui/server.py\u201D\
          , line 100, in load_model_wrapper<br>shared.model, shared.tokenizer = load_model(shared.model_name)<br>File\
          \ \u201C/workspace/text-generation-webui/modules/models.py\u201D, line 125,\
          \ in load_model<br>from modules.GPTQ_loader import load_quantized<br>File\
          \ \u201C/workspace/text-generation-webui/modules/GPTQ_loader.py\u201D, line\
          \ 14, in<br>import llama_inference_offload<br>ModuleNotFoundError: No module\
          \ named \u2018llama_inference_offload\u2019</p>\n<p>This is after setting\
          \ the parameters/variables and then clicking \"reload the model\" </p>\n\
          <p>How do I fix this?</p>\n"
        raw: "I tried following the instructions but keep running into an issue on\
          \ runpod:\r\n\r\nTraceback (most recent call last):\r\nFile \u201C/workspace/text-generation-webui/server.py\u201D\
          , line 100, in load_model_wrapper\r\nshared.model, shared.tokenizer = load_model(shared.model_name)\r\
          \nFile \u201C/workspace/text-generation-webui/modules/models.py\u201D, line\
          \ 125, in load_model\r\nfrom modules.GPTQ_loader import load_quantized\r\
          \nFile \u201C/workspace/text-generation-webui/modules/GPTQ_loader.py\u201D\
          , line 14, in\r\nimport llama_inference_offload\r\nModuleNotFoundError:\
          \ No module named \u2018llama_inference_offload\u2019\r\n\r\nThis is after\
          \ setting the parameters/variables and then clicking \"reload the model\"\
          \ \r\n\r\nHow do I fix this?"
        updatedAt: '2023-05-29T21:02:24.947Z'
      numEdits: 0
      reactions: []
    id: 647512e0bb0e9dd77649518a
    type: comment
  author: matthewberman
  content: "I tried following the instructions but keep running into an issue on runpod:\r\
    \n\r\nTraceback (most recent call last):\r\nFile \u201C/workspace/text-generation-webui/server.py\u201D\
    , line 100, in load_model_wrapper\r\nshared.model, shared.tokenizer = load_model(shared.model_name)\r\
    \nFile \u201C/workspace/text-generation-webui/modules/models.py\u201D, line 125,\
    \ in load_model\r\nfrom modules.GPTQ_loader import load_quantized\r\nFile \u201C\
    /workspace/text-generation-webui/modules/GPTQ_loader.py\u201D, line 14, in\r\n\
    import llama_inference_offload\r\nModuleNotFoundError: No module named \u2018\
    llama_inference_offload\u2019\r\n\r\nThis is after setting the parameters/variables\
    \ and then clicking \"reload the model\" \r\n\r\nHow do I fix this?"
  created_at: 2023-05-29 20:02:24+00:00
  edited: false
  hidden: false
  id: 647512e0bb0e9dd77649518a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-29T21:03:58.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>This means GPTQ-for-LLaMa is not installed and therefore you can''t
          run GPTQs until it''s installed.</p>

          <p>Are you using Runpod''s own template? That doesn''t have GPTQ available.  I
          have one that does, which is all ready to go for both GPTQ and GGML with
          CUDA accel:  <a rel="nofollow" href="https://runpod.io/gsc?template=qk29nkmbfr&amp;ref=eexqfacd">https://runpod.io/gsc?template=qk29nkmbfr&amp;ref=eexqfacd</a></p>

          '
        raw: 'This means GPTQ-for-LLaMa is not installed and therefore you can''t
          run GPTQs until it''s installed.


          Are you using Runpod''s own template? That doesn''t have GPTQ available.  I
          have one that does, which is all ready to go for both GPTQ and GGML with
          CUDA accel:  https://runpod.io/gsc?template=qk29nkmbfr&ref=eexqfacd'
        updatedAt: '2023-05-29T21:03:58.193Z'
      numEdits: 0
      reactions: []
    id: 6475133ed56974d0c0641feb
    type: comment
  author: TheBloke
  content: 'This means GPTQ-for-LLaMa is not installed and therefore you can''t run
    GPTQs until it''s installed.


    Are you using Runpod''s own template? That doesn''t have GPTQ available.  I have
    one that does, which is all ready to go for both GPTQ and GGML with CUDA accel:  https://runpod.io/gsc?template=qk29nkmbfr&ref=eexqfacd'
  created_at: 2023-05-29 20:03:58+00:00
  edited: false
  hidden: false
  id: 6475133ed56974d0c0641feb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/88cfe5a91b7abf8c9c2a0c1a7ab199b8.svg
      fullname: Matthew Berman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: matthewberman
      type: user
    createdAt: '2023-05-29T21:12:12.000Z'
    data:
      edited: false
      editors:
      - matthewberman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/88cfe5a91b7abf8c9c2a0c1a7ab199b8.svg
          fullname: Matthew Berman
          isHf: false
          isPro: false
          name: matthewberman
          type: user
        html: '<p>Amazing, going to try that now. </p>

          <p>Will that also work with the falcon model? I was running into the <code>trust_remote_code=True</code>
          error with that on runpod template</p>

          '
        raw: "Amazing, going to try that now. \n\nWill that also work with the falcon\
          \ model? I was running into the `trust_remote_code=True` error with that\
          \ on runpod template"
        updatedAt: '2023-05-29T21:12:12.630Z'
      numEdits: 0
      reactions: []
    id: 6475152cd56974d0c06447f4
    type: comment
  author: matthewberman
  content: "Amazing, going to try that now. \n\nWill that also work with the falcon\
    \ model? I was running into the `trust_remote_code=True` error with that on runpod\
    \ template"
  created_at: 2023-05-29 20:12:12+00:00
  edited: false
  hidden: false
  id: 6475152cd56974d0c06447f4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-29T21:25:09.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yeah it probably would actually. I added AutoGPTQ to the template
          recently. I don''t recall if I''ve specifically tested it but it looks like
          it has all it needs.</p>

          <p>Just bear in mind that Falcon is horribly slow at the moment! Hopefully
          that will improve in time. It''s very much an experimental GPTQ atm.</p>

          '
        raw: 'Yeah it probably would actually. I added AutoGPTQ to the template recently.
          I don''t recall if I''ve specifically tested it but it looks like it has
          all it needs.


          Just bear in mind that Falcon is horribly slow at the moment! Hopefully
          that will improve in time. It''s very much an experimental GPTQ atm.'
        updatedAt: '2023-05-29T21:25:09.365Z'
      numEdits: 0
      reactions: []
    id: 64751835f9e3e0b312f469d5
    type: comment
  author: TheBloke
  content: 'Yeah it probably would actually. I added AutoGPTQ to the template recently.
    I don''t recall if I''ve specifically tested it but it looks like it has all it
    needs.


    Just bear in mind that Falcon is horribly slow at the moment! Hopefully that will
    improve in time. It''s very much an experimental GPTQ atm.'
  created_at: 2023-05-29 20:25:09+00:00
  edited: false
  hidden: false
  id: 64751835f9e3e0b312f469d5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/68ce1f333b98f5e3104bc2b5a1cc104e.svg
      fullname: krass mann
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: krassmann
      type: user
    createdAt: '2023-06-02T13:41:44.000Z'
    data:
      edited: false
      editors:
      - krassmann
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/68ce1f333b98f5e3104bc2b5a1cc104e.svg
          fullname: krass mann
          isHf: false
          isPro: false
          name: krassmann
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> would you mind\
          \ sharing your dockerfile?</p>\n"
        raw: '@TheBloke would you mind sharing your dockerfile?'
        updatedAt: '2023-06-02T13:41:44.354Z'
      numEdits: 0
      reactions: []
    id: 6479f198f518a860fbc972e0
    type: comment
  author: krassmann
  content: '@TheBloke would you mind sharing your dockerfile?'
  created_at: 2023-06-02 12:41:44+00:00
  edited: false
  hidden: false
  id: 6479f198f518a860fbc972e0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: TheBloke/guanaco-65B-GPTQ
repo_type: model
status: open
target_branch: null
title: issues on runpod
