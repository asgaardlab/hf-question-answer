!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Phil337
conflicting_files: null
created_at: 2023-12-11 19:15:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-11T19:15:44.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9763165712356567
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>Neural chat has much more human-like responses than other LLMs,
          but often lacks "brains". Adding DPO and MetaMath made it better at a broad
          spectrum of tasks. It''s become my preferred general purpose LLM.</p>

          <p>Thanks for your efforts.</p>

          '
        raw: "Neural chat has much more human-like responses than other LLMs, but\
          \ often lacks \"brains\". Adding DPO and MetaMath made it better at a broad\
          \ spectrum of tasks. It's become my preferred general purpose LLM.\r\n\r\
          \nThanks for your efforts."
        updatedAt: '2023-12-11T19:15:44.482Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F917"
        users:
        - lvkaokao
        - Rayg3
      - count: 1
        reaction: "\U0001F44D"
        users:
        - lvkaokao
      - count: 1
        reaction: "\U0001F91D"
        users:
        - lvkaokao
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - lvkaokao
    id: 65775fe0ef57a79574f76481
    type: comment
  author: Phil337
  content: "Neural chat has much more human-like responses than other LLMs, but often\
    \ lacks \"brains\". Adding DPO and MetaMath made it better at a broad spectrum\
    \ of tasks. It's become my preferred general purpose LLM.\r\n\r\nThanks for your\
    \ efforts."
  created_at: 2023-12-11 19:15:44+00:00
  edited: false
  hidden: false
  id: 65775fe0ef57a79574f76481
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/486c1b4c3f4d21f2691fca7f9bc15bb7.svg
      fullname: Haihao Shen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Haihao
      type: user
    createdAt: '2023-12-11T23:15:28.000Z'
    data:
      edited: false
      editors:
      - Haihao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9029593467712402
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/486c1b4c3f4d21f2691fca7f9bc15bb7.svg
          fullname: Haihao Shen
          isHf: false
          isPro: false
          name: Haihao
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;Phil337&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Phil337\"\
          >@<span class=\"underline\">Phil337</span></a></span>\n\n\t</span></span>\
          \  for your great support!</p>\n"
        raw: Thanks @Phil337  for your great support!
        updatedAt: '2023-12-11T23:15:28.980Z'
      numEdits: 0
      reactions: []
    id: 65779810411e14898b78af05
    type: comment
  author: Haihao
  content: Thanks @Phil337  for your great support!
  created_at: 2023-12-11 23:15:28+00:00
  edited: false
  hidden: false
  id: 65779810411e14898b78af05
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Intel/neural-chat-7b-v3-3-Slerp
repo_type: model
status: open
target_branch: null
title: Very Nice! DPO made it better.
