!!python/object:huggingface_hub.community.DiscussionWithDetails
author: w-a-cat
conflicting_files: null
created_at: 2023-08-15 22:20:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a79fb0e45c37a42381aa54b99716191b.svg
      fullname: Oleksii Akhrimenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: w-a-cat
      type: user
    createdAt: '2023-08-15T23:20:10.000Z'
    data:
      edited: true
      editors:
      - w-a-cat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9279707670211792
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a79fb0e45c37a42381aa54b99716191b.svg
          fullname: Oleksii Akhrimenko
          isHf: false
          isPro: false
          name: w-a-cat
          type: user
        html: '<p>Oh, you are the first researcher in my path who diligently combines
          models.<br>Thank you, we''ll try. Your models I have not yet tried even
          once. If you are interested in my opinion, I could find only two creative
          models that can write beautifully at the moment. The rest, either with a
          dead boring style or highly specialized ones, in which a step to the left
          and a step to the right means execution. Well, there are still censored
          zombies where no living life is left in the brain.<br>Here is my rating
          of the models:<br>It is on the verge of insanity but very creative even
          after cutting down to 4 bits, it is simply out of competition</p>

          <p>1 place:<br>22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16<br><a
          href="https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16">https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16</a><br>and
          4 bit<br><a href="https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16-GPTQ">https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16-GPTQ</a></p>

          <p>2nd place:<br>Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16<br><a href="https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16">https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16</a><br>Unfortunately,
          in this neural network, the creative part dies if the bit depth drops below
          8.</p>

          <p>Both models get very dumb if you use --xformers.</p>

          <p>If the model 22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2
          were to have all the rubbish like programming skills or knowledge of the
          rules for compiling documents or a bunch of useless reference information
          cut out of the brain, it would be incredible. And so, alas, sometimes this
          brain sparkled notably. But all the same, it understands the tasks set better
          than anyone for some reason. The rest of the models have a bad habit of
          not following what you ask them to do. And they are not as creative and
          beautiful.</p>

          <p>Eh, I can''t wait to delve into the insides of neural models myself properly.
          While my knowledge is clearly not enough for this. I don''t even understand
          how you connect them and how you see what they have left alive inside after
          gluing.</p>

          '
        raw: "Oh, you are the first researcher in my path who diligently combines\
          \ models.\nThank you, we'll try. Your models I have not yet tried even once.\
          \ If you are interested in my opinion, I could find only two creative models\
          \ that can write beautifully at the moment. The rest, either with a dead\
          \ boring style or highly specialized ones, in which a step to the left and\
          \ a step to the right means execution. Well, there are still censored zombies\
          \ where no living life is left in the brain.\nHere is my rating of the models:\n\
          It is on the verge of insanity but very creative even after cutting down\
          \ to 4 bits, it is simply out of competition\n\n1 place: \n22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16\n\
          https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16\n\
          and 4 bit\nhttps://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16-GPTQ\n\
          \n2nd place:\nWizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16\nhttps://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16\n\
          Unfortunately, in this neural network, the creative part dies if the bit\
          \ depth drops below 8.\n\nBoth models get very dumb if you use --xformers.\n\
          \nIf the model 22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2\
          \ were to have all the rubbish like programming skills or knowledge of the\
          \ rules for compiling documents or a bunch of useless reference information\
          \ cut out of the brain, it would be incredible. And so, alas, sometimes\
          \ this brain sparkled notably. But all the same, it understands the tasks\
          \ set better than anyone for some reason. The rest of the models have a\
          \ bad habit of not following what you ask them to do. And they are not as\
          \ creative and beautiful.\n\nEh, I can't wait to delve into the insides\
          \ of neural models myself properly. While my knowledge is clearly not enough\
          \ for this. I don't even understand how you connect them and how you see\
          \ what they have left alive inside after gluing."
        updatedAt: '2023-08-15T23:23:26.472Z'
      numEdits: 1
      reactions: []
    id: 64dc082aa8829bc7840578b0
    type: comment
  author: w-a-cat
  content: "Oh, you are the first researcher in my path who diligently combines models.\n\
    Thank you, we'll try. Your models I have not yet tried even once. If you are interested\
    \ in my opinion, I could find only two creative models that can write beautifully\
    \ at the moment. The rest, either with a dead boring style or highly specialized\
    \ ones, in which a step to the left and a step to the right means execution. Well,\
    \ there are still censored zombies where no living life is left in the brain.\n\
    Here is my rating of the models:\nIt is on the verge of insanity but very creative\
    \ even after cutting down to 4 bits, it is simply out of competition\n\n1 place:\
    \ \n22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16\nhttps://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16\n\
    and 4 bit\nhttps://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16-GPTQ\n\
    \n2nd place:\nWizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16\nhttps://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16\n\
    Unfortunately, in this neural network, the creative part dies if the bit depth\
    \ drops below 8.\n\nBoth models get very dumb if you use --xformers.\n\nIf the\
    \ model 22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2 were to have\
    \ all the rubbish like programming skills or knowledge of the rules for compiling\
    \ documents or a bunch of useless reference information cut out of the brain,\
    \ it would be incredible. And so, alas, sometimes this brain sparkled notably.\
    \ But all the same, it understands the tasks set better than anyone for some reason.\
    \ The rest of the models have a bad habit of not following what you ask them to\
    \ do. And they are not as creative and beautiful.\n\nEh, I can't wait to delve\
    \ into the insides of neural models myself properly. While my knowledge is clearly\
    \ not enough for this. I don't even understand how you connect them and how you\
    \ see what they have left alive inside after gluing."
  created_at: 2023-08-15 22:20:10+00:00
  edited: true
  hidden: false
  id: 64dc082aa8829bc7840578b0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
      fullname: Devon M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Delcos
      type: user
    createdAt: '2023-08-17T01:22:39.000Z'
    data:
      edited: false
      editors:
      - Delcos
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9235858917236328
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
          fullname: Devon M
          isHf: false
          isPro: false
          name: Delcos
          type: user
        html: '<blockquote>

          <p>Oh, you are the first researcher in my path who diligently combines models.<br>Thank
          you, we''ll try. Your models I have not yet tried even once. If you are
          interested in my opinion, I could find only two creative models that can
          write beautifully at the moment. The rest, either with a dead boring style
          or highly specialized ones, in which a step to the left and a step to the
          right means execution. Well, there are still censored zombies where no living
          life is left in the brain.<br>Here is my rating of the models:<br>It is
          on the verge of insanity but very creative even after cutting down to 4
          bits, it is simply out of competition</p>

          <p>1 place:<br>22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16<br><a
          href="https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16">https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16</a><br>and
          4 bit<br><a href="https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16-GPTQ">https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16-GPTQ</a></p>

          <p>2nd place:<br>Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16<br><a href="https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16">https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16</a><br>Unfortunately,
          in this neural network, the creative part dies if the bit depth drops below
          8.</p>

          <p>Both models get very dumb if you use --xformers.</p>

          <p>If the model 22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2
          were to have all the rubbish like programming skills or knowledge of the
          rules for compiling documents or a bunch of useless reference information
          cut out of the brain, it would be incredible. And so, alas, sometimes this
          brain sparkled notably. But all the same, it understands the tasks set better
          than anyone for some reason. The rest of the models have a bad habit of
          not following what you ask them to do. And they are not as creative and
          beautiful.</p>

          <p>Eh, I can''t wait to delve into the insides of neural models myself properly.
          While my knowledge is clearly not enough for this. I don''t even understand
          how you connect them and how you see what they have left alive inside after
          gluing.</p>

          </blockquote>

          <p>Your phrasing is very interesting. </p>

          '
        raw: "> Oh, you are the first researcher in my path who diligently combines\
          \ models.\n> Thank you, we'll try. Your models I have not yet tried even\
          \ once. If you are interested in my opinion, I could find only two creative\
          \ models that can write beautifully at the moment. The rest, either with\
          \ a dead boring style or highly specialized ones, in which a step to the\
          \ left and a step to the right means execution. Well, there are still censored\
          \ zombies where no living life is left in the brain.\n> Here is my rating\
          \ of the models:\n> It is on the verge of insanity but very creative even\
          \ after cutting down to 4 bits, it is simply out of competition\n> \n> 1\
          \ place: \n> 22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16\n\
          > https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16\n\
          > and 4 bit\n> https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16-GPTQ\n\
          > \n> 2nd place:\n> Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16\n> https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16\n\
          > Unfortunately, in this neural network, the creative part dies if the bit\
          \ depth drops below 8.\n> \n> Both models get very dumb if you use --xformers.\n\
          > \n> If the model 22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2\
          \ were to have all the rubbish like programming skills or knowledge of the\
          \ rules for compiling documents or a bunch of useless reference information\
          \ cut out of the brain, it would be incredible. And so, alas, sometimes\
          \ this brain sparkled notably. But all the same, it understands the tasks\
          \ set better than anyone for some reason. The rest of the models have a\
          \ bad habit of not following what you ask them to do. And they are not as\
          \ creative and beautiful.\n> \n> Eh, I can't wait to delve into the insides\
          \ of neural models myself properly. While my knowledge is clearly not enough\
          \ for this. I don't even understand how you connect them and how you see\
          \ what they have left alive inside after gluing.\n\nYour phrasing is very\
          \ interesting. "
        updatedAt: '2023-08-17T01:22:39.761Z'
      numEdits: 0
      reactions: []
    id: 64dd765f4ee8aed2fecf3f76
    type: comment
  author: Delcos
  content: "> Oh, you are the first researcher in my path who diligently combines\
    \ models.\n> Thank you, we'll try. Your models I have not yet tried even once.\
    \ If you are interested in my opinion, I could find only two creative models that\
    \ can write beautifully at the moment. The rest, either with a dead boring style\
    \ or highly specialized ones, in which a step to the left and a step to the right\
    \ means execution. Well, there are still censored zombies where no living life\
    \ is left in the brain.\n> Here is my rating of the models:\n> It is on the verge\
    \ of insanity but very creative even after cutting down to 4 bits, it is simply\
    \ out of competition\n> \n> 1 place: \n> 22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16\n\
    > https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16\n\
    > and 4 bit\n> https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16-GPTQ\n\
    > \n> 2nd place:\n> Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16\n> https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16\n\
    > Unfortunately, in this neural network, the creative part dies if the bit depth\
    \ drops below 8.\n> \n> Both models get very dumb if you use --xformers.\n> \n\
    > If the model 22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2 were\
    \ to have all the rubbish like programming skills or knowledge of the rules for\
    \ compiling documents or a bunch of useless reference information cut out of the\
    \ brain, it would be incredible. And so, alas, sometimes this brain sparkled notably.\
    \ But all the same, it understands the tasks set better than anyone for some reason.\
    \ The rest of the models have a bad habit of not following what you ask them to\
    \ do. And they are not as creative and beautiful.\n> \n> Eh, I can't wait to delve\
    \ into the insides of neural models myself properly. While my knowledge is clearly\
    \ not enough for this. I don't even understand how you connect them and how you\
    \ see what they have left alive inside after gluing.\n\nYour phrasing is very\
    \ interesting. "
  created_at: 2023-08-17 00:22:39+00:00
  edited: false
  hidden: false
  id: 64dd765f4ee8aed2fecf3f76
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a79fb0e45c37a42381aa54b99716191b.svg
      fullname: Oleksii Akhrimenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: w-a-cat
      type: user
    createdAt: '2023-08-17T07:44:59.000Z'
    data:
      edited: false
      editors:
      - w-a-cat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6424839496612549
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a79fb0e45c37a42381aa54b99716191b.svg
          fullname: Oleksii Akhrimenko
          isHf: false
          isPro: false
          name: w-a-cat
          type: user
        html: "<p>I apologize for the quality of the translation in the last post.\
          \ I was too lazy to write in English and used a translator without proofreading.\
          \ But the main thing is that you all understand me.</p>\n<p>My list of models\
          \ that are more or less able to work sufficiently qualitatively is significantly\
          \ larger. For example, yesterday, I discovered LosslessMegaCoder-Llama2-13B-Mini-8bit-128g-GPTQ.\
          \ It pleasantly surprised me, although not by all criteria. I can't try\
          \ all the models, but I've already tried quite a few.<br>I deleted a dozen\
          \ models to be away from that horror, so I don\u2019t even remember the\
          \ names. Here is my small list of models that I have already tried and left\
          \ to take a closer look at them:<br>22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16<br>22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-4bit-32g-GPTQ<br>airoboros-33b-gpt4-1.4.1-NTK-16384-GPTQ<br>airoboros-l2-13B-gpt4-1.4.1-GPTQ_4bit<br>airoboros-l2-13B-gpt4-1.4.1-GPTQ_8bit<br>22b-mergellama2-22b-chat-wizard-uncensored-GPTQ-4bit-32g<br>WizardLM-Uncensored-SuperCOT-StoryTelling-30b-SuperHOT-8k-4bit-32g<br>wizard-vicuna-30b-uncensored-awq-4bit-g128<br>L2-MythoMax22b-instruct-Falseblock-fp16<br>llama2_13b_chat_uncensored-fp16<br>Luna-AI-Llama2-7b-Uncensored-fp16<br>Luna-AI-Llama2-7b-Uncensored-GPTQ_4bit_128g<br>Luna-AI-Llama2-7b-Uncensored-GPTQ_8bit_128g<br>OpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ_4bit<br>OpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ_8bit<br>Starcoderplus-Guanaco-GPT4-15B-V1.0-GPTQ_4bit<br>Starcoderplus-Guanaco-GPT4-15B-V1.0-GPTQ_8bit<br>Starcoderplus-Guanaco-GPT4-15B-V1.0-fp16<br>Wizard-Vicuna-7B-Uncensored-SuperHOT-8K-fp16<br>Wizard-Vicuna-13B-Uncensored-GPTQ-4bit-128g<br>Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16<br>Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GPTQ<br>Wizard-Vicuna-30B-Uncensored-GPTQ-4bit-128g<br>WizardCoder-15B-1.0-GPTQ-4bit-128g<br>WizardCoder-Guanaco-15B-V1.1-GPTQ-8bit-128g<br>WizardCoder-Guanaco-15B-V1.1-GPTQ_4bit_128g<br>WizardLM-1.0-Uncensored-Llama2-13B-GPTQ<br>WizardLM-Uncensored-Falcon-40B-GPTQ<br>WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ-4bit-128g<br>llama2-22B-daydreamer-v2-4bit-128g-GPTQ<br>Llama2-22B-Daydreamer-v3-4bit-128g-GPTQ<br>llama2-22b-daydreamer-v3-fp16<br>llama2-22B-GPLATTY-fp16<br>LosslessMegaCoder-Llama2-13B-Mini-4bit-128g-GPTQ<br>LosslessMegaCoder-Llama2-13B-Mini-8bit-128g-GPTQ<br>airoboros-33B-gpt4-1.4-GPTQ<br>Llama-2-7b-chat-fp16<br>Llama-2-13B-chat-GPTQ_8bit<br>wizard-vicuna-13B-GPTQ-8bit-128g<br>Wizard-Vicuna-30B-Superhot-8K-GPTQ_4b_1g</p>\n"
        raw: "I apologize for the quality of the translation in the last post. I was\
          \ too lazy to write in English and used a translator without proofreading.\
          \ But the main thing is that you all understand me.\n\nMy list of models\
          \ that are more or less able to work sufficiently qualitatively is significantly\
          \ larger. For example, yesterday, I discovered LosslessMegaCoder-Llama2-13B-Mini-8bit-128g-GPTQ.\
          \ It pleasantly surprised me, although not by all criteria. I can't try\
          \ all the models, but I've already tried quite a few.\nI deleted a dozen\
          \ models to be away from that horror, so I don\u2019t even remember the\
          \ names. Here is my small list of models that I have already tried and left\
          \ to take a closer look at them:\n22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16\n\
          22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-4bit-32g-GPTQ\n\
          airoboros-33b-gpt4-1.4.1-NTK-16384-GPTQ\nairoboros-l2-13B-gpt4-1.4.1-GPTQ_4bit\n\
          airoboros-l2-13B-gpt4-1.4.1-GPTQ_8bit\n22b-mergellama2-22b-chat-wizard-uncensored-GPTQ-4bit-32g\n\
          WizardLM-Uncensored-SuperCOT-StoryTelling-30b-SuperHOT-8k-4bit-32g\nwizard-vicuna-30b-uncensored-awq-4bit-g128\n\
          L2-MythoMax22b-instruct-Falseblock-fp16\nllama2_13b_chat_uncensored-fp16\n\
          Luna-AI-Llama2-7b-Uncensored-fp16\nLuna-AI-Llama2-7b-Uncensored-GPTQ_4bit_128g\n\
          Luna-AI-Llama2-7b-Uncensored-GPTQ_8bit_128g\nOpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ_4bit\n\
          OpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ_8bit\nStarcoderplus-Guanaco-GPT4-15B-V1.0-GPTQ_4bit\n\
          Starcoderplus-Guanaco-GPT4-15B-V1.0-GPTQ_8bit\nStarcoderplus-Guanaco-GPT4-15B-V1.0-fp16\n\
          Wizard-Vicuna-7B-Uncensored-SuperHOT-8K-fp16\nWizard-Vicuna-13B-Uncensored-GPTQ-4bit-128g\n\
          Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16\nWizard-Vicuna-13B-Uncensored-SuperHOT-8K-GPTQ\n\
          Wizard-Vicuna-30B-Uncensored-GPTQ-4bit-128g\nWizardCoder-15B-1.0-GPTQ-4bit-128g\n\
          WizardCoder-Guanaco-15B-V1.1-GPTQ-8bit-128g\nWizardCoder-Guanaco-15B-V1.1-GPTQ_4bit_128g\n\
          WizardLM-1.0-Uncensored-Llama2-13B-GPTQ\nWizardLM-Uncensored-Falcon-40B-GPTQ\n\
          WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ-4bit-128g\nllama2-22B-daydreamer-v2-4bit-128g-GPTQ\n\
          Llama2-22B-Daydreamer-v3-4bit-128g-GPTQ\nllama2-22b-daydreamer-v3-fp16\n\
          llama2-22B-GPLATTY-fp16\nLosslessMegaCoder-Llama2-13B-Mini-4bit-128g-GPTQ\n\
          LosslessMegaCoder-Llama2-13B-Mini-8bit-128g-GPTQ\nairoboros-33B-gpt4-1.4-GPTQ\n\
          Llama-2-7b-chat-fp16\nLlama-2-13B-chat-GPTQ_8bit\nwizard-vicuna-13B-GPTQ-8bit-128g\n\
          Wizard-Vicuna-30B-Superhot-8K-GPTQ_4b_1g"
        updatedAt: '2023-08-17T07:44:59.887Z'
      numEdits: 0
      reactions: []
    id: 64ddcffbd906d4b9979bb3c9
    type: comment
  author: w-a-cat
  content: "I apologize for the quality of the translation in the last post. I was\
    \ too lazy to write in English and used a translator without proofreading. But\
    \ the main thing is that you all understand me.\n\nMy list of models that are\
    \ more or less able to work sufficiently qualitatively is significantly larger.\
    \ For example, yesterday, I discovered LosslessMegaCoder-Llama2-13B-Mini-8bit-128g-GPTQ.\
    \ It pleasantly surprised me, although not by all criteria. I can't try all the\
    \ models, but I've already tried quite a few.\nI deleted a dozen models to be\
    \ away from that horror, so I don\u2019t even remember the names. Here is my small\
    \ list of models that I have already tried and left to take a closer look at them:\n\
    22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16\n22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-4bit-32g-GPTQ\n\
    airoboros-33b-gpt4-1.4.1-NTK-16384-GPTQ\nairoboros-l2-13B-gpt4-1.4.1-GPTQ_4bit\n\
    airoboros-l2-13B-gpt4-1.4.1-GPTQ_8bit\n22b-mergellama2-22b-chat-wizard-uncensored-GPTQ-4bit-32g\n\
    WizardLM-Uncensored-SuperCOT-StoryTelling-30b-SuperHOT-8k-4bit-32g\nwizard-vicuna-30b-uncensored-awq-4bit-g128\n\
    L2-MythoMax22b-instruct-Falseblock-fp16\nllama2_13b_chat_uncensored-fp16\nLuna-AI-Llama2-7b-Uncensored-fp16\n\
    Luna-AI-Llama2-7b-Uncensored-GPTQ_4bit_128g\nLuna-AI-Llama2-7b-Uncensored-GPTQ_8bit_128g\n\
    OpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ_4bit\nOpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ_8bit\n\
    Starcoderplus-Guanaco-GPT4-15B-V1.0-GPTQ_4bit\nStarcoderplus-Guanaco-GPT4-15B-V1.0-GPTQ_8bit\n\
    Starcoderplus-Guanaco-GPT4-15B-V1.0-fp16\nWizard-Vicuna-7B-Uncensored-SuperHOT-8K-fp16\n\
    Wizard-Vicuna-13B-Uncensored-GPTQ-4bit-128g\nWizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16\n\
    Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GPTQ\nWizard-Vicuna-30B-Uncensored-GPTQ-4bit-128g\n\
    WizardCoder-15B-1.0-GPTQ-4bit-128g\nWizardCoder-Guanaco-15B-V1.1-GPTQ-8bit-128g\n\
    WizardCoder-Guanaco-15B-V1.1-GPTQ_4bit_128g\nWizardLM-1.0-Uncensored-Llama2-13B-GPTQ\n\
    WizardLM-Uncensored-Falcon-40B-GPTQ\nWizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ-4bit-128g\n\
    llama2-22B-daydreamer-v2-4bit-128g-GPTQ\nLlama2-22B-Daydreamer-v3-4bit-128g-GPTQ\n\
    llama2-22b-daydreamer-v3-fp16\nllama2-22B-GPLATTY-fp16\nLosslessMegaCoder-Llama2-13B-Mini-4bit-128g-GPTQ\n\
    LosslessMegaCoder-Llama2-13B-Mini-8bit-128g-GPTQ\nairoboros-33B-gpt4-1.4-GPTQ\n\
    Llama-2-7b-chat-fp16\nLlama-2-13B-chat-GPTQ_8bit\nwizard-vicuna-13B-GPTQ-8bit-128g\n\
    Wizard-Vicuna-30B-Superhot-8K-GPTQ_4b_1g"
  created_at: 2023-08-17 06:44:59+00:00
  edited: false
  hidden: false
  id: 64ddcffbd906d4b9979bb3c9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a79fb0e45c37a42381aa54b99716191b.svg
      fullname: Oleksii Akhrimenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: w-a-cat
      type: user
    createdAt: '2023-08-17T08:02:20.000Z'
    data:
      edited: false
      editors:
      - w-a-cat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.889046847820282
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a79fb0e45c37a42381aa54b99716191b.svg
          fullname: Oleksii Akhrimenko
          isHf: false
          isPro: false
          name: w-a-cat
          type: user
        html: '<p>Primary criteria for me:</p>

          <ol>

          <li>Following the model to the task in each request iteration.</li>

          <li>Remembering and using the required character names if writing literature
          or variable names if programming.</li>

          <li>Artistic style. The model is required to create something that will
          be easy to read and, simultaneously, be beautiful and pleasant to sound.
          Not too dry text and not too frilly with bows and patterns.</li>

          <li>Creative part of the model. How original the text can be rewritten based
          on the task as a skeleton. Many models quote one-to-one text from the task
          or throw parts of the task into the text without even linking them to the
          main text.</li>

          <li>Residual creative part of the model. What will remain after quantization
          to 4 bits? Really cool models can easily withstand quantization up to 4
          bits without significantly losing their positive qualities.</li>

          </ol>

          <p>To be honest, I still don''t want to bother with the rating of models
          and test them all honestly, in exactly the same way, with the same number
          of iterations. And then make a rating table out of it. So my conclusions
          are pretty subjective. But maybe someone will come in handy.</p>

          <p>Here is my rating of the models:<br>1 place:<br>22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16<br><a
          href="https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16">https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16</a><br>and
          4 bit<br><a href="https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16-GPTQ">https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16-GPTQ</a></p>

          <p>2nd place:<br>Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16<br><a href="https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16">https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16</a><br>Unfortunately,
          in this neural network, the creative part dies when quantization is below
          8 bits.</p>

          <p>3rd place goes to<br>Wizard-Vicuna-30B-Uncensored-4bit-128g-GPTQ</p>

          <p>4th place<br>WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ-4bit-128g</p>

          <p>The rest of the models do not yet receive a place in the rating of utility
          models. Perhaps upon closer examination, it will become clear that they
          can do more than they showed at the first attempts.</p>

          '
        raw: 'Primary criteria for me:

          1. Following the model to the task in each request iteration.

          2. Remembering and using the required character names if writing literature
          or variable names if programming.

          3. Artistic style. The model is required to create something that will be
          easy to read and, simultaneously, be beautiful and pleasant to sound. Not
          too dry text and not too frilly with bows and patterns.

          4. Creative part of the model. How original the text can be rewritten based
          on the task as a skeleton. Many models quote one-to-one text from the task
          or throw parts of the task into the text without even linking them to the
          main text.

          5. Residual creative part of the model. What will remain after quantization
          to 4 bits? Really cool models can easily withstand quantization up to 4
          bits without significantly losing their positive qualities.


          To be honest, I still don''t want to bother with the rating of models and
          test them all honestly, in exactly the same way, with the same number of
          iterations. And then make a rating table out of it. So my conclusions are
          pretty subjective. But maybe someone will come in handy.


          Here is my rating of the models:

          1 place:

          22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16

          https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16

          and 4 bit

          https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16-GPTQ


          2nd place:

          Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16

          https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16

          Unfortunately, in this neural network, the creative part dies when quantization
          is below 8 bits.


          3rd place goes to

          Wizard-Vicuna-30B-Uncensored-4bit-128g-GPTQ


          4th place

          WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ-4bit-128g


          The rest of the models do not yet receive a place in the rating of utility
          models. Perhaps upon closer examination, it will become clear that they
          can do more than they showed at the first attempts.'
        updatedAt: '2023-08-17T08:02:20.646Z'
      numEdits: 0
      reactions: []
    id: 64ddd40ccccdc9a34be0318c
    type: comment
  author: w-a-cat
  content: 'Primary criteria for me:

    1. Following the model to the task in each request iteration.

    2. Remembering and using the required character names if writing literature or
    variable names if programming.

    3. Artistic style. The model is required to create something that will be easy
    to read and, simultaneously, be beautiful and pleasant to sound. Not too dry text
    and not too frilly with bows and patterns.

    4. Creative part of the model. How original the text can be rewritten based on
    the task as a skeleton. Many models quote one-to-one text from the task or throw
    parts of the task into the text without even linking them to the main text.

    5. Residual creative part of the model. What will remain after quantization to
    4 bits? Really cool models can easily withstand quantization up to 4 bits without
    significantly losing their positive qualities.


    To be honest, I still don''t want to bother with the rating of models and test
    them all honestly, in exactly the same way, with the same number of iterations.
    And then make a rating table out of it. So my conclusions are pretty subjective.
    But maybe someone will come in handy.


    Here is my rating of the models:

    1 place:

    22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16

    https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16

    and 4 bit

    https://huggingface.co/grimpep/22b-mergellama2-22b-chat-wizard-uncensored-Dendrite-22Bchk2-F16-GPTQ


    2nd place:

    Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16

    https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-fp16

    Unfortunately, in this neural network, the creative part dies when quantization
    is below 8 bits.


    3rd place goes to

    Wizard-Vicuna-30B-Uncensored-4bit-128g-GPTQ


    4th place

    WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ-4bit-128g


    The rest of the models do not yet receive a place in the rating of utility models.
    Perhaps upon closer examination, it will become clear that they can do more than
    they showed at the first attempts.'
  created_at: 2023-08-17 07:02:20+00:00
  edited: false
  hidden: false
  id: 64ddd40ccccdc9a34be0318c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: nkpz/llama2-22b-daydreamer-v3
repo_type: model
status: open
target_branch: null
title: my rating of the models
