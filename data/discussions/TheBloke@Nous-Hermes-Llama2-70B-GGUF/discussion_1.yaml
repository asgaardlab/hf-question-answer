!!python/object:huggingface_hub.community.DiscussionWithDetails
author: almanshow
conflicting_files: null
created_at: 2023-08-25 22:28:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2ab7b9877223dff5b8dc0a6700381c69.svg
      fullname: Alric B.A
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: almanshow
      type: user
    createdAt: '2023-08-25T23:28:27.000Z'
    data:
      edited: false
      editors:
      - almanshow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5577344298362732
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2ab7b9877223dff5b8dc0a6700381c69.svg
          fullname: Alric B.A
          isHf: false
          isPro: false
          name: almanshow
          type: user
        html: '<p>Downloaded the model in text-generation-webui/models (oogabooga
          web ui).<br>Starting server with python server.py --n-gpu-layers 1000.<br>When
          loading the model, i get following error:<br>OSError: It looks like the
          config file at ''models/nous-hermes-llama2-70b.Q5_K_M.gguf'' is not a valid
          JSON file.</p>

          '
        raw: "Downloaded the model in text-generation-webui/models (oogabooga web\
          \ ui).\r\nStarting server with python server.py --n-gpu-layers 1000.\r\n\
          When loading the model, i get following error: \r\nOSError: It looks like\
          \ the config file at 'models/nous-hermes-llama2-70b.Q5_K_M.gguf' is not\
          \ a valid JSON file."
        updatedAt: '2023-08-25T23:28:27.238Z'
      numEdits: 0
      reactions: []
    id: 64e9391b836919a5f3668bd7
    type: comment
  author: almanshow
  content: "Downloaded the model in text-generation-webui/models (oogabooga web ui).\r\
    \nStarting server with python server.py --n-gpu-layers 1000.\r\nWhen loading the\
    \ model, i get following error: \r\nOSError: It looks like the config file at\
    \ 'models/nous-hermes-llama2-70b.Q5_K_M.gguf' is not a valid JSON file."
  created_at: 2023-08-25 22:28:27+00:00
  edited: false
  hidden: false
  id: 64e9391b836919a5f3668bd7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-08-25T23:51:36.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9760478734970093
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<p>I didnt think ooba supported GGUF yet?</p>

          '
        raw: I didnt think ooba supported GGUF yet?
        updatedAt: '2023-08-25T23:51:36.111Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - almanshow
    id: 64e93e88213a0415bdf6970c
    type: comment
  author: Nurb432
  content: I didnt think ooba supported GGUF yet?
  created_at: 2023-08-25 22:51:36+00:00
  edited: false
  hidden: false
  id: 64e93e88213a0415bdf6970c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-08-26T07:47:48.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9217900633811951
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>It added support yesterday, but via the new ctransformers backend,
          not yet via llama-cpp-python backend.  Switch to using ctransformers in
          text-gen and I believe it should work.</p>

          <p>That said, llama-cpp-python also added support yesterday so I''m sure
          text-gen will update that soon as well.</p>

          '
        raw: 'It added support yesterday, but via the new ctransformers backend, not
          yet via llama-cpp-python backend.  Switch to using ctransformers in text-gen
          and I believe it should work.


          That said, llama-cpp-python also added support yesterday so I''m sure text-gen
          will update that soon as well.'
        updatedAt: '2023-08-26T07:48:11.846Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - almanshow
        - kirkog86
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - almanshow
        - kirkog86
    id: 64e9ae247e727763c90b9ee8
    type: comment
  author: TheBloke
  content: 'It added support yesterday, but via the new ctransformers backend, not
    yet via llama-cpp-python backend.  Switch to using ctransformers in text-gen and
    I believe it should work.


    That said, llama-cpp-python also added support yesterday so I''m sure text-gen
    will update that soon as well.'
  created_at: 2023-08-26 06:47:48+00:00
  edited: true
  hidden: false
  id: 64e9ae247e727763c90b9ee8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64eb2d60b96ff0e175500f36/tTLrkkAVvS72GvtM4ZSPK.jpeg?w=200&h=200&f=face
      fullname: Kirill Kogan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kirkog86
      type: user
    createdAt: '2023-08-31T12:28:47.000Z'
    data:
      edited: false
      editors:
      - kirkog86
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6017413139343262
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64eb2d60b96ff0e175500f36/tTLrkkAVvS72GvtM4ZSPK.jpeg?w=200&h=200&f=face
          fullname: Kirill Kogan
          isHf: false
          isPro: false
          name: kirkog86
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> , will the models\
          \ work with llama.cpp.python[server] ?</p>\n"
        raw: '@TheBloke , will the models work with llama.cpp.python[server] ?'
        updatedAt: '2023-08-31T12:28:47.091Z'
      numEdits: 0
      reactions: []
    id: 64f0877fbaf704ad6a4dc798
    type: comment
  author: kirkog86
  content: '@TheBloke , will the models work with llama.cpp.python[server] ?'
  created_at: 2023-08-31 11:28:47+00:00
  edited: false
  hidden: false
  id: 64f0877fbaf704ad6a4dc798
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Nous-Hermes-Llama2-70B-GGUF
repo_type: model
status: open
target_branch: null
title: "OSError: It looks like the config file at \u2018models/nous-hermes-llama2-70b.Q5_K_M.gguf\u2019\
  \ is not a valid JSON file"
