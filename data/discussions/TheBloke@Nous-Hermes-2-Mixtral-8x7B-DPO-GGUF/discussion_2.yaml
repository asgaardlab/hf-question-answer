!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TheYuriLover
conflicting_files: null
created_at: 2024-01-18 05:00:39+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2024-01-18T05:00:39.000Z'
    data:
      edited: true
      editors:
      - TheYuriLover
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8939990401268005
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: '<p>Source : <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp/discussions/5006">https://github.com/ggerganov/llama.cpp/discussions/5006</a><br>The
          problem we have when using a calibration dataset is the overfitting to a
          certain style and then in consequence, make the model worse on other aspects.<br><a
          rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/639d9061f87da5e2eb0b2724/FnMHvo0nKXyWVPc-iDaR1.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/639d9061f87da5e2eb0b2724/FnMHvo0nKXyWVPc-iDaR1.png"></a><br>Supposedly,
          the suggestion to fix this is to use a calibration dataset composed of random
          tokens instead.</p>

          '
        raw: 'Source : https://github.com/ggerganov/llama.cpp/discussions/5006

          The problem we have when using a calibration dataset is the overfitting
          to a certain style and then in consequence, make the model worse on other
          aspects.

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/639d9061f87da5e2eb0b2724/FnMHvo0nKXyWVPc-iDaR1.png)

          Supposedly, the suggestion to fix this is to use a calibration dataset composed
          of random tokens instead.'
        updatedAt: '2024-01-18T05:57:47.981Z'
      numEdits: 7
      reactions: []
    id: 65a8b0775e49cc9fdc72b0db
    type: comment
  author: TheYuriLover
  content: 'Source : https://github.com/ggerganov/llama.cpp/discussions/5006

    The problem we have when using a calibration dataset is the overfitting to a certain
    style and then in consequence, make the model worse on other aspects.

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/639d9061f87da5e2eb0b2724/FnMHvo0nKXyWVPc-iDaR1.png)

    Supposedly, the suggestion to fix this is to use a calibration dataset composed
    of random tokens instead.'
  created_at: 2024-01-18 05:00:39+00:00
  edited: true
  hidden: false
  id: 65a8b0775e49cc9fdc72b0db
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2024-01-18T05:02:48.000Z'
    data:
      from: Using the new gguf quant method may result in a woese overall performance
        than that of the old gguf quants.
      to: Using the new gguf quant method may result in a worse overall performance
        than that of the old gguf quants.
    id: 65a8b0f8eea6e76376897f0e
    type: title-change
  author: TheYuriLover
  created_at: 2024-01-18 05:02:48+00:00
  id: 65a8b0f8eea6e76376897f0e
  new_title: Using the new gguf quant method may result in a worse overall performance
    than that of the old gguf quants.
  old_title: Using the new gguf quant method may result in a woese overall performance
    than that of the old gguf quants.
  type: title-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/Nous-Hermes-2-Mixtral-8x7B-DPO-GGUF
repo_type: model
status: open
target_branch: null
title: Using the new gguf quant method may result in a worse overall performance than
  that of the old gguf quants.
