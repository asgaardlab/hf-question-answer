!!python/object:huggingface_hub.community.DiscussionWithDetails
author: DreamyP
conflicting_files: null
created_at: 2023-06-20 14:37:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8f4c48673f54baceacd7580e491194bb.svg
      fullname: Dreamy Pujara
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DreamyP
      type: user
    createdAt: '2023-06-20T15:37:24.000Z'
    data:
      edited: false
      editors:
      - DreamyP
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8690294027328491
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8f4c48673f54baceacd7580e491194bb.svg
          fullname: Dreamy Pujara
          isHf: false
          isPro: false
          name: DreamyP
          type: user
        html: '<p>Can we use this for multilingual ASR? like in a single audio if
          there r say 2 languages and we can differentiate it n it translates into
          both languages simultaniously?</p>

          '
        raw: Can we use this for multilingual ASR? like in a single audio if there
          r say 2 languages and we can differentiate it n it translates into both
          languages simultaniously?
        updatedAt: '2023-06-20T15:37:24.309Z'
      numEdits: 0
      reactions: []
    id: 6491c7b4e9ad369a226d0673
    type: comment
  author: DreamyP
  content: Can we use this for multilingual ASR? like in a single audio if there r
    say 2 languages and we can differentiate it n it translates into both languages
    simultaniously?
  created_at: 2023-06-20 14:37:24+00:00
  edited: false
  hidden: false
  id: 6491c7b4e9ad369a226d0673
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-06-22T17:16:49.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8945476412773132
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: '<p>The LID model will predict a single language (or single distribution
          over languages) per audio input - for multi-language prediction, we could
          batch our audio into smaller chunks and classify the language for each chunk.
          We''ll then know what language is spoken in each chunk, so we can segment
          the audio where it changes languages, and pass each segment to the correct
          ASR model trained on that specific language </p>

          '
        raw: 'The LID model will predict a single language (or single distribution
          over languages) per audio input - for multi-language prediction, we could
          batch our audio into smaller chunks and classify the language for each chunk.
          We''ll then know what language is spoken in each chunk, so we can segment
          the audio where it changes languages, and pass each segment to the correct
          ASR model trained on that specific language '
        updatedAt: '2023-06-22T17:16:49.729Z'
      numEdits: 0
      reactions: []
    id: 649482018d5ff0dd776543e5
    type: comment
  author: sanchit-gandhi
  content: 'The LID model will predict a single language (or single distribution over
    languages) per audio input - for multi-language prediction, we could batch our
    audio into smaller chunks and classify the language for each chunk. We''ll then
    know what language is spoken in each chunk, so we can segment the audio where
    it changes languages, and pass each segment to the correct ASR model trained on
    that specific language '
  created_at: 2023-06-22 16:16:49+00:00
  edited: false
  hidden: false
  id: 649482018d5ff0dd776543e5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: facebook/mms-lid-126
repo_type: model
status: open
target_branch: null
title: real time ASR for multilingual languages same time?
