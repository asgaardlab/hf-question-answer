!!python/object:huggingface_hub.community.DiscussionWithDetails
author: GuenKainto
conflicting_files: null
created_at: 2023-12-28 09:20:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/f9Up4tnICZJBDxkxTQGKD.jpeg?w=200&h=200&f=face
      fullname: GuenKainto
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: GuenKainto
      type: user
    createdAt: '2023-12-28T09:20:37.000Z'
    data:
      edited: false
      editors:
      - GuenKainto
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9131017923355103
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/f9Up4tnICZJBDxkxTQGKD.jpeg?w=200&h=200&f=face
          fullname: GuenKainto
          isHf: false
          isPro: false
          name: GuenKainto
          type: user
        html: '<p>Hello, can I ask how to create a tokenizer file for Japanese? I
          see that Japanese people use some Kanji in sentences or words. I found a
          simple tokenizer file containing hiragana and katakana words, I think I
          can use it but it lacks in compound words and Kanji words.<br>File link:
          <a rel="nofollow" href="https://git.ecker.tech/mrq/ai-voice-cloning/src/branch/master/models/tokenizers/japanese.json">https://git.ecker.tech/mrq/ai-voice-cloning/src/branch/master/models/tokenizers/japanese.json</a><br>Thankyou</p>

          '
        raw: "Hello, can I ask how to create a tokenizer file for Japanese? I see\
          \ that Japanese people use some Kanji in sentences or words. I found a simple\
          \ tokenizer file containing hiragana and katakana words, I think I can use\
          \ it but it lacks in compound words and Kanji words.\r\nFile link: https://git.ecker.tech/mrq/ai-voice-cloning/src/branch/master/models/tokenizers/japanese.json\r\
          \nThankyou"
        updatedAt: '2023-12-28T09:20:37.478Z'
      numEdits: 0
      reactions: []
    id: 658d3de57ecef7270a387df4
    type: comment
  author: GuenKainto
  content: "Hello, can I ask how to create a tokenizer file for Japanese? I see that\
    \ Japanese people use some Kanji in sentences or words. I found a simple tokenizer\
    \ file containing hiragana and katakana words, I think I can use it but it lacks\
    \ in compound words and Kanji words.\r\nFile link: https://git.ecker.tech/mrq/ai-voice-cloning/src/branch/master/models/tokenizers/japanese.json\r\
    \nThankyou"
  created_at: 2023-12-28 09:20:37+00:00
  edited: false
  hidden: false
  id: 658d3de57ecef7270a387df4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: ecker/tortoise-tts-models
repo_type: model
status: open
target_branch: null
title: Tokenizer Japanese
