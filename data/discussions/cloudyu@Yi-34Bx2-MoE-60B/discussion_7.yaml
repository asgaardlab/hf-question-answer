!!python/object:huggingface_hub.community.DiscussionWithDetails
author: oFDz
conflicting_files: null
created_at: 2024-01-15 00:23:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/EP1UsMD4_tc9cct2EIUYh.png?w=200&h=200&f=face
      fullname: MAZ
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: oFDz
      type: user
    createdAt: '2024-01-15T00:23:07.000Z'
    data:
      edited: false
      editors:
      - oFDz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9465630650520325
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/EP1UsMD4_tc9cct2EIUYh.png?w=200&h=200&f=face
          fullname: MAZ
          isHf: false
          isPro: false
          name: oFDz
          type: user
        html: '<p>How hard/time consuming would it be to fine-tune this one to be
          able to handle a language like Arabic?</p>

          '
        raw: How hard/time consuming would it be to fine-tune this one to be able
          to handle a language like Arabic?
        updatedAt: '2024-01-15T00:23:07.340Z'
      numEdits: 0
      reactions: []
    id: 65a47aeb224f96d8cc2b10db
    type: comment
  author: oFDz
  content: How hard/time consuming would it be to fine-tune this one to be able to
    handle a language like Arabic?
  created_at: 2024-01-15 00:23:07+00:00
  edited: false
  hidden: false
  id: 65a47aeb224f96d8cc2b10db
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64618bc5cf638aa8f856137c/zbUqrIeHjz41P3O2b3eey.jpeg?w=200&h=200&f=face
      fullname: hai
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: cloudyu
      type: user
    createdAt: '2024-01-15T01:10:22.000Z'
    data:
      edited: true
      editors:
      - cloudyu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.864215612411499
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64618bc5cf638aa8f856137c/zbUqrIeHjz41P3O2b3eey.jpeg?w=200&h=200&f=face
          fullname: hai
          isHf: false
          isPro: false
          name: cloudyu
          type: user
        html: "<blockquote>\n<p>How hard/time consuming would it be to fine-tune this\
          \ one to be able to handle a language like Arabic?</p>\n</blockquote>\n\
          <p>please take a look at tinyllama <a href=\"https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\
          >https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0</a></p>\n<pre><code>The\
          \ TinyLlama project aims to pretrain a 1.1B Llama model on 3 trillion tokens.\
          \ With some proper optimization, we can achieve this within a span of \"\
          just\" 90 days using 16 A100-40G GPUs \U0001F680\U0001F680. The training\
          \ has started on 2023-09-01.\n</code></pre>\n<p>of course, if you have enough\
          \ power, it would be fast.</p>\n"
        raw: "> How hard/time consuming would it be to fine-tune this one to be able\
          \ to handle a language like Arabic?\n\nplease take a look at tinyllama https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0\n\
          ```\nThe TinyLlama project aims to pretrain a 1.1B Llama model on 3 trillion\
          \ tokens. With some proper optimization, we can achieve this within a span\
          \ of \"just\" 90 days using 16 A100-40G GPUs \U0001F680\U0001F680. The training\
          \ has started on 2023-09-01.\n\n```\nof course, if you have enough power,\
          \ it would be fast."
        updatedAt: '2024-01-15T01:10:32.910Z'
      numEdits: 1
      reactions: []
    id: 65a485fe534e60db99b73a7f
    type: comment
  author: cloudyu
  content: "> How hard/time consuming would it be to fine-tune this one to be able\
    \ to handle a language like Arabic?\n\nplease take a look at tinyllama https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0\n\
    ```\nThe TinyLlama project aims to pretrain a 1.1B Llama model on 3 trillion tokens.\
    \ With some proper optimization, we can achieve this within a span of \"just\"\
    \ 90 days using 16 A100-40G GPUs \U0001F680\U0001F680. The training has started\
    \ on 2023-09-01.\n\n```\nof course, if you have enough power, it would be fast."
  created_at: 2024-01-15 01:10:22+00:00
  edited: true
  hidden: false
  id: 65a485fe534e60db99b73a7f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: cloudyu/Yi-34Bx2-MoE-60B
repo_type: model
status: open
target_branch: null
title: Multi-langua?
