!!python/object:huggingface_hub.community.DiscussionWithDetails
author: obtion
conflicting_files: null
created_at: 2024-01-11 06:04:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/134567518f218cfabf49621d6d70528f.svg
      fullname: y
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: obtion
      type: user
    createdAt: '2024-01-11T06:04:41.000Z'
    data:
      edited: false
      editors:
      - obtion
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7052695155143738
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/134567518f218cfabf49621d6d70528f.svg
          fullname: y
          isHf: false
          isPro: false
          name: obtion
          type: user
        html: '<p>Can VLLM be used for inference acceleration?</p>

          '
        raw: "Can VLLM be used for inference acceleration?\r\n\r\n"
        updatedAt: '2024-01-11T06:04:41.032Z'
      numEdits: 0
      reactions: []
    id: 659f84f92cb13cede01f2cdc
    type: comment
  author: obtion
  content: "Can VLLM be used for inference acceleration?\r\n\r\n"
  created_at: 2024-01-11 06:04:41+00:00
  edited: false
  hidden: false
  id: 659f84f92cb13cede01f2cdc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64618bc5cf638aa8f856137c/zbUqrIeHjz41P3O2b3eey.jpeg?w=200&h=200&f=face
      fullname: hai
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: cloudyu
      type: user
    createdAt: '2024-01-11T06:16:21.000Z'
    data:
      edited: false
      editors:
      - cloudyu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7122088670730591
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64618bc5cf638aa8f856137c/zbUqrIeHjz41P3O2b3eey.jpeg?w=200&h=200&f=face
          fullname: hai
          isHf: false
          isPro: false
          name: cloudyu
          type: user
        html: '<p>"architectures": [<br>    "MixtralForCausalLM"<br>  ],<br>you need
          to check whether vllm support   "MixtralForCausalLM"</p>

          '
        raw: "\"architectures\": [\n    \"MixtralForCausalLM\"\n  ],\nyou need to\
          \ check whether vllm support   \"MixtralForCausalLM\"\n"
        updatedAt: '2024-01-11T06:16:21.475Z'
      numEdits: 0
      reactions: []
    id: 659f87b5b62804e6f43f1914
    type: comment
  author: cloudyu
  content: "\"architectures\": [\n    \"MixtralForCausalLM\"\n  ],\nyou need to check\
    \ whether vllm support   \"MixtralForCausalLM\"\n"
  created_at: 2024-01-11 06:16:21+00:00
  edited: false
  hidden: false
  id: 659f87b5b62804e6f43f1914
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2024-01-11T21:34:19.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9058389663696289
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>yeah VLLM supports that</p>

          '
        raw: yeah VLLM supports that
        updatedAt: '2024-01-11T21:34:19.436Z'
      numEdits: 0
      reactions: []
    id: 65a05edbe969415381de352b
    type: comment
  author: ehartford
  content: yeah VLLM supports that
  created_at: 2024-01-11 21:34:19+00:00
  edited: false
  hidden: false
  id: 65a05edbe969415381de352b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: cloudyu/Yi-34Bx2-MoE-60B
repo_type: model
status: open
target_branch: null
title: Can VLLM be used for inference acceleration?
