!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ghpkishore
conflicting_files: null
created_at: 2022-06-30 09:37:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f41b208bbbdafebe521845140f006c68.svg
      fullname: kishore G
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ghpkishore
      type: user
    createdAt: '2022-06-30T10:37:21.000Z'
    data:
      edited: false
      editors:
      - ghpkishore
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f41b208bbbdafebe521845140f006c68.svg
          fullname: kishore G
          isHf: false
          isPro: false
          name: ghpkishore
          type: user
        html: '<p>I clicked on the Amazon Sagemaker deploy and followed the steps
          given. However, it throws an error. Should I change the "instance type"
          parameter? </p>

          <p>The inference widget doesn''t run, Sagemaker also doesn''t work. So I
          do not know how to use this model. Help is massively appreciated. </p>

          '
        raw: "I clicked on the Amazon Sagemaker deploy and followed the steps given.\
          \ However, it throws an error. Should I change the \"instance type\" parameter?\
          \ \r\n\r\nThe inference widget doesn't run, Sagemaker also doesn't work.\
          \ So I do not know how to use this model. Help is massively appreciated. "
        updatedAt: '2022-06-30T10:37:21.278Z'
      numEdits: 0
      reactions: []
    id: 62bd7ce17c0388414ff4fae1
    type: comment
  author: ghpkishore
  content: "I clicked on the Amazon Sagemaker deploy and followed the steps given.\
    \ However, it throws an error. Should I change the \"instance type\" parameter?\
    \ \r\n\r\nThe inference widget doesn't run, Sagemaker also doesn't work. So I\
    \ do not know how to use this model. Help is massively appreciated. "
  created_at: 2022-06-30 09:37:21+00:00
  edited: false
  hidden: false
  id: 62bd7ce17c0388414ff4fae1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f41b208bbbdafebe521845140f006c68.svg
      fullname: kishore G
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ghpkishore
      type: user
    createdAt: '2022-06-30T13:00:50.000Z'
    data:
      edited: false
      editors:
      - ghpkishore
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f41b208bbbdafebe521845140f006c68.svg
          fullname: kishore G
          isHf: false
          isPro: false
          name: ghpkishore
          type: user
        html: '<p>I realised that there is no way to actually run these models on
          system without having access to A100 GPU''s. In Amazon to request that instance,
          it costs approx. USD 32. Therefore, unless there are folks from big companies
          or academia, this model cannot be used.</p>

          '
        raw: I realised that there is no way to actually run these models on system
          without having access to A100 GPU's. In Amazon to request that instance,
          it costs approx. USD 32. Therefore, unless there are folks from big companies
          or academia, this model cannot be used.
        updatedAt: '2022-06-30T13:00:50.045Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F92F"
        users:
        - julien-c
    id: 62bd9e8226277b1ce54b87c7
    type: comment
  author: ghpkishore
  content: I realised that there is no way to actually run these models on system
    without having access to A100 GPU's. In Amazon to request that instance, it costs
    approx. USD 32. Therefore, unless there are folks from big companies or academia,
    this model cannot be used.
  created_at: 2022-06-30 12:00:50+00:00
  edited: false
  hidden: false
  id: 62bd9e8226277b1ce54b87c7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/NQtzmrDdbG0H8qkZvRyGk.jpeg?w=200&h=200&f=face
      fullname: Julien Chaumond
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: true
      name: julien-c
      type: user
    createdAt: '2022-07-01T06:59:38.000Z'
    data:
      edited: false
      editors:
      - julien-c
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/NQtzmrDdbG0H8qkZvRyGk.jpeg?w=200&h=200&f=face
          fullname: Julien Chaumond
          isHf: true
          isPro: true
          name: julien-c
          type: user
        html: "<p>pinging <span data-props=\"{&quot;user&quot;:&quot;philschmid&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/philschmid\"\
          >@<span class=\"underline\">philschmid</span></a></span>\n\n\t</span></span>\
          \ just for visibility</p>\n"
        raw: pinging @philschmid just for visibility
        updatedAt: '2022-07-01T06:59:38.487Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - ghpkishore
    id: 62be9b5afc633658d3b536d6
    type: comment
  author: julien-c
  content: pinging @philschmid just for visibility
  created_at: 2022-07-01 05:59:38+00:00
  edited: false
  hidden: false
  id: 62be9b5afc633658d3b536d6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png?w=200&h=200&f=face
      fullname: Philipp Schmid
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: philschmid
      type: user
    createdAt: '2022-07-01T19:46:16.000Z'
    data:
      edited: false
      editors:
      - philschmid
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png?w=200&h=200&f=face
          fullname: Philipp Schmid
          isHf: true
          isPro: false
          name: philschmid
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;ghpkishore&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ghpkishore\"\
          >@<span class=\"underline\">ghpkishore</span></a></span>\n\n\t</span></span>,\
          \ </p>\n<p>It should be possible to run the model with <a href=\"https://huggingface.co/docs/transformers/v4.20.1/en/main_classes/model#large-model-loading\"\
          >Large Model Loading</a> on Amazon SageMaker. But there is not yet a container\
          \ with the supported <code>transformers</code> version available meaning\
          \ you would need to create a custom <code>inference.py</code> + <code>requirements.txt</code>\
          \ to deploy to sagemaker. <a rel=\"nofollow\" href=\"https://github.com/huggingface/notebooks/blob/main/sagemaker/17_custom_inference_script/sagemaker-notebook.ipynb\"\
          >example</a></p>\n<p>For instance type i am not sure which one is enough\
          \ I would either try <code>g5.12xlarge\t</code> or <code>p3.8xlarge</code>.</p>\n"
        raw: "Hello @ghpkishore, \n\nIt should be possible to run the model with [Large\
          \ Model Loading](https://huggingface.co/docs/transformers/v4.20.1/en/main_classes/model#large-model-loading)\
          \ on Amazon SageMaker. But there is not yet a container with the supported\
          \ `transformers` version available meaning you would need to create a custom\
          \ `inference.py` + `requirements.txt` to deploy to sagemaker. [example](https://github.com/huggingface/notebooks/blob/main/sagemaker/17_custom_inference_script/sagemaker-notebook.ipynb)\n\
          \nFor instance type i am not sure which one is enough I would either try\
          \ `g5.12xlarge\t` or `p3.8xlarge`."
        updatedAt: '2022-07-01T19:46:16.268Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - ghpkishore
    id: 62bf4f08fbc7a6370babbfca
    type: comment
  author: philschmid
  content: "Hello @ghpkishore, \n\nIt should be possible to run the model with [Large\
    \ Model Loading](https://huggingface.co/docs/transformers/v4.20.1/en/main_classes/model#large-model-loading)\
    \ on Amazon SageMaker. But there is not yet a container with the supported `transformers`\
    \ version available meaning you would need to create a custom `inference.py` +\
    \ `requirements.txt` to deploy to sagemaker. [example](https://github.com/huggingface/notebooks/blob/main/sagemaker/17_custom_inference_script/sagemaker-notebook.ipynb)\n\
    \nFor instance type i am not sure which one is enough I would either try `g5.12xlarge\t\
    ` or `p3.8xlarge`."
  created_at: 2022-07-01 18:46:16+00:00
  edited: false
  hidden: false
  id: 62bf4f08fbc7a6370babbfca
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: google/ul2
repo_type: model
status: open
target_branch: null
title: Amazon sagemaker deploy
