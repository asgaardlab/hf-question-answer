!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ahmedghani
conflicting_files: null
created_at: 2022-06-06 06:37:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/624c2742a8ec93a7ac167604/ihN-qPEs6OKnIGdFeW78f.jpeg?w=200&h=200&f=face
      fullname: Muhammad Ahmed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ahmedghani
      type: user
    createdAt: '2022-06-06T07:37:30.000Z'
    data:
      edited: false
      editors:
      - ahmedghani
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/624c2742a8ec93a7ac167604/ihN-qPEs6OKnIGdFeW78f.jpeg?w=200&h=200&f=face
          fullname: Muhammad Ahmed
          isHf: false
          isPro: false
          name: ahmedghani
          type: user
        html: '<p>from transformers import AutoTokenizer, AutoModel</p>

          <p>tokenizer = AutoTokenizer.from_pretrained("hkunlp/from_all_T5_large_prefix_spider_with_cell_value2")</p>

          <p>model = AutoModel.from_pretrained("hkunlp/from_all_T5_large_prefix_spider_with_cell_value2")</p>

          <p>-------------------------------------------- ERROR --------------------------------------------</p>

          <p>File "/home/user/anaconda3/envs/test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py",
          line 1850, in _from_pretrained<br>    tokenizer = cls(*init_inputs, **init_kwargs)<br>  File
          "/home/user/anaconda3/envs/test/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py",
          line 128, in <strong>init</strong><br>    super().<strong>init</strong>(<br>  File
          "/home/user/anaconda3/envs/test/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py",
          line 107, in <strong>init</strong><br>    fast_tokenizer = TokenizerFast.from_file(fast_tokenizer_file)<br>Exception:
          Permission denied (os error 13)</p>

          '
        raw: "from transformers import AutoTokenizer, AutoModel\r\n\r\ntokenizer =\
          \ AutoTokenizer.from_pretrained(\"hkunlp/from_all_T5_large_prefix_spider_with_cell_value2\"\
          )\r\n\r\nmodel = AutoModel.from_pretrained(\"hkunlp/from_all_T5_large_prefix_spider_with_cell_value2\"\
          )\r\n\r\n-------------------------------------------- ERROR --------------------------------------------\r\
          \n\r\nFile \"/home/user/anaconda3/envs/test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1850, in _from_pretrained\r\n    tokenizer = cls(*init_inputs, **init_kwargs)\r\
          \n  File \"/home/user/anaconda3/envs/test/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py\"\
          , line 128, in __init__\r\n    super().__init__(\r\n  File \"/home/user/anaconda3/envs/test/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\"\
          , line 107, in __init__\r\n    fast_tokenizer = TokenizerFast.from_file(fast_tokenizer_file)\r\
          \nException: Permission denied (os error 13)"
        updatedAt: '2022-06-06T07:37:30.496Z'
      numEdits: 0
      reactions: []
    id: 629daeba09211d5cafadfd37
    type: comment
  author: ahmedghani
  content: "from transformers import AutoTokenizer, AutoModel\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
    hkunlp/from_all_T5_large_prefix_spider_with_cell_value2\")\r\n\r\nmodel = AutoModel.from_pretrained(\"\
    hkunlp/from_all_T5_large_prefix_spider_with_cell_value2\")\r\n\r\n--------------------------------------------\
    \ ERROR --------------------------------------------\r\n\r\nFile \"/home/user/anaconda3/envs/test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\"\
    , line 1850, in _from_pretrained\r\n    tokenizer = cls(*init_inputs, **init_kwargs)\r\
    \n  File \"/home/user/anaconda3/envs/test/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py\"\
    , line 128, in __init__\r\n    super().__init__(\r\n  File \"/home/user/anaconda3/envs/test/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\"\
    , line 107, in __init__\r\n    fast_tokenizer = TokenizerFast.from_file(fast_tokenizer_file)\r\
    \nException: Permission denied (os error 13)"
  created_at: 2022-06-06 06:37:30+00:00
  edited: false
  hidden: false
  id: 629daeba09211d5cafadfd37
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1636263880877-noauth.jpeg?w=200&h=200&f=face
      fullname: Tianbao Xie
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: tianbaoxiexxx
      type: user
    createdAt: '2022-06-06T08:16:08.000Z'
    data:
      edited: false
      editors:
      - tianbaoxiexxx
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1636263880877-noauth.jpeg?w=200&h=200&f=face
          fullname: Tianbao Xie
          isHf: false
          isPro: false
          name: tianbaoxiexxx
          type: user
        html: '<p>Hi, </p>

          <p>This weight relies on the code of prefix-tuning which don''t exists in
          huggingface AutoTokenizer and AutoModel. To load this weight, see <a rel="nofollow"
          href="https://github.com/HKUNLP/UnifiedSKG">UnifiedSKG official code</a>
          and <a rel="nofollow" href="https://colab.research.google.com/drive/1f9yTXC3GpSyRJOjzsKceG_bhk-Cw71Ga#scrollTo=r_3-DN0SvC97">colab
          demo</a>.</p>

          <p>Hope these information helpful!</p>

          <p>Thanks!</p>

          '
        raw: "Hi, \n\nThis weight relies on the code of prefix-tuning which don't\
          \ exists in huggingface AutoTokenizer and AutoModel. To load this weight,\
          \ see [UnifiedSKG official code](https://github.com/HKUNLP/UnifiedSKG) and\
          \ [colab demo](https://colab.research.google.com/drive/1f9yTXC3GpSyRJOjzsKceG_bhk-Cw71Ga#scrollTo=r_3-DN0SvC97).\n\
          \nHope these information helpful!\n\nThanks!"
        updatedAt: '2022-06-06T08:16:08.519Z'
      numEdits: 0
      reactions: []
    id: 629db7c80ecdc0e2a7bc73e2
    type: comment
  author: tianbaoxiexxx
  content: "Hi, \n\nThis weight relies on the code of prefix-tuning which don't exists\
    \ in huggingface AutoTokenizer and AutoModel. To load this weight, see [UnifiedSKG\
    \ official code](https://github.com/HKUNLP/UnifiedSKG) and [colab demo](https://colab.research.google.com/drive/1f9yTXC3GpSyRJOjzsKceG_bhk-Cw71Ga#scrollTo=r_3-DN0SvC97).\n\
    \nHope these information helpful!\n\nThanks!"
  created_at: 2022-06-06 07:16:08+00:00
  edited: false
  hidden: false
  id: 629db7c80ecdc0e2a7bc73e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/624c2742a8ec93a7ac167604/ihN-qPEs6OKnIGdFeW78f.jpeg?w=200&h=200&f=face
      fullname: Muhammad Ahmed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ahmedghani
      type: user
    createdAt: '2022-06-06T11:05:23.000Z'
    data:
      status: closed
    id: 629ddf734f4ea45707b051d3
    type: status-change
  author: ahmedghani
  created_at: 2022-06-06 10:05:23+00:00
  id: 629ddf734f4ea45707b051d3
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: hkunlp/from_all_T5_large_prefix_spider_with_cell_value2
repo_type: model
status: closed
target_branch: null
title: Permission Denied
