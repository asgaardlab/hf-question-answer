!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Saiyan
conflicting_files: null
created_at: 2023-08-15 16:56:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d38adaaa8bc2ff32c0b8000848b79737.svg
      fullname: Roy Sadaka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Saiyan
      type: user
    createdAt: '2023-08-15T17:56:06.000Z'
    data:
      edited: false
      editors:
      - Saiyan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9422740340232849
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d38adaaa8bc2ff32c0b8000848b79737.svg
          fullname: Roy Sadaka
          isHf: false
          isPro: false
          name: Saiyan
          type: user
        html: "<p>Hey Tom and Community,</p>\n<p>Thank you so much for the hard work\
          \ and effort you all put into these GGMLs! \U0001F44F\U0001F44F\U0001F44F\
          </p>\n<p>I\u2019m currently on the lookout for an affordable GPU setup,<br>Specifically,\
          \ I look for something that can comfortably handle the 8-bit version of\
          \ 70B.<br>Do you have any recommendations?</p>\n<p>Also, is there a website\
          \ or forum where the community shares their GPU recommendations for different\
          \ versions of LLM quantizations?</p>\n<p>Thanks in advance for any advice\
          \ or suggestions!</p>\n"
        raw: "Hey Tom and Community,\r\n\r\nThank you so much for the hard work and\
          \ effort you all put into these GGMLs! \U0001F44F\U0001F44F\U0001F44F\r\n\
          \r\nI\u2019m currently on the lookout for an affordable GPU setup,\r\nSpecifically,\
          \ I look for something that can comfortably handle the 8-bit version of\
          \ 70B. \r\nDo you have any recommendations?\r\n\r\nAlso, is there a website\
          \ or forum where the community shares their GPU recommendations for different\
          \ versions of LLM quantizations?\r\n\r\nThanks in advance for any advice\
          \ or suggestions!"
        updatedAt: '2023-08-15T17:56:06.268Z'
      numEdits: 0
      reactions: []
    id: 64dbbc363ae9693d99080ce3
    type: comment
  author: Saiyan
  content: "Hey Tom and Community,\r\n\r\nThank you so much for the hard work and\
    \ effort you all put into these GGMLs! \U0001F44F\U0001F44F\U0001F44F\r\n\r\n\
    I\u2019m currently on the lookout for an affordable GPU setup,\r\nSpecifically,\
    \ I look for something that can comfortably handle the 8-bit version of 70B. \r\
    \nDo you have any recommendations?\r\n\r\nAlso, is there a website or forum where\
    \ the community shares their GPU recommendations for different versions of LLM\
    \ quantizations?\r\n\r\nThanks in advance for any advice or suggestions!"
  created_at: 2023-08-15 16:56:06+00:00
  edited: false
  hidden: false
  id: 64dbbc363ae9693d99080ce3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: TheBloke/Llama-2-70B-Chat-GGML
repo_type: model
status: open
target_branch: null
title: Seeking affordable GPU recommendations for the 70B 8-bit quantization
