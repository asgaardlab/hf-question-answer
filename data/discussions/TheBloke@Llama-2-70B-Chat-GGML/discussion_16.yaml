!!python/object:huggingface_hub.community.DiscussionWithDetails
author: shivammehta
conflicting_files: null
created_at: 2023-11-15 08:46:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2e441d2ae599b51824fb9db8d2a89fff.svg
      fullname: mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shivammehta
      type: user
    createdAt: '2023-11-15T08:46:19.000Z'
    data:
      edited: false
      editors:
      - shivammehta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.26626861095428467
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2e441d2ae599b51824fb9db8d2a89fff.svg
          fullname: mehta
          isHf: false
          isPro: false
          name: shivammehta
          type: user
        html: "<h2 id=\"i-am-getting-this-error---attributeerror-message-object-has-no-attribute-replace-for-the-following-code-any-idea-how-to-solve-this\"\
          >I am getting this error - AttributeError: 'Message' object has no attribute\
          \ 'replace'. For the following code, any idea how to solve this</h2>\n<h2\
          \ id=\"ingestpy\">Ingest.py</h2>\n<p>DATA_PATH = 'data/'<br>DB_FAISS_PATH\
          \ = 'vectorstore/db_faiss'</p>\n<p>def create_vector_db():<br>    loader\
          \ = DirectoryLoader(DATA_PATH,<br>                             glob='*.pdf',<br>\
          \                             loader_cls=PyPDFLoader)</p>\n<pre><code>documents\
          \ = loader.load()\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=500,\n\
          \                                               chunk_overlap=50)\ntexts\
          \ = text_splitter.split_documents(documents)\ndocs_text = [text.text for\
          \ text in texts]\n\nembeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n\
          \                                   model_kwargs={'device': 'cpu'})\n\n\
          db = FAISS.from_documents(docs_text, embeddings)\ndb.save_local(DB_FAISS_PATH)\n\
          </code></pre>\n<p>if <strong>name</strong> == \"<strong>main</strong>\"\
          :<br>    create_vector_db()</p>\n<hr>\n<h2 id=\"apppy\">app.py</h2>\n<p>from\
          \ langchain.document_loaders import PyPDFLoader, DirectoryLoader<br>from\
          \ langchain import PromptTemplate<br>from langchain.embeddings import HuggingFaceEmbeddings<br>from\
          \ langchain.vectorstores import FAISS<br>from langchain.llms import CTransformers<br>from\
          \ langchain.chains import RetrievalQA<br>import chainlit as cl<br>from ctransformers\
          \ import AutoModelForCausalLM,AutoConfig</p>\n<p>DB_FAISS_PATH = 'vectorstore/db_faiss'</p>\n\
          <p>def set_custom_prompt():<br>    prompt = PromptTemplate(template=custom_prompt_template,<br>\
          \                            input_variables=['context', 'question'])<br>\
          \    return prompt</p>\n<p>def retrieval_qa_chain(llm, prompt, db):<br>\
          \    qa_chain = RetrievalQA.from_chain_type(llm=llm,<br>               \
          \                        chain_type='stuff',<br>                       \
          \                retriever=db.as_retriever(search_kwargs={'k': 2}),<br>\
          \                                       return_source_documents=True,<br>\
          \                                       chain_type_kwargs={'prompt': prompt}<br>\
          \                                       )<br>    return qa_chain</p>\n<p>#Loading\
          \ the model<br>def load_llm():<br>    llm = CTransformers(<br>    model\
          \ = \"TheBloke/Llama-2-70B-Chat-GGML\",<br>    model_type=\"llama\",<br>\
          \    config=config<br>    )<br>    return llm</p>\n<p>def qa_bot():<br>\
          \    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\
          ,<br>                                       model_kwargs={'device': 'cpu'})<br>\
          \    db = FAISS.load_local(DB_FAISS_PATH, embeddings)<br>    llm = load_llm()<br>\
          \    qa_prompt = set_custom_prompt()<br>    qa = retrieval_qa_chain(llm,\
          \ qa_prompt, db)</p>\n<pre><code>return qa\n</code></pre>\n<p>def final_result(query):<br>\
          \    qa_result = qa_bot()<br>    response = qa_result({'query': query})<br>\
          \    return response</p>\n"
        raw: "I am getting this error - AttributeError: 'Message' object has no attribute\
          \ 'replace'. For the following code, any idea how to solve this\r\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\
          \nIngest.py\r\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\
          \nDATA_PATH = 'data/'\r\nDB_FAISS_PATH = 'vectorstore/db_faiss'\r\n\r\n\
          def create_vector_db():\r\n    loader = DirectoryLoader(DATA_PATH,\r\n \
          \                            glob='*.pdf',\r\n                         \
          \    loader_cls=PyPDFLoader)\r\n\r\n    documents = loader.load()\r\n  \
          \  text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,\r\n  \
          \                                                 chunk_overlap=50)\r\n\
          \    texts = text_splitter.split_documents(documents)\r\n    docs_text =\
          \ [text.text for text in texts]\r\n\r\n    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\r\
          \n                                       model_kwargs={'device': 'cpu'})\r\
          \n\r\n    db = FAISS.from_documents(docs_text, embeddings)\r\n    db.save_local(DB_FAISS_PATH)\r\
          \n\r\nif __name__ == \"__main__\":\r\n    create_vector_db()\r\n\r\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\
          \napp.py\r\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\
          \nfrom langchain.document_loaders import PyPDFLoader, DirectoryLoader\r\n\
          from langchain import PromptTemplate\r\nfrom langchain.embeddings import\
          \ HuggingFaceEmbeddings\r\nfrom langchain.vectorstores import FAISS\r\n\
          from langchain.llms import CTransformers\r\nfrom langchain.chains import\
          \ RetrievalQA\r\nimport chainlit as cl\r\nfrom ctransformers import AutoModelForCausalLM,AutoConfig\r\
          \n\r\nDB_FAISS_PATH = 'vectorstore/db_faiss'\r\n\r\ndef set_custom_prompt():\r\
          \n    prompt = PromptTemplate(template=custom_prompt_template,\r\n     \
          \                       input_variables=['context', 'question'])\r\n   \
          \ return prompt\r\n\r\ndef retrieval_qa_chain(llm, prompt, db):\r\n    qa_chain\
          \ = RetrievalQA.from_chain_type(llm=llm,\r\n                           \
          \            chain_type='stuff',\r\n                                   \
          \    retriever=db.as_retriever(search_kwargs={'k': 2}),\r\n            \
          \                           return_source_documents=True,\r\n          \
          \                             chain_type_kwargs={'prompt': prompt}\r\n \
          \                                      )\r\n    return qa_chain\r\n\r\n\
          #Loading the model\r\ndef load_llm():\r\n    llm = CTransformers(\r\n  \
          \  model = \"TheBloke/Llama-2-70B-Chat-GGML\",\r\n    model_type=\"llama\"\
          ,\r\n    config=config\r\n    )\r\n    return llm\r\n\r\ndef qa_bot():\r\
          \n    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\
          ,\r\n                                       model_kwargs={'device': 'cpu'})\r\
          \n    db = FAISS.load_local(DB_FAISS_PATH, embeddings)\r\n    llm = load_llm()\r\
          \n    qa_prompt = set_custom_prompt()\r\n    qa = retrieval_qa_chain(llm,\
          \ qa_prompt, db)\r\n\r\n    return qa\r\n\r\ndef final_result(query):\r\n\
          \    qa_result = qa_bot()\r\n    response = qa_result({'query': query})\r\
          \n    return response\r\n"
        updatedAt: '2023-11-15T08:46:19.943Z'
      numEdits: 0
      reactions: []
    id: 6554855be149dd8e9f3a8b79
    type: comment
  author: shivammehta
  content: "I am getting this error - AttributeError: 'Message' object has no attribute\
    \ 'replace'. For the following code, any idea how to solve this\r\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\
    \nIngest.py\r\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\
    \nDATA_PATH = 'data/'\r\nDB_FAISS_PATH = 'vectorstore/db_faiss'\r\n\r\ndef create_vector_db():\r\
    \n    loader = DirectoryLoader(DATA_PATH,\r\n                             glob='*.pdf',\r\
    \n                             loader_cls=PyPDFLoader)\r\n\r\n    documents =\
    \ loader.load()\r\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,\r\
    \n                                                   chunk_overlap=50)\r\n   \
    \ texts = text_splitter.split_documents(documents)\r\n    docs_text = [text.text\
    \ for text in texts]\r\n\r\n    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\r\
    \n                                       model_kwargs={'device': 'cpu'})\r\n\r\
    \n    db = FAISS.from_documents(docs_text, embeddings)\r\n    db.save_local(DB_FAISS_PATH)\r\
    \n\r\nif __name__ == \"__main__\":\r\n    create_vector_db()\r\n\r\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\
    \napp.py\r\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\
    \nfrom langchain.document_loaders import PyPDFLoader, DirectoryLoader\r\nfrom\
    \ langchain import PromptTemplate\r\nfrom langchain.embeddings import HuggingFaceEmbeddings\r\
    \nfrom langchain.vectorstores import FAISS\r\nfrom langchain.llms import CTransformers\r\
    \nfrom langchain.chains import RetrievalQA\r\nimport chainlit as cl\r\nfrom ctransformers\
    \ import AutoModelForCausalLM,AutoConfig\r\n\r\nDB_FAISS_PATH = 'vectorstore/db_faiss'\r\
    \n\r\ndef set_custom_prompt():\r\n    prompt = PromptTemplate(template=custom_prompt_template,\r\
    \n                            input_variables=['context', 'question'])\r\n   \
    \ return prompt\r\n\r\ndef retrieval_qa_chain(llm, prompt, db):\r\n    qa_chain\
    \ = RetrievalQA.from_chain_type(llm=llm,\r\n                                 \
    \      chain_type='stuff',\r\n                                       retriever=db.as_retriever(search_kwargs={'k':\
    \ 2}),\r\n                                       return_source_documents=True,\r\
    \n                                       chain_type_kwargs={'prompt': prompt}\r\
    \n                                       )\r\n    return qa_chain\r\n\r\n#Loading\
    \ the model\r\ndef load_llm():\r\n    llm = CTransformers(\r\n    model = \"TheBloke/Llama-2-70B-Chat-GGML\"\
    ,\r\n    model_type=\"llama\",\r\n    config=config\r\n    )\r\n    return llm\r\
    \n\r\ndef qa_bot():\r\n    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\
    ,\r\n                                       model_kwargs={'device': 'cpu'})\r\n\
    \    db = FAISS.load_local(DB_FAISS_PATH, embeddings)\r\n    llm = load_llm()\r\
    \n    qa_prompt = set_custom_prompt()\r\n    qa = retrieval_qa_chain(llm, qa_prompt,\
    \ db)\r\n\r\n    return qa\r\n\r\ndef final_result(query):\r\n    qa_result =\
    \ qa_bot()\r\n    response = qa_result({'query': query})\r\n    return response\r\
    \n"
  created_at: 2023-11-15 08:46:19+00:00
  edited: false
  hidden: false
  id: 6554855be149dd8e9f3a8b79
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: TheBloke/Llama-2-70B-Chat-GGML
repo_type: model
status: open
target_branch: null
title: 'AttributeError: ''Message'' object has no attribute ''replace'''
