!!python/object:huggingface_hub.community.DiscussionWithDetails
author: gschadow
conflicting_files: null
created_at: 2023-08-16 23:14:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cd7f14d65ad3dec02a82287836b3d246.svg
      fullname: Gunther Schadow
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gschadow
      type: user
    createdAt: '2023-08-17T00:14:04.000Z'
    data:
      edited: false
      editors:
      - gschadow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9288346171379089
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cd7f14d65ad3dec02a82287836b3d246.svg
          fullname: Gunther Schadow
          isHf: false
          isPro: false
          name: gschadow
          type: user
        html: '<p>On an AWS g4dn.metal instance you have 8 GPU cards plus 96 CPU cores.
          However, with llama.cpp, monitoring with nvidia-smi, I see that my GPUs
          are only 35% utilized with the 70B q4 model (and less with the smaller models).
          I also notice that if leaving -t unspecified it uses 96 threads and this
          actually slows things down drastically. I found that -t 4 is about as good
          as it gets, producing 8 tokens per second, but leaving me with 92 CPU cores
          that I can''t use but pay dearly for! Any idea how we can use the resources
          more fully or what causes the apparent contention with the high CPU thread
          count? And why we can''t fully use the GPUs to at least 80%? I would hope
          that 24 tokens per second should be possible with this kind of hardware.</p>

          <p><a rel="nofollow" href="https://stackoverflow.com/questions/76916333/how-can-i-use-the-gpus-more-effectively-on-an-aws-g5dn-metal-instance-running-ll">https://stackoverflow.com/questions/76916333/how-can-i-use-the-gpus-more-effectively-on-an-aws-g5dn-metal-instance-running-ll</a></p>

          '
        raw: "On an AWS g4dn.metal instance you have 8 GPU cards plus 96 CPU cores.\
          \ However, with llama.cpp, monitoring with nvidia-smi, I see that my GPUs\
          \ are only 35% utilized with the 70B q4 model (and less with the smaller\
          \ models). I also notice that if leaving -t unspecified it uses 96 threads\
          \ and this actually slows things down drastically. I found that -t 4 is\
          \ about as good as it gets, producing 8 tokens per second, but leaving me\
          \ with 92 CPU cores that I can't use but pay dearly for! Any idea how we\
          \ can use the resources more fully or what causes the apparent contention\
          \ with the high CPU thread count? And why we can't fully use the GPUs to\
          \ at least 80%? I would hope that 24 tokens per second should be possible\
          \ with this kind of hardware.\r\n\r\nhttps://stackoverflow.com/questions/76916333/how-can-i-use-the-gpus-more-effectively-on-an-aws-g5dn-metal-instance-running-ll"
        updatedAt: '2023-08-17T00:14:04.690Z'
      numEdits: 0
      reactions: []
    id: 64dd664c9f3bf1096316659b
    type: comment
  author: gschadow
  content: "On an AWS g4dn.metal instance you have 8 GPU cards plus 96 CPU cores.\
    \ However, with llama.cpp, monitoring with nvidia-smi, I see that my GPUs are\
    \ only 35% utilized with the 70B q4 model (and less with the smaller models).\
    \ I also notice that if leaving -t unspecified it uses 96 threads and this actually\
    \ slows things down drastically. I found that -t 4 is about as good as it gets,\
    \ producing 8 tokens per second, but leaving me with 92 CPU cores that I can't\
    \ use but pay dearly for! Any idea how we can use the resources more fully or\
    \ what causes the apparent contention with the high CPU thread count? And why\
    \ we can't fully use the GPUs to at least 80%? I would hope that 24 tokens per\
    \ second should be possible with this kind of hardware.\r\n\r\nhttps://stackoverflow.com/questions/76916333/how-can-i-use-the-gpus-more-effectively-on-an-aws-g5dn-metal-instance-running-ll"
  created_at: 2023-08-16 23:14:04+00:00
  edited: false
  hidden: false
  id: 64dd664c9f3bf1096316659b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: TheBloke/Llama-2-70B-Chat-GGML
repo_type: model
status: open
target_branch: null
title: Has anyone been able to use GPU and CPU more fully for higher speed output?
