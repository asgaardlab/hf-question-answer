!!python/object:huggingface_hub.community.DiscussionWithDetails
author: zakester
conflicting_files: null
created_at: 2023-09-23 08:02:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/N3t--oa6NHNSpF52T9Ilq.png?w=200&h=200&f=face
      fullname: Hadjammar Hamza Zakaria
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zakester
      type: user
    createdAt: '2023-09-23T09:02:12.000Z'
    data:
      edited: false
      editors:
      - zakester
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3815535604953766
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/N3t--oa6NHNSpF52T9Ilq.png?w=200&h=200&f=face
          fullname: Hadjammar Hamza Zakaria
          isHf: false
          isPro: false
          name: zakester
          type: user
        html: "<p>Hi, when I try to fine tune phi-1.5 I get this error:</p>\n<pre><code\
          \ class=\"language-error\">AttributeError: 'MixFormerSequentialForCausalLM'\
          \ object has no attribute '_set_gradient_checkpointing'\n</code></pre>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span>\
          \ trl <span class=\"hljs-keyword\">import</span> SFTTrainer\n\nmax_seq_length\
          \ = <span class=\"hljs-number\">512</span>\n\ntrainer = SFTTrainer(\n  \
          \  model=model,\n    train_dataset=dataset,\n    peft_config=lora_config,\n\
          \    dataset_text_field=<span class=\"hljs-string\">\"formated\"</span>,\n\
          \    max_seq_length=max_seq_length,\n    tokenizer=tokenizer,\n    args=training_arguments,\n\
          )\n</code></pre>\n"
        raw: "Hi, when I try to fine tune phi-1.5 I get this error:\r\n```error\r\n\
          AttributeError: 'MixFormerSequentialForCausalLM' object has no attribute\
          \ '_set_gradient_checkpointing'\r\n```\r\n\r\n```python\r\nfrom trl import\
          \ SFTTrainer\r\n\r\nmax_seq_length = 512\r\n\r\ntrainer = SFTTrainer(\r\n\
          \    model=model,\r\n    train_dataset=dataset,\r\n    peft_config=lora_config,\r\
          \n    dataset_text_field=\"formated\",\r\n    max_seq_length=max_seq_length,\r\
          \n    tokenizer=tokenizer,\r\n    args=training_arguments,\r\n)\r\n```\r\
          \n"
        updatedAt: '2023-09-23T09:02:12.193Z'
      numEdits: 0
      reactions: []
    id: 650ea994bfb7dd98bbb942f9
    type: comment
  author: zakester
  content: "Hi, when I try to fine tune phi-1.5 I get this error:\r\n```error\r\n\
    AttributeError: 'MixFormerSequentialForCausalLM' object has no attribute '_set_gradient_checkpointing'\r\
    \n```\r\n\r\n```python\r\nfrom trl import SFTTrainer\r\n\r\nmax_seq_length = 512\r\
    \n\r\ntrainer = SFTTrainer(\r\n    model=model,\r\n    train_dataset=dataset,\r\
    \n    peft_config=lora_config,\r\n    dataset_text_field=\"formated\",\r\n   \
    \ max_seq_length=max_seq_length,\r\n    tokenizer=tokenizer,\r\n    args=training_arguments,\r\
    \n)\r\n```\r\n"
  created_at: 2023-09-23 08:02:12+00:00
  edited: false
  hidden: false
  id: 650ea994bfb7dd98bbb942f9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-09-23T10:24:51.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9109638929367065
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>Phi model does not support gradient checkpointing</p>

          '
        raw: Phi model does not support gradient checkpointing
        updatedAt: '2023-09-23T10:24:51.880Z'
      numEdits: 0
      reactions: []
    id: 650ebcf3871fed2307c0046c
    type: comment
  author: teknium
  content: Phi model does not support gradient checkpointing
  created_at: 2023-09-23 09:24:51+00:00
  edited: false
  hidden: false
  id: 650ebcf3871fed2307c0046c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/N3t--oa6NHNSpF52T9Ilq.png?w=200&h=200&f=face
      fullname: Hadjammar Hamza Zakaria
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zakester
      type: user
    createdAt: '2023-09-24T12:02:38.000Z'
    data:
      edited: false
      editors:
      - zakester
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6148212552070618
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/N3t--oa6NHNSpF52T9Ilq.png?w=200&h=200&f=face
          fullname: Hadjammar Hamza Zakaria
          isHf: false
          isPro: false
          name: zakester
          type: user
        html: "<p>Thank you for your replay, I fixed it by doing this:</p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">from</span> peft\
          \ <span class=\"hljs-keyword\">import</span> LoraConfig\n<span class=\"\
          hljs-keyword\">from</span> peft <span class=\"hljs-keyword\">import</span>\
          \ get_peft_model\n\nlora_config = LoraConfig(\n    lora_alpha=<span class=\"\
          hljs-number\">16</span>,\n    lora_dropout=<span class=\"hljs-number\">0.1</span>,\n\
          \    r=<span class=\"hljs-number\">64</span>,\n    target_modules=[<span\
          \ class=\"hljs-string\">\"Wqkv\"</span>, <span class=\"hljs-string\">\"\
          out_proj\"</span>],\n    bias=<span class=\"hljs-string\">\"none\"</span>,\n\
          \    task_type=<span class=\"hljs-string\">\"CAUSAL_LM\"</span>,\n)\nmodel\
          \ = get_peft_model(model, lora_config) <span class=\"hljs-comment\"># adding\
          \ this line was the fix not sure why.</span>\n</code></pre>\n"
        raw: "Thank you for your replay, I fixed it by doing this:\n```python\nfrom\
          \ peft import LoraConfig\nfrom peft import get_peft_model\n\nlora_config\
          \ = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n\
          \    target_modules=[\"Wqkv\", \"out_proj\"],\n    bias=\"none\",\n    task_type=\"\
          CAUSAL_LM\",\n)\nmodel = get_peft_model(model, lora_config) # adding this\
          \ line was the fix not sure why.\n```"
        updatedAt: '2023-09-24T12:02:38.518Z'
      numEdits: 0
      reactions: []
    id: 6510255e2a45730c3f06b6cd
    type: comment
  author: zakester
  content: "Thank you for your replay, I fixed it by doing this:\n```python\nfrom\
    \ peft import LoraConfig\nfrom peft import get_peft_model\n\nlora_config = LoraConfig(\n\
    \    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    target_modules=[\"\
    Wqkv\", \"out_proj\"],\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\
    model = get_peft_model(model, lora_config) # adding this line was the fix not\
    \ sure why.\n```"
  created_at: 2023-09-24 11:02:38+00:00
  edited: false
  hidden: false
  id: 6510255e2a45730c3f06b6cd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/N3t--oa6NHNSpF52T9Ilq.png?w=200&h=200&f=face
      fullname: Hadjammar Hamza Zakaria
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zakester
      type: user
    createdAt: '2023-09-28T10:39:29.000Z'
    data:
      status: closed
    id: 651557e1d3db5d650578512a
    type: status-change
  author: zakester
  created_at: 2023-09-28 09:39:29+00:00
  id: 651557e1d3db5d650578512a
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: teknium/Phi-Hermes-1.3B
repo_type: model
status: closed
target_branch: null
title: '''MixFormerSequentialForCausalLM'' object has no attribute ''_set_gradient_checkpointing'''
