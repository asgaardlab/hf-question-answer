!!python/object:huggingface_hub.community.DiscussionWithDetails
author: YearZero
conflicting_files: null
created_at: 2023-11-14 23:17:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b236d17571f237ae84ef00ce91556cb6.svg
      fullname: Michael Shatskiy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YearZero
      type: user
    createdAt: '2023-11-14T23:17:41.000Z'
    data:
      edited: true
      editors:
      - YearZero
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9774870276451111
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b236d17571f237ae84ef00ce91556cb6.svg
          fullname: Michael Shatskiy
          isHf: false
          isPro: false
          name: YearZero
          type: user
        html: '<p>Not sure if others have tried the different quants - as the title
          says, I can''t seem to get q4_K_M to give me anything besides symbols, but
          Q4_0 works perfectly.</p>

          <p>Edit: Nevermind, Q4_0 is also only occasionally giving an answer, and
          mostly just &lt; s &gt;. May just have to wait for llamacpp fix and see
          how it works!</p>

          '
        raw: 'Not sure if others have tried the different quants - as the title says,
          I can''t seem to get q4_K_M to give me anything besides symbols, but Q4_0
          works perfectly.


          Edit: Nevermind, Q4_0 is also only occasionally giving an answer, and mostly
          just < s >. May just have to wait for llamacpp fix and see how it works!'
        updatedAt: '2023-11-15T01:00:59.788Z'
      numEdits: 3
      reactions: []
    id: 6554001537b3d8566291023c
    type: comment
  author: YearZero
  content: 'Not sure if others have tried the different quants - as the title says,
    I can''t seem to get q4_K_M to give me anything besides symbols, but Q4_0 works
    perfectly.


    Edit: Nevermind, Q4_0 is also only occasionally giving an answer, and mostly just
    < s >. May just have to wait for llamacpp fix and see how it works!'
  created_at: 2023-11-14 23:17:41+00:00
  edited: true
  hidden: false
  id: 6554001537b3d8566291023c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ee866b2e968f89128ef1c57abde1810c.svg
      fullname: Pol
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: machachu56
      type: user
    createdAt: '2023-11-15T11:40:55.000Z'
    data:
      edited: false
      editors:
      - machachu56
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.656502366065979
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ee866b2e968f89128ef1c57abde1810c.svg
          fullname: Pol
          isHf: false
          isPro: false
          name: machachu56
          type: user
        html: '<p>I''m facing the same issue with the Q4_K_S quant</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6150447400a52e55be2994e2/e7VIDrfvbZNh61G5JPAYG.png"><img
          alt="imagen.png" src="https://cdn-uploads.huggingface.co/production/uploads/6150447400a52e55be2994e2/e7VIDrfvbZNh61G5JPAYG.png"></a></p>

          '
        raw: 'I''m facing the same issue with the Q4_K_S quant


          ![imagen.png](https://cdn-uploads.huggingface.co/production/uploads/6150447400a52e55be2994e2/e7VIDrfvbZNh61G5JPAYG.png)


          '
        updatedAt: '2023-11-15T11:40:55.494Z'
      numEdits: 0
      reactions: []
    id: 6554ae47198da1df58768264
    type: comment
  author: machachu56
  content: 'I''m facing the same issue with the Q4_K_S quant


    ![imagen.png](https://cdn-uploads.huggingface.co/production/uploads/6150447400a52e55be2994e2/e7VIDrfvbZNh61G5JPAYG.png)


    '
  created_at: 2023-11-15 11:40:55+00:00
  edited: false
  hidden: false
  id: 6554ae47198da1df58768264
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-15T12:01:46.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8322142958641052
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I have just now updated the prompt template in the README.  It turns
          out this model is very sensitive to an exact prompt template, and even something
          as simple as adding one space  after <code>ASSISTANT:</code> can break its
          output. Newlines in the prompt template also seem to increase the chance
          of bad output.</p>

          <p>Please change your prompt template to: <code>USER: {prompt} ASSISTANT:</code>
          with no newlines and no space after the final <code>:</code>, and try again.</p>

          <p>See here for more discussions of that, and my testing in llama.cpp: <a
          href="https://huggingface.co/TheBloke/Nous-Capybara-34B-GGUF/discussions/4#6554af44d7b239fd39cdb573">https://huggingface.co/TheBloke/Nous-Capybara-34B-GGUF/discussions/4#6554af44d7b239fd39cdb573</a></p>

          '
        raw: 'I have just now updated the prompt template in the README.  It turns
          out this model is very sensitive to an exact prompt template, and even something
          as simple as adding one space  after `ASSISTANT:` can break its output.
          Newlines in the prompt template also seem to increase the chance of bad
          output.


          Please change your prompt template to: `USER: {prompt} ASSISTANT:` with
          no newlines and no space after the final `:`, and try again.


          See here for more discussions of that, and my testing in llama.cpp: https://huggingface.co/TheBloke/Nous-Capybara-34B-GGUF/discussions/4#6554af44d7b239fd39cdb573'
        updatedAt: '2023-11-15T12:02:31.508Z'
      numEdits: 2
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - PrimeD
        - YearZero
        - machachu56
        - Yhyu13
    id: 6554b32a0a67552288463093
    type: comment
  author: TheBloke
  content: 'I have just now updated the prompt template in the README.  It turns out
    this model is very sensitive to an exact prompt template, and even something as
    simple as adding one space  after `ASSISTANT:` can break its output. Newlines
    in the prompt template also seem to increase the chance of bad output.


    Please change your prompt template to: `USER: {prompt} ASSISTANT:` with no newlines
    and no space after the final `:`, and try again.


    See here for more discussions of that, and my testing in llama.cpp: https://huggingface.co/TheBloke/Nous-Capybara-34B-GGUF/discussions/4#6554af44d7b239fd39cdb573'
  created_at: 2023-11-15 12:01:46+00:00
  edited: true
  hidden: false
  id: 6554b32a0a67552288463093
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b236d17571f237ae84ef00ce91556cb6.svg
      fullname: Michael Shatskiy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YearZero
      type: user
    createdAt: '2023-11-15T17:15:08.000Z'
    data:
      edited: false
      editors:
      - YearZero
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9885066151618958
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b236d17571f237ae84ef00ce91556cb6.svg
          fullname: Michael Shatskiy
          isHf: false
          isPro: false
          name: YearZero
          type: user
        html: '<p>Thanks for the tip, didn''t realize how sensitive it would be as
          bigger models tend to be less sensitive to that stuff. That definitely fixed
          the issue!</p>

          '
        raw: Thanks for the tip, didn't realize how sensitive it would be as bigger
          models tend to be less sensitive to that stuff. That definitely fixed the
          issue!
        updatedAt: '2023-11-15T17:15:08.690Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6554fc9c65204c6fd14c812f
    id: 6554fc9c65204c6fd14c8128
    type: comment
  author: YearZero
  content: Thanks for the tip, didn't realize how sensitive it would be as bigger
    models tend to be less sensitive to that stuff. That definitely fixed the issue!
  created_at: 2023-11-15 17:15:08+00:00
  edited: false
  hidden: false
  id: 6554fc9c65204c6fd14c8128
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/b236d17571f237ae84ef00ce91556cb6.svg
      fullname: Michael Shatskiy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YearZero
      type: user
    createdAt: '2023-11-15T17:15:08.000Z'
    data:
      status: closed
    id: 6554fc9c65204c6fd14c812f
    type: status-change
  author: YearZero
  created_at: 2023-11-15 17:15:08+00:00
  id: 6554fc9c65204c6fd14c812f
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/Nous-Capybara-34B-GGUF
repo_type: model
status: closed
target_branch: null
title: Q4_0 works great in Koboldcpp, Q4_K_M gives absolute gibberish.
