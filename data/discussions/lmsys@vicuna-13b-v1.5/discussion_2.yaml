!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nicoleds
conflicting_files: null
created_at: 2023-09-05 04:37:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7622c1e940db9d5cfb4ae599c608d5c8.svg
      fullname: Nicole
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nicoleds
      type: user
    createdAt: '2023-09-05T05:37:43.000Z'
    data:
      edited: false
      editors:
      - nicoleds
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6602892875671387
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7622c1e940db9d5cfb4ae599c608d5c8.svg
          fullname: Nicole
          isHf: false
          isPro: false
          name: nicoleds
          type: user
        html: '<p>Hi, I have loaded the model into my local using<br>from transformers
          import AutoTokenizer, AutoModelForCausalLM<br>tokenizer = AutoTokenizer.from_pretrained("lmsys/vicuna-13b-v1.5")<br>model
          = AutoModelForCausalLM.from_pretrained("lmsys/vicuna-13b-v1.5") </p>

          <p>but every time I load the model it still tries to connect to huggingface
          to get the tokenizer_config.json and config.json files, returning the error
          as follows:</p>

          <p>''HTTPSConnectionPool(host=''huggingface.co'', port=443): Max retries
          exceeded with url: /lmsys/vicuna-13b-v1.5/resolve/main/tokenizer_config.json
          (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object
          at 0x7fff1f86f0a0&gt;, ''Connection to huggingface.co timed out. (connect
          timeout=10)''))'' thrown while requesting HEAD <a href="https://huggingface.co/lmsys/vicuna-13b-v1.5/resolve/main/tokenizer_config.json">https://huggingface.co/lmsys/vicuna-13b-v1.5/resolve/main/tokenizer_config.json</a><br>''HTTPSConnectionPool(host=''huggingface.co'',
          port=443): Max retries exceeded with url: /lmsys/vicuna-13b-v1.5/resolve/main/config.json
          (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object
          at 0x7fff1f86ff40&gt;, ''Connection to huggingface.co timed out. (connect
          timeout=10)''))'' thrown while requesting HEAD <a href="https://huggingface.co/lmsys/vicuna-13b-v1.5/resolve/main/config.json">https://huggingface.co/lmsys/vicuna-13b-v1.5/resolve/main/config.json</a></p>

          <p>Is it possible for me to download the tokenizer_config.json and config.json
          files into my local? and if so where should they be saved? thanks</p>

          '
        raw: "Hi, I have loaded the model into my local using \r\nfrom transformers\
          \ import AutoTokenizer, AutoModelForCausalLM\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
          lmsys/vicuna-13b-v1.5\")    \r\nmodel = AutoModelForCausalLM.from_pretrained(\"\
          lmsys/vicuna-13b-v1.5\") \r\n\r\nbut every time I load the model it still\
          \ tries to connect to huggingface to get the tokenizer_config.json and config.json\
          \ files, returning the error as follows:\r\n\r\n'HTTPSConnectionPool(host='huggingface.co',\
          \ port=443): Max retries exceeded with url: /lmsys/vicuna-13b-v1.5/resolve/main/tokenizer_config.json\
          \ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object\
          \ at 0x7fff1f86f0a0>, 'Connection to huggingface.co timed out. (connect\
          \ timeout=10)'))' thrown while requesting HEAD https://huggingface.co/lmsys/vicuna-13b-v1.5/resolve/main/tokenizer_config.json\r\
          \n'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded\
          \ with url: /lmsys/vicuna-13b-v1.5/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection\
          \ object at 0x7fff1f86ff40>, 'Connection to huggingface.co timed out. (connect\
          \ timeout=10)'))' thrown while requesting HEAD https://huggingface.co/lmsys/vicuna-13b-v1.5/resolve/main/config.json\r\
          \n\r\nIs it possible for me to download the tokenizer_config.json and config.json\
          \ files into my local? and if so where should they be saved? thanks"
        updatedAt: '2023-09-05T05:37:43.255Z'
      numEdits: 0
      reactions: []
    id: 64f6bea710a91217c3818fad
    type: comment
  author: nicoleds
  content: "Hi, I have loaded the model into my local using \r\nfrom transformers\
    \ import AutoTokenizer, AutoModelForCausalLM\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
    lmsys/vicuna-13b-v1.5\")    \r\nmodel = AutoModelForCausalLM.from_pretrained(\"\
    lmsys/vicuna-13b-v1.5\") \r\n\r\nbut every time I load the model it still tries\
    \ to connect to huggingface to get the tokenizer_config.json and config.json files,\
    \ returning the error as follows:\r\n\r\n'HTTPSConnectionPool(host='huggingface.co',\
    \ port=443): Max retries exceeded with url: /lmsys/vicuna-13b-v1.5/resolve/main/tokenizer_config.json\
    \ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at\
    \ 0x7fff1f86f0a0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))'\
    \ thrown while requesting HEAD https://huggingface.co/lmsys/vicuna-13b-v1.5/resolve/main/tokenizer_config.json\r\
    \n'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded\
    \ with url: /lmsys/vicuna-13b-v1.5/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection\
    \ object at 0x7fff1f86ff40>, 'Connection to huggingface.co timed out. (connect\
    \ timeout=10)'))' thrown while requesting HEAD https://huggingface.co/lmsys/vicuna-13b-v1.5/resolve/main/config.json\r\
    \n\r\nIs it possible for me to download the tokenizer_config.json and config.json\
    \ files into my local? and if so where should they be saved? thanks"
  created_at: 2023-09-05 04:37:43+00:00
  edited: false
  hidden: false
  id: 64f6bea710a91217c3818fad
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: lmsys/vicuna-13b-v1.5
repo_type: model
status: open
target_branch: null
title: 'How to save  tokenizer_config.json and config.json files into local '
