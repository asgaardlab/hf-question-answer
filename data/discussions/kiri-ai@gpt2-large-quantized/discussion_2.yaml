!!python/object:huggingface_hub.community.DiscussionWithDetails
author: apivovarov
conflicting_files: null
created_at: 2023-02-16 07:32:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63db100d9f2687298a11f6c5/gvB6awPC5CHdhGc3V4lq9.jpeg?w=200&h=200&f=face
      fullname: Alexander Pivovarov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: apivovarov
      type: user
    createdAt: '2023-02-16T07:32:09.000Z'
    data:
      edited: false
      editors:
      - apivovarov
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63db100d9f2687298a11f6c5/gvB6awPC5CHdhGc3V4lq9.jpeg?w=200&h=200&f=face
          fullname: Alexander Pivovarov
          isHf: false
          isPro: false
          name: apivovarov
          type: user
        html: "<p><a rel=\"nofollow\" href=\"https://metatext.io/models/kiri-ai-gpt2-large-quantized\"\
          >The Doc</a> says</p>\n<pre><code># Import generic wrappers\nfrom transformers\
          \ import AutoModel, AutoTokenizer \n\n# Define the model repo\nmodel_name\
          \ = \"kiri-ai/gpt2-large-quantized\" \n\n# Download pytorch model\nmodel\
          \ = AutoModel.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\
          \n# Transform input tokens \ninputs = tokenizer(\"Hello world!\", return_tensors=\"\
          pt\")\n\n# Model apply\noutputs = model(**inputs)\n</code></pre>\n<p>However\
          \ it fails.</p>\n<p>Errors:</p>\n<pre><code>Traceback (most recent call\
          \ last):\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\"\
          , line 2007, in from_pretrained\n    resolved_archive_file = cached_path(\n\
          \  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\"\
          , line 284, in cached_path\n    output_path = get_from_cache(\n  File \"\
          /usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\", line\
          \ 495, in get_from_cache\n    _raise_for_status(r)\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\"\
          , line 411, in _raise_for_status\n    raise EntryNotFoundError(f\"404 Client\
          \ Error: Entry Not Found for url: {response.url}\")\ntransformers.utils.hub.EntryNotFoundError:\
          \ 404 Client Error: Entry Not Found for url: https://huggingface.co/kiri-ai/gpt2-large-quantized/resolve/main/pytorch_model.bin\n\
          \nDuring handling of the above exception, another exception occurred:\n\n\
          Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\"\
          , line 2041, in from_pretrained\n    resolved_archive_file = cached_path(\n\
          \  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\"\
          , line 284, in cached_path\n    output_path = get_from_cache(\n  File \"\
          /usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\", line\
          \ 495, in get_from_cache\n    _raise_for_status(r)\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\"\
          , line 411, in _raise_for_status\n    raise EntryNotFoundError(f\"404 Client\
          \ Error: Entry Not Found for url: {response.url}\")\ntransformers.utils.hub.EntryNotFoundError:\
          \ 404 Client Error: Entry Not Found for url: https://huggingface.co/kiri-ai/gpt2-large-quantized/resolve/main/pytorch_model.bin.index.json\n\
          \nDuring handling of the above exception, another exception occurred:\n\n\
          Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in\
          \ &lt;module&gt;\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py\"\
          , line 446, in from_pretrained\n    return model_class.from_pretrained(pretrained_model_name_or_path,\
          \ *model_args, config=config, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\"\
          , line 2074, in from_pretrained\n    raise EnvironmentError(\nOSError: kiri-ai/gpt2-large-quantized\
          \ does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt\
          \ or flax_model.msgpack.\n</code></pre>\n"
        raw: "[The Doc](https://metatext.io/models/kiri-ai-gpt2-large-quantized) says\r\
          \n```\r\n# Import generic wrappers\r\nfrom transformers import AutoModel,\
          \ AutoTokenizer \r\n\r\n# Define the model repo\r\nmodel_name = \"kiri-ai/gpt2-large-quantized\"\
          \ \r\n\r\n# Download pytorch model\r\nmodel = AutoModel.from_pretrained(model_name)\r\
          \ntokenizer = AutoTokenizer.from_pretrained(model_name)\r\n\r\n# Transform\
          \ input tokens \r\ninputs = tokenizer(\"Hello world!\", return_tensors=\"\
          pt\")\r\n\r\n# Model apply\r\noutputs = model(**inputs)\r\n```\r\n\r\nHowever\
          \ it fails.\r\n\r\nErrors:\r\n```\r\nTraceback (most recent call last):\r\
          \n  File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\"\
          , line 2007, in from_pretrained\r\n    resolved_archive_file = cached_path(\r\
          \n  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\"\
          , line 284, in cached_path\r\n    output_path = get_from_cache(\r\n  File\
          \ \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\",\
          \ line 495, in get_from_cache\r\n    _raise_for_status(r)\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\"\
          , line 411, in _raise_for_status\r\n    raise EntryNotFoundError(f\"404\
          \ Client Error: Entry Not Found for url: {response.url}\")\r\ntransformers.utils.hub.EntryNotFoundError:\
          \ 404 Client Error: Entry Not Found for url: https://huggingface.co/kiri-ai/gpt2-large-quantized/resolve/main/pytorch_model.bin\r\
          \n\r\nDuring handling of the above exception, another exception occurred:\r\
          \n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\"\
          , line 2041, in from_pretrained\r\n    resolved_archive_file = cached_path(\r\
          \n  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\"\
          , line 284, in cached_path\r\n    output_path = get_from_cache(\r\n  File\
          \ \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\",\
          \ line 495, in get_from_cache\r\n    _raise_for_status(r)\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\"\
          , line 411, in _raise_for_status\r\n    raise EntryNotFoundError(f\"404\
          \ Client Error: Entry Not Found for url: {response.url}\")\r\ntransformers.utils.hub.EntryNotFoundError:\
          \ 404 Client Error: Entry Not Found for url: https://huggingface.co/kiri-ai/gpt2-large-quantized/resolve/main/pytorch_model.bin.index.json\r\
          \n\r\nDuring handling of the above exception, another exception occurred:\r\
          \n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1,\
          \ in <module>\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py\"\
          , line 446, in from_pretrained\r\n    return model_class.from_pretrained(pretrained_model_name_or_path,\
          \ *model_args, config=config, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\"\
          , line 2074, in from_pretrained\r\n    raise EnvironmentError(\r\nOSError:\
          \ kiri-ai/gpt2-large-quantized does not appear to have a file named pytorch_model.bin,\
          \ tf_model.h5, model.ckpt or flax_model.msgpack.\r\n```"
        updatedAt: '2023-02-16T07:32:09.585Z'
      numEdits: 0
      reactions: []
    id: 63eddbf9288963402f9417fd
    type: comment
  author: apivovarov
  content: "[The Doc](https://metatext.io/models/kiri-ai-gpt2-large-quantized) says\r\
    \n```\r\n# Import generic wrappers\r\nfrom transformers import AutoModel, AutoTokenizer\
    \ \r\n\r\n# Define the model repo\r\nmodel_name = \"kiri-ai/gpt2-large-quantized\"\
    \ \r\n\r\n# Download pytorch model\r\nmodel = AutoModel.from_pretrained(model_name)\r\
    \ntokenizer = AutoTokenizer.from_pretrained(model_name)\r\n\r\n# Transform input\
    \ tokens \r\ninputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\r\n\r\
    \n# Model apply\r\noutputs = model(**inputs)\r\n```\r\n\r\nHowever it fails.\r\
    \n\r\nErrors:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\"\
    , line 2007, in from_pretrained\r\n    resolved_archive_file = cached_path(\r\n\
    \  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\",\
    \ line 284, in cached_path\r\n    output_path = get_from_cache(\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\"\
    , line 495, in get_from_cache\r\n    _raise_for_status(r)\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\"\
    , line 411, in _raise_for_status\r\n    raise EntryNotFoundError(f\"404 Client\
    \ Error: Entry Not Found for url: {response.url}\")\r\ntransformers.utils.hub.EntryNotFoundError:\
    \ 404 Client Error: Entry Not Found for url: https://huggingface.co/kiri-ai/gpt2-large-quantized/resolve/main/pytorch_model.bin\r\
    \n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\
    \nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\"\
    , line 2041, in from_pretrained\r\n    resolved_archive_file = cached_path(\r\n\
    \  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\",\
    \ line 284, in cached_path\r\n    output_path = get_from_cache(\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\"\
    , line 495, in get_from_cache\r\n    _raise_for_status(r)\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\"\
    , line 411, in _raise_for_status\r\n    raise EntryNotFoundError(f\"404 Client\
    \ Error: Entry Not Found for url: {response.url}\")\r\ntransformers.utils.hub.EntryNotFoundError:\
    \ 404 Client Error: Entry Not Found for url: https://huggingface.co/kiri-ai/gpt2-large-quantized/resolve/main/pytorch_model.bin.index.json\r\
    \n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\
    \nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\
    \n  File \"/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py\"\
    , line 446, in from_pretrained\r\n    return model_class.from_pretrained(pretrained_model_name_or_path,\
    \ *model_args, config=config, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\"\
    , line 2074, in from_pretrained\r\n    raise EnvironmentError(\r\nOSError: kiri-ai/gpt2-large-quantized\
    \ does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt\
    \ or flax_model.msgpack.\r\n```"
  created_at: 2023-02-16 07:32:09+00:00
  edited: false
  hidden: false
  id: 63eddbf9288963402f9417fd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: kiri-ai/gpt2-large-quantized
repo_type: model
status: open
target_branch: null
title: how to run kiri-ai/gpt2-large-quantized ?
