!!python/object:huggingface_hub.community.DiscussionWithDetails
author: andreP
conflicting_files: null
created_at: 2023-06-09 06:43:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4c06bf31639cc2bba7d9fb0e5e055047.svg
      fullname: "Andr\xE9 Pankraz"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andreP
      type: user
    createdAt: '2023-06-09T07:43:43.000Z'
    data:
      edited: false
      editors:
      - andreP
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8352339863777161
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4c06bf31639cc2bba7d9fb0e5e055047.svg
          fullname: "Andr\xE9 Pankraz"
          isHf: false
          isPro: false
          name: andreP
          type: user
        html: '<p>Hi,</p>

          <p>thx for this great model, I had very good results for question answering.<br>I
          have just one observation:<br>Following pair is a 100% match, which is not
          unexpected: "Wer ist antragsberechtigt?" and "Wer ist antragsberechtigt?"<br>But
          this similarity drops sub-70% by just adding 1 word: "Wer ist antragsberechtigt?"
          and "Wer ist antragsberechtigt? Test"<br>It drops even further with more
          appended ''Test'' words. Is this expected behaviour?<br>Is this because
          of the asymmetric nature of the training Question -&gt; Answer?<br>On the
          other hand, other embedding models or even cloud services like ada/openai
          or luminous/aleph don''t react quite as harsh, even though they are also
          trained for Q-&gt;A.</p>

          <p>Thx</p>

          '
        raw: "Hi,\r\n\r\nthx for this great model, I had very good results for question\
          \ answering.\r\nI have just one observation:\r\nFollowing pair is a 100%\
          \ match, which is not unexpected: \"Wer ist antragsberechtigt?\" and \"\
          Wer ist antragsberechtigt?\" \r\nBut this similarity drops sub-70% by just\
          \ adding 1 word: \"Wer ist antragsberechtigt?\" and \"Wer ist antragsberechtigt?\
          \ Test\"\r\nIt drops even further with more appended 'Test' words. Is this\
          \ expected behaviour?\r\nIs this because of the asymmetric nature of the\
          \ training Question -> Answer?\r\nOn the other hand, other embedding models\
          \ or even cloud services like ada/openai or luminous/aleph don't react quite\
          \ as harsh, even though they are also trained for Q->A.\r\n\r\nThx"
        updatedAt: '2023-06-09T07:43:43.208Z'
      numEdits: 0
      reactions: []
    id: 6482d82fc1026e4d651ca41d
    type: comment
  author: andreP
  content: "Hi,\r\n\r\nthx for this great model, I had very good results for question\
    \ answering.\r\nI have just one observation:\r\nFollowing pair is a 100% match,\
    \ which is not unexpected: \"Wer ist antragsberechtigt?\" and \"Wer ist antragsberechtigt?\"\
    \ \r\nBut this similarity drops sub-70% by just adding 1 word: \"Wer ist antragsberechtigt?\"\
    \ and \"Wer ist antragsberechtigt? Test\"\r\nIt drops even further with more appended\
    \ 'Test' words. Is this expected behaviour?\r\nIs this because of the asymmetric\
    \ nature of the training Question -> Answer?\r\nOn the other hand, other embedding\
    \ models or even cloud services like ada/openai or luminous/aleph don't react\
    \ quite as harsh, even though they are also trained for Q->A.\r\n\r\nThx"
  created_at: 2023-06-09 06:43:43+00:00
  edited: false
  hidden: false
  id: 6482d82fc1026e4d651ca41d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62da57f34be126e22e8bed5f/ghmINp1UDr9XnqZVaf_9G.png?w=200&h=200&f=face
      fullname: Lukas Kreussel
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LLukas22
      type: user
    createdAt: '2023-06-09T09:56:39.000Z'
    data:
      edited: false
      editors:
      - LLukas22
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9170576930046082
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62da57f34be126e22e8bed5f/ghmINp1UDr9XnqZVaf_9G.png?w=200&h=200&f=face
          fullname: Lukas Kreussel
          isHf: false
          isPro: false
          name: LLukas22
          type: user
        html: '<p>Hey,</p>

          <p>as stated in the modelcard this model is based on <a href="https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2">paraphrase-multilingual-mpnet-base-v2</a>,
          which is trained on a wide range of embedding tasks, but mainly 1-to-1 (same
          size) embeddings. This could maybe be the reason for this behaviour as the
          model still thinks, that the length of the input is important to the similarity.
          But i don''t know if this is only the case for the multilingual version
          or if this also affects the english only version. </p>

          <p>Maybe try the base model and check if it matches this behaviour.</p>

          '
        raw: "Hey,\n\nas stated in the modelcard this model is based on [paraphrase-multilingual-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2),\
          \ which is trained on a wide range of embedding tasks, but mainly 1-to-1\
          \ (same size) embeddings. This could maybe be the reason for this behaviour\
          \ as the model still thinks, that the length of the input is important to\
          \ the similarity. But i don't know if this is only the case for the multilingual\
          \ version or if this also affects the english only version. \n\nMaybe try\
          \ the base model and check if it matches this behaviour."
        updatedAt: '2023-06-09T09:56:39.428Z'
      numEdits: 0
      reactions: []
    id: 6482f757595ee512118bc75a
    type: comment
  author: LLukas22
  content: "Hey,\n\nas stated in the modelcard this model is based on [paraphrase-multilingual-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2),\
    \ which is trained on a wide range of embedding tasks, but mainly 1-to-1 (same\
    \ size) embeddings. This could maybe be the reason for this behaviour as the model\
    \ still thinks, that the length of the input is important to the similarity. But\
    \ i don't know if this is only the case for the multilingual version or if this\
    \ also affects the english only version. \n\nMaybe try the base model and check\
    \ if it matches this behaviour."
  created_at: 2023-06-09 08:56:39+00:00
  edited: false
  hidden: false
  id: 6482f757595ee512118bc75a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4c06bf31639cc2bba7d9fb0e5e055047.svg
      fullname: "Andr\xE9 Pankraz"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andreP
      type: user
    createdAt: '2023-06-12T06:26:27.000Z'
    data:
      edited: false
      editors:
      - andreP
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9925343990325928
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4c06bf31639cc2bba7d9fb0e5e055047.svg
          fullname: "Andr\xE9 Pankraz"
          isHf: false
          isPro: false
          name: andreP
          type: user
        html: '<p>The I tried the base model and it doesn''t react that harsh to adding
          single words, but it''s much worse for german question answering. Seems
          to come from fine tuning. You cannot have it all :)</p>

          '
        raw: The I tried the base model and it doesn't react that harsh to adding
          single words, but it's much worse for german question answering. Seems to
          come from fine tuning. You cannot have it all :)
        updatedAt: '2023-06-12T06:26:27.998Z'
      numEdits: 0
      reactions: []
    id: 6486ba93d29294981d2ef4b5
    type: comment
  author: andreP
  content: The I tried the base model and it doesn't react that harsh to adding single
    words, but it's much worse for german question answering. Seems to come from fine
    tuning. You cannot have it all :)
  created_at: 2023-06-12 05:26:27+00:00
  edited: false
  hidden: false
  id: 6486ba93d29294981d2ef4b5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62da57f34be126e22e8bed5f/ghmINp1UDr9XnqZVaf_9G.png?w=200&h=200&f=face
      fullname: Lukas Kreussel
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LLukas22
      type: user
    createdAt: '2023-06-12T07:49:58.000Z'
    data:
      edited: false
      editors:
      - LLukas22
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9257599115371704
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62da57f34be126e22e8bed5f/ghmINp1UDr9XnqZVaf_9G.png?w=200&h=200&f=face
          fullname: Lukas Kreussel
          isHf: false
          isPro: false
          name: LLukas22
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;andreP&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/andreP\">@<span class=\"\
          underline\">andreP</span></a></span>\n\n\t</span></span> Yeah, if you only\
          \ care about the german qa performance, you could take the base model and\
          \ finetune it on the germanquad dataset. This should result in a model that\
          \ is better on german QA and more robust against differences in sequenze\
          \ lengths.</p>\n"
        raw: '@andreP Yeah, if you only care about the german qa performance, you
          could take the base model and finetune it on the germanquad dataset. This
          should result in a model that is better on german QA and more robust against
          differences in sequenze lengths.'
        updatedAt: '2023-06-12T07:49:58.888Z'
      numEdits: 0
      reactions: []
    id: 6486ce26f69c61734c2961df
    type: comment
  author: LLukas22
  content: '@andreP Yeah, if you only care about the german qa performance, you could
    take the base model and finetune it on the germanquad dataset. This should result
    in a model that is better on german QA and more robust against differences in
    sequenze lengths.'
  created_at: 2023-06-12 06:49:58+00:00
  edited: false
  hidden: false
  id: 6486ce26f69c61734c2961df
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: LLukas22/paraphrase-multilingual-mpnet-base-v2-embedding-all
repo_type: model
status: open
target_branch: null
title: Strange behaviour
