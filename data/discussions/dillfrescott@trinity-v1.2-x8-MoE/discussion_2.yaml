!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ReXommendation
conflicting_files: null
created_at: 2024-01-01 11:59:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bb50f47c5235ec070041a4a9f78fe396.svg
      fullname: ReXommendation
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ReXommendation
      type: user
    createdAt: '2024-01-01T11:59:16.000Z'
    data:
      edited: false
      editors:
      - ReXommendation
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9933249354362488
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bb50f47c5235ec070041a4a9f78fe396.svg
          fullname: ReXommendation
          isHf: false
          isPro: false
          name: ReXommendation
          type: user
        html: '<p>I would like to know, is it just Trinity or is it other 7B models?</p>

          '
        raw: I would like to know, is it just Trinity or is it other 7B models?
        updatedAt: '2024-01-01T11:59:16.240Z'
      numEdits: 0
      reactions: []
    id: 6592a914e7b4143ec824b62d
    type: comment
  author: ReXommendation
  content: I would like to know, is it just Trinity or is it other 7B models?
  created_at: 2024-01-01 11:59:16+00:00
  edited: false
  hidden: false
  id: 6592a914e7b4143ec824b62d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
      fullname: Cross Nastasi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: dillfrescott
      type: user
    createdAt: '2024-01-01T12:30:30.000Z'
    data:
      edited: true
      editors:
      - dillfrescott
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9369049072265625
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
          fullname: Cross Nastasi
          isHf: false
          isPro: false
          name: dillfrescott
          type: user
        html: '<p>This is strictly just Trinity v1.2.</p>

          <p>Keep in mind it is under debate whether or not combining the same model
          into a mixture of experts actually enhances its reasoning ability or not.</p>

          <p>My argument is that it increases the reasoning ability, but not the knowledge,
          because you are adding more digital neurons that fire in parallel.</p>

          <p>But theres the argument that the weights are the same and produce the
          same results, therefore its not beneficial at all.</p>

          '
        raw: 'This is strictly just Trinity v1.2.


          Keep in mind it is under debate whether or not combining the same model
          into a mixture of experts actually enhances its reasoning ability or not.


          My argument is that it increases the reasoning ability, but not the knowledge,
          because you are adding more digital neurons that fire in parallel.


          But theres the argument that the weights are the same and produce the same
          results, therefore its not beneficial at all.'
        updatedAt: '2024-01-01T12:30:57.471Z'
      numEdits: 1
      reactions: []
    id: 6592b066a33889b27fde30f6
    type: comment
  author: dillfrescott
  content: 'This is strictly just Trinity v1.2.


    Keep in mind it is under debate whether or not combining the same model into a
    mixture of experts actually enhances its reasoning ability or not.


    My argument is that it increases the reasoning ability, but not the knowledge,
    because you are adding more digital neurons that fire in parallel.


    But theres the argument that the weights are the same and produce the same results,
    therefore its not beneficial at all.'
  created_at: 2024-01-01 12:30:30+00:00
  edited: true
  hidden: false
  id: 6592b066a33889b27fde30f6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: dillfrescott/trinity-v1.2-x8-MoE
repo_type: model
status: open
target_branch: null
title: What models are added in this MoE?
