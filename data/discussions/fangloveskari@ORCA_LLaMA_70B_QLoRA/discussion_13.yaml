!!python/object:huggingface_hub.community.DiscussionWithDetails
author: asuarez
conflicting_files: null
created_at: 2023-09-21 06:46:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21a1731c1e2cef82ca47282f642d74.svg
      fullname: Andres Suarez
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: asuarez
      type: user
    createdAt: '2023-09-21T07:46:26.000Z'
    data:
      edited: false
      editors:
      - asuarez
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9159742593765259
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21a1731c1e2cef82ca47282f642d74.svg
          fullname: Andres Suarez
          isHf: false
          isPro: false
          name: asuarez
          type: user
        html: '<p>Playing with your model through an inference endpoint and adding
          chat history to it, I seem to be hitting a token limit of 1512.<br>Can this
          be modified to be higher?</p>

          '
        raw: "Playing with your model through an inference endpoint and adding chat\
          \ history to it, I seem to be hitting a token limit of 1512.\r\nCan this\
          \ be modified to be higher?"
        updatedAt: '2023-09-21T07:46:26.438Z'
      numEdits: 0
      reactions: []
    id: 650bf4d224da30e773f11e5b
    type: comment
  author: asuarez
  content: "Playing with your model through an inference endpoint and adding chat\
    \ history to it, I seem to be hitting a token limit of 1512.\r\nCan this be modified\
    \ to be higher?"
  created_at: 2023-09-21 06:46:26+00:00
  edited: false
  hidden: false
  id: 650bf4d224da30e773f11e5b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21a1731c1e2cef82ca47282f642d74.svg
      fullname: Andres Suarez
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: asuarez
      type: user
    createdAt: '2023-10-07T01:45:55.000Z'
    data:
      edited: false
      editors:
      - asuarez
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8948507905006409
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21a1731c1e2cef82ca47282f642d74.svg
          fullname: Andres Suarez
          isHf: false
          isPro: false
          name: asuarez
          type: user
        html: '<p>Responding to myself, when running the inference endpoint, I didn''t
          notice the optional parameter  "Max Number of Tokens (per Query)", which
          was set by default to 1512.</p>

          '
        raw: 'Responding to myself, when running the inference endpoint, I didn''t
          notice the optional parameter  "Max Number of Tokens (per Query)", which
          was set by default to 1512.

          '
        updatedAt: '2023-10-07T01:45:55.559Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6520b853389ef6864d8cdd9a
    id: 6520b853389ef6864d8cdd99
    type: comment
  author: asuarez
  content: 'Responding to myself, when running the inference endpoint, I didn''t notice
    the optional parameter  "Max Number of Tokens (per Query)", which was set by default
    to 1512.

    '
  created_at: 2023-10-07 00:45:55+00:00
  edited: false
  hidden: false
  id: 6520b853389ef6864d8cdd99
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/1d21a1731c1e2cef82ca47282f642d74.svg
      fullname: Andres Suarez
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: asuarez
      type: user
    createdAt: '2023-10-07T01:45:55.000Z'
    data:
      status: closed
    id: 6520b853389ef6864d8cdd9a
    type: status-change
  author: asuarez
  created_at: 2023-10-07 00:45:55+00:00
  id: 6520b853389ef6864d8cdd9a
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: fangloveskari/ORCA_LLaMA_70B_QLoRA
repo_type: model
status: closed
target_branch: null
title: max input tokens?
