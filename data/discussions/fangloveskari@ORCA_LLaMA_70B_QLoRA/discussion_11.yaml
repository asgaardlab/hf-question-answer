!!python/object:huggingface_hub.community.DiscussionWithDetails
author: AIdinner
conflicting_files: null
created_at: 2023-09-14 12:29:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/39fb655746b9f52f289f4cf2a7b0c0e3.svg
      fullname: Pony Donkey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AIdinner
      type: user
    createdAt: '2023-09-14T13:29:34.000Z'
    data:
      edited: false
      editors:
      - AIdinner
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7403318881988525
      isReport: true
      latest:
        author:
          avatarUrl: /avatars/39fb655746b9f52f289f4cf2a7b0c0e3.svg
          fullname: Pony Donkey
          isHf: false
          isPro: false
          name: AIdinner
          type: user
        html: "<p>This model is claimed to be trained on LLaMA-2-70B but \"upstage\"\
          \ is found in its configuration, which is really strange.<br><a rel=\"nofollow\"\
          \ href=\"https://cdn-uploads.huggingface.co/production/uploads/639b39e5308b2454a9a40d73/7-EJJ3VYDFYFDlNUyWCTG.png\"\
          ><img alt=\"\u622A\u5C4F2023-09-14 21.24.32.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/639b39e5308b2454a9a40d73/7-EJJ3VYDFYFDlNUyWCTG.png\"\
          ></a><br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/639b39e5308b2454a9a40d73/ALgvaHTQrEBYlJQ2p7q8T.png\"\
          ><img alt=\"\u622A\u5C4F2023-09-14 21.25.23.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/639b39e5308b2454a9a40d73/ALgvaHTQrEBYlJQ2p7q8T.png\"\
          ></a></p>\n"
        raw: "This model is claimed to be trained on LLaMA-2-70B but \"upstage\" is\
          \ found in its configuration, which is really strange.\r\n![\u622A\u5C4F\
          2023-09-14 21.24.32.png](https://cdn-uploads.huggingface.co/production/uploads/639b39e5308b2454a9a40d73/7-EJJ3VYDFYFDlNUyWCTG.png)\r\
          \n![\u622A\u5C4F2023-09-14 21.25.23.png](https://cdn-uploads.huggingface.co/production/uploads/639b39e5308b2454a9a40d73/ALgvaHTQrEBYlJQ2p7q8T.png)"
        updatedAt: '2023-09-14T13:29:34.719Z'
      numEdits: 0
      reactions: []
    id: 65030abeb1792803da8293ee
    type: comment
  author: AIdinner
  content: "This model is claimed to be trained on LLaMA-2-70B but \"upstage\" is\
    \ found in its configuration, which is really strange.\r\n![\u622A\u5C4F2023-09-14\
    \ 21.24.32.png](https://cdn-uploads.huggingface.co/production/uploads/639b39e5308b2454a9a40d73/7-EJJ3VYDFYFDlNUyWCTG.png)\r\
    \n![\u622A\u5C4F2023-09-14 21.25.23.png](https://cdn-uploads.huggingface.co/production/uploads/639b39e5308b2454a9a40d73/ALgvaHTQrEBYlJQ2p7q8T.png)"
  created_at: 2023-09-14 12:29:34+00:00
  edited: false
  hidden: false
  id: 65030abeb1792803da8293ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/65aa490dce4000dddd743ebbb763bb62.svg
      fullname: Frank Zhao
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: fangloveskari
      type: user
    createdAt: '2023-09-19T07:21:32.000Z'
    data:
      edited: false
      editors:
      - fangloveskari
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9332150220870972
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/65aa490dce4000dddd743ebbb763bb62.svg
          fullname: Frank Zhao
          isHf: false
          isPro: false
          name: fangloveskari
          type: user
        html: '<p>Sorry for late reply, a little busy recently.<br>Here is the thing,
          I will explain for your.<br>First of all, as LoRA is an add-up weights for
          base model, it can be merged to any model with the same architecture. (which
          is more commonly used for text-toimage application like stable-diffusion).</p>

          <p>Secondly,  this model was truly finetuned based on  LLaMA-2-70B, but
          merged with upstage/llama2-70b-instruct-v2. it''s a deploy strategy introduced
          by some other models. If this mislead something and you think relates to
          some ethical issue, we are really sorry for that, and we will explained
          why these strategy taked.</p>

          <p>Thirdly, you could try directly finetuned on upstage/llama2-70b-instruct-v2
          with the mentioned data, scores for the four metric are expected to decrease(I
          experiment for several times), means it may already biased for the base
          model and adding up more data will exacerbate the baises. </p>

          <p>Fourth, actually we did some other works after this model(mixed up with
          more data, evaluate on other benchmark), we found that:1) more data add-up
          finetuning will not bring a huge increase(metamorphosis) for the metric
          (our best finetuned model get ~75.5 average metric on local evaluation and
          never increase any more with more data) and more importantly 2) the evaluation
          scores for humaneval and GSM8k (and others) witness a considerable decrease
          compared to the original LLaMa2-70b. We notice that the finetuned model
          is more-or-less metric-oriented biased, so turn our strategy to large-scale
          dataset mix-up processing and full-parameter pretrainining.</p>

          '
        raw: "Sorry for late reply, a little busy recently.\nHere is the thing, I\
          \ will explain for your.\nFirst of all, as LoRA is an add-up weights for\
          \ base model, it can be merged to any model with the same architecture.\
          \ (which is more commonly used for text-toimage application like stable-diffusion).\n\
          \nSecondly,  this model was truly finetuned based on  LLaMA-2-70B, but merged\
          \ with upstage/llama2-70b-instruct-v2. it's a deploy strategy introduced\
          \ by some other models. If this mislead something and you think relates\
          \ to some ethical issue, we are really sorry for that, and we will explained\
          \ why these strategy taked.\n\nThirdly, you could try directly finetuned\
          \ on upstage/llama2-70b-instruct-v2 with the mentioned data, scores for\
          \ the four metric are expected to decrease(I experiment for several times),\
          \ means it may already biased for the base model and adding up more data\
          \ will exacerbate the baises. \n\nFourth, actually we did some other works\
          \ after this model(mixed up with more data, evaluate on other benchmark),\
          \ we found that:1) more data add-up finetuning will not bring a huge increase(metamorphosis)\
          \ for the metric (our best finetuned model get ~75.5 average metric on local\
          \ evaluation and never increase any more with more data) and more importantly\
          \ 2) the evaluation scores for humaneval and GSM8k (and others) witness\
          \ a considerable decrease compared to the original LLaMa2-70b. We notice\
          \ that the finetuned model is more-or-less metric-oriented biased, so turn\
          \ our strategy to large-scale dataset mix-up processing and full-parameter\
          \ pretrainining.\n"
        updatedAt: '2023-09-19T07:21:32.696Z'
      numEdits: 0
      reactions: []
    id: 65094bfc2c804aed59cba743
    type: comment
  author: fangloveskari
  content: "Sorry for late reply, a little busy recently.\nHere is the thing, I will\
    \ explain for your.\nFirst of all, as LoRA is an add-up weights for base model,\
    \ it can be merged to any model with the same architecture. (which is more commonly\
    \ used for text-toimage application like stable-diffusion).\n\nSecondly,  this\
    \ model was truly finetuned based on  LLaMA-2-70B, but merged with upstage/llama2-70b-instruct-v2.\
    \ it's a deploy strategy introduced by some other models. If this mislead something\
    \ and you think relates to some ethical issue, we are really sorry for that, and\
    \ we will explained why these strategy taked.\n\nThirdly, you could try directly\
    \ finetuned on upstage/llama2-70b-instruct-v2 with the mentioned data, scores\
    \ for the four metric are expected to decrease(I experiment for several times),\
    \ means it may already biased for the base model and adding up more data will\
    \ exacerbate the baises. \n\nFourth, actually we did some other works after this\
    \ model(mixed up with more data, evaluate on other benchmark), we found that:1)\
    \ more data add-up finetuning will not bring a huge increase(metamorphosis) for\
    \ the metric (our best finetuned model get ~75.5 average metric on local evaluation\
    \ and never increase any more with more data) and more importantly 2) the evaluation\
    \ scores for humaneval and GSM8k (and others) witness a considerable decrease\
    \ compared to the original LLaMa2-70b. We notice that the finetuned model is more-or-less\
    \ metric-oriented biased, so turn our strategy to large-scale dataset mix-up processing\
    \ and full-parameter pretrainining.\n"
  created_at: 2023-09-19 06:21:32+00:00
  edited: false
  hidden: false
  id: 65094bfc2c804aed59cba743
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 11
repo_id: fangloveskari/ORCA_LLaMA_70B_QLoRA
repo_type: model
status: open
target_branch: null
title: "\U0001F6A9 Report: Ethical issue(s)"
