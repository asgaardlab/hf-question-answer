!!python/object:huggingface_hub.community.DiscussionWithDetails
author: patrickvonplaten
conflicting_files: []
created_at: 2022-05-25 19:30:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2022-05-25T20:30:10.000Z'
    data:
      edited: false
      editors:
      - patrickvonplaten
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
          fullname: Patrick von Platen
          isHf: true
          isPro: false
          name: patrickvonplaten
          type: user
        html: '<p>This is important to prevent a nasty bug at the moment. Without
          this fix one could load the wrong tokenizer (fast gpt2) when doing tokenizer
          = AutoTokenizer.from_pretrained(''your/model/id''). Currently fast gpt2
          doesn''t work correctly with OPT and one should only use the slow one see:
          <a href="https://huggingface.co/facebook/opt-6.7b#how-to-use">https://huggingface.co/facebook/opt-6.7b#how-to-use</a></p>

          '
        raw: 'This is important to prevent a nasty bug at the moment. Without this
          fix one could load the wrong tokenizer (fast gpt2) when doing tokenizer
          = AutoTokenizer.from_pretrained(''your/model/id''). Currently fast gpt2
          doesn''t work correctly with OPT and one should only use the slow one see:
          https://huggingface.co/facebook/opt-6.7b#how-to-use'
        updatedAt: '2022-05-25T20:30:10.000Z'
      numEdits: 0
      reactions: []
    id: 628e91d2a9a3c754c1f90489
    type: comment
  author: patrickvonplaten
  content: 'This is important to prevent a nasty bug at the moment. Without this fix
    one could load the wrong tokenizer (fast gpt2) when doing tokenizer = AutoTokenizer.from_pretrained(''your/model/id'').
    Currently fast gpt2 doesn''t work correctly with OPT and one should only use the
    slow one see: https://huggingface.co/facebook/opt-6.7b#how-to-use'
  created_at: 2022-05-25 19:30:10+00:00
  edited: false
  hidden: false
  id: 628e91d2a9a3c754c1f90489
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2022-05-25T20:30:11.000Z'
    data:
      oid: f44b4e9c034225245718ca0c0c7137884f7a2032
      parents:
      - 94faa3cafdbc3d6a968b8f2e91b28e3319cfc79f
      subject: Update tokenizer_config.json
    id: 628e91d30000000000000000
    type: commit
  author: patrickvonplaten
  created_at: 2022-05-25 19:30:11+00:00
  id: 628e91d30000000000000000
  oid: f44b4e9c034225245718ca0c0c7137884f7a2032
  summary: Update tokenizer_config.json
  type: commit
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
      fullname: Peter Szemraj
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: pszemraj
      type: user
    createdAt: '2022-05-25T21:27:25.000Z'
    data:
      status: merged
    id: 628e9f3da9a3c754c1f9512b
    type: status-change
  author: pszemraj
  created_at: 2022-05-25 20:27:25+00:00
  id: 628e9f3da9a3c754c1f9512b
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 1584efaa61f10284a2bcb4c0ad145fc3dac1e1ba
num: 1
repo_id: pszemraj/opt-peter-2.7B
repo_type: model
status: merged
target_branch: refs/heads/main
title: Update tokenizer_config.json
