!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kusoge
conflicting_files: null
created_at: 2023-06-27 18:53:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bf0eaf89fa1ea6ad1a350d41a82f03af.svg
      fullname: Shin Asura
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kusoge
      type: user
    createdAt: '2023-06-27T19:53:11.000Z'
    data:
      edited: false
      editors:
      - kusoge
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9638118147850037
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bf0eaf89fa1ea6ad1a350d41a82f03af.svg
          fullname: Shin Asura
          isHf: false
          isPro: false
          name: kusoge
          type: user
        html: '<p>So, immediately after Ooba''s update dropped I tried to use the
          old Nous-Hermes-13B-GPTQ model and managed to get to 4096 context sizes
          without getting OOM''ed from loading it and using it, this was tested with
          3060 12GB VRAM.</p>

          <p>One thing I did notice from the non-superHOT was that after reaching
          a large enough context size, around 3200~ context,(FYI, max_new_token was
          set to 800), the model tends to repeats the previous responses specially
          if you try to reference any elements in its context memory or what the user
          and AI has said.</p>

          <p>context:<br>User: Create a story about a character named Chad.<br>AI:
          Chad is a good boy (...) and he do good things.</p>

          <p>Once context reaches 3000+, when you try to prompt the model with the
          same pattern from before or mentioning a specific character in its context,
          it tends to repeat the response it already gave. </p>

          <p>User: Can you tell me about Sam?<br>AI: Sam is a good boy (...) and he
          do good things. (Repeated a response it already given but changing the subject)
          </p>

          <p>or </p>

          <p>User: Continue the story about Chad becoming bad.<br>AI: Chad is a good
          boy (...) and he do good things. (Completely repeated the response it already
          gave) </p>

          <p>However, I do have to admit that with the update it actually does remember
          what''s in its 3000+ context. Specially if you try to break out of the pattern
          of your prompts. </p>

          <p>User: Summarize the story of Chad.<br>AI: Chad is a good boy and he met
          Sam and he became a bad boy.</p>

          <p>I wonder how does the SuperHOT version differs. I will update this post
          later after I finished downloading this SuperHOT version and find time to
          test it.</p>

          '
        raw: "So, immediately after Ooba's update dropped I tried to use the old Nous-Hermes-13B-GPTQ\
          \ model and managed to get to 4096 context sizes without getting OOM'ed\
          \ from loading it and using it, this was tested with 3060 12GB VRAM.\r\n\
          \r\nOne thing I did notice from the non-superHOT was that after reaching\
          \ a large enough context size, around 3200~ context,(FYI, max_new_token\
          \ was set to 800), the model tends to repeats the previous responses specially\
          \ if you try to reference any elements in its context memory or what the\
          \ user and AI has said.\r\n\r\ncontext:\r\nUser: Create a story about a\
          \ character named Chad. \r\nAI: Chad is a good boy (...) and he do good\
          \ things.\r\n\r\nOnce context reaches 3000+, when you try to prompt the\
          \ model with the same pattern from before or mentioning a specific character\
          \ in its context, it tends to repeat the response it already gave. \r\n\r\
          \nUser: Can you tell me about Sam?\r\nAI: Sam is a good boy (...) and he\
          \ do good things. (Repeated a response it already given but changing the\
          \ subject) \r\n\r\nor \r\n\r\nUser: Continue the story about Chad becoming\
          \ bad.\r\nAI: Chad is a good boy (...) and he do good things. (Completely\
          \ repeated the response it already gave) \r\n\r\nHowever, I do have to admit\
          \ that with the update it actually does remember what's in its 3000+ context.\
          \ Specially if you try to break out of the pattern of your prompts. \r\n\
          \r\nUser: Summarize the story of Chad.\r\nAI: Chad is a good boy and he\
          \ met Sam and he became a bad boy.\r\n\r\nI wonder how does the SuperHOT\
          \ version differs. I will update this post later after I finished downloading\
          \ this SuperHOT version and find time to test it.\r\n"
        updatedAt: '2023-06-27T19:53:11.793Z'
      numEdits: 0
      reactions: []
    id: 649b3e2797793c1ad0962f5e
    type: comment
  author: kusoge
  content: "So, immediately after Ooba's update dropped I tried to use the old Nous-Hermes-13B-GPTQ\
    \ model and managed to get to 4096 context sizes without getting OOM'ed from loading\
    \ it and using it, this was tested with 3060 12GB VRAM.\r\n\r\nOne thing I did\
    \ notice from the non-superHOT was that after reaching a large enough context\
    \ size, around 3200~ context,(FYI, max_new_token was set to 800), the model tends\
    \ to repeats the previous responses specially if you try to reference any elements\
    \ in its context memory or what the user and AI has said.\r\n\r\ncontext:\r\n\
    User: Create a story about a character named Chad. \r\nAI: Chad is a good boy\
    \ (...) and he do good things.\r\n\r\nOnce context reaches 3000+, when you try\
    \ to prompt the model with the same pattern from before or mentioning a specific\
    \ character in its context, it tends to repeat the response it already gave. \r\
    \n\r\nUser: Can you tell me about Sam?\r\nAI: Sam is a good boy (...) and he do\
    \ good things. (Repeated a response it already given but changing the subject)\
    \ \r\n\r\nor \r\n\r\nUser: Continue the story about Chad becoming bad.\r\nAI:\
    \ Chad is a good boy (...) and he do good things. (Completely repeated the response\
    \ it already gave) \r\n\r\nHowever, I do have to admit that with the update it\
    \ actually does remember what's in its 3000+ context. Specially if you try to\
    \ break out of the pattern of your prompts. \r\n\r\nUser: Summarize the story\
    \ of Chad.\r\nAI: Chad is a good boy and he met Sam and he became a bad boy.\r\
    \n\r\nI wonder how does the SuperHOT version differs. I will update this post\
    \ later after I finished downloading this SuperHOT version and find time to test\
    \ it.\r\n"
  created_at: 2023-06-27 18:53:11+00:00
  edited: false
  hidden: false
  id: 649b3e2797793c1ad0962f5e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/bf0eaf89fa1ea6ad1a350d41a82f03af.svg
      fullname: Shin Asura
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kusoge
      type: user
    createdAt: '2023-06-27T19:53:28.000Z'
    data:
      from: Difference between this non 8K context
      to: Difference between this and the non 8K context
    id: 649b3e38962c03f6167536e2
    type: title-change
  author: kusoge
  created_at: 2023-06-27 18:53:28+00:00
  id: 649b3e38962c03f6167536e2
  new_title: Difference between this and the non 8K context
  old_title: Difference between this non 8K context
  type: title-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Nous-Hermes-13B-SuperHOT-8K-GPTQ
repo_type: model
status: open
target_branch: null
title: Difference between this and the non 8K context
