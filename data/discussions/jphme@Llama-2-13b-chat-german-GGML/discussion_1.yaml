!!python/object:huggingface_hub.community.DiscussionWithDetails
author: fathyshalaby
conflicting_files: null
created_at: 2023-08-02 10:49:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1637512102357-noauth.jpeg?w=200&h=200&f=face
      fullname: Fathy Shalaby
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fathyshalaby
      type: user
    createdAt: '2023-08-02T11:49:17.000Z'
    data:
      edited: false
      editors:
      - fathyshalaby
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9640389680862427
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1637512102357-noauth.jpeg?w=200&h=200&f=face
          fullname: Fathy Shalaby
          isHf: false
          isPro: false
          name: fathyshalaby
          type: user
        html: '<p>I would like to request a quant 8 version of this model if possible,
          thanks in advance.</p>

          '
        raw: I would like to request a quant 8 version of this model if possible,
          thanks in advance.
        updatedAt: '2023-08-02T11:49:17.303Z'
      numEdits: 0
      reactions: []
    id: 64ca42bd9e30a46f7b64e4f1
    type: comment
  author: fathyshalaby
  content: I would like to request a quant 8 version of this model if possible, thanks
    in advance.
  created_at: 2023-08-02 10:49:17+00:00
  edited: false
  hidden: false
  id: 64ca42bd9e30a46f7b64e4f1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1gCpz_Og6-LyCBXDmuOd1.jpeg?w=200&h=200&f=face
      fullname: Jan Philipp Harries
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: jphme
      type: user
    createdAt: '2023-08-03T19:02:13.000Z'
    data:
      edited: false
      editors:
      - jphme
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9506012201309204
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1gCpz_Og6-LyCBXDmuOd1.jpeg?w=200&h=200&f=face
          fullname: Jan Philipp Harries
          isHf: false
          isPro: false
          name: jphme
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;fathyshalaby&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/fathyshalaby\"\
          >@<span class=\"underline\">fathyshalaby</span></a></span>\n\n\t</span></span>,\
          \ I plan to release a better llama2-based German model in the coming days\
          \ and will release this with more quantized versions. As of know I only\
          \ run finetunes peridodically and need access to a beefy instance for quantization,\
          \ so I will try to provide q-8 for this but could take a few days...</p>\n\
          <p>In the meantime I would be interested in feedback or usecases for the\
          \ model!</p>\n"
        raw: 'Hi @fathyshalaby, I plan to release a better llama2-based German model
          in the coming days and will release this with more quantized versions. As
          of know I only run finetunes peridodically and need access to a beefy instance
          for quantization, so I will try to provide q-8 for this but could take a
          few days...


          In the meantime I would be interested in feedback or usecases for the model!'
        updatedAt: '2023-08-03T19:02:13.672Z'
      numEdits: 0
      reactions: []
    id: 64cbf9b5a257a3212c08eb89
    type: comment
  author: jphme
  content: 'Hi @fathyshalaby, I plan to release a better llama2-based German model
    in the coming days and will release this with more quantized versions. As of know
    I only run finetunes peridodically and need access to a beefy instance for quantization,
    so I will try to provide q-8 for this but could take a few days...


    In the meantime I would be interested in feedback or usecases for the model!'
  created_at: 2023-08-03 18:02:13+00:00
  edited: false
  hidden: false
  id: 64cbf9b5a257a3212c08eb89
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: jphme/Llama-2-13b-chat-german-GGML
repo_type: model
status: open
target_branch: null
title: 'REQUEST: Quant 8 request'
