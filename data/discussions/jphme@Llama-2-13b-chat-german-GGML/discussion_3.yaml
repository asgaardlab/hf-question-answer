!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ahmadhatahet
conflicting_files: null
created_at: 2023-09-11 12:36:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/858c7f717d9a2a92adf298a5214588b3.svg
      fullname: Ahmad Hatahet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ahmadhatahet
      type: user
    createdAt: '2023-09-11T13:36:04.000Z'
    data:
      edited: true
      editors:
      - ahmadhatahet
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6118853688240051
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/858c7f717d9a2a92adf298a5214588b3.svg
          fullname: Ahmad Hatahet
          isHf: false
          isPro: false
          name: ahmadhatahet
          type: user
        html: "<p>Hi jphme,</p>\n<p>Thank you for fine tuning this model.<br>I am\
          \ trying to load it using </p>\n<pre><code>import torch\nfrom transformers\
          \ import pipeline, AutoTokenizer, AutoModelForCausalLM\nfrom langchain.llms\
          \ import HuggingFacePipeline\n\nllm_model_name = \"jphme/Llama-2-13b-chat-german-GGML\"\
          \n\ntokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n\nllm = AutoModelForCausalLM.from_pretrained(\n\
          \        llm_model_name,\n        device_map=\"auto\",\n        torch_dtype=torch.bfloat16,\n\
          \        load_in_4bit=True,\n        bnb_4bit_quant_type='q4_0',\n     \
          \   bnb_4bit_compute_dtype=torch.bfloat16,\n        cache_folder=str(cache_folder),\n\
          \        trust_remote_code=True)\n</code></pre>\n<p>And I get the following\
          \ error message: \"Llama-2-13b-chat-german-GGML does not appear to have\
          \ a file named config.json.\"<br>I read because the weights are not converted\
          \ to hugging face weights.<br>I obtained the license from Meta, however,\
          \ I don't know what to do with it.</p>\n"
        raw: "Hi jphme,\n\nThank you for fine tuning this model.\nI am trying to load\
          \ it using \n\n```\nimport torch\nfrom transformers import pipeline, AutoTokenizer,\
          \ AutoModelForCausalLM\nfrom langchain.llms import HuggingFacePipeline\n\
          \nllm_model_name = \"jphme/Llama-2-13b-chat-german-GGML\"\n\ntokenizer =\
          \ AutoTokenizer.from_pretrained(llm_model_name)\n\nllm = AutoModelForCausalLM.from_pretrained(\n\
          \        llm_model_name,\n        device_map=\"auto\",\n        torch_dtype=torch.bfloat16,\n\
          \        load_in_4bit=True,\n        bnb_4bit_quant_type='q4_0',\n     \
          \   bnb_4bit_compute_dtype=torch.bfloat16,\n        cache_folder=str(cache_folder),\n\
          \        trust_remote_code=True)\n```\n\nAnd I get the following error message:\
          \ \"Llama-2-13b-chat-german-GGML does not appear to have a file named config.json.\"\
          \nI read because the weights are not converted to hugging face weights.\n\
          I obtained the license from Meta, however, I don't know what to do with\
          \ it."
        updatedAt: '2023-09-11T13:36:52.221Z'
      numEdits: 1
      reactions: []
    id: 64ff17c424c36fb66c3c56f5
    type: comment
  author: ahmadhatahet
  content: "Hi jphme,\n\nThank you for fine tuning this model.\nI am trying to load\
    \ it using \n\n```\nimport torch\nfrom transformers import pipeline, AutoTokenizer,\
    \ AutoModelForCausalLM\nfrom langchain.llms import HuggingFacePipeline\n\nllm_model_name\
    \ = \"jphme/Llama-2-13b-chat-german-GGML\"\n\ntokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n\
    \nllm = AutoModelForCausalLM.from_pretrained(\n        llm_model_name,\n     \
    \   device_map=\"auto\",\n        torch_dtype=torch.bfloat16,\n        load_in_4bit=True,\n\
    \        bnb_4bit_quant_type='q4_0',\n        bnb_4bit_compute_dtype=torch.bfloat16,\n\
    \        cache_folder=str(cache_folder),\n        trust_remote_code=True)\n```\n\
    \nAnd I get the following error message: \"Llama-2-13b-chat-german-GGML does not\
    \ appear to have a file named config.json.\"\nI read because the weights are not\
    \ converted to hugging face weights.\nI obtained the license from Meta, however,\
    \ I don't know what to do with it."
  created_at: 2023-09-11 12:36:04+00:00
  edited: true
  hidden: false
  id: 64ff17c424c36fb66c3c56f5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1gCpz_Og6-LyCBXDmuOd1.jpeg?w=200&h=200&f=face
      fullname: Jan Philipp Harries
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: jphme
      type: user
    createdAt: '2023-09-13T11:24:46.000Z'
    data:
      edited: false
      editors:
      - jphme
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6969533562660217
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1gCpz_Og6-LyCBXDmuOd1.jpeg?w=200&h=200&f=face
          fullname: Jan Philipp Harries
          isHf: false
          isPro: false
          name: jphme
          type: user
        html: '<p>Hi, for use with transformers, please use the standard model (without
          GGML) here: <a href="https://huggingface.co/jphme/Llama-2-13b-chat-german">https://huggingface.co/jphme/Llama-2-13b-chat-german</a></p>

          '
        raw: 'Hi, for use with transformers, please use the standard model (without
          GGML) here: https://huggingface.co/jphme/Llama-2-13b-chat-german'
        updatedAt: '2023-09-13T11:24:46.883Z'
      numEdits: 0
      reactions: []
    id: 65019bfe579f6d070e407792
    type: comment
  author: jphme
  content: 'Hi, for use with transformers, please use the standard model (without
    GGML) here: https://huggingface.co/jphme/Llama-2-13b-chat-german'
  created_at: 2023-09-13 10:24:46+00:00
  edited: false
  hidden: false
  id: 65019bfe579f6d070e407792
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/858c7f717d9a2a92adf298a5214588b3.svg
      fullname: Ahmad Hatahet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ahmadhatahet
      type: user
    createdAt: '2023-09-14T06:18:14.000Z'
    data:
      edited: false
      editors:
      - ahmadhatahet
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5413934588432312
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/858c7f717d9a2a92adf298a5214588b3.svg
          fullname: Ahmad Hatahet
          isHf: false
          isPro: false
          name: ahmadhatahet
          type: user
        html: "<p>Thank you \U0001F44D</p>\n"
        raw: "Thank you \U0001F44D"
        updatedAt: '2023-09-14T06:18:14.021Z'
      numEdits: 0
      reactions: []
    id: 6502a5a6b1792803da70cd33
    type: comment
  author: ahmadhatahet
  content: "Thank you \U0001F44D"
  created_at: 2023-09-14 05:18:14+00:00
  edited: false
  hidden: false
  id: 6502a5a6b1792803da70cd33
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: jphme/Llama-2-13b-chat-german-GGML
repo_type: model
status: open
target_branch: null
title: I get an error message "config.json" is missing
