!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Chelcie
conflicting_files: null
created_at: 2023-07-30 12:10:39+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2e094005ba59fa0bee7ee8114af96ba7.svg
      fullname: De Almeida
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Chelcie
      type: user
    createdAt: '2023-07-30T13:10:39.000Z'
    data:
      edited: false
      editors:
      - Chelcie
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8014971613883972
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2e094005ba59fa0bee7ee8114af96ba7.svg
          fullname: De Almeida
          isHf: false
          isPro: false
          name: Chelcie
          type: user
        html: "<p>I have a table called employees from adventureworks that I pulled\
          \ from postgres.</p>\n<h1 id=\"creating-employee-df-from-postgres-employee-table\"\
          >creating employee df from postgres employee table</h1>\n<pre><code>with\
          \ engine.begin() as conn:\n    query = text(\"\"\"SELECT businessentityid,jobtitle\
          \ FROM humanresources.employee\"\"\")\n    employee = pd.read_sql_query(query,\
          \ conn)\nemployee\n</code></pre>\n<p>I then run the following:</p>\n<pre><code>query\
          \ = \"how many rows does the employee table have?\"\nencoding = tokenizer(table=employee,\
          \ query=query, return_tensors=\"pt\")\n\noutputs = model.generate(**encoding)\n\
          \nprint(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n</code></pre>\n\
          <p>and get the following warning/errors:</p>\n<pre><code>Token indices sequence\
          \ length is longer than the specified maximum sequence length for this model\
          \ (2813 &gt; 1024). Running this sequence through the model will result\
          \ in indexing errors\n</code></pre>\n<pre><code>IndexError: index out of\
          \ range in self\n</code></pre>\n"
        raw: "I have a table called employees from adventureworks that I pulled from\
          \ postgres.\r\n\r\n# creating employee df from postgres employee table\r\
          \n\r\n```\r\nwith engine.begin() as conn:\r\n    query = text(\"\"\"SELECT\
          \ businessentityid,jobtitle FROM humanresources.employee\"\"\")\r\n    employee\
          \ = pd.read_sql_query(query, conn)\r\nemployee\r\n\r\n```\r\n\r\nI then\
          \ run the following:\r\n\r\n```\r\nquery = \"how many rows does the employee\
          \ table have?\"\r\nencoding = tokenizer(table=employee, query=query, return_tensors=\"\
          pt\")\r\n\r\noutputs = model.generate(**encoding)\r\n\r\nprint(tokenizer.batch_decode(outputs,\
          \ skip_special_tokens=True))\r\n\r\n```\r\n\r\nand get the following warning/errors:\r\
          \n```\r\nToken indices sequence length is longer than the specified maximum\
          \ sequence length for this model (2813 > 1024). Running this sequence through\
          \ the model will result in indexing errors\r\n```\r\n\r\n```\r\nIndexError:\
          \ index out of range in self\r\n```"
        updatedAt: '2023-07-30T13:10:39.501Z'
      numEdits: 0
      reactions: []
    id: 64c6614fed521f27a425665e
    type: comment
  author: Chelcie
  content: "I have a table called employees from adventureworks that I pulled from\
    \ postgres.\r\n\r\n# creating employee df from postgres employee table\r\n\r\n\
    ```\r\nwith engine.begin() as conn:\r\n    query = text(\"\"\"SELECT businessentityid,jobtitle\
    \ FROM humanresources.employee\"\"\")\r\n    employee = pd.read_sql_query(query,\
    \ conn)\r\nemployee\r\n\r\n```\r\n\r\nI then run the following:\r\n\r\n```\r\n\
    query = \"how many rows does the employee table have?\"\r\nencoding = tokenizer(table=employee,\
    \ query=query, return_tensors=\"pt\")\r\n\r\noutputs = model.generate(**encoding)\r\
    \n\r\nprint(tokenizer.batch_decode(outputs, skip_special_tokens=True))\r\n\r\n\
    ```\r\n\r\nand get the following warning/errors:\r\n```\r\nToken indices sequence\
    \ length is longer than the specified maximum sequence length for this model (2813\
    \ > 1024). Running this sequence through the model will result in indexing errors\r\
    \n```\r\n\r\n```\r\nIndexError: index out of range in self\r\n```"
  created_at: 2023-07-30 12:10:39+00:00
  edited: false
  hidden: false
  id: 64c6614fed521f27a425665e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
      fullname: Qian Liu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: SivilTaram
      type: user
    createdAt: '2023-08-17T01:55:04.000Z'
    data:
      edited: false
      editors:
      - SivilTaram
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.80974942445755
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
          fullname: Qian Liu
          isHf: false
          isPro: false
          name: SivilTaram
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Chelcie&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Chelcie\">@<span class=\"\
          underline\">Chelcie</span></a></span>\n\n\t</span></span> Hello, thanks\
          \ for your interest on our work! I think the problem should be that the\
          \ table is larger than the maximum positions of TAPEX. You may use the default\
          \ truncation strategy defined in tapex as:</p>\n<pre><code>            encoding\
          \ = tokenizer(\n                table=employee,\n                query=\
          \ query,\n                max_length=1024,\n                truncation=True,\n\
          \            )\n</code></pre>\n<p>And try again!</p>\n"
        raw: "@Chelcie Hello, thanks for your interest on our work! I think the problem\
          \ should be that the table is larger than the maximum positions of TAPEX.\
          \ You may use the default truncation strategy defined in tapex as:\n\n```\n\
          \            encoding = tokenizer(\n                table=employee,\n  \
          \              query= query,\n                max_length=1024,\n       \
          \         truncation=True,\n            )\n```\n\nAnd try again!"
        updatedAt: '2023-08-17T01:55:04.975Z'
      numEdits: 0
      reactions: []
    id: 64dd7df883645d0f9850da49
    type: comment
  author: SivilTaram
  content: "@Chelcie Hello, thanks for your interest on our work! I think the problem\
    \ should be that the table is larger than the maximum positions of TAPEX. You\
    \ may use the default truncation strategy defined in tapex as:\n\n```\n      \
    \      encoding = tokenizer(\n                table=employee,\n              \
    \  query= query,\n                max_length=1024,\n                truncation=True,\n\
    \            )\n```\n\nAnd try again!"
  created_at: 2023-08-17 00:55:04+00:00
  edited: false
  hidden: false
  id: 64dd7df883645d0f9850da49
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
      fullname: Qian Liu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: SivilTaram
      type: user
    createdAt: '2024-01-12T11:25:55.000Z'
    data:
      status: closed
    id: 65a121c333d5d9ca300df3d8
    type: status-change
  author: SivilTaram
  created_at: 2024-01-12 11:25:55+00:00
  id: 65a121c333d5d9ca300df3d8
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: microsoft/tapex-large-finetuned-wtq
repo_type: model
status: closed
target_branch: null
title: How can this model be used on tables that I have stored in Postgres
