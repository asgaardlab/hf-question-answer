!!python/object:huggingface_hub.community.DiscussionWithDetails
author: interstellarninja
conflicting_files: null
created_at: 2024-01-23 17:23:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6446be9a15a27291ef8bea10/9_gywXgzL9Jk3MYLdX9RG.jpeg?w=200&h=200&f=face
      fullname: interstellarninja
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: interstellarninja
      type: user
    createdAt: '2024-01-23T17:23:56.000Z'
    data:
      edited: false
      editors:
      - interstellarninja
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3671070635318756
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6446be9a15a27291ef8bea10/9_gywXgzL9Jk3MYLdX9RG.jpeg?w=200&h=200&f=face
          fullname: interstellarninja
          isHf: false
          isPro: false
          name: interstellarninja
          type: user
        html: '<p>I''m getting a runtime error while attempting to finetune with axolotl
          with <code>flash_attention: true</code> in the config.</p>

          <p>here''s the full stack trace:</p>

          <p><code>[2024-01-23 12:20:53,440] [INFO] [axolotl.callbacks.on_train_begin:572]
          [PID:9523] [RANK:0] The Axolotl config has been saved to the WandB run under
          files.   0%|                                                                                      |
          0/2418 [00:00&lt;?, ?it/s][2024-01-23 12:20:53,446] [INFO] [axolotl.utils.samplers.multipack._len_est:178]
          [PID:9523] [RANK:0] packing_efficiency_estimate: 0.77 total_num_tokens per
          device: 5142267 Traceback (most recent call last):   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/runpy.py",
          line 196, in _run_module_as_main     return _run_code(code, main_globals,
          None,   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/runpy.py",
          line 86, in _run_code     exec(code, run_globals)   File "/home/interstellarninja/ai_projects/axolotl/src/axolotl/cli/train.py",
          line 43, in &lt;module&gt;     fire.Fire(do_cli)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py",
          line 141, in Fire     component_trace = _Fire(component, args, parsed_flag_args,
          context, name)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py",
          line 475, in _Fire     component, remaining_args = _CallAndUpdateTrace(   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py",
          line 691, in _CallAndUpdateTrace     component = fn(*varargs, **kwargs)   File
          "/home/interstellarninja/ai_projects/axolotl/src/axolotl/cli/train.py",
          line 39, in do_cli     train(cfg=parsed_cfg, cli_args=parsed_cli_args, dataset_meta=dataset_meta)   File
          "/home/interstellarninja/ai_projects/axolotl/src/axolotl/train.py", line
          149, in train     trainer.train(resume_from_checkpoint=resume_from_checkpoint)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py",
          line 1534, in train     return inner_training_loop(   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py",
          line 1860, in _inner_training_loop     tr_loss_step = self.training_step(model,
          inputs)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py",
          line 2737, in training_step     loss = self.compute_loss(model, inputs)   File
          "/home/interstellarninja/ai_projects/axolotl/src/axolotl/core/trainer_builder.py",
          line 329, in compute_loss     return super().compute_loss(model, inputs,
          return_outputs=return_outputs)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py",
          line 2760, in compute_loss     outputs = model(**inputs)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl     return forward_call(*args, **kwargs)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/utils/operations.py",
          line 687, in forward     return model_forward(*args, **kwargs)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/utils/operations.py",
          line 675, in __call__     return convert_to_fp32(self.model_forward(*args,
          **kwargs))   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/amp/autocast_mode.py",
          line 14, in decorate_autocast     return func(*args, **kwargs)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/peft/peft_model.py",
          line 1071, in forward     return self.base_model(   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl     return forward_call(*args, **kwargs)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/peft/tuners/tuners_utils.py",
          line 108, in forward     return self.model.forward(*args, **kwargs)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py",
          line 165, in new_forward     output = module._old_forward(*args, **kwargs)   File
          "/home/interstellarninja/.cache/huggingface/modules/transformers_modules/stabilityai/stablelm-2-zephyr-1_6b/589adbfdd913d96282d43411c87a996f1bc7b000/modeling_stablelm_epoch.py",
          line 818, in forward     outputs = self.model(   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl     return forward_call(*args, **kwargs)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py",
          line 165, in new_forward     output = module._old_forward(*args, **kwargs)   File
          "/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py",
          line 366, in stablelm_model_forward     layer_outputs = torch.utils.checkpoint.checkpoint(   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/utils/checkpoint.py",
          line 249, in checkpoint     return CheckpointFunction.apply(function, preserve,
          *args)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/autograd/function.py",
          line 506, in apply     return super().apply(*args, **kwargs)  # type: ignore[misc]   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/utils/checkpoint.py",
          line 107, in forward     outputs = run_function(*args)   File "/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py",
          line 362, in custom_forward     return module(*inputs)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl     return forward_call(*args, **kwargs)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py",
          line 165, in new_forward     output = module._old_forward(*args, **kwargs)   File
          "/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py",
          line 224, in decoder_layer_forward     hidden_states, self_attn_weights,
          present_key_value = self.self_attn(   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl     return forward_call(*args, **kwargs)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py",
          line 165, in new_forward     output = module._old_forward(*args, **kwargs)   File
          "/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py",
          line 159, in flashattn_attn     output = flash_attn_varlen_qkvpacked_func(   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py",
          line 887, in flash_attn_varlen_qkvpacked_func     return FlashAttnVarlenQKVPackedFunc.apply(   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/autograd/function.py",
          line 506, in apply     return super().apply(*args, **kwargs)  # type: ignore[misc]   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py",
          line 288, in forward     out, q, k, v, out_padded, softmax_lse, S_dmask,
          rng_state = _flash_attn_varlen_forward(   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py",
          line 85, in _flash_attn_varlen_forward     out, q, k, v, out_padded, softmax_lse,
          S_dmask, rng_state = flash_attn_cuda.varlen_fwd( RuntimeError: FlashAttention
          only support fp16 and bf16 data type Traceback (most recent call last):   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/runpy.py",
          line 196, in _run_module_as_main     return _run_code(code, main_globals,
          None,   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/runpy.py",
          line 86, in _run_code     exec(code, run_globals)   File "/home/interstellarninja/ai_projects/axolotl/src/axolotl/cli/train.py",
          line 43, in &lt;module&gt;     fire.Fire(do_cli)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py",
          line 141, in Fire     component_trace = _Fire(component, args, parsed_flag_args,
          context, name)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py",
          line 475, in _Fire     component, remaining_args = _CallAndUpdateTrace(   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py",
          line 691, in _CallAndUpdateTrace     component = fn(*varargs, **kwargs)   File
          "/home/interstellarninja/ai_projects/axolotl/src/axolotl/cli/train.py",
          line 39, in do_cli     train(cfg=parsed_cfg, cli_args=parsed_cli_args, dataset_meta=dataset_meta)   File
          "/home/interstellarninja/ai_projects/axolotl/src/axolotl/train.py", line
          149, in train     trainer.train(resume_from_checkpoint=resume_from_checkpoint)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py",
          line 1534, in train     return inner_training_loop(   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py",
          line 1860, in _inner_training_loop     tr_loss_step = self.training_step(model,
          inputs)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py",
          line 2737, in training_step     loss = self.compute_loss(model, inputs)   File
          "/home/interstellarninja/ai_projects/axolotl/src/axolotl/core/trainer_builder.py",
          line 329, in compute_loss     return super().compute_loss(model, inputs,
          return_outputs=return_outputs)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py",
          line 2760, in compute_loss     outputs = model(**inputs)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl     return forward_call(*args, **kwargs)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/utils/operations.py",
          line 687, in forward     return model_forward(*args, **kwargs)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/utils/operations.py",
          line 675, in __call__     return convert_to_fp32(self.model_forward(*args,
          **kwargs))   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/amp/autocast_mode.py",
          line 14, in decorate_autocast     return func(*args, **kwargs)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/peft/peft_model.py",
          line 1071, in forward     return self.base_model(   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl     return forward_call(*args, **kwargs)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/peft/tuners/tuners_utils.py",
          line 108, in forward     return self.model.forward(*args, **kwargs)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py",
          line 165, in new_forward     output = module._old_forward(*args, **kwargs)   File
          "/home/interstellarninja/.cache/huggingface/modules/transformers_modules/stabilityai/stablelm-2-zephyr-1_6b/589adbfdd913d96282d43411c87a996f1bc7b000/modeling_stablelm_epoch.py",
          line 818, in forward     outputs = self.model(   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl     return forward_call(*args, **kwargs)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py",
          line 165, in new_forward     output = module._old_forward(*args, **kwargs)   File
          "/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py",
          line 366, in stablelm_model_forward     layer_outputs = torch.utils.checkpoint.checkpoint(   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/utils/checkpoint.py",
          line 249, in checkpoint     return CheckpointFunction.apply(function, preserve,
          *args)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/autograd/function.py",
          line 506, in apply     return super().apply(*args, **kwargs)  # type: ignore[misc]   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/utils/checkpoint.py",
          line 107, in forward     outputs = run_function(*args)   File "/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py",
          line 362, in custom_forward     return module(*inputs)   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl     return forward_call(*args, **kwargs)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py",
          line 165, in new_forward     output = module._old_forward(*args, **kwargs)   File
          "/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py",
          line 224, in decoder_layer_forward     hidden_states, self_attn_weights,
          present_key_value = self.self_attn(   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl     return forward_call(*args, **kwargs)   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py",
          line 165, in new_forward     output = module._old_forward(*args, **kwargs)   File
          "/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py",
          line 159, in flashattn_attn     output = flash_attn_varlen_qkvpacked_func(   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py",
          line 887, in flash_attn_varlen_qkvpacked_func     return FlashAttnVarlenQKVPackedFunc.apply(   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/autograd/function.py",
          line 506, in apply     return super().apply(*args, **kwargs)  # type: ignore[misc]   File
          "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py",
          line 288, in forward     out, q, k, v, out_padded, softmax_lse, S_dmask,
          rng_state = _flash_attn_varlen_forward(   File "/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py",
          line 85, in _flash_attn_varlen_forward     out, q, k, v, out_padded, softmax_lse,
          S_dmask, rng_state = flash_attn_cuda.varlen_fwd( RuntimeError: FlashAttention
          only support fp16 and bf16 data type</code></p>

          '
        raw: "I'm getting a runtime error while attempting to finetune with axolotl\
          \ with ```flash_attention: true``` in the config.\r\n\r\nhere's the full\
          \ stack trace:\r\n```[2024-01-23 12:20:53,440] [INFO] [axolotl.callbacks.on_train_begin:572]\
          \ [PID:9523] [RANK:0] The Axolotl config has been saved to the WandB run\
          \ under files.\r\n  0%|                                                \
          \                                      | 0/2418 [00:00<?, ?it/s][2024-01-23\
          \ 12:20:53,446] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:9523]\
          \ [RANK:0] packing_efficiency_estimate: 0.77 total_num_tokens per device:\
          \ 5142267\r\nTraceback (most recent call last):\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/runpy.py\"\
          , line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals,\
          \ None,\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/runpy.py\"\
          , line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/cli/train.py\"\
          , line 43, in <module>\r\n    fire.Fire(do_cli)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py\"\
          , line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args,\
          \ context, name)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py\"\
          , line 475, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py\"\
          , line 691, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\
          \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/cli/train.py\"\
          , line 39, in do_cli\r\n    train(cfg=parsed_cfg, cli_args=parsed_cli_args,\
          \ dataset_meta=dataset_meta)\r\n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/train.py\"\
          , line 149, in train\r\n    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 1534, in train\r\n    return inner_training_loop(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 1860, in _inner_training_loop\r\n    tr_loss_step = self.training_step(model,\
          \ inputs)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 2737, in training_step\r\n    loss = self.compute_loss(model, inputs)\r\
          \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/core/trainer_builder.py\"\
          , line 329, in compute_loss\r\n    return super().compute_loss(model, inputs,\
          \ return_outputs=return_outputs)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 2760, in compute_loss\r\n    outputs = model(**inputs)\r\n  File\
          \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/utils/operations.py\"\
          , line 687, in forward\r\n    return model_forward(*args, **kwargs)\r\n\
          \  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/utils/operations.py\"\
          , line 675, in __call__\r\n    return convert_to_fp32(self.model_forward(*args,\
          \ **kwargs))\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/amp/autocast_mode.py\"\
          , line 14, in decorate_autocast\r\n    return func(*args, **kwargs)\r\n\
          \  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/peft/peft_model.py\"\
          , line 1071, in forward\r\n    return self.base_model(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/peft/tuners/tuners_utils.py\"\
          , line 108, in forward\r\n    return self.model.forward(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/.cache/huggingface/modules/transformers_modules/stabilityai/stablelm-2-zephyr-1_6b/589adbfdd913d96282d43411c87a996f1bc7b000/modeling_stablelm_epoch.py\"\
          , line 818, in forward\r\n    outputs = self.model(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
          , line 366, in stablelm_model_forward\r\n    layer_outputs = torch.utils.checkpoint.checkpoint(\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/utils/checkpoint.py\"\
          , line 249, in checkpoint\r\n    return CheckpointFunction.apply(function,\
          \ preserve, *args)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/autograd/function.py\"\
          , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type:\
          \ ignore[misc]\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/utils/checkpoint.py\"\
          , line 107, in forward\r\n    outputs = run_function(*args)\r\n  File \"\
          /home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
          , line 362, in custom_forward\r\n    return module(*inputs)\r\n  File \"\
          /home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
          , line 224, in decoder_layer_forward\r\n    hidden_states, self_attn_weights,\
          \ present_key_value = self.self_attn(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
          , line 159, in flashattn_attn\r\n    output = flash_attn_varlen_qkvpacked_func(\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py\"\
          , line 887, in flash_attn_varlen_qkvpacked_func\r\n    return FlashAttnVarlenQKVPackedFunc.apply(\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/autograd/function.py\"\
          , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type:\
          \ ignore[misc]\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py\"\
          , line 288, in forward\r\n    out, q, k, v, out_padded, softmax_lse, S_dmask,\
          \ rng_state = _flash_attn_varlen_forward(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py\"\
          , line 85, in _flash_attn_varlen_forward\r\n    out, q, k, v, out_padded,\
          \ softmax_lse, S_dmask, rng_state = flash_attn_cuda.varlen_fwd(\r\nRuntimeError:\
          \ FlashAttention only support fp16 and bf16 data type\r\nTraceback (most\
          \ recent call last):\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/runpy.py\"\
          , line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals,\
          \ None,\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/runpy.py\"\
          , line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/cli/train.py\"\
          , line 43, in <module>\r\n    fire.Fire(do_cli)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py\"\
          , line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args,\
          \ context, name)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py\"\
          , line 475, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py\"\
          , line 691, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\
          \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/cli/train.py\"\
          , line 39, in do_cli\r\n    train(cfg=parsed_cfg, cli_args=parsed_cli_args,\
          \ dataset_meta=dataset_meta)\r\n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/train.py\"\
          , line 149, in train\r\n    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 1534, in train\r\n    return inner_training_loop(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 1860, in _inner_training_loop\r\n    tr_loss_step = self.training_step(model,\
          \ inputs)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 2737, in training_step\r\n    loss = self.compute_loss(model, inputs)\r\
          \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/core/trainer_builder.py\"\
          , line 329, in compute_loss\r\n    return super().compute_loss(model, inputs,\
          \ return_outputs=return_outputs)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 2760, in compute_loss\r\n    outputs = model(**inputs)\r\n  File\
          \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/utils/operations.py\"\
          , line 687, in forward\r\n    return model_forward(*args, **kwargs)\r\n\
          \  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/utils/operations.py\"\
          , line 675, in __call__\r\n    return convert_to_fp32(self.model_forward(*args,\
          \ **kwargs))\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/amp/autocast_mode.py\"\
          , line 14, in decorate_autocast\r\n    return func(*args, **kwargs)\r\n\
          \  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/peft/peft_model.py\"\
          , line 1071, in forward\r\n    return self.base_model(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/peft/tuners/tuners_utils.py\"\
          , line 108, in forward\r\n    return self.model.forward(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/.cache/huggingface/modules/transformers_modules/stabilityai/stablelm-2-zephyr-1_6b/589adbfdd913d96282d43411c87a996f1bc7b000/modeling_stablelm_epoch.py\"\
          , line 818, in forward\r\n    outputs = self.model(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
          , line 366, in stablelm_model_forward\r\n    layer_outputs = torch.utils.checkpoint.checkpoint(\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/utils/checkpoint.py\"\
          , line 249, in checkpoint\r\n    return CheckpointFunction.apply(function,\
          \ preserve, *args)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/autograd/function.py\"\
          , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type:\
          \ ignore[misc]\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/utils/checkpoint.py\"\
          , line 107, in forward\r\n    outputs = run_function(*args)\r\n  File \"\
          /home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
          , line 362, in custom_forward\r\n    return module(*inputs)\r\n  File \"\
          /home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
          , line 224, in decoder_layer_forward\r\n    hidden_states, self_attn_weights,\
          \ present_key_value = self.self_attn(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
          , line 159, in flashattn_attn\r\n    output = flash_attn_varlen_qkvpacked_func(\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py\"\
          , line 887, in flash_attn_varlen_qkvpacked_func\r\n    return FlashAttnVarlenQKVPackedFunc.apply(\r\
          \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/autograd/function.py\"\
          , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type:\
          \ ignore[misc]\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py\"\
          , line 288, in forward\r\n    out, q, k, v, out_padded, softmax_lse, S_dmask,\
          \ rng_state = _flash_attn_varlen_forward(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py\"\
          , line 85, in _flash_attn_varlen_forward\r\n    out, q, k, v, out_padded,\
          \ softmax_lse, S_dmask, rng_state = flash_attn_cuda.varlen_fwd(\r\nRuntimeError:\
          \ FlashAttention only support fp16 and bf16 data type```"
        updatedAt: '2024-01-23T17:23:56.331Z'
      numEdits: 0
      reactions: []
    id: 65aff62cbf467a67b8476604
    type: comment
  author: interstellarninja
  content: "I'm getting a runtime error while attempting to finetune with axolotl\
    \ with ```flash_attention: true``` in the config.\r\n\r\nhere's the full stack\
    \ trace:\r\n```[2024-01-23 12:20:53,440] [INFO] [axolotl.callbacks.on_train_begin:572]\
    \ [PID:9523] [RANK:0] The Axolotl config has been saved to the WandB run under\
    \ files.\r\n  0%|                                                            \
    \                          | 0/2418 [00:00<?, ?it/s][2024-01-23 12:20:53,446]\
    \ [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:9523] [RANK:0] packing_efficiency_estimate:\
    \ 0.77 total_num_tokens per device: 5142267\r\nTraceback (most recent call last):\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/runpy.py\"\
    , line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals,\
    \ None,\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/runpy.py\"\
    , line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/cli/train.py\"\
    , line 43, in <module>\r\n    fire.Fire(do_cli)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py\"\
    , line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args,\
    \ context, name)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py\"\
    , line 475, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py\"\
    , line 691, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\
    \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/cli/train.py\"\
    , line 39, in do_cli\r\n    train(cfg=parsed_cfg, cli_args=parsed_cli_args, dataset_meta=dataset_meta)\r\
    \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/train.py\"\
    , line 149, in train\r\n    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 1534, in train\r\n    return inner_training_loop(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 1860, in _inner_training_loop\r\n    tr_loss_step = self.training_step(model,\
    \ inputs)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 2737, in training_step\r\n    loss = self.compute_loss(model, inputs)\r\
    \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/core/trainer_builder.py\"\
    , line 329, in compute_loss\r\n    return super().compute_loss(model, inputs,\
    \ return_outputs=return_outputs)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 2760, in compute_loss\r\n    outputs = model(**inputs)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/utils/operations.py\"\
    , line 687, in forward\r\n    return model_forward(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/utils/operations.py\"\
    , line 675, in __call__\r\n    return convert_to_fp32(self.model_forward(*args,\
    \ **kwargs))\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/amp/autocast_mode.py\"\
    , line 14, in decorate_autocast\r\n    return func(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/peft/peft_model.py\"\
    , line 1071, in forward\r\n    return self.base_model(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/peft/tuners/tuners_utils.py\"\
    , line 108, in forward\r\n    return self.model.forward(*args, **kwargs)\r\n \
    \ File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n  File \"/home/interstellarninja/.cache/huggingface/modules/transformers_modules/stabilityai/stablelm-2-zephyr-1_6b/589adbfdd913d96282d43411c87a996f1bc7b000/modeling_stablelm_epoch.py\"\
    , line 818, in forward\r\n    outputs = self.model(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
    , line 366, in stablelm_model_forward\r\n    layer_outputs = torch.utils.checkpoint.checkpoint(\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/utils/checkpoint.py\"\
    , line 249, in checkpoint\r\n    return CheckpointFunction.apply(function, preserve,\
    \ *args)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/autograd/function.py\"\
    , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/utils/checkpoint.py\"\
    , line 107, in forward\r\n    outputs = run_function(*args)\r\n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
    , line 362, in custom_forward\r\n    return module(*inputs)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
    , line 224, in decoder_layer_forward\r\n    hidden_states, self_attn_weights,\
    \ present_key_value = self.self_attn(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
    , line 159, in flashattn_attn\r\n    output = flash_attn_varlen_qkvpacked_func(\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py\"\
    , line 887, in flash_attn_varlen_qkvpacked_func\r\n    return FlashAttnVarlenQKVPackedFunc.apply(\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/autograd/function.py\"\
    , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py\"\
    , line 288, in forward\r\n    out, q, k, v, out_padded, softmax_lse, S_dmask,\
    \ rng_state = _flash_attn_varlen_forward(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py\"\
    , line 85, in _flash_attn_varlen_forward\r\n    out, q, k, v, out_padded, softmax_lse,\
    \ S_dmask, rng_state = flash_attn_cuda.varlen_fwd(\r\nRuntimeError: FlashAttention\
    \ only support fp16 and bf16 data type\r\nTraceback (most recent call last):\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/runpy.py\"\
    , line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals,\
    \ None,\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/runpy.py\"\
    , line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/cli/train.py\"\
    , line 43, in <module>\r\n    fire.Fire(do_cli)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py\"\
    , line 141, in Fire\r\n    component_trace = _Fire(component, args, parsed_flag_args,\
    \ context, name)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py\"\
    , line 475, in _Fire\r\n    component, remaining_args = _CallAndUpdateTrace(\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/fire/core.py\"\
    , line 691, in _CallAndUpdateTrace\r\n    component = fn(*varargs, **kwargs)\r\
    \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/cli/train.py\"\
    , line 39, in do_cli\r\n    train(cfg=parsed_cfg, cli_args=parsed_cli_args, dataset_meta=dataset_meta)\r\
    \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/train.py\"\
    , line 149, in train\r\n    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 1534, in train\r\n    return inner_training_loop(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 1860, in _inner_training_loop\r\n    tr_loss_step = self.training_step(model,\
    \ inputs)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 2737, in training_step\r\n    loss = self.compute_loss(model, inputs)\r\
    \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/core/trainer_builder.py\"\
    , line 329, in compute_loss\r\n    return super().compute_loss(model, inputs,\
    \ return_outputs=return_outputs)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 2760, in compute_loss\r\n    outputs = model(**inputs)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/utils/operations.py\"\
    , line 687, in forward\r\n    return model_forward(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/utils/operations.py\"\
    , line 675, in __call__\r\n    return convert_to_fp32(self.model_forward(*args,\
    \ **kwargs))\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/amp/autocast_mode.py\"\
    , line 14, in decorate_autocast\r\n    return func(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/peft/peft_model.py\"\
    , line 1071, in forward\r\n    return self.base_model(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/peft/tuners/tuners_utils.py\"\
    , line 108, in forward\r\n    return self.model.forward(*args, **kwargs)\r\n \
    \ File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n  File \"/home/interstellarninja/.cache/huggingface/modules/transformers_modules/stabilityai/stablelm-2-zephyr-1_6b/589adbfdd913d96282d43411c87a996f1bc7b000/modeling_stablelm_epoch.py\"\
    , line 818, in forward\r\n    outputs = self.model(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
    , line 366, in stablelm_model_forward\r\n    layer_outputs = torch.utils.checkpoint.checkpoint(\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/utils/checkpoint.py\"\
    , line 249, in checkpoint\r\n    return CheckpointFunction.apply(function, preserve,\
    \ *args)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/autograd/function.py\"\
    , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/utils/checkpoint.py\"\
    , line 107, in forward\r\n    outputs = run_function(*args)\r\n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
    , line 362, in custom_forward\r\n    return module(*inputs)\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
    , line 224, in decoder_layer_forward\r\n    hidden_states, self_attn_weights,\
    \ present_key_value = self.self_attn(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n  File \"/home/interstellarninja/ai_projects/axolotl/src/axolotl/monkeypatch/stablelm_attn_hijack_flash.py\"\
    , line 159, in flashattn_attn\r\n    output = flash_attn_varlen_qkvpacked_func(\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py\"\
    , line 887, in flash_attn_varlen_qkvpacked_func\r\n    return FlashAttnVarlenQKVPackedFunc.apply(\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/torch/autograd/function.py\"\
    , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\r\
    \n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py\"\
    , line 288, in forward\r\n    out, q, k, v, out_padded, softmax_lse, S_dmask,\
    \ rng_state = _flash_attn_varlen_forward(\r\n  File \"/home/interstellarninja/miniconda3/envs/sft-finetune/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py\"\
    , line 85, in _flash_attn_varlen_forward\r\n    out, q, k, v, out_padded, softmax_lse,\
    \ S_dmask, rng_state = flash_attn_cuda.varlen_fwd(\r\nRuntimeError: FlashAttention\
    \ only support fp16 and bf16 data type```"
  created_at: 2024-01-23 17:23:56+00:00
  edited: false
  hidden: false
  id: 65aff62cbf467a67b8476604
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: stabilityai/stablelm-2-zephyr-1_6b
repo_type: model
status: open
target_branch: null
title: 'RuntimeError: FlashAttention only support fp16 and bf16 data type'
