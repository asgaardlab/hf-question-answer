!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kmuraish
conflicting_files: null
created_at: 2023-11-16 21:10:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7de4f6f88f066deae772ffdd053bad1.svg
      fullname: kmuraish
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kmuraish
      type: user
    createdAt: '2023-11-16T21:10:23.000Z'
    data:
      edited: true
      editors:
      - kmuraish
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9536172151565552
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7de4f6f88f066deae772ffdd053bad1.svg
          fullname: kmuraish
          isHf: false
          isPro: false
          name: kmuraish
          type: user
        html: "<p>Hello,</p>\n<p>I would like to know the training settings for the\
          \ weights of the masked amino acid model.<br>Is it the same as the ones\
          \ described on the paper, as follows?</p>\n<p>\u2022 Batch size:  256<br>\u2022\
          \ Learning rate warmup (number of training steps to linearly \u201Cramp\
          \ up\u201D learning rate to specified value): 0<br>\u2022 Training epochs:\
          \ 50<br>\u2022 Learning rate: 5e-5</p>\n<p>The paper mentions that the number\
          \ of training epochs is 50, but if early stopping was used, I would like\
          \ to know the stopping epoch.<br>Also, what was the number of trainable\
          \ parameters of the model shown in the paper? The model published in Hugginface\
          \ seems to be 57 million, but is this the same as the parm number of the\
          \ model of which results are reported in the paper?</p>\n<p>Thank you in\
          \ advance!</p>\n"
        raw: "Hello,\n\nI would like to know the training settings for the weights\
          \ of the masked amino acid model.\nIs it the same as the ones described\
          \ on the paper, as follows?\n\n\u2022 Batch size:  256\n\u2022 Learning\
          \ rate warmup (number of training steps to linearly \u201Cramp up\u201D\
          \ learning rate to specified value): 0\n\u2022 Training epochs: 50\n\u2022\
          \ Learning rate: 5e-5\n\nThe paper mentions that the number of training\
          \ epochs is 50, but if early stopping was used, I would like to know the\
          \ stopping epoch.\nAlso, what was the number of trainable parameters of\
          \ the model shown in the paper? The model published in Hugginface seems\
          \ to be 57 million, but is this the same as the parm number of the model\
          \ of which results are reported in the paper?\n\nThank you in advance!\n"
        updatedAt: '2023-11-16T21:55:40.917Z'
      numEdits: 2
      reactions: []
    id: 6556853f76fe5cfa6a14747e
    type: comment
  author: kmuraish
  content: "Hello,\n\nI would like to know the training settings for the weights of\
    \ the masked amino acid model.\nIs it the same as the ones described on the paper,\
    \ as follows?\n\n\u2022 Batch size:  256\n\u2022 Learning rate warmup (number\
    \ of training steps to linearly \u201Cramp up\u201D learning rate to specified\
    \ value): 0\n\u2022 Training epochs: 50\n\u2022 Learning rate: 5e-5\n\nThe paper\
    \ mentions that the number of training epochs is 50, but if early stopping was\
    \ used, I would like to know the stopping epoch.\nAlso, what was the number of\
    \ trainable parameters of the model shown in the paper? The model published in\
    \ Hugginface seems to be 57 million, but is this the same as the parm number of\
    \ the model of which results are reported in the paper?\n\nThank you in advance!\n"
  created_at: 2023-11-16 21:10:23+00:00
  edited: true
  hidden: false
  id: 6556853f76fe5cfa6a14747e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: wukevin/tcr-bert
repo_type: model
status: open
target_branch: null
title: Training settings details
