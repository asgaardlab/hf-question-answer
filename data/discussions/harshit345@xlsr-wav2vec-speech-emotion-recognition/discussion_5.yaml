!!python/object:huggingface_hub.community.DiscussionWithDetails
author: krugjo
conflicting_files: null
created_at: 2023-03-22 20:57:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/37efe53031a0f755becc3b1aad363bb5.svg
      fullname: Jonas Krug
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: krugjo
      type: user
    createdAt: '2023-03-22T21:57:47.000Z'
    data:
      edited: false
      editors:
      - krugjo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/37efe53031a0f755becc3b1aad363bb5.svg
          fullname: Jonas Krug
          isHf: false
          isPro: false
          name: krugjo
          type: user
        html: '<p>Hey, I''m trying to run this model with the provided sample Code.
          But I haven''t found any information about the Wav2Vec2ForSpeechClassification
          Class. I think the Huggingface Hub hasn''t provided such a Class. Even ehcalabres,
          who made another emotion speech recognition Model, made a Request to add
          such a Class to the Transformers Library. I worked around this problem using
          the Wav2Vec2ForSequenceClassification Class, but the results in Emotions
          are always pretty similar (Anger: 17.3% | Disgust: 15.1% | Fear: 23.3% |
          Happiness: 23.7% | Sadness: 20.7%). It doesnt matter what audio file I use,
          its always similar to that, so maybe I''m using the wrong class. Can anyone
          provide me with Information of where this Class is located, how to use it
          or has the Code of Wav2Vec2ForSpeechClassification? </p>

          <p>Thanks in advance:)</p>

          '
        raw: "Hey, I'm trying to run this model with the provided sample Code. But\
          \ I haven't found any information about the Wav2Vec2ForSpeechClassification\
          \ Class. I think the Huggingface Hub hasn't provided such a Class. Even\
          \ ehcalabres, who made another emotion speech recognition Model, made a\
          \ Request to add such a Class to the Transformers Library. I worked around\
          \ this problem using the Wav2Vec2ForSequenceClassification Class, but the\
          \ results in Emotions are always pretty similar (Anger: 17.3% | Disgust:\
          \ 15.1% | Fear: 23.3% | Happiness: 23.7% | Sadness: 20.7%). It doesnt matter\
          \ what audio file I use, its always similar to that, so maybe I'm using\
          \ the wrong class. Can anyone provide me with Information of where this\
          \ Class is located, how to use it or has the Code of Wav2Vec2ForSpeechClassification?\
          \ \r\n\r\nThanks in advance:)"
        updatedAt: '2023-03-22T21:57:47.936Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - Moran
        - ahlam7x
        - NspaceOc
    id: 641b79dbabfce26bcf7c71d9
    type: comment
  author: krugjo
  content: "Hey, I'm trying to run this model with the provided sample Code. But I\
    \ haven't found any information about the Wav2Vec2ForSpeechClassification Class.\
    \ I think the Huggingface Hub hasn't provided such a Class. Even ehcalabres, who\
    \ made another emotion speech recognition Model, made a Request to add such a\
    \ Class to the Transformers Library. I worked around this problem using the Wav2Vec2ForSequenceClassification\
    \ Class, but the results in Emotions are always pretty similar (Anger: 17.3% |\
    \ Disgust: 15.1% | Fear: 23.3% | Happiness: 23.7% | Sadness: 20.7%). It doesnt\
    \ matter what audio file I use, its always similar to that, so maybe I'm using\
    \ the wrong class. Can anyone provide me with Information of where this Class\
    \ is located, how to use it or has the Code of Wav2Vec2ForSpeechClassification?\
    \ \r\n\r\nThanks in advance:)"
  created_at: 2023-03-22 20:57:47+00:00
  edited: false
  hidden: false
  id: 641b79dbabfce26bcf7c71d9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/27fcb4fa3f8136b5c188a2fd3ce95612.svg
      fullname: Raghvendra Jain
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: raghvendra
      type: user
    createdAt: '2023-04-18T05:29:46.000Z'
    data:
      edited: false
      editors:
      - raghvendra
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/27fcb4fa3f8136b5c188a2fd3ce95612.svg
          fullname: Raghvendra Jain
          isHf: false
          isPro: false
          name: raghvendra
          type: user
        html: '<p>I am facing the same issue.</p>

          '
        raw: I am facing the same issue.
        updatedAt: '2023-04-18T05:29:46.941Z'
      numEdits: 0
      reactions: []
    id: 643e2acaaa3c5728ed6899da
    type: comment
  author: raghvendra
  content: I am facing the same issue.
  created_at: 2023-04-18 04:29:46+00:00
  edited: false
  hidden: false
  id: 643e2acaaa3c5728ed6899da
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/37efe53031a0f755becc3b1aad363bb5.svg
      fullname: Jonas Krug
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: krugjo
      type: user
    createdAt: '2023-04-18T19:28:06.000Z'
    data:
      edited: false
      editors:
      - krugjo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/37efe53031a0f755becc3b1aad363bb5.svg
          fullname: Jonas Krug
          isHf: false
          isPro: false
          name: krugjo
          type: user
        html: '<p>The Problem was actually solved in another Discussion a few monts
          back, but I didnt pay Attention. The Link to the Wav2Vec2ForSpeechClassification
          Class is: <a rel="nofollow" href="https://github.com/m3hrdadfi/soxan/blob/main/src/models.py">https://github.com/m3hrdadfi/soxan/blob/main/src/models.py</a><br>You
          can implement it by cloning the whole Directory:</p>

          <p>!git clone <a rel="nofollow" href="https://github.com/m3hrdadfi/soxan.git">https://github.com/m3hrdadfi/soxan.git</a></p>

          <p>And then you have to make an own Directory where you can place the Clone.
          I am Using Google Colab and place it in the new Directory in ''Content''</p>

          <p>os.chdir(''/content/soxan'')</p>

          <p>Now you use the Wav2Vec2ForSpeechClassification Class as in the Example
          Code:)</p>

          '
        raw: 'The Problem was actually solved in another Discussion a few monts back,
          but I didnt pay Attention. The Link to the Wav2Vec2ForSpeechClassification
          Class is: https://github.com/m3hrdadfi/soxan/blob/main/src/models.py

          You can implement it by cloning the whole Directory:


          !git clone https://github.com/m3hrdadfi/soxan.git


          And then you have to make an own Directory where you can place the Clone.
          I am Using Google Colab and place it in the new Directory in ''Content''


          os.chdir(''/content/soxan'')


          Now you use the Wav2Vec2ForSpeechClassification Class as in the Example
          Code:)'
        updatedAt: '2023-04-18T19:28:06.417Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\u2764\uFE0F"
        users:
        - KaziRahman
        - ahlam7x
        - luandopke
        - NspaceOc
    id: 643eef46f2ed3bc5c063ee29
    type: comment
  author: krugjo
  content: 'The Problem was actually solved in another Discussion a few monts back,
    but I didnt pay Attention. The Link to the Wav2Vec2ForSpeechClassification Class
    is: https://github.com/m3hrdadfi/soxan/blob/main/src/models.py

    You can implement it by cloning the whole Directory:


    !git clone https://github.com/m3hrdadfi/soxan.git


    And then you have to make an own Directory where you can place the Clone. I am
    Using Google Colab and place it in the new Directory in ''Content''


    os.chdir(''/content/soxan'')


    Now you use the Wav2Vec2ForSpeechClassification Class as in the Example Code:)'
  created_at: 2023-04-18 18:28:06+00:00
  edited: false
  hidden: false
  id: 643eef46f2ed3bc5c063ee29
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4b947ce784a2d9eb19c14ab4a3fefbec.svg
      fullname: hash
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ahlam7x
      type: user
    createdAt: '2023-05-23T16:47:09.000Z'
    data:
      edited: false
      editors:
      - ahlam7x
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4b947ce784a2d9eb19c14ab4a3fefbec.svg
          fullname: hash
          isHf: false
          isPro: false
          name: ahlam7x
          type: user
        html: '<p>CAN YOU SHOW ME HOW YOU DO IT IN GOOGLE COLAB</p>

          '
        raw: CAN YOU SHOW ME HOW YOU DO IT IN GOOGLE COLAB
        updatedAt: '2023-05-23T16:47:09.845Z'
      numEdits: 0
      reactions: []
    id: 646cee0de0c5e395734d1882
    type: comment
  author: ahlam7x
  content: CAN YOU SHOW ME HOW YOU DO IT IN GOOGLE COLAB
  created_at: 2023-05-23 15:47:09+00:00
  edited: false
  hidden: false
  id: 646cee0de0c5e395734d1882
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: harshit345/xlsr-wav2vec-speech-emotion-recognition
repo_type: model
status: open
target_branch: null
title: Wav2Vec2ForSpeechClassification not found
