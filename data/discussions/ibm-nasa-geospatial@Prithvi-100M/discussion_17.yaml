!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hyzhak
conflicting_files: null
created_at: 2023-10-08 06:47:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f23bae5a9063d79256aae707689308cb.svg
      fullname: Ievgenii Krevenets
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hyzhak
      type: user
    createdAt: '2023-10-08T07:47:08.000Z'
    data:
      edited: false
      editors:
      - hyzhak
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9462507367134094
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f23bae5a9063d79256aae707689308cb.svg
          fullname: Ievgenii Krevenets
          isHf: false
          isPro: false
          name: hyzhak
          type: user
        html: '<p>It was mentioned in <a href="https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M/blob/main/README.md">Readme</a></p>

          <blockquote>

          <p>The model was pre-trained with NASA''s HLS V2 L30 product (30m granularity)
          from the <strong>contiguous United States</strong></p>

          </blockquote>

          <p>Have you tested your model on other continents? Did you notice any differences
          in performance there? I can expect that spatial data would be very different
          there.</p>

          '
        raw: "It was mentioned in [Readme](https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M/blob/main/README.md)\r\
          \n> The model was pre-trained with NASA's HLS V2 L30 product (30m granularity)\
          \ from the **contiguous United States**\r\n\r\nHave you tested your model\
          \ on other continents? Did you notice any differences in performance there?\
          \ I can expect that spatial data would be very different there."
        updatedAt: '2023-10-08T07:47:08.799Z'
      numEdits: 0
      reactions: []
    id: 65225e7c974423bd3ee5a297
    type: comment
  author: hyzhak
  content: "It was mentioned in [Readme](https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M/blob/main/README.md)\r\
    \n> The model was pre-trained with NASA's HLS V2 L30 product (30m granularity)\
    \ from the **contiguous United States**\r\n\r\nHave you tested your model on other\
    \ continents? Did you notice any differences in performance there? I can expect\
    \ that spatial data would be very different there."
  created_at: 2023-10-08 06:47:08+00:00
  edited: false
  hidden: false
  id: 65225e7c974423bd3ee5a297
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7bd042f2d502604e0459c727828a5cb.svg
      fullname: Paolo Fraccaro
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Paolo-Fraccaro
      type: user
    createdAt: '2023-10-08T08:37:53.000Z'
    data:
      edited: false
      editors:
      - Paolo-Fraccaro
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9660847187042236
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7bd042f2d502604e0459c727828a5cb.svg
          fullname: Paolo Fraccaro
          isHf: false
          isPro: false
          name: Paolo-Fraccaro
          type: user
        html: '<p>We finetuned the model also to different regions (e.g. sen1floods11
          includes data from 11 regions around the world). This led to state of the
          art performance on this task, so the model was able to generalise.  If input
          data for finetuning would be completely different than what was provided
          during pretraining, the model will take longer to converge to the new data.</p>

          '
        raw: We finetuned the model also to different regions (e.g. sen1floods11 includes
          data from 11 regions around the world). This led to state of the art performance
          on this task, so the model was able to generalise.  If input data for finetuning
          would be completely different than what was provided during pretraining,
          the model will take longer to converge to the new data.
        updatedAt: '2023-10-08T08:37:53.429Z'
      numEdits: 0
      reactions: []
    id: 65226a61728c0b6dc72efb55
    type: comment
  author: Paolo-Fraccaro
  content: We finetuned the model also to different regions (e.g. sen1floods11 includes
    data from 11 regions around the world). This led to state of the art performance
    on this task, so the model was able to generalise.  If input data for finetuning
    would be completely different than what was provided during pretraining, the model
    will take longer to converge to the new data.
  created_at: 2023-10-08 07:37:53+00:00
  edited: false
  hidden: false
  id: 65226a61728c0b6dc72efb55
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/31c5b70f8f6036e4abd8eb0899fae74f.svg
      fullname: Mark Wronkiewicz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wronk
      type: user
    createdAt: '2023-11-07T22:57:05.000Z'
    data:
      edited: false
      editors:
      - wronk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9570032358169556
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/31c5b70f8f6036e4abd8eb0899fae74f.svg
          fullname: Mark Wronkiewicz
          isHf: false
          isPro: false
          name: wronk
          type: user
        html: '<blockquote>

          <p>This led to state of the art performance on this task, so the model was
          able to generalise. </p>

          </blockquote>

          <p>For the flood task specifically, I think that''s persuasive. Have you
          tested generalization for the other 3 datasets? </p>

          <p>Crop segmentation is particularly interesting. Besides forest and vegetation,
          <a href="https://huggingface.co/datasets/ibm-nasa-geospatial/multi-temporal-crop-classification#training-data-distribution">your
          dataset''s</a> largest classes are corn and soybeans. Those are huge in
          the U.S., but less so in many other parts of the world. I''d be interested
          in its ability to detect rice in Asia or cassava and sugar cane in Africa.
          Even if you stayed in the U.S., how does it do on coffee in Hawaii? I ask
          because some of the use-cases you''re testing overlap with the UN''s sustainable
          development goals, so there is potential for large impact. Unfortunately,
          there is often a focus on data from Western countries, so it can be hard
          to figure out how applicable these types of models are for the Global South.</p>

          '
        raw: "> This led to state of the art performance on this task, so the model\
          \ was able to generalise. \n\nFor the flood task specifically, I think that's\
          \ persuasive. Have you tested generalization for the other 3 datasets? \n\
          \nCrop segmentation is particularly interesting. Besides forest and vegetation,\
          \ [your dataset's](https://huggingface.co/datasets/ibm-nasa-geospatial/multi-temporal-crop-classification#training-data-distribution)\
          \ largest classes are corn and soybeans. Those are huge in the U.S., but\
          \ less so in many other parts of the world. I'd be interested in its ability\
          \ to detect rice in Asia or cassava and sugar cane in Africa. Even if you\
          \ stayed in the U.S., how does it do on coffee in Hawaii? I ask because\
          \ some of the use-cases you're testing overlap with the UN's sustainable\
          \ development goals, so there is potential for large impact. Unfortunately,\
          \ there is often a focus on data from Western countries, so it can be hard\
          \ to figure out how applicable these types of models are for the Global\
          \ South.\n"
        updatedAt: '2023-11-07T22:57:05.847Z'
      numEdits: 0
      reactions: []
    id: 654ac0c13b78e73b43b7b54a
    type: comment
  author: wronk
  content: "> This led to state of the art performance on this task, so the model\
    \ was able to generalise. \n\nFor the flood task specifically, I think that's\
    \ persuasive. Have you tested generalization for the other 3 datasets? \n\nCrop\
    \ segmentation is particularly interesting. Besides forest and vegetation, [your\
    \ dataset's](https://huggingface.co/datasets/ibm-nasa-geospatial/multi-temporal-crop-classification#training-data-distribution)\
    \ largest classes are corn and soybeans. Those are huge in the U.S., but less\
    \ so in many other parts of the world. I'd be interested in its ability to detect\
    \ rice in Asia or cassava and sugar cane in Africa. Even if you stayed in the\
    \ U.S., how does it do on coffee in Hawaii? I ask because some of the use-cases\
    \ you're testing overlap with the UN's sustainable development goals, so there\
    \ is potential for large impact. Unfortunately, there is often a focus on data\
    \ from Western countries, so it can be hard to figure out how applicable these\
    \ types of models are for the Global South.\n"
  created_at: 2023-11-07 22:57:05+00:00
  edited: false
  hidden: false
  id: 654ac0c13b78e73b43b7b54a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 17
repo_id: ibm-nasa-geospatial/Prithvi-100M
repo_type: model
status: open
target_branch: null
title: How does pre-training on contiguous United States data affect model performance
  in other regions?
