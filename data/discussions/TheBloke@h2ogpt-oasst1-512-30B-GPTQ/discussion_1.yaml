!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Blacky372
conflicting_files: null
created_at: 2023-05-11 14:35:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0cb601defad1c64c358d6a8d9cee7043.svg
      fullname: Blacky 372
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Blacky372
      type: user
    createdAt: '2023-05-11T15:35:54.000Z'
    data:
      edited: false
      editors:
      - Blacky372
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0cb601defad1c64c358d6a8d9cee7043.svg
          fullname: Blacky 372
          isHf: false
          isPro: false
          name: Blacky372
          type: user
        html: '<p>I want to use this model with the text-generation-webui. What parameters
          to use with python server.py for this model?</p>

          '
        raw: I want to use this model with the text-generation-webui. What parameters
          to use with python server.py for this model?
        updatedAt: '2023-05-11T15:35:54.179Z'
      numEdits: 0
      reactions: []
    id: 645d0b5a5ebf379fd6d90beb
    type: comment
  author: Blacky372
  content: I want to use this model with the text-generation-webui. What parameters
    to use with python server.py for this model?
  created_at: 2023-05-11 14:35:54+00:00
  edited: false
  hidden: false
  id: 645d0b5a5ebf379fd6d90beb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-11T15:48:10.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I''ve not had a chance to do the readme yet.</p>

          <p>GPTQ params are:<br>wbits = 4<br>groupsize = None<br>model_type = llama</p>

          '
        raw: 'I''ve not had a chance to do the readme yet.


          GPTQ params are:

          wbits = 4

          groupsize = None

          model_type = llama'
        updatedAt: '2023-05-11T15:48:10.385Z'
      numEdits: 0
      reactions: []
    id: 645d0e3af1e3b219cb0b6c4f
    type: comment
  author: TheBloke
  content: 'I''ve not had a chance to do the readme yet.


    GPTQ params are:

    wbits = 4

    groupsize = None

    model_type = llama'
  created_at: 2023-05-11 14:48:10+00:00
  edited: false
  hidden: false
  id: 645d0e3af1e3b219cb0b6c4f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fbe4da0ad46033965ebe295238a0cfcb.svg
      fullname: Dee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: deetungsten
      type: user
    createdAt: '2023-05-15T18:27:54.000Z'
    data:
      edited: false
      editors:
      - deetungsten
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fbe4da0ad46033965ebe295238a0cfcb.svg
          fullname: Dee
          isHf: false
          isPro: false
          name: deetungsten
          type: user
        html: '<p>I get a size mismatch error if I use wbits=4</p>

          '
        raw: I get a size mismatch error if I use wbits=4
        updatedAt: '2023-05-15T18:27:54.908Z'
      numEdits: 0
      reactions: []
    id: 646279aa48e13890ea53f157
    type: comment
  author: deetungsten
  content: I get a size mismatch error if I use wbits=4
  created_at: 2023-05-15 17:27:54+00:00
  edited: false
  hidden: false
  id: 646279aa48e13890ea53f157
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-15T18:33:36.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<blockquote>

          <p>I get a size mismatch error if I use wbits=4</p>

          </blockquote>

          <p>Show me the errors. Are you using pre_layer as well?</p>

          '
        raw: '> I get a size mismatch error if I use wbits=4


          Show me the errors. Are you using pre_layer as well?'
        updatedAt: '2023-05-15T18:33:36.315Z'
      numEdits: 0
      reactions: []
    id: 64627b00d290a75bd98e5270
    type: comment
  author: TheBloke
  content: '> I get a size mismatch error if I use wbits=4


    Show me the errors. Are you using pre_layer as well?'
  created_at: 2023-05-15 17:33:36+00:00
  edited: false
  hidden: false
  id: 64627b00d290a75bd98e5270
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fbe4da0ad46033965ebe295238a0cfcb.svg
      fullname: Dee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: deetungsten
      type: user
    createdAt: '2023-05-15T20:04:29.000Z'
    data:
      edited: true
      editors:
      - deetungsten
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fbe4da0ad46033965ebe295238a0cfcb.svg
          fullname: Dee
          isHf: false
          isPro: false
          name: deetungsten
          type: user
        html: "<p>I run this this command <code>python server.py --model TheBloke_h2ogpt-oasst1-512-30B-GPTQ\
          \ --model_type llama --wbits 4 --chat</code></p>\n<p>and I get this error\
          \ (only showing the last two lines):</p>\n<pre><code>        size mismatch\
          \ for model.layers.59.mlp.up_proj.qzeros: copying a param with shape torch.Size([1,\
          \ 2240]) from checkpoint, the shape in current model is torch.Size([52,\
          \ 2240]).\n        size mismatch for model.layers.59.mlp.up_proj.scales:\
          \ copying a param with shape torch.Size([1, 17920]) from checkpoint, the\
          \ shape in current model is torch.Size([52, 17920]\n</code></pre>\n"
        raw: "I run this this command `python server.py --model TheBloke_h2ogpt-oasst1-512-30B-GPTQ\
          \ --model_type llama --wbits 4 --chat`\n\nand I get this error (only showing\
          \ the last two lines):\n```\n        size mismatch for model.layers.59.mlp.up_proj.qzeros:\
          \ copying a param with shape torch.Size([1, 2240]) from checkpoint, the\
          \ shape in current model is torch.Size([52, 2240]).\n        size mismatch\
          \ for model.layers.59.mlp.up_proj.scales: copying a param with shape torch.Size([1,\
          \ 17920]) from checkpoint, the shape in current model is torch.Size([52,\
          \ 17920]\n```"
        updatedAt: '2023-05-15T20:04:44.887Z'
      numEdits: 1
      reactions: []
    id: 6462904d57b29d859fa6952d
    type: comment
  author: deetungsten
  content: "I run this this command `python server.py --model TheBloke_h2ogpt-oasst1-512-30B-GPTQ\
    \ --model_type llama --wbits 4 --chat`\n\nand I get this error (only showing the\
    \ last two lines):\n```\n        size mismatch for model.layers.59.mlp.up_proj.qzeros:\
    \ copying a param with shape torch.Size([1, 2240]) from checkpoint, the shape\
    \ in current model is torch.Size([52, 2240]).\n        size mismatch for model.layers.59.mlp.up_proj.scales:\
    \ copying a param with shape torch.Size([1, 17920]) from checkpoint, the shape\
    \ in current model is torch.Size([52, 17920]\n```"
  created_at: 2023-05-15 19:04:29+00:00
  edited: true
  hidden: false
  id: 6462904d57b29d859fa6952d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-15T20:06:01.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Can you try without --chat and let me know if that makes any difference?</p>

          '
        raw: Can you try without --chat and let me know if that makes any difference?
        updatedAt: '2023-05-15T20:06:01.138Z'
      numEdits: 0
      reactions: []
    id: 646290a948e13890ea54cff4
    type: comment
  author: TheBloke
  content: Can you try without --chat and let me know if that makes any difference?
  created_at: 2023-05-15 19:06:01+00:00
  edited: false
  hidden: false
  id: 646290a948e13890ea54cff4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-05-16T08:54:07.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: "<blockquote>\n<p>I run this this command <code>python server.py --model\
          \ TheBloke_h2ogpt-oasst1-512-30B-GPTQ --model_type llama --wbits 4 --chat</code></p>\n\
          <p>and I get this error (only showing the last two lines):</p>\n<pre><code>\
          \        size mismatch for model.layers.59.mlp.up_proj.qzeros: copying a\
          \ param with shape torch.Size([1, 2240]) from checkpoint, the shape in current\
          \ model is torch.Size([52, 2240]).\n        size mismatch for model.layers.59.mlp.up_proj.scales:\
          \ copying a param with shape torch.Size([1, 17920]) from checkpoint, the\
          \ shape in current model is torch.Size([52, 17920]\n</code></pre>\n</blockquote>\n\
          <p>You need to specifity --groupsize 512</p>\n"
        raw: "> I run this this command `python server.py --model TheBloke_h2ogpt-oasst1-512-30B-GPTQ\
          \ --model_type llama --wbits 4 --chat`\n> \n> and I get this error (only\
          \ showing the last two lines):\n> ```\n>         size mismatch for model.layers.59.mlp.up_proj.qzeros:\
          \ copying a param with shape torch.Size([1, 2240]) from checkpoint, the\
          \ shape in current model is torch.Size([52, 2240]).\n>         size mismatch\
          \ for model.layers.59.mlp.up_proj.scales: copying a param with shape torch.Size([1,\
          \ 17920]) from checkpoint, the shape in current model is torch.Size([52,\
          \ 17920]\n> ```\n\nYou need to specifity --groupsize 512"
        updatedAt: '2023-05-16T08:54:07.353Z'
      numEdits: 0
      reactions: []
    id: 646344af32317fa480669637
    type: comment
  author: Yhyu13
  content: "> I run this this command `python server.py --model TheBloke_h2ogpt-oasst1-512-30B-GPTQ\
    \ --model_type llama --wbits 4 --chat`\n> \n> and I get this error (only showing\
    \ the last two lines):\n> ```\n>         size mismatch for model.layers.59.mlp.up_proj.qzeros:\
    \ copying a param with shape torch.Size([1, 2240]) from checkpoint, the shape\
    \ in current model is torch.Size([52, 2240]).\n>         size mismatch for model.layers.59.mlp.up_proj.scales:\
    \ copying a param with shape torch.Size([1, 17920]) from checkpoint, the shape\
    \ in current model is torch.Size([52, 17920]\n> ```\n\nYou need to specifity --groupsize\
    \ 512"
  created_at: 2023-05-16 07:54:07+00:00
  edited: false
  hidden: false
  id: 646344af32317fa480669637
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-16T08:54:34.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<blockquote>

          <p>You need to specifity --groupsize 512</p>

          </blockquote>

          <p>The 512 in the model size is not the group size.  The group size is None.</p>

          <p>I now know what''s causing this. It appears to be a text-gen-ui bug related
          to groupsize. It''s forcing the model to use a groupsize of 128, ignoring
          the --groupsize -1 default.  For the fix, please see: <a href="https://huggingface.co/TheBloke/OpenAssistant-SFT-7-Llama-30B-GPTQ/discussions/3#6463434bab15db2fa5661b31">https://huggingface.co/TheBloke/OpenAssistant-SFT-7-Llama-30B-GPTQ/discussions/3#6463434bab15db2fa5661b31</a></p>

          '
        raw: '> You need to specifity --groupsize 512


          The 512 in the model size is not the group size.  The group size is None.


          I now know what''s causing this. It appears to be a text-gen-ui bug related
          to groupsize. It''s forcing the model to use a groupsize of 128, ignoring
          the --groupsize -1 default.  For the fix, please see: https://huggingface.co/TheBloke/OpenAssistant-SFT-7-Llama-30B-GPTQ/discussions/3#6463434bab15db2fa5661b31'
        updatedAt: '2023-05-16T10:02:31.213Z'
      numEdits: 2
      reactions: []
    id: 646344ca589d58dbc799b2f1
    type: comment
  author: TheBloke
  content: '> You need to specifity --groupsize 512


    The 512 in the model size is not the group size.  The group size is None.


    I now know what''s causing this. It appears to be a text-gen-ui bug related to
    groupsize. It''s forcing the model to use a groupsize of 128, ignoring the --groupsize
    -1 default.  For the fix, please see: https://huggingface.co/TheBloke/OpenAssistant-SFT-7-Llama-30B-GPTQ/discussions/3#6463434bab15db2fa5661b31'
  created_at: 2023-05-16 07:54:34+00:00
  edited: true
  hidden: false
  id: 646344ca589d58dbc799b2f1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/h2ogpt-oasst1-512-30B-GPTQ
repo_type: model
status: open
target_branch: null
title: Which GPTQ parameters to use? Is 512 groupsize or cutoff length?
