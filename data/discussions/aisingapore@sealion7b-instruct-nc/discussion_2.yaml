!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jahhs0n
conflicting_files: null
created_at: 2023-12-10 12:31:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/90d7a07083f2b6237d3e2f78ae9a0936.svg
      fullname: jason
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jahhs0n
      type: user
    createdAt: '2023-12-10T12:31:35.000Z'
    data:
      edited: false
      editors:
      - jahhs0n
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.655169665813446
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/90d7a07083f2b6237d3e2f78ae9a0936.svg
          fullname: jason
          isHf: false
          isPro: false
          name: jahhs0n
          type: user
        html: "<p>Currently the tokenizer can only be loaded and saved in a legacy\
          \ format. Trying to save it in <a href=\"https://huggingface.co/docs/tokenizers/index\"\
          >FastTokenizer</a> format </p>\n<pre><code class=\"language-python\"><span\
          \ class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\"\
          >import</span> AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\n\
          \    <span class=\"hljs-string\">\"aisingapore/sealion7b\"</span>, trust_remote_code=<span\
          \ class=\"hljs-literal\">True</span>\n)\ntokenizer.save_pretrained(<span\
          \ class=\"hljs-string\">\".\"</span>, legacy_format=<span class=\"hljs-literal\"\
          >False</span>)\n</code></pre>\n<p> will result in the following error: </p>\n\
          <pre><code>Explicitly passing a `revision` is encouraged when loading a\
          \ model with custom code to ensure no malicious code has been contributed\
          \ in a newer revision.\nTraceback (most recent call last):\n  File \"/home/jason/projects/test/test.py\"\
          , line 6, in &lt;module&gt;\n    tokenizer.save_pretrained(\".\", legacy_format=False)\n\
          \  File \"/home/jason/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2182, in save_pretrained\n    save_files = self._save_pretrained(\n\
          \  File \"/home/jason/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2214, in _save_pretrained\n    raise ValueError(\nValueError: Only\
          \ fast tokenizers (instances of PreTrainedTokenizerFast) can be saved in\
          \ non legacy format. \n</code></pre>\n<p>FastTokenizers is used by default\
          \ by the rust web server in <a rel=\"nofollow\" href=\"https://github.com/huggingface/text-generation-inference\"\
          >TGI</a>, and it will fail to load if there isn't a fast tokenizer implementation\
          \ for the tokenizer.<br>There is a <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/blob/df5c5c62ae253055336f5bb0828ca8e3e15ab6bd/src/transformers/convert_slow_tokenizer.py#L1311\"\
          >conversion script</a> for slow tokenizer classes to fast ones, but since\
          \ this is a newly defined tokenizer class instead of using an existing tokenizer\
          \ class, i am unable to convert it into a fast tokenizer.</p>\n"
        raw: "Currently the tokenizer can only be loaded and saved in a legacy format.\
          \ Trying to save it in [FastTokenizer](https://huggingface.co/docs/tokenizers/index)\
          \ format \r\n```python\r\nfrom transformers import AutoTokenizer\r\ntokenizer\
          \ = AutoTokenizer.from_pretrained(\r\n    \"aisingapore/sealion7b\", trust_remote_code=True\r\
          \n)\r\ntokenizer.save_pretrained(\".\", legacy_format=False)\r\n```\r\n\r\
          \n will result in the following error: \r\n```\r\nExplicitly passing a `revision`\
          \ is encouraged when loading a model with custom code to ensure no malicious\
          \ code has been contributed in a newer revision.\r\nTraceback (most recent\
          \ call last):\r\n  File \"/home/jason/projects/test/test.py\", line 6, in\
          \ <module>\r\n    tokenizer.save_pretrained(\".\", legacy_format=False)\r\
          \n  File \"/home/jason/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2182, in save_pretrained\r\n    save_files = self._save_pretrained(\r\
          \n  File \"/home/jason/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2214, in _save_pretrained\r\n    raise ValueError(\r\nValueError:\
          \ Only fast tokenizers (instances of PreTrainedTokenizerFast) can be saved\
          \ in non legacy format. \r\n```\r\n\r\nFastTokenizers is used by default\
          \ by the rust web server in [TGI](https://github.com/huggingface/text-generation-inference),\
          \ and it will fail to load if there isn't a fast tokenizer implementation\
          \ for the tokenizer.\r\nThere is a [conversion script](https://github.com/huggingface/transformers/blob/df5c5c62ae253055336f5bb0828ca8e3e15ab6bd/src/transformers/convert_slow_tokenizer.py#L1311)\
          \ for slow tokenizer classes to fast ones, but since this is a newly defined\
          \ tokenizer class instead of using an existing tokenizer class, i am unable\
          \ to convert it into a fast tokenizer."
        updatedAt: '2023-12-10T12:31:35.206Z'
      numEdits: 0
      reactions: []
    id: 6575afa7eb4b4e0bcf489363
    type: comment
  author: jahhs0n
  content: "Currently the tokenizer can only be loaded and saved in a legacy format.\
    \ Trying to save it in [FastTokenizer](https://huggingface.co/docs/tokenizers/index)\
    \ format \r\n```python\r\nfrom transformers import AutoTokenizer\r\ntokenizer\
    \ = AutoTokenizer.from_pretrained(\r\n    \"aisingapore/sealion7b\", trust_remote_code=True\r\
    \n)\r\ntokenizer.save_pretrained(\".\", legacy_format=False)\r\n```\r\n\r\n will\
    \ result in the following error: \r\n```\r\nExplicitly passing a `revision` is\
    \ encouraged when loading a model with custom code to ensure no malicious code\
    \ has been contributed in a newer revision.\r\nTraceback (most recent call last):\r\
    \n  File \"/home/jason/projects/test/test.py\", line 6, in <module>\r\n    tokenizer.save_pretrained(\"\
    .\", legacy_format=False)\r\n  File \"/home/jason/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
    , line 2182, in save_pretrained\r\n    save_files = self._save_pretrained(\r\n\
    \  File \"/home/jason/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
    , line 2214, in _save_pretrained\r\n    raise ValueError(\r\nValueError: Only\
    \ fast tokenizers (instances of PreTrainedTokenizerFast) can be saved in non legacy\
    \ format. \r\n```\r\n\r\nFastTokenizers is used by default by the rust web server\
    \ in [TGI](https://github.com/huggingface/text-generation-inference), and it will\
    \ fail to load if there isn't a fast tokenizer implementation for the tokenizer.\r\
    \nThere is a [conversion script](https://github.com/huggingface/transformers/blob/df5c5c62ae253055336f5bb0828ca8e3e15ab6bd/src/transformers/convert_slow_tokenizer.py#L1311)\
    \ for slow tokenizer classes to fast ones, but since this is a newly defined tokenizer\
    \ class instead of using an existing tokenizer class, i am unable to convert it\
    \ into a fast tokenizer."
  created_at: 2023-12-10 12:31:35+00:00
  edited: false
  hidden: false
  id: 6575afa7eb4b4e0bcf489363
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c1a6f2f9a28d74fc641f10a1bf2867c.svg
      fullname: Raymond Ng
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RaymondAISG
      type: user
    createdAt: '2023-12-11T05:53:55.000Z'
    data:
      edited: false
      editors:
      - RaymondAISG
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8973901867866516
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c1a6f2f9a28d74fc641f10a1bf2867c.svg
          fullname: Raymond Ng
          isHf: false
          isPro: false
          name: RaymondAISG
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;jahhs0n&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/jahhs0n\">@<span class=\"\
          underline\">jahhs0n</span></a></span>\n\n\t</span></span> ,<br>Thank you\
          \ for checking out SEA-LION!<br>The SEA-LION tokenizer is trained using\
          \ the SentencePiece package, hence its not compatible with the fast tokenizer\
          \ by default.</p>\n<p>I've uploaded a version of the fast tokenizer which\
          \ we converted using the sentencepiece_extractor script from the tokenizer\
          \ package, you can find it in the SEA-LION Github <a rel=\"nofollow\" href=\"\
          https://github.com/aisingapore/sealion/tree/fasttokenizer/tokenizer\">fasttokenizer</a>\
          \ branch, in the tokenizer folder.</p>\n<p>However, please note that due\
          \ to the conversion process, it is not possible to replicate the exact SentencePiece\
          \ model as mentioned in this Github issue, <a rel=\"nofollow\" href=\"https://github.com/huggingface/tokenizers/issues/225#issuecomment-612140650\"\
          >https://github.com/huggingface/tokenizers/issues/225#issuecomment-612140650</a>.</p>\n\
          <p>We will be adding some examples which differs between the original SentencePiece\
          \ model and the fast tokenizer to the README over the next week days. Hope\
          \ this helps.</p>\n"
        raw: 'Hi @jahhs0n ,

          Thank you for checking out SEA-LION!

          The SEA-LION tokenizer is trained using the SentencePiece package, hence
          its not compatible with the fast tokenizer by default.


          I''ve uploaded a version of the fast tokenizer which we converted using
          the sentencepiece_extractor script from the tokenizer package, you can find
          it in the SEA-LION Github [fasttokenizer](https://github.com/aisingapore/sealion/tree/fasttokenizer/tokenizer)
          branch, in the tokenizer folder.


          However, please note that due to the conversion process, it is not possible
          to replicate the exact SentencePiece model as mentioned in this Github issue,
          https://github.com/huggingface/tokenizers/issues/225#issuecomment-612140650.


          We will be adding some examples which differs between the original SentencePiece
          model and the fast tokenizer to the README over the next week days. Hope
          this helps.'
        updatedAt: '2023-12-11T05:53:55.898Z'
      numEdits: 0
      reactions: []
    id: 6576a3f3c79162da90217159
    type: comment
  author: RaymondAISG
  content: 'Hi @jahhs0n ,

    Thank you for checking out SEA-LION!

    The SEA-LION tokenizer is trained using the SentencePiece package, hence its not
    compatible with the fast tokenizer by default.


    I''ve uploaded a version of the fast tokenizer which we converted using the sentencepiece_extractor
    script from the tokenizer package, you can find it in the SEA-LION Github [fasttokenizer](https://github.com/aisingapore/sealion/tree/fasttokenizer/tokenizer)
    branch, in the tokenizer folder.


    However, please note that due to the conversion process, it is not possible to
    replicate the exact SentencePiece model as mentioned in this Github issue, https://github.com/huggingface/tokenizers/issues/225#issuecomment-612140650.


    We will be adding some examples which differs between the original SentencePiece
    model and the fast tokenizer to the README over the next week days. Hope this
    helps.'
  created_at: 2023-12-11 05:53:55+00:00
  edited: false
  hidden: false
  id: 6576a3f3c79162da90217159
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/90d7a07083f2b6237d3e2f78ae9a0936.svg
      fullname: jason
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jahhs0n
      type: user
    createdAt: '2023-12-11T13:27:21.000Z'
    data:
      edited: false
      editors:
      - jahhs0n
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7492246031761169
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/90d7a07083f2b6237d3e2f78ae9a0936.svg
          fullname: jason
          isHf: false
          isPro: false
          name: jahhs0n
          type: user
        html: '<p>thanks for the work! May I know how exactly the conversion is done?
          My understanding of the process is as thus:</p>

          <ul>

          <li>extract the <code>vocab.json</code> file and the <code>merges</code>
          file using <a rel="nofollow" href="https://github.com/huggingface/tokenizers/blob/main/bindings/python/scripts/sentencepiece_extractor.py">sentencepiece_extractor.py</a>
          from huggingface''s <code>tokenizers</code> package</li>

          <li>load the <code>vocab.json</code> file and <code>merges</code> file into
          <code>SentencePieceBPETokenizer</code> class using the <a rel="nofollow"
          href="https://github.com/huggingface/tokenizers/blob/8edec536a737cb04494b454805be16c020abb14f/bindings/python/py_src/tokenizers/implementations/sentencepiece_bpe.py#L48-L51">from_file</a>
          method</li>

          <li>save the <code>SentencePieceBPETokenizer</code> object using the <a
          rel="nofollow" href="https://github.com/huggingface/tokenizers/blob/8edec536a737cb04494b454805be16c020abb14f/bindings/python/py_src/tokenizers/implementations/base_tokenizer.py#L334-L341">save</a>
          method?</li>

          </ul>

          <p>please correct my understanding if i get any part of that process wrong.
          Thank you for your help!</p>

          '
        raw: 'thanks for the work! May I know how exactly the conversion is done?
          My understanding of the process is as thus:

          * extract the `vocab.json` file and the `merges` file using [sentencepiece_extractor.py](https://github.com/huggingface/tokenizers/blob/main/bindings/python/scripts/sentencepiece_extractor.py)
          from huggingface''s `tokenizers` package

          * load the `vocab.json` file and `merges` file into `SentencePieceBPETokenizer`
          class using the [from_file](https://github.com/huggingface/tokenizers/blob/8edec536a737cb04494b454805be16c020abb14f/bindings/python/py_src/tokenizers/implementations/sentencepiece_bpe.py#L48-L51)
          method

          * save the `SentencePieceBPETokenizer` object using the [save](https://github.com/huggingface/tokenizers/blob/8edec536a737cb04494b454805be16c020abb14f/bindings/python/py_src/tokenizers/implementations/base_tokenizer.py#L334-L341)
          method?


          please correct my understanding if i get any part of that process wrong.
          Thank you for your help!'
        updatedAt: '2023-12-11T13:27:21.720Z'
      numEdits: 0
      reactions: []
    id: 65770e39654561a1b34967cb
    type: comment
  author: jahhs0n
  content: 'thanks for the work! May I know how exactly the conversion is done? My
    understanding of the process is as thus:

    * extract the `vocab.json` file and the `merges` file using [sentencepiece_extractor.py](https://github.com/huggingface/tokenizers/blob/main/bindings/python/scripts/sentencepiece_extractor.py)
    from huggingface''s `tokenizers` package

    * load the `vocab.json` file and `merges` file into `SentencePieceBPETokenizer`
    class using the [from_file](https://github.com/huggingface/tokenizers/blob/8edec536a737cb04494b454805be16c020abb14f/bindings/python/py_src/tokenizers/implementations/sentencepiece_bpe.py#L48-L51)
    method

    * save the `SentencePieceBPETokenizer` object using the [save](https://github.com/huggingface/tokenizers/blob/8edec536a737cb04494b454805be16c020abb14f/bindings/python/py_src/tokenizers/implementations/base_tokenizer.py#L334-L341)
    method?


    please correct my understanding if i get any part of that process wrong. Thank
    you for your help!'
  created_at: 2023-12-11 13:27:21+00:00
  edited: false
  hidden: false
  id: 65770e39654561a1b34967cb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c1a6f2f9a28d74fc641f10a1bf2867c.svg
      fullname: Raymond Ng
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RaymondAISG
      type: user
    createdAt: '2023-12-12T00:01:21.000Z'
    data:
      edited: false
      editors:
      - RaymondAISG
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8391981720924377
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c1a6f2f9a28d74fc641f10a1bf2867c.svg
          fullname: Raymond Ng
          isHf: false
          isPro: false
          name: RaymondAISG
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;jahhs0n&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/jahhs0n\">@<span class=\"\
          underline\">jahhs0n</span></a></span>\n\n\t</span></span> ,<br>Yes, your\
          \ understanding is pretty much spot on, there is also a few additional steps:</p>\n\
          <ul>\n<li>Add special tokens</li>\n<li>Manually add <a href=\"https://huggingface.co/aisingapore/sealion7b/blob/11cc4274ab12322435890b20b8de64511e1885f1/tokenizer_config.json#L23\"\
          ><code>auto_map</code> in tokenizer_config.json so that AutoTokenizer recognise\
          \ the custom tokenizer class </a></li>\n</ul>\n<p>I have also uploaded the\
          \ notebook which does the conversion for your reference here,<br><a rel=\"\
          nofollow\" href=\"https://github.com/aisingapore/sealion/blob/fasttokenizer/tokenizer/fast_tokenizer_conversion.ipynb\"\
          >https://github.com/aisingapore/sealion/blob/fasttokenizer/tokenizer/fast_tokenizer_conversion.ipynb</a></p>\n\
          <p>Hope this helps.</p>\n"
        raw: 'Hi @jahhs0n ,

          Yes, your understanding is pretty much spot on, there is also a few additional
          steps:

          - Add special tokens

          - Manually add [`auto_map` in tokenizer_config.json so that AutoTokenizer
          recognise the custom tokenizer class ](https://huggingface.co/aisingapore/sealion7b/blob/11cc4274ab12322435890b20b8de64511e1885f1/tokenizer_config.json#L23)


          I have also uploaded the notebook which does the conversion for your reference
          here,

          https://github.com/aisingapore/sealion/blob/fasttokenizer/tokenizer/fast_tokenizer_conversion.ipynb


          Hope this helps.'
        updatedAt: '2023-12-12T00:01:21.638Z'
      numEdits: 0
      reactions: []
    id: 6577a2d1c37954680a99e177
    type: comment
  author: RaymondAISG
  content: 'Hi @jahhs0n ,

    Yes, your understanding is pretty much spot on, there is also a few additional
    steps:

    - Add special tokens

    - Manually add [`auto_map` in tokenizer_config.json so that AutoTokenizer recognise
    the custom tokenizer class ](https://huggingface.co/aisingapore/sealion7b/blob/11cc4274ab12322435890b20b8de64511e1885f1/tokenizer_config.json#L23)


    I have also uploaded the notebook which does the conversion for your reference
    here,

    https://github.com/aisingapore/sealion/blob/fasttokenizer/tokenizer/fast_tokenizer_conversion.ipynb


    Hope this helps.'
  created_at: 2023-12-12 00:01:21+00:00
  edited: false
  hidden: false
  id: 6577a2d1c37954680a99e177
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/90d7a07083f2b6237d3e2f78ae9a0936.svg
      fullname: jason
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jahhs0n
      type: user
    createdAt: '2023-12-12T01:38:42.000Z'
    data:
      edited: false
      editors:
      - jahhs0n
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9398747682571411
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/90d7a07083f2b6237d3e2f78ae9a0936.svg
          fullname: jason
          isHf: false
          isPro: false
          name: jahhs0n
          type: user
        html: '<p>Thanks for the guidance! The notebook is especially helpful to see
          how the conversion is done. Will be closing this issue now</p>

          '
        raw: Thanks for the guidance! The notebook is especially helpful to see how
          the conversion is done. Will be closing this issue now
        updatedAt: '2023-12-12T01:38:42.458Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6577b9a28369b885d413d50a
    id: 6577b9a28369b885d413d501
    type: comment
  author: jahhs0n
  content: Thanks for the guidance! The notebook is especially helpful to see how
    the conversion is done. Will be closing this issue now
  created_at: 2023-12-12 01:38:42+00:00
  edited: false
  hidden: false
  id: 6577b9a28369b885d413d501
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/90d7a07083f2b6237d3e2f78ae9a0936.svg
      fullname: jason
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jahhs0n
      type: user
    createdAt: '2023-12-12T01:38:42.000Z'
    data:
      status: closed
    id: 6577b9a28369b885d413d50a
    type: status-change
  author: jahhs0n
  created_at: 2023-12-12 01:38:42+00:00
  id: 6577b9a28369b885d413d50a
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c1a6f2f9a28d74fc641f10a1bf2867c.svg
      fullname: Raymond Ng
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RaymondAISG
      type: user
    createdAt: '2023-12-12T01:44:07.000Z'
    data:
      edited: false
      editors:
      - RaymondAISG
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8894636034965515
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c1a6f2f9a28d74fc641f10a1bf2867c.svg
          fullname: Raymond Ng
          isHf: false
          isPro: false
          name: RaymondAISG
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;jahhs0n&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/jahhs0n\">@<span class=\"\
          underline\">jahhs0n</span></a></span>\n\n\t</span></span> ,<br>I'm glad\
          \ the notebook is helpful for you.<br>Unfortunately, I've made a mistake\
          \ with uploading the wrong tokenizer files for the SEA-LION tokenizer.</p>\n\
          <p>I've now replaced it with the correct files and have double checked it\
          \ from my side. Kindly checkout the latest files for the correct files.\
          \ My apologies for the mistake.<br><a rel=\"nofollow\" href=\"https://github.com/aisingapore/sealion/tree/fasttokenizer/tokenizer/sealion_fasttokenizer\"\
          >https://github.com/aisingapore/sealion/tree/fasttokenizer/tokenizer/sealion_fasttokenizer</a></p>\n\
          <p>Thank you!</p>\n"
        raw: 'Hi @jahhs0n ,

          I''m glad the notebook is helpful for you.

          Unfortunately, I''ve made a mistake with uploading the wrong tokenizer files
          for the SEA-LION tokenizer.


          I''ve now replaced it with the correct files and have double checked it
          from my side. Kindly checkout the latest files for the correct files. My
          apologies for the mistake.

          https://github.com/aisingapore/sealion/tree/fasttokenizer/tokenizer/sealion_fasttokenizer


          Thank you!'
        updatedAt: '2023-12-12T01:44:07.023Z'
      numEdits: 0
      reactions: []
    id: 6577bae7283d9184133be26b
    type: comment
  author: RaymondAISG
  content: 'Hi @jahhs0n ,

    I''m glad the notebook is helpful for you.

    Unfortunately, I''ve made a mistake with uploading the wrong tokenizer files for
    the SEA-LION tokenizer.


    I''ve now replaced it with the correct files and have double checked it from my
    side. Kindly checkout the latest files for the correct files. My apologies for
    the mistake.

    https://github.com/aisingapore/sealion/tree/fasttokenizer/tokenizer/sealion_fasttokenizer


    Thank you!'
  created_at: 2023-12-12 01:44:07+00:00
  edited: false
  hidden: false
  id: 6577bae7283d9184133be26b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: aisingapore/sealion7b-instruct-nc
repo_type: model
status: closed
target_branch: null
title: Any plans to convert tokenizer into a Fast Tokenizer class?
