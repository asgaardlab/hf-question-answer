!!python/object:huggingface_hub.community.DiscussionWithDetails
author: neil268
conflicting_files: null
created_at: 2022-08-11 01:06:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c13ba1aefb85fad1992c8523fc1750b6.svg
      fullname: Neil Narciso Fabiao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: neil268
      type: user
    createdAt: '2022-08-11T02:06:36.000Z'
    data:
      edited: false
      editors:
      - neil268
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c13ba1aefb85fad1992c8523fc1750b6.svg
          fullname: Neil Narciso Fabiao
          isHf: false
          isPro: false
          name: neil268
          type: user
        html: "<p>Hie <span data-props=\"{&quot;user&quot;:&quot;ccdv&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ccdv\">@<span class=\"\
          underline\">ccdv</span></a></span>\n\n\t</span></span> -really enjoyed the\
          \ BART-Base PubMed fine tuning! The performance of the models is still consistent\
          \ on other topics.</p>\n<p>Would like to know if the Local + Sparse + Global\
          \ attention (LSG) paper is avaliable and how to reference it ?</p>\n"
        raw: "Hie @ccdv -really enjoyed the BART-Base PubMed fine tuning! The performance\
          \ of the models is still consistent on other topics.\r\n\r\nWould like to\
          \ know if the Local + Sparse + Global attention (LSG) paper is avaliable\
          \ and how to reference it ?"
        updatedAt: '2022-08-11T02:06:36.778Z'
      numEdits: 0
      reactions: []
    id: 62f4642c91d3a1d1e4fcfc85
    type: comment
  author: neil268
  content: "Hie @ccdv -really enjoyed the BART-Base PubMed fine tuning! The performance\
    \ of the models is still consistent on other topics.\r\n\r\nWould like to know\
    \ if the Local + Sparse + Global attention (LSG) paper is avaliable and how to\
    \ reference it ?"
  created_at: 2022-08-11 01:06:36+00:00
  edited: false
  hidden: false
  id: 62f4642c91d3a1d1e4fcfc85
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659877476012-616f3a4cf92cbd8e03c1d541.jpeg?w=200&h=200&f=face
      fullname: ccdv
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ccdv
      type: user
    createdAt: '2022-08-11T09:19:04.000Z'
    data:
      edited: false
      editors:
      - ccdv
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659877476012-616f3a4cf92cbd8e03c1d541.jpeg?w=200&h=200&f=face
          fullname: ccdv
          isHf: false
          isPro: false
          name: ccdv
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;neil268&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/neil268\">@<span class=\"\
          underline\">neil268</span></a></span>\n\n\t</span></span><br>The paper is\
          \ currently under anonymized review and not available right now.<br>You\
          \ can reference this <a rel=\"nofollow\" href=\"https://github.com/ccdv-ai/convert_checkpoint_to_lsg\"\
          >repo</a> if you really want to reference something.</p>\n"
        raw: "Hi @neil268 \nThe paper is currently under anonymized review and not\
          \ available right now.\nYou can reference this [repo](https://github.com/ccdv-ai/convert_checkpoint_to_lsg)\
          \ if you really want to reference something."
        updatedAt: '2022-08-11T09:19:04.549Z'
      numEdits: 0
      reactions: []
    id: 62f4c988ea5bd6b1abc059fb
    type: comment
  author: ccdv
  content: "Hi @neil268 \nThe paper is currently under anonymized review and not available\
    \ right now.\nYou can reference this [repo](https://github.com/ccdv-ai/convert_checkpoint_to_lsg)\
    \ if you really want to reference something."
  created_at: 2022-08-11 08:19:04+00:00
  edited: false
  hidden: false
  id: 62f4c988ea5bd6b1abc059fb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c13ba1aefb85fad1992c8523fc1750b6.svg
      fullname: Neil Narciso Fabiao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: neil268
      type: user
    createdAt: '2022-08-11T16:02:09.000Z'
    data:
      edited: true
      editors:
      - neil268
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c13ba1aefb85fad1992c8523fc1750b6.svg
          fullname: Neil Narciso Fabiao
          isHf: false
          isPro: false
          name: neil268
          type: user
        html: "<p>Hie <span data-props=\"{&quot;user&quot;:&quot;ccdv&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ccdv\">@<span class=\"\
          underline\">ccdv</span></a></span>\n\n\t</span></span> </p>\n<p>Thanks for\
          \ the quick reply :) will do that ! The last query is on understanding how\
          \ LSG differs from the big bird architecture (<a href=\"https://huggingface.co/blog/big-bird\"\
          >https://huggingface.co/blog/big-bird</a>). Is the main difference in random\
          \ key blocks ?</p>\n"
        raw: "Hie @ccdv \n\nThanks for the quick reply :) will do that ! The last\
          \ query is on understanding how LSG differs from the big bird architecture\
          \ (https://huggingface.co/blog/big-bird). Is the main difference in random\
          \ key blocks ?"
        updatedAt: '2022-08-11T16:06:58.022Z'
      numEdits: 4
      reactions: []
      relatedEventId: 62f52801b5673ac3f5200f86
    id: 62f52801b5673ac3f5200f85
    type: comment
  author: neil268
  content: "Hie @ccdv \n\nThanks for the quick reply :) will do that ! The last query\
    \ is on understanding how LSG differs from the big bird architecture (https://huggingface.co/blog/big-bird).\
    \ Is the main difference in random key blocks ?"
  created_at: 2022-08-11 15:02:09+00:00
  edited: true
  hidden: false
  id: 62f52801b5673ac3f5200f85
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/c13ba1aefb85fad1992c8523fc1750b6.svg
      fullname: Neil Narciso Fabiao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: neil268
      type: user
    createdAt: '2022-08-11T16:02:09.000Z'
    data:
      status: closed
    id: 62f52801b5673ac3f5200f86
    type: status-change
  author: neil268
  created_at: 2022-08-11 15:02:09+00:00
  id: 62f52801b5673ac3f5200f86
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/c13ba1aefb85fad1992c8523fc1750b6.svg
      fullname: Neil Narciso Fabiao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: neil268
      type: user
    createdAt: '2022-08-11T16:06:21.000Z'
    data:
      status: open
    id: 62f528fdea5bd6b1abc329f0
    type: status-change
  author: neil268
  created_at: 2022-08-11 15:06:21+00:00
  id: 62f528fdea5bd6b1abc329f0
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659877476012-616f3a4cf92cbd8e03c1d541.jpeg?w=200&h=200&f=face
      fullname: ccdv
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ccdv
      type: user
    createdAt: '2022-08-11T17:00:10.000Z'
    data:
      edited: false
      editors:
      - ccdv
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659877476012-616f3a4cf92cbd8e03c1d541.jpeg?w=200&h=200&f=face
          fullname: ccdv
          isHf: false
          isPro: false
          name: ccdv
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;neil268&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/neil268\">@<span class=\"\
          underline\">neil268</span></a></span>\n\n\t</span></span><br>BigBird is\
          \ considered as a model/architecture while LSG is more like an attention\
          \ pattern to replace vanilla attention. I use \"LSG\" to refer to the attention\
          \ or models using LSG attention instead of the vanilla (full) one.</p>\n\
          <p>BigBird relies on 3 things:</p>\n<ul>\n<li>block local attention</li>\n\
          <li>random block attention (sparse attention)</li>\n<li>global attention:\
          \ some tokens from the sequence are defined as global. The way they are\
          \ selected is unclear.</li>\n</ul>\n<p>LSG relies on:</p>\n<ul>\n<li>block\
          \ local attention</li>\n<li>extended local attention (sparse attention)\
          \ with various selection schemas. The goal is to expand the context with\
          \ minimal cost and without randomness. Each head is processed independently.\
          \ The best schema is tasks specific and can also be removed.</li>\n<li>global\
          \ attention: global tokens are prepended to the sequence and learnable,\
          \ they are not selected from the sequence.</li>\n</ul>\n<p>Other differences:</p>\n\
          <ul>\n<li>The goal of LSG is to replace vanilla attention for a wide range\
          \ of models for them to process long sequences, we dont want to train something\
          \ from scratch. We want minimal training/fine-tuning for maximum performances.</li>\n\
          <li>LSG has better extrapolation capabilities (e.g training on 4096 tokens\
          \ and doing inference on 16384 tokens)</li>\n<li>LSG has very small performance\
          \ loss when converting an existing model to its LSG variant thanks to the\
          \ way global tokens are initialized.</li>\n<li>LSG (with RoBERTa) is a lot\
          \ faster compared to the HF implementation of BigBird (about +80% training\
          \ speed for a similar model size). Same behavior for summarization models\
          \ (LED/BigBird-Pegasus etc...)</li>\n<li>LSG is more memory efficient</li>\n\
          <li>LSG converges with less training steps because random attention slowdowns\
          \ BigBird and affects inference</li>\n</ul>\n"
        raw: "@neil268 \nBigBird is considered as a model/architecture while LSG is\
          \ more like an attention pattern to replace vanilla attention. I use \"\
          LSG\" to refer to the attention or models using LSG attention instead of\
          \ the vanilla (full) one.\n\nBigBird relies on 3 things:\n* block local\
          \ attention\n* random block attention (sparse attention)\n* global attention:\
          \ some tokens from the sequence are defined as global. The way they are\
          \ selected is unclear.\n\nLSG relies on:\n* block local attention\n* extended\
          \ local attention (sparse attention) with various selection schemas. The\
          \ goal is to expand the context with minimal cost and without randomness.\
          \ Each head is processed independently. The best schema is tasks specific\
          \ and can also be removed.\n* global attention: global tokens are prepended\
          \ to the sequence and learnable, they are not selected from the sequence.\n\
          \nOther differences:\n* The goal of LSG is to replace vanilla attention\
          \ for a wide range of models for them to process long sequences, we dont\
          \ want to train something from scratch. We want minimal training/fine-tuning\
          \ for maximum performances.\n* LSG has better extrapolation capabilities\
          \ (e.g training on 4096 tokens and doing inference on 16384 tokens)\n* LSG\
          \ has very small performance loss when converting an existing model to its\
          \ LSG variant thanks to the way global tokens are initialized.\n* LSG (with\
          \ RoBERTa) is a lot faster compared to the HF implementation of BigBird\
          \ (about +80% training speed for a similar model size). Same behavior for\
          \ summarization models (LED/BigBird-Pegasus etc...)\n* LSG is more memory\
          \ efficient\n* LSG converges with less training steps because random attention\
          \ slowdowns BigBird and affects inference"
        updatedAt: '2022-08-11T17:00:10.035Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - neil268
    id: 62f5359ad6d189cbd2637bd5
    type: comment
  author: ccdv
  content: "@neil268 \nBigBird is considered as a model/architecture while LSG is\
    \ more like an attention pattern to replace vanilla attention. I use \"LSG\" to\
    \ refer to the attention or models using LSG attention instead of the vanilla\
    \ (full) one.\n\nBigBird relies on 3 things:\n* block local attention\n* random\
    \ block attention (sparse attention)\n* global attention: some tokens from the\
    \ sequence are defined as global. The way they are selected is unclear.\n\nLSG\
    \ relies on:\n* block local attention\n* extended local attention (sparse attention)\
    \ with various selection schemas. The goal is to expand the context with minimal\
    \ cost and without randomness. Each head is processed independently. The best\
    \ schema is tasks specific and can also be removed.\n* global attention: global\
    \ tokens are prepended to the sequence and learnable, they are not selected from\
    \ the sequence.\n\nOther differences:\n* The goal of LSG is to replace vanilla\
    \ attention for a wide range of models for them to process long sequences, we\
    \ dont want to train something from scratch. We want minimal training/fine-tuning\
    \ for maximum performances.\n* LSG has better extrapolation capabilities (e.g\
    \ training on 4096 tokens and doing inference on 16384 tokens)\n* LSG has very\
    \ small performance loss when converting an existing model to its LSG variant\
    \ thanks to the way global tokens are initialized.\n* LSG (with RoBERTa) is a\
    \ lot faster compared to the HF implementation of BigBird (about +80% training\
    \ speed for a similar model size). Same behavior for summarization models (LED/BigBird-Pegasus\
    \ etc...)\n* LSG is more memory efficient\n* LSG converges with less training\
    \ steps because random attention slowdowns BigBird and affects inference"
  created_at: 2022-08-11 16:00:10+00:00
  edited: false
  hidden: false
  id: 62f5359ad6d189cbd2637bd5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c13ba1aefb85fad1992c8523fc1750b6.svg
      fullname: Neil Narciso Fabiao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: neil268
      type: user
    createdAt: '2022-08-11T17:23:33.000Z'
    data:
      edited: false
      editors:
      - neil268
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c13ba1aefb85fad1992c8523fc1750b6.svg
          fullname: Neil Narciso Fabiao
          isHf: false
          isPro: false
          name: neil268
          type: user
        html: "<p>Thank you so much for the detailed explanation <span data-props=\"\
          {&quot;user&quot;:&quot;ccdv&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/ccdv\">@<span class=\"underline\">ccdv</span></a></span>\n\
          \n\t</span></span> really looking forward to reading the paper in the near\
          \ future \U0001F917 !</p>\n"
        raw: "Thank you so much for the detailed explanation @ccdv really looking\
          \ forward to reading the paper in the near future \U0001F917 !"
        updatedAt: '2022-08-11T17:23:33.455Z'
      numEdits: 0
      reactions: []
    id: 62f53b15567dbf9a39fb96ee
    type: comment
  author: neil268
  content: "Thank you so much for the detailed explanation @ccdv really looking forward\
    \ to reading the paper in the near future \U0001F917 !"
  created_at: 2022-08-11 16:23:33+00:00
  edited: false
  hidden: false
  id: 62f53b15567dbf9a39fb96ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/c13ba1aefb85fad1992c8523fc1750b6.svg
      fullname: Neil Narciso Fabiao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: neil268
      type: user
    createdAt: '2022-08-11T17:23:38.000Z'
    data:
      status: closed
    id: 62f53b1a2873214eb5f2196f
    type: status-change
  author: neil268
  created_at: 2022-08-11 16:23:38+00:00
  id: 62f53b1a2873214eb5f2196f
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: ccdv/lsg-bart-base-16384-pubmed
repo_type: model
status: closed
target_branch: null
title: LSG implementation
