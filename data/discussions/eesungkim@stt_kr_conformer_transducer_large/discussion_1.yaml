!!python/object:huggingface_hub.community.DiscussionWithDetails
author: smajumdar
conflicting_files: null
created_at: 2022-06-07 16:11:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652937892550-61eb5b2f55d896e8b6c1c376.jpeg?w=200&h=200&f=face
      fullname: Somshubra Majumdar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: smajumdar
      type: user
    createdAt: '2022-06-07T17:11:37.000Z'
    data:
      edited: false
      editors:
      - smajumdar
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652937892550-61eb5b2f55d896e8b6c1c376.jpeg?w=200&h=200&f=face
          fullname: Somshubra Majumdar
          isHf: false
          isPro: false
          name: smajumdar
          type: user
        html: '<p>By following the discussion here and building the model card, you
          can enable the inference widget, so that you can do inference without even
          downloading the model, right from the model page</p>

          <p><a rel="nofollow" href="https://github.com/NVIDIA/NeMo/discussions/4333">https://github.com/NVIDIA/NeMo/discussions/4333</a></p>

          '
        raw: "By following the discussion here and building the model card, you can\
          \ enable the inference widget, so that you can do inference without even\
          \ downloading the model, right from the model page\r\n\r\nhttps://github.com/NVIDIA/NeMo/discussions/4333"
        updatedAt: '2022-06-07T17:11:37.480Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - eesungkim
    id: 629f86c9e462d45c92e6dd34
    type: comment
  author: smajumdar
  content: "By following the discussion here and building the model card, you can\
    \ enable the inference widget, so that you can do inference without even downloading\
    \ the model, right from the model page\r\n\r\nhttps://github.com/NVIDIA/NeMo/discussions/4333"
  created_at: 2022-06-07 16:11:37+00:00
  edited: false
  hidden: false
  id: 629f86c9e462d45c92e6dd34
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658166461474-61df729134b589fbaf2e93d9.jpeg?w=200&h=200&f=face
      fullname: Eesung Kim
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: eesungkim
      type: user
    createdAt: '2022-07-18T18:48:16.000Z'
    data:
      status: closed
    id: 62d5aaf03bf5e059f7cd6213
    type: status-change
  author: eesungkim
  created_at: 2022-07-18 17:48:16+00:00
  id: 62d5aaf03bf5e059f7cd6213
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: eesungkim/stt_kr_conformer_transducer_large
repo_type: model
status: closed
target_branch: null
title: Model card to enable inference widget
