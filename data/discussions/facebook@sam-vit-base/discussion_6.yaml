!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rariwa
conflicting_files: null
created_at: 2023-12-26 18:12:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7f502beee8201f264e17bb8bf7f01bd.svg
      fullname: Ramdhan Ari Wibawa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rariwa
      type: user
    createdAt: '2023-12-26T18:12:59.000Z'
    data:
      edited: true
      editors:
      - rariwa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7670274972915649
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7f502beee8201f264e17bb8bf7f01bd.svg
          fullname: Ramdhan Ari Wibawa
          isHf: false
          isPro: false
          name: rariwa
          type: user
        html: '<p>Hi,<br>I am new in this field. I would like to ask about training
          SAM using prompt. I used this :<br><a rel="nofollow" href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/sam">https://github.com/huggingface/transformers/tree/main/src/transformers/models/sam</a><br>there
          are 4 prompts available boxes, labels, masks, and points. Can I use only
          one of prompt? If I specify boxes, it can run smoothly. When I use masks
          only it gives me error AssertionError: ground truth has different shape
          (torch.Size([14, 1, 256, 256])) from input (torch.Size([1, 1, 256, 256]))
          when calculating loss because the model gives 1 channel instead of 14 (num
          of segmented objects). Similar happened when I used labels only but when
          combined with points it gives me error RuntimeError: Sizes of tensors must
          match except in dimension 2. Expected size 1 but got size 14 for tensor
          number 1 in the list. Running use points only run smoothly.<br>This my shape
          of data feeding into the model<br>pixel_values torch.Size([1, 3, 1024, 1024])<br>input_boxes
          torch.Size([1, 14, 4])<br>input_labels torch.Size([1, 1, 14])<br>input_masks
          torch.Size([1, 256, 256])<br>input_points torch.Size([1, 14, 1, 2])<br>14
          is number of segmented objects. I tried to train instance segmentation for
          single class. </p>

          <p>Thank you</p>

          '
        raw: "Hi, \nI am new in this field. I would like to ask about training SAM\
          \ using prompt. I used this :\nhttps://github.com/huggingface/transformers/tree/main/src/transformers/models/sam\n\
          there are 4 prompts available boxes, labels, masks, and points. Can I use\
          \ only one of prompt? If I specify boxes, it can run smoothly. When I use\
          \ masks only it gives me error AssertionError: ground truth has different\
          \ shape (torch.Size([14, 1, 256, 256])) from input (torch.Size([1, 1, 256,\
          \ 256])) when calculating loss because the model gives 1 channel instead\
          \ of 14 (num of segmented objects). Similar happened when I used labels\
          \ only but when combined with points it gives me error RuntimeError: Sizes\
          \ of tensors must match except in dimension 2. Expected size 1 but got size\
          \ 14 for tensor number 1 in the list. Running use points only run smoothly.\
          \ \nThis my shape of data feeding into the model\npixel_values torch.Size([1,\
          \ 3, 1024, 1024])\ninput_boxes torch.Size([1, 14, 4])\ninput_labels torch.Size([1,\
          \ 1, 14])\ninput_masks torch.Size([1, 256, 256])\ninput_points torch.Size([1,\
          \ 14, 1, 2])\n14 is number of segmented objects. I tried to train instance\
          \ segmentation for single class. \n\nThank you"
        updatedAt: '2023-12-26T18:13:29.030Z'
      numEdits: 1
      reactions: []
    id: 658b17abab4c8f1078c8c69e
    type: comment
  author: rariwa
  content: "Hi, \nI am new in this field. I would like to ask about training SAM using\
    \ prompt. I used this :\nhttps://github.com/huggingface/transformers/tree/main/src/transformers/models/sam\n\
    there are 4 prompts available boxes, labels, masks, and points. Can I use only\
    \ one of prompt? If I specify boxes, it can run smoothly. When I use masks only\
    \ it gives me error AssertionError: ground truth has different shape (torch.Size([14,\
    \ 1, 256, 256])) from input (torch.Size([1, 1, 256, 256])) when calculating loss\
    \ because the model gives 1 channel instead of 14 (num of segmented objects).\
    \ Similar happened when I used labels only but when combined with points it gives\
    \ me error RuntimeError: Sizes of tensors must match except in dimension 2. Expected\
    \ size 1 but got size 14 for tensor number 1 in the list. Running use points only\
    \ run smoothly. \nThis my shape of data feeding into the model\npixel_values torch.Size([1,\
    \ 3, 1024, 1024])\ninput_boxes torch.Size([1, 14, 4])\ninput_labels torch.Size([1,\
    \ 1, 14])\ninput_masks torch.Size([1, 256, 256])\ninput_points torch.Size([1,\
    \ 14, 1, 2])\n14 is number of segmented objects. I tried to train instance segmentation\
    \ for single class. \n\nThank you"
  created_at: 2023-12-26 18:12:59+00:00
  edited: true
  hidden: false
  id: 658b17abab4c8f1078c8c69e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: facebook/sam-vit-base
repo_type: model
status: open
target_branch: null
title: Prompt format for SAM training
