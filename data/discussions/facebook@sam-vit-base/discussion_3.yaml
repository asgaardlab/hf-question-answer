!!python/object:huggingface_hub.community.DiscussionWithDetails
author: abdullahalrafib
conflicting_files: null
created_at: 2023-10-22 10:56:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b5ef347470464b38c39b0bafd8f68003.svg
      fullname: Abdullah Al Rafi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abdullahalrafib
      type: user
    createdAt: '2023-10-22T11:56:23.000Z'
    data:
      edited: false
      editors:
      - abdullahalrafib
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.46772056818008423
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b5ef347470464b38c39b0bafd8f68003.svg
          fullname: Abdullah Al Rafi
          isHf: false
          isPro: false
          name: abdullahalrafib
          type: user
        html: "<h2 id=\"code-snippet\">Code snippet:</h2>\n<pre><code>    import torch\n\
          \    from transformers import SamProcessor, pipeline\n\n    # transformers\
          \ == 4.32.0\n    # torch == 2.0.1\n    # torchaudio == 2.0.2\n    # torchvision\
          \ == 0.15.2\n\n    SAM_NAME = \"facebook/sam-vit-base\"\n    processor =\
          \ SamProcessor.from_pretrained(SAM_NAME)\n    generator = pipeline(\n  \
          \      \"mask-generation\", model=SAM_NAME, device=torch.device(\"cuda\"\
          ), batch_size=len(image_list)) # list of PIL images\n    outputs = generator(image_list)\n\
          </code></pre>\n<h2 id=\"another-approach\">Another approach:</h2>\n<pre><code>\
          \    SAM_NAME = \"facebook/sam-vit-base\"\n    processor = SamProcessor.from_pretrained(SAM_NAME)\n\
          \    generator = pipeline(\n        \"mask-generation\", model=SAM_NAME,\
          \ device=torch.device(\"cuda\"))\n    outputs = generator(image_list, batch_size=len(image_list))\n\
          </code></pre>\n<h2 id=\"error-traceback\">Error traceback:</h2>\n<pre><code>\
          \    outputs = generator(image_list)\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/pipelines/mask_generation.py\"\
          , line 173, in __call__\n    return super().__call__(image, *args, num_workers=num_workers,\
          \ batch_size=batch_size, **kwargs)\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/pipelines/base.py\"\
          , line 1110, in __call__\n    outputs = list(final_iterator)\n  File \"\
          /opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/pipelines/pt_utils.py\"\
          , line 125, in __next__\n    processed = self.infer(item, **self.params)\n\
          \  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/pipelines/mask_generation.py\"\
          , line 276, in postprocess\n    output_masks, iou_scores, rle_mask, bounding_boxes\
          \ = self.image_processor.post_process_for_mask_generation(\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/models/sam/image_processing_sam.py\"\
          , line 554, in post_process_for_mask_generation\n    return _postprocess_for_mg(all_masks,\
          \ all_scores, all_boxes, crops_nms_thresh)\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/models/sam/image_processing_sam.py\"\
          , line 1259, in _postprocess_for_mg\n    masks = [_rle_to_mask(rle) for\
          \ rle in rle_masks]\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/models/sam/image_processing_sam.py\"\
          , line 1259, in &lt;listcomp&gt;\n    masks = [_rle_to_mask(rle) for rle\
          \ in rle_masks]\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/models/sam/image_processing_sam.py\"\
          , line 1223, in _rle_to_mask\n    height, width = rle[\"size\"]\nTypeError:\
          \ string indices must be integers\n</code></pre>\n"
        raw: "## Code snippet:\r\n```\r\n    import torch\r\n    from transformers\
          \ import SamProcessor, pipeline\r\n\r\n    # transformers == 4.32.0\r\n\
          \    # torch == 2.0.1\r\n    # torchaudio == 2.0.2\r\n    # torchvision\
          \ == 0.15.2\r\n\r\n    SAM_NAME = \"facebook/sam-vit-base\"\r\n    processor\
          \ = SamProcessor.from_pretrained(SAM_NAME)\r\n    generator = pipeline(\r\
          \n        \"mask-generation\", model=SAM_NAME, device=torch.device(\"cuda\"\
          ), batch_size=len(image_list)) # list of PIL images\r\n    outputs = generator(image_list)\r\
          \n```\r\n\r\n## Another approach:\r\n\r\n```\r\n    SAM_NAME = \"facebook/sam-vit-base\"\
          \r\n    processor = SamProcessor.from_pretrained(SAM_NAME)\r\n    generator\
          \ = pipeline(\r\n        \"mask-generation\", model=SAM_NAME, device=torch.device(\"\
          cuda\"))\r\n    outputs = generator(image_list, batch_size=len(image_list))\r\
          \n```\r\n\r\n## Error traceback:\r\n```\r\n    outputs = generator(image_list)\r\
          \n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/pipelines/mask_generation.py\"\
          , line 173, in __call__\r\n    return super().__call__(image, *args, num_workers=num_workers,\
          \ batch_size=batch_size, **kwargs)\r\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/pipelines/base.py\"\
          , line 1110, in __call__\r\n    outputs = list(final_iterator)\r\n  File\
          \ \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/pipelines/pt_utils.py\"\
          , line 125, in __next__\r\n    processed = self.infer(item, **self.params)\r\
          \n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/pipelines/mask_generation.py\"\
          , line 276, in postprocess\r\n    output_masks, iou_scores, rle_mask, bounding_boxes\
          \ = self.image_processor.post_process_for_mask_generation(\r\n  File \"\
          /opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/models/sam/image_processing_sam.py\"\
          , line 554, in post_process_for_mask_generation\r\n    return _postprocess_for_mg(all_masks,\
          \ all_scores, all_boxes, crops_nms_thresh)\r\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/models/sam/image_processing_sam.py\"\
          , line 1259, in _postprocess_for_mg\r\n    masks = [_rle_to_mask(rle) for\
          \ rle in rle_masks]\r\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/models/sam/image_processing_sam.py\"\
          , line 1259, in <listcomp>\r\n    masks = [_rle_to_mask(rle) for rle in\
          \ rle_masks]\r\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/models/sam/image_processing_sam.py\"\
          , line 1223, in _rle_to_mask\r\n    height, width = rle[\"size\"]\r\nTypeError:\
          \ string indices must be integers\r\n```"
        updatedAt: '2023-10-22T11:56:23.231Z'
      numEdits: 0
      reactions: []
    id: 65350de79326d6da5f405567
    type: comment
  author: abdullahalrafib
  content: "## Code snippet:\r\n```\r\n    import torch\r\n    from transformers import\
    \ SamProcessor, pipeline\r\n\r\n    # transformers == 4.32.0\r\n    # torch ==\
    \ 2.0.1\r\n    # torchaudio == 2.0.2\r\n    # torchvision == 0.15.2\r\n\r\n  \
    \  SAM_NAME = \"facebook/sam-vit-base\"\r\n    processor = SamProcessor.from_pretrained(SAM_NAME)\r\
    \n    generator = pipeline(\r\n        \"mask-generation\", model=SAM_NAME, device=torch.device(\"\
    cuda\"), batch_size=len(image_list)) # list of PIL images\r\n    outputs = generator(image_list)\r\
    \n```\r\n\r\n## Another approach:\r\n\r\n```\r\n    SAM_NAME = \"facebook/sam-vit-base\"\
    \r\n    processor = SamProcessor.from_pretrained(SAM_NAME)\r\n    generator =\
    \ pipeline(\r\n        \"mask-generation\", model=SAM_NAME, device=torch.device(\"\
    cuda\"))\r\n    outputs = generator(image_list, batch_size=len(image_list))\r\n\
    ```\r\n\r\n## Error traceback:\r\n```\r\n    outputs = generator(image_list)\r\
    \n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/pipelines/mask_generation.py\"\
    , line 173, in __call__\r\n    return super().__call__(image, *args, num_workers=num_workers,\
    \ batch_size=batch_size, **kwargs)\r\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/pipelines/base.py\"\
    , line 1110, in __call__\r\n    outputs = list(final_iterator)\r\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/pipelines/pt_utils.py\"\
    , line 125, in __next__\r\n    processed = self.infer(item, **self.params)\r\n\
    \  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/pipelines/mask_generation.py\"\
    , line 276, in postprocess\r\n    output_masks, iou_scores, rle_mask, bounding_boxes\
    \ = self.image_processor.post_process_for_mask_generation(\r\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/models/sam/image_processing_sam.py\"\
    , line 554, in post_process_for_mask_generation\r\n    return _postprocess_for_mg(all_masks,\
    \ all_scores, all_boxes, crops_nms_thresh)\r\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/models/sam/image_processing_sam.py\"\
    , line 1259, in _postprocess_for_mg\r\n    masks = [_rle_to_mask(rle) for rle\
    \ in rle_masks]\r\n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/models/sam/image_processing_sam.py\"\
    , line 1259, in <listcomp>\r\n    masks = [_rle_to_mask(rle) for rle in rle_masks]\r\
    \n  File \"/opt/anaconda3/envs/venv_yolo/lib/python3.8/site-packages/transformers/models/sam/image_processing_sam.py\"\
    , line 1223, in _rle_to_mask\r\n    height, width = rle[\"size\"]\r\nTypeError:\
    \ string indices must be integers\r\n```"
  created_at: 2023-10-22 10:56:23+00:00
  edited: false
  hidden: false
  id: 65350de79326d6da5f405567
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
      fullname: Lysandre
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lysandre
      type: user
    createdAt: '2023-10-23T13:18:18.000Z'
    data:
      edited: false
      editors:
      - lysandre
      hidden: false
      identifiedLanguage:
        language: tr
        probability: 0.10496710985898972
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
          fullname: Lysandre
          isHf: true
          isPro: false
          name: lysandre
          type: user
        html: "<p>cc <span data-props=\"{&quot;user&quot;:&quot;ybelkada&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ybelkada\"\
          >@<span class=\"underline\">ybelkada</span></a></span>\n\n\t</span></span>\
          \ </p>\n"
        raw: 'cc @ybelkada '
        updatedAt: '2023-10-23T13:18:18.063Z'
      numEdits: 0
      reactions: []
    id: 6536729a0917932040d63d68
    type: comment
  author: lysandre
  content: 'cc @ybelkada '
  created_at: 2023-10-23 12:18:18+00:00
  edited: false
  hidden: false
  id: 6536729a0917932040d63d68
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-10-23T15:52:58.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6580743193626404
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;abdullahalrafib&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/abdullahalrafib\"\
          >@<span class=\"underline\">abdullahalrafib</span></a></span>\n\n\t</span></span><br>Thanks\
          \ for the issue!<br>Can you try on a more recent version of <code>transformers</code>\
          \ ? <code>pip install -U transformers</code><br>The script below:</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span>\
          \ PIL <span class=\"hljs-keyword\">import</span> Image\n<span class=\"hljs-keyword\"\
          >import</span> requests\n<span class=\"hljs-keyword\">from</span> transformers\
          \ <span class=\"hljs-keyword\">import</span> pipeline\n\ngenerator =  pipeline(<span\
          \ class=\"hljs-string\">\"mask-generation\"</span>, device = <span class=\"\
          hljs-number\">0</span>, points_per_batch = <span class=\"hljs-number\">256</span>)\n\
          \nimg_url = <span class=\"hljs-string\">\"https://huggingface.co/ybelkada/segment-anything/resolve/main/assets/car.png\"\
          </span>\nraw_image = Image.<span class=\"hljs-built_in\">open</span>(requests.get(img_url,\
          \ stream=<span class=\"hljs-literal\">True</span>).raw).convert(<span class=\"\
          hljs-string\">\"RGB\"</span>)\n\noutputs = generator([img_url, img_url],\
          \ points_per_batch = <span class=\"hljs-number\">64</span>)\n\noutputs =\
          \ generator([raw_image, raw_image], points_per_batch = <span class=\"hljs-number\"\
          >64</span>)\n</code></pre>\n<p>Worked fine on my end, you could either pass\
          \ a list of PIL images or a list of image URLs</p>\n"
        raw: "Hi @abdullahalrafib \nThanks for the issue! \nCan you try on a more\
          \ recent version of `transformers` ? `pip install -U transformers`\nThe\
          \ script below:\n\n```python\nfrom PIL import Image\nimport requests\nfrom\
          \ transformers import pipeline\n\ngenerator =  pipeline(\"mask-generation\"\
          , device = 0, points_per_batch = 256)\n\nimg_url = \"https://huggingface.co/ybelkada/segment-anything/resolve/main/assets/car.png\"\
          \nraw_image = Image.open(requests.get(img_url, stream=True).raw).convert(\"\
          RGB\")\n\noutputs = generator([img_url, img_url], points_per_batch = 64)\n\
          \noutputs = generator([raw_image, raw_image], points_per_batch = 64)\n```\n\
          \nWorked fine on my end, you could either pass a list of PIL images or a\
          \ list of image URLs"
        updatedAt: '2023-10-23T15:52:58.914Z'
      numEdits: 0
      reactions: []
    id: 653696da29f89004f31d58b0
    type: comment
  author: ybelkada
  content: "Hi @abdullahalrafib \nThanks for the issue! \nCan you try on a more recent\
    \ version of `transformers` ? `pip install -U transformers`\nThe script below:\n\
    \n```python\nfrom PIL import Image\nimport requests\nfrom transformers import\
    \ pipeline\n\ngenerator =  pipeline(\"mask-generation\", device = 0, points_per_batch\
    \ = 256)\n\nimg_url = \"https://huggingface.co/ybelkada/segment-anything/resolve/main/assets/car.png\"\
    \nraw_image = Image.open(requests.get(img_url, stream=True).raw).convert(\"RGB\"\
    )\n\noutputs = generator([img_url, img_url], points_per_batch = 64)\n\noutputs\
    \ = generator([raw_image, raw_image], points_per_batch = 64)\n```\n\nWorked fine\
    \ on my end, you could either pass a list of PIL images or a list of image URLs"
  created_at: 2023-10-23 14:52:58+00:00
  edited: false
  hidden: false
  id: 653696da29f89004f31d58b0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b5ef347470464b38c39b0bafd8f68003.svg
      fullname: Abdullah Al Rafi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abdullahalrafib
      type: user
    createdAt: '2023-10-25T04:34:03.000Z'
    data:
      edited: true
      editors:
      - abdullahalrafib
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8087654113769531
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b5ef347470464b38c39b0bafd8f68003.svg
          fullname: Abdullah Al Rafi
          isHf: false
          isPro: false
          name: abdullahalrafib
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;ybelkada&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ybelkada\"\
          >@<span class=\"underline\">ybelkada</span></a></span>\n\n\t</span></span>\
          \ thank you for your response. I have tried with <code>points_per_batch</code>\
          \ with both <code>transformers==4.32.0</code> &amp; <code>transformers==4.34.1</code>\
          \ it worked fine. But I couldn't find any documentation about it. Could\
          \ you share any link for me please?</p>\n<p><a rel=\"nofollow\" href=\"\
          https://cdn-uploads.huggingface.co/production/uploads/646da20abb95b5d4001f3fe9/V01XKSO4zjXJflZS2dDQA.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/646da20abb95b5d4001f3fe9/V01XKSO4zjXJflZS2dDQA.png\"\
          ></a></p>\n<p>Also, I am getting following warning with average inference\
          \ time <code>1.58s</code> per image(which is a lot) for a list of <code>6</code>\
          \ PIL type images.</p>\n<pre><code>/opt/anaconda3/envs/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:645:\
          \ UserWarning: Length of IterableDataset &lt;transformers.pipelines.pt_utils.PipelineChunkIterator\
          \ object at 0x7f6d4594ca60&gt; was reported to be 6 (when accessing len(dataloader)),\
          \ but 96 samples have been fetched. \n  warnings.warn(warn_msg)\n</code></pre>\n"
        raw: "Hi @ybelkada thank you for your response. I have tried with `points_per_batch`\
          \ with both `transformers==4.32.0` & `transformers==4.34.1` it worked fine.\
          \ But I couldn't find any documentation about it. Could you share any link\
          \ for me please?\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/646da20abb95b5d4001f3fe9/V01XKSO4zjXJflZS2dDQA.png)\n\
          \nAlso, I am getting following warning with average inference time `1.58s`\
          \ per image(which is a lot) for a list of `6` PIL type images.\n\n```\n\
          /opt/anaconda3/envs/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:645:\
          \ UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator\
          \ object at 0x7f6d4594ca60> was reported to be 6 (when accessing len(dataloader)),\
          \ but 96 samples have been fetched. \n  warnings.warn(warn_msg)\n```\n"
        updatedAt: '2023-10-25T04:34:37.928Z'
      numEdits: 1
      reactions: []
    id: 65389abb67325b6218f92719
    type: comment
  author: abdullahalrafib
  content: "Hi @ybelkada thank you for your response. I have tried with `points_per_batch`\
    \ with both `transformers==4.32.0` & `transformers==4.34.1` it worked fine. But\
    \ I couldn't find any documentation about it. Could you share any link for me\
    \ please?\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/646da20abb95b5d4001f3fe9/V01XKSO4zjXJflZS2dDQA.png)\n\
    \nAlso, I am getting following warning with average inference time `1.58s` per\
    \ image(which is a lot) for a list of `6` PIL type images.\n\n```\n/opt/anaconda3/envs/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:645:\
    \ UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator\
    \ object at 0x7f6d4594ca60> was reported to be 6 (when accessing len(dataloader)),\
    \ but 96 samples have been fetched. \n  warnings.warn(warn_msg)\n```\n"
  created_at: 2023-10-25 03:34:03+00:00
  edited: true
  hidden: false
  id: 65389abb67325b6218f92719
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-10-26T12:38:07.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7059551477432251
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;abdullahalrafib&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/abdullahalrafib\"\
          >@<span class=\"underline\">abdullahalrafib</span></a></span>\n\n\t</span></span><br>The\
          \ documentation of that pipeline was missing indeed, please find here: <a\
          \ href=\"https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.MaskGenerationPipeline\"\
          >https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.MaskGenerationPipeline</a>\
          \ the corresponding documentation</p>\n"
        raw: "Hi @abdullahalrafib \nThe documentation of that pipeline was missing\
          \ indeed, please find here: https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.MaskGenerationPipeline\
          \ the corresponding documentation"
        updatedAt: '2023-10-26T12:38:07.548Z'
      numEdits: 0
      reactions: []
    id: 653a5dafeacd31a26d6138a3
    type: comment
  author: ybelkada
  content: "Hi @abdullahalrafib \nThe documentation of that pipeline was missing indeed,\
    \ please find here: https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.MaskGenerationPipeline\
    \ the corresponding documentation"
  created_at: 2023-10-26 11:38:07+00:00
  edited: false
  hidden: false
  id: 653a5dafeacd31a26d6138a3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: facebook/sam-vit-base
repo_type: model
status: open
target_branch: null
title: Batching doesn't work with mask-generation task
