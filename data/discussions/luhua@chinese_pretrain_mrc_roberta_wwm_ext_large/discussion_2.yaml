!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ljwd
conflicting_files: null
created_at: 2023-01-10 06:49:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/54725cdfa3022c4286b7272238222cd4.svg
      fullname: dww
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ljwd
      type: user
    createdAt: '2023-01-10T06:49:01.000Z'
    data:
      edited: false
      editors:
      - ljwd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/54725cdfa3022c4286b7272238222cd4.svg
          fullname: dww
          isHf: false
          isPro: false
          name: ljwd
          type: user
        html: "<p>from transformers import pipeline<br>#\u5148\u4E0B\u8F7D\u201CFiles\
          \ and versions\u201D\u4E2D\u7684\u6A21\u578B\u6587\u4EF6\u5230\u672C\u5730\
          \u201Cpretrained\u201D\u6587\u4EF6\u5939<br>qa = pipeline(task='question-answering',model='pretrained',device=0)<br>res\
          \ = qa(question=[\"\u4F60\u53EB\u4EC0\u4E48\",\"\u4F60\u662F\u8C01\"],context=\u201C\
          \u6211\u662F\u4E8C\u72D7\uFF0C\u6211\u53EB\u6E23\u6E23\u7070\u201D)</p>\n"
        raw: "from transformers import pipeline\r\n#\u5148\u4E0B\u8F7D\u201CFiles\
          \ and versions\u201D\u4E2D\u7684\u6A21\u578B\u6587\u4EF6\u5230\u672C\u5730\
          \u201Cpretrained\u201D\u6587\u4EF6\u5939\r\nqa = pipeline(task='question-answering',model='pretrained',device=0)\r\
          \nres = qa(question=[\"\u4F60\u53EB\u4EC0\u4E48\",\"\u4F60\u662F\u8C01\"\
          ],context=\u201C\u6211\u662F\u4E8C\u72D7\uFF0C\u6211\u53EB\u6E23\u6E23\u7070\
          \u201D)"
        updatedAt: '2023-01-10T06:49:01.911Z'
      numEdits: 0
      reactions: []
    id: 63bd0a5db8c61b8aa4a27abc
    type: comment
  author: ljwd
  content: "from transformers import pipeline\r\n#\u5148\u4E0B\u8F7D\u201CFiles and\
    \ versions\u201D\u4E2D\u7684\u6A21\u578B\u6587\u4EF6\u5230\u672C\u5730\u201Cpretrained\u201D\
    \u6587\u4EF6\u5939\r\nqa = pipeline(task='question-answering',model='pretrained',device=0)\r\
    \nres = qa(question=[\"\u4F60\u53EB\u4EC0\u4E48\",\"\u4F60\u662F\u8C01\"],context=\u201C\
    \u6211\u662F\u4E8C\u72D7\uFF0C\u6211\u53EB\u6E23\u6E23\u7070\u201D)"
  created_at: 2023-01-10 06:49:01+00:00
  edited: false
  hidden: false
  id: 63bd0a5db8c61b8aa4a27abc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1f1dc1c8211f453ca9f21aef993e1168.svg
      fullname: lucky_ab
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luckyab
      type: user
    createdAt: '2023-04-14T16:07:33.000Z'
    data:
      edited: false
      editors:
      - luckyab
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1f1dc1c8211f453ca9f21aef993e1168.svg
          fullname: lucky_ab
          isHf: false
          isPro: false
          name: luckyab
          type: user
        html: "<p>\u4E0A\u9762\u7684\u4EE3\u7801\u6211\u6267\u884C\u62A5\u9519\uFF0C\
          \u5E94\u8BE5\u662F\u6CA1\u6709\u5148\u4E0B\u8F7D\u6A21\u578B\u5230pretrained\u6587\
          \u4EF6\u3002\u6211\u662F\u7528\u4E0B\u9762\u547D\u4EE4\u5728python\u4EA4\
          \u4E92\u547D\u4EE4\u7A97\u53E3\u6267\u884C\u7684\uFF0C\u4F1A\u76F4\u63A5\
          \u4E0B\u8F7D\u6A21\u578B\u3002<br>from transformers import pipeline<br>from\
          \ transformers import AutoTokenizer, AutoModelForQuestionAnswering<br>model_name\
          \ = \"chinese_pretrain_mrc_roberta_wwm_ext_large\"<br>tokenizer = AutoTokenizer.from_pretrained(f\"\
          luhua/{model_name}\")<br>model = AutoModelForQuestionAnswering.from_pretrained(f\"\
          luhua/{model_name}\")<br>qa = pipeline(task='question-answering',model=model,tokenizer=tokenizer)<br>qa(question=[\"\
          \u4F60\u53EB\u4EC0\u4E48\",\"\u4F60\u662F\u8C01\"],context='\u6211\u662F\
          \u4E8C\u72D7\uFF0C\u6211\u53EB\u6E23\u6E23\u7070')</p>\n<p>\u7ED3\u679C\uFF1A\
          <br>[{'score': 0.22574695944786072, 'start': 7, 'end': 10, 'answer': '\u6E23\
          \u6E23\u7070'},<br> {'score': 0.21701981127262115, 'start': 7, 'end': 10,\
          \ 'answer': '\u6E23\u6E23\u7070'}]</p>\n"
        raw: "\u4E0A\u9762\u7684\u4EE3\u7801\u6211\u6267\u884C\u62A5\u9519\uFF0C\u5E94\
          \u8BE5\u662F\u6CA1\u6709\u5148\u4E0B\u8F7D\u6A21\u578B\u5230pretrained\u6587\
          \u4EF6\u3002\u6211\u662F\u7528\u4E0B\u9762\u547D\u4EE4\u5728python\u4EA4\
          \u4E92\u547D\u4EE4\u7A97\u53E3\u6267\u884C\u7684\uFF0C\u4F1A\u76F4\u63A5\
          \u4E0B\u8F7D\u6A21\u578B\u3002\nfrom transformers import pipeline\nfrom\
          \ transformers import AutoTokenizer, AutoModelForQuestionAnswering\nmodel_name\
          \ = \"chinese_pretrain_mrc_roberta_wwm_ext_large\"\ntokenizer = AutoTokenizer.from_pretrained(f\"\
          luhua/{model_name}\")\nmodel = AutoModelForQuestionAnswering.from_pretrained(f\"\
          luhua/{model_name}\")\nqa = pipeline(task='question-answering',model=model,tokenizer=tokenizer)\n\
          qa(question=[\"\u4F60\u53EB\u4EC0\u4E48\",\"\u4F60\u662F\u8C01\"],context='\u6211\
          \u662F\u4E8C\u72D7\uFF0C\u6211\u53EB\u6E23\u6E23\u7070')\n\n\u7ED3\u679C\
          \uFF1A\n[{'score': 0.22574695944786072, 'start': 7, 'end': 10, 'answer':\
          \ '\u6E23\u6E23\u7070'},\n {'score': 0.21701981127262115, 'start': 7, 'end':\
          \ 10, 'answer': '\u6E23\u6E23\u7070'}]"
        updatedAt: '2023-04-14T16:07:33.514Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - dkgee
    id: 64397a45eb983fe610bf376d
    type: comment
  author: luckyab
  content: "\u4E0A\u9762\u7684\u4EE3\u7801\u6211\u6267\u884C\u62A5\u9519\uFF0C\u5E94\
    \u8BE5\u662F\u6CA1\u6709\u5148\u4E0B\u8F7D\u6A21\u578B\u5230pretrained\u6587\u4EF6\
    \u3002\u6211\u662F\u7528\u4E0B\u9762\u547D\u4EE4\u5728python\u4EA4\u4E92\u547D\
    \u4EE4\u7A97\u53E3\u6267\u884C\u7684\uFF0C\u4F1A\u76F4\u63A5\u4E0B\u8F7D\u6A21\
    \u578B\u3002\nfrom transformers import pipeline\nfrom transformers import AutoTokenizer,\
    \ AutoModelForQuestionAnswering\nmodel_name = \"chinese_pretrain_mrc_roberta_wwm_ext_large\"\
    \ntokenizer = AutoTokenizer.from_pretrained(f\"luhua/{model_name}\")\nmodel =\
    \ AutoModelForQuestionAnswering.from_pretrained(f\"luhua/{model_name}\")\nqa =\
    \ pipeline(task='question-answering',model=model,tokenizer=tokenizer)\nqa(question=[\"\
    \u4F60\u53EB\u4EC0\u4E48\",\"\u4F60\u662F\u8C01\"],context='\u6211\u662F\u4E8C\
    \u72D7\uFF0C\u6211\u53EB\u6E23\u6E23\u7070')\n\n\u7ED3\u679C\uFF1A\n[{'score':\
    \ 0.22574695944786072, 'start': 7, 'end': 10, 'answer': '\u6E23\u6E23\u7070'},\n\
    \ {'score': 0.21701981127262115, 'start': 7, 'end': 10, 'answer': '\u6E23\u6E23\
    \u7070'}]"
  created_at: 2023-04-14 15:07:33+00:00
  edited: false
  hidden: false
  id: 64397a45eb983fe610bf376d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: luhua/chinese_pretrain_mrc_roberta_wwm_ext_large
repo_type: model
status: open
target_branch: null
title: "\u8FD9\u6A21\u578B\u9760\u8C31"
