!!python/object:huggingface_hub.community.DiscussionWithDetails
author: longquan
conflicting_files: null
created_at: 2023-08-16 13:47:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acc2b650f8780d55c50a5ea3c4ee6499.svg
      fullname: qiulongquan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: longquan
      type: user
    createdAt: '2023-08-16T14:47:03.000Z'
    data:
      edited: false
      editors:
      - longquan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.49507513642311096
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acc2b650f8780d55c50a5ea3c4ee6499.svg
          fullname: qiulongquan
          isHf: false
          isPro: true
          name: longquan
          type: user
        html: "<p>sagemaker configuration information.<br>  'HF_MODEL_ID':'Sparticle/llama-2-7b-chat-japanese-lora',<br>\
          \  'HF_TASK':'question-answering'<br>Configured as a QA quiz</p>\n<pre><code>from\
          \ sagemaker.huggingface import HuggingFaceModel\n\n# Hub Model configuration.\
          \ https://huggingface.co/models\nhub = {\n  'HF_MODEL_ID':'Sparticle/llama-2-7b-chat-japanese-lora',\
          \ # model_id from hf.co/models\n  'HF_TASK':'question-answering' # NLP task\
          \ you want to use for predictions\n}\n\n# create Hugging Face Model Class\n\
          huggingface_model = HuggingFaceModel(\n   env=hub,\n   role=role, # iam\
          \ role with permissions to create an Endpoint\n   transformers_version=\"\
          4.26\", # transformers version used\n   pytorch_version=\"1.13\", # pytorch\
          \ version used\n   py_version=\"py39\", # python version of the DLC\n)\n\
          </code></pre>\n<p>Error information</p>\n<pre><code>ModelError         \
          \                       Traceback (most recent call last)\nCell In[25],\
          \ line 5\n      2 data = {\"inputs\": {\"question\": \"\u65E5\u672C\u306E\
          \u9996\u90FD\u306F\u3069\u3053\u3067\u3059\u304B?\",\"context\": \"\u65E5\
          \u672C\u306E\u9996\u90FD\u306F\u6771\u4EAC\u3067\u3059\u3002\"}}\n     \
          \ 4 # request\n----&gt; 5 predictor.predict(data)\n\nFile ~/SageMaker/.cs/conda/envs/codeserver_py39/lib/python3.9/site-packages/sagemaker/base_predictor.py:185,\
          \ in Predictor.predict(self, data, initial_args, target_model, target_variant,\
          \ inference_id, custom_attributes)\n    138 \"\"\"Return the inference from\
          \ the specified endpoint.\n    139 \n    140 Args:\n   (...)\n    174  \
          \       as is.\n    175 \"\"\"\n    177 request_args = self._create_request_args(\n\
          \    178     data,\n    179     initial_args,\n   (...)\n    183     custom_attributes,\n\
          \    184 )\n--&gt; 185 response = self.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**request_args)\n\
          \    186 return self._handle_response(response)\n\nFile ~/SageMaker/.cs/conda/envs/codeserver_py39/lib/python3.9/site-packages/botocore/client.py:535,\
          \ in ClientCreator._create_api_method.._api_call(self, *args, **kwargs)\n\
          \    531     raise TypeError(\n...\n  \"code\": 400,\n  \"type\": \"InternalServerException\"\
          ,\n  \"message\": \"/.sagemaker/mms/models/Sparticle__llama-2-7b-chat-japanese-lora\
          \ does not appear to have a file named config.json. Checkout \\u0027https://huggingface.co//.sagemaker/mms/models/Sparticle__llama-2-7b-chat-japanese-lora/None\\\
          u0027 for available files.\"\n}\n</code></pre>\n<p>It seems that the path\
          \ is incorrect and the config.json file cannot be found<br>Any help with\
          \ this would be greatly appreciated!</p>\n"
        raw: "sagemaker configuration information.\r\n  'HF_MODEL_ID':'Sparticle/llama-2-7b-chat-japanese-lora',\r\
          \n  'HF_TASK':'question-answering' \r\nConfigured as a QA quiz\r\n```\r\n\
          from sagemaker.huggingface import HuggingFaceModel\r\n\r\n# Hub Model configuration.\
          \ https://huggingface.co/models\r\nhub = {\r\n  'HF_MODEL_ID':'Sparticle/llama-2-7b-chat-japanese-lora',\
          \ # model_id from hf.co/models\r\n  'HF_TASK':'question-answering' # NLP\
          \ task you want to use for predictions\r\n}\r\n\r\n# create Hugging Face\
          \ Model Class\r\nhuggingface_model = HuggingFaceModel(\r\n   env=hub,\r\n\
          \   role=role, # iam role with permissions to create an Endpoint\r\n   transformers_version=\"\
          4.26\", # transformers version used\r\n   pytorch_version=\"1.13\", # pytorch\
          \ version used\r\n   py_version=\"py39\", # python version of the DLC\r\n\
          )\r\n```\r\n\r\nError information\r\n```\r\nModelError                 \
          \               Traceback (most recent call last)\r\nCell In[25], line 5\r\
          \n      2 data = {\"inputs\": {\"question\": \"\u65E5\u672C\u306E\u9996\u90FD\
          \u306F\u3069\u3053\u3067\u3059\u304B?\",\"context\": \"\u65E5\u672C\u306E\
          \u9996\u90FD\u306F\u6771\u4EAC\u3067\u3059\u3002\"}}\r\n      4 # request\r\
          \n----> 5 predictor.predict(data)\r\n\r\nFile ~/SageMaker/.cs/conda/envs/codeserver_py39/lib/python3.9/site-packages/sagemaker/base_predictor.py:185,\
          \ in Predictor.predict(self, data, initial_args, target_model, target_variant,\
          \ inference_id, custom_attributes)\r\n    138 \"\"\"Return the inference\
          \ from the specified endpoint.\r\n    139 \r\n    140 Args:\r\n   (...)\r\
          \n    174         as is.\r\n    175 \"\"\"\r\n    177 request_args = self._create_request_args(\r\
          \n    178     data,\r\n    179     initial_args,\r\n   (...)\r\n    183\
          \     custom_attributes,\r\n    184 )\r\n--> 185 response = self.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**request_args)\r\
          \n    186 return self._handle_response(response)\r\n\r\nFile ~/SageMaker/.cs/conda/envs/codeserver_py39/lib/python3.9/site-packages/botocore/client.py:535,\
          \ in ClientCreator._create_api_method.._api_call(self, *args, **kwargs)\r\
          \n    531     raise TypeError(\r\n...\r\n  \"code\": 400,\r\n  \"type\"\
          : \"InternalServerException\",\r\n  \"message\": \"/.sagemaker/mms/models/Sparticle__llama-2-7b-chat-japanese-lora\
          \ does not appear to have a file named config.json. Checkout \\u0027https://huggingface.co//.sagemaker/mms/models/Sparticle__llama-2-7b-chat-japanese-lora/None\\\
          u0027 for available files.\"\r\n}\r\n```\r\n\r\nIt seems that the path is\
          \ incorrect and the config.json file cannot be found\r\nAny help with this\
          \ would be greatly appreciated!\r\n"
        updatedAt: '2023-08-16T14:47:03.176Z'
      numEdits: 0
      reactions: []
    id: 64dce167fc78c816e8450b20
    type: comment
  author: longquan
  content: "sagemaker configuration information.\r\n  'HF_MODEL_ID':'Sparticle/llama-2-7b-chat-japanese-lora',\r\
    \n  'HF_TASK':'question-answering' \r\nConfigured as a QA quiz\r\n```\r\nfrom\
    \ sagemaker.huggingface import HuggingFaceModel\r\n\r\n# Hub Model configuration.\
    \ https://huggingface.co/models\r\nhub = {\r\n  'HF_MODEL_ID':'Sparticle/llama-2-7b-chat-japanese-lora',\
    \ # model_id from hf.co/models\r\n  'HF_TASK':'question-answering' # NLP task\
    \ you want to use for predictions\r\n}\r\n\r\n# create Hugging Face Model Class\r\
    \nhuggingface_model = HuggingFaceModel(\r\n   env=hub,\r\n   role=role, # iam\
    \ role with permissions to create an Endpoint\r\n   transformers_version=\"4.26\"\
    , # transformers version used\r\n   pytorch_version=\"1.13\", # pytorch version\
    \ used\r\n   py_version=\"py39\", # python version of the DLC\r\n)\r\n```\r\n\r\
    \nError information\r\n```\r\nModelError                                Traceback\
    \ (most recent call last)\r\nCell In[25], line 5\r\n      2 data = {\"inputs\"\
    : {\"question\": \"\u65E5\u672C\u306E\u9996\u90FD\u306F\u3069\u3053\u3067\u3059\
    \u304B?\",\"context\": \"\u65E5\u672C\u306E\u9996\u90FD\u306F\u6771\u4EAC\u3067\
    \u3059\u3002\"}}\r\n      4 # request\r\n----> 5 predictor.predict(data)\r\n\r\
    \nFile ~/SageMaker/.cs/conda/envs/codeserver_py39/lib/python3.9/site-packages/sagemaker/base_predictor.py:185,\
    \ in Predictor.predict(self, data, initial_args, target_model, target_variant,\
    \ inference_id, custom_attributes)\r\n    138 \"\"\"Return the inference from\
    \ the specified endpoint.\r\n    139 \r\n    140 Args:\r\n   (...)\r\n    174\
    \         as is.\r\n    175 \"\"\"\r\n    177 request_args = self._create_request_args(\r\
    \n    178     data,\r\n    179     initial_args,\r\n   (...)\r\n    183     custom_attributes,\r\
    \n    184 )\r\n--> 185 response = self.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**request_args)\r\
    \n    186 return self._handle_response(response)\r\n\r\nFile ~/SageMaker/.cs/conda/envs/codeserver_py39/lib/python3.9/site-packages/botocore/client.py:535,\
    \ in ClientCreator._create_api_method.._api_call(self, *args, **kwargs)\r\n  \
    \  531     raise TypeError(\r\n...\r\n  \"code\": 400,\r\n  \"type\": \"InternalServerException\"\
    ,\r\n  \"message\": \"/.sagemaker/mms/models/Sparticle__llama-2-7b-chat-japanese-lora\
    \ does not appear to have a file named config.json. Checkout \\u0027https://huggingface.co//.sagemaker/mms/models/Sparticle__llama-2-7b-chat-japanese-lora/None\\\
    u0027 for available files.\"\r\n}\r\n```\r\n\r\nIt seems that the path is incorrect\
    \ and the config.json file cannot be found\r\nAny help with this would be greatly\
    \ appreciated!\r\n"
  created_at: 2023-08-16 13:47:03+00:00
  edited: false
  hidden: false
  id: 64dce167fc78c816e8450b20
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fcb02ccf704d60ffb3b2c/WVTDnRxhYpP4bX80WDes1.jpeg?w=200&h=200&f=face
      fullname: Zhao Zitian
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: zhaozitian
      type: user
    createdAt: '2023-08-16T15:06:46.000Z'
    data:
      edited: false
      editors:
      - zhaozitian
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9010863900184631
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fcb02ccf704d60ffb3b2c/WVTDnRxhYpP4bX80WDes1.jpeg?w=200&h=200&f=face
          fullname: Zhao Zitian
          isHf: false
          isPro: false
          name: zhaozitian
          type: user
        html: '<p>Hi,<br>This is a LoRA adapter file, not a whole model, thus it has
          an adapter_config.json instead of config.json.<br>It must be used with Llama-2-7b-chat-hf
          model by Meta and cannot be used alone. Please refer to (<a rel="nofollow"
          href="https://github.com/tloen/alpaca-lora">https://github.com/tloen/alpaca-lora</a>)
          to see how to run this model.</p>

          '
        raw: 'Hi,

          This is a LoRA adapter file, not a whole model, thus it has an adapter_config.json
          instead of config.json.

          It must be used with Llama-2-7b-chat-hf model by Meta and cannot be used
          alone. Please refer to (https://github.com/tloen/alpaca-lora) to see how
          to run this model.'
        updatedAt: '2023-08-16T15:06:46.563Z'
      numEdits: 0
      reactions: []
    id: 64dce60630bd3fef69652abe
    type: comment
  author: zhaozitian
  content: 'Hi,

    This is a LoRA adapter file, not a whole model, thus it has an adapter_config.json
    instead of config.json.

    It must be used with Llama-2-7b-chat-hf model by Meta and cannot be used alone.
    Please refer to (https://github.com/tloen/alpaca-lora) to see how to run this
    model.'
  created_at: 2023-08-16 14:06:46+00:00
  edited: false
  hidden: false
  id: 64dce60630bd3fef69652abe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acc2b650f8780d55c50a5ea3c4ee6499.svg
      fullname: qiulongquan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: longquan
      type: user
    createdAt: '2023-08-16T16:08:29.000Z'
    data:
      edited: true
      editors:
      - longquan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9459027647972107
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acc2b650f8780d55c50a5ea3c4ee6499.svg
          fullname: qiulongquan
          isHf: false
          isPro: true
          name: longquan
          type: user
        html: '<p>Thanks for the quick reply, I have found out that LoRA adapter file
          is just a small auxiliary model that needs to be used in conjunction with
          Llama-2-7b-chat-hf, I will refer to the information you provided <a rel="nofollow"
          href="https://github.com/tloen/alpaca-lora">https://github.com/tloen/alpaca-lora</a></p>

          '
        raw: Thanks for the quick reply, I have found out that LoRA adapter file is
          just a small auxiliary model that needs to be used in conjunction with Llama-2-7b-chat-hf,
          I will refer to the information you provided https://github.com/tloen/alpaca-lora
        updatedAt: '2023-08-16T16:09:07.958Z'
      numEdits: 1
      reactions: []
    id: 64dcf47d30bd3fef6967db6d
    type: comment
  author: longquan
  content: Thanks for the quick reply, I have found out that LoRA adapter file is
    just a small auxiliary model that needs to be used in conjunction with Llama-2-7b-chat-hf,
    I will refer to the information you provided https://github.com/tloen/alpaca-lora
  created_at: 2023-08-16 15:08:29+00:00
  edited: true
  hidden: false
  id: 64dcf47d30bd3fef6967db6d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/acc2b650f8780d55c50a5ea3c4ee6499.svg
      fullname: qiulongquan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: longquan
      type: user
    createdAt: '2023-08-16T16:09:18.000Z'
    data:
      status: closed
    id: 64dcf4ae394a023753cfea4d
    type: status-change
  author: longquan
  created_at: 2023-08-16 15:09:18+00:00
  id: 64dcf4ae394a023753cfea4d
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/acc2b650f8780d55c50a5ea3c4ee6499.svg
      fullname: qiulongquan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: longquan
      type: user
    createdAt: '2023-08-16T16:09:26.000Z'
    data:
      status: open
    id: 64dcf4b62d585b7d35f65ae1
    type: status-change
  author: longquan
  created_at: 2023-08-16 15:09:26+00:00
  id: 64dcf4b62d585b7d35f65ae1
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acc2b650f8780d55c50a5ea3c4ee6499.svg
      fullname: qiulongquan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: longquan
      type: user
    createdAt: '2023-08-17T10:16:52.000Z'
    data:
      edited: true
      editors:
      - longquan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9486907720565796
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acc2b650f8780d55c50a5ea3c4ee6499.svg
          fullname: qiulongquan
          isHf: false
          isPro: true
          name: longquan
          type: user
        html: '<p>Thank you very much for your help, I''ve reproduced the model generation<br>I
          want to train the lora model by taking the customized Japanese dataset finetune
          way, merging the customized dataset with the current [izumi-lab/llm-japanese-dataset]
          dataset and then train the lora model by the method provided by [alpaca-lora],
          would you think that is correct, and thank you very much if you can provide
          guidance!</p>

          '
        raw: 'Thank you very much for your help, I''ve reproduced the model generation

          I want to train the lora model by taking the customized Japanese dataset
          finetune way, merging the customized dataset with the current [izumi-lab/llm-japanese-dataset]
          dataset and then train the lora model by the method provided by [alpaca-lora],
          would you think that is correct, and thank you very much if you can provide
          guidance!'
        updatedAt: '2023-08-17T10:19:15.173Z'
      numEdits: 2
      reactions: []
    id: 64ddf394808492ba6e5fd74c
    type: comment
  author: longquan
  content: 'Thank you very much for your help, I''ve reproduced the model generation

    I want to train the lora model by taking the customized Japanese dataset finetune
    way, merging the customized dataset with the current [izumi-lab/llm-japanese-dataset]
    dataset and then train the lora model by the method provided by [alpaca-lora],
    would you think that is correct, and thank you very much if you can provide guidance!'
  created_at: 2023-08-17 09:16:52+00:00
  edited: true
  hidden: false
  id: 64ddf394808492ba6e5fd74c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fcb02ccf704d60ffb3b2c/WVTDnRxhYpP4bX80WDes1.jpeg?w=200&h=200&f=face
      fullname: Zhao Zitian
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: zhaozitian
      type: user
    createdAt: '2023-08-17T10:27:04.000Z'
    data:
      edited: false
      editors:
      - zhaozitian
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9642113447189331
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fcb02ccf704d60ffb3b2c/WVTDnRxhYpP4bX80WDes1.jpeg?w=200&h=200&f=face
          fullname: Zhao Zitian
          isHf: false
          isPro: false
          name: zhaozitian
          type: user
        html: '<p>Hi,<br>It is hard to predict if a finetuned model would perform
          well or not before you finish training it, and it is also hard to tell if
          a training paradigm is ''normal'' or not without actually doing it by oneself.
          My advice is to be careful about the compatibility of the liscences of datasets
          when merging them. Good luck with your endeavours.</p>

          '
        raw: 'Hi,

          It is hard to predict if a finetuned model would perform well or not before
          you finish training it, and it is also hard to tell if a training paradigm
          is ''normal'' or not without actually doing it by oneself. My advice is
          to be careful about the compatibility of the liscences of datasets when
          merging them. Good luck with your endeavours.'
        updatedAt: '2023-08-17T10:27:04.802Z'
      numEdits: 0
      reactions: []
    id: 64ddf5f8d27135dd5648c87a
    type: comment
  author: zhaozitian
  content: 'Hi,

    It is hard to predict if a finetuned model would perform well or not before you
    finish training it, and it is also hard to tell if a training paradigm is ''normal''
    or not without actually doing it by oneself. My advice is to be careful about
    the compatibility of the liscences of datasets when merging them. Good luck with
    your endeavours.'
  created_at: 2023-08-17 09:27:04+00:00
  edited: false
  hidden: false
  id: 64ddf5f8d27135dd5648c87a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acc2b650f8780d55c50a5ea3c4ee6499.svg
      fullname: qiulongquan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: longquan
      type: user
    createdAt: '2023-08-17T12:41:38.000Z'
    data:
      edited: false
      editors:
      - longquan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8978463411331177
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acc2b650f8780d55c50a5ea3c4ee6499.svg
          fullname: qiulongquan
          isHf: false
          isPro: true
          name: longquan
          type: user
        html: '<p>Thanks for your suggestion,<br>Could you provide the configuration
          of the machine you are training[Sparticle/llama-2-13b-chat-japanese-lora]
          on (GPU model and number and video memory size), hyperparameters for training,
          and spend training time.</p>

          '
        raw: 'Thanks for your suggestion,

          Could you provide the configuration of the machine you are training[Sparticle/llama-2-13b-chat-japanese-lora]
          on (GPU model and number and video memory size), hyperparameters for training,
          and spend training time.'
        updatedAt: '2023-08-17T12:41:38.862Z'
      numEdits: 0
      reactions: []
    id: 64de15828761a0f3027d1bf1
    type: comment
  author: longquan
  content: 'Thanks for your suggestion,

    Could you provide the configuration of the machine you are training[Sparticle/llama-2-13b-chat-japanese-lora]
    on (GPU model and number and video memory size), hyperparameters for training,
    and spend training time.'
  created_at: 2023-08-17 11:41:38+00:00
  edited: false
  hidden: false
  id: 64de15828761a0f3027d1bf1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acc2b650f8780d55c50a5ea3c4ee6499.svg
      fullname: qiulongquan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: longquan
      type: user
    createdAt: '2023-08-19T02:32:19.000Z'
    data:
      edited: false
      editors:
      - longquan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9204208850860596
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acc2b650f8780d55c50a5ea3c4ee6499.svg
          fullname: qiulongquan
          isHf: false
          isPro: true
          name: longquan
          type: user
        html: '<p>Hi,<br>Could you provide the configuration of the machine you are
          trained[Sparticle/llama-2-13b-chat-japanese-lora] on (GPU model and number
          and video memory size), config hyperparameters for training, and spend training
          time.<br>We are training LoRA models like [Sparticle/llama-2-13b-chat-japanese-lora]
          and would like to get information about your trained.</p>

          '
        raw: 'Hi,

          Could you provide the configuration of the machine you are trained[Sparticle/llama-2-13b-chat-japanese-lora]
          on (GPU model and number and video memory size), config hyperparameters
          for training, and spend training time.

          We are training LoRA models like [Sparticle/llama-2-13b-chat-japanese-lora]
          and would like to get information about your trained.'
        updatedAt: '2023-08-19T02:32:19.158Z'
      numEdits: 0
      reactions: []
    id: 64e029b353e858b0eda42b2a
    type: comment
  author: longquan
  content: 'Hi,

    Could you provide the configuration of the machine you are trained[Sparticle/llama-2-13b-chat-japanese-lora]
    on (GPU model and number and video memory size), config hyperparameters for training,
    and spend training time.

    We are training LoRA models like [Sparticle/llama-2-13b-chat-japanese-lora] and
    would like to get information about your trained.'
  created_at: 2023-08-19 01:32:19+00:00
  edited: false
  hidden: false
  id: 64e029b353e858b0eda42b2a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/acc2b650f8780d55c50a5ea3c4ee6499.svg
      fullname: qiulongquan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: longquan
      type: user
    createdAt: '2023-08-22T00:47:24.000Z'
    data:
      status: closed
    id: 64e4059c98b7b68a1c1baad3
    type: status-change
  author: longquan
  created_at: 2023-08-21 23:47:24+00:00
  id: 64e4059c98b7b68a1c1baad3
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Sparticle/llama-2-7b-chat-japanese-lora
repo_type: model
status: closed
target_branch: null
title: Can't reproduce this model prediction on sagemaker
