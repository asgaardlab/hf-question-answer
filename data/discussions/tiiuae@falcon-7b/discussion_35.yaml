!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Andcircle
conflicting_files: null
created_at: 2023-06-14 06:35:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/aa85c93760f96e64a17a9ede2f75ebff.svg
      fullname: Li Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Andcircle
      type: user
    createdAt: '2023-06-14T07:35:42.000Z'
    data:
      edited: false
      editors:
      - Andcircle
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8987684845924377
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/aa85c93760f96e64a17a9ede2f75ebff.svg
          fullname: Li Zhang
          isHf: false
          isPro: false
          name: Andcircle
          type: user
        html: '<p>Trying to run SFT using PEFT as here <a rel="nofollow" href="https://gist.github.com/pacman100/1731b41f7a90a87b457e8c5415ff1c14">https://gist.github.com/pacman100/1731b41f7a90a87b457e8c5415ff1c14</a></p>

          <p>If I set device_map to {"":0}, will got out of mem problem, have to set
          device_map to "auto", which will use all 4 GPU, then it works.<br>But according
          to the instruction, it should work with 16G mem, isn''t it?</p>

          <p>I use a cluster with 4 a10g 24G<br>CUDA version 12.0<br>torch version
          2.0.1-cu118 </p>

          '
        raw: "Trying to run SFT using PEFT as here https://gist.github.com/pacman100/1731b41f7a90a87b457e8c5415ff1c14\r\
          \n\r\nIf I set device_map to {\"\":0}, will got out of mem problem, have\
          \ to set device_map to \"auto\", which will use all 4 GPU, then it works.\r\
          \nBut according to the instruction, it should work with 16G mem, isn't it?\r\
          \n\r\nI use a cluster with 4 a10g 24G\r\nCUDA version 12.0\r\ntorch version\
          \ 2.0.1-cu118 "
        updatedAt: '2023-06-14T07:35:42.801Z'
      numEdits: 0
      reactions: []
    id: 64896dce238422ccf37ac1d3
    type: comment
  author: Andcircle
  content: "Trying to run SFT using PEFT as here https://gist.github.com/pacman100/1731b41f7a90a87b457e8c5415ff1c14\r\
    \n\r\nIf I set device_map to {\"\":0}, will got out of mem problem, have to set\
    \ device_map to \"auto\", which will use all 4 GPU, then it works.\r\nBut according\
    \ to the instruction, it should work with 16G mem, isn't it?\r\n\r\nI use a cluster\
    \ with 4 a10g 24G\r\nCUDA version 12.0\r\ntorch version 2.0.1-cu118 "
  created_at: 2023-06-14 06:35:42+00:00
  edited: false
  hidden: false
  id: 64896dce238422ccf37ac1d3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 35
repo_id: tiiuae/falcon-7b
repo_type: model
status: open
target_branch: null
title: Run SFT using PEFT on single a10g with 24G mem, got out of mem problem
