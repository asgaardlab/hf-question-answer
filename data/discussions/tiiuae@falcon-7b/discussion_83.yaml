!!python/object:huggingface_hub.community.DiscussionWithDetails
author: YoYo1234Qwerty
conflicting_files: null
created_at: 2023-09-26 20:25:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f8ed016c6d496e6205f60b3e26ea4586.svg
      fullname: Yoyo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YoYo1234Qwerty
      type: user
    createdAt: '2023-09-26T21:25:18.000Z'
    data:
      edited: false
      editors:
      - YoYo1234Qwerty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9550620317459106
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f8ed016c6d496e6205f60b3e26ea4586.svg
          fullname: Yoyo
          isHf: false
          isPro: false
          name: YoYo1234Qwerty
          type: user
        html: '<p>It seems like it''s still a mystery what dataset TII used, and how
          to prompt this model. I''ve noticed from experiments that it''s eager to
          output a format like:</p>

          <pre><code>User How are you

          Mini Fine thanks

          </code></pre>

          <p>For instance:</p>

          <pre><code>User Nice to meet you. How''s the weather?

          Mini The weather is actually terrible, with rain and thunderstorms predicted.
          Are you and your friends still planning on seeing a movie together tonight?

          User Oh wow, we might have umbrellas handy then.... So have you seen any
          good movies recently?

          Mini As an AI I''m not capable off `watching` movies per-said, but are some
          favorites include Titanic 1922, Interstellar, Avatar, and Avengers movies.

          </code></pre>

          <p>I''ve seen in the tokenizer things like <code>&gt;&gt;QUESTION&lt;&lt;</code>
          and <code>&gt;&gt;ANSWER&lt;&lt;</code>, but it''s not clear if they just
          ripped off this tokenizer from somewhere, and never actually trained it
          like this.</p>

          <p>Other users suggest this format, but I''ve never seen it verified:</p>

          <pre><code>User: blah

          Assistant: blah

          </code></pre>

          <p>Anyone have any insights into the Instruct dataset, or how this was intended
          to be prompted?</p>

          '
        raw: "It seems like it's still a mystery what dataset TII used, and how to\
          \ prompt this model. I've noticed from experiments that it's eager to output\
          \ a format like:\r\n\r\n```\r\nUser How are you\r\nMini Fine thanks\r\n\
          ```\r\n\r\nFor instance:\r\n\r\n```\r\nUser Nice to meet you. How's the\
          \ weather?\r\nMini The weather is actually terrible, with rain and thunderstorms\
          \ predicted. Are you and your friends still planning on seeing a movie together\
          \ tonight?\r\nUser Oh wow, we might have umbrellas handy then.... So have\
          \ you seen any good movies recently?\r\nMini As an AI I'm not capable off\
          \ `watching` movies per-said, but are some favorites include Titanic 1922,\
          \ Interstellar, Avatar, and Avengers movies.\r\n```\r\n\r\n\r\nI've seen\
          \ in the tokenizer things like `>>QUESTION<<` and `>>ANSWER<<`, but it's\
          \ not clear if they just ripped off this tokenizer from somewhere, and never\
          \ actually trained it like this.\r\n\r\nOther users suggest this format,\
          \ but I've never seen it verified:\r\n\r\n```\r\nUser: blah\r\nAssistant:\
          \ blah\r\n```\r\n\r\nAnyone have any insights into the Instruct dataset,\
          \ or how this was intended to be prompted?\r\n"
        updatedAt: '2023-09-26T21:25:18.835Z'
      numEdits: 0
      reactions: []
    id: 65134c3e7b2e843f39c5a328
    type: comment
  author: YoYo1234Qwerty
  content: "It seems like it's still a mystery what dataset TII used, and how to prompt\
    \ this model. I've noticed from experiments that it's eager to output a format\
    \ like:\r\n\r\n```\r\nUser How are you\r\nMini Fine thanks\r\n```\r\n\r\nFor instance:\r\
    \n\r\n```\r\nUser Nice to meet you. How's the weather?\r\nMini The weather is\
    \ actually terrible, with rain and thunderstorms predicted. Are you and your friends\
    \ still planning on seeing a movie together tonight?\r\nUser Oh wow, we might\
    \ have umbrellas handy then.... So have you seen any good movies recently?\r\n\
    Mini As an AI I'm not capable off `watching` movies per-said, but are some favorites\
    \ include Titanic 1922, Interstellar, Avatar, and Avengers movies.\r\n```\r\n\r\
    \n\r\nI've seen in the tokenizer things like `>>QUESTION<<` and `>>ANSWER<<`,\
    \ but it's not clear if they just ripped off this tokenizer from somewhere, and\
    \ never actually trained it like this.\r\n\r\nOther users suggest this format,\
    \ but I've never seen it verified:\r\n\r\n```\r\nUser: blah\r\nAssistant: blah\r\
    \n```\r\n\r\nAnyone have any insights into the Instruct dataset, or how this was\
    \ intended to be prompted?\r\n"
  created_at: 2023-09-26 20:25:18+00:00
  edited: false
  hidden: false
  id: 65134c3e7b2e843f39c5a328
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 83
repo_id: tiiuae/falcon-7b
repo_type: model
status: open
target_branch: null
title: Anyone discovered "Mini" yet in prompting?
