!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ivyas
conflicting_files: null
created_at: 2023-05-31 16:19:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5dbd54dc1994d45683b19e49848cc7fc.svg
      fullname: Ishani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ivyas
      type: user
    createdAt: '2023-05-31T17:19:29.000Z'
    data:
      edited: false
      editors:
      - ivyas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5dbd54dc1994d45683b19e49848cc7fc.svg
          fullname: Ishani
          isHf: false
          isPro: false
          name: ivyas
          type: user
        html: "<p>I'm having issue with falcon-7b model. I am running sample code\
          \ from </p>\n<pre><code>from transformers import AutoTokenizer, AutoModelForCausalLM\n\
          import transformers\nimport torch\n\nmodel = \"tiiuae/falcon-7b\"\n\ntokenizer\
          \ = AutoTokenizer.from_pretrained(model)\npipeline = transformers.pipeline(\n\
          \    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n\
          \    torch_dtype=torch.bfloat16,\n    trust_remote_code=True,\n    device_map=\"\
          auto\",\n)\nsequences = pipeline(\n   \"Girafatron is obsessed with giraffes,\
          \ the most glorious animal on the face of this Earth. Giraftron believes\
          \ all other animals are irrelevant when compared to the glorious majesty\
          \ of the giraffe.\\nDaniel: Hello, Girafatron!\\nGirafatron:\",\n    max_length=200,\n\
          \    do_sample=True,\n    top_k=10,\n    num_return_sequences=1,\n    eos_token_id=tokenizer.eos_token_id,\n\
          )\nfor seq in sequences:\n    print(f\"Result: {seq['generated_text']}\"\
          )\n</code></pre>\n<p>I am getting stuck at Setting <code>pad_token_id</code>\
          \ to <code>eos_token_id</code>:11 for open-end generation.</p>\n<p>I am\
          \ running on my macbook pro with intel chip.</p>\n"
        raw: "I'm having issue with falcon-7b model. I am running sample code from\
          \ \r\n\r\n```\r\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\r\
          \nimport transformers\r\nimport torch\r\n\r\nmodel = \"tiiuae/falcon-7b\"\
          \r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model)\r\npipeline = transformers.pipeline(\r\
          \n    \"text-generation\",\r\n    model=model,\r\n    tokenizer=tokenizer,\r\
          \n    torch_dtype=torch.bfloat16,\r\n    trust_remote_code=True,\r\n   \
          \ device_map=\"auto\",\r\n)\r\nsequences = pipeline(\r\n   \"Girafatron\
          \ is obsessed with giraffes, the most glorious animal on the face of this\
          \ Earth. Giraftron believes all other animals are irrelevant when compared\
          \ to the glorious majesty of the giraffe.\\nDaniel: Hello, Girafatron!\\\
          nGirafatron:\",\r\n    max_length=200,\r\n    do_sample=True,\r\n    top_k=10,\r\
          \n    num_return_sequences=1,\r\n    eos_token_id=tokenizer.eos_token_id,\r\
          \n)\r\nfor seq in sequences:\r\n    print(f\"Result: {seq['generated_text']}\"\
          )\r\n```\r\n\r\nI am getting stuck at Setting `pad_token_id` to `eos_token_id`:11\
          \ for open-end generation.\r\n\r\nI am running on my macbook pro with intel\
          \ chip.\r\n"
        updatedAt: '2023-05-31T17:19:29.826Z'
      numEdits: 0
      reactions: []
    id: 647781a1c21496284db48b02
    type: comment
  author: ivyas
  content: "I'm having issue with falcon-7b model. I am running sample code from \r\
    \n\r\n```\r\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\r\n\
    import transformers\r\nimport torch\r\n\r\nmodel = \"tiiuae/falcon-7b\"\r\n\r\n\
    tokenizer = AutoTokenizer.from_pretrained(model)\r\npipeline = transformers.pipeline(\r\
    \n    \"text-generation\",\r\n    model=model,\r\n    tokenizer=tokenizer,\r\n\
    \    torch_dtype=torch.bfloat16,\r\n    trust_remote_code=True,\r\n    device_map=\"\
    auto\",\r\n)\r\nsequences = pipeline(\r\n   \"Girafatron is obsessed with giraffes,\
    \ the most glorious animal on the face of this Earth. Giraftron believes all other\
    \ animals are irrelevant when compared to the glorious majesty of the giraffe.\\\
    nDaniel: Hello, Girafatron!\\nGirafatron:\",\r\n    max_length=200,\r\n    do_sample=True,\r\
    \n    top_k=10,\r\n    num_return_sequences=1,\r\n    eos_token_id=tokenizer.eos_token_id,\r\
    \n)\r\nfor seq in sequences:\r\n    print(f\"Result: {seq['generated_text']}\"\
    )\r\n```\r\n\r\nI am getting stuck at Setting `pad_token_id` to `eos_token_id`:11\
    \ for open-end generation.\r\n\r\nI am running on my macbook pro with intel chip.\r\
    \n"
  created_at: 2023-05-31 16:19:29+00:00
  edited: false
  hidden: false
  id: 647781a1c21496284db48b02
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/34c7cbce0a03ba1ed2ef1f762dd5f2e1.svg
      fullname: Sandor Tucakov Caetano
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tucakov
      type: user
    createdAt: '2023-06-01T17:34:42.000Z'
    data:
      edited: false
      editors:
      - Tucakov
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/34c7cbce0a03ba1ed2ef1f762dd5f2e1.svg
          fullname: Sandor Tucakov Caetano
          isHf: false
          isPro: false
          name: Tucakov
          type: user
        html: '<p>+1</p>

          '
        raw: '+1'
        updatedAt: '2023-06-01T17:34:42.989Z'
      numEdits: 0
      reactions: []
    id: 6478d6b225e06d2ffe8a1bbf
    type: comment
  author: Tucakov
  content: '+1'
  created_at: 2023-06-01 16:34:42+00:00
  edited: false
  hidden: false
  id: 6478d6b225e06d2ffe8a1bbf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1a3542fda3c104331b12678ba293ea62.svg
      fullname: Sameera Horawalavithana
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: samtube405
      type: user
    createdAt: '2023-06-01T18:42:11.000Z'
    data:
      edited: false
      editors:
      - samtube405
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1a3542fda3c104331b12678ba293ea62.svg
          fullname: Sameera Horawalavithana
          isHf: false
          isPro: false
          name: samtube405
          type: user
        html: '<p>same issue.</p>

          '
        raw: same issue.
        updatedAt: '2023-06-01T18:42:11.592Z'
      numEdits: 0
      reactions: []
    id: 6478e68342b1805ae2adf297
    type: comment
  author: samtube405
  content: same issue.
  created_at: 2023-06-01 17:42:11+00:00
  edited: false
  hidden: false
  id: 6478e68342b1805ae2adf297
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d6883133cb5b7111d319054df402f89d.svg
      fullname: Ujjwal agrawal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ujjwalagr
      type: user
    createdAt: '2023-06-27T05:57:54.000Z'
    data:
      edited: false
      editors:
      - ujjwalagr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.99784916639328
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d6883133cb5b7111d319054df402f89d.svg
          fullname: Ujjwal agrawal
          isHf: false
          isPro: false
          name: ujjwalagr
          type: user
        html: '<p>Same happening with as well</p>

          '
        raw: Same happening with as well
        updatedAt: '2023-06-27T05:57:54.201Z'
      numEdits: 0
      reactions: []
    id: 649a7a6220a3399ff5c03cde
    type: comment
  author: ujjwalagr
  content: Same happening with as well
  created_at: 2023-06-27 04:57:54+00:00
  edited: false
  hidden: false
  id: 649a7a6220a3399ff5c03cde
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4a4a0c90b8593cc0c0dba8fb81064304.svg
      fullname: vishal kajjam
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vkajjam
      type: user
    createdAt: '2023-06-27T17:48:17.000Z'
    data:
      edited: false
      editors:
      - vkajjam
      hidden: false
      identifiedLanguage:
        language: it
        probability: 0.9861560463905334
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4a4a0c90b8593cc0c0dba8fb81064304.svg
          fullname: vishal kajjam
          isHf: false
          isPro: false
          name: vkajjam
          type: user
        html: '<p>+1</p>

          '
        raw: '+1'
        updatedAt: '2023-06-27T17:48:17.703Z'
      numEdits: 0
      reactions: []
    id: 649b20e1ca20306aeefb5b91
    type: comment
  author: vkajjam
  content: '+1'
  created_at: 2023-06-27 16:48:17+00:00
  edited: false
  hidden: false
  id: 649b20e1ca20306aeefb5b91
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/gkzTVrxWD5Z9SdmExQ1tY.jpeg?w=200&h=200&f=face
      fullname: Kunjesh Patel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kunjesh07
      type: user
    createdAt: '2023-08-07T06:14:38.000Z'
    data:
      edited: false
      editors:
      - Kunjesh07
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9016775488853455
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/gkzTVrxWD5Z9SdmExQ1tY.jpeg?w=200&h=200&f=face
          fullname: Kunjesh Patel
          isHf: false
          isPro: false
          name: Kunjesh07
          type: user
        html: '<p>I''ve same issue when I try 4096 max_length but I got the output
          in 200 max_length</p>

          '
        raw: I've same issue when I try 4096 max_length but I got the output in 200
          max_length
        updatedAt: '2023-08-07T06:14:38.644Z'
      numEdits: 0
      reactions: []
    id: 64d08bce9617774ce407d707
    type: comment
  author: Kunjesh07
  content: I've same issue when I try 4096 max_length but I got the output in 200
    max_length
  created_at: 2023-08-07 05:14:38+00:00
  edited: false
  hidden: false
  id: 64d08bce9617774ce407d707
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 14
repo_id: tiiuae/falcon-7b
repo_type: model
status: open
target_branch: null
title: Getting stuck at Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.
