!!python/object:huggingface_hub.community.DiscussionWithDetails
author: cekal
conflicting_files: null
created_at: 2023-05-27 22:18:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
      fullname: Vojtech Cekal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: cekal
      type: user
    createdAt: '2023-05-27T23:18:58.000Z'
    data:
      edited: false
      editors:
      - cekal
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
          fullname: Vojtech Cekal
          isHf: false
          isPro: true
          name: cekal
          type: user
        html: "<p>Hi, does this have support for LoRA training? I've tried to finetune\
          \ the model on this (slightly modified) code: <a rel=\"nofollow\" href=\"\
          https://github.com/tloen/alpaca-lora/blob/main/finetune.py\">https://github.com/tloen/alpaca-lora/blob/main/finetune.py</a>\
          \ and it started training but learning rate 0.0, odd loss between 40 - 50\
          \ (LLaMA models usually have under 2) and when the adapter was run along\
          \ with this base model after the training finished, the model gave weird\
          \ outputs.</p>\n<p>If anyone tried to finetune using LoRA and were successful,\
          \ please share how you did so. Any help is much appreciated! \U0001F44D\U0001F91D\
          </p>\n"
        raw: "Hi, does this have support for LoRA training? I've tried to finetune\
          \ the model on this (slightly modified) code: https://github.com/tloen/alpaca-lora/blob/main/finetune.py\
          \ and it started training but learning rate 0.0, odd loss between 40 - 50\
          \ (LLaMA models usually have under 2) and when the adapter was run along\
          \ with this base model after the training finished, the model gave weird\
          \ outputs.\r\n\r\nIf anyone tried to finetune using LoRA and were successful,\
          \ please share how you did so. Any help is much appreciated! \U0001F44D\U0001F91D"
        updatedAt: '2023-05-27T23:18:58.913Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - Kernel
        - jeril
        - Aspik101
    id: 64728fe245c2f5457fb0b868
    type: comment
  author: cekal
  content: "Hi, does this have support for LoRA training? I've tried to finetune the\
    \ model on this (slightly modified) code: https://github.com/tloen/alpaca-lora/blob/main/finetune.py\
    \ and it started training but learning rate 0.0, odd loss between 40 - 50 (LLaMA\
    \ models usually have under 2) and when the adapter was run along with this base\
    \ model after the training finished, the model gave weird outputs.\r\n\r\nIf anyone\
    \ tried to finetune using LoRA and were successful, please share how you did so.\
    \ Any help is much appreciated! \U0001F44D\U0001F91D"
  created_at: 2023-05-27 22:18:58+00:00
  edited: false
  hidden: false
  id: 64728fe245c2f5457fb0b868
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/624ae13993d46cf4a0928032/kaIXTCGMbkuxuT59p0NAO.jpeg?w=200&h=200&f=face
      fullname: Panic
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kernel
      type: user
    createdAt: '2023-05-28T10:16:14.000Z'
    data:
      edited: false
      editors:
      - Kernel
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/624ae13993d46cf4a0928032/kaIXTCGMbkuxuT59p0NAO.jpeg?w=200&h=200&f=face
          fullname: Panic
          isHf: false
          isPro: false
          name: Kernel
          type: user
        html: '<p>If someone managed to train with QLoRA, please share your results</p>

          '
        raw: If someone managed to train with QLoRA, please share your results
        updatedAt: '2023-05-28T10:16:14.625Z'
      numEdits: 0
      reactions: []
    id: 647329ee352c94a20dd11e88
    type: comment
  author: Kernel
  content: If someone managed to train with QLoRA, please share your results
  created_at: 2023-05-28 09:16:14+00:00
  edited: false
  hidden: false
  id: 647329ee352c94a20dd11e88
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4ad43c2d0ff136ee686c96c7a50dafa8.svg
      fullname: zhangbo2008
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zhangbo2008
      type: user
    createdAt: '2023-05-29T08:17:02.000Z'
    data:
      edited: false
      editors:
      - zhangbo2008
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4ad43c2d0ff136ee686c96c7a50dafa8.svg
          fullname: zhangbo2008
          isHf: false
          isPro: false
          name: zhangbo2008
          type: user
        html: '<p>you can check the code of alpaca .  maybe not change too much code.<br><a
          rel="nofollow" href="https://github.com/tloen/alpaca-lora/blob/main/finetune.py">https://github.com/tloen/alpaca-lora/blob/main/finetune.py</a></p>

          '
        raw: 'you can check the code of alpaca .  maybe not change too much code.

          https://github.com/tloen/alpaca-lora/blob/main/finetune.py'
        updatedAt: '2023-05-29T08:17:02.753Z'
      numEdits: 0
      reactions: []
    id: 64745f7ef9e3e0b312e7724e
    type: comment
  author: zhangbo2008
  content: 'you can check the code of alpaca .  maybe not change too much code.

    https://github.com/tloen/alpaca-lora/blob/main/finetune.py'
  created_at: 2023-05-29 07:17:02+00:00
  edited: false
  hidden: false
  id: 64745f7ef9e3e0b312e7724e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
      fullname: Vojtech Cekal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: cekal
      type: user
    createdAt: '2023-05-29T08:21:29.000Z'
    data:
      edited: false
      editors:
      - cekal
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
          fullname: Vojtech Cekal
          isHf: false
          isPro: true
          name: cekal
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;zhangbo2008&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/zhangbo2008\"\
          >@<span class=\"underline\">zhangbo2008</span></a></span>\n\n\t</span></span>\
          \ as you can see in my initial message, I mentioned that I already tried\
          \ it, just modified the script a bit so it would fit the correct \u201C\
          AutoModelForCasualLM\u201D and \u201CAutoTokenizer\u201D etc. Seems like\
          \ it is not working correctly, something is wrong.</p>\n"
        raw: "@zhangbo2008 as you can see in my initial message, I mentioned that\
          \ I already tried it, just modified the script a bit so it would fit the\
          \ correct \u201CAutoModelForCasualLM\u201D and \u201CAutoTokenizer\u201D\
          \ etc. Seems like it is not working correctly, something is wrong."
        updatedAt: '2023-05-29T08:21:29.555Z'
      numEdits: 0
      reactions: []
    id: 64746089d56974d0c0578ff5
    type: comment
  author: cekal
  content: "@zhangbo2008 as you can see in my initial message, I mentioned that I\
    \ already tried it, just modified the script a bit so it would fit the correct\
    \ \u201CAutoModelForCasualLM\u201D and \u201CAutoTokenizer\u201D etc. Seems like\
    \ it is not working correctly, something is wrong."
  created_at: 2023-05-29 07:21:29+00:00
  edited: false
  hidden: false
  id: 64746089d56974d0c0578ff5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4ad43c2d0ff136ee686c96c7a50dafa8.svg
      fullname: zhangbo2008
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zhangbo2008
      type: user
    createdAt: '2023-05-29T08:24:24.000Z'
    data:
      edited: false
      editors:
      - zhangbo2008
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4ad43c2d0ff136ee686c96c7a50dafa8.svg
          fullname: zhangbo2008
          isHf: false
          isPro: false
          name: zhangbo2008
          type: user
        html: '<p>ok, i will try</p>

          '
        raw: ok, i will try
        updatedAt: '2023-05-29T08:24:24.646Z'
      numEdits: 0
      reactions: []
    id: 64746138d56974d0c0579b26
    type: comment
  author: zhangbo2008
  content: ok, i will try
  created_at: 2023-05-29 07:24:24+00:00
  edited: false
  hidden: false
  id: 64746138d56974d0c0579b26
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
      fullname: Vojtech Cekal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: cekal
      type: user
    createdAt: '2023-05-29T08:32:22.000Z'
    data:
      edited: false
      editors:
      - cekal
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
          fullname: Vojtech Cekal
          isHf: false
          isPro: true
          name: cekal
          type: user
        html: "<p>Alright. You\u2019ll probably get the training running but if the\
          \ training loss is too high and it shows learning rate 0.0 chances are the\
          \ model is training incorrectly (final adapter will then be useless). This\
          \ might be due to an issue in modeling_RW.py that does not allow support\
          \ (is not configured) for LoRA</p>\n<p>If it works for you, please share\
          \ your version of the code. Thanks!</p>\n"
        raw: "Alright. You\u2019ll probably get the training running but if the training\
          \ loss is too high and it shows learning rate 0.0 chances are the model\
          \ is training incorrectly (final adapter will then be useless). This might\
          \ be due to an issue in modeling_RW.py that does not allow support (is not\
          \ configured) for LoRA\n\nIf it works for you, please share your version\
          \ of the code. Thanks!"
        updatedAt: '2023-05-29T08:32:22.194Z'
      numEdits: 0
      reactions: []
    id: 6474631682907acddde88364
    type: comment
  author: cekal
  content: "Alright. You\u2019ll probably get the training running but if the training\
    \ loss is too high and it shows learning rate 0.0 chances are the model is training\
    \ incorrectly (final adapter will then be useless). This might be due to an issue\
    \ in modeling_RW.py that does not allow support (is not configured) for LoRA\n\
    \nIf it works for you, please share your version of the code. Thanks!"
  created_at: 2023-05-29 07:32:22+00:00
  edited: false
  hidden: false
  id: 6474631682907acddde88364
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
      fullname: Vojtech Cekal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: cekal
      type: user
    createdAt: '2023-05-29T08:39:20.000Z'
    data:
      edited: false
      editors:
      - cekal
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
          fullname: Vojtech Cekal
          isHf: false
          isPro: true
          name: cekal
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;zhangbo2008&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/zhangbo2008\"\
          >@<span class=\"underline\">zhangbo2008</span></a></span>\n\n\t</span></span>\
          \ I found this: <a rel=\"nofollow\" href=\"https://github.com/lvwerra/trl/blob/main/examples/sentiment/scripts/gpt-neox-20b_peft/clm_finetune_peft_imdb.py\"\
          >https://github.com/lvwerra/trl/blob/main/examples/sentiment/scripts/gpt-neox-20b_peft/clm_finetune_peft_imdb.py</a></p>\n\
          <p>Maybe slightly modifying this code could do the thing? I\u2019m not home\
          \ so I can\u2019t run the training but this could possibly work</p>\n"
        raw: "@zhangbo2008 I found this: https://github.com/lvwerra/trl/blob/main/examples/sentiment/scripts/gpt-neox-20b_peft/clm_finetune_peft_imdb.py\n\
          \nMaybe slightly modifying this code could do the thing? I\u2019m not home\
          \ so I can\u2019t run the training but this could possibly work"
        updatedAt: '2023-05-29T08:39:20.349Z'
      numEdits: 0
      reactions: []
    id: 647464b882907acddde89f28
    type: comment
  author: cekal
  content: "@zhangbo2008 I found this: https://github.com/lvwerra/trl/blob/main/examples/sentiment/scripts/gpt-neox-20b_peft/clm_finetune_peft_imdb.py\n\
    \nMaybe slightly modifying this code could do the thing? I\u2019m not home so\
    \ I can\u2019t run the training but this could possibly work"
  created_at: 2023-05-29 07:39:20+00:00
  edited: false
  hidden: false
  id: 647464b882907acddde89f28
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8ddcd18bca58cf2fc217c35fba261948.svg
      fullname: junxian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xiao111
      type: user
    createdAt: '2023-05-30T10:52:24.000Z'
    data:
      edited: false
      editors:
      - xiao111
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8ddcd18bca58cf2fc217c35fba261948.svg
          fullname: junxian
          isHf: false
          isPro: false
          name: xiao111
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;cekal&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/cekal\">@<span class=\"\
          underline\">cekal</span></a></span>\n\n\t</span></span> you can see this:<a\
          \ href=\"https://huggingface.co/dfurman/falcon-7b-chat-oasst1/blob/main/finetune_falcon7b_oasst1_with_bnb_peft.ipynb\"\
          >https://huggingface.co/dfurman/falcon-7b-chat-oasst1/blob/main/finetune_falcon7b_oasst1_with_bnb_peft.ipynb</a>\
          \ </p>\n<p>wish can help you, and I had not  try this code.</p>\n"
        raw: "@cekal you can see this:https://huggingface.co/dfurman/falcon-7b-chat-oasst1/blob/main/finetune_falcon7b_oasst1_with_bnb_peft.ipynb\
          \ \n\nwish can help you, and I had not  try this code."
        updatedAt: '2023-05-30T10:52:24.958Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F917"
        users:
        - Kernel
        - AmanRai7
        - cekal
    id: 6475d568c894b5c9cf73a233
    type: comment
  author: xiao111
  content: "@cekal you can see this:https://huggingface.co/dfurman/falcon-7b-chat-oasst1/blob/main/finetune_falcon7b_oasst1_with_bnb_peft.ipynb\
    \ \n\nwish can help you, and I had not  try this code."
  created_at: 2023-05-30 09:52:24+00:00
  edited: false
  hidden: false
  id: 6475d568c894b5c9cf73a233
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/614c6aa80fde75fda1a2d029/iOcJRyhYO7YsPskdqqE9F.jpeg?w=200&h=200&f=face
      fullname: Julian Gerhard
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JulianGerhard
      type: user
    createdAt: '2023-05-31T05:14:20.000Z'
    data:
      edited: false
      editors:
      - JulianGerhard
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/614c6aa80fde75fda1a2d029/iOcJRyhYO7YsPskdqqE9F.jpeg?w=200&h=200&f=face
          fullname: Julian Gerhard
          isHf: false
          isPro: false
          name: JulianGerhard
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;cekal&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/cekal\">@<span class=\"\
          underline\">cekal</span></a></span>\n\n\t</span></span> <span data-props=\"\
          {&quot;user&quot;:&quot;xiao111&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/xiao111\">@<span class=\"underline\">xiao111</span></a></span>\n\
          \n\t</span></span>  - I can confirm that the mentioned modification in the\
          \ notebook actually works. I was able to finetune / further train falcon-7b\
          \ with an instruction following strategy. Keep in mind that after training\
          \ you need to merge the new weights back into the original model files in\
          \ order to be able to set <code>trust_remote_code</code> to True.</p>\n"
        raw: '@cekal @xiao111  - I can confirm that the mentioned modification in
          the notebook actually works. I was able to finetune / further train falcon-7b
          with an instruction following strategy. Keep in mind that after training
          you need to merge the new weights back into the original model files in
          order to be able to set `trust_remote_code` to True.'
        updatedAt: '2023-05-31T05:14:20.254Z'
      numEdits: 0
      reactions: []
    id: 6476d7aca4ebdbfb1388686f
    type: comment
  author: JulianGerhard
  content: '@cekal @xiao111  - I can confirm that the mentioned modification in the
    notebook actually works. I was able to finetune / further train falcon-7b with
    an instruction following strategy. Keep in mind that after training you need to
    merge the new weights back into the original model files in order to be able to
    set `trust_remote_code` to True.'
  created_at: 2023-05-31 04:14:20+00:00
  edited: false
  hidden: false
  id: 6476d7aca4ebdbfb1388686f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionEvent
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
      fullname: Falcon LLM TII UAE
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: FalconLLM
      type: user
    createdAt: '2023-05-31T05:23:09.000Z'
    data:
      pinned: true
    id: 6476d9bd26ec66674c711eed
    type: pinning-change
  author: FalconLLM
  created_at: 2023-05-31 04:23:09+00:00
  id: 6476d9bd26ec66674c711eed
  type: pinning-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4ad43c2d0ff136ee686c96c7a50dafa8.svg
      fullname: zhangbo2008
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zhangbo2008
      type: user
    createdAt: '2023-05-31T07:30:38.000Z'
    data:
      edited: false
      editors:
      - zhangbo2008
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4ad43c2d0ff136ee686c96c7a50dafa8.svg
          fullname: zhangbo2008
          isHf: false
          isPro: false
          name: zhangbo2008
          type: user
        html: '<p>thanks for sharing . i am so xxx cause my colab only 15g gpu not
          work for  4biteint_mode.</p>

          '
        raw: thanks for sharing . i am so xxx cause my colab only 15g gpu not work
          for  4biteint_mode.
        updatedAt: '2023-05-31T07:30:38.075Z'
      numEdits: 0
      reactions: []
    id: 6476f79e242dde3163fd061c
    type: comment
  author: zhangbo2008
  content: thanks for sharing . i am so xxx cause my colab only 15g gpu not work for  4biteint_mode.
  created_at: 2023-05-31 06:30:38+00:00
  edited: false
  hidden: false
  id: 6476f79e242dde3163fd061c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a30fc4114856bc3ba729c1ed95e54d9b.svg
      fullname: Utensil Song
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: utensil
      type: user
    createdAt: '2023-06-01T06:16:23.000Z'
    data:
      edited: true
      editors:
      - utensil
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a30fc4114856bc3ba729c1ed95e54d9b.svg
          fullname: Utensil Song
          isHf: false
          isPro: false
          name: utensil
          type: user
        html: '<p>I have tried fine-tuning falcon 7b with qlora using axolotl, and
          it seems to work: <a rel="nofollow" href="https://github.com/OpenAccess-AI-Collective/axolotl/pull/132">https://github.com/OpenAccess-AI-Collective/axolotl/pull/132</a></p>

          <p>If you encounter any issue with the config or spot any problems in the
          config, please ping me in the PR. Thanks!</p>

          '
        raw: 'I have tried fine-tuning falcon 7b with qlora using axolotl, and it
          seems to work: https://github.com/OpenAccess-AI-Collective/axolotl/pull/132


          If you encounter any issue with the config or spot any problems in the config,
          please ping me in the PR. Thanks!'
        updatedAt: '2023-06-01T06:16:52.804Z'
      numEdits: 1
      reactions: []
    id: 647837b7ad83f3939b442dc0
    type: comment
  author: utensil
  content: 'I have tried fine-tuning falcon 7b with qlora using axolotl, and it seems
    to work: https://github.com/OpenAccess-AI-Collective/axolotl/pull/132


    If you encounter any issue with the config or spot any problems in the config,
    please ping me in the PR. Thanks!'
  created_at: 2023-06-01 05:16:23+00:00
  edited: true
  hidden: false
  id: 647837b7ad83f3939b442dc0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ff9452783ffd8b268e17bc102ad8cf97.svg
      fullname: Sumegh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sumegh
      type: user
    createdAt: '2023-06-02T11:52:00.000Z'
    data:
      edited: true
      editors:
      - sumegh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ff9452783ffd8b268e17bc102ad8cf97.svg
          fullname: Sumegh
          isHf: false
          isPro: false
          name: sumegh
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;cekal&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/cekal\">@<span class=\"\
          underline\">cekal</span></a></span>\n\n\t</span></span> how did you get\
          \ it to work finally ? I also tried modifying the Alpaca-LORA code by changing\
          \ AutoTokenizer &amp; AutoModelForCausalLM.<br>Also changed lora_target_module\
          \ to [\"query_key_value\"].</p>\n<p>I get the error <code>ValueError: The\
          \ length of enable_lora must divide out_features</code></p>\n<p><em>EDIT\
          \ - Fixed by updating the packages.</em></p>\n"
        raw: "@cekal how did you get it to work finally ? I also tried modifying the\
          \ Alpaca-LORA code by changing AutoTokenizer & AutoModelForCausalLM. \n\
          Also changed lora_target_module to [\"query_key_value\"].\n\nI get the error\
          \ `ValueError: The length of enable_lora must divide out_features`\n\n*EDIT\
          \ - Fixed by updating the packages.*"
        updatedAt: '2023-06-02T19:37:37.962Z'
      numEdits: 1
      reactions: []
    id: 6479d7e01a2aefceecd6ca5b
    type: comment
  author: sumegh
  content: "@cekal how did you get it to work finally ? I also tried modifying the\
    \ Alpaca-LORA code by changing AutoTokenizer & AutoModelForCausalLM. \nAlso changed\
    \ lora_target_module to [\"query_key_value\"].\n\nI get the error `ValueError:\
    \ The length of enable_lora must divide out_features`\n\n*EDIT - Fixed by updating\
    \ the packages.*"
  created_at: 2023-06-02 10:52:00+00:00
  edited: true
  hidden: false
  id: 6479d7e01a2aefceecd6ca5b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
      fullname: Vojtech Cekal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: cekal
      type: user
    createdAt: '2023-06-03T13:59:47.000Z'
    data:
      edited: false
      editors:
      - cekal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.1911717653274536
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
          fullname: Vojtech Cekal
          isHf: false
          isPro: true
          name: cekal
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sumegh&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/sumegh\">@<span class=\"\
          underline\">sumegh</span></a></span>\n\n\t</span></span> try this: <a href=\"\
          https://huggingface.co/dfurman/falcon-7b-chat-oasst1/blob/main/finetune_falcon7b_oasst1_with_bnb_peft.ipynb\"\
          >https://huggingface.co/dfurman/falcon-7b-chat-oasst1/blob/main/finetune_falcon7b_oasst1_with_bnb_peft.ipynb</a></p>\n"
        raw: '@sumegh try this: https://huggingface.co/dfurman/falcon-7b-chat-oasst1/blob/main/finetune_falcon7b_oasst1_with_bnb_peft.ipynb'
        updatedAt: '2023-06-03T13:59:47.092Z'
      numEdits: 0
      reactions: []
    id: 647b4753e8b7333058a42c39
    type: comment
  author: cekal
  content: '@sumegh try this: https://huggingface.co/dfurman/falcon-7b-chat-oasst1/blob/main/finetune_falcon7b_oasst1_with_bnb_peft.ipynb'
  created_at: 2023-06-03 12:59:47+00:00
  edited: false
  hidden: false
  id: 647b4753e8b7333058a42c39
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8ddcd18bca58cf2fc217c35fba261948.svg
      fullname: junxian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xiao111
      type: user
    createdAt: '2023-06-05T03:32:17.000Z'
    data:
      edited: true
      editors:
      - xiao111
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8423366546630859
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8ddcd18bca58cf2fc217c35fba261948.svg
          fullname: junxian
          isHf: false
          isPro: false
          name: xiao111
          type: user
        html: "<blockquote>\n<p>I have tried fine-tuning falcon 7b with qlora using\
          \ axolotl, and it seems to work: <a rel=\"nofollow\" href=\"https://github.com/OpenAccess-AI-Collective/axolotl/pull/132\"\
          >https://github.com/OpenAccess-AI-Collective/axolotl/pull/132</a></p>\n\
          <p>If you encounter any issue with the config or spot any problems in the\
          \ config, please ping me in the PR. Thanks!</p>\n</blockquote>\n<p>hi, <span\
          \ data-props=\"{&quot;user&quot;:&quot;utensil&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/utensil\">@<span class=\"underline\"\
          >utensil</span></a></span>\n\n\t</span></span>  I have compared qlora.yml\
          \ and lora.yml on falcon 7B. The main difference seems to be only these\
          \ fields</p>\n<pre><code>load_in_8bit: true\nload_in_4bit: false\noptimizer:\
          \ paged_adamw_32bit\n</code></pre>\n<p>Is there any other difference?</p>\n"
        raw: "> I have tried fine-tuning falcon 7b with qlora using axolotl, and it\
          \ seems to work: https://github.com/OpenAccess-AI-Collective/axolotl/pull/132\n\
          > \n> If you encounter any issue with the config or spot any problems in\
          \ the config, please ping me in the PR. Thanks!\n\n\nhi, @utensil  I have\
          \ compared qlora.yml and lora.yml on falcon 7B. The main difference seems\
          \ to be only these fields\n```\nload_in_8bit: true\nload_in_4bit: false\n\
          optimizer: paged_adamw_32bit\n```\nIs there any other difference?"
        updatedAt: '2023-06-05T03:32:36.006Z'
      numEdits: 1
      reactions: []
    id: 647d574160dfe0f35d6a2175
    type: comment
  author: xiao111
  content: "> I have tried fine-tuning falcon 7b with qlora using axolotl, and it\
    \ seems to work: https://github.com/OpenAccess-AI-Collective/axolotl/pull/132\n\
    > \n> If you encounter any issue with the config or spot any problems in the config,\
    \ please ping me in the PR. Thanks!\n\n\nhi, @utensil  I have compared qlora.yml\
    \ and lora.yml on falcon 7B. The main difference seems to be only these fields\n\
    ```\nload_in_8bit: true\nload_in_4bit: false\noptimizer: paged_adamw_32bit\n```\n\
    Is there any other difference?"
  created_at: 2023-06-05 02:32:17+00:00
  edited: true
  hidden: false
  id: 647d574160dfe0f35d6a2175
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
      fullname: Falcon LLM TII UAE
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: FalconLLM
      type: user
    createdAt: '2023-06-09T14:02:14.000Z'
    data:
      edited: false
      editors:
      - FalconLLM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8956881761550903
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
          fullname: Falcon LLM TII UAE
          isHf: false
          isPro: false
          name: FalconLLM
          type: user
        html: '<p>If you are interested in finetuning the models, we would recommend
          having a look at <a rel="nofollow" href="https://github.com/rmihaylov/falcontune">FalconTune</a>
          (which supports finetuning in 4-bit) or at this <a href="https://huggingface.co/blog/falcon#fine-tuning-with-peft">blogpost
          from HF</a>, specifically at the section on finetuning the model with PEFT.</p>

          '
        raw: If you are interested in finetuning the models, we would recommend having
          a look at [FalconTune](https://github.com/rmihaylov/falcontune) (which supports
          finetuning in 4-bit) or at this [blogpost from HF](https://huggingface.co/blog/falcon#fine-tuning-with-peft),
          specifically at the section on finetuning the model with PEFT.
        updatedAt: '2023-06-09T14:02:14.181Z'
      numEdits: 0
      reactions: []
    id: 648330e68bfd740d4e0bd519
    type: comment
  author: FalconLLM
  content: If you are interested in finetuning the models, we would recommend having
    a look at [FalconTune](https://github.com/rmihaylov/falcontune) (which supports
    finetuning in 4-bit) or at this [blogpost from HF](https://huggingface.co/blog/falcon#fine-tuning-with-peft),
    specifically at the section on finetuning the model with PEFT.
  created_at: 2023-06-09 13:02:14+00:00
  edited: false
  hidden: false
  id: 648330e68bfd740d4e0bd519
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fc04bf42b8982bc319340e9091eaa044.svg
      fullname: vi-c
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vi-c
      type: user
    createdAt: '2023-07-11T15:28:36.000Z'
    data:
      edited: false
      editors:
      - vi-c
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8480284810066223
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fc04bf42b8982bc319340e9091eaa044.svg
          fullname: vi-c
          isHf: false
          isPro: false
          name: vi-c
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;cekal&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/cekal\"\
          >@<span class=\"underline\">cekal</span></a></span>\n\n\t</span></span>\
          \ how did you get it to work finally ? I also tried modifying the Alpaca-LORA\
          \ code by changing AutoTokenizer &amp; AutoModelForCausalLM.<br>Also changed\
          \ lora_target_module to [\"query_key_value\"].</p>\n<p>I get the error <code>ValueError:\
          \ The length of enable_lora must divide out_features</code></p>\n<p><em>EDIT\
          \ - Fixed by updating the packages.</em></p>\n</blockquote>\n<p>hi sumegh,\
          \ which package are you referring to ? I get the same error and don't know\
          \ how to fix it.</p>\n"
        raw: "> @cekal how did you get it to work finally ? I also tried modifying\
          \ the Alpaca-LORA code by changing AutoTokenizer & AutoModelForCausalLM.\
          \ \n> Also changed lora_target_module to [\"query_key_value\"].\n> \n> I\
          \ get the error `ValueError: The length of enable_lora must divide out_features`\n\
          > \n> *EDIT - Fixed by updating the packages.*\n\nhi sumegh, which package\
          \ are you referring to ? I get the same error and don't know how to fix\
          \ it."
        updatedAt: '2023-07-11T15:28:36.249Z'
      numEdits: 0
      reactions: []
    id: 64ad752409d1b58891f6dacc
    type: comment
  author: vi-c
  content: "> @cekal how did you get it to work finally ? I also tried modifying the\
    \ Alpaca-LORA code by changing AutoTokenizer & AutoModelForCausalLM. \n> Also\
    \ changed lora_target_module to [\"query_key_value\"].\n> \n> I get the error\
    \ `ValueError: The length of enable_lora must divide out_features`\n> \n> *EDIT\
    \ - Fixed by updating the packages.*\n\nhi sumegh, which package are you referring\
    \ to ? I get the same error and don't know how to fix it."
  created_at: 2023-07-11 14:28:36+00:00
  edited: false
  hidden: false
  id: 64ad752409d1b58891f6dacc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ff9452783ffd8b268e17bc102ad8cf97.svg
      fullname: Sumegh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sumegh
      type: user
    createdAt: '2023-07-11T15:40:30.000Z'
    data:
      edited: false
      editors:
      - sumegh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8788591623306274
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ff9452783ffd8b268e17bc102ad8cf97.svg
          fullname: Sumegh
          isHf: false
          isPro: false
          name: sumegh
          type: user
        html: "<blockquote>\n<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;cekal&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/cekal\"\
          >@<span class=\"underline\">cekal</span></a></span>\n\n\t</span></span>\
          \ how did you get it to work finally ? I also tried modifying the Alpaca-LORA\
          \ code by changing AutoTokenizer &amp; AutoModelForCausalLM.<br>Also changed\
          \ lora_target_module to [\"query_key_value\"].</p>\n<p>I get the error <code>ValueError:\
          \ The length of enable_lora must divide out_features</code></p>\n<p><em>EDIT\
          \ - Fixed by updating the packages.</em></p>\n</blockquote>\n<p>hi sumegh,\
          \ which package are you referring to ? I get the same error and don't know\
          \ how to fix it.</p>\n</blockquote>\n<p>I updated my CUDA version to 11.8\
          \ and re-installed all packages following the jupyter notebook as it is.\
          \ It worked.</p>\n"
        raw: "> > @cekal how did you get it to work finally ? I also tried modifying\
          \ the Alpaca-LORA code by changing AutoTokenizer & AutoModelForCausalLM.\
          \ \n> > Also changed lora_target_module to [\"query_key_value\"].\n> > \n\
          > > I get the error `ValueError: The length of enable_lora must divide out_features`\n\
          > > \n> > *EDIT - Fixed by updating the packages.*\n> \n> hi sumegh, which\
          \ package are you referring to ? I get the same error and don't know how\
          \ to fix it.\n\nI updated my CUDA version to 11.8 and re-installed all packages\
          \ following the jupyter notebook as it is. It worked."
        updatedAt: '2023-07-11T15:40:30.357Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - vi-c
      - count: 1
        reaction: "\U0001F44D"
        users:
        - vi-c
    id: 64ad77eec29542a745b65cf6
    type: comment
  author: sumegh
  content: "> > @cekal how did you get it to work finally ? I also tried modifying\
    \ the Alpaca-LORA code by changing AutoTokenizer & AutoModelForCausalLM. \n> >\
    \ Also changed lora_target_module to [\"query_key_value\"].\n> > \n> > I get the\
    \ error `ValueError: The length of enable_lora must divide out_features`\n> >\
    \ \n> > *EDIT - Fixed by updating the packages.*\n> \n> hi sumegh, which package\
    \ are you referring to ? I get the same error and don't know how to fix it.\n\n\
    I updated my CUDA version to 11.8 and re-installed all packages following the\
    \ jupyter notebook as it is. It worked."
  created_at: 2023-07-11 14:40:30+00:00
  edited: false
  hidden: false
  id: 64ad77eec29542a745b65cf6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d0eb07de8a750405eb5dd139731aa545.svg
      fullname: Sahil Malhotra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sahilmalhotra17
      type: user
    createdAt: '2023-09-15T15:11:03.000Z'
    data:
      edited: true
      editors:
      - sahilmalhotra17
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9524915814399719
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d0eb07de8a750405eb5dd139731aa545.svg
          fullname: Sahil Malhotra
          isHf: false
          isPro: false
          name: sahilmalhotra17
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;FalconLLM&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/FalconLLM\">@<span class=\"\
          underline\">FalconLLM</span></a></span>\n\n\t</span></span><br>Is there\
          \ any literature published on the internal architecture of the decoder blocks\
          \ and how they are organized? Are there any plans for a publication anytime\
          \ soon?<br>I would like to experiment with only touching certain submodules\
          \ (instead of all) with LoRA/QLoRA adapters during fine tuning for some\
          \ understanding on how the self attention block and the mlp block across\
          \ various decoder layers contribute to overall model performance.</p>\n"
        raw: "@FalconLLM  \nIs there any literature published on the internal architecture\
          \ of the decoder blocks and how they are organized? Are there any plans\
          \ for a publication anytime soon?\nI would like to experiment with only\
          \ touching certain submodules (instead of all) with LoRA/QLoRA adapters\
          \ during fine tuning for some understanding on how the self attention block\
          \ and the mlp block across various decoder layers contribute to overall\
          \ model performance."
        updatedAt: '2023-09-15T15:12:04.384Z'
      numEdits: 1
      reactions: []
    id: 650474075e7b86997d24efad
    type: comment
  author: sahilmalhotra17
  content: "@FalconLLM  \nIs there any literature published on the internal architecture\
    \ of the decoder blocks and how they are organized? Are there any plans for a\
    \ publication anytime soon?\nI would like to experiment with only touching certain\
    \ submodules (instead of all) with LoRA/QLoRA adapters during fine tuning for\
    \ some understanding on how the self attention block and the mlp block across\
    \ various decoder layers contribute to overall model performance."
  created_at: 2023-09-15 14:11:03+00:00
  edited: true
  hidden: false
  id: 650474075e7b86997d24efad
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: tiiuae/falcon-7b
repo_type: model
status: open
target_branch: null
title: Support for LoRA?
