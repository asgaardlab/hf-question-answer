!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mhyatt000
conflicting_files: null
created_at: 2022-08-20 17:07:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658862186149-62b09fe1a14cbd64386c042d.jpeg?w=200&h=200&f=face
      fullname: Matt Hyatt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mhyatt000
      type: user
    createdAt: '2022-08-20T18:07:11.000Z'
    data:
      edited: false
      editors:
      - mhyatt000
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658862186149-62b09fe1a14cbd64386c042d.jpeg?w=200&h=200&f=face
          fullname: Matt Hyatt
          isHf: false
          isPro: false
          name: mhyatt000
          type: user
        html: "<p>I tried to reproduce the results mentioned on this model card. The\
          \ received mAP does not match the claimed mAP in the model card.</p>\n<ul>\n\
          <li>Claimed mAP: 28.7</li>\n<li>Recieved mAP: 24.7</li>\n</ul>\n<p>Here\
          \ are the details for my validation:</p>\n<ul>\n<li>I instantiate pre-trained\
          \ model with <code>transformers.pipeline()</code> and use COCO API to calculate\
          \ AP from detection bboxes. </li>\n<li>Evaluation was performed on macOS\
          \ CPU.</li>\n<li>Dataset was downloaded from cocodataset.org</li>\n</ul>\n\
          <hr>\n<pre><code> Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all\
          \ | maxDets=100 ] = 0.247\n Average Precision  (AP) @[ IoU=0.50      | area=\
          \   all | maxDets=100 ] = 0.427\n Average Precision  (AP) @[ IoU=0.75  \
          \    | area=   all | maxDets=100 ] = 0.243\n Average Precision  (AP) @[\
          \ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n Average Precision\
          \  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.245\n Average\
          \ Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425\n\
          \ Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ]\
          \ = 0.231\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=\
          \ 10 ] = 0.333\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all\
          \ | maxDets=100 ] = 0.344\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=\
          \ small | maxDets=100 ] = 0.103\n Average Recall     (AR) @[ IoU=0.50:0.95\
          \ | area=medium | maxDets=100 ] = 0.355\n Average Recall     (AR) @[ IoU=0.50:0.95\
          \ | area= large | maxDets=100 ] = 0.563\n</code></pre>\n"
        raw: "I tried to reproduce the results mentioned on this model card. The received\
          \ mAP does not match the claimed mAP in the model card.\r\n\r\n- Claimed\
          \ mAP: 28.7\r\n- Recieved mAP: 24.7\r\n\r\nHere are the details for my validation:\r\
          \n\r\n- I instantiate pre-trained model with `transformers.pipeline()` and\
          \ use COCO API to calculate AP from detection bboxes. \r\n- Evaluation was\
          \ performed on macOS CPU.\r\n- Dataset was downloaded from cocodataset.org\r\
          \n---\r\n\r\n```\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=  \
          \ all | maxDets=100 ] = 0.247\r\n Average Precision  (AP) @[ IoU=0.50  \
          \    | area=   all | maxDets=100 ] = 0.427\r\n Average Precision  (AP) @[\
          \ IoU=0.75      | area=   all | maxDets=100 ] = 0.243\r\n Average Precision\
          \  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\r\n Average\
          \ Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.245\r\
          \n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100\
          \ ] = 0.425\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all |\
          \ maxDets=  1 ] = 0.231\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=\
          \   all | maxDets= 10 ] = 0.333\r\n Average Recall     (AR) @[ IoU=0.50:0.95\
          \ | area=   all | maxDets=100 ] = 0.344\r\n Average Recall     (AR) @[ IoU=0.50:0.95\
          \ | area= small | maxDets=100 ] = 0.103\r\n Average Recall     (AR) @[ IoU=0.50:0.95\
          \ | area=medium | maxDets=100 ] = 0.355\r\n Average Recall     (AR) @[ IoU=0.50:0.95\
          \ | area= large | maxDets=100 ] = 0.563\r\n```"
        updatedAt: '2022-08-20T18:07:11.186Z'
      numEdits: 0
      reactions: []
    id: 630122cf274b494f56072852
    type: comment
  author: mhyatt000
  content: "I tried to reproduce the results mentioned on this model card. The received\
    \ mAP does not match the claimed mAP in the model card.\r\n\r\n- Claimed mAP:\
    \ 28.7\r\n- Recieved mAP: 24.7\r\n\r\nHere are the details for my validation:\r\
    \n\r\n- I instantiate pre-trained model with `transformers.pipeline()` and use\
    \ COCO API to calculate AP from detection bboxes. \r\n- Evaluation was performed\
    \ on macOS CPU.\r\n- Dataset was downloaded from cocodataset.org\r\n---\r\n\r\n\
    ```\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ]\
    \ = 0.247\r\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100\
    \ ] = 0.427\r\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100\
    \ ] = 0.243\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100\
    \ ] = 0.065\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100\
    \ ] = 0.245\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100\
    \ ] = 0.425\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=\
    \  1 ] = 0.231\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=\
    \ 10 ] = 0.333\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100\
    \ ] = 0.344\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100\
    \ ] = 0.103\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100\
    \ ] = 0.355\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100\
    \ ] = 0.563\r\n```"
  created_at: 2022-08-20 17:07:11+00:00
  edited: false
  hidden: false
  id: 630122cf274b494f56072852
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: hustvl/yolos-tiny
repo_type: model
status: open
target_branch: null
title: mAP drop
