!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Khumbaba
conflicting_files: null
created_at: 2023-06-27 14:43:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2fa92ed3966d295f9c52b6facc7ab3af.svg
      fullname: Ali Kawtharani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Khumbaba
      type: user
    createdAt: '2023-06-27T15:43:40.000Z'
    data:
      edited: false
      editors:
      - Khumbaba
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8949252963066101
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2fa92ed3966d295f9c52b6facc7ab3af.svg
          fullname: Ali Kawtharani
          isHf: false
          isPro: false
          name: Khumbaba
          type: user
        html: '<p>Hello!</p>

          <p>Many in the literature on Personalized Speech Enhancement (PSE)  use
          your pretrained ECAPA-TDNN model to generate the embeddings from enrollment
          utterances (for instance, it''s the goto embedding model for Microsoft''s
          5th DNS challenge, check out its github). The issue is, they always mention
          an embedding size of 256 which boggles me, because your pretrained parameters
          has clearly 192 as output size for the encoder. Am I missing something?</p>

          <p>(btw, thank you for your valuable open source contributions!)</p>

          '
        raw: "Hello!\r\n\r\nMany in the literature on Personalized Speech Enhancement\
          \ (PSE)  use your pretrained ECAPA-TDNN model to generate the embeddings\
          \ from enrollment utterances (for instance, it's the goto embedding model\
          \ for Microsoft's 5th DNS challenge, check out its github). The issue is,\
          \ they always mention an embedding size of 256 which boggles me, because\
          \ your pretrained parameters has clearly 192 as output size for the encoder.\
          \ Am I missing something?\r\n\r\n(btw, thank you for your valuable open\
          \ source contributions!)"
        updatedAt: '2023-06-27T15:43:40.926Z'
      numEdits: 0
      reactions: []
    id: 649b03acca20306aeef7a211
    type: comment
  author: Khumbaba
  content: "Hello!\r\n\r\nMany in the literature on Personalized Speech Enhancement\
    \ (PSE)  use your pretrained ECAPA-TDNN model to generate the embeddings from\
    \ enrollment utterances (for instance, it's the goto embedding model for Microsoft's\
    \ 5th DNS challenge, check out its github). The issue is, they always mention\
    \ an embedding size of 256 which boggles me, because your pretrained parameters\
    \ has clearly 192 as output size for the encoder. Am I missing something?\r\n\r\
    \n(btw, thank you for your valuable open source contributions!)"
  created_at: 2023-06-27 14:43:40+00:00
  edited: false
  hidden: false
  id: 649b03acca20306aeef7a211
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: speechbrain/spkrec-ecapa-voxceleb
repo_type: model
status: open
target_branch: null
title: Pretrained ECAPA-TDNN with 256 as output?
