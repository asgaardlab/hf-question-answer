!!python/object:huggingface_hub.community.DiscussionWithDetails
author: YaTharThShaRma999
conflicting_files: null
created_at: 2023-10-09 13:29:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
      fullname: Yatharth  Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YaTharThShaRma999
      type: user
    createdAt: '2023-10-09T14:29:47.000Z'
    data:
      edited: false
      editors:
      - YaTharThShaRma999
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9913637638092041
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
          fullname: Yatharth  Sharma
          isHf: false
          isPro: false
          name: YaTharThShaRma999
          type: user
        html: "<p>It seems really intresting but how does it work? You did give a\
          \ description but I didn\u2019t really understand it. Could you explain\
          \ it a bit further but a bit simpler? Thanks anyway!</p>\n"
        raw: "It seems really intresting but how does it work? You did give a description\
          \ but I didn\u2019t really understand it. Could you explain it a bit further\
          \ but a bit simpler? Thanks anyway!"
        updatedAt: '2023-10-09T14:29:47.334Z'
      numEdits: 0
      reactions: []
    id: 65240e5bc2d934608387be23
    type: comment
  author: YaTharThShaRma999
  content: "It seems really intresting but how does it work? You did give a description\
    \ but I didn\u2019t really understand it. Could you explain it a bit further but\
    \ a bit simpler? Thanks anyway!"
  created_at: 2023-10-09 13:29:47+00:00
  edited: false
  hidden: false
  id: 65240e5bc2d934608387be23
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0015a4dd12e883a8a4ff0c8148313e7.svg
      fullname: John David Pressman
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: jdpressman
      type: user
    createdAt: '2023-10-11T12:34:02.000Z'
    data:
      edited: false
      editors:
      - jdpressman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8868165612220764
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0015a4dd12e883a8a4ff0c8148313e7.svg
          fullname: John David Pressman
          isHf: false
          isPro: false
          name: jdpressman
          type: user
        html: '<p>Basically it''s an encoder-decoder model made from a pretrained
          GPT-N (here, Mistral 7B). In the first phase it is trained to encode and
          decode a 64 token sentence. In the next phase I train a main "router head"
          which reconstructs 64 tokens from an embedding and then predicts the next
          64 tokens. You can then use the resulting model to guide sampling, encode
          text for later retrieval, etc.</p>

          '
        raw: Basically it's an encoder-decoder model made from a pretrained GPT-N
          (here, Mistral 7B). In the first phase it is trained to encode and decode
          a 64 token sentence. In the next phase I train a main "router head" which
          reconstructs 64 tokens from an embedding and then predicts the next 64 tokens.
          You can then use the resulting model to guide sampling, encode text for
          later retrieval, etc.
        updatedAt: '2023-10-11T12:34:02.110Z'
      numEdits: 0
      reactions: []
    id: 6526963a2f6f160f577bfd36
    type: comment
  author: jdpressman
  content: Basically it's an encoder-decoder model made from a pretrained GPT-N (here,
    Mistral 7B). In the first phase it is trained to encode and decode a 64 token
    sentence. In the next phase I train a main "router head" which reconstructs 64
    tokens from an embedding and then predicts the next 64 tokens. You can then use
    the resulting model to guide sampling, encode text for later retrieval, etc.
  created_at: 2023-10-11 11:34:02+00:00
  edited: false
  hidden: false
  id: 6526963a2f6f160f577bfd36
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
      fullname: Yatharth  Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YaTharThShaRma999
      type: user
    createdAt: '2023-10-11T12:52:53.000Z'
    data:
      edited: false
      editors:
      - YaTharThShaRma999
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8371745944023132
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
          fullname: Yatharth  Sharma
          isHf: false
          isPro: false
          name: YaTharThShaRma999
          type: user
        html: '<p>Ah, ok. Thanks for explaining it now!</p>

          '
        raw: Ah, ok. Thanks for explaining it now!
        updatedAt: '2023-10-11T12:52:53.174Z'
      numEdits: 0
      reactions: []
    id: 65269aa5b97d8aa0cf7ffeee
    type: comment
  author: YaTharThShaRma999
  content: Ah, ok. Thanks for explaining it now!
  created_at: 2023-10-11 11:52:53+00:00
  edited: false
  hidden: false
  id: 65269aa5b97d8aa0cf7ffeee
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: jdpressman/BigVAE-Mistral-7B-v0.1
repo_type: model
status: open
target_branch: null
title: How does this work? Thanks!
