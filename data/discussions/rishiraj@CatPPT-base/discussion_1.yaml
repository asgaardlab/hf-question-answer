!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Phil337
conflicting_files: null
created_at: 2023-12-23 03:42:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-23T03:42:55.000Z'
    data:
      edited: true
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9589977860450745
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>This shows up as a foundational model on the HF leaderboard with
          a green icon next to its name.</p>

          <p>Am I missing something? A foundational model, as defined everywhere,
          including at HF, isn''t a fine-tune, let alone a slerp merge. A foundational
          model is an unsupervised model made from a large corpus of data trained
          using millions of dollars in hardware over months, such as Mistral, or a
          non-fine-tuned modification like Solar.</p>

          <p>This is just a slerp merge of two Mistral fine-tunes. It''s no more a
          foundational model than the 100s of other Mistral mergers. Just because
          you did additional fine-tuning when making your CatPPL version doesn''t
          change the fact that this CatPPL-Base is just a slerp merge.</p>

          <p>Edit: Plus you should make it clear what neuralchat and openchat versions
          you used. And while I like them both, they are anything but free of contamination.</p>

          '
        raw: 'This shows up as a foundational model on the HF leaderboard with a green
          icon next to its name.


          Am I missing something? A foundational model, as defined everywhere, including
          at HF, isn''t a fine-tune, let alone a slerp merge. A foundational model
          is an unsupervised model made from a large corpus of data trained using
          millions of dollars in hardware over months, such as Mistral, or a non-fine-tuned
          modification like Solar.


          This is just a slerp merge of two Mistral fine-tunes. It''s no more a foundational
          model than the 100s of other Mistral mergers. Just because you did additional
          fine-tuning when making your CatPPL version doesn''t change the fact that
          this CatPPL-Base is just a slerp merge.


          Edit: Plus you should make it clear what neuralchat and openchat versions
          you used. And while I like them both, they are anything but free of contamination.'
        updatedAt: '2023-12-23T03:51:02.800Z'
      numEdits: 1
      reactions: []
    id: 6586573fae21a8ff281cdedb
    type: comment
  author: Phil337
  content: 'This shows up as a foundational model on the HF leaderboard with a green
    icon next to its name.


    Am I missing something? A foundational model, as defined everywhere, including
    at HF, isn''t a fine-tune, let alone a slerp merge. A foundational model is an
    unsupervised model made from a large corpus of data trained using millions of
    dollars in hardware over months, such as Mistral, or a non-fine-tuned modification
    like Solar.


    This is just a slerp merge of two Mistral fine-tunes. It''s no more a foundational
    model than the 100s of other Mistral mergers. Just because you did additional
    fine-tuning when making your CatPPL version doesn''t change the fact that this
    CatPPL-Base is just a slerp merge.


    Edit: Plus you should make it clear what neuralchat and openchat versions you
    used. And while I like them both, they are anything but free of contamination.'
  created_at: 2023-12-23 03:42:55+00:00
  edited: true
  hidden: false
  id: 6586573fae21a8ff281cdedb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61030ed7d6edf00e0107a465/JP29xIxDfvQAsFgxpNkbp.png?w=200&h=200&f=face
      fullname: Rishiraj Acharya
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: rishiraj
      type: user
    createdAt: '2023-12-23T12:22:32.000Z'
    data:
      edited: false
      editors:
      - rishiraj
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9797614812850952
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61030ed7d6edf00e0107a465/JP29xIxDfvQAsFgxpNkbp.png?w=200&h=200&f=face
          fullname: Rishiraj Acharya
          isHf: false
          isPro: false
          name: rishiraj
          type: user
        html: '<p>yes maybe the category has been wrongly marked. do you know a way
          how can it be corrected? i feel part of the reason it is marked as pretrained
          is because the resulting merge model was not finetuned for instruction/chat
          on any dataset and was acting more of a text completion model if you try
          using it.</p>

          <p>the version of models being merged are Intel/neural-chat-7b-v3-3 and
          openchat/openchat-3.5-1210, both of which are free of contamination in my
          knowledge. if you feel otherwise, please raise an issue againt them in their
          own discussion and if any of them are found to be contaminated, I''ll personally
          mark this model to be contaminated as well.</p>

          '
        raw: 'yes maybe the category has been wrongly marked. do you know a way how
          can it be corrected? i feel part of the reason it is marked as pretrained
          is because the resulting merge model was not finetuned for instruction/chat
          on any dataset and was acting more of a text completion model if you try
          using it.


          the version of models being merged are Intel/neural-chat-7b-v3-3 and openchat/openchat-3.5-1210,
          both of which are free of contamination in my knowledge. if you feel otherwise,
          please raise an issue againt them in their own discussion and if any of
          them are found to be contaminated, I''ll personally mark this model to be
          contaminated as well.'
        updatedAt: '2023-12-23T12:22:32.727Z'
      numEdits: 0
      reactions: []
    id: 6586d108dda02636b0a514e2
    type: comment
  author: rishiraj
  content: 'yes maybe the category has been wrongly marked. do you know a way how
    can it be corrected? i feel part of the reason it is marked as pretrained is because
    the resulting merge model was not finetuned for instruction/chat on any dataset
    and was acting more of a text completion model if you try using it.


    the version of models being merged are Intel/neural-chat-7b-v3-3 and openchat/openchat-3.5-1210,
    both of which are free of contamination in my knowledge. if you feel otherwise,
    please raise an issue againt them in their own discussion and if any of them are
    found to be contaminated, I''ll personally mark this model to be contaminated
    as well.'
  created_at: 2023-12-23 12:22:32+00:00
  edited: false
  hidden: false
  id: 6586d108dda02636b0a514e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-23T16:31:37.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9647572636604309
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;rishiraj&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/rishiraj\">@<span class=\"\
          underline\">rishiraj</span></a></span>\n\n\t</span></span> My concern about\
          \ the pre-train mark is not with this particular merge, but with the floodgates\
          \ it may open.</p>\n<p>HF has a merger problem. It's being flooded by them\
          \ and it's hard to identify them at first glance, or even when reading their\
          \ model cards. And if they start labeling mergers as pre-trained the merger\
          \ confusion will only get worse. So my advice would be to avoid labeling\
          \ mergers as pre-trained going forward. Also, this model has SFT, DPO, RLAIF...\
          \ from neural and chat, so they aren't just completing text like foundational\
          \ models. They can be used like any other fine-tunes in 0-prompt contexts\
          \ (e.g. Q&amp;A).</p>\n<p>Regarding the contamination, I have never personally\
          \ identified contamination, nor know how to, but others have (see link).\
          \ And for example, neural 3.3 is contaminated with GSM8K (MetaMath), and\
          \ almost certainly with TruthfulQA data as well. And this matches my experience\
          \ with both (openchat as well) and knowledge of how they were made (e.g.\
          \ DPO and RLAIF). Such training methods inevitably get contaminated with\
          \ TruthfulQA. MetaMath is respectable and transparent, but contaminated\
          \ with GSM8K data. In short, the models you merged aren't deliberately \"\
          cheating\", but there's a &gt;95% chance that they have a significant amount\
          \ of contamination (an artificial ~5 point boost in both TruthfulQA and\
          \ GSM8K scores that don't reflect their true performance) . This is the\
          \ main problem with mergers. They only perform about 2 points higher than\
          \ their parent models, yet are scoring ~5 or more points higher due to the\
          \ build-up of test contamination, putting them higher on the leaderboard\
          \ than higher performing models like Mixtral.</p>\n<p><a href=\"https://huggingface.co/spaces/Yeyito/llm_contamination_detector\"\
          >https://huggingface.co/spaces/Yeyito/llm_contamination_detector</a></p>\n"
        raw: '@rishiraj My concern about the pre-train mark is not with this particular
          merge, but with the floodgates it may open.


          HF has a merger problem. It''s being flooded by them and it''s hard to identify
          them at first glance, or even when reading their model cards. And if they
          start labeling mergers as pre-trained the merger confusion will only get
          worse. So my advice would be to avoid labeling mergers as pre-trained going
          forward. Also, this model has SFT, DPO, RLAIF... from neural and chat, so
          they aren''t just completing text like foundational models. They can be
          used like any other fine-tunes in 0-prompt contexts (e.g. Q&A).


          Regarding the contamination, I have never personally identified contamination,
          nor know how to, but others have (see link). And for example, neural 3.3
          is contaminated with GSM8K (MetaMath), and almost certainly with TruthfulQA
          data as well. And this matches my experience with both (openchat as well)
          and knowledge of how they were made (e.g. DPO and RLAIF). Such training
          methods inevitably get contaminated with TruthfulQA. MetaMath is respectable
          and transparent, but contaminated with GSM8K data. In short, the models
          you merged aren''t deliberately "cheating", but there''s a >95% chance that
          they have a significant amount of contamination (an artificial ~5 point
          boost in both TruthfulQA and GSM8K scores that don''t reflect their true
          performance) . This is the main problem with mergers. They only perform
          about 2 points higher than their parent models, yet are scoring ~5 or more
          points higher due to the build-up of test contamination, putting them higher
          on the leaderboard than higher performing models like Mixtral.


          https://huggingface.co/spaces/Yeyito/llm_contamination_detector'
        updatedAt: '2023-12-23T16:31:37.698Z'
      numEdits: 0
      reactions: []
    id: 65870b69991d8e7fb2e37bca
    type: comment
  author: Phil337
  content: '@rishiraj My concern about the pre-train mark is not with this particular
    merge, but with the floodgates it may open.


    HF has a merger problem. It''s being flooded by them and it''s hard to identify
    them at first glance, or even when reading their model cards. And if they start
    labeling mergers as pre-trained the merger confusion will only get worse. So my
    advice would be to avoid labeling mergers as pre-trained going forward. Also,
    this model has SFT, DPO, RLAIF... from neural and chat, so they aren''t just completing
    text like foundational models. They can be used like any other fine-tunes in 0-prompt
    contexts (e.g. Q&A).


    Regarding the contamination, I have never personally identified contamination,
    nor know how to, but others have (see link). And for example, neural 3.3 is contaminated
    with GSM8K (MetaMath), and almost certainly with TruthfulQA data as well. And
    this matches my experience with both (openchat as well) and knowledge of how they
    were made (e.g. DPO and RLAIF). Such training methods inevitably get contaminated
    with TruthfulQA. MetaMath is respectable and transparent, but contaminated with
    GSM8K data. In short, the models you merged aren''t deliberately "cheating", but
    there''s a >95% chance that they have a significant amount of contamination (an
    artificial ~5 point boost in both TruthfulQA and GSM8K scores that don''t reflect
    their true performance) . This is the main problem with mergers. They only perform
    about 2 points higher than their parent models, yet are scoring ~5 or more points
    higher due to the build-up of test contamination, putting them higher on the leaderboard
    than higher performing models like Mixtral.


    https://huggingface.co/spaces/Yeyito/llm_contamination_detector'
  created_at: 2023-12-23 16:31:37+00:00
  edited: false
  hidden: false
  id: 65870b69991d8e7fb2e37bca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-23T16:31:45.000Z'
    data:
      status: closed
    id: 65870b7165df457a558ef017
    type: status-change
  author: Phil337
  created_at: 2023-12-23 16:31:45+00:00
  id: 65870b7165df457a558ef017
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: rishiraj/CatPPT-base
repo_type: model
status: closed
target_branch: null
title: Foundational Model?
