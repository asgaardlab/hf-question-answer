!!python/object:huggingface_hub.community.DiscussionWithDetails
author: LaferriereJC
conflicting_files: null
created_at: 2023-09-30 19:41:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7e8da869c47dbc3f9052f1cbd4cc5ae6.svg
      fullname: Joshua Laferriere
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LaferriereJC
      type: user
    createdAt: '2023-09-30T20:41:30.000Z'
    data:
      edited: true
      editors:
      - LaferriereJC
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.44252142310142517
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7e8da869c47dbc3f9052f1cbd4cc5ae6.svg
          fullname: Joshua Laferriere
          isHf: false
          isPro: false
          name: LaferriereJC
          type: user
        html: '<p>python server.py --api --listen --trust-remote-code --disk-cache-dir
          /data/tmp --use_double_quant --quant_type nf4 --load-in-4bit --settings
          settings-template.yaml --model models/DeciLM-6b-instruct/</p>

          <p>To create a public link, set <code>share=True</code> in <code>launch()</code>.<br>Traceback
          (most recent call last):<br>  File "/home/user/text-generation-webui/modules/callbacks.py",
          line 56, in gentask<br>    ret = self.mfunc(callback=_callback, *args, **self.kwargs)<br>  File
          "/home/user/text-generation-webui/modules/text_generation.py", line 347,
          in generate_with_callback<br>    shared.model.generate(**kwargs)<br>  File
          "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/utils/_contextlib.py",
          line 115, in decorate_context<br>    return func(*args, **kwargs)<br>  File
          "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/generation/utils.py",
          line 1652, in generate<br>    return self.sample(<br>  File "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/generation/utils.py",
          line 2734, in sample<br>    outputs = self(<br>  File "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl<br>    return forward_call(*args, **kwargs)<br>  File
          "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/accelerate/hooks.py",
          line 165, in new_forward<br>    output = old_forward(*args, **kwargs)<br>  File
          "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py",
          line 1034, in forward<br>    outputs = self.model(<br>  File "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl<br>    return forward_call(*args, **kwargs)<br>  File
          "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/accelerate/hooks.py",
          line 165, in new_forward<br>    output = old_forward(*args, **kwargs)<br>  File
          "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py",
          line 921, in forward<br>    layer_outputs = decoder_layer(<br>  File "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl<br>    return forward_call(*args, **kwargs)<br>  File
          "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/accelerate/hooks.py",
          line 165, in new_forward<br>    output = old_forward(*args, **kwargs)<br>  File
          "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py",
          line 631, in forward<br>    hidden_states, self_attn_weights, present_key_value
          = self.self_attn(<br>  File "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl<br>    return forward_call(*args, **kwargs)<br>  File
          "/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/accelerate/hooks.py",
          line 165, in new_forward<br>    output = old_forward(*args, **kwargs)<br>TypeError:
          DeciLMAttention.forward() got an unexpected keyword argument ''padding_mask''<br>Output
          generated in 0.28 seconds (0.00 tokens/s, 0 tokens, context 207, seed 880665434)</p>

          '
        raw: "python server.py --api --listen --trust-remote-code --disk-cache-dir\
          \ /data/tmp --use_double_quant --quant_type nf4 --load-in-4bit --settings\
          \ settings-template.yaml --model models/DeciLM-6b-instruct/\n\nTo create\
          \ a public link, set `share=True` in `launch()`.\nTraceback (most recent\
          \ call last):\n  File \"/home/user/text-generation-webui/modules/callbacks.py\"\
          , line 56, in gentask\n    ret = self.mfunc(callback=_callback, *args, **self.kwargs)\n\
          \  File \"/home/user/text-generation-webui/modules/text_generation.py\"\
          , line 347, in generate_with_callback\n    shared.model.generate(**kwargs)\n\
          \  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 1652, in generate\n    return self.sample(\n  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 2734, in sample\n    outputs = self(\n  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\"\
          , line 1034, in forward\n    outputs = self.model(\n  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\"\
          , line 921, in forward\n    layer_outputs = decoder_layer(\n  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\"\
          , line 631, in forward\n    hidden_states, self_attn_weights, present_key_value\
          \ = self.self_attn(\n  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          TypeError: DeciLMAttention.forward() got an unexpected keyword argument\
          \ 'padding_mask'\nOutput generated in 0.28 seconds (0.00 tokens/s, 0 tokens,\
          \ context 207, seed 880665434)\n"
        updatedAt: '2023-09-30T20:42:45.143Z'
      numEdits: 1
      reactions: []
    id: 651887fa53c98221043e25db
    type: comment
  author: LaferriereJC
  content: "python server.py --api --listen --trust-remote-code --disk-cache-dir /data/tmp\
    \ --use_double_quant --quant_type nf4 --load-in-4bit --settings settings-template.yaml\
    \ --model models/DeciLM-6b-instruct/\n\nTo create a public link, set `share=True`\
    \ in `launch()`.\nTraceback (most recent call last):\n  File \"/home/user/text-generation-webui/modules/callbacks.py\"\
    , line 56, in gentask\n    ret = self.mfunc(callback=_callback, *args, **self.kwargs)\n\
    \  File \"/home/user/text-generation-webui/modules/text_generation.py\", line\
    \ 347, in generate_with_callback\n    shared.model.generate(**kwargs)\n  File\
    \ \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 1652, in generate\n    return self.sample(\n  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 2734, in sample\n    outputs = self(\n  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n  File\
    \ \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\"\
    , line 1034, in forward\n    outputs = self.model(\n  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n  File\
    \ \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\"\
    , line 921, in forward\n    layer_outputs = decoder_layer(\n  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n  File\
    \ \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\"\
    , line 631, in forward\n    hidden_states, self_attn_weights, present_key_value\
    \ = self.self_attn(\n  File \"/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\n    output = old_forward(*args, **kwargs)\nTypeError:\
    \ DeciLMAttention.forward() got an unexpected keyword argument 'padding_mask'\n\
    Output generated in 0.28 seconds (0.00 tokens/s, 0 tokens, context 207, seed 880665434)\n"
  created_at: 2023-09-30 19:41:30+00:00
  edited: true
  hidden: false
  id: 651887fa53c98221043e25db
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/31517c94ac6390273cc9dd6e869faf98.svg
      fullname: Akhiad
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Informer
      type: user
    createdAt: '2023-09-30T21:17:17.000Z'
    data:
      edited: false
      editors:
      - Informer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8847073316574097
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/31517c94ac6390273cc9dd6e869faf98.svg
          fullname: Akhiad
          isHf: false
          isPro: false
          name: Informer
          type: user
        html: '<p>This is due to a change in transformers latest version, we will
          push a fix shortly. Meanwhile you can ''pip install transformers==4.31.0''
          if you want, no issue there</p>

          '
        raw: This is due to a change in transformers latest version, we will push
          a fix shortly. Meanwhile you can 'pip install transformers==4.31.0' if you
          want, no issue there
        updatedAt: '2023-09-30T21:17:17.422Z'
      numEdits: 0
      reactions: []
    id: 6518905d493fe76b25d36813
    type: comment
  author: Informer
  content: This is due to a change in transformers latest version, we will push a
    fix shortly. Meanwhile you can 'pip install transformers==4.31.0' if you want,
    no issue there
  created_at: 2023-09-30 20:17:17+00:00
  edited: false
  hidden: false
  id: 6518905d493fe76b25d36813
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7e8da869c47dbc3f9052f1cbd4cc5ae6.svg
      fullname: Joshua Laferriere
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LaferriereJC
      type: user
    createdAt: '2023-09-30T21:57:42.000Z'
    data:
      edited: true
      editors:
      - LaferriereJC
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4327252209186554
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7e8da869c47dbc3f9052f1cbd4cc5ae6.svg
          fullname: Joshua Laferriere
          isHf: false
          isPro: false
          name: LaferriereJC
          type: user
        html: '<p>2023-09-30 14:59:26 WARNING:trust_remote_code is enabled. This is
          dangerous.<br>2023-09-30 14:59:26 WARNING:<br>You are potentially exposing
          the web UI to the entire internet without any access password.<br>You can
          create one with the "--gradio-auth" flag like this:</p>

          <p>--gradio-auth username:password</p>

          <p>Make sure to replace username:password with your own.<br>Traceback (most
          recent call last):<br>  File "/home/user/text-generation-webui/server.py",
          line 30, in <br>    from modules import (<br>  File "/home/user/text-generation-webui/modules/chat.py",
          line 18, in <br>    from modules.text_generation import (<br>  File "/home/user/text-generation-webui/modules/text_generation.py",
          line 23, in <br>    from modules.models import clear_torch_cache, local_rank<br>  File
          "/home/user/text-generation-webui/modules/models.py", line 11, in <br>    from
          transformers import (<br>ImportError: cannot import name ''GPTQConfig''
          from ''transformers'' (/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/<strong>init</strong>.py)</p>

          '
        raw: "2023-09-30 14:59:26 WARNING:trust_remote_code is enabled. This is dangerous.\n\
          2023-09-30 14:59:26 WARNING:\nYou are potentially exposing the web UI to\
          \ the entire internet without any access password.\nYou can create one with\
          \ the \"--gradio-auth\" flag like this:\n\n--gradio-auth username:password\n\
          \nMake sure to replace username:password with your own.\nTraceback (most\
          \ recent call last):\n  File \"/home/user/text-generation-webui/server.py\"\
          , line 30, in <module>\n    from modules import (\n  File \"/home/user/text-generation-webui/modules/chat.py\"\
          , line 18, in <module>\n    from modules.text_generation import (\n  File\
          \ \"/home/user/text-generation-webui/modules/text_generation.py\", line\
          \ 23, in <module>\n    from modules.models import clear_torch_cache, local_rank\n\
          \  File \"/home/user/text-generation-webui/modules/models.py\", line 11,\
          \ in <module>\n    from transformers import (\nImportError: cannot import\
          \ name 'GPTQConfig' from 'transformers' (/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/__init__.py)\n"
        updatedAt: '2023-09-30T21:59:58.635Z'
      numEdits: 2
      reactions: []
    id: 651899d6ce732bf33a40939c
    type: comment
  author: LaferriereJC
  content: "2023-09-30 14:59:26 WARNING:trust_remote_code is enabled. This is dangerous.\n\
    2023-09-30 14:59:26 WARNING:\nYou are potentially exposing the web UI to the entire\
    \ internet without any access password.\nYou can create one with the \"--gradio-auth\"\
    \ flag like this:\n\n--gradio-auth username:password\n\nMake sure to replace username:password\
    \ with your own.\nTraceback (most recent call last):\n  File \"/home/user/text-generation-webui/server.py\"\
    , line 30, in <module>\n    from modules import (\n  File \"/home/user/text-generation-webui/modules/chat.py\"\
    , line 18, in <module>\n    from modules.text_generation import (\n  File \"/home/user/text-generation-webui/modules/text_generation.py\"\
    , line 23, in <module>\n    from modules.models import clear_torch_cache, local_rank\n\
    \  File \"/home/user/text-generation-webui/modules/models.py\", line 11, in <module>\n\
    \    from transformers import (\nImportError: cannot import name 'GPTQConfig'\
    \ from 'transformers' (/home/user/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/__init__.py)\n"
  created_at: 2023-09-30 20:57:42+00:00
  edited: true
  hidden: false
  id: 651899d6ce732bf33a40939c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/028ebd51b2b71598f1a070117f109eaa.svg
      fullname: Itay  Levy
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: itay-levy
      type: user
    createdAt: '2023-10-01T08:30:39.000Z'
    data:
      edited: false
      editors:
      - itay-levy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8599075675010681
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/028ebd51b2b71598f1a070117f109eaa.svg
          fullname: Itay  Levy
          isHf: false
          isPro: false
          name: itay-levy
          type: user
        html: '<p>Hey Joshua<br>We''ve pushed a fix to support the latest transformers
          dev version</p>

          '
        raw: 'Hey Joshua

          We''ve pushed a fix to support the latest transformers dev version'
        updatedAt: '2023-10-01T08:30:39.753Z'
      numEdits: 0
      reactions: []
    id: 65192e2f34c26962537e80b2
    type: comment
  author: itay-levy
  content: 'Hey Joshua

    We''ve pushed a fix to support the latest transformers dev version'
  created_at: 2023-10-01 07:30:39+00:00
  edited: false
  hidden: false
  id: 65192e2f34c26962537e80b2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7e8da869c47dbc3f9052f1cbd4cc5ae6.svg
      fullname: Joshua Laferriere
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LaferriereJC
      type: user
    createdAt: '2023-10-01T12:52:31.000Z'
    data:
      edited: false
      editors:
      - LaferriereJC
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9620960354804993
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7e8da869c47dbc3f9052f1cbd4cc5ae6.svg
          fullname: Joshua Laferriere
          isHf: false
          isPro: false
          name: LaferriereJC
          type: user
        html: '<p>My bad. I thought I commented but after updating to latest transformers.
          The issue went away</p>

          '
        raw: My bad. I thought I commented but after updating to latest transformers.
          The issue went away
        updatedAt: '2023-10-01T12:52:31.918Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65196b901660b68bb2bf8f30
    id: 65196b8f1660b68bb2bf8f2c
    type: comment
  author: LaferriereJC
  content: My bad. I thought I commented but after updating to latest transformers.
    The issue went away
  created_at: 2023-10-01 11:52:31+00:00
  edited: false
  hidden: false
  id: 65196b8f1660b68bb2bf8f2c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/7e8da869c47dbc3f9052f1cbd4cc5ae6.svg
      fullname: Joshua Laferriere
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LaferriereJC
      type: user
    createdAt: '2023-10-01T12:52:32.000Z'
    data:
      status: closed
    id: 65196b901660b68bb2bf8f30
    type: status-change
  author: LaferriereJC
  created_at: 2023-10-01 11:52:32+00:00
  id: 65196b901660b68bb2bf8f30
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: Deci/DeciLM-6b-instruct
repo_type: model
status: closed
target_branch: null
title: 'TypeError: DeciLMAttention.forward() got an unexpected keyword argument ''padding_mask'''
