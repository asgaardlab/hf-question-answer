!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Yhyu13
conflicting_files: null
created_at: 2023-11-12 07:15:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-11-12T07:15:45.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8052238821983337
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;LoneStriker&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/LoneStriker\"\
          >@<span class=\"underline\">LoneStriker</span></a></span>\n\n\t</span></span>\
          \ How to use this LoRA file?</p>\n<p>Is it only appiled to the un-quantized\
          \ model? Can it be used on Yi-34B quantized models?</p>\n"
        raw: "@LoneStriker How to use this LoRA file?\r\n\r\nIs it only appiled to\
          \ the un-quantized model? Can it be used on Yi-34B quantized models?"
        updatedAt: '2023-11-12T07:15:45.264Z'
      numEdits: 0
      reactions: []
    id: 65507ba132f278f50386927e
    type: comment
  author: Yhyu13
  content: "@LoneStriker How to use this LoRA file?\r\n\r\nIs it only appiled to the\
    \ un-quantized model? Can it be used on Yi-34B quantized models?"
  created_at: 2023-11-12 07:15:45+00:00
  edited: false
  hidden: false
  id: 65507ba132f278f50386927e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-11-12T07:36:39.000Z'
    data:
      edited: true
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6560158133506775
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>Apply to the <a href="https://huggingface.co/chargoddard/Yi-34B-Llama">Llama-converted
          model</a> referenced in the model card.  Or you can just download one of
          my already-quantized models if you have a GPU.  In ooba, just use the Exllama
          v2 loader and load one of the models; 4-bit should fit on a 24 GB VRAM card.</p>

          '
        raw: Apply to the [Llama-converted model](https://huggingface.co/chargoddard/Yi-34B-Llama)
          referenced in the model card.  Or you can just download one of my already-quantized
          models if you have a GPU.  In ooba, just use the Exllama v2 loader and load
          one of the models; 4-bit should fit on a 24 GB VRAM card.
        updatedAt: '2023-11-12T07:37:48.464Z'
      numEdits: 1
      reactions: []
    id: 655080871e13b38aecbb7770
    type: comment
  author: LoneStriker
  content: Apply to the [Llama-converted model](https://huggingface.co/chargoddard/Yi-34B-Llama)
    referenced in the model card.  Or you can just download one of my already-quantized
    models if you have a GPU.  In ooba, just use the Exllama v2 loader and load one
    of the models; 4-bit should fit on a 24 GB VRAM card.
  created_at: 2023-11-12 07:36:39+00:00
  edited: true
  hidden: false
  id: 655080871e13b38aecbb7770
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-11-13T05:37:27.000Z'
    data:
      status: closed
    id: 6551b61719c62ea90f64eeb8
    type: status-change
  author: Yhyu13
  created_at: 2023-11-13 05:37:27+00:00
  id: 6551b61719c62ea90f64eeb8
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: LoneStriker/Yi-34B-Spicyboros-3.1-LoRA
repo_type: model
status: closed
target_branch: null
title: How to use thie LoRa?
