!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Sulav
conflicting_files: null
created_at: 2023-05-27 21:57:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/61a1a0a460fa58f4d9f5abc9e44e73ac.svg
      fullname: Sulav Khadka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sulav
      type: user
    createdAt: '2023-05-27T22:57:38.000Z'
    data:
      edited: false
      editors:
      - Sulav
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/61a1a0a460fa58f4d9f5abc9e44e73ac.svg
          fullname: Sulav Khadka
          isHf: false
          isPro: false
          name: Sulav
          type: user
        html: "<p>Receiving this error when trying to run this locally:<br><code>OSError:\
          \ teknium/Replit-v1-CodeInstruct-3B does not appear to have a file named\
          \ replit/replit-code-v1-3b--replit_lm_tokenizer.py. Checkout 'https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B/main'\
          \ for available files.</code></p>\n<p>I can see that the main branch has\
          \ a file called <code>replit_lm_tokenizer.py</code> not sure why there is\
          \ a <code>replit/replit-code-v1-3b--</code> being pre-pended to it. If I\
          \ replace the <code>model_name</code> to be <code>replit/replit-code-v1-3b</code>\
          \ then it loads properly.</p>\n<p>This is the code snippet I am running\
          \ for this:</p>\n<pre><code class=\"language-python\"><span class=\"hljs-keyword\"\
          >from</span> transformers <span class=\"hljs-keyword\">import</span> AutoModelForCausalLM,\
          \ AutoTokenizer\n<span class=\"hljs-keyword\">import</span> torch \n\n<span\
          \ class=\"hljs-comment\"># model_name = \"replit/replit-code-v1-3b\" # loads\
          \ properly</span>\nmodel_name = <span class=\"hljs-string\">\"teknium/Replit-v1-CodeInstruct-3B\"\
          </span> <span class=\"hljs-comment\"># encounters the error above</span>\n\
          \ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=<span\
          \ class=\"hljs-literal\">True</span>)\nmodel = AutoModelForCausalLM.from_pretrained(\n\
          \    model_name,\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=<span\
          \ class=\"hljs-literal\">True</span>\n)\nmodel.to(<span class=\"hljs-string\"\
          >'cuda'</span>)\n</code></pre>\n"
        raw: "Receiving this error when trying to run this locally:\r\n`OSError: teknium/Replit-v1-CodeInstruct-3B\
          \ does not appear to have a file named replit/replit-code-v1-3b--replit_lm_tokenizer.py.\
          \ Checkout 'https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B/main'\
          \ for available files.`\r\n\r\nI can see that the main branch has a file\
          \ called `replit_lm_tokenizer.py` not sure why there is a `replit/replit-code-v1-3b--`\
          \ being pre-pended to it. If I replace the `model_name` to be `replit/replit-code-v1-3b`\
          \ then it loads properly.\r\n\r\n\r\nThis is the code snippet I am running\
          \ for this:\r\n```python\r\nfrom transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\r\nimport torch \r\n\r\n# model_name = \"replit/replit-code-v1-3b\"\
          \ # loads properly\r\nmodel_name = \"teknium/Replit-v1-CodeInstruct-3B\"\
          \ # encounters the error above\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model_name,\
          \ trust_remote_code=True)\r\nmodel = AutoModelForCausalLM.from_pretrained(\r\
          \n    model_name,\r\n    torch_dtype=torch.bfloat16,\r\n    trust_remote_code=True\r\
          \n)\r\nmodel.to('cuda')\r\n```"
        updatedAt: '2023-05-27T22:57:38.400Z'
      numEdits: 0
      reactions: []
    id: 64728ae245c2f5457fb0a1c1
    type: comment
  author: Sulav
  content: "Receiving this error when trying to run this locally:\r\n`OSError: teknium/Replit-v1-CodeInstruct-3B\
    \ does not appear to have a file named replit/replit-code-v1-3b--replit_lm_tokenizer.py.\
    \ Checkout 'https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B/main' for\
    \ available files.`\r\n\r\nI can see that the main branch has a file called `replit_lm_tokenizer.py`\
    \ not sure why there is a `replit/replit-code-v1-3b--` being pre-pended to it.\
    \ If I replace the `model_name` to be `replit/replit-code-v1-3b` then it loads\
    \ properly.\r\n\r\n\r\nThis is the code snippet I am running for this:\r\n```python\r\
    \nfrom transformers import AutoModelForCausalLM, AutoTokenizer\r\nimport torch\
    \ \r\n\r\n# model_name = \"replit/replit-code-v1-3b\" # loads properly\r\nmodel_name\
    \ = \"teknium/Replit-v1-CodeInstruct-3B\" # encounters the error above\r\n\r\n\
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\r\
    \nmodel = AutoModelForCausalLM.from_pretrained(\r\n    model_name,\r\n    torch_dtype=torch.bfloat16,\r\
    \n    trust_remote_code=True\r\n)\r\nmodel.to('cuda')\r\n```"
  created_at: 2023-05-27 21:57:38+00:00
  edited: false
  hidden: false
  id: 64728ae245c2f5457fb0a1c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-05-28T01:14:32.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: "<blockquote>\n<p>Receiving this error when trying to run this locally:<br><code>OSError:\
          \ teknium/Replit-v1-CodeInstruct-3B does not appear to have a file named\
          \ replit/replit-code-v1-3b--replit_lm_tokenizer.py. Checkout 'https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B/main'\
          \ for available files.</code></p>\n<p>I can see that the main branch has\
          \ a file called <code>replit_lm_tokenizer.py</code> not sure why there is\
          \ a <code>replit/replit-code-v1-3b--</code> being pre-pended to it. If I\
          \ replace the <code>model_name</code> to be <code>replit/replit-code-v1-3b</code>\
          \ then it loads properly.</p>\n<p>This is the code snippet I am running\
          \ for this:</p>\n<pre><code class=\"language-python\"><span class=\"hljs-keyword\"\
          >from</span> transformers <span class=\"hljs-keyword\">import</span> AutoModelForCausalLM,\
          \ AutoTokenizer\n<span class=\"hljs-keyword\">import</span> torch \n\n<span\
          \ class=\"hljs-comment\"># model_name = \"replit/replit-code-v1-3b\" # loads\
          \ properly</span>\nmodel_name = <span class=\"hljs-string\">\"teknium/Replit-v1-CodeInstruct-3B\"\
          </span> <span class=\"hljs-comment\"># encounters the error above</span>\n\
          \ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=<span\
          \ class=\"hljs-literal\">True</span>)\nmodel = AutoModelForCausalLM.from_pretrained(\n\
          \    model_name,\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=<span\
          \ class=\"hljs-literal\">True</span>\n)\nmodel.to(<span class=\"hljs-string\"\
          >'cuda'</span>)\n</code></pre>\n</blockquote>\n<p>Yes thank you we are fixing\
          \ it right now ^_^ It's got some references to the original replit model\
          \ in the config.json</p>\n"
        raw: "> Receiving this error when trying to run this locally:\n> `OSError:\
          \ teknium/Replit-v1-CodeInstruct-3B does not appear to have a file named\
          \ replit/replit-code-v1-3b--replit_lm_tokenizer.py. Checkout 'https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B/main'\
          \ for available files.`\n> \n> I can see that the main branch has a file\
          \ called `replit_lm_tokenizer.py` not sure why there is a `replit/replit-code-v1-3b--`\
          \ being pre-pended to it. If I replace the `model_name` to be `replit/replit-code-v1-3b`\
          \ then it loads properly.\n> \n> \n> This is the code snippet I am running\
          \ for this:\n> ```python\n> from transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\n> import torch \n> \n> # model_name = \"replit/replit-code-v1-3b\"\
          \ # loads properly\n> model_name = \"teknium/Replit-v1-CodeInstruct-3B\"\
          \ # encounters the error above\n> \n> tokenizer = AutoTokenizer.from_pretrained(model_name,\
          \ trust_remote_code=True)\n> model = AutoModelForCausalLM.from_pretrained(\n\
          >     model_name,\n>     torch_dtype=torch.bfloat16,\n>     trust_remote_code=True\n\
          > )\n> model.to('cuda')\n> ```\n\nYes thank you we are fixing it right now\
          \ ^_^ It's got some references to the original replit model in the config.json"
        updatedAt: '2023-05-28T01:14:32.508Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Sulav
    id: 6472aaf897a75cc77abc9569
    type: comment
  author: teknium
  content: "> Receiving this error when trying to run this locally:\n> `OSError: teknium/Replit-v1-CodeInstruct-3B\
    \ does not appear to have a file named replit/replit-code-v1-3b--replit_lm_tokenizer.py.\
    \ Checkout 'https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B/main' for\
    \ available files.`\n> \n> I can see that the main branch has a file called `replit_lm_tokenizer.py`\
    \ not sure why there is a `replit/replit-code-v1-3b--` being pre-pended to it.\
    \ If I replace the `model_name` to be `replit/replit-code-v1-3b` then it loads\
    \ properly.\n> \n> \n> This is the code snippet I am running for this:\n> ```python\n\
    > from transformers import AutoModelForCausalLM, AutoTokenizer\n> import torch\
    \ \n> \n> # model_name = \"replit/replit-code-v1-3b\" # loads properly\n> model_name\
    \ = \"teknium/Replit-v1-CodeInstruct-3B\" # encounters the error above\n> \n>\
    \ tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n\
    > model = AutoModelForCausalLM.from_pretrained(\n>     model_name,\n>     torch_dtype=torch.bfloat16,\n\
    >     trust_remote_code=True\n> )\n> model.to('cuda')\n> ```\n\nYes thank you\
    \ we are fixing it right now ^_^ It's got some references to the original replit\
    \ model in the config.json"
  created_at: 2023-05-28 00:14:32+00:00
  edited: false
  hidden: false
  id: 6472aaf897a75cc77abc9569
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-05-28T11:22:45.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: "<blockquote>\n<p>Receiving this error when trying to run this locally:<br><code>OSError:\
          \ teknium/Replit-v1-CodeInstruct-3B does not appear to have a file named\
          \ replit/replit-code-v1-3b--replit_lm_tokenizer.py. Checkout 'https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B/main'\
          \ for available files.</code></p>\n<p>I can see that the main branch has\
          \ a file called <code>replit_lm_tokenizer.py</code> not sure why there is\
          \ a <code>replit/replit-code-v1-3b--</code> being pre-pended to it. If I\
          \ replace the <code>model_name</code> to be <code>replit/replit-code-v1-3b</code>\
          \ then it loads properly.</p>\n<p>This is the code snippet I am running\
          \ for this:</p>\n<pre><code class=\"language-python\"><span class=\"hljs-keyword\"\
          >from</span> transformers <span class=\"hljs-keyword\">import</span> AutoModelForCausalLM,\
          \ AutoTokenizer\n<span class=\"hljs-keyword\">import</span> torch \n\n<span\
          \ class=\"hljs-comment\"># model_name = \"replit/replit-code-v1-3b\" # loads\
          \ properly</span>\nmodel_name = <span class=\"hljs-string\">\"teknium/Replit-v1-CodeInstruct-3B\"\
          </span> <span class=\"hljs-comment\"># encounters the error above</span>\n\
          \ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=<span\
          \ class=\"hljs-literal\">True</span>)\nmodel = AutoModelForCausalLM.from_pretrained(\n\
          \    model_name,\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=<span\
          \ class=\"hljs-literal\">True</span>\n)\nmodel.to(<span class=\"hljs-string\"\
          >'cuda'</span>)\n</code></pre>\n</blockquote>\n<p>It's fixed now. You can\
          \ just update the config.json to fix it</p>\n"
        raw: "> Receiving this error when trying to run this locally:\n> `OSError:\
          \ teknium/Replit-v1-CodeInstruct-3B does not appear to have a file named\
          \ replit/replit-code-v1-3b--replit_lm_tokenizer.py. Checkout 'https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B/main'\
          \ for available files.`\n> \n> I can see that the main branch has a file\
          \ called `replit_lm_tokenizer.py` not sure why there is a `replit/replit-code-v1-3b--`\
          \ being pre-pended to it. If I replace the `model_name` to be `replit/replit-code-v1-3b`\
          \ then it loads properly.\n> \n> \n> This is the code snippet I am running\
          \ for this:\n> ```python\n> from transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\n> import torch \n> \n> # model_name = \"replit/replit-code-v1-3b\"\
          \ # loads properly\n> model_name = \"teknium/Replit-v1-CodeInstruct-3B\"\
          \ # encounters the error above\n> \n> tokenizer = AutoTokenizer.from_pretrained(model_name,\
          \ trust_remote_code=True)\n> model = AutoModelForCausalLM.from_pretrained(\n\
          >     model_name,\n>     torch_dtype=torch.bfloat16,\n>     trust_remote_code=True\n\
          > )\n> model.to('cuda')\n> ```\n\nIt's fixed now. You can just update the\
          \ config.json to fix it"
        updatedAt: '2023-05-28T11:22:45.672Z'
      numEdits: 0
      reactions: []
    id: 64733985352c94a20dd21de4
    type: comment
  author: teknium
  content: "> Receiving this error when trying to run this locally:\n> `OSError: teknium/Replit-v1-CodeInstruct-3B\
    \ does not appear to have a file named replit/replit-code-v1-3b--replit_lm_tokenizer.py.\
    \ Checkout 'https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B/main' for\
    \ available files.`\n> \n> I can see that the main branch has a file called `replit_lm_tokenizer.py`\
    \ not sure why there is a `replit/replit-code-v1-3b--` being pre-pended to it.\
    \ If I replace the `model_name` to be `replit/replit-code-v1-3b` then it loads\
    \ properly.\n> \n> \n> This is the code snippet I am running for this:\n> ```python\n\
    > from transformers import AutoModelForCausalLM, AutoTokenizer\n> import torch\
    \ \n> \n> # model_name = \"replit/replit-code-v1-3b\" # loads properly\n> model_name\
    \ = \"teknium/Replit-v1-CodeInstruct-3B\" # encounters the error above\n> \n>\
    \ tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n\
    > model = AutoModelForCausalLM.from_pretrained(\n>     model_name,\n>     torch_dtype=torch.bfloat16,\n\
    >     trust_remote_code=True\n> )\n> model.to('cuda')\n> ```\n\nIt's fixed now.\
    \ You can just update the config.json to fix it"
  created_at: 2023-05-28 10:22:45+00:00
  edited: false
  hidden: false
  id: 64733985352c94a20dd21de4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-05-28T11:22:47.000Z'
    data:
      status: closed
    id: 647339872a74fb43ccdaccda
    type: status-change
  author: teknium
  created_at: 2023-05-28 10:22:47+00:00
  id: 647339872a74fb43ccdaccda
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/61a1a0a460fa58f4d9f5abc9e44e73ac.svg
      fullname: Sulav Khadka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sulav
      type: user
    createdAt: '2023-05-28T17:53:23.000Z'
    data:
      edited: false
      editors:
      - Sulav
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/61a1a0a460fa58f4d9f5abc9e44e73ac.svg
          fullname: Sulav Khadka
          isHf: false
          isPro: false
          name: Sulav
          type: user
        html: '<p>The issue still persists with the same error. I looked at the repo
          and changing the string in the tokenizer_config.json resolves the issue.</p>

          <p>Current:</p>

          <p><code>"AutoTokenizer": [       "replit/replit-code-v1-3b--replit_lm_tokenizer.ReplitLMTokenizer",       null     ]   }</code></p>

          <p>Fixed:</p>

          <p><code>"AutoTokenizer": [       "replit_lm_tokenizer.ReplitLMTokenizer",       null     ]   }</code></p>

          '
        raw: "The issue still persists with the same error. I looked at the repo and\
          \ changing the string in the tokenizer_config.json resolves the issue.\n\
          \nCurrent:\n```\"AutoTokenizer\": [\n      \"replit/replit-code-v1-3b--replit_lm_tokenizer.ReplitLMTokenizer\"\
          ,\n      null\n    ]\n  }```\n\nFixed:\n```\"AutoTokenizer\": [\n      \"\
          replit_lm_tokenizer.ReplitLMTokenizer\",\n      null\n    ]\n  }```"
        updatedAt: '2023-05-28T17:53:23.057Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64739513352c94a20dd85f93
    id: 64739513352c94a20dd85f92
    type: comment
  author: Sulav
  content: "The issue still persists with the same error. I looked at the repo and\
    \ changing the string in the tokenizer_config.json resolves the issue.\n\nCurrent:\n\
    ```\"AutoTokenizer\": [\n      \"replit/replit-code-v1-3b--replit_lm_tokenizer.ReplitLMTokenizer\"\
    ,\n      null\n    ]\n  }```\n\nFixed:\n```\"AutoTokenizer\": [\n      \"replit_lm_tokenizer.ReplitLMTokenizer\"\
    ,\n      null\n    ]\n  }```"
  created_at: 2023-05-28 16:53:23+00:00
  edited: false
  hidden: false
  id: 64739513352c94a20dd85f92
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/61a1a0a460fa58f4d9f5abc9e44e73ac.svg
      fullname: Sulav Khadka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sulav
      type: user
    createdAt: '2023-05-28T17:53:23.000Z'
    data:
      status: open
    id: 64739513352c94a20dd85f93
    type: status-change
  author: Sulav
  created_at: 2023-05-28 16:53:23+00:00
  id: 64739513352c94a20dd85f93
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-05-28T19:54:13.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>There were two sections of the config file to update, did you remove
          the model name portion?</p>

          '
        raw: There were two sections of the config file to update, did you remove
          the model name portion?
        updatedAt: '2023-05-28T19:54:13.335Z'
      numEdits: 0
      reactions: []
    id: 6473b16563001a0002cfe298
    type: comment
  author: teknium
  content: There were two sections of the config file to update, did you remove the
    model name portion?
  created_at: 2023-05-28 18:54:13+00:00
  edited: false
  hidden: false
  id: 6473b16563001a0002cfe298
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-05-28T20:06:01.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>Technically, 3 lines to change, see the commit here:<br><a href="https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B/commit/ad718ea176f4089ff593187fe31a9632ad2a5daf">https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B/commit/ad718ea176f4089ff593187fe31a9632ad2a5daf</a></p>

          '
        raw: 'Technically, 3 lines to change, see the commit here:

          https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B/commit/ad718ea176f4089ff593187fe31a9632ad2a5daf'
        updatedAt: '2023-05-28T20:06:01.423Z'
      numEdits: 0
      reactions: []
    id: 6473b4296cff2f8672099936
    type: comment
  author: teknium
  content: 'Technically, 3 lines to change, see the commit here:

    https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B/commit/ad718ea176f4089ff593187fe31a9632ad2a5daf'
  created_at: 2023-05-28 19:06:01+00:00
  edited: false
  hidden: false
  id: 6473b4296cff2f8672099936
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/61a1a0a460fa58f4d9f5abc9e44e73ac.svg
      fullname: Sulav Khadka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sulav
      type: user
    createdAt: '2023-05-29T00:31:23.000Z'
    data:
      edited: false
      editors:
      - Sulav
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/61a1a0a460fa58f4d9f5abc9e44e73ac.svg
          fullname: Sulav Khadka
          isHf: false
          isPro: false
          name: Sulav
          type: user
        html: '<p>I see. I thought I had the latest pulled. Thanks!</p>

          '
        raw: I see. I thought I had the latest pulled. Thanks!
        updatedAt: '2023-05-29T00:31:23.245Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6473f25b2a74fb43cce70280
    id: 6473f25b2a74fb43cce7027f
    type: comment
  author: Sulav
  content: I see. I thought I had the latest pulled. Thanks!
  created_at: 2023-05-28 23:31:23+00:00
  edited: false
  hidden: false
  id: 6473f25b2a74fb43cce7027f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/61a1a0a460fa58f4d9f5abc9e44e73ac.svg
      fullname: Sulav Khadka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sulav
      type: user
    createdAt: '2023-05-29T00:31:23.000Z'
    data:
      status: closed
    id: 6473f25b2a74fb43cce70280
    type: status-change
  author: Sulav
  created_at: 2023-05-28 23:31:23+00:00
  id: 6473f25b2a74fb43cce70280
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: teknium/Replit-v1-CodeInstruct-3B
repo_type: model
status: closed
target_branch: null
title: 'OSError: teknium/Replit-v1-CodeInstruct-3B does not appear to have a tokenizer
  file'
