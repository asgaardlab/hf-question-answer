!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SaraQX
conflicting_files: null
created_at: 2023-07-20 02:29:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/99e8f8ce877577f818691a11720f83ad.svg
      fullname: LI QINGXIA
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SaraQX
      type: user
    createdAt: '2023-07-20T03:29:19.000Z'
    data:
      edited: false
      editors:
      - SaraQX
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9354960322380066
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/99e8f8ce877577f818691a11720f83ad.svg
          fullname: LI QINGXIA
          isHf: false
          isPro: false
          name: SaraQX
          type: user
        html: '<p>Hi Bloke, many thanks for your generous efforts. Just wondering
          if llama-2-70B would be your next focus?<br>The model is amazing.<br>Best,<br>Sarai</p>

          '
        raw: "Hi Bloke, many thanks for your generous efforts. Just wondering if llama-2-70B\
          \ would be your next focus?\r\nThe model is amazing. \r\nBest,\r\nSarai"
        updatedAt: '2023-07-20T03:29:19.485Z'
      numEdits: 0
      reactions: []
    id: 64b8aa0f8b53fb5dbdf3e037
    type: comment
  author: SaraQX
  content: "Hi Bloke, many thanks for your generous efforts. Just wondering if llama-2-70B\
    \ would be your next focus?\r\nThe model is amazing. \r\nBest,\r\nSarai"
  created_at: 2023-07-20 02:29:19+00:00
  edited: false
  hidden: false
  id: 64b8aa0f8b53fb5dbdf3e037
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-20T08:11:37.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9632799625396729
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Sorry I don''t follow - I''ve already done Llama-2-70B-GPTQ ?</p>

          <p>Do you mean in GGML? If so, I will do that as soon as llama.cpp supports
          them.</p>

          '
        raw: 'Sorry I don''t follow - I''ve already done Llama-2-70B-GPTQ ?


          Do you mean in GGML? If so, I will do that as soon as llama.cpp supports
          them.'
        updatedAt: '2023-07-20T08:11:37.078Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - cariaga
        - Renegadesoffun
        - SaraQX
    id: 64b8ec397ec316f84f804e7e
    type: comment
  author: TheBloke
  content: 'Sorry I don''t follow - I''ve already done Llama-2-70B-GPTQ ?


    Do you mean in GGML? If so, I will do that as soon as llama.cpp supports them.'
  created_at: 2023-07-20 07:11:37+00:00
  edited: false
  hidden: false
  id: 64b8ec397ec316f84f804e7e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8101faa04b9de356da11698420d90ff5.svg
      fullname: GOUNADON Ange
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ange09
      type: user
    createdAt: '2023-07-20T16:01:13.000Z'
    data:
      edited: false
      editors:
      - Ange09
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9619701504707336
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8101faa04b9de356da11698420d90ff5.svg
          fullname: GOUNADON Ange
          isHf: false
          isPro: false
          name: Ange09
          type: user
        html: '<p>Hi Bloke, many thanks for this amazing work. Just wondering how
          to increase the context Length. On Llama 2 it seems to be 4k. But in your
          fine-tuning it 2048. How can I use your model but with a context  Length
          of 4k. It would be great if you could help me. Many thanks</p>

          '
        raw: Hi Bloke, many thanks for this amazing work. Just wondering how to increase
          the context Length. On Llama 2 it seems to be 4k. But in your fine-tuning
          it 2048. How can I use your model but with a context  Length of 4k. It would
          be great if you could help me. Many thanks
        updatedAt: '2023-07-20T16:01:13.857Z'
      numEdits: 0
      reactions: []
    id: 64b95a49894eb78e396735f3
    type: comment
  author: Ange09
  content: Hi Bloke, many thanks for this amazing work. Just wondering how to increase
    the context Length. On Llama 2 it seems to be 4k. But in your fine-tuning it 2048.
    How can I use your model but with a context  Length of 4k. It would be great if
    you could help me. Many thanks
  created_at: 2023-07-20 15:01:13+00:00
  edited: false
  hidden: false
  id: 64b95a49894eb78e396735f3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-20T16:10:42.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9629597067832947
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I''ve just updated my config.json to match the new config.json in
          Meta''s Llama-2-13b-HF.</p>

          <p>When I first made the quants I couldn''t use their config.json due to
          an error in their files.  I used my own and it was missing the max-length:4096
          parameter.  That wouldn''t affect the quantisation, and to be honest it
          doesn''t affect most clients either.  But anyway I''ve fixed it now and
          will shortly push this fix to all the branches and to my other Llama 2 repos.</p>

          <p>Download config.json from the main branch and overwrite the one you have
          and try that.</p>

          '
        raw: 'I''ve just updated my config.json to match the new config.json in Meta''s
          Llama-2-13b-HF.


          When I first made the quants I couldn''t use their config.json due to an
          error in their files.  I used my own and it was missing the max-length:4096
          parameter.  That wouldn''t affect the quantisation, and to be honest it
          doesn''t affect most clients either.  But anyway I''ve fixed it now and
          will shortly push this fix to all the branches and to my other Llama 2 repos.


          Download config.json from the main branch and overwrite the one you have
          and try that.'
        updatedAt: '2023-07-20T16:10:42.480Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Ange09
    id: 64b95c827ec316f84f90473c
    type: comment
  author: TheBloke
  content: 'I''ve just updated my config.json to match the new config.json in Meta''s
    Llama-2-13b-HF.


    When I first made the quants I couldn''t use their config.json due to an error
    in their files.  I used my own and it was missing the max-length:4096 parameter.  That
    wouldn''t affect the quantisation, and to be honest it doesn''t affect most clients
    either.  But anyway I''ve fixed it now and will shortly push this fix to all the
    branches and to my other Llama 2 repos.


    Download config.json from the main branch and overwrite the one you have and try
    that.'
  created_at: 2023-07-20 15:10:42+00:00
  edited: false
  hidden: false
  id: 64b95c827ec316f84f90473c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8101faa04b9de356da11698420d90ff5.svg
      fullname: GOUNADON Ange
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ange09
      type: user
    createdAt: '2023-07-20T18:44:11.000Z'
    data:
      edited: false
      editors:
      - Ange09
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7841798663139343
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8101faa04b9de356da11698420d90ff5.svg
          fullname: GOUNADON Ange
          isHf: false
          isPro: false
          name: Ange09
          type: user
        html: '<p>Great, thank you</p>

          '
        raw: 'Great, thank you

          '
        updatedAt: '2023-07-20T18:44:11.733Z'
      numEdits: 0
      reactions: []
    id: 64b9807b6a7c71f0045f0da6
    type: comment
  author: Ange09
  content: 'Great, thank you

    '
  created_at: 2023-07-20 17:44:11+00:00
  edited: false
  hidden: false
  id: 64b9807b6a7c71f0045f0da6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/99e8f8ce877577f818691a11720f83ad.svg
      fullname: LI QINGXIA
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SaraQX
      type: user
    createdAt: '2023-07-21T01:37:59.000Z'
    data:
      edited: false
      editors:
      - SaraQX
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9515312910079956
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/99e8f8ce877577f818691a11720f83ad.svg
          fullname: LI QINGXIA
          isHf: false
          isPro: false
          name: SaraQX
          type: user
        html: '<blockquote>

          <p>Sorry I don''t follow - I''ve already done Llama-2-70B-GPTQ ?</p>

          <p>Do you mean in GGML? If so, I will do that as soon as llama.cpp supports
          them.</p>

          </blockquote>

          <p>That would be so cool. Thank you Bloke~</p>

          '
        raw: "> Sorry I don't follow - I've already done Llama-2-70B-GPTQ ?\n> \n\
          > Do you mean in GGML? If so, I will do that as soon as llama.cpp supports\
          \ them.\n\nThat would be so cool. Thank you Bloke~"
        updatedAt: '2023-07-21T01:37:59.347Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - cariaga
    id: 64b9e177842aa47891c61a1d
    type: comment
  author: SaraQX
  content: "> Sorry I don't follow - I've already done Llama-2-70B-GPTQ ?\n> \n> Do\
    \ you mean in GGML? If so, I will do that as soon as llama.cpp supports them.\n\
    \nThat would be so cool. Thank you Bloke~"
  created_at: 2023-07-21 00:37:59+00:00
  edited: false
  hidden: false
  id: 64b9e177842aa47891c61a1d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b912c9af139d1b0874b9fe0fbf364be8.svg
      fullname: none
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: spike4379
      type: user
    createdAt: '2023-07-21T04:02:18.000Z'
    data:
      edited: false
      editors:
      - spike4379
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9855310320854187
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b912c9af139d1b0874b9fe0fbf364be8.svg
          fullname: none
          isHf: false
          isPro: false
          name: spike4379
          type: user
        html: '<p>Im using this 13b that you first released two days ago and its fantastic.
          I made sure to back it up because the one you posted yesterday seems to
          respond to everything really weirdly. swapping between them is a night and
          day difference</p>

          '
        raw: Im using this 13b that you first released two days ago and its fantastic.
          I made sure to back it up because the one you posted yesterday seems to
          respond to everything really weirdly. swapping between them is a night and
          day difference
        updatedAt: '2023-07-21T04:02:18.457Z'
      numEdits: 0
      reactions: []
    id: 64ba034a5a29c19c8d243b23
    type: comment
  author: spike4379
  content: Im using this 13b that you first released two days ago and its fantastic.
    I made sure to back it up because the one you posted yesterday seems to respond
    to everything really weirdly. swapping between them is a night and day difference
  created_at: 2023-07-21 03:02:18+00:00
  edited: false
  hidden: false
  id: 64ba034a5a29c19c8d243b23
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-21T09:20:16.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.972161591053009
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<blockquote>

          <p>Im using this 13b that you first released two days ago and its fantastic.
          I made sure to back it up because the one you posted yesterday seems to
          respond to everything really weirdly. swapping between them is a night and
          day difference</p>

          </blockquote>

          <p>The 13B I uploaded first was accidentally 13B Chat, it should be identical
          to 13B-Chat-GPTQ.  So if you''re using the old one, you''re actually using
          the same files as <a href="https://huggingface.co/TheBloke/Llama-2-13B-Chat-GPTQ">https://huggingface.co/TheBloke/Llama-2-13B-Chat-GPTQ</a></p>

          <p>The files that are here now are the correct Llama 13B, which is a non-fine-tuned
          base model, so yes it will respond strangely because it''s not really designed
          to be used for question/answer.</p>

          '
        raw: '> Im using this 13b that you first released two days ago and its fantastic.
          I made sure to back it up because the one you posted yesterday seems to
          respond to everything really weirdly. swapping between them is a night and
          day difference


          The 13B I uploaded first was accidentally 13B Chat, it should be identical
          to 13B-Chat-GPTQ.  So if you''re using the old one, you''re actually using
          the same files as https://huggingface.co/TheBloke/Llama-2-13B-Chat-GPTQ


          The files that are here now are the correct Llama 13B, which is a non-fine-tuned
          base model, so yes it will respond strangely because it''s not really designed
          to be used for question/answer.'
        updatedAt: '2023-07-21T09:20:16.161Z'
      numEdits: 0
      reactions: []
    id: 64ba4dd0c71d6882de3b23c3
    type: comment
  author: TheBloke
  content: '> Im using this 13b that you first released two days ago and its fantastic.
    I made sure to back it up because the one you posted yesterday seems to respond
    to everything really weirdly. swapping between them is a night and day difference


    The 13B I uploaded first was accidentally 13B Chat, it should be identical to
    13B-Chat-GPTQ.  So if you''re using the old one, you''re actually using the same
    files as https://huggingface.co/TheBloke/Llama-2-13B-Chat-GPTQ


    The files that are here now are the correct Llama 13B, which is a non-fine-tuned
    base model, so yes it will respond strangely because it''s not really designed
    to be used for question/answer.'
  created_at: 2023-07-21 08:20:16+00:00
  edited: false
  hidden: false
  id: 64ba4dd0c71d6882de3b23c3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b912c9af139d1b0874b9fe0fbf364be8.svg
      fullname: none
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: spike4379
      type: user
    createdAt: '2023-07-21T14:31:05.000Z'
    data:
      edited: false
      editors:
      - spike4379
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9691655039787292
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b912c9af139d1b0874b9fe0fbf364be8.svg
          fullname: none
          isHf: false
          isPro: false
          name: spike4379
          type: user
        html: '<blockquote>

          <blockquote>

          <p>Im using this 13b that you first released two days ago and its fantastic.
          I made sure to back it up because the one you posted yesterday seems to
          respond to everything really weirdly. swapping between them is a night and
          day difference</p>

          </blockquote>

          <p>The 13B I uploaded first was accidentally 13B Chat, it should be identical
          to 13B-Chat-GPTQ.  So if you''re using the old one, you''re actually using
          the same files as <a href="https://huggingface.co/TheBloke/Llama-2-13B-Chat-GPTQ">https://huggingface.co/TheBloke/Llama-2-13B-Chat-GPTQ</a></p>

          <p>The files that are here now are the correct Llama 13B, which is a non-fine-tuned
          base model, so yes it will respond strangely because it''s not really designed
          to be used for question/answer.</p>

          </blockquote>

          <p>Dude you must have been facepalming so bad reading my comment. ofc it
          was the chat one im so stupid I didn''t even see the different name. my
          mistake!<br>Loving the work you do :)</p>

          '
        raw: "> > Im using this 13b that you first released two days ago and its fantastic.\
          \ I made sure to back it up because the one you posted yesterday seems to\
          \ respond to everything really weirdly. swapping between them is a night\
          \ and day difference\n> \n> The 13B I uploaded first was accidentally 13B\
          \ Chat, it should be identical to 13B-Chat-GPTQ.  So if you're using the\
          \ old one, you're actually using the same files as https://huggingface.co/TheBloke/Llama-2-13B-Chat-GPTQ\n\
          > \n> The files that are here now are the correct Llama 13B, which is a\
          \ non-fine-tuned base model, so yes it will respond strangely because it's\
          \ not really designed to be used for question/answer.\n\nDude you must have\
          \ been facepalming so bad reading my comment. ofc it was the chat one im\
          \ so stupid I didn't even see the different name. my mistake!\nLoving the\
          \ work you do :)"
        updatedAt: '2023-07-21T14:31:05.159Z'
      numEdits: 0
      reactions: []
    id: 64ba96a9367f9a05963aa7a0
    type: comment
  author: spike4379
  content: "> > Im using this 13b that you first released two days ago and its fantastic.\
    \ I made sure to back it up because the one you posted yesterday seems to respond\
    \ to everything really weirdly. swapping between them is a night and day difference\n\
    > \n> The 13B I uploaded first was accidentally 13B Chat, it should be identical\
    \ to 13B-Chat-GPTQ.  So if you're using the old one, you're actually using the\
    \ same files as https://huggingface.co/TheBloke/Llama-2-13B-Chat-GPTQ\n> \n> The\
    \ files that are here now are the correct Llama 13B, which is a non-fine-tuned\
    \ base model, so yes it will respond strangely because it's not really designed\
    \ to be used for question/answer.\n\nDude you must have been facepalming so bad\
    \ reading my comment. ofc it was the chat one im so stupid I didn't even see the\
    \ different name. my mistake!\nLoving the work you do :)"
  created_at: 2023-07-21 13:31:05+00:00
  edited: false
  hidden: false
  id: 64ba96a9367f9a05963aa7a0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/99e8f8ce877577f818691a11720f83ad.svg
      fullname: LI QINGXIA
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SaraQX
      type: user
    createdAt: '2023-07-23T09:41:09.000Z'
    data:
      edited: true
      editors:
      - SaraQX
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9558700323104858
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/99e8f8ce877577f818691a11720f83ad.svg
          fullname: LI QINGXIA
          isHf: false
          isPro: false
          name: SaraQX
          type: user
        html: "<blockquote>\n<p>Sorry I don't follow - I've already done Llama-2-70B-GPTQ\
          \ ?</p>\n<p>Do you mean in GGML? If so, I will do that as soon as llama.cpp\
          \ supports them.</p>\n</blockquote>\n<p>I see. Many thanks! I am new to\
          \ GPTQ version. Will definitely give it try \U0001F604\U0001F339</p>\n"
        raw: "> Sorry I don't follow - I've already done Llama-2-70B-GPTQ ?\n> \n\
          > Do you mean in GGML? If so, I will do that as soon as llama.cpp supports\
          \ them.\n\nI see. Many thanks! I am new to GPTQ version. Will definitely\
          \ give it try \U0001F604\U0001F339"
        updatedAt: '2023-07-23T09:41:36.158Z'
      numEdits: 1
      reactions: []
    id: 64bcf5b586e7fb5b8a59f00b
    type: comment
  author: SaraQX
  content: "> Sorry I don't follow - I've already done Llama-2-70B-GPTQ ?\n> \n> Do\
    \ you mean in GGML? If so, I will do that as soon as llama.cpp supports them.\n\
    \nI see. Many thanks! I am new to GPTQ version. Will definitely give it try \U0001F604\
    \U0001F339"
  created_at: 2023-07-23 08:41:09+00:00
  edited: true
  hidden: false
  id: 64bcf5b586e7fb5b8a59f00b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/Llama-2-13B-GPTQ
repo_type: model
status: open
target_branch: null
title: Will llama-2-70B be supported in near future?
