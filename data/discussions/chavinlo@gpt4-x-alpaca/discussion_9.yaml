!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tonyaw
conflicting_files: null
created_at: 2023-04-06 08:35:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ed8d9a55a19d8c5a138ba918d7c2450e.svg
      fullname: Tony W
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tonyaw
      type: user
    createdAt: '2023-04-06T09:35:47.000Z'
    data:
      edited: false
      editors:
      - tonyaw
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ed8d9a55a19d8c5a138ba918d7c2450e.svg
          fullname: Tony W
          isHf: false
          isPro: false
          name: tonyaw
          type: user
        html: '<p>I''m trying to use koboldai-client to load this model, and get this
          error. Could you please help to check what the issue is?<br>Thanks!<br>accelerate
          version and transformers version in use:<br>accelerate-0.18.0.dev0.dist-info<br>transformers-4.28.0.dev0.dist-info</p>

          <p>ERROR      | <strong>main</strong>:generate:4945 - Traceback (most recent
          call last):<br>  File "aiserver.py", line 4934, in generate<br>    genout,
          already_generated = tpool.execute(_generate, txt, minimum, maximum, found_entries)<br>  File
          "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/eventlet/tpool.py",
          line 132, in execute<br>    six.reraise(c, e, tb)<br>  File "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/six.py",
          line 719, in reraise<br>    raise value<br>  File "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/eventlet/tpool.py",
          line 86, in tworker<br>    rv = meth(*args, **kwargs)<br>  File "aiserver.py",
          line 4857, in _generate<br>    genout = generator(<br>  File "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/autograd/grad_mode.py",
          line 27, in decorate_context<br>    return func(*args, **kwargs)<br>  File
          "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/generation/utils.py",
          line 1485, in generate<br>    return self.sample(<br>  File "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/generation/utils.py",
          line 2524, in sample<br>    outputs = self(<br>  File "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py",
          line 1110, in _call_impl<br>    return forward_call(*input, **kwargs)<br>  File
          "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py",
          line 165, in new_forward<br>    output = old_forward(*args, **kwargs)<br>  File
          "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py",
          line 687, in forward<br>    outputs = self.model(<br>  File "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py",
          line 1110, in _call_impl<br>    return forward_call(*input, **kwargs)<br>  File
          "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py",
          line 577, in forward<br>    layer_outputs = decoder_layer(<br>  File "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py",
          line 1110, in _call_impl<br>    return forward_call(*input, **kwargs)<br>  File
          "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py",
          line 165, in new_forward<br>    output = old_forward(*args, **kwargs)<br>  File
          "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py",
          line 292, in forward<br>    hidden_states, self_attn_weights, present_key_value
          = self.self_attn(<br>  File "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py",
          line 1110, in _call_impl<br>    return forward_call(*input, **kwargs)<br>  File
          "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py",
          line 165, in new_forward<br>    output = old_forward(*args, **kwargs)<br>  File
          "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py",
          line 203, in forward<br>    cos, sin = self.rotary_emb(value_states, seq_len=kv_seq_len)<br>  File
          "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py",
          line 1110, in _call_impl<br>    return forward_call(*input, **kwargs)<br>  File
          "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py",
          line 160, in new_forward<br>    args, kwargs = module._hf_hook.pre_forward(module,
          *args, **kwargs)<br>  File "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py",
          line 280, in pre_forward<br>    set_module_tensor_to_device(module, name,
          self.execution_device, value=self.weights_map[name])<br>  File "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/utils/offload.py",
          line 123, in <strong>getitem</strong><br>    return self.dataset[f"{self.prefix}{key}"]<br>  File
          "/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/utils/offload.py",
          line 170, in <strong>getitem</strong><br>    weight_info = self.index[key]<br>KeyError:
          ''model.layers.0.self_attn.rotary_emb.cos_cached''</p>

          '
        raw: "I'm trying to use koboldai-client to load this model, and get this error.\
          \ Could you please help to check what the issue is?\r\nThanks!\r\naccelerate\
          \ version and transformers version in use:\r\naccelerate-0.18.0.dev0.dist-info\r\
          \ntransformers-4.28.0.dev0.dist-info\r\n\r\nERROR      | __main__:generate:4945\
          \ - Traceback (most recent call last):\r\n  File \"aiserver.py\", line 4934,\
          \ in generate\r\n    genout, already_generated = tpool.execute(_generate,\
          \ txt, minimum, maximum, found_entries)\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/eventlet/tpool.py\"\
          , line 132, in execute\r\n    six.reraise(c, e, tb)\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/six.py\"\
          , line 719, in reraise\r\n    raise value\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/eventlet/tpool.py\"\
          , line 86, in tworker\r\n    rv = meth(*args, **kwargs)\r\n  File \"aiserver.py\"\
          , line 4857, in _generate\r\n    genout = generator(\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context\r\n    return func(*args, **kwargs)\r\n \
          \ File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/generation/utils.py\"\
          , line 1485, in generate\r\n    return self.sample(\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/generation/utils.py\"\
          , line 2524, in sample\r\n    outputs = self(\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = old_forward(*args, **kwargs)\r\
          \n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py\"\
          , line 687, in forward\r\n    outputs = self.model(\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py\"\
          , line 577, in forward\r\n    layer_outputs = decoder_layer(\r\n  File \"\
          /home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = old_forward(*args, **kwargs)\r\
          \n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py\"\
          , line 292, in forward\r\n    hidden_states, self_attn_weights, present_key_value\
          \ = self.self_attn(\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = old_forward(*args, **kwargs)\r\
          \n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py\"\
          , line 203, in forward\r\n    cos, sin = self.rotary_emb(value_states, seq_len=kv_seq_len)\r\
          \n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py\"\
          , line 160, in new_forward\r\n    args, kwargs = module._hf_hook.pre_forward(module,\
          \ *args, **kwargs)\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py\"\
          , line 280, in pre_forward\r\n    set_module_tensor_to_device(module, name,\
          \ self.execution_device, value=self.weights_map[name])\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/utils/offload.py\"\
          , line 123, in __getitem__\r\n    return self.dataset[f\"{self.prefix}{key}\"\
          ]\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/utils/offload.py\"\
          , line 170, in __getitem__\r\n    weight_info = self.index[key]\r\nKeyError:\
          \ 'model.layers.0.self_attn.rotary_emb.cos_cached'\r\n\r\n"
        updatedAt: '2023-04-06T09:35:47.044Z'
      numEdits: 0
      reactions: []
    id: 642e9273bd7a26bb2cb4ae45
    type: comment
  author: tonyaw
  content: "I'm trying to use koboldai-client to load this model, and get this error.\
    \ Could you please help to check what the issue is?\r\nThanks!\r\naccelerate version\
    \ and transformers version in use:\r\naccelerate-0.18.0.dev0.dist-info\r\ntransformers-4.28.0.dev0.dist-info\r\
    \n\r\nERROR      | __main__:generate:4945 - Traceback (most recent call last):\r\
    \n  File \"aiserver.py\", line 4934, in generate\r\n    genout, already_generated\
    \ = tpool.execute(_generate, txt, minimum, maximum, found_entries)\r\n  File \"\
    /home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/eventlet/tpool.py\"\
    , line 132, in execute\r\n    six.reraise(c, e, tb)\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/six.py\"\
    , line 719, in reraise\r\n    raise value\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/eventlet/tpool.py\"\
    , line 86, in tworker\r\n    rv = meth(*args, **kwargs)\r\n  File \"aiserver.py\"\
    , line 4857, in _generate\r\n    genout = generator(\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/autograd/grad_mode.py\"\
    , line 27, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"\
    /home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/generation/utils.py\"\
    , line 1485, in generate\r\n    return self.sample(\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/generation/utils.py\"\
    , line 2524, in sample\r\n    outputs = self(\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
    , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = old_forward(*args, **kwargs)\r\n  File\
    \ \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py\"\
    , line 687, in forward\r\n    outputs = self.model(\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
    , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py\"\
    , line 577, in forward\r\n    layer_outputs = decoder_layer(\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
    , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = old_forward(*args, **kwargs)\r\n  File\
    \ \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py\"\
    , line 292, in forward\r\n    hidden_states, self_attn_weights, present_key_value\
    \ = self.self_attn(\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
    , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = old_forward(*args, **kwargs)\r\n  File\
    \ \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py\"\
    , line 203, in forward\r\n    cos, sin = self.rotary_emb(value_states, seq_len=kv_seq_len)\r\
    \n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
    , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py\"\
    , line 160, in new_forward\r\n    args, kwargs = module._hf_hook.pre_forward(module,\
    \ *args, **kwargs)\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/hooks.py\"\
    , line 280, in pre_forward\r\n    set_module_tensor_to_device(module, name, self.execution_device,\
    \ value=self.weights_map[name])\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/utils/offload.py\"\
    , line 123, in __getitem__\r\n    return self.dataset[f\"{self.prefix}{key}\"\
    ]\r\n  File \"/home/tonyaw/sandbox//koboldai-client/runtime/envs/koboldai/lib/python3.8/site-packages/accelerate/utils/offload.py\"\
    , line 170, in __getitem__\r\n    weight_info = self.index[key]\r\nKeyError: 'model.layers.0.self_attn.rotary_emb.cos_cached'\r\
    \n\r\n"
  created_at: 2023-04-06 08:35:47+00:00
  edited: false
  hidden: false
  id: 642e9273bd7a26bb2cb4ae45
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: chavinlo/gpt4-x-alpaca
repo_type: model
status: open
target_branch: null
title: 'KeyError: ''model.layers.0.self_attn.rotary_emb.cos_cached'''
