!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Light4Bear
conflicting_files: null
created_at: 2023-04-03 05:44:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666277867924-noauth.png?w=200&h=200&f=face
      fullname: Plus Light
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Light4Bear
      type: user
    createdAt: '2023-04-03T06:44:43.000Z'
    data:
      edited: false
      editors:
      - Light4Bear
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666277867924-noauth.png?w=200&h=200&f=face
          fullname: Plus Light
          isHf: false
          isPro: false
          name: Light4Bear
          type: user
        html: '<p>Is there any benefit using fp32? I think the original Llama from
          meta is already in fp16.</p>

          '
        raw: Is there any benefit using fp32? I think the original Llama from meta
          is already in fp16.
        updatedAt: '2023-04-03T06:44:43.899Z'
      numEdits: 0
      reactions: []
    id: 642a75dbd651bae3c11b10c4
    type: comment
  author: Light4Bear
  content: Is there any benefit using fp32? I think the original Llama from meta is
    already in fp16.
  created_at: 2023-04-03 05:44:43+00:00
  edited: false
  hidden: false
  id: 642a75dbd651bae3c11b10c4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-04-05T21:51:57.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>It will run in fp16 in transformers, but it would have been better
          to have fp16 uploaded so it would be smaller</p>

          '
        raw: It will run in fp16 in transformers, but it would have been better to
          have fp16 uploaded so it would be smaller
        updatedAt: '2023-04-05T21:51:57.950Z'
      numEdits: 0
      reactions: []
    id: 642ded7dd6d6892408e1546b
    type: comment
  author: teknium
  content: It will run in fp16 in transformers, but it would have been better to have
    fp16 uploaded so it would be smaller
  created_at: 2023-04-05 20:51:57+00:00
  edited: false
  hidden: false
  id: 642ded7dd6d6892408e1546b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: chavinlo/gpt4-x-alpaca
repo_type: model
status: open
target_branch: null
title: fp16 version of the model
