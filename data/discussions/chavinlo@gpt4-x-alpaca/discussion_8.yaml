!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Said2k
conflicting_files: null
created_at: 2023-04-04 21:51:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e8c049d12c947b8aea6c7a988a6e7c68.svg
      fullname: Anon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Said2k
      type: user
    createdAt: '2023-04-04T22:51:16.000Z'
    data:
      edited: false
      editors:
      - Said2k
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e8c049d12c947b8aea6c7a988a6e7c68.svg
          fullname: Anon
          isHf: false
          isPro: false
          name: Said2k
          type: user
        html: '<p>What is the minimum required to run this? I have 8GB of VRAM and
          64GB of RAM</p>

          '
        raw: What is the minimum required to run this? I have 8GB of VRAM and 64GB
          of RAM
        updatedAt: '2023-04-04T22:51:16.941Z'
      numEdits: 0
      reactions: []
    id: 642ca9e43a6a3fa1ebb0477d
    type: comment
  author: Said2k
  content: What is the minimum required to run this? I have 8GB of VRAM and 64GB of
    RAM
  created_at: 2023-04-04 21:51:16+00:00
  edited: false
  hidden: false
  id: 642ca9e43a6a3fa1ebb0477d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-04-05T21:52:20.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>at least 20GB in 8bit</p>

          '
        raw: at least 20GB in 8bit
        updatedAt: '2023-04-05T21:52:20.525Z'
      numEdits: 0
      reactions: []
    id: 642ded9493f22bbdacfaa94b
    type: comment
  author: teknium
  content: at least 20GB in 8bit
  created_at: 2023-04-05 20:52:20+00:00
  edited: false
  hidden: false
  id: 642ded9493f22bbdacfaa94b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e8c049d12c947b8aea6c7a988a6e7c68.svg
      fullname: Anon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Said2k
      type: user
    createdAt: '2023-04-05T22:16:03.000Z'
    data:
      edited: false
      editors:
      - Said2k
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e8c049d12c947b8aea6c7a988a6e7c68.svg
          fullname: Anon
          isHf: false
          isPro: false
          name: Said2k
          type: user
        html: '<p>RAM or VRAM?</p>

          '
        raw: RAM or VRAM?
        updatedAt: '2023-04-05T22:16:03.450Z'
      numEdits: 0
      reactions: []
    id: 642df32342b094c9138d6961
    type: comment
  author: Said2k
  content: RAM or VRAM?
  created_at: 2023-04-05 21:16:03+00:00
  edited: false
  hidden: false
  id: 642df32342b094c9138d6961
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-04-06T10:15:17.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>Technically, either, but you may need GPTQ (outside the scope of
          HuggingFace) to do it with RAM</p>

          '
        raw: Technically, either, but you may need GPTQ (outside the scope of HuggingFace)
          to do it with RAM
        updatedAt: '2023-04-06T10:15:17.754Z'
      numEdits: 0
      reactions: []
    id: 642e9bb55e76acc792c9218e
    type: comment
  author: teknium
  content: Technically, either, but you may need GPTQ (outside the scope of HuggingFace)
    to do it with RAM
  created_at: 2023-04-06 09:15:17+00:00
  edited: false
  hidden: false
  id: 642e9bb55e76acc792c9218e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/23aba778a7daae99348aeb0728cf4aec.svg
      fullname: Eric Kryski
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ekryski
      type: user
    createdAt: '2023-04-07T20:55:00.000Z'
    data:
      edited: false
      editors:
      - ekryski
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/23aba778a7daae99348aeb0728cf4aec.svg
          fullname: Eric Kryski
          isHf: false
          isPro: false
          name: ekryski
          type: user
        html: '<p>You definitely will but it is runnable and there is a model that
          has been converted to ggml already. Details in other thread:</p>

          <p><a href="https://huggingface.co/chavinlo/gpt4-x-alpaca/discussions/7#6430803a1a8652d76a3e68b5">https://huggingface.co/chavinlo/gpt4-x-alpaca/discussions/7#6430803a1a8652d76a3e68b5</a></p>

          '
        raw: 'You definitely will but it is runnable and there is a model that has
          been converted to ggml already. Details in other thread:


          https://huggingface.co/chavinlo/gpt4-x-alpaca/discussions/7#6430803a1a8652d76a3e68b5'
        updatedAt: '2023-04-07T20:55:00.476Z'
      numEdits: 0
      reactions: []
    id: 64308324dbf96004473fc9a7
    type: comment
  author: ekryski
  content: 'You definitely will but it is runnable and there is a model that has been
    converted to ggml already. Details in other thread:


    https://huggingface.co/chavinlo/gpt4-x-alpaca/discussions/7#6430803a1a8652d76a3e68b5'
  created_at: 2023-04-07 19:55:00+00:00
  edited: false
  hidden: false
  id: 64308324dbf96004473fc9a7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: chavinlo/gpt4-x-alpaca
repo_type: model
status: open
target_branch: null
title: system requirements?
