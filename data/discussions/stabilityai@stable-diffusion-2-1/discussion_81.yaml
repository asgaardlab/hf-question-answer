!!python/object:huggingface_hub.community.DiscussionWithDetails
author: JungaoCanada
conflicting_files: null
created_at: 2023-08-22 00:09:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5d48c171ddbcc7ca39bdc0d11c6224e4.svg
      fullname: Jun Gao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JungaoCanada
      type: user
    createdAt: '2023-08-22T01:09:45.000Z'
    data:
      edited: false
      editors:
      - JungaoCanada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.782565712928772
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5d48c171ddbcc7ca39bdc0d11c6224e4.svg
          fullname: Jun Gao
          isHf: false
          isPro: false
          name: JungaoCanada
          type: user
        html: '<p>Hi, </p>

          <p>I find there probably is a problem in setting up the text encoder, not
          sure why this occurs...</p>

          <p>In particular, in the text encoder, the number of hidden layers is set
          to 23 <a href="https://huggingface.co/stabilityai/stable-diffusion-2-1/blob/main/text_encoder/config.json#L19">https://huggingface.co/stabilityai/stable-diffusion-2-1/blob/main/text_encoder/config.json#L19</a>,
          However, when looking into the official OpenClip H-14, the number of the
          hidden layer is 24 <a rel="nofollow" href="https://github.com/mlfoundations/open_clip/blob/main/src/open_clip/model_configs/ViT-H-14.json#L15">https://github.com/mlfoundations/open_clip/blob/main/src/open_clip/model_configs/ViT-H-14.json#L15</a>,
          this can also be confirmed from the number of layers in the LAION CLIP ViT
          H-14 repo, <a href="https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/blob/main/config.json#L54">https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/blob/main/config.json#L54</a></p>

          <p>Does anyone know why the hugging face repo is setting the number of hidden
          layers to 23? Is this a bug, or a small trick to improve the sampling performance?
          </p>

          <p>Thanks</p>

          '
        raw: "Hi, \r\n\r\nI find there probably is a problem in setting up the text\
          \ encoder, not sure why this occurs...\r\n\r\nIn particular, in the text\
          \ encoder, the number of hidden layers is set to 23 https://huggingface.co/stabilityai/stable-diffusion-2-1/blob/main/text_encoder/config.json#L19,\
          \ However, when looking into the official OpenClip H-14, the number of the\
          \ hidden layer is 24 https://github.com/mlfoundations/open_clip/blob/main/src/open_clip/model_configs/ViT-H-14.json#L15,\
          \ this can also be confirmed from the number of layers in the LAION CLIP\
          \ ViT H-14 repo, https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/blob/main/config.json#L54\r\
          \n\r\n\r\nDoes anyone know why the hugging face repo is setting the number\
          \ of hidden layers to 23? Is this a bug, or a small trick to improve the\
          \ sampling performance? \r\n\r\nThanks\r\n"
        updatedAt: '2023-08-22T01:09:45.796Z'
      numEdits: 0
      reactions: []
    id: 64e40ad958579025cbb403d7
    type: comment
  author: JungaoCanada
  content: "Hi, \r\n\r\nI find there probably is a problem in setting up the text\
    \ encoder, not sure why this occurs...\r\n\r\nIn particular, in the text encoder,\
    \ the number of hidden layers is set to 23 https://huggingface.co/stabilityai/stable-diffusion-2-1/blob/main/text_encoder/config.json#L19,\
    \ However, when looking into the official OpenClip H-14, the number of the hidden\
    \ layer is 24 https://github.com/mlfoundations/open_clip/blob/main/src/open_clip/model_configs/ViT-H-14.json#L15,\
    \ this can also be confirmed from the number of layers in the LAION CLIP ViT H-14\
    \ repo, https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/blob/main/config.json#L54\r\
    \n\r\n\r\nDoes anyone know why the hugging face repo is setting the number of\
    \ hidden layers to 23? Is this a bug, or a small trick to improve the sampling\
    \ performance? \r\n\r\nThanks\r\n"
  created_at: 2023-08-22 00:09:45+00:00
  edited: false
  hidden: false
  id: 64e40ad958579025cbb403d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62fa41d0363251ee40a2915d/AWbQCvPkxujxR5BCfCniz.jpeg?w=200&h=200&f=face
      fullname: Viktor Toth
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vtoth
      type: user
    createdAt: '2023-12-01T22:32:59.000Z'
    data:
      edited: true
      editors:
      - vtoth
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9129307270050049
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62fa41d0363251ee40a2915d/AWbQCvPkxujxR5BCfCniz.jpeg?w=200&h=200&f=face
          fullname: Viktor Toth
          isHf: false
          isPro: false
          name: vtoth
          type: user
        html: '<p>Can this possibly be about the last projection layer being removed
          from/not used in SD as it takes the 77x1024 text embedding as input, not
          the final CLIP projection of dim 1024? </p>

          '
        raw: 'Can this possibly be about the last projection layer being removed from/not
          used in SD as it takes the 77x1024 text embedding as input, not the final
          CLIP projection of dim 1024? '
        updatedAt: '2023-12-01T22:33:16.496Z'
      numEdits: 1
      reactions: []
    id: 656a5f1baf6d3c4129e96e1e
    type: comment
  author: vtoth
  content: 'Can this possibly be about the last projection layer being removed from/not
    used in SD as it takes the 77x1024 text embedding as input, not the final CLIP
    projection of dim 1024? '
  created_at: 2023-12-01 22:32:59+00:00
  edited: true
  hidden: false
  id: 656a5f1baf6d3c4129e96e1e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 81
repo_id: stabilityai/stable-diffusion-2-1
repo_type: model
status: open
target_branch: null
title: 'Question in the Text encoder setting '
