!!python/object:huggingface_hub.community.DiscussionWithDetails
author: petarulev
conflicting_files: null
created_at: 2023-01-04 09:09:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8b708e9c4d61baf79a7bbf23002adf9e.svg
      fullname: Petar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: petarulev
      type: user
    createdAt: '2023-01-04T09:09:00.000Z'
    data:
      edited: false
      editors:
      - petarulev
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8b708e9c4d61baf79a7bbf23002adf9e.svg
          fullname: Petar
          isHf: false
          isPro: false
          name: petarulev
          type: user
        html: '<p>I have tried a couple sentences and the model seems not to give
          accurate predictions most of the time. </p>

          <p>What dataset it was trained on, I mean, how was the data labelled? Did
          you train this model on VADER-generated labels?</p>

          <p>I can help you improve your model. Please respond to this discussion.</p>

          '
        raw: "I have tried a couple sentences and the model seems not to give accurate\
          \ predictions most of the time. \r\n\r\nWhat dataset it was trained on,\
          \ I mean, how was the data labelled? Did you train this model on VADER-generated\
          \ labels?\r\n\r\nI can help you improve your model. Please respond to this\
          \ discussion."
        updatedAt: '2023-01-04T09:09:00.837Z'
      numEdits: 0
      reactions: []
    id: 63b5422c2bd3611e666c503a
    type: comment
  author: petarulev
  content: "I have tried a couple sentences and the model seems not to give accurate\
    \ predictions most of the time. \r\n\r\nWhat dataset it was trained on, I mean,\
    \ how was the data labelled? Did you train this model on VADER-generated labels?\r\
    \n\r\nI can help you improve your model. Please respond to this discussion."
  created_at: 2023-01-04 09:09:00+00:00
  edited: false
  hidden: false
  id: 63b5422c2bd3611e666c503a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655591341573-noauth.jpeg?w=200&h=200&f=face
      fullname: Mikolaj Kulakowski
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ElKulako
      type: user
    createdAt: '2023-01-04T19:51:24.000Z'
    data:
      edited: false
      editors:
      - ElKulako
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655591341573-noauth.jpeg?w=200&h=200&f=face
          fullname: Mikolaj Kulakowski
          isHf: false
          isPro: false
          name: ElKulako
          type: user
        html: '<p>Hello there,</p>

          <p>Thanks for taking the interest in this model. As you can read in the
          model card, the classification head has been trained on a balanced sample
          of around 2M StockTwits posts.</p>

          <p>The stocktwits posts are labelled by their authors as either Bullish
          or bearish (or, if there''s no label, we assume it is neutral). This is
          thus exogenous labelling. </p>

          <p>The model has been tested, out-of-sample, on a set of around 200K stocktwits
          posts, and delivered superior classification performance when compared to
          Vader or other BERT-based classifiers. The accuracy and F1-score for 3-class
          problem (bearish, neutral and bullish) was around 70% if I remember correctly.
          This greatly outperformed VADER''s predictions, which delivered accuracy
          closer to 50%. </p>

          <p>So cryptobert is the most accurate model for the task at hand (sentiment
          analysis of cryptocurrency-related social media posts), at least it was
          in July 2022 when I tested it. However, this task is very cumbersome, as
          people can label their posts however they see fit.<br>Remember that the
          cryptocurrency investor''s language is not standardised and can be imprecise
          in many cases.</p>

          <p>The above means that in some cases the predictions could be slightly
          off. However, this model is still the most accurate classifier for the task
          at hand. </p>

          <p>Using Vader-generated labels, like you suggest, would likely lead to
          inferior performance, as CryptoBERT severely outperforms vader for this
          particular task. I''ve also spent many months trying to improve the model
          in an affordable way. </p>

          <p>So if you have any suggestions on how to improve its performance, I''ll
          be happy to read them, however bare in mind that this task is very difficult
          by default, and reaching accuracies above 75% is simply not possible for
          the data available. (As e.g. two people could write a very similar post,
          but if each of them gives a different label, then it''s impossible to predict
          both instances correctly).</p>

          <p>Oh, and please don''t try to use it for other tasks, such as testing
          restaurant reviews, as this model can only be used for cryprocurrency-related
          language from social media posts</p>

          '
        raw: "Hello there,\n\nThanks for taking the interest in this model. As you\
          \ can read in the model card, the classification head has been trained on\
          \ a balanced sample of around 2M StockTwits posts.\n\nThe stocktwits posts\
          \ are labelled by their authors as either Bullish or bearish (or, if there's\
          \ no label, we assume it is neutral). This is thus exogenous labelling.\
          \ \n\nThe model has been tested, out-of-sample, on a set of around 200K\
          \ stocktwits posts, and delivered superior classification performance when\
          \ compared to Vader or other BERT-based classifiers. The accuracy and F1-score\
          \ for 3-class problem (bearish, neutral and bullish) was around 70% if I\
          \ remember correctly. This greatly outperformed VADER's predictions, which\
          \ delivered accuracy closer to 50%. \n\nSo cryptobert is the most accurate\
          \ model for the task at hand (sentiment analysis of cryptocurrency-related\
          \ social media posts), at least it was in July 2022 when I tested it. However,\
          \ this task is very cumbersome, as people can label their posts however\
          \ they see fit.\nRemember that the cryptocurrency investor's language is\
          \ not standardised and can be imprecise in many cases.\n \nThe above means\
          \ that in some cases the predictions could be slightly off. However, this\
          \ model is still the most accurate classifier for the task at hand. \n\n\
          Using Vader-generated labels, like you suggest, would likely lead to inferior\
          \ performance, as CryptoBERT severely outperforms vader for this particular\
          \ task. I've also spent many months trying to improve the model in an affordable\
          \ way. \n\nSo if you have any suggestions on how to improve its performance,\
          \ I'll be happy to read them, however bare in mind that this task is very\
          \ difficult by default, and reaching accuracies above 75% is simply not\
          \ possible for the data available. (As e.g. two people could write a very\
          \ similar post, but if each of them gives a different label, then it's impossible\
          \ to predict both instances correctly).\n\nOh, and please don't try to use\
          \ it for other tasks, such as testing restaurant reviews, as this model\
          \ can only be used for cryprocurrency-related language from social media\
          \ posts"
        updatedAt: '2023-01-04T19:51:24.563Z'
      numEdits: 0
      reactions: []
    id: 63b5d8bc9223c073fe8f5b80
    type: comment
  author: ElKulako
  content: "Hello there,\n\nThanks for taking the interest in this model. As you can\
    \ read in the model card, the classification head has been trained on a balanced\
    \ sample of around 2M StockTwits posts.\n\nThe stocktwits posts are labelled by\
    \ their authors as either Bullish or bearish (or, if there's no label, we assume\
    \ it is neutral). This is thus exogenous labelling. \n\nThe model has been tested,\
    \ out-of-sample, on a set of around 200K stocktwits posts, and delivered superior\
    \ classification performance when compared to Vader or other BERT-based classifiers.\
    \ The accuracy and F1-score for 3-class problem (bearish, neutral and bullish)\
    \ was around 70% if I remember correctly. This greatly outperformed VADER's predictions,\
    \ which delivered accuracy closer to 50%. \n\nSo cryptobert is the most accurate\
    \ model for the task at hand (sentiment analysis of cryptocurrency-related social\
    \ media posts), at least it was in July 2022 when I tested it. However, this task\
    \ is very cumbersome, as people can label their posts however they see fit.\n\
    Remember that the cryptocurrency investor's language is not standardised and can\
    \ be imprecise in many cases.\n \nThe above means that in some cases the predictions\
    \ could be slightly off. However, this model is still the most accurate classifier\
    \ for the task at hand. \n\nUsing Vader-generated labels, like you suggest, would\
    \ likely lead to inferior performance, as CryptoBERT severely outperforms vader\
    \ for this particular task. I've also spent many months trying to improve the\
    \ model in an affordable way. \n\nSo if you have any suggestions on how to improve\
    \ its performance, I'll be happy to read them, however bare in mind that this\
    \ task is very difficult by default, and reaching accuracies above 75% is simply\
    \ not possible for the data available. (As e.g. two people could write a very\
    \ similar post, but if each of them gives a different label, then it's impossible\
    \ to predict both instances correctly).\n\nOh, and please don't try to use it\
    \ for other tasks, such as testing restaurant reviews, as this model can only\
    \ be used for cryprocurrency-related language from social media posts"
  created_at: 2023-01-04 19:51:24+00:00
  edited: false
  hidden: false
  id: 63b5d8bc9223c073fe8f5b80
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655591341573-noauth.jpeg?w=200&h=200&f=face
      fullname: Mikolaj Kulakowski
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ElKulako
      type: user
    createdAt: '2023-01-23T02:54:10.000Z'
    data:
      from: Model doesn't give accurate predictions most of the time.
      to: Improving the model predictions
    id: 63cdf6d2ffc75ec5ce5238d5
    type: title-change
  author: ElKulako
  created_at: 2023-01-23 02:54:10+00:00
  id: 63cdf6d2ffc75ec5ce5238d5
  new_title: Improving the model predictions
  old_title: Model doesn't give accurate predictions most of the time.
  type: title-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: ElKulako/cryptobert
repo_type: model
status: open
target_branch: null
title: Improving the model predictions
