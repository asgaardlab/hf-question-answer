!!python/object:huggingface_hub.community.DiscussionWithDetails
author: qinluo
conflicting_files: null
created_at: 2023-05-31 07:04:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/376ae9997c5b02eb6faafdbd6b50f66b.svg
      fullname: qinluo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: qinluo
      type: user
    createdAt: '2023-05-31T08:04:09.000Z'
    data:
      edited: false
      editors:
      - qinluo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/376ae9997c5b02eb6faafdbd6b50f66b.svg
          fullname: qinluo
          isHf: false
          isPro: false
          name: qinluo
          type: user
        html: '<p>could you share the training loss curve pic ? Thanks a lot.</p>

          '
        raw: could you share the training loss curve pic ? Thanks a lot.
        updatedAt: '2023-05-31T08:04:09.938Z'
      numEdits: 0
      reactions: []
    id: 6476ff7903fe88eff54c4179
    type: comment
  author: qinluo
  content: could you share the training loss curve pic ? Thanks a lot.
  created_at: 2023-05-31 07:04:09+00:00
  edited: false
  hidden: false
  id: 6476ff7903fe88eff54c4179
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-05-31T09:54:14.000Z'
    data:
      edited: true
      editors:
      - loubnabnl
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
          fullname: Loubna Ben Allal
          isHf: true
          isPro: false
          name: loubnabnl
          type: user
        html: '<p>Here are the training loss curves:<br><img height="300" width="400"
          src="https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/lORgPR-dILs55npUvjg9R.png"><br><img
          height="300" width="400" src="https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/LxG5AYX81stXR1ih8jVPx.png"></p>

          '
        raw: "Here are the training loss curves:\n<img src=\"https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/lORgPR-dILs55npUvjg9R.png\"\
          \  width=\"400\" height=\"300\"> \n<img src=\"https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/LxG5AYX81stXR1ih8jVPx.png\"\
          \  width=\"400\" height=\"300\">"
        updatedAt: '2023-05-31T09:56:23.161Z'
      numEdits: 2
      reactions: []
    id: 64771946906bb0203e5007ac
    type: comment
  author: loubnabnl
  content: "Here are the training loss curves:\n<img src=\"https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/lORgPR-dILs55npUvjg9R.png\"\
    \  width=\"400\" height=\"300\"> \n<img src=\"https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/LxG5AYX81stXR1ih8jVPx.png\"\
    \  width=\"400\" height=\"300\">"
  created_at: 2023-05-31 08:54:14+00:00
  edited: true
  hidden: false
  id: 64771946906bb0203e5007ac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/376ae9997c5b02eb6faafdbd6b50f66b.svg
      fullname: qinluo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: qinluo
      type: user
    createdAt: '2023-05-31T10:05:44.000Z'
    data:
      edited: false
      editors:
      - qinluo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/376ae9997c5b02eb6faafdbd6b50f66b.svg
          fullname: qinluo
          isHf: false
          isPro: false
          name: qinluo
          type: user
        html: '<p>Thanks very much.</p>

          <p>I''ve got a similar training loss curve, but with weird Human-Eval pass@1
          = 0.0%. </p>

          <p>The Model Arch: Multi-Head-Attention + FlashAttention + Rotary Position
          embedding + 2048 context length</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6195e082c08b46ac32a10755/mCTbfvwBKpjXd2ScIyFdj.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6195e082c08b46ac32a10755/mCTbfvwBKpjXd2ScIyFdj.png"></a></p>

          '
        raw: "Thanks very much.\n\nI've got a similar training loss curve, but with\
          \ weird Human-Eval pass@1 = 0.0%. \n\nThe Model Arch: Multi-Head-Attention\
          \ + FlashAttention + Rotary Position embedding + 2048 context length\n\n\
          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6195e082c08b46ac32a10755/mCTbfvwBKpjXd2ScIyFdj.png)"
        updatedAt: '2023-05-31T10:05:44.256Z'
      numEdits: 0
      reactions: []
    id: 64771bf8242dde316300de43
    type: comment
  author: qinluo
  content: "Thanks very much.\n\nI've got a similar training loss curve, but with\
    \ weird Human-Eval pass@1 = 0.0%. \n\nThe Model Arch: Multi-Head-Attention + FlashAttention\
    \ + Rotary Position embedding + 2048 context length\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6195e082c08b46ac32a10755/mCTbfvwBKpjXd2ScIyFdj.png)"
  created_at: 2023-05-31 09:05:44+00:00
  edited: false
  hidden: false
  id: 64771bf8242dde316300de43
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-05-31T11:59:53.000Z'
    data:
      edited: false
      editors:
      - loubnabnl
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
          fullname: Loubna Ben Allal
          isHf: true
          isPro: false
          name: loubnabnl
          type: user
        html: '<p>it''s hard to compare without context, on what data did you train
          your model, is it the same as this <code>tiny_starcoder_py</code>? And what''s
          your global batch size? For us it was 2M tokens (256 BS *8196 seq_length)
          so if you used the same batch size with 2048 seq length that means you trained
          on 4 times less data than we did with 50k steps</p>

          '
        raw: it's hard to compare without context, on what data did you train your
          model, is it the same as this `tiny_starcoder_py`? And what's your global
          batch size? For us it was 2M tokens (256 BS *8196 seq_length) so if you
          used the same batch size with 2048 seq length that means you trained on
          4 times less data than we did with 50k steps
        updatedAt: '2023-05-31T11:59:53.760Z'
      numEdits: 0
      reactions: []
    id: 647736b940c99df876047458
    type: comment
  author: loubnabnl
  content: it's hard to compare without context, on what data did you train your model,
    is it the same as this `tiny_starcoder_py`? And what's your global batch size?
    For us it was 2M tokens (256 BS *8196 seq_length) so if you used the same batch
    size with 2048 seq length that means you trained on 4 times less data than we
    did with 50k steps
  created_at: 2023-05-31 10:59:53+00:00
  edited: false
  hidden: false
  id: 647736b940c99df876047458
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/376ae9997c5b02eb6faafdbd6b50f66b.svg
      fullname: qinluo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: qinluo
      type: user
    createdAt: '2023-05-31T12:16:05.000Z'
    data:
      edited: false
      editors:
      - qinluo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/376ae9997c5b02eb6faafdbd6b50f66b.svg
          fullname: qinluo
          isHf: false
          isPro: false
          name: qinluo
          type: user
        html: '<blockquote>

          <p>it''s hard to compare without context, on what data did you train your
          model, is it the same as this <code>tiny_starcoder_py</code>? And what''s
          your global batch size? For us it was 2M tokens (256 BS *8196 seq_length)
          so if you used the same batch size with 2048 seq length that means you trained
          on 4 times less data than we did with 50k steps</p>

          </blockquote>

          <ol>

          <li>data: same as this <code>tiny_starcoder_py</code>, the python code from
          starcoderdata. </li>

          <li>global batch size: 8*16 = 128 =&gt; global batch tokens = 128 BS *2048</li>

          <li>seq_length: 2048</li>

          </ol>

          <p>I''ll try more.</p>

          <p>Thanks a again</p>

          '
        raw: "> it's hard to compare without context, on what data did you train your\
          \ model, is it the same as this `tiny_starcoder_py`? And what's your global\
          \ batch size? For us it was 2M tokens (256 BS *8196 seq_length) so if you\
          \ used the same batch size with 2048 seq length that means you trained on\
          \ 4 times less data than we did with 50k steps\n\n1) data: same as this\
          \ `tiny_starcoder_py`, the python code from starcoderdata. \n2) global batch\
          \ size: 8*16 = 128 => global batch tokens = 128 BS *2048\n3) seq_length:\
          \ 2048\n\nI'll try more.\n\nThanks a again"
        updatedAt: '2023-05-31T12:16:05.467Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - loubnabnl
    id: 64773a85beaeebff4a56d5bd
    type: comment
  author: qinluo
  content: "> it's hard to compare without context, on what data did you train your\
    \ model, is it the same as this `tiny_starcoder_py`? And what's your global batch\
    \ size? For us it was 2M tokens (256 BS *8196 seq_length) so if you used the same\
    \ batch size with 2048 seq length that means you trained on 4 times less data\
    \ than we did with 50k steps\n\n1) data: same as this `tiny_starcoder_py`, the\
    \ python code from starcoderdata. \n2) global batch size: 8*16 = 128 => global\
    \ batch tokens = 128 BS *2048\n3) seq_length: 2048\n\nI'll try more.\n\nThanks\
    \ a again"
  created_at: 2023-05-31 11:16:05+00:00
  edited: false
  hidden: false
  id: 64773a85beaeebff4a56d5bd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-08-15T10:32:44.000Z'
    data:
      status: closed
    id: 64db544c3e51c5123381313f
    type: status-change
  author: loubnabnl
  created_at: 2023-08-15 09:32:44+00:00
  id: 64db544c3e51c5123381313f
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: bigcode/tiny_starcoder_py
repo_type: model
status: closed
target_branch: null
title: what is the final value of the training loss?
