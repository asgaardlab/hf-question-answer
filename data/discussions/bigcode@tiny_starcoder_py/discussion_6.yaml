!!python/object:huggingface_hub.community.DiscussionWithDetails
author: cdj0311
conflicting_files: null
created_at: 2023-06-16 08:08:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ab12d5c485bd2e3b2f351f0419d2164.svg
      fullname: ChenDajun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cdj0311
      type: user
    createdAt: '2023-06-16T09:08:33.000Z'
    data:
      edited: false
      editors:
      - cdj0311
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8757283091545105
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ab12d5c485bd2e3b2f351f0419d2164.svg
          fullname: ChenDajun
          isHf: false
          isPro: false
          name: cdj0311
          type: user
        html: '<p>hi,<br>I want convert megatron model (trained by myself with bigcode-project/Megatron-LM
          repo) to huggingface format, can you provide a script to convert it?</p>

          '
        raw: "hi,\r\nI want convert megatron model (trained by myself with bigcode-project/Megatron-LM\
          \ repo) to huggingface format, can you provide a script to convert it?"
        updatedAt: '2023-06-16T09:08:33.985Z'
      numEdits: 0
      reactions: []
    id: 648c2691f96e28beac341820
    type: comment
  author: cdj0311
  content: "hi,\r\nI want convert megatron model (trained by myself with bigcode-project/Megatron-LM\
    \ repo) to huggingface format, can you provide a script to convert it?"
  created_at: 2023-06-16 08:08:33+00:00
  edited: false
  hidden: false
  id: 648c2691f96e28beac341820
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-06-16T16:59:24.000Z'
    data:
      edited: false
      editors:
      - loubnabnl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5923019051551819
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
          fullname: Loubna Ben Allal
          isHf: true
          isPro: false
          name: loubnabnl
          type: user
        html: '<p>You can clone this repo: <a rel="nofollow" href="https://github.com/bigcode-project/transformers/">https://github.com/bigcode-project/transformers/</a>
          and use this <a rel="nofollow" href="https://github.com/bigcode-project/transformers/blob/main/src/transformers/models/megatron_gpt_bigcode/push_checkpoints.py">code</a></p>

          '
        raw: 'You can clone this repo: https://github.com/bigcode-project/transformers/
          and use this [code](https://github.com/bigcode-project/transformers/blob/main/src/transformers/models/megatron_gpt_bigcode/push_checkpoints.py)

          '
        updatedAt: '2023-06-16T16:59:24.639Z'
      numEdits: 0
      reactions: []
    id: 648c94ec21a4e18834e4f923
    type: comment
  author: loubnabnl
  content: 'You can clone this repo: https://github.com/bigcode-project/transformers/
    and use this [code](https://github.com/bigcode-project/transformers/blob/main/src/transformers/models/megatron_gpt_bigcode/push_checkpoints.py)

    '
  created_at: 2023-06-16 15:59:24+00:00
  edited: false
  hidden: false
  id: 648c94ec21a4e18834e4f923
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ab12d5c485bd2e3b2f351f0419d2164.svg
      fullname: ChenDajun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cdj0311
      type: user
    createdAt: '2023-08-15T07:56:30.000Z'
    data:
      edited: false
      editors:
      - cdj0311
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6483924984931946
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ab12d5c485bd2e3b2f351f0419d2164.svg
          fullname: ChenDajun
          isHf: false
          isPro: false
          name: cdj0311
          type: user
        html: '<blockquote>

          <p>You can clone this repo: <a rel="nofollow" href="https://github.com/bigcode-project/transformers/">https://github.com/bigcode-project/transformers/</a>
          and use this <a rel="nofollow" href="https://github.com/bigcode-project/transformers/blob/main/src/transformers/models/megatron_gpt_bigcode/push_checkpoints.py">code</a></p>

          </blockquote>

          <p>Thanks,<br>   But this code just support 1-way tensor/pipeline parallelism
          model converted, how to convert when tensor/pipline parallelism &gt; 1?</p>

          '
        raw: "> You can clone this repo: https://github.com/bigcode-project/transformers/\
          \ and use this [code](https://github.com/bigcode-project/transformers/blob/main/src/transformers/models/megatron_gpt_bigcode/push_checkpoints.py)\n\
          \nThanks, \n   But this code just support 1-way tensor/pipeline parallelism\
          \ model converted, how to convert when tensor/pipline parallelism > 1?"
        updatedAt: '2023-08-15T07:56:30.349Z'
      numEdits: 0
      reactions: []
    id: 64db2fae3725f8d9a9fb6cea
    type: comment
  author: cdj0311
  content: "> You can clone this repo: https://github.com/bigcode-project/transformers/\
    \ and use this [code](https://github.com/bigcode-project/transformers/blob/main/src/transformers/models/megatron_gpt_bigcode/push_checkpoints.py)\n\
    \nThanks, \n   But this code just support 1-way tensor/pipeline parallelism model\
    \ converted, how to convert when tensor/pipline parallelism > 1?"
  created_at: 2023-08-15 06:56:30+00:00
  edited: false
  hidden: false
  id: 64db2fae3725f8d9a9fb6cea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-08-15T10:29:36.000Z'
    data:
      edited: false
      editors:
      - loubnabnl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5648171305656433
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
          fullname: Loubna Ben Allal
          isHf: true
          isPro: false
          name: loubnabnl
          type: user
        html: "<p>you need to merge the partitions with Megatron-LM before the conversion,\
          \ with something like this</p>\n<pre><code class=\"language-bash\">python\
          \ Megatron-LM/tools/checkpoint_util.py \\\n        --model-type GPT  \\\n\
          \        --load-dir CKPT_DIR \\\n        --save-dir OUTPUT_PATH \\\n   \
          \     --target-tensor-parallel-size 1 \\\n        --target-pipeline-parallel-size\
          \ 1 \n</code></pre>\n"
        raw: "you need to merge the partitions with Megatron-LM before the conversion,\
          \ with something like this\n```bash\npython Megatron-LM/tools/checkpoint_util.py\
          \ \\\n        --model-type GPT  \\\n        --load-dir CKPT_DIR \\\n   \
          \     --save-dir OUTPUT_PATH \\\n        --target-tensor-parallel-size 1\
          \ \\\n        --target-pipeline-parallel-size 1 \n```"
        updatedAt: '2023-08-15T10:29:36.680Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - cdj0311
    id: 64db53903a7ab21ea7eaadb9
    type: comment
  author: loubnabnl
  content: "you need to merge the partitions with Megatron-LM before the conversion,\
    \ with something like this\n```bash\npython Megatron-LM/tools/checkpoint_util.py\
    \ \\\n        --model-type GPT  \\\n        --load-dir CKPT_DIR \\\n        --save-dir\
    \ OUTPUT_PATH \\\n        --target-tensor-parallel-size 1 \\\n        --target-pipeline-parallel-size\
    \ 1 \n```"
  created_at: 2023-08-15 09:29:36+00:00
  edited: false
  hidden: false
  id: 64db53903a7ab21ea7eaadb9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9ab12d5c485bd2e3b2f351f0419d2164.svg
      fullname: ChenDajun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cdj0311
      type: user
    createdAt: '2023-10-23T03:18:09.000Z'
    data:
      status: closed
    id: 6535e5f13da0ff3c70bf642e
    type: status-change
  author: cdj0311
  created_at: 2023-10-23 02:18:09+00:00
  id: 6535e5f13da0ff3c70bf642e
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: bigcode/tiny_starcoder_py
repo_type: model
status: closed
target_branch: null
title: how to convert megatron model to huggingface?
