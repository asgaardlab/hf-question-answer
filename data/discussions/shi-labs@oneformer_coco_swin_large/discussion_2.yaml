!!python/object:huggingface_hub.community.DiscussionWithDetails
author: galochka
conflicting_files: null
created_at: 2023-11-22 15:31:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4fd8459f88d9f3f9d6532704b430cfea.svg
      fullname: Galina Rozhkova
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: galochka
      type: user
    createdAt: '2023-11-22T15:31:29.000Z'
    data:
      edited: false
      editors:
      - galochka
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.70710688829422
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4fd8459f88d9f3f9d6532704b430cfea.svg
          fullname: Galina Rozhkova
          isHf: false
          isPro: false
          name: galochka
          type: user
        html: "<p>I have a problem when I use a model on GPU.<br>I use a simple code</p>\n\
          <pre><code class=\"language-processor\">model = OneFormerForUniversalSegmentation.from_pretrained('shi-labs/oneformer_coco_swin_large').to('cuda')\n\
          instance_inputs = processor(images=image, task_inputs=['instance'], return_tensors='pt').to('cuda')\n\
          with torch.no_grad():\n    outputs = model(**instance_inputs)\ninstance_segmentation\
          \ = processor.post_process_instance_segmentation(outputs)[0]\n</code></pre>\n\
          <p>In this case model return OneFormerModelOutput object and it's on GPU.\
          \ model(**instance_inputs).to('cpu') doesn't work here. How can I return\
          \ this object on CPU?</p>\n"
        raw: "I have a problem when I use a model on GPU.\r\nI use a simple code\r\
          \n```processor = OneFormerProcessor.from_pretrained('shi-labs/oneformer_coco_swin_large')\r\
          \nmodel = OneFormerForUniversalSegmentation.from_pretrained('shi-labs/oneformer_coco_swin_large').to('cuda')\r\
          \ninstance_inputs = processor(images=image, task_inputs=['instance'], return_tensors='pt').to('cuda')\r\
          \nwith torch.no_grad():\r\n    outputs = model(**instance_inputs)\r\ninstance_segmentation\
          \ = processor.post_process_instance_segmentation(outputs)[0]\r\n```\r\n\
          In this case model return OneFormerModelOutput object and it's on GPU. model(**instance_inputs).to('cpu')\
          \ doesn't work here. How can I return this object on CPU?"
        updatedAt: '2023-11-22T15:31:29.623Z'
      numEdits: 0
      reactions: []
    id: 655e1ed182afda0fc483efe0
    type: comment
  author: galochka
  content: "I have a problem when I use a model on GPU.\r\nI use a simple code\r\n\
    ```processor = OneFormerProcessor.from_pretrained('shi-labs/oneformer_coco_swin_large')\r\
    \nmodel = OneFormerForUniversalSegmentation.from_pretrained('shi-labs/oneformer_coco_swin_large').to('cuda')\r\
    \ninstance_inputs = processor(images=image, task_inputs=['instance'], return_tensors='pt').to('cuda')\r\
    \nwith torch.no_grad():\r\n    outputs = model(**instance_inputs)\r\ninstance_segmentation\
    \ = processor.post_process_instance_segmentation(outputs)[0]\r\n```\r\nIn this\
    \ case model return OneFormerModelOutput object and it's on GPU. model(**instance_inputs).to('cpu')\
    \ doesn't work here. How can I return this object on CPU?"
  created_at: 2023-11-22 15:31:29+00:00
  edited: false
  hidden: false
  id: 655e1ed182afda0fc483efe0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: shi-labs/oneformer_coco_swin_large
repo_type: model
status: open
target_branch: null
title: Problem using on GPU
