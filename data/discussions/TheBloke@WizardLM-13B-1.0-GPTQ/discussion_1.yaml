!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jaspreet2744
conflicting_files: null
created_at: 2023-10-04 18:28:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b28db7886e20e83f05ec16b22ae60c3c.svg
      fullname: Jaspreet Kambo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jaspreet2744
      type: user
    createdAt: '2023-10-04T19:28:38.000Z'
    data:
      edited: false
      editors:
      - jaspreet2744
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.38413283228874207
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b28db7886e20e83f05ec16b22ae60c3c.svg
          fullname: Jaspreet Kambo
          isHf: false
          isPro: false
          name: jaspreet2744
          type: user
        html: "<p>Traceback (most recent call last):</p>\n<p>File \u201CC:\\Users\\\
          kambo-s\\text-generation-webui\\modules\\exllama_hf.py\u201D, line 14, in</p>\n\
          <p>from exllama.model import ExLlama, ExLlamaCache, ExLlamaConfig<br>File\
          \ \u201CC:\\Users\\kambo-s\\anaconda3\\envs\\textgen\\lib\\site-packages\\\
          exllama_init_.py\u201D, line 1, in</p>\n<p>from . import cuda_ext, generator,\
          \ model, tokenizer<br>File \u201CC:\\Users\\kambo-s\\anaconda3\\envs\\textgen\\\
          lib\\site-packages\\exllama\\cuda_ext.py\u201D, line 9, in</p>\n<p>import\
          \ exllama_ext<br>ImportError: DLL load failed while importing exllama_ext:\
          \ The specified module could not be found.</p>\n<p>During handling of the\
          \ above exception, another exception occurred:</p>\n<p>Traceback (most recent\
          \ call last):</p>\n<p>File \u201CC:\\Users\\kambo-s\\text-generation-webui\\\
          modules\\ui_model_menu.py\u201D, line 201, in load_model_wrapper</p>\n<p>shared.model,\
          \ shared.tokenizer = load_model(shared.model_name, loader)<br>File \u201C\
          C:\\Users\\kambo-s\\text-generation-webui\\modules\\models.py\u201D, line\
          \ 78, in load_model</p>\n<p>output = load_func_map<a rel=\"nofollow\" href=\"\
          model_name\">loader</a><br>File \u201CC:\\Users\\kambo-s\\text-generation-webui\\\
          modules\\models.py\u201D, line 312, in ExLlama_HF_loader</p>\n<p>from modules.exllama_hf\
          \ import ExllamaHF<br>File \u201CC:\\Users\\kambo-s\\text-generation-webui\\\
          modules\\exllama_hf.py\u201D, line 21, in</p>\n<p>from model import ExLlama,\
          \ ExLlamaCache, ExLlamaConfig<br>ModuleNotFoundError: No module named \u2018\
          model\u2019</p>\n"
        raw: "Traceback (most recent call last):\r\n\r\nFile \u201CC:\\Users\\kambo-s\\\
          text-generation-webui\\modules\\exllama_hf.py\u201D, line 14, in\r\n\r\n\
          from exllama.model import ExLlama, ExLlamaCache, ExLlamaConfig\r\nFile \u201C\
          C:\\Users\\kambo-s\\anaconda3\\envs\\textgen\\lib\\site-packages\\exllama_init_.py\u201D\
          , line 1, in\r\n\r\nfrom . import cuda_ext, generator, model, tokenizer\r\
          \nFile \u201CC:\\Users\\kambo-s\\anaconda3\\envs\\textgen\\lib\\site-packages\\\
          exllama\\cuda_ext.py\u201D, line 9, in\r\n\r\nimport exllama_ext\r\nImportError:\
          \ DLL load failed while importing exllama_ext: The specified module could\
          \ not be found.\r\n\r\nDuring handling of the above exception, another exception\
          \ occurred:\r\n\r\nTraceback (most recent call last):\r\n\r\nFile \u201C\
          C:\\Users\\kambo-s\\text-generation-webui\\modules\\ui_model_menu.py\u201D\
          , line 201, in load_model_wrapper\r\n\r\nshared.model, shared.tokenizer\
          \ = load_model(shared.model_name, loader)\r\nFile \u201CC:\\Users\\kambo-s\\\
          text-generation-webui\\modules\\models.py\u201D, line 78, in load_model\r\
          \n\r\noutput = load_func_map[loader](model_name)\r\nFile \u201CC:\\Users\\\
          kambo-s\\text-generation-webui\\modules\\models.py\u201D, line 312, in ExLlama_HF_loader\r\
          \n\r\nfrom modules.exllama_hf import ExllamaHF\r\nFile \u201CC:\\Users\\\
          kambo-s\\text-generation-webui\\modules\\exllama_hf.py\u201D, line 21, in\r\
          \n\r\nfrom model import ExLlama, ExLlamaCache, ExLlamaConfig\r\nModuleNotFoundError:\
          \ No module named \u2018model\u2019"
        updatedAt: '2023-10-04T19:28:38.693Z'
      numEdits: 0
      reactions: []
    id: 651dbce63f54cfb8ddd6da5c
    type: comment
  author: jaspreet2744
  content: "Traceback (most recent call last):\r\n\r\nFile \u201CC:\\Users\\kambo-s\\\
    text-generation-webui\\modules\\exllama_hf.py\u201D, line 14, in\r\n\r\nfrom exllama.model\
    \ import ExLlama, ExLlamaCache, ExLlamaConfig\r\nFile \u201CC:\\Users\\kambo-s\\\
    anaconda3\\envs\\textgen\\lib\\site-packages\\exllama_init_.py\u201D, line 1,\
    \ in\r\n\r\nfrom . import cuda_ext, generator, model, tokenizer\r\nFile \u201C\
    C:\\Users\\kambo-s\\anaconda3\\envs\\textgen\\lib\\site-packages\\exllama\\cuda_ext.py\u201D\
    , line 9, in\r\n\r\nimport exllama_ext\r\nImportError: DLL load failed while importing\
    \ exllama_ext: The specified module could not be found.\r\n\r\nDuring handling\
    \ of the above exception, another exception occurred:\r\n\r\nTraceback (most recent\
    \ call last):\r\n\r\nFile \u201CC:\\Users\\kambo-s\\text-generation-webui\\modules\\\
    ui_model_menu.py\u201D, line 201, in load_model_wrapper\r\n\r\nshared.model, shared.tokenizer\
    \ = load_model(shared.model_name, loader)\r\nFile \u201CC:\\Users\\kambo-s\\text-generation-webui\\\
    modules\\models.py\u201D, line 78, in load_model\r\n\r\noutput = load_func_map[loader](model_name)\r\
    \nFile \u201CC:\\Users\\kambo-s\\text-generation-webui\\modules\\models.py\u201D\
    , line 312, in ExLlama_HF_loader\r\n\r\nfrom modules.exllama_hf import ExllamaHF\r\
    \nFile \u201CC:\\Users\\kambo-s\\text-generation-webui\\modules\\exllama_hf.py\u201D\
    , line 21, in\r\n\r\nfrom model import ExLlama, ExLlamaCache, ExLlamaConfig\r\n\
    ModuleNotFoundError: No module named \u2018model\u2019"
  created_at: 2023-10-04 18:28:38+00:00
  edited: false
  hidden: false
  id: 651dbce63f54cfb8ddd6da5c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/efe0eabd99455ada4da1ff729f632c83.svg
      fullname: "Ren\xE9 Peinl"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rpeinl
      type: user
    createdAt: '2023-12-20T09:36:17.000Z'
    data:
      edited: false
      editors:
      - rpeinl
      hidden: false
      identifiedLanguage:
        language: ja
        probability: 0.1250762641429901
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/efe0eabd99455ada4da1ff729f632c83.svg
          fullname: "Ren\xE9 Peinl"
          isHf: false
          isPro: false
          name: rpeinl
          type: user
        html: '<p>I tried this model and it gives a strange error message while loading<br>It
          seems there was a major problem during quantizing</p>

          <p>Some weights of LlamaForCausalLM were not initialized from the model
          checkpoint at TheBloke/WizardLM-13B-1.0-GPTQ and are newly initialized:
          [''model.layers.26.mlp.up_proj.g_idx'', ''model.layers.4.self_attn.k_proj.g_idx'',
          ''model.layers.26.self_attn.o_proj.g_idx'', ''model.layers.10.self_attn.v_proj.g_idx'',
          ''model.layers.9.self_attn.o_proj.g_idx'', ''model.layers.36.self_attn.v_proj.g_idx'',
          ''model.layers.4.mlp.gate_proj.g_idx'', ''model.layers.31.mlp.gate_proj.g_idx'',
          ''model.layers.16.mlp.gate_proj.g_idx'', ''model.layers.4.mlp.down_proj.g_idx'',
          ''model.layers.19.mlp.up_proj.g_idx'', ''model.layers.28.self_attn.o_proj.g_idx'',
          ''model.layers.26.self_attn.k_proj.g_idx'', ''model.layers.27.self_attn.q_proj.g_idx'',
          ''model.layers.8.mlp.up_proj.g_idx'', ''model.layers.37.mlp.up_proj.g_idx'',
          ''model.layers.23.self_attn.q_proj.g_idx'', ''model.layers.18.mlp.down_proj.g_idx'',
          ''model.layers.12.self_attn.k_proj.g_idx'', ''model.layers.27.mlp.up_proj.g_idx'',
          ''model.layers.15.self_attn.o_proj.g_idx'', ''model.layers.22.mlp.up_proj.g_idx'',
          ''model.layers.6.mlp.gate_proj.g_idx'', ''model.layers.20.self_attn.o_proj.g_idx'',
          ''model.layers.13.self_attn.q_proj.g_idx'', ''model.layers.28.mlp.up_proj.g_idx'',
          ''model.layers.1.self_attn.o_proj.g_idx'', ''model.layers.28.mlp.gate_proj.g_idx'',
          ''model.layers.7.self_attn.v_proj.g_idx'', ''model.layers.33.self_attn.k_proj.g_idx'',
          ''model.layers.39.mlp.gate_proj.g_idx'', ''model.layers.2.self_attn.o_proj.g_idx'',
          ''model.layers.1.mlp.up_proj.g_idx'', ''model.layers.6.self_attn.k_proj.g_idx'',
          ''model.layers.17.self_attn.k_proj.g_idx'', ''model.layers.27.self_attn.k_proj.g_idx'',
          ''model.layers.34.self_attn.v_proj.g_idx'', ''model.layers.21.mlp.gate_proj.g_idx'',
          ''model.layers.23.mlp.gate_proj.g_idx'', ''model.layers.37.mlp.gate_proj.g_idx'',
          ''model.layers.36.self_attn.o_proj.g_idx'', ''model.layers.0.self_attn.q_proj.g_idx'',
          ''model.layers.19.mlp.gate_proj.g_idx'', ''model.layers.8.mlp.down_proj.g_idx'',
          ''model.layers.11.mlp.up_proj.g_idx'', ''model.layers.31.self_attn.q_proj.g_idx'',
          ''model.layers.35.mlp.up_proj.g_idx'', ''model.layers.31.self_attn.o_proj.g_idx'',
          ''model.layers.33.mlp.up_proj.g_idx'', ''model.layers.8.mlp.gate_proj.g_idx'',
          ''model.layers.1.self_attn.k_proj.g_idx'', ''model.layers.34.mlp.up_proj.g_idx'',
          ''model.layers.7.self_attn.k_proj.g_idx'', ''model.layers.28.self_attn.v_proj.g_idx'',
          ''model.layers.31.self_attn.k_proj.g_idx'', ''model.layers.29.mlp.gate_proj.g_idx'',
          ''model.layers.33.mlp.down_proj.g_idx'', ''model.layers.12.self_attn.v_proj.g_idx'',
          ''model.layers.3.self_attn.k_proj.g_idx'', ''model.layers.3.self_attn.q_proj.g_idx'',
          ''model.layers.25.mlp.up_proj.g_idx'', ''model.layers.10.mlp.gate_proj.g_idx'',
          ''model.layers.12.self_attn.o_proj.g_idx'', ''model.layers.33.mlp.gate_proj.g_idx'',
          ''model.layers.5.mlp.up_proj.g_idx'', ''model.layers.27.mlp.down_proj.g_idx'',
          ''model.layers.12.mlp.down_proj.g_idx'', ''model.layers.38.self_attn.k_proj.g_idx'',
          ''model.layers.22.self_attn.k_proj.g_idx'', ''model.layers.32.mlp.gate_proj.g_idx'',
          ''model.layers.8.self_attn.v_proj.g_idx'', ''model.layers.3.mlp.gate_proj.g_idx'',
          ''model.layers.17.mlp.up_proj.g_idx'', ''model.layers.9.mlp.down_proj.g_idx'',
          ''model.layers.34.self_attn.k_proj.g_idx'', ''model.layers.20.mlp.down_proj.g_idx'',
          ''model.layers.3.self_attn.v_proj.g_idx'', ''model.layers.24.self_attn.k_proj.g_idx'',
          ''model.layers.21.mlp.up_proj.g_idx'', ''model.layers.16.mlp.down_proj.g_idx'',
          ''model.layers.11.mlp.gate_proj.g_idx'', ''model.layers.4.mlp.up_proj.g_idx'',
          ''model.layers.30.self_attn.k_proj.g_idx'', ''model.layers.38.mlp.down_proj.g_idx'',
          ''model.layers.24.mlp.gate_proj.g_idx'', ''model.layers.27.self_attn.o_proj.g_idx'',
          ''model.layers.5.mlp.gate_proj.g_idx'', ''model.layers.24.self_attn.v_proj.g_idx'',
          ''model.layers.39.self_attn.v_proj.g_idx'', ''model.layers.6.self_attn.o_proj.g_idx'',
          ''model.layers.33.self_attn.q_proj.g_idx'', ''model.layers.21.mlp.down_proj.g_idx'',
          ''model.layers.7.mlp.gate_proj.g_idx'', ''model.layers.34.self_attn.o_proj.g_idx'',
          ''model.layers.35.self_attn.k_proj.g_idx'', ''model.layers.31.mlp.up_proj.g_idx'',
          ''model.layers.26.mlp.gate_proj.g_idx'', ''model.layers.19.self_attn.q_proj.g_idx'',
          ''model.layers.39.self_attn.o_proj.g_idx'', ''model.layers.22.mlp.down_proj.g_idx'',
          ''model.layers.29.mlp.up_proj.g_idx'', ''model.layers.5.mlp.down_proj.g_idx'',
          ''model.layers.9.mlp.up_proj.g_idx'', ''model.layers.16.self_attn.k_proj.g_idx'',
          ''model.layers.13.self_attn.k_proj.g_idx'', ''model.layers.26.self_attn.v_proj.g_idx'',
          ''model.layers.24.mlp.up_proj.g_idx'', ''model.layers.30.mlp.down_proj.g_idx'',
          ''model.layers.0.mlp.gate_proj.g_idx'', ''model.layers.17.self_attn.q_proj.g_idx'',
          ''model.layers.29.self_attn.k_proj.g_idx'', ''model.layers.1.self_attn.q_proj.g_idx'',
          ''model.layers.25.self_attn.q_proj.g_idx'', ''model.layers.23.mlp.down_proj.g_idx'',
          ''model.layers.9.self_attn.q_proj.g_idx'', ''model.layers.2.self_attn.k_proj.g_idx'',
          ''model.layers.39.self_attn.k_proj.g_idx'', ''model.layers.24.mlp.down_proj.g_idx'',
          ''model.layers.14.mlp.up_proj.g_idx'', ''model.layers.28.mlp.down_proj.g_idx'',
          ''model.layers.0.mlp.up_proj.g_idx'', ''model.layers.25.mlp.down_proj.g_idx'',
          ''model.layers.38.self_attn.o_proj.g_idx'', ''model.layers.23.mlp.up_proj.g_idx'',
          ''model.layers.29.self_attn.v_proj.g_idx'', ''model.layers.25.self_attn.k_proj.g_idx'',
          ''model.layers.13.mlp.down_proj.g_idx'', ''model.layers.37.self_attn.o_proj.g_idx'',
          ''model.layers.2.mlp.gate_proj.g_idx'', ''model.layers.35.mlp.gate_proj.g_idx'',
          ''model.layers.6.mlp.down_proj.g_idx'', ''model.layers.10.mlp.up_proj.g_idx'',
          ''model.layers.15.mlp.gate_proj.g_idx'', ''model.layers.8.self_attn.o_proj.g_idx'',
          ''model.layers.30.self_attn.v_proj.g_idx'', ''model.layers.10.self_attn.k_proj.g_idx'',
          ''model.layers.2.mlp.up_proj.g_idx'', ''model.layers.18.self_attn.v_proj.g_idx'',
          ''model.layers.17.self_attn.v_proj.g_idx'', ''model.layers.15.self_attn.q_proj.g_idx'',
          ''model.layers.4.self_attn.o_proj.g_idx'', ''model.layers.25.self_attn.v_proj.g_idx'',
          ''model.layers.22.mlp.gate_proj.g_idx'', ''model.layers.16.self_attn.v_proj.g_idx'',
          ''model.layers.17.mlp.gate_proj.g_idx'', ''model.layers.34.mlp.down_proj.g_idx'',
          ''model.layers.32.mlp.up_proj.g_idx'', ''model.layers.1.mlp.gate_proj.g_idx'',
          ''model.layers.20.mlp.gate_proj.g_idx'', ''model.layers.21.self_attn.v_proj.g_idx'',
          ''model.layers.13.mlp.gate_proj.g_idx'', ''model.layers.2.self_attn.q_proj.g_idx'',
          ''model.layers.37.mlp.down_proj.g_idx'', ''model.layers.9.self_attn.v_proj.g_idx'',
          ''model.layers.19.self_attn.v_proj.g_idx'', ''model.layers.34.self_attn.q_proj.g_idx'',
          ''model.layers.34.mlp.gate_proj.g_idx'', ''model.layers.25.mlp.gate_proj.g_idx'',
          ''model.layers.32.self_attn.k_proj.g_idx'', ''model.layers.17.self_attn.o_proj.g_idx'',
          ''model.layers.22.self_attn.v_proj.g_idx'', ''model.layers.31.mlp.down_proj.g_idx'',
          ''model.layers.20.self_attn.q_proj.g_idx'', ''model.layers.0.self_attn.k_proj.g_idx'',
          ''model.layers.1.self_attn.v_proj.g_idx'', ''model.layers.15.mlp.down_proj.g_idx'',
          ''model.layers.11.mlp.down_proj.g_idx'', ''model.layers.15.self_attn.k_proj.g_idx'',
          ''model.layers.18.mlp.gate_proj.g_idx'', ''model.layers.25.self_attn.o_proj.g_idx'',
          ''model.layers.24.self_attn.q_proj.g_idx'', ''model.layers.16.self_attn.o_proj.g_idx'',
          ''model.layers.28.self_attn.q_proj.g_idx'', ''model.layers.10.self_attn.q_proj.g_idx'',
          ''model.layers.38.mlp.up_proj.g_idx'', ''model.layers.39.self_attn.q_proj.g_idx'',
          ''model.layers.5.self_attn.q_proj.g_idx'', ''model.layers.18.self_attn.k_proj.g_idx'',
          ''model.layers.17.mlp.down_proj.g_idx'', ''model.layers.1.mlp.down_proj.g_idx'',
          ''model.layers.10.mlp.down_proj.g_idx'', ''model.layers.8.self_attn.k_proj.g_idx'',
          ''model.layers.20.self_attn.v_proj.g_idx'', ''model.layers.13.mlp.up_proj.g_idx'',
          ''model.layers.11.self_attn.q_proj.g_idx'', ''model.layers.24.self_attn.o_proj.g_idx'',
          ''model.layers.4.self_attn.v_proj.g_idx'', ''model.layers.7.self_attn.q_proj.g_idx'',
          ''model.layers.19.self_attn.k_proj.g_idx'', ''model.layers.9.mlp.gate_proj.g_idx'',
          ''model.layers.33.self_attn.v_proj.g_idx'', ''model.layers.30.self_attn.q_proj.g_idx'',
          ''model.layers.14.self_attn.v_proj.g_idx'', ''model.layers.36.self_attn.q_proj.g_idx'',
          ''model.layers.26.mlp.down_proj.g_idx'', ''model.layers.7.mlp.up_proj.g_idx'',
          ''model.layers.18.self_attn.o_proj.g_idx'', ''model.layers.21.self_attn.o_proj.g_idx'',
          ''model.layers.32.self_attn.v_proj.g_idx'', ''model.layers.36.mlp.gate_proj.g_idx'',
          ''model.layers.23.self_attn.v_proj.g_idx'', ''model.layers.21.self_attn.q_proj.g_idx'',
          ''model.layers.5.self_attn.o_proj.g_idx'', ''model.layers.2.mlp.down_proj.g_idx'',
          ''model.layers.36.mlp.up_proj.g_idx'', ''model.layers.14.mlp.down_proj.g_idx'',
          ''model.layers.29.self_attn.o_proj.g_idx'', ''model.layers.38.mlp.gate_proj.g_idx'',
          ''model.layers.22.self_attn.q_proj.g_idx'', ''model.layers.13.self_attn.o_proj.g_idx'',
          ''model.layers.0.mlp.down_proj.g_idx'', ''model.layers.6.self_attn.q_proj.g_idx'',
          ''model.layers.7.self_attn.o_proj.g_idx'', ''model.layers.14.self_attn.k_proj.g_idx'',
          ''model.layers.30.self_attn.o_proj.g_idx'', ''model.layers.18.mlp.up_proj.g_idx'',
          ''model.layers.29.mlp.down_proj.g_idx'', ''model.layers.19.self_attn.o_proj.g_idx'',
          ''model.layers.27.self_attn.v_proj.g_idx'', ''model.layers.32.self_attn.q_proj.g_idx'',
          ''model.layers.15.mlp.up_proj.g_idx'', ''model.layers.27.mlp.gate_proj.g_idx'',
          ''model.layers.36.mlp.down_proj.g_idx'', ''model.layers.3.mlp.down_proj.g_idx'',
          ''model.layers.28.self_attn.k_proj.g_idx'', ''model.layers.21.self_attn.k_proj.g_idx'',
          ''model.layers.14.self_attn.o_proj.g_idx'', ''model.layers.10.self_attn.o_proj.g_idx'',
          ''model.layers.12.mlp.gate_proj.g_idx'', ''model.layers.30.mlp.gate_proj.g_idx'',
          ''model.layers.9.self_attn.k_proj.g_idx'', ''model.layers.6.self_attn.v_proj.g_idx'',
          ''model.layers.35.self_attn.q_proj.g_idx'', ''model.layers.30.mlp.up_proj.g_idx'',
          ''model.layers.3.self_attn.o_proj.g_idx'', ''model.layers.37.self_attn.k_proj.g_idx'',
          ''model.layers.6.mlp.up_proj.g_idx'', ''model.layers.18.self_attn.q_proj.g_idx'',
          ''model.layers.31.self_attn.v_proj.g_idx'', ''model.layers.4.self_attn.q_proj.g_idx'',
          ''model.layers.0.self_attn.v_proj.g_idx'', ''model.layers.35.mlp.down_proj.g_idx'',
          ''model.layers.35.self_attn.v_proj.g_idx'', ''model.layers.8.self_attn.q_proj.g_idx'',
          ''model.layers.35.self_attn.o_proj.g_idx'', ''model.layers.11.self_attn.o_proj.g_idx'',
          ''model.layers.7.mlp.down_proj.g_idx'', ''model.layers.32.mlp.down_proj.g_idx'',
          ''model.layers.20.self_attn.k_proj.g_idx'', ''model.layers.5.self_attn.k_proj.g_idx'',
          ''model.layers.39.mlp.up_proj.g_idx'', ''model.layers.37.self_attn.q_proj.g_idx'',
          ''model.layers.32.self_attn.o_proj.g_idx'', ''model.layers.39.mlp.down_proj.g_idx'',
          ''model.layers.11.self_attn.k_proj.g_idx'', ''model.layers.23.self_attn.k_proj.g_idx'',
          ''model.layers.13.self_attn.v_proj.g_idx'', ''model.layers.37.self_attn.v_proj.g_idx'',
          ''model.layers.16.mlp.up_proj.g_idx'', ''model.layers.16.self_attn.q_proj.g_idx'',
          ''model.layers.14.mlp.gate_proj.g_idx'', ''model.layers.12.mlp.up_proj.g_idx'',
          ''model.layers.15.self_attn.v_proj.g_idx'', ''model.layers.22.self_attn.o_proj.g_idx'',
          ''model.layers.38.self_attn.v_proj.g_idx'', ''model.layers.19.mlp.down_proj.g_idx'',
          ''model.layers.38.self_attn.q_proj.g_idx'', ''model.layers.14.self_attn.q_proj.g_idx'',
          ''model.layers.11.self_attn.v_proj.g_idx'', ''model.layers.5.self_attn.v_proj.g_idx'',
          ''model.layers.26.self_attn.q_proj.g_idx'', ''model.layers.3.mlp.up_proj.g_idx'',
          ''model.layers.36.self_attn.k_proj.g_idx'', ''model.layers.2.self_attn.v_proj.g_idx'',
          ''model.layers.33.self_attn.o_proj.g_idx'', ''model.layers.20.mlp.up_proj.g_idx'',
          ''model.layers.0.self_attn.o_proj.g_idx'', ''model.layers.23.self_attn.o_proj.g_idx'',
          ''model.layers.29.self_attn.q_proj.g_idx'', ''model.layers.12.self_attn.q_proj.g_idx'']<br>You
          should probably TRAIN this model on a down-stream task to be able to use
          it for predictions and inference.</p>

          '
        raw: 'I tried this model and it gives a strange error message while loading

          It seems there was a major problem during quantizing


          Some weights of LlamaForCausalLM were not initialized from the model checkpoint
          at TheBloke/WizardLM-13B-1.0-GPTQ and are newly initialized: [''model.layers.26.mlp.up_proj.g_idx'',
          ''model.layers.4.self_attn.k_proj.g_idx'', ''model.layers.26.self_attn.o_proj.g_idx'',
          ''model.layers.10.self_attn.v_proj.g_idx'', ''model.layers.9.self_attn.o_proj.g_idx'',
          ''model.layers.36.self_attn.v_proj.g_idx'', ''model.layers.4.mlp.gate_proj.g_idx'',
          ''model.layers.31.mlp.gate_proj.g_idx'', ''model.layers.16.mlp.gate_proj.g_idx'',
          ''model.layers.4.mlp.down_proj.g_idx'', ''model.layers.19.mlp.up_proj.g_idx'',
          ''model.layers.28.self_attn.o_proj.g_idx'', ''model.layers.26.self_attn.k_proj.g_idx'',
          ''model.layers.27.self_attn.q_proj.g_idx'', ''model.layers.8.mlp.up_proj.g_idx'',
          ''model.layers.37.mlp.up_proj.g_idx'', ''model.layers.23.self_attn.q_proj.g_idx'',
          ''model.layers.18.mlp.down_proj.g_idx'', ''model.layers.12.self_attn.k_proj.g_idx'',
          ''model.layers.27.mlp.up_proj.g_idx'', ''model.layers.15.self_attn.o_proj.g_idx'',
          ''model.layers.22.mlp.up_proj.g_idx'', ''model.layers.6.mlp.gate_proj.g_idx'',
          ''model.layers.20.self_attn.o_proj.g_idx'', ''model.layers.13.self_attn.q_proj.g_idx'',
          ''model.layers.28.mlp.up_proj.g_idx'', ''model.layers.1.self_attn.o_proj.g_idx'',
          ''model.layers.28.mlp.gate_proj.g_idx'', ''model.layers.7.self_attn.v_proj.g_idx'',
          ''model.layers.33.self_attn.k_proj.g_idx'', ''model.layers.39.mlp.gate_proj.g_idx'',
          ''model.layers.2.self_attn.o_proj.g_idx'', ''model.layers.1.mlp.up_proj.g_idx'',
          ''model.layers.6.self_attn.k_proj.g_idx'', ''model.layers.17.self_attn.k_proj.g_idx'',
          ''model.layers.27.self_attn.k_proj.g_idx'', ''model.layers.34.self_attn.v_proj.g_idx'',
          ''model.layers.21.mlp.gate_proj.g_idx'', ''model.layers.23.mlp.gate_proj.g_idx'',
          ''model.layers.37.mlp.gate_proj.g_idx'', ''model.layers.36.self_attn.o_proj.g_idx'',
          ''model.layers.0.self_attn.q_proj.g_idx'', ''model.layers.19.mlp.gate_proj.g_idx'',
          ''model.layers.8.mlp.down_proj.g_idx'', ''model.layers.11.mlp.up_proj.g_idx'',
          ''model.layers.31.self_attn.q_proj.g_idx'', ''model.layers.35.mlp.up_proj.g_idx'',
          ''model.layers.31.self_attn.o_proj.g_idx'', ''model.layers.33.mlp.up_proj.g_idx'',
          ''model.layers.8.mlp.gate_proj.g_idx'', ''model.layers.1.self_attn.k_proj.g_idx'',
          ''model.layers.34.mlp.up_proj.g_idx'', ''model.layers.7.self_attn.k_proj.g_idx'',
          ''model.layers.28.self_attn.v_proj.g_idx'', ''model.layers.31.self_attn.k_proj.g_idx'',
          ''model.layers.29.mlp.gate_proj.g_idx'', ''model.layers.33.mlp.down_proj.g_idx'',
          ''model.layers.12.self_attn.v_proj.g_idx'', ''model.layers.3.self_attn.k_proj.g_idx'',
          ''model.layers.3.self_attn.q_proj.g_idx'', ''model.layers.25.mlp.up_proj.g_idx'',
          ''model.layers.10.mlp.gate_proj.g_idx'', ''model.layers.12.self_attn.o_proj.g_idx'',
          ''model.layers.33.mlp.gate_proj.g_idx'', ''model.layers.5.mlp.up_proj.g_idx'',
          ''model.layers.27.mlp.down_proj.g_idx'', ''model.layers.12.mlp.down_proj.g_idx'',
          ''model.layers.38.self_attn.k_proj.g_idx'', ''model.layers.22.self_attn.k_proj.g_idx'',
          ''model.layers.32.mlp.gate_proj.g_idx'', ''model.layers.8.self_attn.v_proj.g_idx'',
          ''model.layers.3.mlp.gate_proj.g_idx'', ''model.layers.17.mlp.up_proj.g_idx'',
          ''model.layers.9.mlp.down_proj.g_idx'', ''model.layers.34.self_attn.k_proj.g_idx'',
          ''model.layers.20.mlp.down_proj.g_idx'', ''model.layers.3.self_attn.v_proj.g_idx'',
          ''model.layers.24.self_attn.k_proj.g_idx'', ''model.layers.21.mlp.up_proj.g_idx'',
          ''model.layers.16.mlp.down_proj.g_idx'', ''model.layers.11.mlp.gate_proj.g_idx'',
          ''model.layers.4.mlp.up_proj.g_idx'', ''model.layers.30.self_attn.k_proj.g_idx'',
          ''model.layers.38.mlp.down_proj.g_idx'', ''model.layers.24.mlp.gate_proj.g_idx'',
          ''model.layers.27.self_attn.o_proj.g_idx'', ''model.layers.5.mlp.gate_proj.g_idx'',
          ''model.layers.24.self_attn.v_proj.g_idx'', ''model.layers.39.self_attn.v_proj.g_idx'',
          ''model.layers.6.self_attn.o_proj.g_idx'', ''model.layers.33.self_attn.q_proj.g_idx'',
          ''model.layers.21.mlp.down_proj.g_idx'', ''model.layers.7.mlp.gate_proj.g_idx'',
          ''model.layers.34.self_attn.o_proj.g_idx'', ''model.layers.35.self_attn.k_proj.g_idx'',
          ''model.layers.31.mlp.up_proj.g_idx'', ''model.layers.26.mlp.gate_proj.g_idx'',
          ''model.layers.19.self_attn.q_proj.g_idx'', ''model.layers.39.self_attn.o_proj.g_idx'',
          ''model.layers.22.mlp.down_proj.g_idx'', ''model.layers.29.mlp.up_proj.g_idx'',
          ''model.layers.5.mlp.down_proj.g_idx'', ''model.layers.9.mlp.up_proj.g_idx'',
          ''model.layers.16.self_attn.k_proj.g_idx'', ''model.layers.13.self_attn.k_proj.g_idx'',
          ''model.layers.26.self_attn.v_proj.g_idx'', ''model.layers.24.mlp.up_proj.g_idx'',
          ''model.layers.30.mlp.down_proj.g_idx'', ''model.layers.0.mlp.gate_proj.g_idx'',
          ''model.layers.17.self_attn.q_proj.g_idx'', ''model.layers.29.self_attn.k_proj.g_idx'',
          ''model.layers.1.self_attn.q_proj.g_idx'', ''model.layers.25.self_attn.q_proj.g_idx'',
          ''model.layers.23.mlp.down_proj.g_idx'', ''model.layers.9.self_attn.q_proj.g_idx'',
          ''model.layers.2.self_attn.k_proj.g_idx'', ''model.layers.39.self_attn.k_proj.g_idx'',
          ''model.layers.24.mlp.down_proj.g_idx'', ''model.layers.14.mlp.up_proj.g_idx'',
          ''model.layers.28.mlp.down_proj.g_idx'', ''model.layers.0.mlp.up_proj.g_idx'',
          ''model.layers.25.mlp.down_proj.g_idx'', ''model.layers.38.self_attn.o_proj.g_idx'',
          ''model.layers.23.mlp.up_proj.g_idx'', ''model.layers.29.self_attn.v_proj.g_idx'',
          ''model.layers.25.self_attn.k_proj.g_idx'', ''model.layers.13.mlp.down_proj.g_idx'',
          ''model.layers.37.self_attn.o_proj.g_idx'', ''model.layers.2.mlp.gate_proj.g_idx'',
          ''model.layers.35.mlp.gate_proj.g_idx'', ''model.layers.6.mlp.down_proj.g_idx'',
          ''model.layers.10.mlp.up_proj.g_idx'', ''model.layers.15.mlp.gate_proj.g_idx'',
          ''model.layers.8.self_attn.o_proj.g_idx'', ''model.layers.30.self_attn.v_proj.g_idx'',
          ''model.layers.10.self_attn.k_proj.g_idx'', ''model.layers.2.mlp.up_proj.g_idx'',
          ''model.layers.18.self_attn.v_proj.g_idx'', ''model.layers.17.self_attn.v_proj.g_idx'',
          ''model.layers.15.self_attn.q_proj.g_idx'', ''model.layers.4.self_attn.o_proj.g_idx'',
          ''model.layers.25.self_attn.v_proj.g_idx'', ''model.layers.22.mlp.gate_proj.g_idx'',
          ''model.layers.16.self_attn.v_proj.g_idx'', ''model.layers.17.mlp.gate_proj.g_idx'',
          ''model.layers.34.mlp.down_proj.g_idx'', ''model.layers.32.mlp.up_proj.g_idx'',
          ''model.layers.1.mlp.gate_proj.g_idx'', ''model.layers.20.mlp.gate_proj.g_idx'',
          ''model.layers.21.self_attn.v_proj.g_idx'', ''model.layers.13.mlp.gate_proj.g_idx'',
          ''model.layers.2.self_attn.q_proj.g_idx'', ''model.layers.37.mlp.down_proj.g_idx'',
          ''model.layers.9.self_attn.v_proj.g_idx'', ''model.layers.19.self_attn.v_proj.g_idx'',
          ''model.layers.34.self_attn.q_proj.g_idx'', ''model.layers.34.mlp.gate_proj.g_idx'',
          ''model.layers.25.mlp.gate_proj.g_idx'', ''model.layers.32.self_attn.k_proj.g_idx'',
          ''model.layers.17.self_attn.o_proj.g_idx'', ''model.layers.22.self_attn.v_proj.g_idx'',
          ''model.layers.31.mlp.down_proj.g_idx'', ''model.layers.20.self_attn.q_proj.g_idx'',
          ''model.layers.0.self_attn.k_proj.g_idx'', ''model.layers.1.self_attn.v_proj.g_idx'',
          ''model.layers.15.mlp.down_proj.g_idx'', ''model.layers.11.mlp.down_proj.g_idx'',
          ''model.layers.15.self_attn.k_proj.g_idx'', ''model.layers.18.mlp.gate_proj.g_idx'',
          ''model.layers.25.self_attn.o_proj.g_idx'', ''model.layers.24.self_attn.q_proj.g_idx'',
          ''model.layers.16.self_attn.o_proj.g_idx'', ''model.layers.28.self_attn.q_proj.g_idx'',
          ''model.layers.10.self_attn.q_proj.g_idx'', ''model.layers.38.mlp.up_proj.g_idx'',
          ''model.layers.39.self_attn.q_proj.g_idx'', ''model.layers.5.self_attn.q_proj.g_idx'',
          ''model.layers.18.self_attn.k_proj.g_idx'', ''model.layers.17.mlp.down_proj.g_idx'',
          ''model.layers.1.mlp.down_proj.g_idx'', ''model.layers.10.mlp.down_proj.g_idx'',
          ''model.layers.8.self_attn.k_proj.g_idx'', ''model.layers.20.self_attn.v_proj.g_idx'',
          ''model.layers.13.mlp.up_proj.g_idx'', ''model.layers.11.self_attn.q_proj.g_idx'',
          ''model.layers.24.self_attn.o_proj.g_idx'', ''model.layers.4.self_attn.v_proj.g_idx'',
          ''model.layers.7.self_attn.q_proj.g_idx'', ''model.layers.19.self_attn.k_proj.g_idx'',
          ''model.layers.9.mlp.gate_proj.g_idx'', ''model.layers.33.self_attn.v_proj.g_idx'',
          ''model.layers.30.self_attn.q_proj.g_idx'', ''model.layers.14.self_attn.v_proj.g_idx'',
          ''model.layers.36.self_attn.q_proj.g_idx'', ''model.layers.26.mlp.down_proj.g_idx'',
          ''model.layers.7.mlp.up_proj.g_idx'', ''model.layers.18.self_attn.o_proj.g_idx'',
          ''model.layers.21.self_attn.o_proj.g_idx'', ''model.layers.32.self_attn.v_proj.g_idx'',
          ''model.layers.36.mlp.gate_proj.g_idx'', ''model.layers.23.self_attn.v_proj.g_idx'',
          ''model.layers.21.self_attn.q_proj.g_idx'', ''model.layers.5.self_attn.o_proj.g_idx'',
          ''model.layers.2.mlp.down_proj.g_idx'', ''model.layers.36.mlp.up_proj.g_idx'',
          ''model.layers.14.mlp.down_proj.g_idx'', ''model.layers.29.self_attn.o_proj.g_idx'',
          ''model.layers.38.mlp.gate_proj.g_idx'', ''model.layers.22.self_attn.q_proj.g_idx'',
          ''model.layers.13.self_attn.o_proj.g_idx'', ''model.layers.0.mlp.down_proj.g_idx'',
          ''model.layers.6.self_attn.q_proj.g_idx'', ''model.layers.7.self_attn.o_proj.g_idx'',
          ''model.layers.14.self_attn.k_proj.g_idx'', ''model.layers.30.self_attn.o_proj.g_idx'',
          ''model.layers.18.mlp.up_proj.g_idx'', ''model.layers.29.mlp.down_proj.g_idx'',
          ''model.layers.19.self_attn.o_proj.g_idx'', ''model.layers.27.self_attn.v_proj.g_idx'',
          ''model.layers.32.self_attn.q_proj.g_idx'', ''model.layers.15.mlp.up_proj.g_idx'',
          ''model.layers.27.mlp.gate_proj.g_idx'', ''model.layers.36.mlp.down_proj.g_idx'',
          ''model.layers.3.mlp.down_proj.g_idx'', ''model.layers.28.self_attn.k_proj.g_idx'',
          ''model.layers.21.self_attn.k_proj.g_idx'', ''model.layers.14.self_attn.o_proj.g_idx'',
          ''model.layers.10.self_attn.o_proj.g_idx'', ''model.layers.12.mlp.gate_proj.g_idx'',
          ''model.layers.30.mlp.gate_proj.g_idx'', ''model.layers.9.self_attn.k_proj.g_idx'',
          ''model.layers.6.self_attn.v_proj.g_idx'', ''model.layers.35.self_attn.q_proj.g_idx'',
          ''model.layers.30.mlp.up_proj.g_idx'', ''model.layers.3.self_attn.o_proj.g_idx'',
          ''model.layers.37.self_attn.k_proj.g_idx'', ''model.layers.6.mlp.up_proj.g_idx'',
          ''model.layers.18.self_attn.q_proj.g_idx'', ''model.layers.31.self_attn.v_proj.g_idx'',
          ''model.layers.4.self_attn.q_proj.g_idx'', ''model.layers.0.self_attn.v_proj.g_idx'',
          ''model.layers.35.mlp.down_proj.g_idx'', ''model.layers.35.self_attn.v_proj.g_idx'',
          ''model.layers.8.self_attn.q_proj.g_idx'', ''model.layers.35.self_attn.o_proj.g_idx'',
          ''model.layers.11.self_attn.o_proj.g_idx'', ''model.layers.7.mlp.down_proj.g_idx'',
          ''model.layers.32.mlp.down_proj.g_idx'', ''model.layers.20.self_attn.k_proj.g_idx'',
          ''model.layers.5.self_attn.k_proj.g_idx'', ''model.layers.39.mlp.up_proj.g_idx'',
          ''model.layers.37.self_attn.q_proj.g_idx'', ''model.layers.32.self_attn.o_proj.g_idx'',
          ''model.layers.39.mlp.down_proj.g_idx'', ''model.layers.11.self_attn.k_proj.g_idx'',
          ''model.layers.23.self_attn.k_proj.g_idx'', ''model.layers.13.self_attn.v_proj.g_idx'',
          ''model.layers.37.self_attn.v_proj.g_idx'', ''model.layers.16.mlp.up_proj.g_idx'',
          ''model.layers.16.self_attn.q_proj.g_idx'', ''model.layers.14.mlp.gate_proj.g_idx'',
          ''model.layers.12.mlp.up_proj.g_idx'', ''model.layers.15.self_attn.v_proj.g_idx'',
          ''model.layers.22.self_attn.o_proj.g_idx'', ''model.layers.38.self_attn.v_proj.g_idx'',
          ''model.layers.19.mlp.down_proj.g_idx'', ''model.layers.38.self_attn.q_proj.g_idx'',
          ''model.layers.14.self_attn.q_proj.g_idx'', ''model.layers.11.self_attn.v_proj.g_idx'',
          ''model.layers.5.self_attn.v_proj.g_idx'', ''model.layers.26.self_attn.q_proj.g_idx'',
          ''model.layers.3.mlp.up_proj.g_idx'', ''model.layers.36.self_attn.k_proj.g_idx'',
          ''model.layers.2.self_attn.v_proj.g_idx'', ''model.layers.33.self_attn.o_proj.g_idx'',
          ''model.layers.20.mlp.up_proj.g_idx'', ''model.layers.0.self_attn.o_proj.g_idx'',
          ''model.layers.23.self_attn.o_proj.g_idx'', ''model.layers.29.self_attn.q_proj.g_idx'',
          ''model.layers.12.self_attn.q_proj.g_idx'']

          You should probably TRAIN this model on a down-stream task to be able to
          use it for predictions and inference.'
        updatedAt: '2023-12-20T09:36:17.941Z'
      numEdits: 0
      reactions: []
    id: 6582b5912db4c45ef303a498
    type: comment
  author: rpeinl
  content: 'I tried this model and it gives a strange error message while loading

    It seems there was a major problem during quantizing


    Some weights of LlamaForCausalLM were not initialized from the model checkpoint
    at TheBloke/WizardLM-13B-1.0-GPTQ and are newly initialized: [''model.layers.26.mlp.up_proj.g_idx'',
    ''model.layers.4.self_attn.k_proj.g_idx'', ''model.layers.26.self_attn.o_proj.g_idx'',
    ''model.layers.10.self_attn.v_proj.g_idx'', ''model.layers.9.self_attn.o_proj.g_idx'',
    ''model.layers.36.self_attn.v_proj.g_idx'', ''model.layers.4.mlp.gate_proj.g_idx'',
    ''model.layers.31.mlp.gate_proj.g_idx'', ''model.layers.16.mlp.gate_proj.g_idx'',
    ''model.layers.4.mlp.down_proj.g_idx'', ''model.layers.19.mlp.up_proj.g_idx'',
    ''model.layers.28.self_attn.o_proj.g_idx'', ''model.layers.26.self_attn.k_proj.g_idx'',
    ''model.layers.27.self_attn.q_proj.g_idx'', ''model.layers.8.mlp.up_proj.g_idx'',
    ''model.layers.37.mlp.up_proj.g_idx'', ''model.layers.23.self_attn.q_proj.g_idx'',
    ''model.layers.18.mlp.down_proj.g_idx'', ''model.layers.12.self_attn.k_proj.g_idx'',
    ''model.layers.27.mlp.up_proj.g_idx'', ''model.layers.15.self_attn.o_proj.g_idx'',
    ''model.layers.22.mlp.up_proj.g_idx'', ''model.layers.6.mlp.gate_proj.g_idx'',
    ''model.layers.20.self_attn.o_proj.g_idx'', ''model.layers.13.self_attn.q_proj.g_idx'',
    ''model.layers.28.mlp.up_proj.g_idx'', ''model.layers.1.self_attn.o_proj.g_idx'',
    ''model.layers.28.mlp.gate_proj.g_idx'', ''model.layers.7.self_attn.v_proj.g_idx'',
    ''model.layers.33.self_attn.k_proj.g_idx'', ''model.layers.39.mlp.gate_proj.g_idx'',
    ''model.layers.2.self_attn.o_proj.g_idx'', ''model.layers.1.mlp.up_proj.g_idx'',
    ''model.layers.6.self_attn.k_proj.g_idx'', ''model.layers.17.self_attn.k_proj.g_idx'',
    ''model.layers.27.self_attn.k_proj.g_idx'', ''model.layers.34.self_attn.v_proj.g_idx'',
    ''model.layers.21.mlp.gate_proj.g_idx'', ''model.layers.23.mlp.gate_proj.g_idx'',
    ''model.layers.37.mlp.gate_proj.g_idx'', ''model.layers.36.self_attn.o_proj.g_idx'',
    ''model.layers.0.self_attn.q_proj.g_idx'', ''model.layers.19.mlp.gate_proj.g_idx'',
    ''model.layers.8.mlp.down_proj.g_idx'', ''model.layers.11.mlp.up_proj.g_idx'',
    ''model.layers.31.self_attn.q_proj.g_idx'', ''model.layers.35.mlp.up_proj.g_idx'',
    ''model.layers.31.self_attn.o_proj.g_idx'', ''model.layers.33.mlp.up_proj.g_idx'',
    ''model.layers.8.mlp.gate_proj.g_idx'', ''model.layers.1.self_attn.k_proj.g_idx'',
    ''model.layers.34.mlp.up_proj.g_idx'', ''model.layers.7.self_attn.k_proj.g_idx'',
    ''model.layers.28.self_attn.v_proj.g_idx'', ''model.layers.31.self_attn.k_proj.g_idx'',
    ''model.layers.29.mlp.gate_proj.g_idx'', ''model.layers.33.mlp.down_proj.g_idx'',
    ''model.layers.12.self_attn.v_proj.g_idx'', ''model.layers.3.self_attn.k_proj.g_idx'',
    ''model.layers.3.self_attn.q_proj.g_idx'', ''model.layers.25.mlp.up_proj.g_idx'',
    ''model.layers.10.mlp.gate_proj.g_idx'', ''model.layers.12.self_attn.o_proj.g_idx'',
    ''model.layers.33.mlp.gate_proj.g_idx'', ''model.layers.5.mlp.up_proj.g_idx'',
    ''model.layers.27.mlp.down_proj.g_idx'', ''model.layers.12.mlp.down_proj.g_idx'',
    ''model.layers.38.self_attn.k_proj.g_idx'', ''model.layers.22.self_attn.k_proj.g_idx'',
    ''model.layers.32.mlp.gate_proj.g_idx'', ''model.layers.8.self_attn.v_proj.g_idx'',
    ''model.layers.3.mlp.gate_proj.g_idx'', ''model.layers.17.mlp.up_proj.g_idx'',
    ''model.layers.9.mlp.down_proj.g_idx'', ''model.layers.34.self_attn.k_proj.g_idx'',
    ''model.layers.20.mlp.down_proj.g_idx'', ''model.layers.3.self_attn.v_proj.g_idx'',
    ''model.layers.24.self_attn.k_proj.g_idx'', ''model.layers.21.mlp.up_proj.g_idx'',
    ''model.layers.16.mlp.down_proj.g_idx'', ''model.layers.11.mlp.gate_proj.g_idx'',
    ''model.layers.4.mlp.up_proj.g_idx'', ''model.layers.30.self_attn.k_proj.g_idx'',
    ''model.layers.38.mlp.down_proj.g_idx'', ''model.layers.24.mlp.gate_proj.g_idx'',
    ''model.layers.27.self_attn.o_proj.g_idx'', ''model.layers.5.mlp.gate_proj.g_idx'',
    ''model.layers.24.self_attn.v_proj.g_idx'', ''model.layers.39.self_attn.v_proj.g_idx'',
    ''model.layers.6.self_attn.o_proj.g_idx'', ''model.layers.33.self_attn.q_proj.g_idx'',
    ''model.layers.21.mlp.down_proj.g_idx'', ''model.layers.7.mlp.gate_proj.g_idx'',
    ''model.layers.34.self_attn.o_proj.g_idx'', ''model.layers.35.self_attn.k_proj.g_idx'',
    ''model.layers.31.mlp.up_proj.g_idx'', ''model.layers.26.mlp.gate_proj.g_idx'',
    ''model.layers.19.self_attn.q_proj.g_idx'', ''model.layers.39.self_attn.o_proj.g_idx'',
    ''model.layers.22.mlp.down_proj.g_idx'', ''model.layers.29.mlp.up_proj.g_idx'',
    ''model.layers.5.mlp.down_proj.g_idx'', ''model.layers.9.mlp.up_proj.g_idx'',
    ''model.layers.16.self_attn.k_proj.g_idx'', ''model.layers.13.self_attn.k_proj.g_idx'',
    ''model.layers.26.self_attn.v_proj.g_idx'', ''model.layers.24.mlp.up_proj.g_idx'',
    ''model.layers.30.mlp.down_proj.g_idx'', ''model.layers.0.mlp.gate_proj.g_idx'',
    ''model.layers.17.self_attn.q_proj.g_idx'', ''model.layers.29.self_attn.k_proj.g_idx'',
    ''model.layers.1.self_attn.q_proj.g_idx'', ''model.layers.25.self_attn.q_proj.g_idx'',
    ''model.layers.23.mlp.down_proj.g_idx'', ''model.layers.9.self_attn.q_proj.g_idx'',
    ''model.layers.2.self_attn.k_proj.g_idx'', ''model.layers.39.self_attn.k_proj.g_idx'',
    ''model.layers.24.mlp.down_proj.g_idx'', ''model.layers.14.mlp.up_proj.g_idx'',
    ''model.layers.28.mlp.down_proj.g_idx'', ''model.layers.0.mlp.up_proj.g_idx'',
    ''model.layers.25.mlp.down_proj.g_idx'', ''model.layers.38.self_attn.o_proj.g_idx'',
    ''model.layers.23.mlp.up_proj.g_idx'', ''model.layers.29.self_attn.v_proj.g_idx'',
    ''model.layers.25.self_attn.k_proj.g_idx'', ''model.layers.13.mlp.down_proj.g_idx'',
    ''model.layers.37.self_attn.o_proj.g_idx'', ''model.layers.2.mlp.gate_proj.g_idx'',
    ''model.layers.35.mlp.gate_proj.g_idx'', ''model.layers.6.mlp.down_proj.g_idx'',
    ''model.layers.10.mlp.up_proj.g_idx'', ''model.layers.15.mlp.gate_proj.g_idx'',
    ''model.layers.8.self_attn.o_proj.g_idx'', ''model.layers.30.self_attn.v_proj.g_idx'',
    ''model.layers.10.self_attn.k_proj.g_idx'', ''model.layers.2.mlp.up_proj.g_idx'',
    ''model.layers.18.self_attn.v_proj.g_idx'', ''model.layers.17.self_attn.v_proj.g_idx'',
    ''model.layers.15.self_attn.q_proj.g_idx'', ''model.layers.4.self_attn.o_proj.g_idx'',
    ''model.layers.25.self_attn.v_proj.g_idx'', ''model.layers.22.mlp.gate_proj.g_idx'',
    ''model.layers.16.self_attn.v_proj.g_idx'', ''model.layers.17.mlp.gate_proj.g_idx'',
    ''model.layers.34.mlp.down_proj.g_idx'', ''model.layers.32.mlp.up_proj.g_idx'',
    ''model.layers.1.mlp.gate_proj.g_idx'', ''model.layers.20.mlp.gate_proj.g_idx'',
    ''model.layers.21.self_attn.v_proj.g_idx'', ''model.layers.13.mlp.gate_proj.g_idx'',
    ''model.layers.2.self_attn.q_proj.g_idx'', ''model.layers.37.mlp.down_proj.g_idx'',
    ''model.layers.9.self_attn.v_proj.g_idx'', ''model.layers.19.self_attn.v_proj.g_idx'',
    ''model.layers.34.self_attn.q_proj.g_idx'', ''model.layers.34.mlp.gate_proj.g_idx'',
    ''model.layers.25.mlp.gate_proj.g_idx'', ''model.layers.32.self_attn.k_proj.g_idx'',
    ''model.layers.17.self_attn.o_proj.g_idx'', ''model.layers.22.self_attn.v_proj.g_idx'',
    ''model.layers.31.mlp.down_proj.g_idx'', ''model.layers.20.self_attn.q_proj.g_idx'',
    ''model.layers.0.self_attn.k_proj.g_idx'', ''model.layers.1.self_attn.v_proj.g_idx'',
    ''model.layers.15.mlp.down_proj.g_idx'', ''model.layers.11.mlp.down_proj.g_idx'',
    ''model.layers.15.self_attn.k_proj.g_idx'', ''model.layers.18.mlp.gate_proj.g_idx'',
    ''model.layers.25.self_attn.o_proj.g_idx'', ''model.layers.24.self_attn.q_proj.g_idx'',
    ''model.layers.16.self_attn.o_proj.g_idx'', ''model.layers.28.self_attn.q_proj.g_idx'',
    ''model.layers.10.self_attn.q_proj.g_idx'', ''model.layers.38.mlp.up_proj.g_idx'',
    ''model.layers.39.self_attn.q_proj.g_idx'', ''model.layers.5.self_attn.q_proj.g_idx'',
    ''model.layers.18.self_attn.k_proj.g_idx'', ''model.layers.17.mlp.down_proj.g_idx'',
    ''model.layers.1.mlp.down_proj.g_idx'', ''model.layers.10.mlp.down_proj.g_idx'',
    ''model.layers.8.self_attn.k_proj.g_idx'', ''model.layers.20.self_attn.v_proj.g_idx'',
    ''model.layers.13.mlp.up_proj.g_idx'', ''model.layers.11.self_attn.q_proj.g_idx'',
    ''model.layers.24.self_attn.o_proj.g_idx'', ''model.layers.4.self_attn.v_proj.g_idx'',
    ''model.layers.7.self_attn.q_proj.g_idx'', ''model.layers.19.self_attn.k_proj.g_idx'',
    ''model.layers.9.mlp.gate_proj.g_idx'', ''model.layers.33.self_attn.v_proj.g_idx'',
    ''model.layers.30.self_attn.q_proj.g_idx'', ''model.layers.14.self_attn.v_proj.g_idx'',
    ''model.layers.36.self_attn.q_proj.g_idx'', ''model.layers.26.mlp.down_proj.g_idx'',
    ''model.layers.7.mlp.up_proj.g_idx'', ''model.layers.18.self_attn.o_proj.g_idx'',
    ''model.layers.21.self_attn.o_proj.g_idx'', ''model.layers.32.self_attn.v_proj.g_idx'',
    ''model.layers.36.mlp.gate_proj.g_idx'', ''model.layers.23.self_attn.v_proj.g_idx'',
    ''model.layers.21.self_attn.q_proj.g_idx'', ''model.layers.5.self_attn.o_proj.g_idx'',
    ''model.layers.2.mlp.down_proj.g_idx'', ''model.layers.36.mlp.up_proj.g_idx'',
    ''model.layers.14.mlp.down_proj.g_idx'', ''model.layers.29.self_attn.o_proj.g_idx'',
    ''model.layers.38.mlp.gate_proj.g_idx'', ''model.layers.22.self_attn.q_proj.g_idx'',
    ''model.layers.13.self_attn.o_proj.g_idx'', ''model.layers.0.mlp.down_proj.g_idx'',
    ''model.layers.6.self_attn.q_proj.g_idx'', ''model.layers.7.self_attn.o_proj.g_idx'',
    ''model.layers.14.self_attn.k_proj.g_idx'', ''model.layers.30.self_attn.o_proj.g_idx'',
    ''model.layers.18.mlp.up_proj.g_idx'', ''model.layers.29.mlp.down_proj.g_idx'',
    ''model.layers.19.self_attn.o_proj.g_idx'', ''model.layers.27.self_attn.v_proj.g_idx'',
    ''model.layers.32.self_attn.q_proj.g_idx'', ''model.layers.15.mlp.up_proj.g_idx'',
    ''model.layers.27.mlp.gate_proj.g_idx'', ''model.layers.36.mlp.down_proj.g_idx'',
    ''model.layers.3.mlp.down_proj.g_idx'', ''model.layers.28.self_attn.k_proj.g_idx'',
    ''model.layers.21.self_attn.k_proj.g_idx'', ''model.layers.14.self_attn.o_proj.g_idx'',
    ''model.layers.10.self_attn.o_proj.g_idx'', ''model.layers.12.mlp.gate_proj.g_idx'',
    ''model.layers.30.mlp.gate_proj.g_idx'', ''model.layers.9.self_attn.k_proj.g_idx'',
    ''model.layers.6.self_attn.v_proj.g_idx'', ''model.layers.35.self_attn.q_proj.g_idx'',
    ''model.layers.30.mlp.up_proj.g_idx'', ''model.layers.3.self_attn.o_proj.g_idx'',
    ''model.layers.37.self_attn.k_proj.g_idx'', ''model.layers.6.mlp.up_proj.g_idx'',
    ''model.layers.18.self_attn.q_proj.g_idx'', ''model.layers.31.self_attn.v_proj.g_idx'',
    ''model.layers.4.self_attn.q_proj.g_idx'', ''model.layers.0.self_attn.v_proj.g_idx'',
    ''model.layers.35.mlp.down_proj.g_idx'', ''model.layers.35.self_attn.v_proj.g_idx'',
    ''model.layers.8.self_attn.q_proj.g_idx'', ''model.layers.35.self_attn.o_proj.g_idx'',
    ''model.layers.11.self_attn.o_proj.g_idx'', ''model.layers.7.mlp.down_proj.g_idx'',
    ''model.layers.32.mlp.down_proj.g_idx'', ''model.layers.20.self_attn.k_proj.g_idx'',
    ''model.layers.5.self_attn.k_proj.g_idx'', ''model.layers.39.mlp.up_proj.g_idx'',
    ''model.layers.37.self_attn.q_proj.g_idx'', ''model.layers.32.self_attn.o_proj.g_idx'',
    ''model.layers.39.mlp.down_proj.g_idx'', ''model.layers.11.self_attn.k_proj.g_idx'',
    ''model.layers.23.self_attn.k_proj.g_idx'', ''model.layers.13.self_attn.v_proj.g_idx'',
    ''model.layers.37.self_attn.v_proj.g_idx'', ''model.layers.16.mlp.up_proj.g_idx'',
    ''model.layers.16.self_attn.q_proj.g_idx'', ''model.layers.14.mlp.gate_proj.g_idx'',
    ''model.layers.12.mlp.up_proj.g_idx'', ''model.layers.15.self_attn.v_proj.g_idx'',
    ''model.layers.22.self_attn.o_proj.g_idx'', ''model.layers.38.self_attn.v_proj.g_idx'',
    ''model.layers.19.mlp.down_proj.g_idx'', ''model.layers.38.self_attn.q_proj.g_idx'',
    ''model.layers.14.self_attn.q_proj.g_idx'', ''model.layers.11.self_attn.v_proj.g_idx'',
    ''model.layers.5.self_attn.v_proj.g_idx'', ''model.layers.26.self_attn.q_proj.g_idx'',
    ''model.layers.3.mlp.up_proj.g_idx'', ''model.layers.36.self_attn.k_proj.g_idx'',
    ''model.layers.2.self_attn.v_proj.g_idx'', ''model.layers.33.self_attn.o_proj.g_idx'',
    ''model.layers.20.mlp.up_proj.g_idx'', ''model.layers.0.self_attn.o_proj.g_idx'',
    ''model.layers.23.self_attn.o_proj.g_idx'', ''model.layers.29.self_attn.q_proj.g_idx'',
    ''model.layers.12.self_attn.q_proj.g_idx'']

    You should probably TRAIN this model on a down-stream task to be able to use it
    for predictions and inference.'
  created_at: 2023-12-20 09:36:17+00:00
  edited: false
  hidden: false
  id: 6582b5912db4c45ef303a498
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/WizardLM-13B-1.0-GPTQ
repo_type: model
status: open
target_branch: null
title: 'Traceback (most recent call last): error'
