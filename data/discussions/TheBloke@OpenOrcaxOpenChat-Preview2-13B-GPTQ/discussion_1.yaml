!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ssmi153
conflicting_files: null
created_at: 2023-08-04 03:04:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c64757e9d577bf3e4de111e43c10d6e3.svg
      fullname: Shane Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: ssmi153
      type: user
    createdAt: '2023-08-04T04:04:35.000Z'
    data:
      edited: true
      editors:
      - ssmi153
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9231387376785278
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c64757e9d577bf3e4de111e43c10d6e3.svg
          fullname: Shane Smith
          isHf: false
          isPro: true
          name: ssmi153
          type: user
        html: '<p>I''m finding that these quantized models don''t know how to stop.
          Comparing your special_tokens_map.json to the original repo, you have a
          different "eos_token" value. I think this should be "&lt;|end_of_turn|&gt;"
          rather than "&lt;/s&gt;".</p>

          '
        raw: I'm finding that these quantized models don't know how to stop. Comparing
          your special_tokens_map.json to the original repo, you have a different
          "eos_token" value. I think this should be "<|end_of_turn|>" rather than
          "\</s>".
        updatedAt: '2023-08-04T04:13:09.209Z'
      numEdits: 1
      reactions: []
    id: 64cc78d3eed22517ae1157ad
    type: comment
  author: ssmi153
  content: I'm finding that these quantized models don't know how to stop. Comparing
    your special_tokens_map.json to the original repo, you have a different "eos_token"
    value. I think this should be "<|end_of_turn|>" rather than "\</s>".
  created_at: 2023-08-04 03:04:35+00:00
  edited: true
  hidden: false
  id: 64cc78d3eed22517ae1157ad
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-08-04T07:28:40.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9853441715240479
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Ah yeah, they must have edited their JSON after I did my quantisations.  I
          have edited my JSON to match theirs, so do a re-download of those files
          and hopefully that will sort it out.</p>

          '
        raw: Ah yeah, they must have edited their JSON after I did my quantisations.  I
          have edited my JSON to match theirs, so do a re-download of those files
          and hopefully that will sort it out.
        updatedAt: '2023-08-04T07:28:40.977Z'
      numEdits: 0
      reactions: []
    id: 64cca8a84dcdaead7a309ce8
    type: comment
  author: TheBloke
  content: Ah yeah, they must have edited their JSON after I did my quantisations.  I
    have edited my JSON to match theirs, so do a re-download of those files and hopefully
    that will sort it out.
  created_at: 2023-08-04 06:28:40+00:00
  edited: false
  hidden: false
  id: 64cca8a84dcdaead7a309ce8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a3c458d4c0ffbf4e1e01f1911707889f.svg
      fullname: Vincent Grey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: countzero238
      type: user
    createdAt: '2023-08-05T09:18:10.000Z'
    data:
      edited: false
      editors:
      - countzero238
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7995628118515015
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a3c458d4c0ffbf4e1e01f1911707889f.svg
          fullname: Vincent Grey
          isHf: false
          isPro: false
          name: countzero238
          type: user
        html: '<p>Could it be that TheBloke/vicuna-13B-v1.5-16K-GPTQ suffers from
          the same problem?</p>

          '
        raw: Could it be that TheBloke/vicuna-13B-v1.5-16K-GPTQ suffers from the same
          problem?
        updatedAt: '2023-08-05T09:18:10.348Z'
      numEdits: 0
      reactions: []
    id: 64ce13d22f1f9578a0ec5c24
    type: comment
  author: countzero238
  content: Could it be that TheBloke/vicuna-13B-v1.5-16K-GPTQ suffers from the same
    problem?
  created_at: 2023-08-05 08:18:10+00:00
  edited: false
  hidden: false
  id: 64ce13d22f1f9578a0ec5c24
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-08-05T09:20:05.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9407112002372742
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<blockquote>

          <p>Could it be that TheBloke/vicuna-13B-v1.5-16K-GPTQ suffers from the same
          problem?</p>

          </blockquote>

          <p>Don''t think so - Vicuna has always used <code>&lt;/s&gt;</code> and
          this hasn''t changed</p>

          '
        raw: '> Could it be that TheBloke/vicuna-13B-v1.5-16K-GPTQ suffers from the
          same problem?


          Don''t think so - Vicuna has always used `</s>` and this hasn''t changed'
        updatedAt: '2023-08-05T09:20:05.969Z'
      numEdits: 0
      reactions: []
    id: 64ce1445995a0b5d592e7e42
    type: comment
  author: TheBloke
  content: '> Could it be that TheBloke/vicuna-13B-v1.5-16K-GPTQ suffers from the
    same problem?


    Don''t think so - Vicuna has always used `</s>` and this hasn''t changed'
  created_at: 2023-08-05 08:20:05+00:00
  edited: false
  hidden: false
  id: 64ce1445995a0b5d592e7e42
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a3c458d4c0ffbf4e1e01f1911707889f.svg
      fullname: Vincent Grey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: countzero238
      type: user
    createdAt: '2023-08-05T18:25:50.000Z'
    data:
      edited: false
      editors:
      - countzero238
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9345835447311401
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a3c458d4c0ffbf4e1e01f1911707889f.svg
          fullname: Vincent Grey
          isHf: false
          isPro: false
          name: countzero238
          type: user
        html: '<p>Thanks for the answer! Your newer GPTQ-models don''t know when to
          stop in 1 of five cases on my end. The original vicuna-13B-v1.5-16K seems
          to be fine though..</p>

          '
        raw: Thanks for the answer! Your newer GPTQ-models don't know when to stop
          in 1 of five cases on my end. The original vicuna-13B-v1.5-16K seems to
          be fine though..
        updatedAt: '2023-08-05T18:25:50.992Z'
      numEdits: 0
      reactions: []
    id: 64ce942e73dc458c16f84753
    type: comment
  author: countzero238
  content: Thanks for the answer! Your newer GPTQ-models don't know when to stop in
    1 of five cases on my end. The original vicuna-13B-v1.5-16K seems to be fine though..
  created_at: 2023-08-05 17:25:50+00:00
  edited: false
  hidden: false
  id: 64ce942e73dc458c16f84753
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/OpenOrcaxOpenChat-Preview2-13B-GPTQ
repo_type: model
status: open
target_branch: null
title: EOS Token
