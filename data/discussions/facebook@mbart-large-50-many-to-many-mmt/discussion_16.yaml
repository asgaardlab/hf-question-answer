!!python/object:huggingface_hub.community.DiscussionWithDetails
author: testerman2023
conflicting_files: null
created_at: 2023-12-10 20:39:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a72b21f3a4fc6e78b85c65da5965319.svg
      fullname: T A
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: testerman2023
      type: user
    createdAt: '2023-12-10T20:39:19.000Z'
    data:
      edited: false
      editors:
      - testerman2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9358113408088684
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a72b21f3a4fc6e78b85c65da5965319.svg
          fullname: T A
          isHf: false
          isPro: false
          name: testerman2023
          type: user
        html: '<p>I am rather new to this, so I have no idea if it is possible or
          how it would be done, is there any way to take the .h5 mode featured here
          and convert it to gguf for use with something like llama.cpp?</p>

          '
        raw: I am rather new to this, so I have no idea if it is possible or how it
          would be done, is there any way to take the .h5 mode featured here and convert
          it to gguf for use with something like llama.cpp?
        updatedAt: '2023-12-10T20:39:19.095Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mabarton
    id: 657621f7ec3bf96e437b2219
    type: comment
  author: testerman2023
  content: I am rather new to this, so I have no idea if it is possible or how it
    would be done, is there any way to take the .h5 mode featured here and convert
    it to gguf for use with something like llama.cpp?
  created_at: 2023-12-10 20:39:19+00:00
  edited: false
  hidden: false
  id: 657621f7ec3bf96e437b2219
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: facebook/mbart-large-50-many-to-many-mmt
repo_type: model
status: open
target_branch: null
title: converting an .h5 file to a gguf file
