!!python/object:huggingface_hub.community.DiscussionWithDetails
author: starinskycc
conflicting_files: null
created_at: 2024-01-07 23:37:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/223d0928597a45ae80321c330045b867.svg
      fullname: demos
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: starinskycc
      type: user
    createdAt: '2024-01-07T23:37:59.000Z'
    data:
      edited: false
      editors:
      - starinskycc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9776552319526672
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/223d0928597a45ae80321c330045b867.svg
          fullname: demos
          isHf: false
          isPro: false
          name: starinskycc
          type: user
        html: '<p>I tested your ctrl model before, and found it quite interesting,
          but there seems to be a little problem in the effect.I want to try to train
          a model of inpaint control by myself. You can teach me how to train.<br>Can
          you give me some manuals or tell me how to do it?</p>

          '
        raw: "I tested your ctrl model before, and found it quite interesting, but\
          \ there seems to be a little problem in the effect.I want to try to train\
          \ a model of inpaint control by myself. You can teach me how to train.\r\
          \nCan you give me some manuals or tell me how to do it?"
        updatedAt: '2024-01-07T23:37:59.766Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - chengzhiyuan
    id: 659b35d7eff07dcf1fdcfd1c
    type: comment
  author: starinskycc
  content: "I tested your ctrl model before, and found it quite interesting, but there\
    \ seems to be a little problem in the effect.I want to try to train a model of\
    \ inpaint control by myself. You can teach me how to train.\r\nCan you give me\
    \ some manuals or tell me how to do it?"
  created_at: 2024-01-07 23:37:59+00:00
  edited: false
  hidden: false
  id: 659b35d7eff07dcf1fdcfd1c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1119ffa9c294b5ee435bdbd5556d2e95.svg
      fullname: chengzhiyuan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chengzhiyuan
      type: user
    createdAt: '2024-01-25T05:02:14.000Z'
    data:
      edited: false
      editors:
      - chengzhiyuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5355128049850464
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1119ffa9c294b5ee435bdbd5556d2e95.svg
          fullname: chengzhiyuan
          isHf: false
          isPro: false
          name: chengzhiyuan
          type: user
        html: "<p><a rel=\"nofollow\" href=\"https://github.com/huggingface/diffusers/blob/main/examples/controlnet/README_sdxl.md%EF%BC%8Chere%EF%BC%8Cbut%EF%BC%8Ci\"\
          >https://github.com/huggingface/diffusers/blob/main/examples/controlnet/README_sdxl.md\uFF0C\
          here\uFF0Cbut\uFF0Ci</a> cant run\uFF0Cyou can try\uFF0C</p>\n"
        raw: "https://github.com/huggingface/diffusers/blob/main/examples/controlnet/README_sdxl.md\uFF0C\
          here\uFF0Cbut\uFF0Ci cant run\uFF0Cyou can try\uFF0C"
        updatedAt: '2024-01-25T05:02:14.055Z'
      numEdits: 0
      reactions: []
    id: 65b1eb56313a2943c7d7cb69
    type: comment
  author: chengzhiyuan
  content: "https://github.com/huggingface/diffusers/blob/main/examples/controlnet/README_sdxl.md\uFF0C\
    here\uFF0Cbut\uFF0Ci cant run\uFF0Cyou can try\uFF0C"
  created_at: 2024-01-25 05:02:14+00:00
  edited: false
  hidden: false
  id: 65b1eb56313a2943c7d7cb69
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/77ca28527def312701155d50b0dc2998.svg
      fullname: Jean-Loup Maillet
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: destitech
      type: user
    createdAt: '2024-01-25T06:57:09.000Z'
    data:
      edited: false
      editors:
      - destitech
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9345002770423889
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/77ca28527def312701155d50b0dc2998.svg
          fullname: Jean-Loup Maillet
          isHf: false
          isPro: false
          name: destitech
          type: user
        html: '<p>Chengzhiyuan is right I used the script provided by the controlnet
          library:<br><a rel="nofollow" href="https://github.com/huggingface/diffusers/blob/main/examples/controlnet/train_controlnet_sdxl.py">Link</a><br>I
          tried different ways of tuning the script bu the original one is still the
          one which gave the best results.<br>I build a dataset from lexica images
          which are all AI generated and might be the explanation for not having enough
          real photography (dataset was also limited, between a few thousands and
          ten thousands images).</p>

          '
        raw: 'Chengzhiyuan is right I used the script provided by the controlnet library:

          [Link](https://github.com/huggingface/diffusers/blob/main/examples/controlnet/train_controlnet_sdxl.py)

          I tried different ways of tuning the script bu the original one is still
          the one which gave the best results.

          I build a dataset from lexica images which are all AI generated and might
          be the explanation for not having enough real photography (dataset was also
          limited, between a few thousands and ten thousands images).'
        updatedAt: '2024-01-25T06:57:09.422Z'
      numEdits: 0
      reactions: []
    id: 65b20645b4225e3e423f50d3
    type: comment
  author: destitech
  content: 'Chengzhiyuan is right I used the script provided by the controlnet library:

    [Link](https://github.com/huggingface/diffusers/blob/main/examples/controlnet/train_controlnet_sdxl.py)

    I tried different ways of tuning the script bu the original one is still the one
    which gave the best results.

    I build a dataset from lexica images which are all AI generated and might be the
    explanation for not having enough real photography (dataset was also limited,
    between a few thousands and ten thousands images).'
  created_at: 2024-01-25 06:57:09+00:00
  edited: false
  hidden: false
  id: 65b20645b4225e3e423f50d3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/77ca28527def312701155d50b0dc2998.svg
      fullname: Jean-Loup Maillet
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: destitech
      type: user
    createdAt: '2024-01-25T07:00:41.000Z'
    data:
      edited: false
      editors:
      - destitech
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9602017402648926
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/77ca28527def312701155d50b0dc2998.svg
          fullname: Jean-Loup Maillet
          isHf: false
          isPro: false
          name: destitech
          type: user
        html: '<p>Just to add another clarification, it is a simple controlnet, this
          is why the image to inpaint is provided as the controlnet input and not
          just a mask, I have no idea how to train an inpaint controlnet which would
          work by just giving a mask to the controlnet  and work on an img2img pipeline</p>

          '
        raw: Just to add another clarification, it is a simple controlnet, this is
          why the image to inpaint is provided as the controlnet input and not just
          a mask, I have no idea how to train an inpaint controlnet which would work
          by just giving a mask to the controlnet  and work on an img2img pipeline
        updatedAt: '2024-01-25T07:00:41.054Z'
      numEdits: 0
      reactions: []
    id: 65b207198b1f6bf3ac5a4c39
    type: comment
  author: destitech
  content: Just to add another clarification, it is a simple controlnet, this is why
    the image to inpaint is provided as the controlnet input and not just a mask,
    I have no idea how to train an inpaint controlnet which would work by just giving
    a mask to the controlnet  and work on an img2img pipeline
  created_at: 2024-01-25 07:00:41+00:00
  edited: false
  hidden: false
  id: 65b207198b1f6bf3ac5a4c39
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: destitech/controlnet-inpaint-dreamer-sdxl
repo_type: model
status: open
target_branch: null
title: how to  train a  inpaint  controlnet model
