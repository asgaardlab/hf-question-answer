!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nacs
conflicting_files: null
created_at: 2023-04-17 01:37:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b8ca3771abd51458d8d3055d2b4668cf.svg
      fullname: nacs
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nacs
      type: user
    createdAt: '2023-04-17T02:37:35.000Z'
    data:
      edited: false
      editors:
      - nacs
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b8ca3771abd51458d8d3055d2b4668cf.svg
          fullname: nacs
          isHf: false
          isPro: false
          name: nacs
          type: user
        html: '<p>Thanks for training this dataset. I''d love to try it but was curious
          if you could upload a 4-bit quantized version  of this model?</p>

          <p>(It would take a lot less space and VRAM). Thanks!</p>

          '
        raw: "Thanks for training this dataset. I'd love to try it but was curious\
          \ if you could upload a 4-bit quantized version  of this model?\r\n\r\n\
          (It would take a lot less space and VRAM). Thanks!"
        updatedAt: '2023-04-17T02:37:35.230Z'
      numEdits: 0
      reactions: []
    id: 643cb0ef6eeb746f5ad80043
    type: comment
  author: nacs
  content: "Thanks for training this dataset. I'd love to try it but was curious if\
    \ you could upload a 4-bit quantized version  of this model?\r\n\r\n(It would\
    \ take a lot less space and VRAM). Thanks!"
  created_at: 2023-04-17 01:37:35+00:00
  edited: false
  hidden: false
  id: 643cb0ef6eeb746f5ad80043
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-04-18T02:50:29.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<blockquote>

          <p>Thanks for training this dataset. I''d love to try it but was curious
          if you could upload a 4-bit quantized version  of this model?</p>

          <p>(It would take a lot less space and VRAM). Thanks!</p>

          </blockquote>

          <p>Yes I''ll do so right now</p>

          '
        raw: "> Thanks for training this dataset. I'd love to try it but was curious\
          \ if you could upload a 4-bit quantized version  of this model?\n> \n> (It\
          \ would take a lot less space and VRAM). Thanks!\n\nYes I'll do so right\
          \ now"
        updatedAt: '2023-04-18T02:50:29.430Z'
      numEdits: 0
      reactions: []
    id: 643e057546c2cebe83bd5866
    type: comment
  author: teknium
  content: "> Thanks for training this dataset. I'd love to try it but was curious\
    \ if you could upload a 4-bit quantized version  of this model?\n> \n> (It would\
    \ take a lot less space and VRAM). Thanks!\n\nYes I'll do so right now"
  created_at: 2023-04-18 01:50:29+00:00
  edited: false
  hidden: false
  id: 643e057546c2cebe83bd5866
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a97cfbaf6cd58ad8ad35cfd96cb87aa4.svg
      fullname: gkp
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gkp255
      type: user
    createdAt: '2023-04-19T18:26:01.000Z'
    data:
      edited: false
      editors:
      - gkp255
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a97cfbaf6cd58ad8ad35cfd96cb87aa4.svg
          fullname: gkp
          isHf: false
          isPro: false
          name: gkp255
          type: user
        html: '<p>Would it be possible to also get a version that works with llama.cpp
          (<a rel="nofollow" href="https://github.com/ggerganov/llama.cpp">https://github.com/ggerganov/llama.cpp</a>)?</p>

          '
        raw: Would it be possible to also get a version that works with llama.cpp
          (https://github.com/ggerganov/llama.cpp)?
        updatedAt: '2023-04-19T18:26:01.792Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Crataco
    id: 644032394164a65ca12bea5f
    type: comment
  author: gkp255
  content: Would it be possible to also get a version that works with llama.cpp (https://github.com/ggerganov/llama.cpp)?
  created_at: 2023-04-19 17:26:01+00:00
  edited: false
  hidden: false
  id: 644032394164a65ca12bea5f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-04-22T21:25:17.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<blockquote>

          <p>Would it be possible to also get a version that works with llama.cpp
          (<a rel="nofollow" href="https://github.com/ggerganov/llama.cpp">https://github.com/ggerganov/llama.cpp</a>)?</p>

          </blockquote>

          <p>I''m sorry I''ve never worked with it, so I''m not quite sure how to</p>

          '
        raw: '> Would it be possible to also get a version that works with llama.cpp
          (https://github.com/ggerganov/llama.cpp)?


          I''m sorry I''ve never worked with it, so I''m not quite sure how to'
        updatedAt: '2023-04-22T21:25:17.300Z'
      numEdits: 0
      reactions: []
    id: 644450bdc63001ae63568b92
    type: comment
  author: teknium
  content: '> Would it be possible to also get a version that works with llama.cpp
    (https://github.com/ggerganov/llama.cpp)?


    I''m sorry I''ve never worked with it, so I''m not quite sure how to'
  created_at: 2023-04-22 20:25:17+00:00
  edited: false
  hidden: false
  id: 644450bdc63001ae63568b92
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-04-22T21:25:47.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<blockquote>

          <p>Thanks for training this dataset. I''d love to try it but was curious
          if you could upload a 4-bit quantized version  of this model?</p>

          <p>(It would take a lot less space and VRAM). Thanks!</p>

          </blockquote>

          <p>I''m uploading a version 2 of the RP Lora merged with GPT4-x-Alpaca model
          in 4bit quantization right now, you can get it here:<br><a href="https://huggingface.co/teknium/GPT4-x-Alpaca13b-RolePlayLora-4bit-v2">https://huggingface.co/teknium/GPT4-x-Alpaca13b-RolePlayLora-4bit-v2</a></p>

          '
        raw: "> Thanks for training this dataset. I'd love to try it but was curious\
          \ if you could upload a 4-bit quantized version  of this model?\n> \n> (It\
          \ would take a lot less space and VRAM). Thanks!\n\nI'm uploading a version\
          \ 2 of the RP Lora merged with GPT4-x-Alpaca model in 4bit quantization\
          \ right now, you can get it here:\nhttps://huggingface.co/teknium/GPT4-x-Alpaca13b-RolePlayLora-4bit-v2"
        updatedAt: '2023-04-22T21:25:47.083Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - nacs
    id: 644450db8f795c936d05db00
    type: comment
  author: teknium
  content: "> Thanks for training this dataset. I'd love to try it but was curious\
    \ if you could upload a 4-bit quantized version  of this model?\n> \n> (It would\
    \ take a lot less space and VRAM). Thanks!\n\nI'm uploading a version 2 of the\
    \ RP Lora merged with GPT4-x-Alpaca model in 4bit quantization right now, you\
    \ can get it here:\nhttps://huggingface.co/teknium/GPT4-x-Alpaca13b-RolePlayLora-4bit-v2"
  created_at: 2023-04-22 20:25:47+00:00
  edited: false
  hidden: false
  id: 644450db8f795c936d05db00
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a97cfbaf6cd58ad8ad35cfd96cb87aa4.svg
      fullname: gkp
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gkp255
      type: user
    createdAt: '2023-04-27T06:23:24.000Z'
    data:
      edited: false
      editors:
      - gkp255
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a97cfbaf6cd58ad8ad35cfd96cb87aa4.svg
          fullname: gkp
          isHf: false
          isPro: false
          name: gkp255
          type: user
        html: '<blockquote>

          <blockquote>

          <p>Would it be possible to also get a version that works with llama.cpp
          (<a rel="nofollow" href="https://github.com/ggerganov/llama.cpp">https://github.com/ggerganov/llama.cpp</a>)?</p>

          </blockquote>

          <p>I''m sorry I''ve never worked with it, so I''m not quite sure how to</p>

          </blockquote>

          <p>I can take a crack at it. It''s for compatibility with Llama.cpp</p>

          '
        raw: "> > Would it be possible to also get a version that works with llama.cpp\
          \ (https://github.com/ggerganov/llama.cpp)?\n> \n> I'm sorry I've never\
          \ worked with it, so I'm not quite sure how to\n\nI can take a crack at\
          \ it. It's for compatibility with Llama.cpp"
        updatedAt: '2023-04-27T06:23:24.332Z'
      numEdits: 0
      reactions: []
    id: 644a14dc71b0a500118bda59
    type: comment
  author: gkp255
  content: "> > Would it be possible to also get a version that works with llama.cpp\
    \ (https://github.com/ggerganov/llama.cpp)?\n> \n> I'm sorry I've never worked\
    \ with it, so I'm not quite sure how to\n\nI can take a crack at it. It's for\
    \ compatibility with Llama.cpp"
  created_at: 2023-04-27 05:23:24+00:00
  edited: false
  hidden: false
  id: 644a14dc71b0a500118bda59
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: teknium/Base-GPT4-x-Alpaca-Roleplay-Lora
repo_type: model
status: open
target_branch: null
title: 4bit GPTQ version?
