!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aflip
conflicting_files: null
created_at: 2023-10-01 15:17:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/44fb8b8f8262f2550bbb0018aaa28d0d.svg
      fullname: Anand Philip
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aflip
      type: user
    createdAt: '2023-10-01T16:17:31.000Z'
    data:
      edited: true
      editors:
      - aflip
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8638274669647217
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/44fb8b8f8262f2550bbb0018aaa28d0d.svg
          fullname: Anand Philip
          isHf: false
          isPro: false
          name: aflip
          type: user
        html: '<p>I am trying to create a sentence embedding using a corpus that is
          ~40MB in size. But I keep getting Cuda out of memory errors.  Why does it
          try to allocate such a huge amount of memory for such a small dataset? What
          am I doing wrong? </p>

          <p>Training code: <code>corpus_embeddings = encode_batch(sentence_encoder,
          tokenizer, corpus , "cuda")</code> , i haven''t modified the given code
          in any way other than moving this to gpu. My CPU runs also crash due to
          memory issues.  I am training on a single A6000 GPU with 48GB of ram</p>

          <p> <code>OutOfMemoryError: CUDA out of memory. Tried to allocate 80.32
          GiB (GPU 0; 47.54 GiB total capacity; 20.52 GiB already allocated; 26.63
          GiB free; 20.56 GiB reserved in total by PyTorch) If reserved memory is
          &gt;&gt; allocated memory try setting max_split_size_mb to avoid fragmentation.  See
          documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF</code></p>

          '
        raw: "I am trying to create a sentence embedding using a corpus that is ~40MB\
          \ in size. But I keep getting Cuda out of memory errors.  Why does it try\
          \ to allocate such a huge amount of memory for such a small dataset? What\
          \ am I doing wrong? \n\nTraining code: ```corpus_embeddings = encode_batch(sentence_encoder,\
          \ tokenizer, corpus , \"cuda\")``` , i haven't modified the given code in\
          \ any way other than moving this to gpu. My CPU runs also crash due to memory\
          \ issues.  I am training on a single A6000 GPU with 48GB of ram\n\n ```OutOfMemoryError:\
          \ CUDA out of memory. Tried to allocate 80.32 GiB (GPU 0; 47.54 GiB total\
          \ capacity; 20.52 GiB already allocated; 26.63 GiB free; 20.56 GiB reserved\
          \ in total by PyTorch) If reserved memory is >> allocated memory try setting\
          \ max_split_size_mb to avoid fragmentation.  See documentation for Memory\
          \ Management and PYTORCH_CUDA_ALLOC_CONF```"
        updatedAt: '2023-10-01T16:19:25.151Z'
      numEdits: 2
      reactions: []
    id: 65199b9b0e3a5553d4ad588e
    type: comment
  author: aflip
  content: "I am trying to create a sentence embedding using a corpus that is ~40MB\
    \ in size. But I keep getting Cuda out of memory errors.  Why does it try to allocate\
    \ such a huge amount of memory for such a small dataset? What am I doing wrong?\
    \ \n\nTraining code: ```corpus_embeddings = encode_batch(sentence_encoder, tokenizer,\
    \ corpus , \"cuda\")``` , i haven't modified the given code in any way other than\
    \ moving this to gpu. My CPU runs also crash due to memory issues.  I am training\
    \ on a single A6000 GPU with 48GB of ram\n\n ```OutOfMemoryError: CUDA out of\
    \ memory. Tried to allocate 80.32 GiB (GPU 0; 47.54 GiB total capacity; 20.52\
    \ GiB already allocated; 26.63 GiB free; 20.56 GiB reserved in total by PyTorch)\
    \ If reserved memory is >> allocated memory try setting max_split_size_mb to avoid\
    \ fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF```"
  created_at: 2023-10-01 15:17:31+00:00
  edited: true
  hidden: false
  id: 65199b9b0e3a5553d4ad588e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: biu-nlp/abstract-sim-sentence
repo_type: model
status: open
target_branch: null
title: How much memory is needed to create an embedding
