!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Test157t
conflicting_files: null
created_at: 2024-01-17 14:30:46+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/369c25f1391084255418b14d2dfa9abf.svg
      fullname: Test157 Nitral
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Test157t
      type: user
    createdAt: '2024-01-17T14:30:46.000Z'
    data:
      edited: false
      editors:
      - Test157t
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8420543670654297
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/369c25f1391084255418b14d2dfa9abf.svg
          fullname: Test157 Nitral
          isHf: false
          isPro: false
          name: Test157t
          type: user
        html: "<p>Can confirm prompt format \"should\" be chatml, this was an attempt\
          \ to recreate kunoichi dpo but for chatml instead of alpaca - while also\
          \ using the newer version of noromaid 0.4.  Thanks to <span data-props=\"\
          {&quot;user&quot;:&quot;SanjiWatsuki&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/SanjiWatsuki\">@<span class=\"underline\"\
          >SanjiWatsuki</span></a></span>\n\n\t</span></span> for merging at my selfish\
          \ request ;)</p>\n"
        raw: Can confirm prompt format "should" be chatml, this was an attempt to
          recreate kunoichi dpo but for chatml instead of alpaca - while also using
          the newer version of noromaid 0.4.  Thanks to @SanjiWatsuki for merging
          at my selfish request ;)
        updatedAt: '2024-01-17T14:30:46.268Z'
      numEdits: 0
      reactions: []
    id: 65a7e496de63b063e32aff54
    type: comment
  author: Test157t
  content: Can confirm prompt format "should" be chatml, this was an attempt to recreate
    kunoichi dpo but for chatml instead of alpaca - while also using the newer version
    of noromaid 0.4.  Thanks to @SanjiWatsuki for merging at my selfish request ;)
  created_at: 2024-01-17 14:30:46+00:00
  edited: false
  hidden: false
  id: 65a7e496de63b063e32aff54
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/369c25f1391084255418b14d2dfa9abf.svg
      fullname: Test157 Nitral
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Test157t
      type: user
    createdAt: '2024-01-17T15:29:17.000Z'
    data:
      edited: true
      editors:
      - Test157t
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9530129432678223
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/369c25f1391084255418b14d2dfa9abf.svg
          fullname: Test157 Nitral
          isHf: false
          isPro: false
          name: Test157t
          type: user
        html: '<p>After testing this, and the noromaid 0.4 4bpw quant. it appears
          there''s something wrong with the stop tokens, neither model wants to stop
          generating, and can confirm at least on noromaid 0.4 that this is not a
          problem in the gptq and gguf quants from thebloke. Hopefully it''s contained
          to just these noromaid 0.4 based models in 4bpw, when other quants of this
          model drop i will report back with further findings.</p>

          '
        raw: After testing this, and the noromaid 0.4 4bpw quant. it appears there's
          something wrong with the stop tokens, neither model wants to stop generating,
          and can confirm at least on noromaid 0.4 that this is not a problem in the
          gptq and gguf quants from thebloke. Hopefully it's contained to just these
          noromaid 0.4 based models in 4bpw, when other quants of this model drop
          i will report back with further findings.
        updatedAt: '2024-01-17T15:29:44.841Z'
      numEdits: 1
      reactions: []
    id: 65a7f24de5ddfd7d1da8ec5b
    type: comment
  author: Test157t
  content: After testing this, and the noromaid 0.4 4bpw quant. it appears there's
    something wrong with the stop tokens, neither model wants to stop generating,
    and can confirm at least on noromaid 0.4 that this is not a problem in the gptq
    and gguf quants from thebloke. Hopefully it's contained to just these noromaid
    0.4 based models in 4bpw, when other quants of this model drop i will report back
    with further findings.
  created_at: 2024-01-17 15:29:17+00:00
  edited: true
  hidden: false
  id: 65a7f24de5ddfd7d1da8ec5b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6376b76aa3b787faca41f8e8/-3_1Y8WSYnXQrA1jxy-q5.jpeg?w=200&h=200&f=face
      fullname: Kooten
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Kooten
      type: user
    createdAt: '2024-01-17T16:38:35.000Z'
    data:
      edited: false
      editors:
      - Kooten
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9947404861450195
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6376b76aa3b787faca41f8e8/-3_1Y8WSYnXQrA1jxy-q5.jpeg?w=200&h=200&f=face
          fullname: Kooten
          isHf: false
          isPro: false
          name: Kooten
          type: user
        html: '<p>I was able to confirm the problem with both the Lelantos-Maid quants
          i uploaded from both tabby and ooba.<br>There was no change in setup between
          these and the Noromaid models from just before. I will try to redo them
          completely.</p>

          '
        raw: "I was able to confirm the problem with both the Lelantos-Maid quants\
          \ i uploaded from both tabby and ooba. \nThere was no change in setup between\
          \ these and the Noromaid models from just before. I will try to redo them\
          \ completely."
        updatedAt: '2024-01-17T16:38:35.122Z'
      numEdits: 0
      reactions: []
    id: 65a8028bc0e51d82e67f000c
    type: comment
  author: Kooten
  content: "I was able to confirm the problem with both the Lelantos-Maid quants i\
    \ uploaded from both tabby and ooba. \nThere was no change in setup between these\
    \ and the Noromaid models from just before. I will try to redo them completely."
  created_at: 2024-01-17 16:38:35+00:00
  edited: false
  hidden: false
  id: 65a8028bc0e51d82e67f000c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/369c25f1391084255418b14d2dfa9abf.svg
      fullname: Test157 Nitral
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Test157t
      type: user
    createdAt: '2024-01-17T17:43:31.000Z'
    data:
      edited: true
      editors:
      - Test157t
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9763107895851135
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/369c25f1391084255418b14d2dfa9abf.svg
          fullname: Test157 Nitral
          isHf: false
          isPro: false
          name: Test157t
          type: user
        html: '<p>Thank you so much my man, ive been trying to wrap my head around
          what is going on. Ive gotten really good prose in some instances, and just
          off the wall nonesense in others. I saw it was loading with alpaca by default
          for both noromaid and this and wondered if that may be contributing to the
          issue aswell. </p>

          '
        raw: 'Thank you so much my man, ive been trying to wrap my head around what
          is going on. Ive gotten really good prose in some instances, and just off
          the wall nonesense in others. I saw it was loading with alpaca by default
          for both noromaid and this and wondered if that may be contributing to the
          issue aswell. '
        updatedAt: '2024-01-17T17:44:05.299Z'
      numEdits: 1
      reactions: []
    id: 65a811c310125597326b6907
    type: comment
  author: Test157t
  content: 'Thank you so much my man, ive been trying to wrap my head around what
    is going on. Ive gotten really good prose in some instances, and just off the
    wall nonesense in others. I saw it was loading with alpaca by default for both
    noromaid and this and wondered if that may be contributing to the issue aswell. '
  created_at: 2024-01-17 17:43:31+00:00
  edited: true
  hidden: false
  id: 65a811c310125597326b6907
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Kooten/Lelantos-Maid-DPO-7B-4bpw-exl2
repo_type: model
status: open
target_branch: null
title: Thanks my dude <3
