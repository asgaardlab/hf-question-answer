!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Lyriccoder
conflicting_files: null
created_at: 2022-07-22 12:23:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0a54fe5786c825aa9f967ad2f1bb2b35.svg
      fullname: Lyric Coder
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lyriccoder
      type: user
    createdAt: '2022-07-22T13:23:14.000Z'
    data:
      edited: true
      editors:
      - Lyriccoder
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0a54fe5786c825aa9f967ad2f1bb2b35.svg
          fullname: Lyric Coder
          isHf: false
          isPro: false
          name: Lyriccoder
          type: user
        html: '<p>If I try to follow the guide (<a href="https://huggingface.co/docs/transformers/main/serialization">https://huggingface.co/docs/transformers/main/serialization</a>)
          and try to export the unixcoder model, I see the errors:</p>

          <pre><code>    raise RepositoryNotFoundError(

          transformers.utils.hub.RepositoryNotFoundError: 401 Client Error: Repository
          not found for url: https://huggingface.co/unixcoder-base/resolve/main/config.json.
          If the repo is private, make sure you are authenticated.

          OSError: unixcoder-base is not a local folder and is not a valid model identifier
          listed on ''https://huggingface.co/models''

          </code></pre>

          <p>I tried to export model with local files (located in <a href="https://huggingface.co/microsoft/unixcoder-base/tree/main">https://huggingface.co/microsoft/unixcoder-base/tree/main</a>),<br>but
          I also get the following error:</p>

          <pre><code>    raise ValueError(

          ValueError: Unrecognized processor in unixcoder-base. Should have a `processor_type`
          key in its preprocessor_config.json, or one of the following `model_type`
          keys in its config.json: clip, flava, layoutlmv2, layoutlmv3, layoutxlm,
          sew, sew-d, speech_to_text, speech_to_text_2, trocr, unispeech, unispeech-sat,
          vilt, vision-text-dual-encoder, wav2vec2, wav2vec2-conformer, wav2vec2_with_lm,
          wavlm

          </code></pre>

          <p>Could you please tell me whether it is possible to export the unixcoder
          model to ONNX?<br>If no, could you please make such an opportunity?<br>
          I am trying to reduce the inference time for GPU of unixcoder model (I have
          an own checkpoint)</p>

          '
        raw: "If I try to follow the guide (https://huggingface.co/docs/transformers/main/serialization)\
          \ and try to export the unixcoder model, I see the errors:\n```\n    raise\
          \ RepositoryNotFoundError(\ntransformers.utils.hub.RepositoryNotFoundError:\
          \ 401 Client Error: Repository not found for url: https://huggingface.co/unixcoder-base/resolve/main/config.json.\
          \ If the repo is private, make sure you are authenticated.\nOSError: unixcoder-base\
          \ is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n\
          ```\n\nI tried to export model with local files (located in https://huggingface.co/microsoft/unixcoder-base/tree/main),\n\
          but I also get the following error:\n\n```\n    raise ValueError(\nValueError:\
          \ Unrecognized processor in unixcoder-base. Should have a `processor_type`\
          \ key in its preprocessor_config.json, or one of the following `model_type`\
          \ keys in its config.json: clip, flava, layoutlmv2, layoutlmv3, layoutxlm,\
          \ sew, sew-d, speech_to_text, speech_to_text_2, trocr, unispeech, unispeech-sat,\
          \ vilt, vision-text-dual-encoder, wav2vec2, wav2vec2-conformer, wav2vec2_with_lm,\
          \ wavlm\n```\n\nCould you please tell me whether it is possible to export\
          \ the unixcoder model to ONNX?\nIf no, could you please make such an opportunity?\n\
          \ I am trying to reduce the inference time for GPU of unixcoder model (I\
          \ have an own checkpoint)"
        updatedAt: '2022-07-22T13:24:03.336Z'
      numEdits: 2
      reactions: []
    id: 62daa4c25575019463cc55bb
    type: comment
  author: Lyriccoder
  content: "If I try to follow the guide (https://huggingface.co/docs/transformers/main/serialization)\
    \ and try to export the unixcoder model, I see the errors:\n```\n    raise RepositoryNotFoundError(\n\
    transformers.utils.hub.RepositoryNotFoundError: 401 Client Error: Repository not\
    \ found for url: https://huggingface.co/unixcoder-base/resolve/main/config.json.\
    \ If the repo is private, make sure you are authenticated.\nOSError: unixcoder-base\
    \ is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n\
    ```\n\nI tried to export model with local files (located in https://huggingface.co/microsoft/unixcoder-base/tree/main),\n\
    but I also get the following error:\n\n```\n    raise ValueError(\nValueError:\
    \ Unrecognized processor in unixcoder-base. Should have a `processor_type` key\
    \ in its preprocessor_config.json, or one of the following `model_type` keys in\
    \ its config.json: clip, flava, layoutlmv2, layoutlmv3, layoutxlm, sew, sew-d,\
    \ speech_to_text, speech_to_text_2, trocr, unispeech, unispeech-sat, vilt, vision-text-dual-encoder,\
    \ wav2vec2, wav2vec2-conformer, wav2vec2_with_lm, wavlm\n```\n\nCould you please\
    \ tell me whether it is possible to export the unixcoder model to ONNX?\nIf no,\
    \ could you please make such an opportunity?\n I am trying to reduce the inference\
    \ time for GPU of unixcoder model (I have an own checkpoint)"
  created_at: 2022-07-22 12:23:14+00:00
  edited: true
  hidden: false
  id: 62daa4c25575019463cc55bb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2022-07-24T12:49:16.000Z'
    data:
      edited: false
      editors:
      - nielsr
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: "<p>Cc <span data-props=\"{&quot;user&quot;:&quot;regisss&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/regisss\">@<span class=\"\
          underline\">regisss</span></a></span>\n\n\t</span></span></p>\n"
        raw: Cc @regisss
        updatedAt: '2022-07-24T12:49:16.019Z'
      numEdits: 0
      reactions: []
    id: 62dd3fcc169bd1d2ef2e3692
    type: comment
  author: nielsr
  content: Cc @regisss
  created_at: 2022-07-24 11:49:16+00:00
  edited: false
  hidden: false
  id: 62dd3fcc169bd1d2ef2e3692
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0a54fe5786c825aa9f967ad2f1bb2b35.svg
      fullname: Lyric Coder
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lyriccoder
      type: user
    createdAt: '2022-08-23T13:03:01.000Z'
    data:
      edited: false
      editors:
      - Lyriccoder
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0a54fe5786c825aa9f967ad2f1bb2b35.svg
          fullname: Lyric Coder
          isHf: false
          isPro: false
          name: Lyriccoder
          type: user
        html: "<p>Hi guys, do u have any updates?<br><span data-props=\"{&quot;user&quot;:&quot;nielsr&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/nielsr\"\
          >@<span class=\"underline\">nielsr</span></a></span>\n\n\t</span></span></p>\n"
        raw: 'Hi guys, do u have any updates?

          @nielsr'
        updatedAt: '2022-08-23T13:03:01.117Z'
      numEdits: 0
      reactions: []
    id: 6304d0059aef62c4013eea84
    type: comment
  author: Lyriccoder
  content: 'Hi guys, do u have any updates?

    @nielsr'
  created_at: 2022-08-23 12:03:01+00:00
  edited: false
  hidden: false
  id: 6304d0059aef62c4013eea84
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2022-08-23T13:41:19.000Z'
    data:
      edited: false
      editors:
      - nielsr
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;Lyriccoder&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Lyriccoder\"\
          >@<span class=\"underline\">Lyriccoder</span></a></span>\n\n\t</span></span>,</p>\n\
          <p>The reason you get the error is because you just need to provide the\
          \ model name, rather than the URL. The following works for me in Google\
          \ Colab:</p>\n<pre><code>!pip install -q transformers[onnx]\n!python -m\
          \ transformers.onnx --model=microsoft/unixcoder-base onnx/ --atol 1e-4 \n\
          </code></pre>\n"
        raw: "Hi @Lyriccoder,\n\nThe reason you get the error is because you just\
          \ need to provide the model name, rather than the URL. The following works\
          \ for me in Google Colab:\n\n```\n!pip install -q transformers[onnx]\n!python\
          \ -m transformers.onnx --model=microsoft/unixcoder-base onnx/ --atol 1e-4\
          \ \n```"
        updatedAt: '2022-08-23T13:41:19.982Z'
      numEdits: 0
      reactions: []
    id: 6304d8ffce6b12280b1bc816
    type: comment
  author: nielsr
  content: "Hi @Lyriccoder,\n\nThe reason you get the error is because you just need\
    \ to provide the model name, rather than the URL. The following works for me in\
    \ Google Colab:\n\n```\n!pip install -q transformers[onnx]\n!python -m transformers.onnx\
    \ --model=microsoft/unixcoder-base onnx/ --atol 1e-4 \n```"
  created_at: 2022-08-23 12:41:19+00:00
  edited: false
  hidden: false
  id: 6304d8ffce6b12280b1bc816
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0a54fe5786c825aa9f967ad2f1bb2b35.svg
      fullname: Lyric Coder
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lyriccoder
      type: user
    createdAt: '2022-08-24T08:15:30.000Z'
    data:
      edited: true
      editors:
      - Lyriccoder
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0a54fe5786c825aa9f967ad2f1bb2b35.svg
          fullname: Lyric Coder
          isHf: false
          isPro: false
          name: Lyriccoder
          type: user
        html: '<p>First, I am talking about model with fine-tuning for code summarization
          (folder code-summarization).<br>Secondly, I tried to export already fine-tuned
          Unixcoder model (Seq2Seq, I have a saved checkpoint) for code summarization
          (not the original model).<br>Does it happen just because Seq2Seq with Unixcoder
          encoder-decoder model is not supported?</p>

          '
        raw: "First, I am talking about model with fine-tuning for code summarization\
          \ (folder code-summarization). \nSecondly, I tried to export already fine-tuned\
          \ Unixcoder model (Seq2Seq, I have a saved checkpoint) for code summarization\
          \ (not the original model).\nDoes it happen just because Seq2Seq with Unixcoder\
          \ encoder-decoder model is not supported?"
        updatedAt: '2022-08-24T10:30:49.735Z'
      numEdits: 2
      reactions: []
    id: 6305de223aed65d34e93f15f
    type: comment
  author: Lyriccoder
  content: "First, I am talking about model with fine-tuning for code summarization\
    \ (folder code-summarization). \nSecondly, I tried to export already fine-tuned\
    \ Unixcoder model (Seq2Seq, I have a saved checkpoint) for code summarization\
    \ (not the original model).\nDoes it happen just because Seq2Seq with Unixcoder\
    \ encoder-decoder model is not supported?"
  created_at: 2022-08-24 07:15:30+00:00
  edited: true
  hidden: false
  id: 6305de223aed65d34e93f15f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2022-08-24T08:22:46.000Z'
    data:
      edited: false
      editors:
      - nielsr
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: '<p>Do you mean that your model is an instance of the <code>EncoderDecoderModel</code>
          <a href="https://huggingface.co/docs/transformers/model_doc/encoder-decoder">class</a>?</p>

          '
        raw: Do you mean that your model is an instance of the `EncoderDecoderModel`
          [class](https://huggingface.co/docs/transformers/model_doc/encoder-decoder)?
        updatedAt: '2022-08-24T08:22:46.228Z'
      numEdits: 0
      reactions: []
    id: 6305dfd6660f01f1509e13d0
    type: comment
  author: nielsr
  content: Do you mean that your model is an instance of the `EncoderDecoderModel`
    [class](https://huggingface.co/docs/transformers/model_doc/encoder-decoder)?
  created_at: 2022-08-24 07:22:46+00:00
  edited: false
  hidden: false
  id: 6305dfd6660f01f1509e13d0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0a54fe5786c825aa9f967ad2f1bb2b35.svg
      fullname: Lyric Coder
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lyriccoder
      type: user
    createdAt: '2022-08-24T10:36:09.000Z'
    data:
      edited: false
      editors:
      - Lyriccoder
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0a54fe5786c825aa9f967ad2f1bb2b35.svg
          fullname: Lyric Coder
          isHf: false
          isPro: false
          name: Lyriccoder
          type: user
        html: '<p>I trained your model, located here:</p>

          <p><a rel="nofollow" href="https://github.com/microsoft/CodeBERT/blob/master/UniXcoder/downstream-tasks/code-summarization/model.py">https://github.com/microsoft/CodeBERT/blob/master/UniXcoder/downstream-tasks/code-summarization/model.py</a>.
          I didn''t change that model.</p>

          <p>I trained it successfully, I have a checkpoint. Onnx supports loading
          models from checkpoints (not only officially deployed in huggingface).<br>But
          when I try to load a load checkpoint with ONNX  (<a rel="nofollow" href="https://github.com/microsoft/CodeBERT/blob/master/UniXcoder/downstream-tasks/code-summarization/model.py">https://github.com/microsoft/CodeBERT/blob/master/UniXcoder/downstream-tasks/code-summarization/model.py</a>),
          I have the error:</p>

          <pre><code> raise ValueError(

          ValueError: Unrecognized processor in unixcoder-base. Should have a `processor_type`
          key in its preprocessor_config.json, or one of the following `model_type`
          keys in its config.json: clip, flava, layoutlmv2, layoutlmv3, layoutxlm,
          sew, sew-d, speech_to_text, speech_to_text_2, trocr, unispeech, unispeech-sat,
          vilt, vision-text-dual-encoder, wav2vec2, wav2vec2-conformer, wav2vec2_with_lm,
          wavlm

          </code></pre>

          '
        raw: "I trained your model, located here:\n\nhttps://github.com/microsoft/CodeBERT/blob/master/UniXcoder/downstream-tasks/code-summarization/model.py.\
          \ I didn't change that model.\n\nI trained it successfully, I have a checkpoint.\
          \ Onnx supports loading models from checkpoints (not only officially deployed\
          \ in huggingface).\nBut when I try to load a load checkpoint with ONNX \
          \ (https://github.com/microsoft/CodeBERT/blob/master/UniXcoder/downstream-tasks/code-summarization/model.py),\
          \ I have the error:\n\n```\n raise ValueError(\nValueError: Unrecognized\
          \ processor in unixcoder-base. Should have a `processor_type` key in its\
          \ preprocessor_config.json, or one of the following `model_type` keys in\
          \ its config.json: clip, flava, layoutlmv2, layoutlmv3, layoutxlm, sew,\
          \ sew-d, speech_to_text, speech_to_text_2, trocr, unispeech, unispeech-sat,\
          \ vilt, vision-text-dual-encoder, wav2vec2, wav2vec2-conformer, wav2vec2_with_lm,\
          \ wavlm\n```"
        updatedAt: '2022-08-24T10:36:09.003Z'
      numEdits: 0
      reactions: []
    id: 6305ff1941bf1fbadaea46ce
    type: comment
  author: Lyriccoder
  content: "I trained your model, located here:\n\nhttps://github.com/microsoft/CodeBERT/blob/master/UniXcoder/downstream-tasks/code-summarization/model.py.\
    \ I didn't change that model.\n\nI trained it successfully, I have a checkpoint.\
    \ Onnx supports loading models from checkpoints (not only officially deployed\
    \ in huggingface).\nBut when I try to load a load checkpoint with ONNX  (https://github.com/microsoft/CodeBERT/blob/master/UniXcoder/downstream-tasks/code-summarization/model.py),\
    \ I have the error:\n\n```\n raise ValueError(\nValueError: Unrecognized processor\
    \ in unixcoder-base. Should have a `processor_type` key in its preprocessor_config.json,\
    \ or one of the following `model_type` keys in its config.json: clip, flava, layoutlmv2,\
    \ layoutlmv3, layoutxlm, sew, sew-d, speech_to_text, speech_to_text_2, trocr,\
    \ unispeech, unispeech-sat, vilt, vision-text-dual-encoder, wav2vec2, wav2vec2-conformer,\
    \ wav2vec2_with_lm, wavlm\n```"
  created_at: 2022-08-24 09:36:09+00:00
  edited: false
  hidden: false
  id: 6305ff1941bf1fbadaea46ce
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2022-08-24T11:13:38.000Z'
    data:
      edited: false
      editors:
      - nielsr
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: '<p>Ok I see. That custom <code>Seq2Seq</code> class isn''t supported
          by the ONNX tools that HuggingFace provides (which only include models available
          in the Transformers library).</p>

          <p>So this would require a custom implementation. Alternatively (and this
          is what I''d recommend), is to fine-tune an <code>EncoderDecoderModel</code>
          <a href="https://huggingface.co/docs/transformers/model_doc/encoder-decoder">class</a>,
          warm-started with the weights of <code>microsoft/unixcoder-base</code> for
          both the encoder and decoder, on a code summarization dataset. This is also
          what the UnixCoder authors did as seen <a rel="nofollow" href="https://github.com/microsoft/CodeBERT/blob/0b522a6d7b2e25456e52b1c99a8e9cc6cd2aa6e0/UniXcoder/downstream-tasks/code-summarization/run.py#L221">here</a>.</p>

          <p>We''re planning to add ONNX support for that class soon.</p>

          '
        raw: 'Ok I see. That custom `Seq2Seq` class isn''t supported by the ONNX tools
          that HuggingFace provides (which only include models available in the Transformers
          library).


          So this would require a custom implementation. Alternatively (and this is
          what I''d recommend), is to fine-tune an `EncoderDecoderModel` [class](https://huggingface.co/docs/transformers/model_doc/encoder-decoder),
          warm-started with the weights of `microsoft/unixcoder-base` for both the
          encoder and decoder, on a code summarization dataset. This is also what
          the UnixCoder authors did as seen [here](https://github.com/microsoft/CodeBERT/blob/0b522a6d7b2e25456e52b1c99a8e9cc6cd2aa6e0/UniXcoder/downstream-tasks/code-summarization/run.py#L221).


          We''re planning to add ONNX support for that class soon.'
        updatedAt: '2022-08-24T11:13:38.380Z'
      numEdits: 0
      reactions: []
    id: 630607e2df993a789e6346de
    type: comment
  author: nielsr
  content: 'Ok I see. That custom `Seq2Seq` class isn''t supported by the ONNX tools
    that HuggingFace provides (which only include models available in the Transformers
    library).


    So this would require a custom implementation. Alternatively (and this is what
    I''d recommend), is to fine-tune an `EncoderDecoderModel` [class](https://huggingface.co/docs/transformers/model_doc/encoder-decoder),
    warm-started with the weights of `microsoft/unixcoder-base` for both the encoder
    and decoder, on a code summarization dataset. This is also what the UnixCoder
    authors did as seen [here](https://github.com/microsoft/CodeBERT/blob/0b522a6d7b2e25456e52b1c99a8e9cc6cd2aa6e0/UniXcoder/downstream-tasks/code-summarization/run.py#L221).


    We''re planning to add ONNX support for that class soon.'
  created_at: 2022-08-24 10:13:38+00:00
  edited: false
  hidden: false
  id: 630607e2df993a789e6346de
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0a54fe5786c825aa9f967ad2f1bb2b35.svg
      fullname: Lyric Coder
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lyriccoder
      type: user
    createdAt: '2022-08-24T11:59:22.000Z'
    data:
      edited: true
      editors:
      - Lyriccoder
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0a54fe5786c825aa9f967ad2f1bb2b35.svg
          fullname: Lyric Coder
          isHf: false
          isPro: false
          name: Lyriccoder
          type: user
        html: '<p>Oh, got it. It''s not an issue of Unixcoder. I am looking forward
          for that class.<br>If it is possible, could you please make documentation
          with example for that case when ONNX will support the mentioned feature
          in future?</p>

          <p>Thank you for your answer.</p>

          '
        raw: 'Oh, got it. It''s not an issue of Unixcoder. I am looking forward for
          that class.

          If it is possible, could you please make documentation with example for
          that case when ONNX will support the mentioned feature in future?


          Thank you for your answer.'
        updatedAt: '2022-08-24T12:02:23.930Z'
      numEdits: 1
      reactions: []
    id: 6306129a41bf1fbadaeb0042
    type: comment
  author: Lyriccoder
  content: 'Oh, got it. It''s not an issue of Unixcoder. I am looking forward for
    that class.

    If it is possible, could you please make documentation with example for that case
    when ONNX will support the mentioned feature in future?


    Thank you for your answer.'
  created_at: 2022-08-24 10:59:22+00:00
  edited: true
  hidden: false
  id: 6306129a41bf1fbadaeb0042
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/0a54fe5786c825aa9f967ad2f1bb2b35.svg
      fullname: Lyric Coder
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lyriccoder
      type: user
    createdAt: '2022-08-25T07:03:17.000Z'
    data:
      status: closed
    id: 63071eb51801ecc7d2599d28
    type: status-change
  author: Lyriccoder
  created_at: 2022-08-25 06:03:17+00:00
  id: 63071eb51801ecc7d2599d28
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: microsoft/unixcoder-base
repo_type: model
status: closed
target_branch: null
title: Is it possible to export unixcoder to ONNX format?
