!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Ks01
conflicting_files: null
created_at: 2023-11-10 00:47:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/jiBJzFDGtCMsOt7U3czoG.png?w=200&h=200&f=face
      fullname: Ks
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ks01
      type: user
    createdAt: '2023-11-10T00:47:58.000Z'
    data:
      edited: true
      editors:
      - Ks01
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9874852895736694
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/jiBJzFDGtCMsOt7U3czoG.png?w=200&h=200&f=face
          fullname: Ks
          isHf: false
          isPro: false
          name: Ks01
          type: user
        html: '<p>It took a while to dig myself into those models.<br>Both two were
          good, and both two have a little problem too.<br>First of all, I think those
          are the improvements from the last models you merged.<br>They did decent
          at RP and definitely have better intelligence.<br>They did get confused
          with complex prompts, but at least they tried to understand what''s going
          on.</p>

          <p>Xwin-StellarBright was better on RP. It described more about the physical
          depiction. For example, how the body hurts after the fight But dolphin-xwin
          is more descriptive in mood and atmosphere, which is not my favorite since
          I can be repetitive very soon.<br>However, Dolphin-xwin was slightly better
          at understanding complex prompts and felt it had more intelligence. Xwin-stellar
          also has great intelligence, but it is not as great as dolphin.<br>Additionally,
          I felt that the reply quality got slightly lower after 4k too. I used a
          2.7 alpha value for 8k. And there was definitely a quality difference after
          my RP session passed 4k context. Both models are slightly repetitive but
          not serious as xwin-steallar-mythospice merge. It was more like a LZLV repetition
          issue. It definitely reproduces some phrase like, ''Her eyes are filled
          with determination.'' over and over.</p>

          <p>So, what I felt about those two models was that they were like mythomax
          and mythalion.<br>Dolphin merge has slightly better intelligence, but stellar
          merge is better at RP/ERP since its characteristics describe scenes more
          physically and vividly.<br>Both are my favorites, and I will update feedback
          after I try more.</p>

          <ul>

          <li>Would you mind uploading both models? I would like to ask Thebloke to
          merge those.</li>

          </ul>

          '
        raw: 'It took a while to dig myself into those models.

          Both two were good, and both two have a little problem too.

          First of all, I think those are the improvements from the last models you
          merged.

          They did decent at RP and definitely have better intelligence.

          They did get confused with complex prompts, but at least they tried to understand
          what''s going on.


          Xwin-StellarBright was better on RP. It described more about the physical
          depiction. For example, how the body hurts after the fight But dolphin-xwin
          is more descriptive in mood and atmosphere, which is not my favorite since
          I can be repetitive very soon.

          However, Dolphin-xwin was slightly better at understanding complex prompts
          and felt it had more intelligence. Xwin-stellar also has great intelligence,
          but it is not as great as dolphin.

          Additionally, I felt that the reply quality got slightly lower after 4k
          too. I used a 2.7 alpha value for 8k. And there was definitely a quality
          difference after my RP session passed 4k context. Both models are slightly
          repetitive but not serious as xwin-steallar-mythospice merge. It was more
          like a LZLV repetition issue. It definitely reproduces some phrase like,
          ''Her eyes are filled with determination.'' over and over.


          So, what I felt about those two models was that they were like mythomax
          and mythalion.

          Dolphin merge has slightly better intelligence, but stellar merge is better
          at RP/ERP since its characteristics describe scenes more physically and
          vividly.

          Both are my favorites, and I will update feedback after I try more.


          + Would you mind uploading both models? I would like to ask Thebloke to
          merge those.'
        updatedAt: '2023-11-10T05:28:27.617Z'
      numEdits: 1
      reactions: []
    id: 654d7dbecf8aa735d83d2022
    type: comment
  author: Ks01
  content: 'It took a while to dig myself into those models.

    Both two were good, and both two have a little problem too.

    First of all, I think those are the improvements from the last models you merged.

    They did decent at RP and definitely have better intelligence.

    They did get confused with complex prompts, but at least they tried to understand
    what''s going on.


    Xwin-StellarBright was better on RP. It described more about the physical depiction.
    For example, how the body hurts after the fight But dolphin-xwin is more descriptive
    in mood and atmosphere, which is not my favorite since I can be repetitive very
    soon.

    However, Dolphin-xwin was slightly better at understanding complex prompts and
    felt it had more intelligence. Xwin-stellar also has great intelligence, but it
    is not as great as dolphin.

    Additionally, I felt that the reply quality got slightly lower after 4k too. I
    used a 2.7 alpha value for 8k. And there was definitely a quality difference after
    my RP session passed 4k context. Both models are slightly repetitive but not serious
    as xwin-steallar-mythospice merge. It was more like a LZLV repetition issue. It
    definitely reproduces some phrase like, ''Her eyes are filled with determination.''
    over and over.


    So, what I felt about those two models was that they were like mythomax and mythalion.

    Dolphin merge has slightly better intelligence, but stellar merge is better at
    RP/ERP since its characteristics describe scenes more physically and vividly.

    Both are my favorites, and I will update feedback after I try more.


    + Would you mind uploading both models? I would like to ask Thebloke to merge
    those.'
  created_at: 2023-11-10 00:47:58+00:00
  edited: true
  hidden: false
  id: 654d7dbecf8aa735d83d2022
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b4b108103617b0a5b0f6f5/A5P1pKfMv5KhGvnpfo21G.png?w=200&h=200&f=face
      fullname: Sophosympatheia
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sophosympatheia
      type: user
    createdAt: '2023-11-10T06:36:50.000Z'
    data:
      edited: false
      editors:
      - sophosympatheia
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8855524063110352
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b4b108103617b0a5b0f6f5/A5P1pKfMv5KhGvnpfo21G.png?w=200&h=200&f=face
          fullname: Sophosympatheia
          isHf: false
          isPro: false
          name: sophosympatheia
          type: user
        html: '<p>I''ll see what I can do. I really need to get more disk space. I
          have to delete the full-precision weights as I go to make space for the
          next experiment. I already deleted the FP weights for dolphin-xwin-airoboros_peft
          and xwin-stellarbright-airoboros_peft, but I made another variant of xwin-stellarbright
          that includes limarp and Kimiko in addition to the airoboros LoRA. It''s
          good and I''ll be uploading it soon. I might get the full weights up too.</p>

          <p>With these StellarBright merges, I''m finding that they seem to perform
          better at a temperature lower than I''m accustomed to using for my sampler
          settings. I''m also finding some success with setting Presence Penalty to
          some value between 0.2 and 1.0, and even Frequency Penalty has been interesting.
          Below is a snapshot of my current sampler settings, just what I''m running
          tonight as I experiment. I normally don''t mess with Frequency Penalty,
          but it''s interesting. Either set it to 0 (the default) or 0.01, anything
          else gets weird or downright incoherent very quickly. I recommend trying
          Frequency Penalty at 0.01 to see if you like that output better. Presence
          Penalty is like another form of repetition penalty that can help cut down
          on repetition, especially of the same phrases that appear in the input (i.e.
          earlier in the chat).</p>

          <p>{<br>    "temp": 0.55,<br>    "top_p": 1,<br>    "top_k": 0,<br>    "top_a":
          0,<br>    "tfs": 1,<br>    "epsilon_cutoff": 0,<br>    "eta_cutoff": 0,<br>    "typical_p":
          1,<br>    "rep_pen": 1.07,<br>    "rep_pen_range": 0,<br>    "no_repeat_ngram_size":
          0,<br>    "penalty_alpha": 0,<br>    "num_beams": 1,<br>    "length_penalty":
          1,<br>    "min_length": 0,<br>    "encoder_rep_pen": 1,<br>    "freq_pen":
          0.01,<br>    "presence_pen": 0.2,<br>    "do_sample": true,<br>    "early_stopping":
          false,<br>    "add_bos_token": true,<br>    "truncation_length": 2048,<br>    "ban_eos_token":
          false,<br>    "skip_special_tokens": true,<br>    "streaming": true,<br>    "mirostat_mode":
          2,<br>    "mirostat_tau": 5,<br>    "mirostat_eta": 0.5,<br>    "guidance_scale":
          1,<br>    "negative_prompt": "",<br>    "grammar_string": "",<br>    "banned_tokens":
          "",<br>    "type": "ooba",<br>    "rep_pen_size": 0,<br>    "genamt": 500,<br>    "max_length":
          8192<br>}</p>

          '
        raw: "I'll see what I can do. I really need to get more disk space. I have\
          \ to delete the full-precision weights as I go to make space for the next\
          \ experiment. I already deleted the FP weights for dolphin-xwin-airoboros_peft\
          \ and xwin-stellarbright-airoboros_peft, but I made another variant of xwin-stellarbright\
          \ that includes limarp and Kimiko in addition to the airoboros LoRA. It's\
          \ good and I'll be uploading it soon. I might get the full weights up too.\n\
          \nWith these StellarBright merges, I'm finding that they seem to perform\
          \ better at a temperature lower than I'm accustomed to using for my sampler\
          \ settings. I'm also finding some success with setting Presence Penalty\
          \ to some value between 0.2 and 1.0, and even Frequency Penalty has been\
          \ interesting. Below is a snapshot of my current sampler settings, just\
          \ what I'm running tonight as I experiment. I normally don't mess with Frequency\
          \ Penalty, but it's interesting. Either set it to 0 (the default) or 0.01,\
          \ anything else gets weird or downright incoherent very quickly. I recommend\
          \ trying Frequency Penalty at 0.01 to see if you like that output better.\
          \ Presence Penalty is like another form of repetition penalty that can help\
          \ cut down on repetition, especially of the same phrases that appear in\
          \ the input (i.e. earlier in the chat).\n\n{\n    \"temp\": 0.55,\n    \"\
          top_p\": 1,\n    \"top_k\": 0,\n    \"top_a\": 0,\n    \"tfs\": 1,\n   \
          \ \"epsilon_cutoff\": 0,\n    \"eta_cutoff\": 0,\n    \"typical_p\": 1,\n\
          \    \"rep_pen\": 1.07,\n    \"rep_pen_range\": 0,\n    \"no_repeat_ngram_size\"\
          : 0,\n    \"penalty_alpha\": 0,\n    \"num_beams\": 1,\n    \"length_penalty\"\
          : 1,\n    \"min_length\": 0,\n    \"encoder_rep_pen\": 1,\n    \"freq_pen\"\
          : 0.01,\n    \"presence_pen\": 0.2,\n    \"do_sample\": true,\n    \"early_stopping\"\
          : false,\n    \"add_bos_token\": true,\n    \"truncation_length\": 2048,\n\
          \    \"ban_eos_token\": false,\n    \"skip_special_tokens\": true,\n   \
          \ \"streaming\": true,\n    \"mirostat_mode\": 2,\n    \"mirostat_tau\"\
          : 5,\n    \"mirostat_eta\": 0.5,\n    \"guidance_scale\": 1,\n    \"negative_prompt\"\
          : \"\",\n    \"grammar_string\": \"\",\n    \"banned_tokens\": \"\",\n \
          \   \"type\": \"ooba\",\n    \"rep_pen_size\": 0,\n    \"genamt\": 500,\n\
          \    \"max_length\": 8192\n}"
        updatedAt: '2023-11-10T06:36:50.336Z'
      numEdits: 0
      reactions: []
    id: 654dcf822fdbbde41e7a30f7
    type: comment
  author: sophosympatheia
  content: "I'll see what I can do. I really need to get more disk space. I have to\
    \ delete the full-precision weights as I go to make space for the next experiment.\
    \ I already deleted the FP weights for dolphin-xwin-airoboros_peft and xwin-stellarbright-airoboros_peft,\
    \ but I made another variant of xwin-stellarbright that includes limarp and Kimiko\
    \ in addition to the airoboros LoRA. It's good and I'll be uploading it soon.\
    \ I might get the full weights up too.\n\nWith these StellarBright merges, I'm\
    \ finding that they seem to perform better at a temperature lower than I'm accustomed\
    \ to using for my sampler settings. I'm also finding some success with setting\
    \ Presence Penalty to some value between 0.2 and 1.0, and even Frequency Penalty\
    \ has been interesting. Below is a snapshot of my current sampler settings, just\
    \ what I'm running tonight as I experiment. I normally don't mess with Frequency\
    \ Penalty, but it's interesting. Either set it to 0 (the default) or 0.01, anything\
    \ else gets weird or downright incoherent very quickly. I recommend trying Frequency\
    \ Penalty at 0.01 to see if you like that output better. Presence Penalty is like\
    \ another form of repetition penalty that can help cut down on repetition, especially\
    \ of the same phrases that appear in the input (i.e. earlier in the chat).\n\n\
    {\n    \"temp\": 0.55,\n    \"top_p\": 1,\n    \"top_k\": 0,\n    \"top_a\": 0,\n\
    \    \"tfs\": 1,\n    \"epsilon_cutoff\": 0,\n    \"eta_cutoff\": 0,\n    \"typical_p\"\
    : 1,\n    \"rep_pen\": 1.07,\n    \"rep_pen_range\": 0,\n    \"no_repeat_ngram_size\"\
    : 0,\n    \"penalty_alpha\": 0,\n    \"num_beams\": 1,\n    \"length_penalty\"\
    : 1,\n    \"min_length\": 0,\n    \"encoder_rep_pen\": 1,\n    \"freq_pen\": 0.01,\n\
    \    \"presence_pen\": 0.2,\n    \"do_sample\": true,\n    \"early_stopping\"\
    : false,\n    \"add_bos_token\": true,\n    \"truncation_length\": 2048,\n   \
    \ \"ban_eos_token\": false,\n    \"skip_special_tokens\": true,\n    \"streaming\"\
    : true,\n    \"mirostat_mode\": 2,\n    \"mirostat_tau\": 5,\n    \"mirostat_eta\"\
    : 0.5,\n    \"guidance_scale\": 1,\n    \"negative_prompt\": \"\",\n    \"grammar_string\"\
    : \"\",\n    \"banned_tokens\": \"\",\n    \"type\": \"ooba\",\n    \"rep_pen_size\"\
    : 0,\n    \"genamt\": 500,\n    \"max_length\": 8192\n}"
  created_at: 2023-11-10 06:36:50+00:00
  edited: false
  hidden: false
  id: 654dcf822fdbbde41e7a30f7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/jiBJzFDGtCMsOt7U3czoG.png?w=200&h=200&f=face
      fullname: Ks
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ks01
      type: user
    createdAt: '2023-11-10T07:05:46.000Z'
    data:
      edited: false
      editors:
      - Ks01
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9672989249229431
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/jiBJzFDGtCMsOt7U3czoG.png?w=200&h=200&f=face
          fullname: Ks
          isHf: false
          isPro: false
          name: Ks01
          type: user
        html: '<p>Lzlv also worked fine when I cranked up the repetition penalty.<br>But
          I usually do not set it high since I like to test models on complex prompts
          that contain status. And the model tends to not write what they should when
          I crank it up.</p>

          <p>I will try the setting recommended next time. And your models are definitely
          getting better.<br>Cheers for your work!</p>

          '
        raw: 'Lzlv also worked fine when I cranked up the repetition penalty.

          But I usually do not set it high since I like to test models on complex
          prompts that contain status. And the model tends to not write what they
          should when I crank it up.


          I will try the setting recommended next time. And your models are definitely
          getting better.

          Cheers for your work!'
        updatedAt: '2023-11-10T07:05:46.771Z'
      numEdits: 0
      reactions: []
    id: 654dd64a226325e6ecea7a9c
    type: comment
  author: Ks01
  content: 'Lzlv also worked fine when I cranked up the repetition penalty.

    But I usually do not set it high since I like to test models on complex prompts
    that contain status. And the model tends to not write what they should when I
    crank it up.


    I will try the setting recommended next time. And your models are definitely getting
    better.

    Cheers for your work!'
  created_at: 2023-11-10 07:05:46+00:00
  edited: false
  hidden: false
  id: 654dd64a226325e6ecea7a9c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b4b108103617b0a5b0f6f5/A5P1pKfMv5KhGvnpfo21G.png?w=200&h=200&f=face
      fullname: Sophosympatheia
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sophosympatheia
      type: user
    createdAt: '2023-11-10T19:05:24.000Z'
    data:
      edited: false
      editors:
      - sophosympatheia
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.936066210269928
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b4b108103617b0a5b0f6f5/A5P1pKfMv5KhGvnpfo21G.png?w=200&h=200&f=face
          fullname: Sophosympatheia
          isHf: false
          isPro: false
          name: sophosympatheia
          type: user
        html: '<p>Thanks, Ks01. It has been fun experimenting and seeing the resultant
          blends becoming better. Keep the reviews coming and let me know if you find
          any other 70b models that perform well for instruction following, complex
          prompts, etc. Or maybe we''ll get lucky and Xwin 70b v0.2 will be a total
          beast and elevate these blends to a new level.</p>

          '
        raw: Thanks, Ks01. It has been fun experimenting and seeing the resultant
          blends becoming better. Keep the reviews coming and let me know if you find
          any other 70b models that perform well for instruction following, complex
          prompts, etc. Or maybe we'll get lucky and Xwin 70b v0.2 will be a total
          beast and elevate these blends to a new level.
        updatedAt: '2023-11-10T19:05:24.407Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Ks01
    id: 654e7ef4714135794eaf228b
    type: comment
  author: sophosympatheia
  content: Thanks, Ks01. It has been fun experimenting and seeing the resultant blends
    becoming better. Keep the reviews coming and let me know if you find any other
    70b models that perform well for instruction following, complex prompts, etc.
    Or maybe we'll get lucky and Xwin 70b v0.2 will be a total beast and elevate these
    blends to a new level.
  created_at: 2023-11-10 19:05:24+00:00
  edited: false
  hidden: false
  id: 654e7ef4714135794eaf228b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: sophosympatheia/dolphin-xwin-airoboros_peft-70b
repo_type: model
status: open
target_branch: null
title: Review of both dolphin-xwin-airoboros_peft and  xwin-stellarbright-airoboros_peft
