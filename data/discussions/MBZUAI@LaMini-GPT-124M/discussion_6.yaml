!!python/object:huggingface_hub.community.DiscussionWithDetails
author: szhf
conflicting_files: null
created_at: 2023-06-09 02:13:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7f692e65b59b05f159ce2fe7ebc7bec0.svg
      fullname: SunZhifan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: szhf
      type: user
    createdAt: '2023-06-09T03:13:47.000Z'
    data:
      edited: false
      editors:
      - szhf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7927424311637878
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7f692e65b59b05f159ce2fe7ebc7bec0.svg
          fullname: SunZhifan
          isHf: false
          isPro: false
          name: szhf
          type: user
        html: '<h2 id="i-tried-to-download-the-model-with-the-codes">I tried to download
          the model with the codes:</h2>

          <h2 id="model--automodelforcausallmfrom_pretrainedlamini-gpt-124m">model
          = AutoModelForCausalLM.from_pretrained("LaMini-GPT-124M")</h2>

          <p>And it says:<br>OSError: LaMini-GPT-124M is not a local folder and is
          not a valid model identifier listed on ''<a href="https://huggingface.co/models''">https://huggingface.co/models''</a><br>If
          this is a private repository, make sure to pass a token having permission
          to this repo with <code>use_auth_token</code> or log in with <code>huggingface-cli
          login</code> and pass <code>use_auth_token=True</code>.</p>

          <p>How should I fix this issue?<br>Thank you in advance!</p>

          '
        raw: "I tried to download the model with the codes:\r\n----\r\nmodel = AutoModelForCausalLM.from_pretrained(\"\
          LaMini-GPT-124M\")\r\n-----\r\nAnd it says: \r\nOSError: LaMini-GPT-124M\
          \ is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\r\
          \nIf this is a private repository, make sure to pass a token having permission\
          \ to this repo with `use_auth_token` or log in with `huggingface-cli login`\
          \ and pass `use_auth_token=True`.\r\n\r\nHow should I fix this issue? \r\
          \nThank you in advance!"
        updatedAt: '2023-06-09T03:13:47.477Z'
      numEdits: 0
      reactions: []
    id: 648298eb5f581f45184c387e
    type: comment
  author: szhf
  content: "I tried to download the model with the codes:\r\n----\r\nmodel = AutoModelForCausalLM.from_pretrained(\"\
    LaMini-GPT-124M\")\r\n-----\r\nAnd it says: \r\nOSError: LaMini-GPT-124M is not\
    \ a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\r\
    \nIf this is a private repository, make sure to pass a token having permission\
    \ to this repo with `use_auth_token` or log in with `huggingface-cli login` and\
    \ pass `use_auth_token=True`.\r\n\r\nHow should I fix this issue? \r\nThank you\
    \ in advance!"
  created_at: 2023-06-09 02:13:47+00:00
  edited: false
  hidden: false
  id: 648298eb5f581f45184c387e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/db64e2d2ed905e4f1c187c046fa2948d.svg
      fullname: Minghao Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: minghaowu
      type: user
    createdAt: '2023-06-09T04:14:00.000Z'
    data:
      edited: false
      editors:
      - minghaowu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.46038180589675903
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/db64e2d2ed905e4f1c187c046fa2948d.svg
          fullname: Minghao Wu
          isHf: false
          isPro: false
          name: minghaowu
          type: user
        html: '<p>You should use <code>model = AutoModelForCausalLM.from_pretrained("MBZUAI/LaMini-GPT-124M")</code></p>

          '
        raw: You should use `model = AutoModelForCausalLM.from_pretrained("MBZUAI/LaMini-GPT-124M")`
        updatedAt: '2023-06-09T04:14:00.150Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - szhf
      relatedEventId: 6482a7083c609184f6de80f3
    id: 6482a7083c609184f6de80f2
    type: comment
  author: minghaowu
  content: You should use `model = AutoModelForCausalLM.from_pretrained("MBZUAI/LaMini-GPT-124M")`
  created_at: 2023-06-09 03:14:00+00:00
  edited: false
  hidden: false
  id: 6482a7083c609184f6de80f2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/db64e2d2ed905e4f1c187c046fa2948d.svg
      fullname: Minghao Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: minghaowu
      type: user
    createdAt: '2023-06-09T04:14:00.000Z'
    data:
      status: closed
    id: 6482a7083c609184f6de80f3
    type: status-change
  author: minghaowu
  created_at: 2023-06-09 03:14:00+00:00
  id: 6482a7083c609184f6de80f3
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: MBZUAI/LaMini-GPT-124M
repo_type: model
status: closed
target_branch: null
title: Cannot access the model
