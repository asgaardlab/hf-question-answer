!!python/object:huggingface_hub.community.DiscussionWithDetails
author: whatever1983
conflicting_files: null
created_at: 2023-10-17 09:36:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b628b91320688dcf2e954c4b22d4a630.svg
      fullname: TS
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: whatever1983
      type: user
    createdAt: '2023-10-17T10:36:43.000Z'
    data:
      edited: false
      editors:
      - whatever1983
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9341200590133667
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b628b91320688dcf2e954c4b22d4a630.svg
          fullname: TS
          isHf: false
          isPro: false
          name: whatever1983
          type: user
        html: '<p>I don''t know why people love the "French" mistral 7B model so much.  It
          is an European approach to be a jack of all trades but master of none model.  Outputs
          are unnatural,  I would definitely use the 13B models instead of 7B.  Look
          at xwin 13B, almost GPT4 level, quantized to Q4K_M, is only 7.9GB.  Even
          phones can just use 4GB model memory to upgrade to 13B.</p>

          <p>Using the Mistral 7B as base(HumanEval = 30ish), I wonder the 80K evol
          instruct would bring it above HumanEval=40.   Why not try Evo-Instruct on
          either Phi-1(already at HumanEval 50.6  or TinyLlama 1.1 to see if you can
          get Human Eval to &gt; 60( which is WizardCoder-13B levels)</p>

          '
        raw: "I don't know why people love the \"French\" mistral 7B model so much.\
          \  It is an European approach to be a jack of all trades but master of none\
          \ model.  Outputs are unnatural,  I would definitely use the 13B models\
          \ instead of 7B.  Look at xwin 13B, almost GPT4 level, quantized to Q4K_M,\
          \ is only 7.9GB.  Even phones can just use 4GB model memory to upgrade to\
          \ 13B.\r\n\r\nUsing the Mistral 7B as base(HumanEval = 30ish), I wonder\
          \ the 80K evol instruct would bring it above HumanEval=40.   Why not try\
          \ Evo-Instruct on either Phi-1(already at HumanEval 50.6  or TinyLlama 1.1\
          \ to see if you can get Human Eval to > 60( which is WizardCoder-13B levels)"
        updatedAt: '2023-10-17T10:36:43.615Z'
      numEdits: 0
      reactions: []
    id: 652e63bb74d1b0d7ff69d2d9
    type: comment
  author: whatever1983
  content: "I don't know why people love the \"French\" mistral 7B model so much.\
    \  It is an European approach to be a jack of all trades but master of none model.\
    \  Outputs are unnatural,  I would definitely use the 13B models instead of 7B.\
    \  Look at xwin 13B, almost GPT4 level, quantized to Q4K_M, is only 7.9GB.  Even\
    \ phones can just use 4GB model memory to upgrade to 13B.\r\n\r\nUsing the Mistral\
    \ 7B as base(HumanEval = 30ish), I wonder the 80K evol instruct would bring it\
    \ above HumanEval=40.   Why not try Evo-Instruct on either Phi-1(already at HumanEval\
    \ 50.6  or TinyLlama 1.1 to see if you can get Human Eval to > 60( which is WizardCoder-13B\
    \ levels)"
  created_at: 2023-10-17 09:36:43+00:00
  edited: false
  hidden: false
  id: 652e63bb74d1b0d7ff69d2d9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/64ac7b4159bd86340458e53d3e30aee2.svg
      fullname: Bumba
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pumba2
      type: user
    createdAt: '2023-10-17T11:20:27.000Z'
    data:
      edited: true
      editors:
      - Pumba2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.766266942024231
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/64ac7b4159bd86340458e53d3e30aee2.svg
          fullname: Bumba
          isHf: false
          isPro: false
          name: Pumba2
          type: user
        html: '<p>Xwin 13b ? You mean xwinLM-13b ?<br>Whats the humaneval for mistral
          code model anyway ?</p>

          '
        raw: 'Xwin 13b ? You mean xwinLM-13b ?

          Whats the humaneval for mistral code model anyway ?'
        updatedAt: '2023-10-17T11:23:24.078Z'
      numEdits: 2
      reactions: []
    id: 652e6dfbed5d17edd768a1c2
    type: comment
  author: Pumba2
  content: 'Xwin 13b ? You mean xwinLM-13b ?

    Whats the humaneval for mistral code model anyway ?'
  created_at: 2023-10-17 10:20:27+00:00
  edited: true
  hidden: false
  id: 652e6dfbed5d17edd768a1c2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63729f35acef705233c87909/2ApbWLasMZLptlSbk9emj.png?w=200&h=200&f=face
      fullname: Kamil
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Nondzu
      type: user
    createdAt: '2023-10-17T11:45:26.000Z'
    data:
      edited: true
      editors:
      - Nondzu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9127759337425232
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63729f35acef705233c87909/2ApbWLasMZLptlSbk9emj.png?w=200&h=200&f=face
          fullname: Kamil
          isHf: false
          isPro: false
          name: Nondzu
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Pumba2&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Pumba2\">@<span class=\"\
          underline\">Pumba2</span></a></span>\n\n\t</span></span> no humaneval atm<br>I\
          \ will work on it today but dunno how to do it yet.</p>\n"
        raw: '@Pumba2 no humaneval atm

          I will work on it today but dunno how to do it yet.'
        updatedAt: '2023-10-17T11:45:40.302Z'
      numEdits: 1
      reactions: []
    id: 652e73d60b13cc07396a52ff
    type: comment
  author: Nondzu
  content: '@Pumba2 no humaneval atm

    I will work on it today but dunno how to do it yet.'
  created_at: 2023-10-17 10:45:26+00:00
  edited: true
  hidden: false
  id: 652e73d60b13cc07396a52ff
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
      fullname: Yatharth  Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YaTharThShaRma999
      type: user
    createdAt: '2023-10-17T14:35:51.000Z'
    data:
      edited: false
      editors:
      - YaTharThShaRma999
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9613112807273865
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
          fullname: Yatharth  Sharma
          isHf: false
          isPro: false
          name: YaTharThShaRma999
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;whatever1983&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/whatever1983\"\
          >@<span class=\"underline\">whatever1983</span></a></span>\n\n\t</span></span>\
          \  its because mistral is \"smarter\" then 13b models. xwin 13b is gpt4level\
          \ in ALPACA eval only. Thats one eval and its a good eval but on other evals\
          \ xwin is lower.</p>\n<p>The model has enough common sense to solve riddles\
          \ that even 13b models have hard time solving. True that 13b llama models\
          \ are probably better for chat and rp but still mistral is coherant and\
          \ actually really well overall compared to other models that excel at one\
          \ taks but suck at another.</p>\n<p>Phi 1.5 is garbage at anything thats\
          \ not \"textbook\" like and tinyllama will not magically reach 60 at humaneval\
          \ even with evol instruct. Its good for its size but still much worse than\
          \ llama 7b.</p>\n<p>The reason wizardcoder has such a high score is because\
          \ it uses codellama not llama. If you trained mistral on the same amount\
          \ of code. 99% it will be better than wizardcoder 13b.</p>\n"
        raw: '@whatever1983  its because mistral is "smarter" then 13b models. xwin
          13b is gpt4level in ALPACA eval only. Thats one eval and its a good eval
          but on other evals xwin is lower.


          The model has enough common sense to solve riddles that even 13b models
          have hard time solving. True that 13b llama models are probably better for
          chat and rp but still mistral is coherant and actually really well overall
          compared to other models that excel at one taks but suck at another.


          Phi 1.5 is garbage at anything thats not "textbook" like and tinyllama will
          not magically reach 60 at humaneval even with evol instruct. Its good for
          its size but still much worse than llama 7b.


          The reason wizardcoder has such a high score is because it uses codellama
          not llama. If you trained mistral on the same amount of code. 99% it will
          be better than wizardcoder 13b.'
        updatedAt: '2023-10-17T14:35:51.607Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - Pumba2
        - Lynxpda
        - YaTharThShaRma999
    id: 652e9bc7f08bb52d9953f907
    type: comment
  author: YaTharThShaRma999
  content: '@whatever1983  its because mistral is "smarter" then 13b models. xwin
    13b is gpt4level in ALPACA eval only. Thats one eval and its a good eval but on
    other evals xwin is lower.


    The model has enough common sense to solve riddles that even 13b models have hard
    time solving. True that 13b llama models are probably better for chat and rp but
    still mistral is coherant and actually really well overall compared to other models
    that excel at one taks but suck at another.


    Phi 1.5 is garbage at anything thats not "textbook" like and tinyllama will not
    magically reach 60 at humaneval even with evol instruct. Its good for its size
    but still much worse than llama 7b.


    The reason wizardcoder has such a high score is because it uses codellama not
    llama. If you trained mistral on the same amount of code. 99% it will be better
    than wizardcoder 13b.'
  created_at: 2023-10-17 13:35:51+00:00
  edited: false
  hidden: false
  id: 652e9bc7f08bb52d9953f907
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63729f35acef705233c87909/2ApbWLasMZLptlSbk9emj.png?w=200&h=200&f=face
      fullname: Kamil
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Nondzu
      type: user
    createdAt: '2023-10-20T15:53:35.000Z'
    data:
      edited: true
      editors:
      - Nondzu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3660505414009094
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63729f35acef705233c87909/2ApbWLasMZLptlSbk9emj.png?w=200&h=200&f=face
          fullname: Kamil
          isHf: false
          isPro: false
          name: Nondzu
          type: user
        html: "<p>I started humaneval testing, </p>\n<pre><code>Nondzu mistral7b-code\
          \ \nBase\n{'pass@1': 0.3353658536585366}\nBase + Extra\n{'pass@1': 0.2804878048780488}\n\
          </code></pre>\n<p> to compare here is original Mistral model tested on the\
          \ same machine </p>\n<pre><code>Mistral 7b\nBase\n{'pass@1': 0.2926829268292683}\n\
          Base + Extra\n{'pass@1': 0.24390243902439024}\n</code></pre>\n<pre><code>python\
          \ codegen/generate.py --bs 1 --temperature 0 --dataset humaneval --model\
          \ mistral-7b --root /root/kamil/workdir  --resume    --greedy\n</code></pre>\n\
          <p>I will do test for 200 examples and few temperature settings</p>\n<p><a\
          \ rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/63729f35acef705233c87909/iQzuE74GNaDuiVRsRwAry.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/63729f35acef705233c87909/iQzuE74GNaDuiVRsRwAry.png\"\
          ></a></p>\n"
        raw: "\nI started humaneval testing, \n\n```\nNondzu mistral7b-code \nBase\n\
          {'pass@1': 0.3353658536585366}\nBase + Extra\n{'pass@1': 0.2804878048780488}\n\
          ```\n to compare here is original Mistral model tested on the same machine\
          \ \n```\nMistral 7b\nBase\n{'pass@1': 0.2926829268292683}\nBase + Extra\n\
          {'pass@1': 0.24390243902439024}\n```\n```\npython codegen/generate.py --bs\
          \ 1 --temperature 0 --dataset humaneval --model mistral-7b --root /root/kamil/workdir\
          \  --resume    --greedy\n\n```\n\nI will do test for 200 examples and few\
          \ temperature settings\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63729f35acef705233c87909/iQzuE74GNaDuiVRsRwAry.png)\n"
        updatedAt: '2023-10-20T15:57:38.563Z'
      numEdits: 2
      reactions: []
    id: 6532a27fe778506c5bda19e2
    type: comment
  author: Nondzu
  content: "\nI started humaneval testing, \n\n```\nNondzu mistral7b-code \nBase\n\
    {'pass@1': 0.3353658536585366}\nBase + Extra\n{'pass@1': 0.2804878048780488}\n\
    ```\n to compare here is original Mistral model tested on the same machine \n\
    ```\nMistral 7b\nBase\n{'pass@1': 0.2926829268292683}\nBase + Extra\n{'pass@1':\
    \ 0.24390243902439024}\n```\n```\npython codegen/generate.py --bs 1 --temperature\
    \ 0 --dataset humaneval --model mistral-7b --root /root/kamil/workdir  --resume\
    \    --greedy\n\n```\n\nI will do test for 200 examples and few temperature settings\n\
    \n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63729f35acef705233c87909/iQzuE74GNaDuiVRsRwAry.png)\n"
  created_at: 2023-10-20 14:53:35+00:00
  edited: true
  hidden: false
  id: 6532a27fe778506c5bda19e2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Nondzu/Mistral-7B-code-16k-qlora
repo_type: model
status: open
target_branch: null
title: Human Eval and Human Eval-X score?
