!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lk99
conflicting_files: null
created_at: 2023-09-12 00:52:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acccb18cca8b86866ad9af0e048a8443.svg
      fullname: lucky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lk99
      type: user
    createdAt: '2023-09-12T01:52:00.000Z'
    data:
      edited: false
      editors:
      - lk99
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.34438851475715637
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acccb18cca8b86866ad9af0e048a8443.svg
          fullname: lucky
          isHf: false
          isPro: false
          name: lk99
          type: user
        html: "<p>images = pipe(prompt, height=args.height, width=args.height, num_inference_steps=args.num_steps,guidance_scale=args.guidance_scale,\
          \ negative_prompt=ne_prompt,num_images_per_prompt=args.num_images, generator=generator)</p>\n\
          <p>When I use multiple prompts to generate images, I traverse to the second\
          \ prompt, and after reasoning to the end, an error will be reported here.</p>\n\
          <p>Loading pipeline components...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7\
          \ [00:01&lt;00:00,  6.95it/s]100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588| 15/15 [00:26&lt;00:00,  1.79s/it]100%|\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:26&lt;00:00,\
          \  1.78s/it]172.16.139.155 - - [12/Sep/2023 09:45:35] \"GET /animagine/gen/ani.txt\
          \ HTTP/1.1\" 500 -<br>Traceback (most recent call last):<br>  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
          , line 2552, in <strong>call</strong><br>    return self.wsgi_app(environ,\
          \ start_response)<br>  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
          , line 2532, in wsgi_app<br>    response = self.handle_exception(e)<br>\
          \  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
          , line 2529, in wsgi_app<br>    response = self.full_dispatch_request()<br>\
          \  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
          , line 1825, in full_dispatch_request<br>    rv = self.handle_user_exception(e)<br>\
          \  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
          , line 1823, in full_dispatch_request<br>    rv = self.dispatch_request()<br>\
          \  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
          , line 1799, in dispatch_request<br>    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)<br>\
          \  File \"/home/w505/AIGC/AIGC_diffusers_0911/diffusers_generator_server_0908.py\"\
          , line 47, in generator_animagine_img<br>    return generator_images(file_name,\
          \ model_name, args)<br>  File \"/home/w505/AIGC/AIGC_diffusers_0911/aigc_model.py\"\
          , line 90, in generator_images<br>    num_images_per_prompt=args.num_images,\
          \ generator=generator<br>  File \"/anaconda/envs/505/lib/python3.7/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context<br>    return func(*args, **kwargs)<br> \
          \ File \"/anaconda/envs/505/lib/python3.7/site-packages/diffusers-0.21.0.dev0-py3.7.egg/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py\"\
          , line 845, in <strong>call</strong><br>    image = self.vae.decode(latents\
          \ / self.vae.config.scaling_factor, return_dict=False)[0]<br>  File \"/anaconda/envs/505/lib/python3.7/site-packages/diffusers-0.21.0.dev0-py3.7.egg/diffusers/utils/accelerate_utils.py\"\
          , line 46, in wrapper<br>    return method(self, *args, **kwargs)<br>  File\
          \ \"/anaconda/envs/505/lib/python3.7/site-packages/diffusers-0.21.0.dev0-py3.7.egg/diffusers/models/autoencoder_kl.py\"\
          , line 270, in decode<br>    decoded = self._decode(z).sample<br>  File\
          \ \"/anaconda/envs/505/lib/python3.7/site-packages/diffusers-0.21.0.dev0-py3.7.egg/diffusers/models/autoencoder_kl.py\"\
          , line 256, in _decode<br>    z = self.post_quant_conv(z)<br>  File \"/anaconda/envs/505/lib/python3.7/site-packages/torch/nn/modules/module.py\"\
          , line 1194, in _call_impl<br>    return forward_call(*input, **kwargs)<br>\
          \  File \"/anaconda/envs/505/lib/python3.7/site-packages/torch/nn/modules/conv.py\"\
          , line 463, in forward<br>    return self._conv_forward(input, self.weight,\
          \ self.bias)<br>  File \"/anaconda/envs/505/lib/python3.7/site-packages/torch/nn/modules/conv.py\"\
          , line 460, in _conv_forward<br>    self.padding, self.dilation, self.groups)<br>RuntimeError:\
          \ Input type (c10::Half) and bias type (float) should be the same</p>\n"
        raw: "images = pipe(prompt, height=args.height, width=args.height, num_inference_steps=args.num_steps,guidance_scale=args.guidance_scale,\
          \ negative_prompt=ne_prompt,num_images_per_prompt=args.num_images, generator=generator)\r\
          \n\r\nWhen I use multiple prompts to generate images, I traverse to the\
          \ second prompt, and after reasoning to the end, an error will be reported\
          \ here.\r\n\r\nLoading pipeline components...: 100%|\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588| 7/7 [00:01<00:00,  6.95it/s]100%|\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588| 15/15 [00:26<00:00,  1.79s/it]100%|\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:26<00:00,\
          \  1.78s/it]172.16.139.155 - - [12/Sep/2023 09:45:35] \"GET /animagine/gen/ani.txt\
          \ HTTP/1.1\" 500 -\r\nTraceback (most recent call last):\r\n  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
          , line 2552, in __call__\r\n    return self.wsgi_app(environ, start_response)\r\
          \n  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
          , line 2532, in wsgi_app\r\n    response = self.handle_exception(e)\r\n\
          \  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
          , line 2529, in wsgi_app\r\n    response = self.full_dispatch_request()\r\
          \n  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
          , line 1825, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\
          \n  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
          , line 1823, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\
          \n  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
          , line 1799, in dispatch_request\r\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\r\
          \n  File \"/home/w505/AIGC/AIGC_diffusers_0911/diffusers_generator_server_0908.py\"\
          , line 47, in generator_animagine_img\r\n    return generator_images(file_name,\
          \ model_name, args)\r\n  File \"/home/w505/AIGC/AIGC_diffusers_0911/aigc_model.py\"\
          , line 90, in generator_images\r\n    num_images_per_prompt=args.num_images,\
          \ generator=generator\r\n  File \"/anaconda/envs/505/lib/python3.7/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context\r\n    return func(*args, **kwargs)\r\n \
          \ File \"/anaconda/envs/505/lib/python3.7/site-packages/diffusers-0.21.0.dev0-py3.7.egg/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py\"\
          , line 845, in __call__\r\n    image = self.vae.decode(latents / self.vae.config.scaling_factor,\
          \ return_dict=False)[0]\r\n  File \"/anaconda/envs/505/lib/python3.7/site-packages/diffusers-0.21.0.dev0-py3.7.egg/diffusers/utils/accelerate_utils.py\"\
          , line 46, in wrapper\r\n    return method(self, *args, **kwargs)\r\n  File\
          \ \"/anaconda/envs/505/lib/python3.7/site-packages/diffusers-0.21.0.dev0-py3.7.egg/diffusers/models/autoencoder_kl.py\"\
          , line 270, in decode\r\n    decoded = self._decode(z).sample\r\n  File\
          \ \"/anaconda/envs/505/lib/python3.7/site-packages/diffusers-0.21.0.dev0-py3.7.egg/diffusers/models/autoencoder_kl.py\"\
          , line 256, in _decode\r\n    z = self.post_quant_conv(z)\r\n  File \"/anaconda/envs/505/lib/python3.7/site-packages/torch/nn/modules/module.py\"\
          , line 1194, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/anaconda/envs/505/lib/python3.7/site-packages/torch/nn/modules/conv.py\"\
          , line 463, in forward\r\n    return self._conv_forward(input, self.weight,\
          \ self.bias)\r\n  File \"/anaconda/envs/505/lib/python3.7/site-packages/torch/nn/modules/conv.py\"\
          , line 460, in _conv_forward\r\n    self.padding, self.dilation, self.groups)\r\
          \nRuntimeError: Input type (c10::Half) and bias type (float) should be the\
          \ same"
        updatedAt: '2023-09-12T01:52:00.989Z'
      numEdits: 0
      reactions: []
    id: 64ffc440520f8d7b4dee7c1e
    type: comment
  author: lk99
  content: "images = pipe(prompt, height=args.height, width=args.height, num_inference_steps=args.num_steps,guidance_scale=args.guidance_scale,\
    \ negative_prompt=ne_prompt,num_images_per_prompt=args.num_images, generator=generator)\r\
    \n\r\nWhen I use multiple prompts to generate images, I traverse to the second\
    \ prompt, and after reasoning to the end, an error will be reported here.\r\n\r\
    \nLoading pipeline components...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:01<00:00,  6.95it/s]100%|\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588| 15/15 [00:26<00:00,  1.79s/it]100%|\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588| 15/15 [00:26<00:00,  1.78s/it]172.16.139.155 - - [12/Sep/2023 09:45:35]\
    \ \"GET /animagine/gen/ani.txt HTTP/1.1\" 500 -\r\nTraceback (most recent call\
    \ last):\r\n  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
    , line 2552, in __call__\r\n    return self.wsgi_app(environ, start_response)\r\
    \n  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\", line\
    \ 2532, in wsgi_app\r\n    response = self.handle_exception(e)\r\n  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
    , line 2529, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File\
    \ \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\", line 1825,\
    \ in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File\
    \ \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\", line 1823,\
    \ in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"/anaconda/envs/505/lib/python3.7/site-packages/flask/app.py\"\
    , line 1799, in dispatch_request\r\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\r\
    \n  File \"/home/w505/AIGC/AIGC_diffusers_0911/diffusers_generator_server_0908.py\"\
    , line 47, in generator_animagine_img\r\n    return generator_images(file_name,\
    \ model_name, args)\r\n  File \"/home/w505/AIGC/AIGC_diffusers_0911/aigc_model.py\"\
    , line 90, in generator_images\r\n    num_images_per_prompt=args.num_images, generator=generator\r\
    \n  File \"/anaconda/envs/505/lib/python3.7/site-packages/torch/autograd/grad_mode.py\"\
    , line 27, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"\
    /anaconda/envs/505/lib/python3.7/site-packages/diffusers-0.21.0.dev0-py3.7.egg/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py\"\
    , line 845, in __call__\r\n    image = self.vae.decode(latents / self.vae.config.scaling_factor,\
    \ return_dict=False)[0]\r\n  File \"/anaconda/envs/505/lib/python3.7/site-packages/diffusers-0.21.0.dev0-py3.7.egg/diffusers/utils/accelerate_utils.py\"\
    , line 46, in wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"\
    /anaconda/envs/505/lib/python3.7/site-packages/diffusers-0.21.0.dev0-py3.7.egg/diffusers/models/autoencoder_kl.py\"\
    , line 270, in decode\r\n    decoded = self._decode(z).sample\r\n  File \"/anaconda/envs/505/lib/python3.7/site-packages/diffusers-0.21.0.dev0-py3.7.egg/diffusers/models/autoencoder_kl.py\"\
    , line 256, in _decode\r\n    z = self.post_quant_conv(z)\r\n  File \"/anaconda/envs/505/lib/python3.7/site-packages/torch/nn/modules/module.py\"\
    , line 1194, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/anaconda/envs/505/lib/python3.7/site-packages/torch/nn/modules/conv.py\"\
    , line 463, in forward\r\n    return self._conv_forward(input, self.weight, self.bias)\r\
    \n  File \"/anaconda/envs/505/lib/python3.7/site-packages/torch/nn/modules/conv.py\"\
    , line 460, in _conv_forward\r\n    self.padding, self.dilation, self.groups)\r\
    \nRuntimeError: Input type (c10::Half) and bias type (float) should be the same"
  created_at: 2023-09-12 00:52:00+00:00
  edited: false
  hidden: false
  id: 64ffc440520f8d7b4dee7c1e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63c09b32dd793d5a62895a95/27FwQlh3am6xCh9f1mExM.jpeg?w=200&h=200&f=face
      fullname: Duskfall Crew
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Duskfallcrew
      type: user
    createdAt: '2023-09-12T10:55:11.000Z'
    data:
      edited: false
      editors:
      - Duskfallcrew
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9965602159500122
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63c09b32dd793d5a62895a95/27FwQlh3am6xCh9f1mExM.jpeg?w=200&h=200&f=face
          fullname: Duskfall Crew
          isHf: false
          isPro: false
          name: Duskfallcrew
          type: user
        html: '<p>That''s an A1111 issue not the model, i''ve had that with SDXL models
          that aren''t this one as weell it''s a python/UI isue i think</p>

          '
        raw: That's an A1111 issue not the model, i've had that with SDXL models that
          aren't this one as weell it's a python/UI isue i think
        updatedAt: '2023-09-12T10:55:11.102Z'
      numEdits: 0
      reactions: []
    id: 6500438fe0c94282ab3d7752
    type: comment
  author: Duskfallcrew
  content: That's an A1111 issue not the model, i've had that with SDXL models that
    aren't this one as weell it's a python/UI isue i think
  created_at: 2023-09-12 09:55:11+00:00
  edited: false
  hidden: false
  id: 6500438fe0c94282ab3d7752
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Linaqruf/pastel-anime-xl-lora
repo_type: model
status: open
target_branch: null
title: 'RuntimeError: Input type (c10::Half) and bias type (float) should be the same'
