!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mirek190
conflicting_files: null
created_at: 2023-09-01 15:13:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-09-01T16:13:30.000Z'
    data:
      edited: true
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6946535110473633
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>How to use 128k context using llamacpp?</p>

          '
        raw: How to use 128k context using llamacpp?
        updatedAt: '2023-09-01T16:13:43.969Z'
      numEdits: 1
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - dillfrescott
        - wmsmigiel
        - tachyphylaxis
    id: 64f20daaf4543001098b9d37
    type: comment
  author: mirek190
  content: How to use 128k context using llamacpp?
  created_at: 2023-09-01 15:13:30+00:00
  edited: true
  hidden: false
  id: 64f20daaf4543001098b9d37
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
      fullname: Cross Nastasi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dillfrescott
      type: user
    createdAt: '2023-09-01T20:02:20.000Z'
    data:
      edited: false
      editors:
      - dillfrescott
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9975732564926147
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
          fullname: Cross Nastasi
          isHf: false
          isPro: false
          name: dillfrescott
          type: user
        html: '<p>I would also like to know, as the example in the readme only has
          4096 set as the ctx length.</p>

          '
        raw: I would also like to know, as the example in the readme only has 4096
          set as the ctx length.
        updatedAt: '2023-09-01T20:02:20.821Z'
      numEdits: 0
      reactions: []
    id: 64f2434c9b0e5c0cc91afdb0
    type: comment
  author: dillfrescott
  content: I would also like to know, as the example in the readme only has 4096 set
    as the ctx length.
  created_at: 2023-09-01 19:02:20+00:00
  edited: false
  hidden: false
  id: 64f2434c9b0e5c0cc91afdb0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/UjVzo2J3imLBM9GCmN9q_.png?w=200&h=200&f=face
      fullname: Erik Scholz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Green-Sky
      type: user
    createdAt: '2023-09-03T17:03:58.000Z'
    data:
      edited: false
      editors:
      - Green-Sky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8909701704978943
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/UjVzo2J3imLBM9GCmN9q_.png?w=200&h=200&f=face
          fullname: Erik Scholz
          isHf: false
          isPro: false
          name: Green-Sky
          type: user
        html: '<p>llama.cpp currently does not support the yarn rope scaler.</p>

          '
        raw: llama.cpp currently does not support the yarn rope scaler.
        updatedAt: '2023-09-03T17:03:58.550Z'
      numEdits: 0
      reactions: []
    id: 64f4bc7e611fd5f14b2186d1
    type: comment
  author: Green-Sky
  content: llama.cpp currently does not support the yarn rope scaler.
  created_at: 2023-09-03 16:03:58+00:00
  edited: false
  hidden: false
  id: 64f4bc7e611fd5f14b2186d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/921171db37d397559d875d3d49a64a3f.svg
      fullname: Jopaul Jose
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DarkCoverUnleashed
      type: user
    createdAt: '2023-09-03T18:13:35.000Z'
    data:
      edited: true
      editors:
      - DarkCoverUnleashed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8595370054244995
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/921171db37d397559d875d3d49a64a3f.svg
          fullname: Jopaul Jose
          isHf: false
          isPro: false
          name: DarkCoverUnleashed
          type: user
        html: '<blockquote>

          <p>llama.cpp currently does not support the yarn rope scaler.</p>

          </blockquote>

          <p>So how exactly can we use this models 128k context? </p>

          '
        raw: '> llama.cpp currently does not support the yarn rope scaler.


          So how exactly can we use this models 128k context? '
        updatedAt: '2023-09-03T18:13:55.969Z'
      numEdits: 1
      reactions: []
    id: 64f4cccfa3cfde60ac00a543
    type: comment
  author: DarkCoverUnleashed
  content: '> llama.cpp currently does not support the yarn rope scaler.


    So how exactly can we use this models 128k context? '
  created_at: 2023-09-03 17:13:35+00:00
  edited: true
  hidden: false
  id: 64f4cccfa3cfde60ac00a543
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/UjVzo2J3imLBM9GCmN9q_.png?w=200&h=200&f=face
      fullname: Erik Scholz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Green-Sky
      type: user
    createdAt: '2023-09-04T12:59:27.000Z'
    data:
      edited: false
      editors:
      - Green-Sky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8609974384307861
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/UjVzo2J3imLBM9GCmN9q_.png?w=200&h=200&f=face
          fullname: Erik Scholz
          isHf: false
          isPro: false
          name: Green-Sky
          type: user
        html: "<blockquote>\n<p>So how exactly can we use this models 128k context?\
          \ </p>\n</blockquote>\n<p>you dont. <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ , there is currently no way to use this model(file) that i am aware of.</p>\n"
        raw: "> So how exactly can we use this models 128k context? \n\nyou dont.\
          \ @TheBloke , there is currently no way to use this model(file) that i am\
          \ aware of."
        updatedAt: '2023-09-04T12:59:27.825Z'
      numEdits: 0
      reactions: []
    id: 64f5d4af114fb4b910f19792
    type: comment
  author: Green-Sky
  content: "> So how exactly can we use this models 128k context? \n\nyou dont. @TheBloke\
    \ , there is currently no way to use this model(file) that i am aware of."
  created_at: 2023-09-04 11:59:27+00:00
  edited: false
  hidden: false
  id: 64f5d4af114fb4b910f19792
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
      fullname: Cross Nastasi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dillfrescott
      type: user
    createdAt: '2023-09-04T22:46:04.000Z'
    data:
      edited: false
      editors:
      - dillfrescott
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9852128624916077
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
          fullname: Cross Nastasi
          isHf: false
          isPro: false
          name: dillfrescott
          type: user
        html: '<p>He should probably put a note at the top of the readme saying that
          there is currently no way to use this</p>

          '
        raw: He should probably put a note at the top of the readme saying that there
          is currently no way to use this
        updatedAt: '2023-09-04T22:46:04.973Z'
      numEdits: 0
      reactions: []
    id: 64f65e2c376094fe6e19b8e3
    type: comment
  author: dillfrescott
  content: He should probably put a note at the top of the readme saying that there
    is currently no way to use this
  created_at: 2023-09-04 21:46:04+00:00
  edited: false
  hidden: false
  id: 64f65e2c376094fe6e19b8e3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1664423184322-noauth.png?w=200&h=200&f=face
      fullname: Collin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: infocyde
      type: user
    createdAt: '2023-09-05T03:30:49.000Z'
    data:
      edited: false
      editors:
      - infocyde
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9617080092430115
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1664423184322-noauth.png?w=200&h=200&f=face
          fullname: Collin
          isHf: false
          isPro: false
          name: infocyde
          type: user
        html: '<p>*can''t use it at it''s current context limit.  I got it working
          with smaller context (defeats the point) but the responses where really
          bad.  But, I''m a noob so I could have been prompting the model incorrectly.  Still
          props for this model being one of the first OS LLMs out the gate with the
          over 100K context window (at least potentially) and I look forward to seeing
          more refinements here.</p>

          '
        raw: '*can''t use it at it''s current context limit.  I got it working with
          smaller context (defeats the point) but the responses where really bad.  But,
          I''m a noob so I could have been prompting the model incorrectly.  Still
          props for this model being one of the first OS LLMs out the gate with the
          over 100K context window (at least potentially) and I look forward to seeing
          more refinements here.'
        updatedAt: '2023-09-05T03:30:49.195Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - dillfrescott
        - Green-Sky
    id: 64f6a0e9e916843d8eccc251
    type: comment
  author: infocyde
  content: '*can''t use it at it''s current context limit.  I got it working with
    smaller context (defeats the point) but the responses where really bad.  But,
    I''m a noob so I could have been prompting the model incorrectly.  Still props
    for this model being one of the first OS LLMs out the gate with the over 100K
    context window (at least potentially) and I look forward to seeing more refinements
    here.'
  created_at: 2023-09-05 02:30:49+00:00
  edited: false
  hidden: false
  id: 64f6a0e9e916843d8eccc251
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/UjVzo2J3imLBM9GCmN9q_.png?w=200&h=200&f=face
      fullname: Erik Scholz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Green-Sky
      type: user
    createdAt: '2023-09-05T18:15:09.000Z'
    data:
      edited: false
      editors:
      - Green-Sky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7207645773887634
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/UjVzo2J3imLBM9GCmN9q_.png?w=200&h=200&f=face
          fullname: Erik Scholz
          isHf: false
          isPro: false
          name: Green-Sky
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/FWEkm38xf7qrKHTvt4asm.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/FWEkm38xf7qrKHTvt4asm.png"></a></p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/tocqSfKxFwsiqRyIi_UIJ.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/tocqSfKxFwsiqRyIi_UIJ.png"></a></p>

          <p>excerpts from <a rel="nofollow" href="https://arxiv.org/abs/2309.00071">their
          paper</a></p>

          <p>looks like for coding tasks, the code llama models perform very well
          for long contexts as is</p>

          '
        raw: '

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/FWEkm38xf7qrKHTvt4asm.png)


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/tocqSfKxFwsiqRyIi_UIJ.png)



          excerpts from [their paper]( https://arxiv.org/abs/2309.00071 )


          looks like for coding tasks, the code llama models perform very well for
          long contexts as is

          '
        updatedAt: '2023-09-05T18:15:09.197Z'
      numEdits: 0
      reactions: []
    id: 64f7702dc3c12b377c7f7991
    type: comment
  author: Green-Sky
  content: '

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/FWEkm38xf7qrKHTvt4asm.png)


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/tocqSfKxFwsiqRyIi_UIJ.png)



    excerpts from [their paper]( https://arxiv.org/abs/2309.00071 )


    looks like for coding tasks, the code llama models perform very well for long
    contexts as is

    '
  created_at: 2023-09-05 17:15:09+00:00
  edited: false
  hidden: false
  id: 64f7702dc3c12b377c7f7991
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/UjVzo2J3imLBM9GCmN9q_.png?w=200&h=200&f=face
      fullname: Erik Scholz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Green-Sky
      type: user
    createdAt: '2023-09-05T18:44:22.000Z'
    data:
      edited: false
      editors:
      - Green-Sky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6816492676734924
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/645ce413a19f3e64bbeece31/UjVzo2J3imLBM9GCmN9q_.png?w=200&h=200&f=face
          fullname: Erik Scholz
          isHf: false
          isPro: false
          name: Green-Sky
          type: user
        html: '<p>pr for yarn (aka ntk v2) <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp/pull/2268">https://github.com/ggerganov/llama.cpp/pull/2268</a></p>

          '
        raw: pr for yarn (aka ntk v2) https://github.com/ggerganov/llama.cpp/pull/2268
        updatedAt: '2023-09-05T18:44:22.483Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - attashe
    id: 64f777064db24c1ca940131e
    type: comment
  author: Green-Sky
  content: pr for yarn (aka ntk v2) https://github.com/ggerganov/llama.cpp/pull/2268
  created_at: 2023-09-05 17:44:22+00:00
  edited: false
  hidden: false
  id: 64f777064db24c1ca940131e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Yarn-Llama-2-13B-128K-GGUF
repo_type: model
status: open
target_branch: null
title: how to use 128k context?
