!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jphme
conflicting_files: null
created_at: 2023-08-03 21:44:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1gCpz_Og6-LyCBXDmuOd1.jpeg?w=200&h=200&f=face
      fullname: Jan Philipp Harries
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jphme
      type: user
    createdAt: '2023-08-03T22:44:11.000Z'
    data:
      edited: false
      editors:
      - jphme
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9215462803840637
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1gCpz_Og6-LyCBXDmuOd1.jpeg?w=200&h=200&f=face
          fullname: Jan Philipp Harries
          isHf: false
          isPro: false
          name: jphme
          type: user
        html: '<p>As orca relies on different system prompts, I was wondering why
          there is no system prompt in your given prompt Template?</p>

          <p>Is that an error? For the webui you mention a "context", where should
          that be placed in the prompt format?</p>

          '
        raw: "As orca relies on different system prompts, I was wondering why there\
          \ is no system prompt in your given prompt Template?\r\n\r\nIs that an error?\
          \ For the webui you mention a \"context\", where should that be placed in\
          \ the prompt format?"
        updatedAt: '2023-08-03T22:44:11.436Z'
      numEdits: 0
      reactions: []
    id: 64cc2dbb4ca74090b9aa056c
    type: comment
  author: jphme
  content: "As orca relies on different system prompts, I was wondering why there\
    \ is no system prompt in your given prompt Template?\r\n\r\nIs that an error?\
    \ For the webui you mention a \"context\", where should that be placed in the\
    \ prompt format?"
  created_at: 2023-08-03 21:44:11+00:00
  edited: false
  hidden: false
  id: 64cc2dbb4ca74090b9aa056c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9441d895e3308a15a50c5dab942454ff.svg
      fullname: Bleys
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: bleysg
      type: user
    createdAt: '2023-08-04T23:39:40.000Z'
    data:
      edited: false
      editors:
      - bleysg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9491639733314514
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9441d895e3308a15a50c5dab942454ff.svg
          fullname: Bleys
          isHf: false
          isPro: true
          name: bleysg
          type: user
        html: '<p>You can give the context immediately preceding the first " User:
          " section. It is analogous to a system prompt.</p>

          '
        raw: 'You can give the context immediately preceding the first " User: " section.
          It is analogous to a system prompt.'
        updatedAt: '2023-08-04T23:39:40.753Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64cd8c3ce13e7c2bc571eeff
    id: 64cd8c3ce13e7c2bc571eefd
    type: comment
  author: bleysg
  content: 'You can give the context immediately preceding the first " User: " section.
    It is analogous to a system prompt.'
  created_at: 2023-08-04 22:39:40+00:00
  edited: false
  hidden: false
  id: 64cd8c3ce13e7c2bc571eefd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9441d895e3308a15a50c5dab942454ff.svg
      fullname: Bleys
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: bleysg
      type: user
    createdAt: '2023-08-04T23:39:40.000Z'
    data:
      status: closed
    id: 64cd8c3ce13e7c2bc571eeff
    type: status-change
  author: bleysg
  created_at: 2023-08-04 22:39:40+00:00
  id: 64cd8c3ce13e7c2bc571eeff
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1gCpz_Og6-LyCBXDmuOd1.jpeg?w=200&h=200&f=face
      fullname: Jan Philipp Harries
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jphme
      type: user
    createdAt: '2023-08-05T08:58:22.000Z'
    data:
      edited: true
      editors:
      - jphme
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9429464936256409
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1gCpz_Og6-LyCBXDmuOd1.jpeg?w=200&h=200&f=face
          fullname: Jan Philipp Harries
          isHf: false
          isPro: false
          name: jphme
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;bleysg&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/bleysg\">@<span class=\"\
          underline\">bleysg</span></a></span>\n\n\t</span></span> thanks for your\
          \ answer.<br>I suppose there should be 2 line breaks after the context like\
          \ in other similar prompt templates?</p>\n<p>It would be nice if you would\
          \ add an example (string and/or tokenization) for this as you write yourself\
          \ \"The model is heavily conditioned to work using this format only\" and\
          \ I also experienced degradation just due to missing/wrong separators.<br>Many\
          \ thanks!</p>\n<p>Edit: found that in the example Gradio Space, I guess\
          \ this is the correct format then, with 2 line breaks as expected? Would\
          \ make sense to add that to the Model card imho:</p>\n<blockquote>\n<p>messages\
          \ = BASE_SYSTEM_MESSAGE + system_message.strip() + \"\\n\" + <br>      \
          \         \"\\n\".join([\"\\n\".join([\"User: \"+item[0]+\"&lt;|end_of_turn|&gt;\"\
          , \"Assistant: \"+item[1]+\"&lt;|end_of_turn|&gt;\"])<br>              \
          \            for item in history])</p>\n</blockquote>\n<p>Edit2: actually\
          \ this is just one line break and no free line after the system prpmpt,\
          \ misred the 2 loops... So a deviation from the prompt format which is used\
          \ by many other models.</p>\n"
        raw: "Hi @bleysg thanks for your answer. \nI suppose there should be 2 line\
          \ breaks after the context like in other similar prompt templates?\n\nIt\
          \ would be nice if you would add an example (string and/or tokenization)\
          \ for this as you write yourself \"The model is heavily conditioned to work\
          \ using this format only\" and I also experienced degradation just due to\
          \ missing/wrong separators.\nMany thanks!\n\nEdit: found that in the example\
          \ Gradio Space, I guess this is the correct format then, with 2 line breaks\
          \ as expected? Would make sense to add that to the Model card imho:\n\n\
          > messages = BASE_SYSTEM_MESSAGE + system_message.strip() + \"\\n\" + \\\
          \n               \"\\n\".join([\"\\n\".join([\"User: \"+item[0]+\"<|end_of_turn|>\"\
          , \"Assistant: \"+item[1]+\"<|end_of_turn|>\"])\n                      \
          \    for item in history])\n\nEdit2: actually this is just one line break\
          \ and no free line after the system prpmpt, misred the 2 loops... So a deviation\
          \ from the prompt format which is used by many other models."
        updatedAt: '2023-08-05T09:12:46.794Z'
      numEdits: 2
      reactions: []
      relatedEventId: 64ce0f2e31c655ff8a2ef568
    id: 64ce0f2e31c655ff8a2ef567
    type: comment
  author: jphme
  content: "Hi @bleysg thanks for your answer. \nI suppose there should be 2 line\
    \ breaks after the context like in other similar prompt templates?\n\nIt would\
    \ be nice if you would add an example (string and/or tokenization) for this as\
    \ you write yourself \"The model is heavily conditioned to work using this format\
    \ only\" and I also experienced degradation just due to missing/wrong separators.\n\
    Many thanks!\n\nEdit: found that in the example Gradio Space, I guess this is\
    \ the correct format then, with 2 line breaks as expected? Would make sense to\
    \ add that to the Model card imho:\n\n> messages = BASE_SYSTEM_MESSAGE + system_message.strip()\
    \ + \"\\n\" + \\\n               \"\\n\".join([\"\\n\".join([\"User: \"+item[0]+\"\
    <|end_of_turn|>\", \"Assistant: \"+item[1]+\"<|end_of_turn|>\"])\n           \
    \               for item in history])\n\nEdit2: actually this is just one line\
    \ break and no free line after the system prpmpt, misred the 2 loops... So a deviation\
    \ from the prompt format which is used by many other models."
  created_at: 2023-08-05 07:58:22+00:00
  edited: true
  hidden: false
  id: 64ce0f2e31c655ff8a2ef567
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1gCpz_Og6-LyCBXDmuOd1.jpeg?w=200&h=200&f=face
      fullname: Jan Philipp Harries
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jphme
      type: user
    createdAt: '2023-08-05T08:58:22.000Z'
    data:
      status: open
    id: 64ce0f2e31c655ff8a2ef568
    type: status-change
  author: jphme
  created_at: 2023-08-05 07:58:22+00:00
  id: 64ce0f2e31c655ff8a2ef568
  new_status: open
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Open-Orca/OpenOrcaxOpenChat-Preview2-13B
repo_type: model
status: open
target_branch: null
title: 'System Prompt '
