!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tridungduong16
conflicting_files: null
created_at: 2023-08-05 12:20:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6454fa48b27940efcb944bb9/3GcYK4RXljPSjBUgQEArL.png?w=200&h=200&f=face
      fullname: Duong Tri Dung
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tridungduong16
      type: user
    createdAt: '2023-08-05T13:20:27.000Z'
    data:
      edited: true
      editors:
      - tridungduong16
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9756449460983276
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6454fa48b27940efcb944bb9/3GcYK4RXljPSjBUgQEArL.png?w=200&h=200&f=face
          fullname: Duong Tri Dung
          isHf: false
          isPro: false
          name: tridungduong16
          type: user
        html: '<p> I am quite surprised that it''s pretty good for chat. Very few
          models have this capability.<br>Can you provide more information about training
          mult-turn conversation since datasets just contains a pair of question-answer
          information; I am curious that how we can fine tune it for conversational
          purpose.</p>

          '
        raw: " I am quite surprised that it's pretty good for chat. Very few models\
          \ have this capability. \nCan you provide more information about training\
          \ mult-turn conversation since datasets just contains a pair of question-answer\
          \ information; I am curious that how we can fine tune it for conversational\
          \ purpose."
        updatedAt: '2023-08-06T02:09:28.401Z'
      numEdits: 1
      reactions: []
    id: 64ce4c9b5c86caf951bdf5b2
    type: comment
  author: tridungduong16
  content: " I am quite surprised that it's pretty good for chat. Very few models\
    \ have this capability. \nCan you provide more information about training mult-turn\
    \ conversation since datasets just contains a pair of question-answer information;\
    \ I am curious that how we can fine tune it for conversational purpose."
  created_at: 2023-08-05 12:20:27+00:00
  edited: true
  hidden: false
  id: 64ce4c9b5c86caf951bdf5b2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b6cbbdbfb266841ec0f24a/PHUVNOOMEw_R2CF3u-sMS.png?w=200&h=200&f=face
      fullname: One
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: imone
      type: user
    createdAt: '2023-08-06T06:23:06.000Z'
    data:
      edited: false
      editors:
      - imone
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9131373763084412
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b6cbbdbfb266841ec0f24a/PHUVNOOMEw_R2CF3u-sMS.png?w=200&h=200&f=face
          fullname: One
          isHf: false
          isPro: false
          name: imone
          type: user
        html: '<p>The model hasn''t been trained on multi-turn chat, so it''s shocking.
          To further train on conversations, I''d recommend using the 6K ShareGPT
          GPT-4 conversations from OpenChat. You can follow the instructions here
          <a rel="nofollow" href="https://github.com/imoneoi/openchat/">https://github.com/imoneoi/openchat/</a></p>

          '
        raw: The model hasn't been trained on multi-turn chat, so it's shocking. To
          further train on conversations, I'd recommend using the 6K ShareGPT GPT-4
          conversations from OpenChat. You can follow the instructions here https://github.com/imoneoi/openchat/
        updatedAt: '2023-08-06T06:23:06.179Z'
      numEdits: 0
      reactions: []
    id: 64cf3c4ae8df1f66dd6a5b50
    type: comment
  author: imone
  content: The model hasn't been trained on multi-turn chat, so it's shocking. To
    further train on conversations, I'd recommend using the 6K ShareGPT GPT-4 conversations
    from OpenChat. You can follow the instructions here https://github.com/imoneoi/openchat/
  created_at: 2023-08-06 05:23:06+00:00
  edited: false
  hidden: false
  id: 64cf3c4ae8df1f66dd6a5b50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6454fa48b27940efcb944bb9/3GcYK4RXljPSjBUgQEArL.png?w=200&h=200&f=face
      fullname: Duong Tri Dung
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tridungduong16
      type: user
    createdAt: '2023-08-06T11:00:57.000Z'
    data:
      edited: false
      editors:
      - tridungduong16
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9241703748703003
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6454fa48b27940efcb944bb9/3GcYK4RXljPSjBUgQEArL.png?w=200&h=200&f=face
          fullname: Duong Tri Dung
          isHf: false
          isPro: false
          name: tridungduong16
          type: user
        html: '<p>Thanks for your answer. Very helpful for me. Just one concern that
          why the model can achieve conversational task when not training on multi-turn
          chat? Does it assume the previous history is the context?</p>

          '
        raw: Thanks for your answer. Very helpful for me. Just one concern that why
          the model can achieve conversational task when not training on multi-turn
          chat? Does it assume the previous history is the context?
        updatedAt: '2023-08-06T11:00:57.270Z'
      numEdits: 0
      reactions: []
    id: 64cf7d694dfd5df7071af5b9
    type: comment
  author: tridungduong16
  content: Thanks for your answer. Very helpful for me. Just one concern that why
    the model can achieve conversational task when not training on multi-turn chat?
    Does it assume the previous history is the context?
  created_at: 2023-08-06 10:00:57+00:00
  edited: false
  hidden: false
  id: 64cf7d694dfd5df7071af5b9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9441d895e3308a15a50c5dab942454ff.svg
      fullname: Bleys
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: bleysg
      type: user
    createdAt: '2023-08-06T23:47:08.000Z'
    data:
      edited: false
      editors:
      - bleysg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9246484041213989
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9441d895e3308a15a50c5dab942454ff.svg
          fullname: Bleys
          isHf: false
          isPro: true
          name: bleysg
          type: user
        html: "<p>It may be an emergent understanding based on the combination of\
          \ the focus on step by step reasoning and the format of the task training.\
          \ The model demonstrates fairly robust theory of mind, as it is capable\
          \ of clearly interpreting requests to interact as multiple separate agents\
          \ in diverse ways in a single prompt. We haven\u2019t tested this exhaustively\
          \ though.</p>\n"
        raw: "It may be an emergent understanding based on the combination of the\
          \ focus on step by step reasoning and the format of the task training. The\
          \ model demonstrates fairly robust theory of mind, as it is capable of clearly\
          \ interpreting requests to interact as multiple separate agents in diverse\
          \ ways in a single prompt. We haven\u2019t tested this exhaustively though."
        updatedAt: '2023-08-06T23:47:08.313Z'
      numEdits: 0
      reactions: []
    id: 64d030fc8749302d815967bd
    type: comment
  author: bleysg
  content: "It may be an emergent understanding based on the combination of the focus\
    \ on step by step reasoning and the format of the task training. The model demonstrates\
    \ fairly robust theory of mind, as it is capable of clearly interpreting requests\
    \ to interact as multiple separate agents in diverse ways in a single prompt.\
    \ We haven\u2019t tested this exhaustively though."
  created_at: 2023-08-06 22:47:08+00:00
  edited: false
  hidden: false
  id: 64d030fc8749302d815967bd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: Open-Orca/OpenOrcaxOpenChat-Preview2-13B
repo_type: model
status: open
target_branch: null
title: Can you explain how can we train multi-turn conversation?
