!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tonyaw
conflicting_files: null
created_at: 2023-04-13 08:41:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ed8d9a55a19d8c5a138ba918d7c2450e.svg
      fullname: Tony W
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tonyaw
      type: user
    createdAt: '2023-04-13T09:41:31.000Z'
    data:
      edited: false
      editors:
      - tonyaw
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ed8d9a55a19d8c5a138ba918d7c2450e.svg
          fullname: Tony W
          isHf: false
          isPro: false
          name: tonyaw
          type: user
        html: "<p>I'm trying to use a CPU server to run vicuna-13b-delta-v0 via huggingface\
          \ pipeline.<br>Unfortunately, I got non-sense result.<br>One possibility\
          \ is I'm using wrong version of Python library.<br>Could you please help\
          \ to provide the recommended Python library version?<br>What I'm using:<br>transformers-4.29.0.dev0.dist-info<br>torch-2.0.0-py3.8.egg-info<br>accelerate-0.18.0.dev0.dist-info</p>\n\
          <p>My code:<br>`model_name = \"./models/vicuna-13b-delta-v0\"</p>\n<p>import\
          \ torch<br>converse = pipeline(\"conversational\", model=model_name)</p>\n\
          <p>conversation_1 = Conversation(\"Going to the movies tonight - any suggestions?\"\
          )<br>conversation_2 = Conversation(\"What's the last book you have read?\"\
          )<br>result = converse([conversation_1, conversation_2])<br>logger.info(\"\
          result=%s\", result)`</p>\n<p>I got nonsense result:<br>result=[Conversation\
          \ id: 0fd4b846-ecb0-40df-804c-a036d5204303<br>user &gt;&gt; Going to the\
          \ movies tonight - any suggestions?<br>bot &gt;&gt; Auflage occasionally.\xA1\
          \xAA [ [<br>, Conversation id: 32f1e750-6021-4c7a-827f-3a8cf1bcff98<br>user\
          \ &gt;&gt; What's the last book you have read?<br>Raf &gt; {\\ gathered;<br>]</p>\n\
          <p>Could you please guide me what I missed?<br>Thanks very much in advance!</p>\n"
        raw: "I'm trying to use a CPU server to run vicuna-13b-delta-v0 via huggingface\
          \ pipeline.\r\nUnfortunately, I got non-sense result.\r\nOne possibility\
          \ is I'm using wrong version of Python library.\r\nCould you please help\
          \ to provide the recommended Python library version?\r\nWhat I'm using:\r\
          \ntransformers-4.29.0.dev0.dist-info\r\ntorch-2.0.0-py3.8.egg-info\r\naccelerate-0.18.0.dev0.dist-info\r\
          \n\r\nMy code:\r\n`model_name = \"./models/vicuna-13b-delta-v0\"\r\n\r\n\
          import torch\r\nconverse = pipeline(\"conversational\", model=model_name)\r\
          \n\r\nconversation_1 = Conversation(\"Going to the movies tonight - any\
          \ suggestions?\")\r\nconversation_2 = Conversation(\"What's the last book\
          \ you have read?\")\r\nresult = converse([conversation_1, conversation_2])\r\
          \nlogger.info(\"result=%s\", result)`\r\n\r\nI got nonsense result:\r\n\
          result=[Conversation id: 0fd4b846-ecb0-40df-804c-a036d5204303\r\nuser >>\
          \ Going to the movies tonight - any suggestions?\r\nbot >> Auflage occasionally.\xA1\
          \xAA [ [\r\n, Conversation id: 32f1e750-6021-4c7a-827f-3a8cf1bcff98\r\n\
          user >> What's the last book you have read?\r\nRaf > {\\ gathered;\r\n]\r\
          \n\r\nCould you please guide me what I missed?\r\nThanks very much in advance!"
        updatedAt: '2023-04-13T09:41:31.066Z'
      numEdits: 0
      reactions: []
    id: 6437ce4bfac5ea753f1dce45
    type: comment
  author: tonyaw
  content: "I'm trying to use a CPU server to run vicuna-13b-delta-v0 via huggingface\
    \ pipeline.\r\nUnfortunately, I got non-sense result.\r\nOne possibility is I'm\
    \ using wrong version of Python library.\r\nCould you please help to provide the\
    \ recommended Python library version?\r\nWhat I'm using:\r\ntransformers-4.29.0.dev0.dist-info\r\
    \ntorch-2.0.0-py3.8.egg-info\r\naccelerate-0.18.0.dev0.dist-info\r\n\r\nMy code:\r\
    \n`model_name = \"./models/vicuna-13b-delta-v0\"\r\n\r\nimport torch\r\nconverse\
    \ = pipeline(\"conversational\", model=model_name)\r\n\r\nconversation_1 = Conversation(\"\
    Going to the movies tonight - any suggestions?\")\r\nconversation_2 = Conversation(\"\
    What's the last book you have read?\")\r\nresult = converse([conversation_1, conversation_2])\r\
    \nlogger.info(\"result=%s\", result)`\r\n\r\nI got nonsense result:\r\nresult=[Conversation\
    \ id: 0fd4b846-ecb0-40df-804c-a036d5204303\r\nuser >> Going to the movies tonight\
    \ - any suggestions?\r\nbot >> Auflage occasionally.\xA1\xAA [ [\r\n, Conversation\
    \ id: 32f1e750-6021-4c7a-827f-3a8cf1bcff98\r\nuser >> What's the last book you\
    \ have read?\r\nRaf > {\\ gathered;\r\n]\r\n\r\nCould you please guide me what\
    \ I missed?\r\nThanks very much in advance!"
  created_at: 2023-04-13 08:41:31+00:00
  edited: false
  hidden: false
  id: 6437ce4bfac5ea753f1dce45
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62d35f3ceaf3858ce253ab7a/3yiiMriltXJBi242FZY-W.jpeg?w=200&h=200&f=face
      fullname: Lianmin
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lmzheng
      type: user
    createdAt: '2023-04-13T18:33:56.000Z'
    data:
      edited: false
      editors:
      - lmzheng
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62d35f3ceaf3858ce253ab7a/3yiiMriltXJBi242FZY-W.jpeg?w=200&h=200&f=face
          fullname: Lianmin
          isHf: false
          isPro: false
          name: lmzheng
          type: user
        html: '<p>NOTE: This "delta model" cannot be used directly.<br>Users have
          to apply it on top of the original LLaMA weights to get actual Vicuna weights.<br>See
          <a rel="nofollow" href="https://github.com/lm-sys/FastChat#vicuna-weights">https://github.com/lm-sys/FastChat#vicuna-weights</a>
          for instructions.</p>

          '
        raw: 'NOTE: This "delta model" cannot be used directly.

          Users have to apply it on top of the original LLaMA weights to get actual
          Vicuna weights.

          See https://github.com/lm-sys/FastChat#vicuna-weights for instructions.'
        updatedAt: '2023-04-13T18:33:56.069Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64384b1455cf8c810dd5ca64
    id: 64384b1455cf8c810dd5ca63
    type: comment
  author: lmzheng
  content: 'NOTE: This "delta model" cannot be used directly.

    Users have to apply it on top of the original LLaMA weights to get actual Vicuna
    weights.

    See https://github.com/lm-sys/FastChat#vicuna-weights for instructions.'
  created_at: 2023-04-13 17:33:56+00:00
  edited: false
  hidden: false
  id: 64384b1455cf8c810dd5ca63
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62d35f3ceaf3858ce253ab7a/3yiiMriltXJBi242FZY-W.jpeg?w=200&h=200&f=face
      fullname: Lianmin
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lmzheng
      type: user
    createdAt: '2023-04-13T18:33:56.000Z'
    data:
      status: closed
    id: 64384b1455cf8c810dd5ca64
    type: status-change
  author: lmzheng
  created_at: 2023-04-13 17:33:56+00:00
  id: 64384b1455cf8c810dd5ca64
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: lmsys/vicuna-13b-delta-v0
repo_type: model
status: closed
target_branch: null
title: Python library version recommendation
