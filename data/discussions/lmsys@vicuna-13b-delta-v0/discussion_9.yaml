!!python/object:huggingface_hub.community.DiscussionWithDetails
author: naveenthomas
conflicting_files: null
created_at: 2023-04-24 20:36:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5f31f7aa136c1efdf4c6555a46ba3f97.svg
      fullname: Naveen Thomas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: naveenthomas
      type: user
    createdAt: '2023-04-24T21:36:45.000Z'
    data:
      edited: false
      editors:
      - naveenthomas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5f31f7aa136c1efdf4c6555a46ba3f97.svg
          fullname: Naveen Thomas
          isHf: false
          isPro: false
          name: naveenthomas
          type: user
        html: "<p>I downloaded the oobabaga and downloaded the model and attempted\
          \ to run it in the software.<br>But, I get the following error. </p>\n<p>tokenizer\
          \ = LlamaTokenizer.from_pretrained(Path(f\"{shared.args.model_dir}/{shared.model_name}/\"\
          ), clean_up_tokenization_spaces=True)<br>TypeError: \u2018NoneType\u2019\
          \ object is not callable</p>\n<p>Can anyone help me with this error. </p>\n"
        raw: "I downloaded the oobabaga and downloaded the model and attempted to\
          \ run it in the software. \r\nBut, I get the following error. \r\n\r\ntokenizer\
          \ = LlamaTokenizer.from_pretrained(Path(f\"{shared.args.model_dir}/{shared.model_name}/\"\
          ), clean_up_tokenization_spaces=True)\r\nTypeError: \u2018NoneType\u2019\
          \ object is not callable\r\n\r\nCan anyone help me with this error. "
        updatedAt: '2023-04-24T21:36:45.877Z'
      numEdits: 0
      reactions: []
    id: 6446f66da38ff9f7c2b91079
    type: comment
  author: naveenthomas
  content: "I downloaded the oobabaga and downloaded the model and attempted to run\
    \ it in the software. \r\nBut, I get the following error. \r\n\r\ntokenizer =\
    \ LlamaTokenizer.from_pretrained(Path(f\"{shared.args.model_dir}/{shared.model_name}/\"\
    ), clean_up_tokenization_spaces=True)\r\nTypeError: \u2018NoneType\u2019 object\
    \ is not callable\r\n\r\nCan anyone help me with this error. "
  created_at: 2023-04-24 20:36:45+00:00
  edited: false
  hidden: false
  id: 6446f66da38ff9f7c2b91079
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-25T08:20:25.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Did you merge the deltas first? You can''t run the files in this
          repo directly. They need to be merged first. Also this repo is v1.0 and
          has been superseded by v1.1  </p>

          <p>I have an already merged repo for v1.1 available here: <a href="https://huggingface.co/TheBloke/vicuna-13B-1.1-HF">https://huggingface.co/TheBloke/vicuna-13B-1.1-HF</a></p>

          '
        raw: "Did you merge the deltas first? You can't run the files in this repo\
          \ directly. They need to be merged first. Also this repo is v1.0 and has\
          \ been superseded by v1.1  \n\nI have an already merged repo for v1.1 available\
          \ here: https://huggingface.co/TheBloke/vicuna-13B-1.1-HF"
        updatedAt: '2023-04-25T08:20:25.644Z'
      numEdits: 0
      reactions: []
    id: 64478d493411a0902bb000a6
    type: comment
  author: TheBloke
  content: "Did you merge the deltas first? You can't run the files in this repo directly.\
    \ They need to be merged first. Also this repo is v1.0 and has been superseded\
    \ by v1.1  \n\nI have an already merged repo for v1.1 available here: https://huggingface.co/TheBloke/vicuna-13B-1.1-HF"
  created_at: 2023-04-25 07:20:25+00:00
  edited: false
  hidden: false
  id: 64478d493411a0902bb000a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5f31f7aa136c1efdf4c6555a46ba3f97.svg
      fullname: Naveen Thomas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: naveenthomas
      type: user
    createdAt: '2023-04-26T15:13:11.000Z'
    data:
      edited: false
      editors:
      - naveenthomas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5f31f7aa136c1efdf4c6555a46ba3f97.svg
          fullname: Naveen Thomas
          isHf: false
          isPro: false
          name: naveenthomas
          type: user
        html: '<p>Thanks a lot TheBloke. I implemented your code and it seems to works
          out</p>

          '
        raw: Thanks a lot TheBloke. I implemented your code and it seems to works
          out
        updatedAt: '2023-04-26T15:13:11.946Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TheBloke
    id: 64493f871af713976c2c410b
    type: comment
  author: naveenthomas
  content: Thanks a lot TheBloke. I implemented your code and it seems to works out
  created_at: 2023-04-26 14:13:11+00:00
  edited: false
  hidden: false
  id: 64493f871af713976c2c410b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a28ed89c9688caf7ed660278d1eacadc.svg
      fullname: gandolfi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gandolfi
      type: user
    createdAt: '2023-05-20T21:51:47.000Z'
    data:
      edited: false
      editors:
      - gandolfi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a28ed89c9688caf7ed660278d1eacadc.svg
          fullname: gandolfi
          isHf: false
          isPro: false
          name: gandolfi
          type: user
        html: "<p>hello, i have the same error with \"<a href=\"https://huggingface.co/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g&quot;\"\
          >https://huggingface.co/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g\"</a> </p>\n\
          <p>Traceback (most recent call last): File \u201C/home/ryzen/T\xE9l\xE9\
          chargements/LLM/oobabooga_linux/text-generation-webui/server.py\u201D, line\
          \ 68, in load_model_wrapper shared.model, shared.tokenizer = load_model(shared.model_name)\
          \ File \u201C/home/ryzen/T\xE9l\xE9chargements/LLM/oobabooga_linux/text-generation-webui/modules/models.py\u201D\
          , line 103, in load_model tokenizer = load_tokenizer(model_name, model)\
          \ File \u201C/home/ryzen/T\xE9l\xE9chargements/LLM/oobabooga_linux/text-generation-webui/modules/models.py\u201D\
          , line 128, in load_tokenizer tokenizer = LlamaTokenizer.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}/\"), clean_up_tokenization_spaces=True)\
          \ TypeError: \u2018NoneType\u2019 object is not callable</p>\n"
        raw: "hello, i have the same error with \"https://huggingface.co/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g\"\
          \ \n\nTraceback (most recent call last): File \u201C/home/ryzen/T\xE9l\xE9\
          chargements/LLM/oobabooga_linux/text-generation-webui/server.py\u201D, line\
          \ 68, in load_model_wrapper shared.model, shared.tokenizer = load_model(shared.model_name)\
          \ File \u201C/home/ryzen/T\xE9l\xE9chargements/LLM/oobabooga_linux/text-generation-webui/modules/models.py\u201D\
          , line 103, in load_model tokenizer = load_tokenizer(model_name, model)\
          \ File \u201C/home/ryzen/T\xE9l\xE9chargements/LLM/oobabooga_linux/text-generation-webui/modules/models.py\u201D\
          , line 128, in load_tokenizer tokenizer = LlamaTokenizer.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}/\"), clean_up_tokenization_spaces=True)\
          \ TypeError: \u2018NoneType\u2019 object is not callable"
        updatedAt: '2023-05-20T21:51:47.081Z'
      numEdits: 0
      reactions: []
    id: 646940f397ffc33d43ce3cf5
    type: comment
  author: gandolfi
  content: "hello, i have the same error with \"https://huggingface.co/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g\"\
    \ \n\nTraceback (most recent call last): File \u201C/home/ryzen/T\xE9l\xE9chargements/LLM/oobabooga_linux/text-generation-webui/server.py\u201D\
    , line 68, in load_model_wrapper shared.model, shared.tokenizer = load_model(shared.model_name)\
    \ File \u201C/home/ryzen/T\xE9l\xE9chargements/LLM/oobabooga_linux/text-generation-webui/modules/models.py\u201D\
    , line 103, in load_model tokenizer = load_tokenizer(model_name, model) File \u201C\
    /home/ryzen/T\xE9l\xE9chargements/LLM/oobabooga_linux/text-generation-webui/modules/models.py\u201D\
    , line 128, in load_tokenizer tokenizer = LlamaTokenizer.from_pretrained(Path(f\"\
    {shared.args.model_dir}/{model_name}/\"), clean_up_tokenization_spaces=True) TypeError:\
    \ \u2018NoneType\u2019 object is not callable"
  created_at: 2023-05-20 20:51:47+00:00
  edited: false
  hidden: false
  id: 646940f397ffc33d43ce3cf5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: lmsys/vicuna-13b-delta-v0
repo_type: model
status: open
target_branch: null
title: 'Error while running the code. '
