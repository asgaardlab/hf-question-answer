!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Krougher
conflicting_files: null
created_at: 2023-05-09 18:42:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/56b619ca7913bb0d8502e097535f85b1.svg
      fullname: k
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Krougher
      type: user
    createdAt: '2023-05-09T19:42:51.000Z'
    data:
      edited: false
      editors:
      - Krougher
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/56b619ca7913bb0d8502e097535f85b1.svg
          fullname: k
          isHf: false
          isPro: false
          name: Krougher
          type: user
        html: "<p>Before everything, hi and thank you for the amount of work and time\
          \ you put in that.</p>\n<p>And as i said when i load the model, i have that\
          \ error:</p>\n<p>Traceback (most recent call last):<br>File \u201CD:\\AI\\\
          TextAI\\oobabooga-windows\\text-generation-webui\\server.py\u201D, line\
          \ 67, in load_model_wrapper<br>shared.model, shared.tokenizer = load_model(shared.model_name)<br>File\
          \ \u201CD:\\AI\\TextAI\\oobabooga-windows\\text-generation-webui\\modules\\\
          models.py\u201D, line 219, in load_model<br>model = LoaderClass.from_pretrained(checkpoint,\
          \ **params)<br>File \u201CD:\\AI\\TextAI\\oobabooga-windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u201D\
          , line 471, in from_pretrained<br>return model_class.from_pretrained(<br>File\
          \ \u201CD:\\AI\\TextAI\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
          transformers\\modeling_utils.py\u201D, line 2349, in from_pretrained<br>raise\
          \ EnvironmentError(<br>OSError: Error no file named pytorch_model.bin, tf_model.h5,\
          \ model.ckpt.index or flax_model.msgpack found in directory models\\TheBloke_WizardLM-7B-uncensored-GPTQ.</p>\n\
          <p>Can you help me ?</p>\n"
        raw: "Before everything, hi and thank you for the amount of work and time\
          \ you put in that.\r\n\r\nAnd as i said when i load the model, i have that\
          \ error:\r\n\r\nTraceback (most recent call last):\r\nFile \u201CD:\\AI\\\
          TextAI\\oobabooga-windows\\text-generation-webui\\server.py\u201D, line\
          \ 67, in load_model_wrapper\r\nshared.model, shared.tokenizer = load_model(shared.model_name)\r\
          \nFile \u201CD:\\AI\\TextAI\\oobabooga-windows\\text-generation-webui\\\
          modules\\models.py\u201D, line 219, in load_model\r\nmodel = LoaderClass.from_pretrained(checkpoint,\
          \ **params)\r\nFile \u201CD:\\AI\\TextAI\\oobabooga-windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u201D\
          , line 471, in from_pretrained\r\nreturn model_class.from_pretrained(\r\n\
          File \u201CD:\\AI\\TextAI\\oobabooga-windows\\installer_files\\env\\lib\\\
          site-packages\\transformers\\modeling_utils.py\u201D, line 2349, in from_pretrained\r\
          \nraise EnvironmentError(\r\nOSError: Error no file named pytorch_model.bin,\
          \ tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory\
          \ models\\TheBloke_WizardLM-7B-uncensored-GPTQ.\r\n\r\nCan you help me ?"
        updatedAt: '2023-05-09T19:42:51.646Z'
      numEdits: 0
      reactions: []
    id: 645aa23bc35da9c7afd768a3
    type: comment
  author: Krougher
  content: "Before everything, hi and thank you for the amount of work and time you\
    \ put in that.\r\n\r\nAnd as i said when i load the model, i have that error:\r\
    \n\r\nTraceback (most recent call last):\r\nFile \u201CD:\\AI\\TextAI\\oobabooga-windows\\\
    text-generation-webui\\server.py\u201D, line 67, in load_model_wrapper\r\nshared.model,\
    \ shared.tokenizer = load_model(shared.model_name)\r\nFile \u201CD:\\AI\\TextAI\\\
    oobabooga-windows\\text-generation-webui\\modules\\models.py\u201D, line 219,\
    \ in load_model\r\nmodel = LoaderClass.from_pretrained(checkpoint, **params)\r\
    \nFile \u201CD:\\AI\\TextAI\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\models\\auto\\auto_factory.py\u201D, line 471, in from_pretrained\r\
    \nreturn model_class.from_pretrained(\r\nFile \u201CD:\\AI\\TextAI\\oobabooga-windows\\\
    installer_files\\env\\lib\\site-packages\\transformers\\modeling_utils.py\u201D\
    , line 2349, in from_pretrained\r\nraise EnvironmentError(\r\nOSError: Error no\
    \ file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
    \ found in directory models\\TheBloke_WizardLM-7B-uncensored-GPTQ.\r\n\r\nCan\
    \ you help me ?"
  created_at: 2023-05-09 18:42:51+00:00
  edited: false
  hidden: false
  id: 645aa23bc35da9c7afd768a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-10T10:03:17.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I''m told there''s currently a bug in text-gen-ui where it seems
          to forget GPTQ params.  You could also try updating text-gen-ui to the latest
          code in case this bug is fixed now.</p>

          <p>If that doesn''t work, you may just have to manually set the GPTQ params
          and "Reload this model" each time.  Hopefully the bug will be fixed soon.</p>

          '
        raw: 'I''m told there''s currently a bug in text-gen-ui where it seems to
          forget GPTQ params.  You could also try updating text-gen-ui to the latest
          code in case this bug is fixed now.


          If that doesn''t work, you may just have to manually set the GPTQ params
          and "Reload this model" each time.  Hopefully the bug will be fixed soon.'
        updatedAt: '2023-05-10T10:06:51.447Z'
      numEdits: 1
      reactions: []
    id: 645b6be5b4e65f04f7f28d63
    type: comment
  author: TheBloke
  content: 'I''m told there''s currently a bug in text-gen-ui where it seems to forget
    GPTQ params.  You could also try updating text-gen-ui to the latest code in case
    this bug is fixed now.


    If that doesn''t work, you may just have to manually set the GPTQ params and "Reload
    this model" each time.  Hopefully the bug will be fixed soon.'
  created_at: 2023-05-10 09:03:17+00:00
  edited: true
  hidden: false
  id: 645b6be5b4e65f04f7f28d63
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b5e47bcebe0de3cade0537739c739846.svg
      fullname: Alex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 1galaxy1
      type: user
    createdAt: '2023-05-10T13:31:17.000Z'
    data:
      edited: false
      editors:
      - 1galaxy1
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b5e47bcebe0de3cade0537739c739846.svg
          fullname: Alex
          isHf: false
          isPro: false
          name: 1galaxy1
          type: user
        html: '<p>Update oobabooga by running update_windows.bat. Worked for me.</p>

          '
        raw: Update oobabooga by running update_windows.bat. Worked for me.
        updatedAt: '2023-05-10T13:31:17.991Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TheBloke
    id: 645b9ca52c76efd4c6657cfa
    type: comment
  author: 1galaxy1
  content: Update oobabooga by running update_windows.bat. Worked for me.
  created_at: 2023-05-10 12:31:17+00:00
  edited: false
  hidden: false
  id: 645b9ca52c76efd4c6657cfa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-10T14:00:41.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Great, thanks for letting us know.</p>

          '
        raw: Great, thanks for letting us know.
        updatedAt: '2023-05-10T14:00:41.359Z'
      numEdits: 0
      reactions: []
    id: 645ba389337b2ccf07fa7d5c
    type: comment
  author: TheBloke
  content: Great, thanks for letting us know.
  created_at: 2023-05-10 13:00:41+00:00
  edited: false
  hidden: false
  id: 645ba389337b2ccf07fa7d5c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/56b619ca7913bb0d8502e097535f85b1.svg
      fullname: k
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Krougher
      type: user
    createdAt: '2023-05-10T14:50:00.000Z'
    data:
      edited: false
      editors:
      - Krougher
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/56b619ca7913bb0d8502e097535f85b1.svg
          fullname: k
          isHf: false
          isPro: false
          name: Krougher
          type: user
        html: "<p>Hi thanks for your answers, i updated oobabooga, redone the config\
          \ 4/128/llama, and now i have that error:</p>\n<p>Traceback (most recent\
          \ call last):<br>File \u201CD:\\AI\\TextAI\\oobabooga-windows\\text-generation-webui\\\
          server.py\u201D, line 67, in load_model_wrapper<br>shared.model, shared.tokenizer\
          \ = load_model(shared.model_name)<br>File \u201CD:\\AI\\TextAI\\oobabooga-windows\\\
          text-generation-webui\\modules\\models.py\u201D, line 159, in load_model<br>model\
          \ = load_quantized(model_name)<br>File \u201CD:\\AI\\TextAI\\oobabooga-windows\\\
          text-generation-webui\\modules\\GPTQ_loader.py\u201D, line 181, in load_quantized<br>model\
          \ = load_quant(str(path_to_model), str(pt_path), shared.args.wbits, shared.args.groupsize,\
          \ shared.args.pre_layer)<br>File \u201CD:\\AI\\TextAI\\oobabooga-windows\\\
          text-generation-webui\\repositories\\GPTQ-for-LLaMa\\llama_inference_offload.py\u201D\
          , line 226, in load_quant<br>model.load_state_dict(safe_load(checkpoint))<br>File\
          \ \u201CD:\\AI\\TextAI\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
          torch\\nn\\modules\\module.py\u201D, line 2041, in load_state_dict<br>raise\
          \ RuntimeError(\u2018Error(s) in loading state_dict for {}:\\n\\t{}\u2019\
          .format(<br>RuntimeError: Error(s) in loading state_dict for LlamaForCausalLM:<br>Missing\
          \ key(s) in state_dict: \u201Cmodel.layers.0.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.0.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.0.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.0.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.0.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.0.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.0.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.1.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.1.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.1.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.1.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.1.mlp.down_proj.bias\u201D, \u201Cmodel.layers.1.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.1.mlp.up_proj.bias\u201D, \u201Cmodel.layers.2.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.2.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.2.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.2.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.2.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.2.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.2.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.3.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.3.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.3.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.3.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.3.mlp.down_proj.bias\u201D, \u201Cmodel.layers.3.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.3.mlp.up_proj.bias\u201D, \u201Cmodel.layers.4.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.4.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.4.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.4.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.4.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.4.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.4.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.5.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.5.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.5.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.5.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.5.mlp.down_proj.bias\u201D, \u201Cmodel.layers.5.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.5.mlp.up_proj.bias\u201D, \u201Cmodel.layers.6.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.6.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.6.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.6.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.6.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.6.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.6.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.7.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.7.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.7.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.7.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.7.mlp.down_proj.bias\u201D, \u201Cmodel.layers.7.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.7.mlp.up_proj.bias\u201D, \u201Cmodel.layers.8.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.8.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.8.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.8.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.8.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.8.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.8.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.9.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.9.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.9.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.9.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.9.mlp.down_proj.bias\u201D, \u201Cmodel.layers.9.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.9.mlp.up_proj.bias\u201D, \u201Cmodel.layers.10.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.10.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.10.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.10.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.10.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.10.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.10.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.11.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.11.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.11.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.11.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.11.mlp.down_proj.bias\u201D, \u201Cmodel.layers.11.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.11.mlp.up_proj.bias\u201D, \u201Cmodel.layers.12.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.12.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.12.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.12.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.12.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.12.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.12.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.13.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.13.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.13.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.13.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.13.mlp.down_proj.bias\u201D, \u201Cmodel.layers.13.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.13.mlp.up_proj.bias\u201D, \u201Cmodel.layers.14.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.14.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.14.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.14.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.14.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.14.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.14.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.15.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.15.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.15.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.15.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.15.mlp.down_proj.bias\u201D, \u201Cmodel.layers.15.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.15.mlp.up_proj.bias\u201D, \u201Cmodel.layers.16.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.16.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.16.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.16.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.16.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.16.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.16.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.17.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.17.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.17.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.17.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.17.mlp.down_proj.bias\u201D, \u201Cmodel.layers.17.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.17.mlp.up_proj.bias\u201D, \u201Cmodel.layers.18.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.18.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.18.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.18.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.18.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.18.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.18.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.19.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.19.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.19.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.19.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.19.mlp.down_proj.bias\u201D, \u201Cmodel.layers.19.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.19.mlp.up_proj.bias\u201D, \u201Cmodel.layers.20.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.20.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.20.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.20.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.20.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.20.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.20.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.21.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.21.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.21.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.21.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.21.mlp.down_proj.bias\u201D, \u201Cmodel.layers.21.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.21.mlp.up_proj.bias\u201D, \u201Cmodel.layers.22.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.22.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.22.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.22.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.22.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.22.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.22.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.23.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.23.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.23.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.23.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.23.mlp.down_proj.bias\u201D, \u201Cmodel.layers.23.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.23.mlp.up_proj.bias\u201D, \u201Cmodel.layers.24.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.24.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.24.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.24.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.24.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.24.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.24.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.25.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.25.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.25.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.25.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.25.mlp.down_proj.bias\u201D, \u201Cmodel.layers.25.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.25.mlp.up_proj.bias\u201D, \u201Cmodel.layers.26.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.26.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.26.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.26.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.26.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.26.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.26.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.27.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.27.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.27.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.27.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.27.mlp.down_proj.bias\u201D, \u201Cmodel.layers.27.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.27.mlp.up_proj.bias\u201D, \u201Cmodel.layers.28.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.28.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.28.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.28.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.28.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.28.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.28.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.29.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.29.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.29.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.29.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.29.mlp.down_proj.bias\u201D, \u201Cmodel.layers.29.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.29.mlp.up_proj.bias\u201D, \u201Cmodel.layers.30.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.30.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.30.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.30.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.30.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.30.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.30.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.31.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.31.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.31.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.31.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.31.mlp.down_proj.bias\u201D, \u201Cmodel.layers.31.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.31.mlp.up_proj.bias\u201D.<br>Unexpected key(s) in\
          \ state_dict: \u201Cmodel.layers.0.self_attn.k_proj.g_idx\u201D, \u201C\
          model.layers.0.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.0.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.0.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.0.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.0.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.0.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.1.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.1.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.1.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.1.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.1.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.1.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.1.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.2.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.2.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.2.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.2.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.2.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.2.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.2.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.3.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.3.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.3.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.3.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.3.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.3.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.3.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.4.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.4.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.4.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.4.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.4.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.4.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.4.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.5.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.5.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.5.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.5.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.5.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.5.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.5.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.6.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.6.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.6.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.6.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.6.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.6.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.6.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.7.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.7.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.7.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.7.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.7.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.7.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.7.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.8.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.8.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.8.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.8.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.8.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.8.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.8.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.9.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.9.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.9.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.9.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.9.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.9.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.9.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.10.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.10.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.10.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.10.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.10.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.10.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.10.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.11.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.11.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.11.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.11.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.11.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.11.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.11.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.12.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.12.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.12.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.12.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.12.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.12.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.12.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.13.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.13.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.13.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.13.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.13.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.13.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.13.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.14.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.14.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.14.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.14.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.14.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.14.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.14.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.15.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.15.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.15.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.15.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.15.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.15.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.15.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.16.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.16.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.16.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.16.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.16.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.16.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.16.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.17.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.17.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.17.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.17.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.17.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.17.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.17.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.18.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.18.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.18.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.18.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.18.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.18.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.18.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.19.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.19.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.19.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.19.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.19.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.19.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.19.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.20.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.20.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.20.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.20.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.20.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.20.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.20.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.21.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.21.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.21.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.21.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.21.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.21.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.21.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.22.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.22.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.22.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.22.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.22.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.22.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.22.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.23.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.23.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.23.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.23.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.23.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.23.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.23.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.24.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.24.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.24.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.24.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.24.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.24.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.24.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.25.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.25.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.25.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.25.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.25.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.25.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.25.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.26.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.26.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.26.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.26.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.26.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.26.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.26.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.27.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.27.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.27.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.27.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.27.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.27.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.27.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.28.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.28.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.28.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.28.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.28.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.28.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.28.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.29.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.29.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.29.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.29.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.29.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.29.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.29.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.30.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.30.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.30.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.30.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.30.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.30.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.30.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.31.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.31.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.31.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.31.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.31.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.31.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.31.mlp.up_proj.g_idx\u201D.</p>\n"
        raw: "Hi thanks for your answers, i updated oobabooga, redone the config 4/128/llama,\
          \ and now i have that error:\n\n\nTraceback (most recent call last):\nFile\
          \ \u201CD:\\AI\\TextAI\\oobabooga-windows\\text-generation-webui\\server.py\u201D\
          , line 67, in load_model_wrapper\nshared.model, shared.tokenizer = load_model(shared.model_name)\n\
          File \u201CD:\\AI\\TextAI\\oobabooga-windows\\text-generation-webui\\modules\\\
          models.py\u201D, line 159, in load_model\nmodel = load_quantized(model_name)\n\
          File \u201CD:\\AI\\TextAI\\oobabooga-windows\\text-generation-webui\\modules\\\
          GPTQ_loader.py\u201D, line 181, in load_quantized\nmodel = load_quant(str(path_to_model),\
          \ str(pt_path), shared.args.wbits, shared.args.groupsize, shared.args.pre_layer)\n\
          File \u201CD:\\AI\\TextAI\\oobabooga-windows\\text-generation-webui\\repositories\\\
          GPTQ-for-LLaMa\\llama_inference_offload.py\u201D, line 226, in load_quant\n\
          model.load_state_dict(safe_load(checkpoint))\nFile \u201CD:\\AI\\TextAI\\\
          oobabooga-windows\\installer_files\\env\\lib\\site-packages\\torch\\nn\\\
          modules\\module.py\u201D, line 2041, in load_state_dict\nraise RuntimeError(\u2018\
          Error(s) in loading state_dict for {}:\\n\\t{}\u2019.format(\nRuntimeError:\
          \ Error(s) in loading state_dict for LlamaForCausalLM:\nMissing key(s) in\
          \ state_dict: \u201Cmodel.layers.0.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.0.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.0.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.0.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.0.mlp.down_proj.bias\u201D, \u201Cmodel.layers.0.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.0.mlp.up_proj.bias\u201D, \u201Cmodel.layers.1.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.1.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.1.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.1.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.1.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.1.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.1.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.2.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.2.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.2.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.2.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.2.mlp.down_proj.bias\u201D, \u201Cmodel.layers.2.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.2.mlp.up_proj.bias\u201D, \u201Cmodel.layers.3.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.3.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.3.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.3.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.3.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.3.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.3.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.4.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.4.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.4.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.4.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.4.mlp.down_proj.bias\u201D, \u201Cmodel.layers.4.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.4.mlp.up_proj.bias\u201D, \u201Cmodel.layers.5.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.5.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.5.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.5.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.5.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.5.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.5.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.6.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.6.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.6.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.6.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.6.mlp.down_proj.bias\u201D, \u201Cmodel.layers.6.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.6.mlp.up_proj.bias\u201D, \u201Cmodel.layers.7.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.7.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.7.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.7.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.7.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.7.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.7.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.8.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.8.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.8.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.8.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.8.mlp.down_proj.bias\u201D, \u201Cmodel.layers.8.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.8.mlp.up_proj.bias\u201D, \u201Cmodel.layers.9.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.9.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.9.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.9.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.9.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.9.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.9.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.10.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.10.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.10.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.10.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.10.mlp.down_proj.bias\u201D, \u201Cmodel.layers.10.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.10.mlp.up_proj.bias\u201D, \u201Cmodel.layers.11.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.11.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.11.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.11.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.11.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.11.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.11.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.12.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.12.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.12.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.12.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.12.mlp.down_proj.bias\u201D, \u201Cmodel.layers.12.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.12.mlp.up_proj.bias\u201D, \u201Cmodel.layers.13.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.13.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.13.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.13.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.13.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.13.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.13.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.14.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.14.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.14.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.14.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.14.mlp.down_proj.bias\u201D, \u201Cmodel.layers.14.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.14.mlp.up_proj.bias\u201D, \u201Cmodel.layers.15.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.15.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.15.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.15.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.15.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.15.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.15.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.16.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.16.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.16.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.16.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.16.mlp.down_proj.bias\u201D, \u201Cmodel.layers.16.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.16.mlp.up_proj.bias\u201D, \u201Cmodel.layers.17.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.17.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.17.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.17.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.17.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.17.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.17.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.18.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.18.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.18.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.18.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.18.mlp.down_proj.bias\u201D, \u201Cmodel.layers.18.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.18.mlp.up_proj.bias\u201D, \u201Cmodel.layers.19.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.19.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.19.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.19.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.19.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.19.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.19.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.20.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.20.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.20.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.20.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.20.mlp.down_proj.bias\u201D, \u201Cmodel.layers.20.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.20.mlp.up_proj.bias\u201D, \u201Cmodel.layers.21.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.21.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.21.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.21.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.21.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.21.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.21.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.22.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.22.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.22.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.22.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.22.mlp.down_proj.bias\u201D, \u201Cmodel.layers.22.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.22.mlp.up_proj.bias\u201D, \u201Cmodel.layers.23.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.23.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.23.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.23.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.23.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.23.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.23.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.24.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.24.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.24.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.24.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.24.mlp.down_proj.bias\u201D, \u201Cmodel.layers.24.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.24.mlp.up_proj.bias\u201D, \u201Cmodel.layers.25.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.25.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.25.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.25.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.25.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.25.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.25.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.26.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.26.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.26.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.26.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.26.mlp.down_proj.bias\u201D, \u201Cmodel.layers.26.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.26.mlp.up_proj.bias\u201D, \u201Cmodel.layers.27.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.27.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.27.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.27.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.27.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.27.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.27.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.28.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.28.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.28.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.28.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.28.mlp.down_proj.bias\u201D, \u201Cmodel.layers.28.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.28.mlp.up_proj.bias\u201D, \u201Cmodel.layers.29.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.29.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.29.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.29.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.29.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.29.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.29.mlp.up_proj.bias\u201D\
          , \u201Cmodel.layers.30.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.30.self_attn.o_proj.bias\u201D\
          , \u201Cmodel.layers.30.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.30.self_attn.v_proj.bias\u201D\
          , \u201Cmodel.layers.30.mlp.down_proj.bias\u201D, \u201Cmodel.layers.30.mlp.gate_proj.bias\u201D\
          , \u201Cmodel.layers.30.mlp.up_proj.bias\u201D, \u201Cmodel.layers.31.self_attn.k_proj.bias\u201D\
          , \u201Cmodel.layers.31.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.31.self_attn.q_proj.bias\u201D\
          , \u201Cmodel.layers.31.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.31.mlp.down_proj.bias\u201D\
          , \u201Cmodel.layers.31.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.31.mlp.up_proj.bias\u201D\
          .\nUnexpected key(s) in state_dict: \u201Cmodel.layers.0.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.0.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.0.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.0.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.0.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.0.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.0.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.1.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.1.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.1.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.1.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.1.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.1.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.1.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.2.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.2.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.2.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.2.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.2.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.2.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.2.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.3.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.3.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.3.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.3.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.3.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.3.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.3.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.4.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.4.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.4.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.4.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.4.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.4.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.4.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.5.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.5.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.5.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.5.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.5.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.5.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.5.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.6.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.6.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.6.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.6.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.6.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.6.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.6.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.7.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.7.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.7.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.7.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.7.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.7.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.7.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.8.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.8.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.8.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.8.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.8.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.8.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.8.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.9.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.9.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.9.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.9.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.9.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.9.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.9.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.10.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.10.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.10.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.10.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.10.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.10.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.10.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.11.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.11.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.11.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.11.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.11.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.11.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.11.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.12.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.12.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.12.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.12.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.12.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.12.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.12.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.13.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.13.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.13.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.13.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.13.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.13.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.13.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.14.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.14.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.14.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.14.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.14.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.14.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.14.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.15.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.15.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.15.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.15.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.15.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.15.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.15.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.16.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.16.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.16.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.16.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.16.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.16.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.16.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.17.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.17.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.17.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.17.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.17.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.17.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.17.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.18.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.18.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.18.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.18.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.18.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.18.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.18.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.19.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.19.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.19.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.19.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.19.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.19.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.19.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.20.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.20.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.20.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.20.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.20.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.20.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.20.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.21.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.21.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.21.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.21.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.21.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.21.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.21.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.22.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.22.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.22.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.22.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.22.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.22.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.22.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.23.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.23.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.23.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.23.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.23.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.23.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.23.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.24.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.24.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.24.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.24.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.24.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.24.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.24.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.25.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.25.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.25.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.25.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.25.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.25.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.25.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.26.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.26.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.26.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.26.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.26.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.26.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.26.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.27.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.27.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.27.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.27.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.27.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.27.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.27.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.28.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.28.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.28.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.28.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.28.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.28.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.28.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.29.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.29.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.29.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.29.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.29.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.29.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.29.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.30.self_attn.k_proj.g_idx\u201D\
          , \u201Cmodel.layers.30.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.30.self_attn.q_proj.g_idx\u201D\
          , \u201Cmodel.layers.30.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.30.mlp.down_proj.g_idx\u201D\
          , \u201Cmodel.layers.30.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.30.mlp.up_proj.g_idx\u201D\
          , \u201Cmodel.layers.31.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.31.self_attn.o_proj.g_idx\u201D\
          , \u201Cmodel.layers.31.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.31.self_attn.v_proj.g_idx\u201D\
          , \u201Cmodel.layers.31.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.31.mlp.gate_proj.g_idx\u201D\
          , \u201Cmodel.layers.31.mlp.up_proj.g_idx\u201D."
        updatedAt: '2023-05-10T14:50:00.770Z'
      numEdits: 0
      reactions: []
    id: 645baf18c971fbab74208c42
    type: comment
  author: Krougher
  content: "Hi thanks for your answers, i updated oobabooga, redone the config 4/128/llama,\
    \ and now i have that error:\n\n\nTraceback (most recent call last):\nFile \u201C\
    D:\\AI\\TextAI\\oobabooga-windows\\text-generation-webui\\server.py\u201D, line\
    \ 67, in load_model_wrapper\nshared.model, shared.tokenizer = load_model(shared.model_name)\n\
    File \u201CD:\\AI\\TextAI\\oobabooga-windows\\text-generation-webui\\modules\\\
    models.py\u201D, line 159, in load_model\nmodel = load_quantized(model_name)\n\
    File \u201CD:\\AI\\TextAI\\oobabooga-windows\\text-generation-webui\\modules\\\
    GPTQ_loader.py\u201D, line 181, in load_quantized\nmodel = load_quant(str(path_to_model),\
    \ str(pt_path), shared.args.wbits, shared.args.groupsize, shared.args.pre_layer)\n\
    File \u201CD:\\AI\\TextAI\\oobabooga-windows\\text-generation-webui\\repositories\\\
    GPTQ-for-LLaMa\\llama_inference_offload.py\u201D, line 226, in load_quant\nmodel.load_state_dict(safe_load(checkpoint))\n\
    File \u201CD:\\AI\\TextAI\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    torch\\nn\\modules\\module.py\u201D, line 2041, in load_state_dict\nraise RuntimeError(\u2018\
    Error(s) in loading state_dict for {}:\\n\\t{}\u2019.format(\nRuntimeError: Error(s)\
    \ in loading state_dict for LlamaForCausalLM:\nMissing key(s) in state_dict: \u201C\
    model.layers.0.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.0.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.0.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.0.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.0.mlp.down_proj.bias\u201D, \u201Cmodel.layers.0.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.0.mlp.up_proj.bias\u201D, \u201Cmodel.layers.1.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.1.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.1.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.1.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.1.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.1.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.1.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.2.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.2.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.2.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.2.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.2.mlp.down_proj.bias\u201D, \u201Cmodel.layers.2.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.2.mlp.up_proj.bias\u201D, \u201Cmodel.layers.3.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.3.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.3.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.3.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.3.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.3.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.3.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.4.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.4.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.4.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.4.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.4.mlp.down_proj.bias\u201D, \u201Cmodel.layers.4.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.4.mlp.up_proj.bias\u201D, \u201Cmodel.layers.5.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.5.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.5.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.5.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.5.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.5.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.5.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.6.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.6.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.6.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.6.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.6.mlp.down_proj.bias\u201D, \u201Cmodel.layers.6.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.6.mlp.up_proj.bias\u201D, \u201Cmodel.layers.7.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.7.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.7.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.7.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.7.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.7.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.7.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.8.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.8.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.8.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.8.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.8.mlp.down_proj.bias\u201D, \u201Cmodel.layers.8.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.8.mlp.up_proj.bias\u201D, \u201Cmodel.layers.9.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.9.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.9.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.9.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.9.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.9.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.9.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.10.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.10.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.10.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.10.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.10.mlp.down_proj.bias\u201D, \u201Cmodel.layers.10.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.10.mlp.up_proj.bias\u201D, \u201Cmodel.layers.11.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.11.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.11.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.11.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.11.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.11.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.11.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.12.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.12.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.12.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.12.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.12.mlp.down_proj.bias\u201D, \u201Cmodel.layers.12.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.12.mlp.up_proj.bias\u201D, \u201Cmodel.layers.13.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.13.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.13.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.13.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.13.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.13.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.13.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.14.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.14.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.14.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.14.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.14.mlp.down_proj.bias\u201D, \u201Cmodel.layers.14.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.14.mlp.up_proj.bias\u201D, \u201Cmodel.layers.15.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.15.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.15.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.15.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.15.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.15.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.15.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.16.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.16.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.16.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.16.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.16.mlp.down_proj.bias\u201D, \u201Cmodel.layers.16.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.16.mlp.up_proj.bias\u201D, \u201Cmodel.layers.17.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.17.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.17.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.17.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.17.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.17.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.17.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.18.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.18.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.18.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.18.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.18.mlp.down_proj.bias\u201D, \u201Cmodel.layers.18.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.18.mlp.up_proj.bias\u201D, \u201Cmodel.layers.19.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.19.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.19.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.19.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.19.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.19.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.19.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.20.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.20.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.20.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.20.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.20.mlp.down_proj.bias\u201D, \u201Cmodel.layers.20.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.20.mlp.up_proj.bias\u201D, \u201Cmodel.layers.21.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.21.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.21.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.21.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.21.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.21.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.21.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.22.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.22.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.22.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.22.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.22.mlp.down_proj.bias\u201D, \u201Cmodel.layers.22.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.22.mlp.up_proj.bias\u201D, \u201Cmodel.layers.23.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.23.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.23.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.23.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.23.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.23.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.23.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.24.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.24.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.24.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.24.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.24.mlp.down_proj.bias\u201D, \u201Cmodel.layers.24.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.24.mlp.up_proj.bias\u201D, \u201Cmodel.layers.25.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.25.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.25.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.25.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.25.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.25.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.25.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.26.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.26.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.26.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.26.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.26.mlp.down_proj.bias\u201D, \u201Cmodel.layers.26.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.26.mlp.up_proj.bias\u201D, \u201Cmodel.layers.27.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.27.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.27.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.27.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.27.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.27.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.27.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.28.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.28.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.28.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.28.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.28.mlp.down_proj.bias\u201D, \u201Cmodel.layers.28.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.28.mlp.up_proj.bias\u201D, \u201Cmodel.layers.29.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.29.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.29.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.29.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.29.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.29.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.29.mlp.up_proj.bias\u201D\
    , \u201Cmodel.layers.30.self_attn.k_proj.bias\u201D, \u201Cmodel.layers.30.self_attn.o_proj.bias\u201D\
    , \u201Cmodel.layers.30.self_attn.q_proj.bias\u201D, \u201Cmodel.layers.30.self_attn.v_proj.bias\u201D\
    , \u201Cmodel.layers.30.mlp.down_proj.bias\u201D, \u201Cmodel.layers.30.mlp.gate_proj.bias\u201D\
    , \u201Cmodel.layers.30.mlp.up_proj.bias\u201D, \u201Cmodel.layers.31.self_attn.k_proj.bias\u201D\
    , \u201Cmodel.layers.31.self_attn.o_proj.bias\u201D, \u201Cmodel.layers.31.self_attn.q_proj.bias\u201D\
    , \u201Cmodel.layers.31.self_attn.v_proj.bias\u201D, \u201Cmodel.layers.31.mlp.down_proj.bias\u201D\
    , \u201Cmodel.layers.31.mlp.gate_proj.bias\u201D, \u201Cmodel.layers.31.mlp.up_proj.bias\u201D\
    .\nUnexpected key(s) in state_dict: \u201Cmodel.layers.0.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.0.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.0.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.0.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.0.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.0.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.0.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.1.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.1.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.1.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.1.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.1.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.1.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.1.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.2.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.2.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.2.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.2.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.2.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.2.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.2.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.3.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.3.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.3.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.3.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.3.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.3.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.3.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.4.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.4.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.4.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.4.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.4.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.4.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.4.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.5.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.5.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.5.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.5.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.5.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.5.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.5.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.6.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.6.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.6.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.6.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.6.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.6.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.6.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.7.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.7.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.7.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.7.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.7.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.7.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.7.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.8.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.8.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.8.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.8.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.8.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.8.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.8.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.9.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.9.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.9.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.9.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.9.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.9.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.9.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.10.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.10.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.10.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.10.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.10.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.10.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.10.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.11.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.11.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.11.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.11.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.11.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.11.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.11.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.12.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.12.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.12.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.12.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.12.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.12.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.12.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.13.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.13.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.13.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.13.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.13.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.13.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.13.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.14.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.14.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.14.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.14.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.14.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.14.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.14.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.15.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.15.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.15.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.15.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.15.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.15.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.15.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.16.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.16.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.16.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.16.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.16.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.16.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.16.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.17.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.17.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.17.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.17.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.17.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.17.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.17.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.18.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.18.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.18.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.18.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.18.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.18.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.18.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.19.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.19.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.19.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.19.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.19.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.19.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.19.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.20.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.20.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.20.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.20.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.20.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.20.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.20.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.21.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.21.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.21.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.21.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.21.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.21.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.21.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.22.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.22.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.22.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.22.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.22.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.22.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.22.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.23.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.23.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.23.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.23.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.23.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.23.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.23.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.24.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.24.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.24.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.24.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.24.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.24.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.24.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.25.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.25.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.25.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.25.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.25.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.25.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.25.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.26.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.26.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.26.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.26.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.26.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.26.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.26.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.27.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.27.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.27.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.27.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.27.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.27.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.27.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.28.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.28.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.28.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.28.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.28.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.28.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.28.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.29.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.29.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.29.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.29.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.29.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.29.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.29.mlp.up_proj.g_idx\u201D, \u201Cmodel.layers.30.self_attn.k_proj.g_idx\u201D\
    , \u201Cmodel.layers.30.self_attn.o_proj.g_idx\u201D, \u201Cmodel.layers.30.self_attn.q_proj.g_idx\u201D\
    , \u201Cmodel.layers.30.self_attn.v_proj.g_idx\u201D, \u201Cmodel.layers.30.mlp.down_proj.g_idx\u201D\
    , \u201Cmodel.layers.30.mlp.gate_proj.g_idx\u201D, \u201Cmodel.layers.30.mlp.up_proj.g_idx\u201D\
    , \u201Cmodel.layers.31.self_attn.k_proj.g_idx\u201D, \u201Cmodel.layers.31.self_attn.o_proj.g_idx\u201D\
    , \u201Cmodel.layers.31.self_attn.q_proj.g_idx\u201D, \u201Cmodel.layers.31.self_attn.v_proj.g_idx\u201D\
    , \u201Cmodel.layers.31.mlp.down_proj.g_idx\u201D, \u201Cmodel.layers.31.mlp.gate_proj.g_idx\u201D\
    , \u201Cmodel.layers.31.mlp.up_proj.g_idx\u201D."
  created_at: 2023-05-10 13:50:00+00:00
  edited: false
  hidden: false
  id: 645baf18c971fbab74208c42
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-10T20:18:47.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Ah yeah this happens when the GPTQ models are used with <code>pre_layer</code>
          to enable CPU offload. I don''t have a solution for that atm, other than
          using a more recent version of GPTQ-for-LLaMA. Check out the ''manual install''
          section of one of my older GPTQ READMEs (I stopped putting it in the more
          recent ones as it tended to confuse people.)</p>

          '
        raw: Ah yeah this happens when the GPTQ models are used with `pre_layer` to
          enable CPU offload. I don't have a solution for that atm, other than using
          a more recent version of GPTQ-for-LLaMA. Check out the 'manual install'
          section of one of my older GPTQ READMEs (I stopped putting it in the more
          recent ones as it tended to confuse people.)
        updatedAt: '2023-05-10T20:18:47.731Z'
      numEdits: 0
      reactions: []
    id: 645bfc27c971fbab74237b15
    type: comment
  author: TheBloke
  content: Ah yeah this happens when the GPTQ models are used with `pre_layer` to
    enable CPU offload. I don't have a solution for that atm, other than using a more
    recent version of GPTQ-for-LLaMA. Check out the 'manual install' section of one
    of my older GPTQ READMEs (I stopped putting it in the more recent ones as it tended
    to confuse people.)
  created_at: 2023-05-10 19:18:47+00:00
  edited: false
  hidden: false
  id: 645bfc27c971fbab74237b15
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: TheBloke/WizardLM-7B-uncensored-GPTQ
repo_type: model
status: open
target_branch: null
title: Error while loading model, even with savec settings.
