!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TheEncrypted777
conflicting_files: null
created_at: 2023-05-05 11:11:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7f96fe532484a3c26584c07abd01bd1c.svg
      fullname: Encrypted
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheEncrypted777
      type: user
    createdAt: '2023-05-05T12:11:40.000Z'
    data:
      edited: false
      editors:
      - TheEncrypted777
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7f96fe532484a3c26584c07abd01bd1c.svg
          fullname: Encrypted
          isHf: false
          isPro: false
          name: TheEncrypted777
          type: user
        html: '<p>Installed successfully, properly set the GPTQ parameters, but when
          generating a prompt, I get the following error: </p>

          <p>Traceback (most recent call last):<br>  File "D:\DOCUMENTS\ai\oobabooga-windows\text-generation-webui\modules\callbacks.py",
          line 66, in gentask<br>    ret = self.mfunc(callback=_callback, **self.kwargs)<br>  File
          "D:\DOCUMENTS\ai\oobabooga-windows\text-generation-webui\modules\text_generation.py",
          line 252, in generate_with_callback<br>    shared.model.generate(**kwargs)<br>  File
          "D:\DOCUMENTS\ai\oobabooga-windows\installer_files\env\lib\site-packages\torch\utils_contextlib.py",
          line 115, in decorate_context<br>    return func(*args, **kwargs)<br>  File
          "D:\DOCUMENTS\ai\oobabooga-windows\installer_files\env\lib\site-packages\transformers\generation\utils.py",
          line 1485, in generate<br>    return self.sample(<br>  File "D:\DOCUMENTS\ai\oobabooga-windows\installer_files\env\lib\site-packages\transformers\generation\utils.py",
          line 2560, in sample<br>    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)<br>RuntimeError:
          probability tensor contains either <code>inf</code>, <code>nan</code> or
          element &lt; 0</p>

          '
        raw: "Installed successfully, properly set the GPTQ parameters, but when generating\
          \ a prompt, I get the following error: \r\n\r\nTraceback (most recent call\
          \ last):\r\n  File \"D:\\DOCUMENTS\\ai\\oobabooga-windows\\text-generation-webui\\\
          modules\\callbacks.py\", line 66, in gentask\r\n    ret = self.mfunc(callback=_callback,\
          \ **self.kwargs)\r\n  File \"D:\\DOCUMENTS\\ai\\oobabooga-windows\\text-generation-webui\\\
          modules\\text_generation.py\", line 252, in generate_with_callback\r\n \
          \   shared.model.generate(**kwargs)\r\n  File \"D:\\DOCUMENTS\\ai\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\torch\\utils\\_contextlib.py\"\
          , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n\
          \  File \"D:\\DOCUMENTS\\ai\\oobabooga-windows\\installer_files\\env\\lib\\\
          site-packages\\transformers\\generation\\utils.py\", line 1485, in generate\r\
          \n    return self.sample(\r\n  File \"D:\\DOCUMENTS\\ai\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\generation\\utils.py\"\
          , line 2560, in sample\r\n    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)\r\
          \nRuntimeError: probability tensor contains either `inf`, `nan` or element\
          \ < 0"
        updatedAt: '2023-05-05T12:11:40.245Z'
      numEdits: 0
      reactions: []
    id: 6454f27cb27940efcb941c84
    type: comment
  author: TheEncrypted777
  content: "Installed successfully, properly set the GPTQ parameters, but when generating\
    \ a prompt, I get the following error: \r\n\r\nTraceback (most recent call last):\r\
    \n  File \"D:\\DOCUMENTS\\ai\\oobabooga-windows\\text-generation-webui\\modules\\\
    callbacks.py\", line 66, in gentask\r\n    ret = self.mfunc(callback=_callback,\
    \ **self.kwargs)\r\n  File \"D:\\DOCUMENTS\\ai\\oobabooga-windows\\text-generation-webui\\\
    modules\\text_generation.py\", line 252, in generate_with_callback\r\n    shared.model.generate(**kwargs)\r\
    \n  File \"D:\\DOCUMENTS\\ai\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    torch\\utils\\_contextlib.py\", line 115, in decorate_context\r\n    return func(*args,\
    \ **kwargs)\r\n  File \"D:\\DOCUMENTS\\ai\\oobabooga-windows\\installer_files\\\
    env\\lib\\site-packages\\transformers\\generation\\utils.py\", line 1485, in generate\r\
    \n    return self.sample(\r\n  File \"D:\\DOCUMENTS\\ai\\oobabooga-windows\\installer_files\\\
    env\\lib\\site-packages\\transformers\\generation\\utils.py\", line 2560, in sample\r\
    \n    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)\r\nRuntimeError:\
    \ probability tensor contains either `inf`, `nan` or element < 0"
  created_at: 2023-05-05 11:11:40+00:00
  edited: false
  hidden: false
  id: 6454f27cb27940efcb941c84
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-05T12:45:45.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Hm that''s odd. First of all can you check the sha256sum and confirm
          it''s downloaded correctly compared to what''s shown on HF:</p>

          <pre><code>Git LFS Details

          SHA256: 232c254d1ab4c8992e509467c88face36a7f5c3ce774736c7f8fcda07581a008

          Pointer size: 135 Bytes

          Size of remote file: 3.89 GB

          </code></pre>

          '
        raw: 'Hm that''s odd. First of all can you check the sha256sum and confirm
          it''s downloaded correctly compared to what''s shown on HF:

          ```

          Git LFS Details

          SHA256: 232c254d1ab4c8992e509467c88face36a7f5c3ce774736c7f8fcda07581a008

          Pointer size: 135 Bytes

          Size of remote file: 3.89 GB

          ```'
        updatedAt: '2023-05-05T12:45:45.053Z'
      numEdits: 0
      reactions: []
    id: 6454fa79d55525a4fee41a5a
    type: comment
  author: TheBloke
  content: 'Hm that''s odd. First of all can you check the sha256sum and confirm it''s
    downloaded correctly compared to what''s shown on HF:

    ```

    Git LFS Details

    SHA256: 232c254d1ab4c8992e509467c88face36a7f5c3ce774736c7f8fcda07581a008

    Pointer size: 135 Bytes

    Size of remote file: 3.89 GB

    ```'
  created_at: 2023-05-05 11:45:45+00:00
  edited: false
  hidden: false
  id: 6454fa79d55525a4fee41a5a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7f96fe532484a3c26584c07abd01bd1c.svg
      fullname: Encrypted
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheEncrypted777
      type: user
    createdAt: '2023-05-05T13:31:18.000Z'
    data:
      edited: false
      editors:
      - TheEncrypted777
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7f96fe532484a3c26584c07abd01bd1c.svg
          fullname: Encrypted
          isHf: false
          isPro: false
          name: TheEncrypted777
          type: user
        html: '<p>Redownloaded and it seems to work now, thank you.</p>

          <blockquote>

          <p>Hm that''s odd. First of all can you check the sha256sum and confirm
          it''s downloaded correctly compared to what''s shown on HF:</p>

          <pre><code>Git LFS Details

          SHA256: 232c254d1ab4c8992e509467c88face36a7f5c3ce774736c7f8fcda07581a008

          Pointer size: 135 Bytes

          Size of remote file: 3.89 GB

          </code></pre>

          </blockquote>

          '
        raw: 'Redownloaded and it seems to work now, thank you.

          > Hm that''s odd. First of all can you check the sha256sum and confirm it''s
          downloaded correctly compared to what''s shown on HF:

          > ```

          > Git LFS Details

          > SHA256: 232c254d1ab4c8992e509467c88face36a7f5c3ce774736c7f8fcda07581a008

          > Pointer size: 135 Bytes

          > Size of remote file: 3.89 GB

          > ```'
        updatedAt: '2023-05-05T13:31:18.330Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TheBloke
    id: 64550526a473375be56ee9b0
    type: comment
  author: TheEncrypted777
  content: 'Redownloaded and it seems to work now, thank you.

    > Hm that''s odd. First of all can you check the sha256sum and confirm it''s downloaded
    correctly compared to what''s shown on HF:

    > ```

    > Git LFS Details

    > SHA256: 232c254d1ab4c8992e509467c88face36a7f5c3ce774736c7f8fcda07581a008

    > Pointer size: 135 Bytes

    > Size of remote file: 3.89 GB

    > ```'
  created_at: 2023-05-05 12:31:18+00:00
  edited: false
  hidden: false
  id: 64550526a473375be56ee9b0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/7f96fe532484a3c26584c07abd01bd1c.svg
      fullname: Encrypted
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheEncrypted777
      type: user
    createdAt: '2023-05-05T13:31:29.000Z'
    data:
      status: closed
    id: 64550531f61f10d69dc6c741
    type: status-change
  author: TheEncrypted777
  created_at: 2023-05-05 12:31:29+00:00
  id: 64550531f61f10d69dc6c741
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/WizardLM-7B-uncensored-GPTQ
repo_type: model
status: closed
target_branch: null
title: Error upon generating text.
