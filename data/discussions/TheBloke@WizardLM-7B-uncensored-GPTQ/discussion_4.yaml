!!python/object:huggingface_hub.community.DiscussionWithDetails
author: loser0020
conflicting_files: null
created_at: 2023-05-06 20:05:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/879454593c4bbb535cf12eeef4a6fe1d.svg
      fullname: ibi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: loser0020
      type: user
    createdAt: '2023-05-06T21:05:53.000Z'
    data:
      edited: false
      editors:
      - loser0020
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/879454593c4bbb535cf12eeef4a6fe1d.svg
          fullname: ibi
          isHf: false
          isPro: false
          name: loser0020
          type: user
        html: "<p>Traceback (most recent call last):<br>File \u201CC:\\ai\\oobabooga-windows\\\
          oobabooga-windows\\text-generation-webui\\server.py\u201D, line 103, in\
          \ load_model_wrapper<br>shared.model, shared.tokenizer = load_model(shared.model_name)<br>File\
          \ \u201CC:\\ai\\oobabooga-windows\\oobabooga-windows\\text-generation-webui\\\
          modules\\models.py\u201D, line 219, in load_model<br>model = LoaderClass.from_pretrained(checkpoint,\
          \ **params)<br>File \u201CC:\\ai\\oobabooga-windows\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u201D\
          , line 471, in from_pretrained<br>return model_class.from_pretrained(<br>File\
          \ \u201CC:\\ai\\oobabooga-windows\\oobabooga-windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\modeling_utils.py\u201D, line 2405,\
          \ in from_pretrained<br>raise EnvironmentError(<br>OSError: Error no file\
          \ named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
          \ found in directory models\\TheBloke_WizardLM-7B-uncensored-GPTQ.</p>\n\
          <p>tried restarting ooba as well but no working</p>\n"
        raw: "Traceback (most recent call last):\r\nFile \u201CC:\\ai\\oobabooga-windows\\\
          oobabooga-windows\\text-generation-webui\\server.py\u201D, line 103, in\
          \ load_model_wrapper\r\nshared.model, shared.tokenizer = load_model(shared.model_name)\r\
          \nFile \u201CC:\\ai\\oobabooga-windows\\oobabooga-windows\\text-generation-webui\\\
          modules\\models.py\u201D, line 219, in load_model\r\nmodel = LoaderClass.from_pretrained(checkpoint,\
          \ **params)\r\nFile \u201CC:\\ai\\oobabooga-windows\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u201D\
          , line 471, in from_pretrained\r\nreturn model_class.from_pretrained(\r\n\
          File \u201CC:\\ai\\oobabooga-windows\\oobabooga-windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\modeling_utils.py\u201D, line 2405,\
          \ in from_pretrained\r\nraise EnvironmentError(\r\nOSError: Error no file\
          \ named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
          \ found in directory models\\TheBloke_WizardLM-7B-uncensored-GPTQ.\r\n\r\
          \ntried restarting ooba as well but no working"
        updatedAt: '2023-05-06T21:05:53.260Z'
      numEdits: 0
      reactions: []
    id: 6456c1314cfac49227922b87
    type: comment
  author: loser0020
  content: "Traceback (most recent call last):\r\nFile \u201CC:\\ai\\oobabooga-windows\\\
    oobabooga-windows\\text-generation-webui\\server.py\u201D, line 103, in load_model_wrapper\r\
    \nshared.model, shared.tokenizer = load_model(shared.model_name)\r\nFile \u201C\
    C:\\ai\\oobabooga-windows\\oobabooga-windows\\text-generation-webui\\modules\\\
    models.py\u201D, line 219, in load_model\r\nmodel = LoaderClass.from_pretrained(checkpoint,\
    \ **params)\r\nFile \u201CC:\\ai\\oobabooga-windows\\oobabooga-windows\\installer_files\\\
    env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u201D, line\
    \ 471, in from_pretrained\r\nreturn model_class.from_pretrained(\r\nFile \u201C\
    C:\\ai\\oobabooga-windows\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\modeling_utils.py\u201D, line 2405, in from_pretrained\r\nraise\
    \ EnvironmentError(\r\nOSError: Error no file named pytorch_model.bin, tf_model.h5,\
    \ model.ckpt.index or flax_model.msgpack found in directory models\\TheBloke_WizardLM-7B-uncensored-GPTQ.\r\
    \n\r\ntried restarting ooba as well but no working"
  created_at: 2023-05-06 20:05:53+00:00
  edited: false
  hidden: false
  id: 6456c1314cfac49227922b87
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c102346f9bb46b7506a4b0b3db0ee0f7.svg
      fullname: noro moxy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: noromoxy
      type: user
    createdAt: '2023-05-06T21:07:32.000Z'
    data:
      edited: false
      editors:
      - noromoxy
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c102346f9bb46b7506a4b0b3db0ee0f7.svg
          fullname: noro moxy
          isHf: false
          isPro: false
          name: noromoxy
          type: user
        html: '<p>I get the same error.</p>

          '
        raw: I get the same error.
        updatedAt: '2023-05-06T21:07:32.109Z'
      numEdits: 0
      reactions: []
    id: 6456c19403625871eb7ad7a0
    type: comment
  author: noromoxy
  content: I get the same error.
  created_at: 2023-05-06 20:07:32+00:00
  edited: false
  hidden: false
  id: 6456c19403625871eb7ad7a0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/879454593c4bbb535cf12eeef4a6fe1d.svg
      fullname: ibi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: loser0020
      type: user
    createdAt: '2023-05-06T21:15:03.000Z'
    data:
      edited: false
      editors:
      - loser0020
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/879454593c4bbb535cf12eeef4a6fe1d.svg
          fullname: ibi
          isHf: false
          isPro: false
          name: loser0020
          type: user
        html: '<blockquote>

          <p>I get the same error.</p>

          </blockquote>

          <p>nvm i found out why. click save settings for this model and then reload
          it. then choose 4bit and 126 and llama type and save again and then reload</p>

          '
        raw: '> I get the same error.


          nvm i found out why. click save settings for this model and then reload
          it. then choose 4bit and 126 and llama type and save again and then reload'
        updatedAt: '2023-05-06T21:15:03.580Z'
      numEdits: 0
      reactions: []
    id: 6456c35703625871eb7af34b
    type: comment
  author: loser0020
  content: '> I get the same error.


    nvm i found out why. click save settings for this model and then reload it. then
    choose 4bit and 126 and llama type and save again and then reload'
  created_at: 2023-05-06 20:15:03+00:00
  edited: false
  hidden: false
  id: 6456c35703625871eb7af34b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/879454593c4bbb535cf12eeef4a6fe1d.svg
      fullname: ibi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: loser0020
      type: user
    createdAt: '2023-05-06T21:15:06.000Z'
    data:
      status: closed
    id: 6456c35ad10badc955616e8b
    type: status-change
  author: loser0020
  created_at: 2023-05-06 20:15:06+00:00
  id: 6456c35ad10badc955616e8b
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-07T06:33:06.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<blockquote>

          <blockquote>

          <p>I get the same error.</p>

          </blockquote>

          <p>nvm i found out why. click save settings for this model and then reload
          it. then choose 4bit and 126 and llama type and save again and then reload</p>

          </blockquote>

          <p>Yup. Just like it says in the README! :)</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/-YtvDjsRiUjsN-dwQtTy6.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/-YtvDjsRiUjsN-dwQtTy6.png"></a></p>

          '
        raw: "> > I get the same error.\n> \n> nvm i found out why. click save settings\
          \ for this model and then reload it. then choose 4bit and 126 and llama\
          \ type and save again and then reload\n\nYup. Just like it says in the README!\
          \ :)\n\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/-YtvDjsRiUjsN-dwQtTy6.png)"
        updatedAt: '2023-05-07T06:33:06.992Z'
      numEdits: 0
      reactions: []
    id: 6457462245536759276011a1
    type: comment
  author: TheBloke
  content: "> > I get the same error.\n> \n> nvm i found out why. click save settings\
    \ for this model and then reload it. then choose 4bit and 126 and llama type and\
    \ save again and then reload\n\nYup. Just like it says in the README! :)\n\n\n\
    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/-YtvDjsRiUjsN-dwQtTy6.png)"
  created_at: 2023-05-07 05:33:06+00:00
  edited: false
  hidden: false
  id: 6457462245536759276011a1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TheBloke/WizardLM-7B-uncensored-GPTQ
repo_type: model
status: closed
target_branch: null
title: error
