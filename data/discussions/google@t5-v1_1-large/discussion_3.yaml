!!python/object:huggingface_hub.community.DiscussionWithDetails
author: CUIGuy
conflicting_files: null
created_at: 2023-12-31 05:23:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af5e8947845d198701e452cd8a514cce.svg
      fullname: Xiaoyun Wu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CUIGuy
      type: user
    createdAt: '2023-12-31T05:23:27.000Z'
    data:
      edited: false
      editors:
      - CUIGuy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9442505240440369
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af5e8947845d198701e452cd8a514cce.svg
          fullname: Xiaoyun Wu
          isHf: false
          isPro: false
          name: CUIGuy
          type: user
        html: '<p>ValueError: You are trying to save a non contiguous tensor: <code>encoder.block.0.layer.0.SelfAttention.q.weight</code>
          which is not allowed. It either means you are trying to save tensors which
          are reference of each other in which case it''s recommended to save only
          the full tensors, and reslice at load time, or simply call <code>.contiguous()</code>
          on your tensor to pack it before saving.</p>

          <p>I have some code that fine-tune flan t5 on some nlp tasks, and when I
          try to switch to this version instead, the same code give me this, what
          I am missing? I thought we should use this instead flan T5 for fine tuning,
          the transformer code is not working on this one?</p>

          '
        raw: "ValueError: You are trying to save a non contiguous tensor: `encoder.block.0.layer.0.SelfAttention.q.weight`\
          \ which is not allowed. It either means you are trying to save tensors which\
          \ are reference of each other in which case it's recommended to save only\
          \ the full tensors, and reslice at load time, or simply call `.contiguous()`\
          \ on your tensor to pack it before saving.\r\n\r\nI have some code that\
          \ fine-tune flan t5 on some nlp tasks, and when I try to switch to this\
          \ version instead, the same code give me this, what I am missing? I thought\
          \ we should use this instead flan T5 for fine tuning, the transformer code\
          \ is not working on this one?"
        updatedAt: '2023-12-31T05:23:27.647Z'
      numEdits: 0
      reactions: []
    id: 6590facf68d0b76331d9782b
    type: comment
  author: CUIGuy
  content: "ValueError: You are trying to save a non contiguous tensor: `encoder.block.0.layer.0.SelfAttention.q.weight`\
    \ which is not allowed. It either means you are trying to save tensors which are\
    \ reference of each other in which case it's recommended to save only the full\
    \ tensors, and reslice at load time, or simply call `.contiguous()` on your tensor\
    \ to pack it before saving.\r\n\r\nI have some code that fine-tune flan t5 on\
    \ some nlp tasks, and when I try to switch to this version instead, the same code\
    \ give me this, what I am missing? I thought we should use this instead flan T5\
    \ for fine tuning, the transformer code is not working on this one?"
  created_at: 2023-12-31 05:23:27+00:00
  edited: false
  hidden: false
  id: 6590facf68d0b76331d9782b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: google/t5-v1_1-large
repo_type: model
status: open
target_branch: null
title: the same fine tune code, flan t5 work, and this does not.
