!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nickhugs
conflicting_files: []
created_at: 2023-02-08 23:45:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/02a70c7e57d742b06b4508616c5bfc72.svg
      fullname: Nick Hill
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nickhugs
      type: user
    createdAt: '2023-02-08T23:45:19.000Z'
    data:
      edited: false
      editors:
      - nickhugs
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/02a70c7e57d742b06b4508616c5bfc72.svg
          fullname: Nick Hill
          isHf: false
          isPro: false
          name: nickhugs
          type: user
        html: '<p>The current values don''t appear to even be in the vocab. This makes
          it match the recent updates done to the tokenizer config.</p>

          '
        raw: The current values don't appear to even be in the vocab. This makes it
          match the recent updates done to the tokenizer config.
        updatedAt: '2023-02-08T23:45:19.582Z'
      numEdits: 0
      reactions: []
    id: 63e4340f27da6c5651273206
    type: comment
  author: nickhugs
  content: The current values don't appear to even be in the vocab. This makes it
    match the recent updates done to the tokenizer config.
  created_at: 2023-02-08 23:45:19+00:00
  edited: false
  hidden: false
  id: 63e4340f27da6c5651273206
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/02a70c7e57d742b06b4508616c5bfc72.svg
      fullname: Nick Hill
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nickhugs
      type: user
    createdAt: '2023-02-08T23:45:20.000Z'
    data:
      oid: fb44eff34ade2abe395a5f5108b9f7eb47ead6ee
      parents:
      - 636ad0a694975c25bdb8a16fb8ffda275525a2a8
      subject: Update eos_token_id / bos_token_id in config.json
    id: 63e434100000000000000000
    type: commit
  author: nickhugs
  created_at: 2023-02-08 23:45:20+00:00
  id: 63e434100000000000000000
  oid: fb44eff34ade2abe395a5f5108b9f7eb47ead6ee
  summary: Update eos_token_id / bos_token_id in config.json
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1656685953025-62bf03d1e80cec527083cd66.jpeg?w=200&h=200&f=face
      fullname: Benjamin Bossan
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BenjaminB
      type: user
    createdAt: '2023-03-23T15:01:55.000Z'
    data:
      edited: false
      editors:
      - BenjaminB
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1656685953025-62bf03d1e80cec527083cd66.jpeg?w=200&h=200&f=face
          fullname: Benjamin Bossan
          isHf: true
          isPro: false
          name: BenjaminB
          type: user
        html: '<p>Can confirm that this may cause bugs. To reproduce, take the example
          from the README and pass <code>min_new_tokens</code> to <code>generate</code>:</p>

          <pre><code class="language-python"><span class="hljs-keyword">from</span>
          transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM,
          AutoTokenizer


          checkpoint = <span class="hljs-string">"bigcode/santacoder"</span>

          device = <span class="hljs-string">"cuda"</span>

          tokenizer = AutoTokenizer.from_pretrained(checkpoint)


          inputs = tokenizer.encode(<span class="hljs-string">"def print_hello_world():"</span>,
          return_tensors=<span class="hljs-string">"pt"</span>).to(device)

          outputs = model.generate(inputs, min_new_tokens=<span class="hljs-number">5</span>)  <span
          class="hljs-comment"># &lt;== change</span>


          <span class="hljs-comment"># raises IndexError: index 50256 is out of bounds
          for dimension 1 with size 49280</span>

          </code></pre>

          <p>Passing <code>min_new_tokens</code> results in the <code>logits_processor</code>
          containing a <code>MinNewTokensLengthLogitsProcessor</code> with the incorrect
          <code>eos_token_id</code>, which causes the <code>IndexError</code>. Other
          additional arguments may have similar effects, I haven''t tested.</p>

          '
        raw: 'Can confirm that this may cause bugs. To reproduce, take the example
          from the README and pass `min_new_tokens` to `generate`:


          ```python

          from transformers import AutoModelForCausalLM, AutoTokenizer


          checkpoint = "bigcode/santacoder"

          device = "cuda"

          tokenizer = AutoTokenizer.from_pretrained(checkpoint)


          inputs = tokenizer.encode("def print_hello_world():", return_tensors="pt").to(device)

          outputs = model.generate(inputs, min_new_tokens=5)  # <== change


          # raises IndexError: index 50256 is out of bounds for dimension 1 with size
          49280

          ```


          Passing `min_new_tokens` results in the `logits_processor` containing a
          `MinNewTokensLengthLogitsProcessor` with the incorrect `eos_token_id`, which
          causes the `IndexError`. Other additional arguments may have similar effects,
          I haven''t tested.'
        updatedAt: '2023-03-23T15:01:55.703Z'
      numEdits: 0
      reactions: []
    id: 641c69e38357e6ae9b1a0f7e
    type: comment
  author: BenjaminB
  content: 'Can confirm that this may cause bugs. To reproduce, take the example from
    the README and pass `min_new_tokens` to `generate`:


    ```python

    from transformers import AutoModelForCausalLM, AutoTokenizer


    checkpoint = "bigcode/santacoder"

    device = "cuda"

    tokenizer = AutoTokenizer.from_pretrained(checkpoint)


    inputs = tokenizer.encode("def print_hello_world():", return_tensors="pt").to(device)

    outputs = model.generate(inputs, min_new_tokens=5)  # <== change


    # raises IndexError: index 50256 is out of bounds for dimension 1 with size 49280

    ```


    Passing `min_new_tokens` results in the `logits_processor` containing a `MinNewTokensLengthLogitsProcessor`
    with the incorrect `eos_token_id`, which causes the `IndexError`. Other additional
    arguments may have similar effects, I haven''t tested.'
  created_at: 2023-03-23 14:01:55+00:00
  edited: false
  hidden: false
  id: 641c69e38357e6ae9b1a0f7e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-04-23T15:41:23.000Z'
    data:
      edited: false
      editors:
      - loubnabnl
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
          fullname: Loubna Ben Allal
          isHf: true
          isPro: false
          name: loubnabnl
          type: user
        html: '<p>thanks for the fix!</p>

          '
        raw: thanks for the fix!
        updatedAt: '2023-04-23T15:41:23.526Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - nickhugs
      relatedEventId: 644551a353ecc52f50f0074e
    id: 644551a353ecc52f50f0074d
    type: comment
  author: loubnabnl
  content: thanks for the fix!
  created_at: 2023-04-23 14:41:23+00:00
  edited: false
  hidden: false
  id: 644551a353ecc52f50f0074d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-04-23T15:41:23.000Z'
    data:
      status: merged
    id: 644551a353ecc52f50f0074e
    type: status-change
  author: loubnabnl
  created_at: 2023-04-23 14:41:23+00:00
  id: 644551a353ecc52f50f0074e
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 0b048f3e0e15a18cecf974ff5e264d995402a788
num: 19
repo_id: bigcode/santacoder
repo_type: model
status: merged
target_branch: refs/heads/main
title: Update eos_token_id / bos_token_id in config.json
