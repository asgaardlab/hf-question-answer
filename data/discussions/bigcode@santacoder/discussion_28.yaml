!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kanandk
conflicting_files: null
created_at: 2023-04-24 09:33:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/842a2dadb44eda3943783560e440a79c.svg
      fullname: Anand Keshavan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kanandk
      type: user
    createdAt: '2023-04-24T10:33:50.000Z'
    data:
      edited: false
      editors:
      - kanandk
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/842a2dadb44eda3943783560e440a79c.svg
          fullname: Anand Keshavan
          isHf: false
          isPro: false
          name: kanandk
          type: user
        html: '<p>It gives the following error:</p>

          <p> An error occurred (ModelError) when calling the InvokeEndpoint operation:
          Received client error (400) from primary with message "{<br>  "code": 400,<br>  "type":
          "InternalServerException",<br>  "message": "Loading /.sagemaker/mms/models/bigcode__santacoder
          requires you to execute the configuration file in that repo on your local
          machine. Make sure you have read the code there to avoid malicious use,
          then set the option <code>trust_remote_code\u003dTrue</code> to remove this
          error."<br>}</p>

          <p>Source:</p>

          <p>from sagemaker.huggingface import HuggingFaceModel<br>import sagemaker</p>

          <p>role = sagemaker.get_execution_role()</p>

          <h1 id="hub-model-configuration-httpshuggingfacecomodels">Hub Model configuration.
          <a href="https://huggingface.co/models">https://huggingface.co/models</a></h1>

          <p>hub = {<br>    ''HF_MODEL_ID'':''bigcode/santacoder'',<br>    ''HF_TASK'':''text-generation''<br>}</p>

          <h1 id="create-hugging-face-model-class">create Hugging Face Model Class</h1>

          <p>huggingface_model = HuggingFaceModel(<br>    transformers_version=''4.17.0'',<br>    pytorch_version=''1.10.2'',<br>    py_version=''py38'',<br>    env=hub,<br>    role=role,
          </p>

          <p>)</p>

          <p>print("Deploying...")</p>

          <h1 id="deploy-model-to-sagemaker-inference">deploy model to SageMaker Inference</h1>

          <p>predictor = huggingface_model.deploy(<br>    initial_instance_count=1,
          # number of instances<br>    instance_type=''ml.p3.2xlarge'', # ec2 instance
          type<br>    trust_remote_code=True<br>) </p>

          <p>And then:</p>

          <p>predictor.predict({<br>    "inputs": "function helloWorld "<br>})</p>

          <p>At this point it gives the above error</p>

          '
        raw: "It gives the following error:\r\n\r\n An error occurred (ModelError)\
          \ when calling the InvokeEndpoint operation: Received client error (400)\
          \ from primary with message \"{\r\n  \"code\": 400,\r\n  \"type\": \"InternalServerException\"\
          ,\r\n  \"message\": \"Loading /.sagemaker/mms/models/bigcode__santacoder\
          \ requires you to execute the configuration file in that repo on your local\
          \ machine. Make sure you have read the code there to avoid malicious use,\
          \ then set the option `trust_remote_code\\u003dTrue` to remove this error.\"\
          \r\n}\r\n\r\n\r\nSource:\r\n\r\nfrom sagemaker.huggingface import HuggingFaceModel\r\
          \nimport sagemaker\r\n\r\nrole = sagemaker.get_execution_role()\r\n# Hub\
          \ Model configuration. https://huggingface.co/models\r\nhub = {\r\n\t'HF_MODEL_ID':'bigcode/santacoder',\r\
          \n\t'HF_TASK':'text-generation'\r\n}\r\n\r\n# create Hugging Face Model\
          \ Class\r\nhuggingface_model = HuggingFaceModel(\r\n\ttransformers_version='4.17.0',\r\
          \n\tpytorch_version='1.10.2',\r\n\tpy_version='py38',\r\n\tenv=hub,\r\n\t\
          role=role, \r\n     \r\n)\r\n\r\nprint(\"Deploying...\")\r\n# deploy model\
          \ to SageMaker Inference\r\npredictor = huggingface_model.deploy(\r\n\t\
          initial_instance_count=1, # number of instances\r\n\tinstance_type='ml.p3.2xlarge',\
          \ # ec2 instance type\r\n    trust_remote_code=True\r\n) \r\n\r\n\r\n\r\n\
          And then:\r\n\r\npredictor.predict({\r\n\t\"inputs\": \"function helloWorld\
          \ \"\r\n})\r\n \r\nAt this point it gives the above error"
        updatedAt: '2023-04-24T10:33:50.643Z'
      numEdits: 0
      reactions: []
    id: 64465b0e5004f2cb3af05cea
    type: comment
  author: kanandk
  content: "It gives the following error:\r\n\r\n An error occurred (ModelError) when\
    \ calling the InvokeEndpoint operation: Received client error (400) from primary\
    \ with message \"{\r\n  \"code\": 400,\r\n  \"type\": \"InternalServerException\"\
    ,\r\n  \"message\": \"Loading /.sagemaker/mms/models/bigcode__santacoder requires\
    \ you to execute the configuration file in that repo on your local machine. Make\
    \ sure you have read the code there to avoid malicious use, then set the option\
    \ `trust_remote_code\\u003dTrue` to remove this error.\"\r\n}\r\n\r\n\r\nSource:\r\
    \n\r\nfrom sagemaker.huggingface import HuggingFaceModel\r\nimport sagemaker\r\
    \n\r\nrole = sagemaker.get_execution_role()\r\n# Hub Model configuration. https://huggingface.co/models\r\
    \nhub = {\r\n\t'HF_MODEL_ID':'bigcode/santacoder',\r\n\t'HF_TASK':'text-generation'\r\
    \n}\r\n\r\n# create Hugging Face Model Class\r\nhuggingface_model = HuggingFaceModel(\r\
    \n\ttransformers_version='4.17.0',\r\n\tpytorch_version='1.10.2',\r\n\tpy_version='py38',\r\
    \n\tenv=hub,\r\n\trole=role, \r\n     \r\n)\r\n\r\nprint(\"Deploying...\")\r\n\
    # deploy model to SageMaker Inference\r\npredictor = huggingface_model.deploy(\r\
    \n\tinitial_instance_count=1, # number of instances\r\n\tinstance_type='ml.p3.2xlarge',\
    \ # ec2 instance type\r\n    trust_remote_code=True\r\n) \r\n\r\n\r\n\r\nAnd then:\r\
    \n\r\npredictor.predict({\r\n\t\"inputs\": \"function helloWorld \"\r\n})\r\n\
    \ \r\nAt this point it gives the above error"
  created_at: 2023-04-24 09:33:50+00:00
  edited: false
  hidden: false
  id: 64465b0e5004f2cb3af05cea
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 28
repo_id: bigcode/santacoder
repo_type: model
status: open
target_branch: null
title: Deploying bigcode/santacoder on sagemaker gives an error
