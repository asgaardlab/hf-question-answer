!!python/object:huggingface_hub.community.DiscussionWithDetails
author: williamberman
conflicting_files: []
created_at: 2023-02-04 01:07:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668468846504-63407fadb78ed99eab00203d.jpeg?w=200&h=200&f=face
      fullname: Will Berman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: williamberman
      type: user
    createdAt: '2023-02-04T01:07:04.000Z'
    data:
      edited: true
      editors:
      - williamberman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668468846504-63407fadb78ed99eab00203d.jpeg?w=200&h=200&f=face
          fullname: Will Berman
          isHf: false
          isPro: false
          name: williamberman
          type: user
        html: '<p>The default projection_dim is 512 which will throw an error when
          loading weights for</p>

          <pre><code class="language-py"><span class="hljs-keyword">from</span> transformers
          <span class="hljs-keyword">import</span> CLIPVisionModelWithProjection

          CLIPVisionModelWithProjection.from_pretrained(<span class="hljs-string">''laion/CLIP-ViT-H-14-laion2B-s32B-b79K''</span>)

          </code></pre>

          <p>or</p>

          <pre><code class="language-py"><span class="hljs-keyword">from</span> transformers
          <span class="hljs-keyword">import</span> CLIPTextModelWithProjection

          CLIPTextModelWithProjection.from_pretrained(<span class="hljs-string">''laion/CLIP-ViT-H-14-laion2B-s32B-b79K''</span>)

          </code></pre>

          <p>Loading CLIPModel will not throw an error because it uses the <code>projection_dim</code>
          on the top level of the config. </p>

          <pre><code class="language-py"><span class="hljs-keyword">from</span> transformers
          <span class="hljs-keyword">import</span> CLIPModel

          CLIPModel.from_pretrained(<span class="hljs-string">''laion/CLIP-ViT-H-14-laion2B-s32B-b79K''</span>)

          </code></pre>

          <p>Testing the PR:</p>

          <pre><code class="language-py"><span class="hljs-keyword">from</span> transformers
          <span class="hljs-keyword">import</span> CLIPVisionModelWithProjection,
          CLIPTextModelWithProjection, CLIPModel


          CLIPVisionModelWithProjection.from_pretrained(<span class="hljs-string">''laion/CLIP-ViT-H-14-laion2B-s32B-b79K''</span>,
          revision=<span class="hljs-string">"refs/pr/6"</span>)


          CLIPTextModelWithProjection.from_pretrained(<span class="hljs-string">''laion/CLIP-ViT-H-14-laion2B-s32B-b79K''</span>,
          revision=<span class="hljs-string">"refs/pr/6"</span>)


          CLIPModel.from_pretrained(<span class="hljs-string">''laion/CLIP-ViT-H-14-laion2B-s32B-b79K''</span>,
          revision=<span class="hljs-string">"refs/pr/6"</span>)

          </code></pre>

          '
        raw: "The default projection_dim is 512 which will throw an error when loading\
          \ weights for\n\n```py\nfrom transformers import CLIPVisionModelWithProjection\n\
          CLIPVisionModelWithProjection.from_pretrained('laion/CLIP-ViT-H-14-laion2B-s32B-b79K')\n\
          ```\n\nor\n\n```py\nfrom transformers import CLIPTextModelWithProjection\n\
          CLIPTextModelWithProjection.from_pretrained('laion/CLIP-ViT-H-14-laion2B-s32B-b79K')\n\
          ```\n\nLoading CLIPModel will not throw an error because it uses the `projection_dim`\
          \ on the top level of the config. \n\n```py\nfrom transformers import CLIPModel\n\
          CLIPModel.from_pretrained('laion/CLIP-ViT-H-14-laion2B-s32B-b79K')\n```\n\
          \nTesting the PR:\n\n```py\nfrom transformers import CLIPVisionModelWithProjection,\
          \ CLIPTextModelWithProjection, CLIPModel\n\nCLIPVisionModelWithProjection.from_pretrained('laion/CLIP-ViT-H-14-laion2B-s32B-b79K',\
          \ revision=\"refs/pr/6\")\n\nCLIPTextModelWithProjection.from_pretrained('laion/CLIP-ViT-H-14-laion2B-s32B-b79K',\
          \ revision=\"refs/pr/6\")\n\nCLIPModel.from_pretrained('laion/CLIP-ViT-H-14-laion2B-s32B-b79K',\
          \ revision=\"refs/pr/6\")\n```"
        updatedAt: '2023-02-04T01:10:58.287Z'
      numEdits: 1
      reactions: []
    id: 63ddafb80f0131a0e7f2ff5f
    type: comment
  author: williamberman
  content: "The default projection_dim is 512 which will throw an error when loading\
    \ weights for\n\n```py\nfrom transformers import CLIPVisionModelWithProjection\n\
    CLIPVisionModelWithProjection.from_pretrained('laion/CLIP-ViT-H-14-laion2B-s32B-b79K')\n\
    ```\n\nor\n\n```py\nfrom transformers import CLIPTextModelWithProjection\nCLIPTextModelWithProjection.from_pretrained('laion/CLIP-ViT-H-14-laion2B-s32B-b79K')\n\
    ```\n\nLoading CLIPModel will not throw an error because it uses the `projection_dim`\
    \ on the top level of the config. \n\n```py\nfrom transformers import CLIPModel\n\
    CLIPModel.from_pretrained('laion/CLIP-ViT-H-14-laion2B-s32B-b79K')\n```\n\nTesting\
    \ the PR:\n\n```py\nfrom transformers import CLIPVisionModelWithProjection, CLIPTextModelWithProjection,\
    \ CLIPModel\n\nCLIPVisionModelWithProjection.from_pretrained('laion/CLIP-ViT-H-14-laion2B-s32B-b79K',\
    \ revision=\"refs/pr/6\")\n\nCLIPTextModelWithProjection.from_pretrained('laion/CLIP-ViT-H-14-laion2B-s32B-b79K',\
    \ revision=\"refs/pr/6\")\n\nCLIPModel.from_pretrained('laion/CLIP-ViT-H-14-laion2B-s32B-b79K',\
    \ revision=\"refs/pr/6\")\n```"
  created_at: 2023-02-04 01:07:04+00:00
  edited: true
  hidden: false
  id: 63ddafb80f0131a0e7f2ff5f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668468846504-63407fadb78ed99eab00203d.jpeg?w=200&h=200&f=face
      fullname: Will Berman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: williamberman
      type: user
    createdAt: '2023-02-04T01:07:05.000Z'
    data:
      oid: 6e95467f175aad4da91da332f69eb0d8be88e81e
      parents:
      - babb4f6a96d549f88b005dca40764a4274e914f6
      subject: Add projection dim to text and vision model configs for CLIPVisionModelWithProjection
        and CLIPTextModelWithProjection support
    id: 63ddafb90000000000000000
    type: commit
  author: williamberman
  created_at: 2023-02-04 01:07:05+00:00
  id: 63ddafb90000000000000000
  oid: 6e95467f175aad4da91da332f69eb0d8be88e81e
  summary: Add projection dim to text and vision model configs for CLIPVisionModelWithProjection
    and CLIPTextModelWithProjection support
  type: commit
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
      fullname: Ross Wightman
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: rwightman
      type: user
    createdAt: '2023-02-04T05:37:15.000Z'
    data:
      status: merged
    id: 63ddef0ba05f19fc14e4a8fd
    type: status-change
  author: rwightman
  created_at: 2023-02-04 05:37:15+00:00
  id: 63ddef0ba05f19fc14e4a8fd
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 719803079cc9d41bf3ad0a0916fa24e778320c50
num: 6
repo_id: laion/CLIP-ViT-H-14-laion2B-s32B-b79K
repo_type: model
status: merged
target_branch: refs/heads/main
title: Add projection dim to text and vision model configs for CLIPVisionModelWithProjection
  and CLIPTextModelWithProjection support
