!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mirek190
conflicting_files: null
created_at: 2023-08-26 15:54:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-08-26T16:54:33.000Z'
    data:
      edited: true
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9690190553665161
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: "<p>Have to make tests later .... </p>\n<p>HumanEval 73.2 is insane\
          \ ... that is better than older GPT-4 .</p>\n<p>Right now I can say that\
          \ codellama-34b is a total crap comparing to that wizard.</p>\n<p>My command\
          \ for wizardcoder - this one works the best for me for no reason ... </p>\n\
          <p>main --model models\\new3\\wizardcoder-python-34b-v1.0.Q4_K_M.gguf --mlock\
          \ --color --threads 16 --keep -1 --batch_size 512 --n_predict -1 --top_k\
          \ 40 --top_p 0.9 --temp 0.96 --repeat_penalty 1.1 --ctx_size 4096 --interactive\
          \ --instruct --reverse-prompt \"### Human:\" -ngl 51 --simple-io  --in-prefix\
          \ \" ### Instruction: \" --in-suffix \" ### Response: \" -p \"Below is an\
          \ instruction that describes a task. Write a response that appropriately\
          \ completes the request.  \"</p>\n<blockquote>\n<p>Build a webpage in one\
          \ html file with html, css and javascript code, the webpage should have\
          \ 10 jokes and the button that changing background colors randomly.</p>\n\
          </blockquote>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n\
          \n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;Joke\
          \ Page&lt;/title&gt;\n    &lt;style&gt;\n        body {\n            background-color:\
          \ #f5f5f5f5;\n        }\n        .joke {\n            width: 70%;\n    \
          \        margin: auto;\n            padding: 2rem;\n            border:\
          \ 1px solid black;\n            border-radius: 10px;\n            box-shadow:\
          \ 5px 5px 10px grey;\n        }\n        h1 {\n            text-align: center;\n\
          \            background-color: #6d73ae;\n            color: white;\n   \
          \         padding: 1rem;\n            border-radius: 10px;\n           \
          \ margin: 2rem 0;\n        }\n        button {\n            display: block;\n\
          \            margin: 2rem auto;\n            padding: 1rem;\n          \
          \  background-color: #6d73ae;\n            color: white;\n            border-radius:\
          \ 10px;\n            font-size: 1.5rem;\n            border: none;\n   \
          \     }\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Joke\
          \ Page&lt;/h1&gt;\n    &lt;div class=\"joke\"&gt;\n        &lt;p id=\"joke\"\
          &gt;Click on the button below to see a random joke!&lt;/p&gt;\n    &lt;/div&gt;\n\
          \    &lt;button onclick=\"changeBackgroundColor()\"&gt;Change Color&lt;/button&gt;\n\
          \n    &lt;button onclick=\"getRandomJoke()\"&gt;Get Random Joke&lt;/button&gt;\n\
          \n    &lt;script&gt;\n        function getRandomJoke() {\n            const\
          \ jokes = [\n                \"What did the chemist say when he found two\
          \ helium molecules? HeHe made a noble gas.\",\n                \"Why are\
          \ mountains so funny? Because they are hill areas.\",\n                \"\
          How do you make a tissue dance? Put a little boogie in it!\",\n        \
          \        \"What is the difference between ignorance and apathy? I don't\
          \ know.\",\n                \"What's the best thing about Switzerland? Not\
          \ sure, but the flag is a big plus.\",\n                \"Why can't you\
          \ trust an atom? Because they make up everything!\",\n                \"\
          What does a baby grape say when it gets stuck in a grapefruit juicer? 'Eeeeghh!'\"\
          ,\n                \"What do you call a guy with a rubber toe? Roberto.\"\
          ,\n                \"Why did the physics teacher lose her job? She didn't\
          \ have enough momentum.\",\n                \"How does a dog stop a video?\
          \ By pressing the pause button.\",\n                \"I'm not a big fan\
          \ of stairs, they always make me feel like I'm going up in life.\",\n  \
          \              \"What kind of shoes do ninjas wear? Sneakers.\"\n      \
          \      ];\n            const joke = document.getElementById(\"joke\");\n\
          \            joke.innerHTML = jokes[Math.floor(Math.random() * jokes.length)];\n\
          \        }\n        function changeBackgroundColor() {\n            let\
          \ colors = [\"red\", \"green\", \"blue\", \"yellow\", \"orange\", \"purple\"\
          , \"pink\"];\n            document.body.style.backgroundColor = colors[Math.floor(Math.random()\
          \ * colors.length)];\n        }\n    &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\
          </code></pre>\n<p>So far works ... above GOOD.</p>\n"
        raw: "Have to make tests later .... \n\nHumanEval 73.2 is insane ... that\
          \ is better than older GPT-4 .\n\nRight now I can say that codellama-34b\
          \ is a total crap comparing to that wizard.\n\nMy command for wizardcoder\
          \ - this one works the best for me for no reason ... \n\nmain --model models\\\
          new3\\wizardcoder-python-34b-v1.0.Q4_K_M.gguf --mlock --color --threads\
          \ 16 --keep -1 --batch_size 512 --n_predict -1 --top_k 40 --top_p 0.9 --temp\
          \ 0.96 --repeat_penalty 1.1 --ctx_size 4096 --interactive --instruct --reverse-prompt\
          \ \"### Human:\" -ngl 51 --simple-io  --in-prefix \" ### Instruction: \"\
          \ --in-suffix \" ### Response: \" -p \"Below is an instruction that describes\
          \ a task. Write a response that appropriately completes the request.  \"\
          \n\n> Build a webpage in one html file with html, css and javascript code,\
          \ the webpage should have 10 jokes and the button that changing background\
          \ colors randomly.\n\n\n\n````\n<!DOCTYPE html>\n<html lang=\"en\">\n\n\
          <head>\n    <meta charset=\"UTF-8\">\n    <title>Joke Page</title>\n   \
          \ <style>\n        body {\n            background-color: #f5f5f5f5;\n  \
          \      }\n        .joke {\n            width: 70%;\n            margin:\
          \ auto;\n            padding: 2rem;\n            border: 1px solid black;\n\
          \            border-radius: 10px;\n            box-shadow: 5px 5px 10px\
          \ grey;\n        }\n        h1 {\n            text-align: center;\n    \
          \        background-color: #6d73ae;\n            color: white;\n       \
          \     padding: 1rem;\n            border-radius: 10px;\n            margin:\
          \ 2rem 0;\n        }\n        button {\n            display: block;\n  \
          \          margin: 2rem auto;\n            padding: 1rem;\n            background-color:\
          \ #6d73ae;\n            color: white;\n            border-radius: 10px;\n\
          \            font-size: 1.5rem;\n            border: none;\n        }\n\
          \    </style>\n</head>\n<body>\n    <h1>Joke Page</h1>\n    <div class=\"\
          joke\">\n        <p id=\"joke\">Click on the button below to see a random\
          \ joke!</p>\n    </div>\n    <button onclick=\"changeBackgroundColor()\"\
          >Change Color</button>\n\n    <button onclick=\"getRandomJoke()\">Get Random\
          \ Joke</button>\n\n    <script>\n        function getRandomJoke() {\n  \
          \          const jokes = [\n                \"What did the chemist say when\
          \ he found two helium molecules? HeHe made a noble gas.\",\n           \
          \     \"Why are mountains so funny? Because they are hill areas.\",\n  \
          \              \"How do you make a tissue dance? Put a little boogie in\
          \ it!\",\n                \"What is the difference between ignorance and\
          \ apathy? I don't know.\",\n                \"What's the best thing about\
          \ Switzerland? Not sure, but the flag is a big plus.\",\n              \
          \  \"Why can't you trust an atom? Because they make up everything!\",\n\
          \                \"What does a baby grape say when it gets stuck in a grapefruit\
          \ juicer? 'Eeeeghh!'\",\n                \"What do you call a guy with a\
          \ rubber toe? Roberto.\",\n                \"Why did the physics teacher\
          \ lose her job? She didn't have enough momentum.\",\n                \"\
          How does a dog stop a video? By pressing the pause button.\",\n        \
          \        \"I'm not a big fan of stairs, they always make me feel like I'm\
          \ going up in life.\",\n                \"What kind of shoes do ninjas wear?\
          \ Sneakers.\"\n            ];\n            const joke = document.getElementById(\"\
          joke\");\n            joke.innerHTML = jokes[Math.floor(Math.random() *\
          \ jokes.length)];\n        }\n        function changeBackgroundColor() {\n\
          \            let colors = [\"red\", \"green\", \"blue\", \"yellow\", \"\
          orange\", \"purple\", \"pink\"];\n            document.body.style.backgroundColor\
          \ = colors[Math.floor(Math.random() * colors.length)];\n        }\n    </script>\n\
          </body>\n</html>\n````\n\n\nSo far works ... above GOOD.\n\n\n"
        updatedAt: '2023-08-26T17:39:17.119Z'
      numEdits: 6
      reactions:
      - count: 1
        reaction: "\U0001F92F"
        users:
        - ronenzyroff
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Sab1
    id: 64ea2e491dce571e8550be5e
    type: comment
  author: mirek190
  content: "Have to make tests later .... \n\nHumanEval 73.2 is insane ... that is\
    \ better than older GPT-4 .\n\nRight now I can say that codellama-34b is a total\
    \ crap comparing to that wizard.\n\nMy command for wizardcoder - this one works\
    \ the best for me for no reason ... \n\nmain --model models\\new3\\wizardcoder-python-34b-v1.0.Q4_K_M.gguf\
    \ --mlock --color --threads 16 --keep -1 --batch_size 512 --n_predict -1 --top_k\
    \ 40 --top_p 0.9 --temp 0.96 --repeat_penalty 1.1 --ctx_size 4096 --interactive\
    \ --instruct --reverse-prompt \"### Human:\" -ngl 51 --simple-io  --in-prefix\
    \ \" ### Instruction: \" --in-suffix \" ### Response: \" -p \"Below is an instruction\
    \ that describes a task. Write a response that appropriately completes the request.\
    \  \"\n\n> Build a webpage in one html file with html, css and javascript code,\
    \ the webpage should have 10 jokes and the button that changing background colors\
    \ randomly.\n\n\n\n````\n<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n    <meta\
    \ charset=\"UTF-8\">\n    <title>Joke Page</title>\n    <style>\n        body\
    \ {\n            background-color: #f5f5f5f5;\n        }\n        .joke {\n  \
    \          width: 70%;\n            margin: auto;\n            padding: 2rem;\n\
    \            border: 1px solid black;\n            border-radius: 10px;\n    \
    \        box-shadow: 5px 5px 10px grey;\n        }\n        h1 {\n           \
    \ text-align: center;\n            background-color: #6d73ae;\n            color:\
    \ white;\n            padding: 1rem;\n            border-radius: 10px;\n     \
    \       margin: 2rem 0;\n        }\n        button {\n            display: block;\n\
    \            margin: 2rem auto;\n            padding: 1rem;\n            background-color:\
    \ #6d73ae;\n            color: white;\n            border-radius: 10px;\n    \
    \        font-size: 1.5rem;\n            border: none;\n        }\n    </style>\n\
    </head>\n<body>\n    <h1>Joke Page</h1>\n    <div class=\"joke\">\n        <p\
    \ id=\"joke\">Click on the button below to see a random joke!</p>\n    </div>\n\
    \    <button onclick=\"changeBackgroundColor()\">Change Color</button>\n\n   \
    \ <button onclick=\"getRandomJoke()\">Get Random Joke</button>\n\n    <script>\n\
    \        function getRandomJoke() {\n            const jokes = [\n           \
    \     \"What did the chemist say when he found two helium molecules? HeHe made\
    \ a noble gas.\",\n                \"Why are mountains so funny? Because they\
    \ are hill areas.\",\n                \"How do you make a tissue dance? Put a\
    \ little boogie in it!\",\n                \"What is the difference between ignorance\
    \ and apathy? I don't know.\",\n                \"What's the best thing about\
    \ Switzerland? Not sure, but the flag is a big plus.\",\n                \"Why\
    \ can't you trust an atom? Because they make up everything!\",\n             \
    \   \"What does a baby grape say when it gets stuck in a grapefruit juicer? 'Eeeeghh!'\"\
    ,\n                \"What do you call a guy with a rubber toe? Roberto.\",\n \
    \               \"Why did the physics teacher lose her job? She didn't have enough\
    \ momentum.\",\n                \"How does a dog stop a video? By pressing the\
    \ pause button.\",\n                \"I'm not a big fan of stairs, they always\
    \ make me feel like I'm going up in life.\",\n                \"What kind of shoes\
    \ do ninjas wear? Sneakers.\"\n            ];\n            const joke = document.getElementById(\"\
    joke\");\n            joke.innerHTML = jokes[Math.floor(Math.random() * jokes.length)];\n\
    \        }\n        function changeBackgroundColor() {\n            let colors\
    \ = [\"red\", \"green\", \"blue\", \"yellow\", \"orange\", \"purple\", \"pink\"\
    ];\n            document.body.style.backgroundColor = colors[Math.floor(Math.random()\
    \ * colors.length)];\n        }\n    </script>\n</body>\n</html>\n````\n\n\nSo\
    \ far works ... above GOOD.\n\n\n"
  created_at: 2023-08-26 15:54:33+00:00
  edited: true
  hidden: false
  id: 64ea2e491dce571e8550be5e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-08-26T17:04:37.000Z'
    data:
      from: 'This model looks insanely good for coding ..... '
      to: This model looks insanely good for coding ( 73.2 for humanEval )!
    id: 64ea30a52ca4ff1d53af2eee
    type: title-change
  author: mirek190
  created_at: 2023-08-26 16:04:37+00:00
  id: 64ea30a52ca4ff1d53af2eee
  new_title: This model looks insanely good for coding ( 73.2 for humanEval )!
  old_title: 'This model looks insanely good for coding ..... '
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/43fd0050e827ad080aabbd3fec287ed8.svg
      fullname: Ronen Zyroff
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ronenzyroff
      type: user
    createdAt: '2023-08-26T17:33:47.000Z'
    data:
      edited: false
      editors:
      - ronenzyroff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9512040615081787
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/43fd0050e827ad080aabbd3fec287ed8.svg
          fullname: Ronen Zyroff
          isHf: false
          isPro: false
          name: ronenzyroff
          type: user
        html: '<blockquote>

          <p>Have to make tests later .... </p>

          <p>HumanEval 73.2 is insane ... that is better than older GPT-4 .</p>

          </blockquote>

          <p>Nah, I tried it and it''s not even as good for coding as the current
          ChatGPT-3.5.<br>I stay away from anything with the word "Wizard" in it:
          they have lots of data, but it''s a very low-quality dataset.</p>

          <p>My hope is jondurbin''s 34b model. He has historically been creating
          the only competitive language models: see my post analyzing the performance
          of his 70B model: <a href="https://huggingface.co/jondurbin/airoboros-l2-70b-gpt4-1.4.1/discussions/4#64c396ed7918ee895ba54f53">https://huggingface.co/jondurbin/airoboros-l2-70b-gpt4-1.4.1/discussions/4#64c396ed7918ee895ba54f53</a></p>

          '
        raw: "> Have to make tests later .... \n> \n> HumanEval 73.2 is insane ...\
          \ that is better than older GPT-4 .\n\nNah, I tried it and it's not even\
          \ as good for coding as the current ChatGPT-3.5.\nI stay away from anything\
          \ with the word \"Wizard\" in it: they have lots of data, but it's a very\
          \ low-quality dataset.\n\nMy hope is jondurbin's 34b model. He has historically\
          \ been creating the only competitive language models: see my post analyzing\
          \ the performance of his 70B model: https://huggingface.co/jondurbin/airoboros-l2-70b-gpt4-1.4.1/discussions/4#64c396ed7918ee895ba54f53"
        updatedAt: '2023-08-26T17:33:47.847Z'
      numEdits: 0
      reactions: []
    id: 64ea377bc68ddc867b5ad92c
    type: comment
  author: ronenzyroff
  content: "> Have to make tests later .... \n> \n> HumanEval 73.2 is insane ... that\
    \ is better than older GPT-4 .\n\nNah, I tried it and it's not even as good for\
    \ coding as the current ChatGPT-3.5.\nI stay away from anything with the word\
    \ \"Wizard\" in it: they have lots of data, but it's a very low-quality dataset.\n\
    \nMy hope is jondurbin's 34b model. He has historically been creating the only\
    \ competitive language models: see my post analyzing the performance of his 70B\
    \ model: https://huggingface.co/jondurbin/airoboros-l2-70b-gpt4-1.4.1/discussions/4#64c396ed7918ee895ba54f53"
  created_at: 2023-08-26 16:33:47+00:00
  edited: false
  hidden: false
  id: 64ea377bc68ddc867b5ad92c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-08-26T17:44:05.000Z'
    data:
      edited: true
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9827762842178345
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>You know that model is for coding only?</p>

          <p> humanEval   73.2 &lt;-- indicates how good is in coding. </p>

          '
        raw: "You know that model is for coding only?\n\n humanEval   73.2 <-- indicates\
          \ how good is in coding. "
        updatedAt: '2023-08-26T17:47:19.577Z'
      numEdits: 1
      reactions: []
    id: 64ea39e57e2ec711a7263a2d
    type: comment
  author: mirek190
  content: "You know that model is for coding only?\n\n humanEval   73.2 <-- indicates\
    \ how good is in coding. "
  created_at: 2023-08-26 16:44:05+00:00
  edited: true
  hidden: false
  id: 64ea39e57e2ec711a7263a2d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-08-26T17:50:00.000Z'
    data:
      edited: false
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7357843518257141
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>Look how good code was generated from my question above. </p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/ylZHqysskavGsYClP4WMa.png"><img
          alt="Screenshot 2023-08-26 184812.png" src="https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/ylZHqysskavGsYClP4WMa.png"></a></p>

          '
        raw: "\nLook how good code was generated from my question above. \n\n![Screenshot\
          \ 2023-08-26 184812.png](https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/ylZHqysskavGsYClP4WMa.png)\n"
        updatedAt: '2023-08-26T17:50:00.737Z'
      numEdits: 0
      reactions: []
    id: 64ea3b488b59aa317e450f61
    type: comment
  author: mirek190
  content: "\nLook how good code was generated from my question above. \n\n![Screenshot\
    \ 2023-08-26 184812.png](https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/ylZHqysskavGsYClP4WMa.png)\n"
  created_at: 2023-08-26 16:50:00+00:00
  edited: false
  hidden: false
  id: 64ea3b488b59aa317e450f61
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/43fd0050e827ad080aabbd3fec287ed8.svg
      fullname: Ronen Zyroff
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ronenzyroff
      type: user
    createdAt: '2023-08-26T18:13:01.000Z'
    data:
      edited: true
      editors:
      - ronenzyroff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8516029119491577
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/43fd0050e827ad080aabbd3fec287ed8.svg
          fullname: Ronen Zyroff
          isHf: false
          isPro: false
          name: ronenzyroff
          type: user
        html: '<blockquote>

          <p>Look how good code was generated from my question above. </p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/ylZHqysskavGsYClP4WMa.png"><img
          alt="Screenshot 2023-08-26 184812.png" src="https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/ylZHqysskavGsYClP4WMa.png"></a></p>

          </blockquote>

          <p>I must admit. That''s a very good result.<br>My test was the precise
          prompt:<br>Create a realistic looking tree using a popular Python graphics
          library.</p>

          <p>Result from:<br>koboldcpp_nocuda.exe wizardcoder-python-34b-v1.0.Q8_0.gguf
          --contextsize 4096<br>after fixing some Python errors and logic error (to
          go up you need to subtract from y, not add).<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/_Ni1PFIfm_SJTbeqz_6xu.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/_Ni1PFIfm_SJTbeqz_6xu.png"></a></p>

          <p>ChatGPT-3.5 attempt 2 (attempt 1 was completely wrong):<br><a rel="nofollow"
          href="https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/0bx4SXXszw4LMpv4Qb96S.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/0bx4SXXszw4LMpv4Qb96S.png"></a></p>

          <p>As you can see, ChatGPT-3.5 was the winner in my test (especially since
          I didn''t have to edit the Python code to get it working).<br>Sure, wizardcoder-python-34b
          is currently better than any other open-source LLM for coding, but I definitely
          don''t buy that MMLU score (MMLU dataset was probably leaked in the training
          or something).</p>

          <p>I''m just waiting until <a href="https://huggingface.co/jondurbin/airoboros-c34b-2.1">https://huggingface.co/jondurbin/airoboros-c34b-2.1</a>
          gets a GGUF.</p>

          '
        raw: "> Look how good code was generated from my question above. \n> \n> ![Screenshot\
          \ 2023-08-26 184812.png](https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/ylZHqysskavGsYClP4WMa.png)\n\
          \nI must admit. That's a very good result.\nMy test was the precise prompt:\n\
          Create a realistic looking tree using a popular Python graphics library.\n\
          \nResult from:\nkoboldcpp_nocuda.exe wizardcoder-python-34b-v1.0.Q8_0.gguf\
          \ --contextsize 4096\nafter fixing some Python errors and logic error (to\
          \ go up you need to subtract from y, not add).\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/_Ni1PFIfm_SJTbeqz_6xu.png)\n\
          \nChatGPT-3.5 attempt 2 (attempt 1 was completely wrong):\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/0bx4SXXszw4LMpv4Qb96S.png)\n\
          \nAs you can see, ChatGPT-3.5 was the winner in my test (especially since\
          \ I didn't have to edit the Python code to get it working).\nSure, wizardcoder-python-34b\
          \ is currently better than any other open-source LLM for coding, but I definitely\
          \ don't buy that MMLU score (MMLU dataset was probably leaked in the training\
          \ or something).\n\nI'm just waiting until https://huggingface.co/jondurbin/airoboros-c34b-2.1\
          \ gets a GGUF."
        updatedAt: '2023-08-26T18:21:26.879Z'
      numEdits: 2
      reactions: []
    id: 64ea40adde393e513c427c5b
    type: comment
  author: ronenzyroff
  content: "> Look how good code was generated from my question above. \n> \n> ![Screenshot\
    \ 2023-08-26 184812.png](https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/ylZHqysskavGsYClP4WMa.png)\n\
    \nI must admit. That's a very good result.\nMy test was the precise prompt:\n\
    Create a realistic looking tree using a popular Python graphics library.\n\nResult\
    \ from:\nkoboldcpp_nocuda.exe wizardcoder-python-34b-v1.0.Q8_0.gguf --contextsize\
    \ 4096\nafter fixing some Python errors and logic error (to go up you need to\
    \ subtract from y, not add).\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/_Ni1PFIfm_SJTbeqz_6xu.png)\n\
    \nChatGPT-3.5 attempt 2 (attempt 1 was completely wrong):\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/0bx4SXXszw4LMpv4Qb96S.png)\n\
    \nAs you can see, ChatGPT-3.5 was the winner in my test (especially since I didn't\
    \ have to edit the Python code to get it working).\nSure, wizardcoder-python-34b\
    \ is currently better than any other open-source LLM for coding, but I definitely\
    \ don't buy that MMLU score (MMLU dataset was probably leaked in the training\
    \ or something).\n\nI'm just waiting until https://huggingface.co/jondurbin/airoboros-c34b-2.1\
    \ gets a GGUF."
  created_at: 2023-08-26 17:13:01+00:00
  edited: true
  hidden: false
  id: 64ea40adde393e513c427c5b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/43fd0050e827ad080aabbd3fec287ed8.svg
      fullname: Ronen Zyroff
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ronenzyroff
      type: user
    createdAt: '2023-08-26T18:19:43.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/43fd0050e827ad080aabbd3fec287ed8.svg
          fullname: Ronen Zyroff
          isHf: false
          isPro: false
          name: ronenzyroff
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-08-26T18:20:19.341Z'
      numEdits: 0
      reactions: []
    id: 64ea423f2ca4ff1d53b0ebe0
    type: comment
  author: ronenzyroff
  content: This comment has been hidden
  created_at: 2023-08-26 17:19:43+00:00
  edited: true
  hidden: true
  id: 64ea423f2ca4ff1d53b0ebe0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-08-26T19:19:21.000Z'
    data:
      edited: true
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9580655694007874
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>I tried your prompt</p>

          <p>"Create a realistic looking tree using a popular Python graphics library."</p>

          <p>GPT3.5 ( chat gpt ) - 10 attempts - never get a proper tree or code just
          not worked<br>GPT 4  ( bing AI ) - 3 attempts - I got some kind of tree
          but very deformed. </p>

          <p>So you had to be very lucky to get working that prompt under GPT 3.5
          </p>

          <p>Also tried that prompt with wizard</p>

          <p>on the second attempt I got something like this  ( did not have to fix
          the code to work ) </p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/R-Fd_Cb6jRqWMOKQwFPF8.png"><img
          alt="Screenshot 2023-08-26 202122.png" src="https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/R-Fd_Cb6jRqWMOKQwFPF8.png"></a></p>

          <p>I am using wizardcoder-python-34b-v1.0.Q4_K_M.gguf</p>

          '
        raw: "I tried your prompt\n\n\"Create a realistic looking tree using a popular\
          \ Python graphics library.\"\n\nGPT3.5 ( chat gpt ) - 10 attempts - never\
          \ get a proper tree or code just not worked\nGPT 4  ( bing AI ) - 3 attempts\
          \ - I got some kind of tree but very deformed. \n\nSo you had to be very\
          \ lucky to get working that prompt under GPT 3.5 \n\n\nAlso tried that prompt\
          \ with wizard\n\non the second attempt I got something like this  ( did\
          \ not have to fix the code to work ) \n\n\n![Screenshot 2023-08-26 202122.png](https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/R-Fd_Cb6jRqWMOKQwFPF8.png)\n\
          \nI am using wizardcoder-python-34b-v1.0.Q4_K_M.gguf"
        updatedAt: '2023-08-26T19:36:35.449Z'
      numEdits: 2
      reactions: []
    id: 64ea5039e8dd717fd3f86a2e
    type: comment
  author: mirek190
  content: "I tried your prompt\n\n\"Create a realistic looking tree using a popular\
    \ Python graphics library.\"\n\nGPT3.5 ( chat gpt ) - 10 attempts - never get\
    \ a proper tree or code just not worked\nGPT 4  ( bing AI ) - 3 attempts - I got\
    \ some kind of tree but very deformed. \n\nSo you had to be very lucky to get\
    \ working that prompt under GPT 3.5 \n\n\nAlso tried that prompt with wizard\n\
    \non the second attempt I got something like this  ( did not have to fix the code\
    \ to work ) \n\n\n![Screenshot 2023-08-26 202122.png](https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/R-Fd_Cb6jRqWMOKQwFPF8.png)\n\
    \nI am using wizardcoder-python-34b-v1.0.Q4_K_M.gguf"
  created_at: 2023-08-26 18:19:21+00:00
  edited: true
  hidden: false
  id: 64ea5039e8dd717fd3f86a2e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/43fd0050e827ad080aabbd3fec287ed8.svg
      fullname: Ronen Zyroff
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ronenzyroff
      type: user
    createdAt: '2023-08-26T21:00:36.000Z'
    data:
      edited: false
      editors:
      - ronenzyroff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8306779861450195
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/43fd0050e827ad080aabbd3fec287ed8.svg
          fullname: Ronen Zyroff
          isHf: false
          isPro: false
          name: ronenzyroff
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mirek190&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mirek190\">@<span class=\"\
          underline\">mirek190</span></a></span>\n\n\t</span></span> I changed the\
          \ prompt to try to give the best chance to wizardcoder-python-34b-v1.0.Q8_0.gguf\
          \ (running in koboldcpp in CPU mode).<br>This is the prompt:</p>\n<pre><code\
          \ class=\"language-txt\">Below is an instruction that describes a task.\
          \ Write a response that appropriately completes the request.\n\n### Instruction:\n\
          Provide complete working code for a realistic looking tree in Python using\
          \ the Turtle graphics library and a recursive algorithm.\n\n### Response:\n\
          </code></pre>\n<p>Result:<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/0pUihFKGxs836cHEk4ICN.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/0pUihFKGxs836cHEk4ICN.png\"\
          ></a></p>\n<p>GPT-3.5 result:<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/T1TTdEoTPT05DQqOkxest.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/T1TTdEoTPT05DQqOkxest.png\"\
          ></a></p>\n<p>It seems that there are many small mistakes that GPT-3.5 just\
          \ doesn't make. Not to mention that fact that ChatGPT3.5 (August version)\
          \ tends to generate code that doesn't crash. Even when the code doesn't\
          \ produce the desired result, there rarely any Python errors.</p>\n<p>You\
          \ should know that Bing Chat is stupid compared to ChatGPT-4 ($20 USD per\
          \ month).<br>Here is the result of that same prompt given to ChatGPT-4 (August\
          \ version):</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/vhJdeDsjYSgbxDk_3Z-Bt.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/vhJdeDsjYSgbxDk_3Z-Bt.png\"\
          ></a></p>\n<p>So no. WizardCoder-Python-34B-V1.0 is not comparable to ChatGPT3.5,\
          \ nor is it comparable to ChatGPT-4.</p>\n"
        raw: '@mirek190 I changed the prompt to try to give the best chance to wizardcoder-python-34b-v1.0.Q8_0.gguf
          (running in koboldcpp in CPU mode).

          This is the prompt:

          ```txt

          Below is an instruction that describes a task. Write a response that appropriately
          completes the request.


          ### Instruction:

          Provide complete working code for a realistic looking tree in Python using
          the Turtle graphics library and a recursive algorithm.


          ### Response:


          ```

          Result:

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/0pUihFKGxs836cHEk4ICN.png)


          GPT-3.5 result:

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/T1TTdEoTPT05DQqOkxest.png)


          It seems that there are many small mistakes that GPT-3.5 just doesn''t make.
          Not to mention that fact that ChatGPT3.5 (August version) tends to generate
          code that doesn''t crash. Even when the code doesn''t produce the desired
          result, there rarely any Python errors.


          You should know that Bing Chat is stupid compared to ChatGPT-4 ($20 USD
          per month).

          Here is the result of that same prompt given to ChatGPT-4 (August version):


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/vhJdeDsjYSgbxDk_3Z-Bt.png)


          So no. WizardCoder-Python-34B-V1.0 is not comparable to ChatGPT3.5, nor
          is it comparable to ChatGPT-4.'
        updatedAt: '2023-08-26T21:00:36.358Z'
      numEdits: 0
      reactions: []
    id: 64ea67f481e68021f07dafa8
    type: comment
  author: ronenzyroff
  content: '@mirek190 I changed the prompt to try to give the best chance to wizardcoder-python-34b-v1.0.Q8_0.gguf
    (running in koboldcpp in CPU mode).

    This is the prompt:

    ```txt

    Below is an instruction that describes a task. Write a response that appropriately
    completes the request.


    ### Instruction:

    Provide complete working code for a realistic looking tree in Python using the
    Turtle graphics library and a recursive algorithm.


    ### Response:


    ```

    Result:

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/0pUihFKGxs836cHEk4ICN.png)


    GPT-3.5 result:

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/T1TTdEoTPT05DQqOkxest.png)


    It seems that there are many small mistakes that GPT-3.5 just doesn''t make. Not
    to mention that fact that ChatGPT3.5 (August version) tends to generate code that
    doesn''t crash. Even when the code doesn''t produce the desired result, there
    rarely any Python errors.


    You should know that Bing Chat is stupid compared to ChatGPT-4 ($20 USD per month).

    Here is the result of that same prompt given to ChatGPT-4 (August version):


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/vhJdeDsjYSgbxDk_3Z-Bt.png)


    So no. WizardCoder-Python-34B-V1.0 is not comparable to ChatGPT3.5, nor is it
    comparable to ChatGPT-4.'
  created_at: 2023-08-26 20:00:36+00:00
  edited: false
  hidden: false
  id: 64ea67f481e68021f07dafa8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-08-26T22:03:18.000Z'
    data:
      edited: true
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9696134328842163
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>you are right .. gpt3.5 is still better ... not too far but still
          .... considering local AI for coding few months ago was practically not
          exist this one is really impassive ;D  33B vs 170B (gpt3)</p>

          '
        raw: you are right .. gpt3.5 is still better ... not too far but still ....
          considering local AI for coding few months ago was practically not exist
          this one is really impassive ;D  33B vs 170B (gpt3)
        updatedAt: '2023-08-26T23:27:53.174Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\U0001F917"
        users:
        - ronenzyroff
        - kajuberdut
    id: 64ea76a6e8dd717fd3fba25b
    type: comment
  author: mirek190
  content: you are right .. gpt3.5 is still better ... not too far but still ....
    considering local AI for coding few months ago was practically not exist this
    one is really impassive ;D  33B vs 170B (gpt3)
  created_at: 2023-08-26 21:03:18+00:00
  edited: true
  hidden: false
  id: 64ea76a6e8dd717fd3fba25b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6d97b20672975167a8355f54b5edf248.svg
      fullname: Patrick Shechet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kajuberdut
      type: user
    createdAt: '2023-08-26T23:18:05.000Z'
    data:
      edited: true
      editors:
      - kajuberdut
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7688879370689392
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6d97b20672975167a8355f54b5edf248.svg
          fullname: Patrick Shechet
          isHf: false
          isPro: false
          name: kajuberdut
          type: user
        html: '<p>Ok, so the GPT 4 version is darned impressive but with TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True
          using the Debug-deterministic parameter preset in ooga I ran the following:<br>(The
          code renders better in HTML but is much less compact so I''m using the crappy
          markdown render since it fits in one screen):</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/d5RlY8E-6_4Y6r0yHccrD.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/d5RlY8E-6_4Y6r0yHccrD.png"></a></p>

          <p>Which draws:<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/6c8hXaTcdZXl-FbGc3oL4.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/6c8hXaTcdZXl-FbGc3oL4.png"></a></p>

          <p>Only to say: These models are insanely impressive for being liberally
          licensed and running on consumer hardware.</p>

          <p>And, I think if there was an instruct training on top of the python model
          as a base it might be very very good at Python.</p>

          '
        raw: "Ok, so the GPT 4 version is darned impressive but with TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True\
          \ using the Debug-deterministic parameter preset in ooga I ran the following:\
          \ \n(The code renders better in HTML but is much less compact so I'm using\
          \ the crappy markdown render since it fits in one screen):\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/d5RlY8E-6_4Y6r0yHccrD.png)\n\
          \ \nWhich draws:\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/6c8hXaTcdZXl-FbGc3oL4.png)\n\
          \n\nOnly to say: These models are insanely impressive for being liberally\
          \ licensed and running on consumer hardware.\n\nAnd, I think if there was\
          \ an instruct training on top of the python model as a base it might be\
          \ very very good at Python."
        updatedAt: '2023-08-26T23:18:50.337Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F92F"
        users:
        - gnomealone
    id: 64ea882d5b8d8156f2c098a1
    type: comment
  author: kajuberdut
  content: "Ok, so the GPT 4 version is darned impressive but with TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True\
    \ using the Debug-deterministic parameter preset in ooga I ran the following:\
    \ \n(The code renders better in HTML but is much less compact so I'm using the\
    \ crappy markdown render since it fits in one screen):\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/d5RlY8E-6_4Y6r0yHccrD.png)\n\
    \ \nWhich draws:\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/6c8hXaTcdZXl-FbGc3oL4.png)\n\
    \n\nOnly to say: These models are insanely impressive for being liberally licensed\
    \ and running on consumer hardware.\n\nAnd, I think if there was an instruct training\
    \ on top of the python model as a base it might be very very good at Python."
  created_at: 2023-08-26 22:18:05+00:00
  edited: true
  hidden: false
  id: 64ea882d5b8d8156f2c098a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/efacf65b052b236d859b56506576fa97.svg
      fullname: gnome
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gnomealone
      type: user
    createdAt: '2023-08-27T02:14:26.000Z'
    data:
      edited: false
      editors:
      - gnomealone
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8657443523406982
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/efacf65b052b236d859b56506576fa97.svg
          fullname: gnome
          isHf: false
          isPro: false
          name: gnomealone
          type: user
        html: "<blockquote>\n<p>Ok, so the GPT 4 version is darned impressive but\
          \ with TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True using\
          \ the Debug-deterministic parameter preset in ooga I ran the following:<br>(The\
          \ code renders better in HTML but is much less compact so I'm using the\
          \ crappy markdown render since it fits in one screen):</p>\n<p><a rel=\"\
          nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/d5RlY8E-6_4Y6r0yHccrD.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/d5RlY8E-6_4Y6r0yHccrD.png\"\
          ></a></p>\n<p>Which draws:<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/6c8hXaTcdZXl-FbGc3oL4.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/6c8hXaTcdZXl-FbGc3oL4.png\"\
          ></a></p>\n<p>Only to say: These models are insanely impressive for being\
          \ liberally licensed and running on consumer hardware.</p>\n<p>And, I think\
          \ if there was an instruct training on top of the python model as a base\
          \ it might be very very good at Python.</p>\n</blockquote>\n<p>so the difference\
          \ in quantized versions really matters for that type of result. \U0001F914\
          </p>\n<p>what specs do you have to run that ?</p>\n"
        raw: "> Ok, so the GPT 4 version is darned impressive but with TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True\
          \ using the Debug-deterministic parameter preset in ooga I ran the following:\
          \ \n> (The code renders better in HTML but is much less compact so I'm using\
          \ the crappy markdown render since it fits in one screen):\n> \n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/d5RlY8E-6_4Y6r0yHccrD.png)\n\
          >  \n> Which draws:\n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/6c8hXaTcdZXl-FbGc3oL4.png)\n\
          > \n> \n> Only to say: These models are insanely impressive for being liberally\
          \ licensed and running on consumer hardware.\n> \n> And, I think if there\
          \ was an instruct training on top of the python model as a base it might\
          \ be very very good at Python.\n\nso the difference in quantized versions\
          \ really matters for that type of result. \U0001F914\n\nwhat specs do you\
          \ have to run that ?"
        updatedAt: '2023-08-27T02:14:26.432Z'
      numEdits: 0
      reactions: []
    id: 64eab1827e727763c9256e84
    type: comment
  author: gnomealone
  content: "> Ok, so the GPT 4 version is darned impressive but with TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True\
    \ using the Debug-deterministic parameter preset in ooga I ran the following:\
    \ \n> (The code renders better in HTML but is much less compact so I'm using the\
    \ crappy markdown render since it fits in one screen):\n> \n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/d5RlY8E-6_4Y6r0yHccrD.png)\n\
    >  \n> Which draws:\n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/6c8hXaTcdZXl-FbGc3oL4.png)\n\
    > \n> \n> Only to say: These models are insanely impressive for being liberally\
    \ licensed and running on consumer hardware.\n> \n> And, I think if there was\
    \ an instruct training on top of the python model as a base it might be very very\
    \ good at Python.\n\nso the difference in quantized versions really matters for\
    \ that type of result. \U0001F914\n\nwhat specs do you have to run that ?"
  created_at: 2023-08-27 01:14:26+00:00
  edited: false
  hidden: false
  id: 64eab1827e727763c9256e84
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6d97b20672975167a8355f54b5edf248.svg
      fullname: Patrick Shechet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kajuberdut
      type: user
    createdAt: '2023-08-27T02:46:02.000Z'
    data:
      edited: true
      editors:
      - kajuberdut
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8840942978858948
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6d97b20672975167a8355f54b5edf248.svg
          fullname: Patrick Shechet
          isHf: false
          isPro: false
          name: kajuberdut
          type: user
        html: "<blockquote>\n<blockquote>\n<p>Ok, so the GPT 4 version is darned impressive\
          \ but with TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True\
          \ using the Debug-deterministic parameter preset in ooga I ran the following:<br>(The\
          \ code renders better in HTML but is much less compact so I'm using the\
          \ crappy markdown render since it fits in one screen):</p>\n<p><a rel=\"\
          nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/d5RlY8E-6_4Y6r0yHccrD.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/d5RlY8E-6_4Y6r0yHccrD.png\"\
          ></a></p>\n<p>Which draws:<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/6c8hXaTcdZXl-FbGc3oL4.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/6c8hXaTcdZXl-FbGc3oL4.png\"\
          ></a></p>\n<p>Only to say: These models are insanely impressive for being\
          \ liberally licensed and running on consumer hardware.</p>\n<p>And, I think\
          \ if there was an instruct training on top of the python model as a base\
          \ it might be very very good at Python.</p>\n</blockquote>\n<p>so the difference\
          \ in quantized versions really matters for that type of result. \U0001F914\
          </p>\n<p>what specs do you have to run that ?</p>\n</blockquote>\n<p>Sorry,\
          \ I should have made this more clear that I also wasn't using the wizard\
          \ coder version, just the Python one from Meta. So I don't think it was\
          \ strictly the quantization but the different model and the different style\
          \ of prompt (the non-wizard version of the python model is a continuation\
          \ model, so my prompt was a module level python docstring and a import statement\
          \ to get it started.)</p>\n<p>Edit: you asked what specs I have, I have\
          \ a 3090 and a 3060 in my desktop but I'm pretty sure this 34B 4 bit GPTQ\
          \ can fit in just the 24GB card alone.</p>\n"
        raw: "> > Ok, so the GPT 4 version is darned impressive but with TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True\
          \ using the Debug-deterministic parameter preset in ooga I ran the following:\
          \ \n> > (The code renders better in HTML but is much less compact so I'm\
          \ using the crappy markdown render since it fits in one screen):\n> > \n\
          > > ![image.png](https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/d5RlY8E-6_4Y6r0yHccrD.png)\n\
          > >  \n> > Which draws:\n> > ![image.png](https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/6c8hXaTcdZXl-FbGc3oL4.png)\n\
          > > \n> > \n> > Only to say: These models are insanely impressive for being\
          \ liberally licensed and running on consumer hardware.\n> > \n> > And, I\
          \ think if there was an instruct training on top of the python model as\
          \ a base it might be very very good at Python.\n> \n> so the difference\
          \ in quantized versions really matters for that type of result. \U0001F914\
          \n> \n> what specs do you have to run that ?\n\nSorry, I should have made\
          \ this more clear that I also wasn't using the wizard coder version, just\
          \ the Python one from Meta. So I don't think it was strictly the quantization\
          \ but the different model and the different style of prompt (the non-wizard\
          \ version of the python model is a continuation model, so my prompt was\
          \ a module level python docstring and a import statement to get it started.)\n\
          \nEdit: you asked what specs I have, I have a 3090 and a 3060 in my desktop\
          \ but I'm pretty sure this 34B 4 bit GPTQ can fit in just the 24GB card\
          \ alone."
        updatedAt: '2023-08-27T02:48:44.260Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - gnomealone
    id: 64eab8ea9d939716d040e19f
    type: comment
  author: kajuberdut
  content: "> > Ok, so the GPT 4 version is darned impressive but with TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True\
    \ using the Debug-deterministic parameter preset in ooga I ran the following:\
    \ \n> > (The code renders better in HTML but is much less compact so I'm using\
    \ the crappy markdown render since it fits in one screen):\n> > \n> > ![image.png](https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/d5RlY8E-6_4Y6r0yHccrD.png)\n\
    > >  \n> > Which draws:\n> > ![image.png](https://cdn-uploads.huggingface.co/production/uploads/631612c195b55e2621d0900b/6c8hXaTcdZXl-FbGc3oL4.png)\n\
    > > \n> > \n> > Only to say: These models are insanely impressive for being liberally\
    \ licensed and running on consumer hardware.\n> > \n> > And, I think if there\
    \ was an instruct training on top of the python model as a base it might be very\
    \ very good at Python.\n> \n> so the difference in quantized versions really matters\
    \ for that type of result. \U0001F914\n> \n> what specs do you have to run that\
    \ ?\n\nSorry, I should have made this more clear that I also wasn't using the\
    \ wizard coder version, just the Python one from Meta. So I don't think it was\
    \ strictly the quantization but the different model and the different style of\
    \ prompt (the non-wizard version of the python model is a continuation model,\
    \ so my prompt was a module level python docstring and a import statement to get\
    \ it started.)\n\nEdit: you asked what specs I have, I have a 3090 and a 3060\
    \ in my desktop but I'm pretty sure this 34B 4 bit GPTQ can fit in just the 24GB\
    \ card alone."
  created_at: 2023-08-27 01:46:02+00:00
  edited: true
  hidden: false
  id: 64eab8ea9d939716d040e19f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6d97b20672975167a8355f54b5edf248.svg
      fullname: Patrick Shechet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kajuberdut
      type: user
    createdAt: '2023-08-27T02:47:55.000Z'
    data:
      edited: false
      editors:
      - kajuberdut
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7557843923568726
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6d97b20672975167a8355f54b5edf248.svg
          fullname: Patrick Shechet
          isHf: false
          isPro: false
          name: kajuberdut
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;gnomealone&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/gnomealone\">@<span class=\"\
          underline\">gnomealone</span></a></span>\n\n\t</span></span> You could try\
          \ running my exact prompt on TheBloke/WizardCoder-Python-34B-V1.0-GGUF and\
          \ see what kind of results you get.</p>\n<pre><code>\"\"\" This module generates\
          \ a graph of a realistic looking tree using the Turtle graphics library\
          \ and a recursive algorithm.\n\"\"\"\nimport turtle\n</code></pre>\n"
        raw: '@gnomealone You could try running my exact prompt on TheBloke/WizardCoder-Python-34B-V1.0-GGUF
          and see what kind of results you get.


          ```

          """ This module generates a graph of a realistic looking tree using the
          Turtle graphics library and a recursive algorithm.

          """

          import turtle

          ```'
        updatedAt: '2023-08-27T02:47:55.200Z'
      numEdits: 0
      reactions: []
    id: 64eab95bfb77a3eaa7f9be8c
    type: comment
  author: kajuberdut
  content: '@gnomealone You could try running my exact prompt on TheBloke/WizardCoder-Python-34B-V1.0-GGUF
    and see what kind of results you get.


    ```

    """ This module generates a graph of a realistic looking tree using the Turtle
    graphics library and a recursive algorithm.

    """

    import turtle

    ```'
  created_at: 2023-08-27 01:47:55+00:00
  edited: false
  hidden: false
  id: 64eab95bfb77a3eaa7f9be8c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677644903536-62ceeb27e7f6014c0e9d9268.jpeg?w=200&h=200&f=face
      fullname: Anton Bacaj
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abacaj
      type: user
    createdAt: '2023-08-27T03:06:47.000Z'
    data:
      edited: false
      editors:
      - abacaj
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7805869579315186
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677644903536-62ceeb27e7f6014c0e9d9268.jpeg?w=200&h=200&f=face
          fullname: Anton Bacaj
          isHf: false
          isPro: false
          name: abacaj
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;mirek190&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/mirek190\"\
          >@<span class=\"underline\">mirek190</span></a></span>\n\n\t</span></span>\
          \ I changed the prompt to try to give the best chance to wizardcoder-python-34b-v1.0.Q8_0.gguf\
          \ (running in koboldcpp in CPU mode).<br>This is the prompt:</p>\n<pre><code\
          \ class=\"language-txt\">Below is an instruction that describes a task.\
          \ Write a response that appropriately completes the request.\n\n### Instruction:\n\
          Provide complete working code for a realistic looking tree in Python using\
          \ the Turtle graphics library and a recursive algorithm.\n\n### Response:\n\
          </code></pre>\n<p>Result:<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/0pUihFKGxs836cHEk4ICN.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/0pUihFKGxs836cHEk4ICN.png\"\
          ></a></p>\n<p>GPT-3.5 result:<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/T1TTdEoTPT05DQqOkxest.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/T1TTdEoTPT05DQqOkxest.png\"\
          ></a></p>\n<p>It seems that there are many small mistakes that GPT-3.5 just\
          \ doesn't make. Not to mention that fact that ChatGPT3.5 (August version)\
          \ tends to generate code that doesn't crash. Even when the code doesn't\
          \ produce the desired result, there rarely any Python errors.</p>\n<p>You\
          \ should know that Bing Chat is stupid compared to ChatGPT-4 ($20 USD per\
          \ month).<br>Here is the result of that same prompt given to ChatGPT-4 (August\
          \ version):</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/vhJdeDsjYSgbxDk_3Z-Bt.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/vhJdeDsjYSgbxDk_3Z-Bt.png\"\
          ></a></p>\n<p>So no. WizardCoder-Python-34B-V1.0 is not comparable to ChatGPT3.5,\
          \ nor is it comparable to ChatGPT-4.</p>\n</blockquote>\n<p>Base code llama\
          \ 34B at higher precision is much better.</p>\n<p><a rel=\"nofollow\" href=\"\
          https://cdn-uploads.huggingface.co/production/uploads/62ceeb27e7f6014c0e9d9268/RGfICnaQLFLHUdz6CSGv9.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/62ceeb27e7f6014c0e9d9268/RGfICnaQLFLHUdz6CSGv9.png\"\
          ></a><br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/62ceeb27e7f6014c0e9d9268/Vsyht0cTz_S2vt94pPWDP.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/62ceeb27e7f6014c0e9d9268/Vsyht0cTz_S2vt94pPWDP.png\"\
          ></a></p>\n"
        raw: "> @mirek190 I changed the prompt to try to give the best chance to wizardcoder-python-34b-v1.0.Q8_0.gguf\
          \ (running in koboldcpp in CPU mode).\n> This is the prompt:\n> ```txt\n\
          > Below is an instruction that describes a task. Write a response that appropriately\
          \ completes the request.\n> \n> ### Instruction:\n> Provide complete working\
          \ code for a realistic looking tree in Python using the Turtle graphics\
          \ library and a recursive algorithm.\n> \n> ### Response:\n> \n> ```\n>\
          \ Result:\n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/0pUihFKGxs836cHEk4ICN.png)\n\
          > \n> GPT-3.5 result:\n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/T1TTdEoTPT05DQqOkxest.png)\n\
          > \n> It seems that there are many small mistakes that GPT-3.5 just doesn't\
          \ make. Not to mention that fact that ChatGPT3.5 (August version) tends\
          \ to generate code that doesn't crash. Even when the code doesn't produce\
          \ the desired result, there rarely any Python errors.\n> \n> You should\
          \ know that Bing Chat is stupid compared to ChatGPT-4 ($20 USD per month).\n\
          > Here is the result of that same prompt given to ChatGPT-4 (August version):\n\
          > \n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/vhJdeDsjYSgbxDk_3Z-Bt.png)\n\
          > \n> So no. WizardCoder-Python-34B-V1.0 is not comparable to ChatGPT3.5,\
          \ nor is it comparable to ChatGPT-4.\n\nBase code llama 34B at higher precision\
          \ is much better.\n\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/62ceeb27e7f6014c0e9d9268/RGfICnaQLFLHUdz6CSGv9.png)\n\
          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62ceeb27e7f6014c0e9d9268/Vsyht0cTz_S2vt94pPWDP.png)\n"
        updatedAt: '2023-08-27T03:06:47.773Z'
      numEdits: 0
      reactions: []
    id: 64eabdc72f70f2a4c7637090
    type: comment
  author: abacaj
  content: "> @mirek190 I changed the prompt to try to give the best chance to wizardcoder-python-34b-v1.0.Q8_0.gguf\
    \ (running in koboldcpp in CPU mode).\n> This is the prompt:\n> ```txt\n> Below\
    \ is an instruction that describes a task. Write a response that appropriately\
    \ completes the request.\n> \n> ### Instruction:\n> Provide complete working code\
    \ for a realistic looking tree in Python using the Turtle graphics library and\
    \ a recursive algorithm.\n> \n> ### Response:\n> \n> ```\n> Result:\n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/0pUihFKGxs836cHEk4ICN.png)\n\
    > \n> GPT-3.5 result:\n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/T1TTdEoTPT05DQqOkxest.png)\n\
    > \n> It seems that there are many small mistakes that GPT-3.5 just doesn't make.\
    \ Not to mention that fact that ChatGPT3.5 (August version) tends to generate\
    \ code that doesn't crash. Even when the code doesn't produce the desired result,\
    \ there rarely any Python errors.\n> \n> You should know that Bing Chat is stupid\
    \ compared to ChatGPT-4 ($20 USD per month).\n> Here is the result of that same\
    \ prompt given to ChatGPT-4 (August version):\n> \n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/vhJdeDsjYSgbxDk_3Z-Bt.png)\n\
    > \n> So no. WizardCoder-Python-34B-V1.0 is not comparable to ChatGPT3.5, nor\
    \ is it comparable to ChatGPT-4.\n\nBase code llama 34B at higher precision is\
    \ much better.\n\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/62ceeb27e7f6014c0e9d9268/RGfICnaQLFLHUdz6CSGv9.png)\n\
    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62ceeb27e7f6014c0e9d9268/Vsyht0cTz_S2vt94pPWDP.png)\n"
  created_at: 2023-08-27 02:06:47+00:00
  edited: false
  hidden: false
  id: 64eabdc72f70f2a4c7637090
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-08-27T08:46:45.000Z'
    data:
      edited: false
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.48188531398773193
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>For me base llama 2 code 34 is the worst . </p>

          '
        raw: 'For me base llama 2 code 34 is the worst . '
        updatedAt: '2023-08-27T08:46:45.981Z'
      numEdits: 0
      reactions: []
    id: 64eb0d755ba66cfe779060c4
    type: comment
  author: mirek190
  content: 'For me base llama 2 code 34 is the worst . '
  created_at: 2023-08-27 07:46:45+00:00
  edited: false
  hidden: false
  id: 64eb0d755ba66cfe779060c4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/43fd0050e827ad080aabbd3fec287ed8.svg
      fullname: Ronen Zyroff
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ronenzyroff
      type: user
    createdAt: '2023-08-28T02:43:16.000Z'
    data:
      edited: true
      editors:
      - ronenzyroff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.615731418132782
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/43fd0050e827ad080aabbd3fec287ed8.svg
          fullname: Ronen Zyroff
          isHf: false
          isPro: false
          name: ronenzyroff
          type: user
        html: '<p>As I thought, <a href="https://huggingface.co/TheBloke/Airoboros-c34B-2.1-GGUF">airoboros-c34b-2.1.Q8_0.gguf</a>
          is better than any wizard model:<br>koboldcpp_nocuda.exe airoboros-c34b-2.1.Q8_0.gguf
          --contextsize 4096<br>Prompt:</p>

          <pre><code class="language-text">A chat

          USER: Provide complete working code for a realistic looking tree in Python
          using the Turtle graphics library and a recursive algorithm.

          ASSISTANT:

          </code></pre>

          <p>Edit: I later discovered the the actual correct prompt template includes
          a period (that might affect quality of generation, who knows):</p>

          <pre><code class="language-text">A chat.

          USER: Provide complete working code for a realistic looking tree in Python
          using the Turtle graphics library and a recursive algorithm.

          ASSISTANT:

          </code></pre>

          <p>Result (zero-shot):<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/2-SU1cXTEUI65QCw_O-n_.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/2-SU1cXTEUI65QCw_O-n_.png"></a></p>

          <p>Still not as good as GPT-3.5</p>

          '
        raw: 'As I thought, [airoboros-c34b-2.1.Q8_0.gguf](https://huggingface.co/TheBloke/Airoboros-c34B-2.1-GGUF)
          is better than any wizard model:

          koboldcpp_nocuda.exe airoboros-c34b-2.1.Q8_0.gguf --contextsize 4096

          Prompt:

          ```text

          A chat

          USER: Provide complete working code for a realistic looking tree in Python
          using the Turtle graphics library and a recursive algorithm.

          ASSISTANT:

          ```

          Edit: I later discovered the the actual correct prompt template includes
          a period (that might affect quality of generation, who knows):

          ```text

          A chat.

          USER: Provide complete working code for a realistic looking tree in Python
          using the Turtle graphics library and a recursive algorithm.

          ASSISTANT:

          ```

          Result (zero-shot):

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/2-SU1cXTEUI65QCw_O-n_.png)


          Still not as good as GPT-3.5'
        updatedAt: '2023-08-28T03:01:32.870Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mirek190
    id: 64ec09c4c68ddc867b897078
    type: comment
  author: ronenzyroff
  content: 'As I thought, [airoboros-c34b-2.1.Q8_0.gguf](https://huggingface.co/TheBloke/Airoboros-c34B-2.1-GGUF)
    is better than any wizard model:

    koboldcpp_nocuda.exe airoboros-c34b-2.1.Q8_0.gguf --contextsize 4096

    Prompt:

    ```text

    A chat

    USER: Provide complete working code for a realistic looking tree in Python using
    the Turtle graphics library and a recursive algorithm.

    ASSISTANT:

    ```

    Edit: I later discovered the the actual correct prompt template includes a period
    (that might affect quality of generation, who knows):

    ```text

    A chat.

    USER: Provide complete working code for a realistic looking tree in Python using
    the Turtle graphics library and a recursive algorithm.

    ASSISTANT:

    ```

    Result (zero-shot):

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/2-SU1cXTEUI65QCw_O-n_.png)


    Still not as good as GPT-3.5'
  created_at: 2023-08-28 01:43:16+00:00
  edited: true
  hidden: false
  id: 64ec09c4c68ddc867b897078
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-08-28T08:11:26.000Z'
    data:
      edited: false
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7816212773323059
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<blockquote>

          <p>As I thought, <a href="https://huggingface.co/TheBloke/Airoboros-c34B-2.1-GGUF">airoboros-c34b-2.1.Q8_0.gguf</a>
          is better than any wizard model:<br>koboldcpp_nocuda.exe airoboros-c34b-2.1.Q8_0.gguf
          --contextsize 4096<br>Prompt:</p>

          <pre><code class="language-text">A chat

          USER: Provide complete working code for a realistic looking tree in Python
          using the Turtle graphics library and a recursive algorithm.

          ASSISTANT:

          </code></pre>

          <p>Edit: I later discovered the the actual correct prompt template includes
          a period (that might affect quality of generation, who knows):</p>

          <pre><code class="language-text">A chat.

          USER: Provide complete working code for a realistic looking tree in Python
          using the Turtle graphics library and a recursive algorithm.

          ASSISTANT:

          </code></pre>

          <p>Result (zero-shot):<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/2-SU1cXTEUI65QCw_O-n_.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/2-SU1cXTEUI65QCw_O-n_.png"></a></p>

          <p>Still not as good as GPT-3.5</p>

          </blockquote>

          <p>You right I also tested that model and getting a  better results than
          wizardcoder.... even a text responses are cleaner as sentences. </p>

          '
        raw: "> As I thought, [airoboros-c34b-2.1.Q8_0.gguf](https://huggingface.co/TheBloke/Airoboros-c34B-2.1-GGUF)\
          \ is better than any wizard model:\n> koboldcpp_nocuda.exe airoboros-c34b-2.1.Q8_0.gguf\
          \ --contextsize 4096\n> Prompt:\n> ```text\n> A chat\n> USER: Provide complete\
          \ working code for a realistic looking tree in Python using the Turtle graphics\
          \ library and a recursive algorithm.\n> ASSISTANT:\n> ```\n> Edit: I later\
          \ discovered the the actual correct prompt template includes a period (that\
          \ might affect quality of generation, who knows):\n> ```text\n> A chat.\n\
          > USER: Provide complete working code for a realistic looking tree in Python\
          \ using the Turtle graphics library and a recursive algorithm.\n> ASSISTANT:\n\
          > ```\n> Result (zero-shot):\n> ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/2-SU1cXTEUI65QCw_O-n_.png)\n\
          > \n> Still not as good as GPT-3.5\n\nYou right I also tested that model\
          \ and getting a  better results than wizardcoder.... even a text responses\
          \ are cleaner as sentences. "
        updatedAt: '2023-08-28T08:11:26.068Z'
      numEdits: 0
      reactions: []
    id: 64ec56ae233101ed9910d5e8
    type: comment
  author: mirek190
  content: "> As I thought, [airoboros-c34b-2.1.Q8_0.gguf](https://huggingface.co/TheBloke/Airoboros-c34B-2.1-GGUF)\
    \ is better than any wizard model:\n> koboldcpp_nocuda.exe airoboros-c34b-2.1.Q8_0.gguf\
    \ --contextsize 4096\n> Prompt:\n> ```text\n> A chat\n> USER: Provide complete\
    \ working code for a realistic looking tree in Python using the Turtle graphics\
    \ library and a recursive algorithm.\n> ASSISTANT:\n> ```\n> Edit: I later discovered\
    \ the the actual correct prompt template includes a period (that might affect\
    \ quality of generation, who knows):\n> ```text\n> A chat.\n> USER: Provide complete\
    \ working code for a realistic looking tree in Python using the Turtle graphics\
    \ library and a recursive algorithm.\n> ASSISTANT:\n> ```\n> Result (zero-shot):\n\
    > ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/2-SU1cXTEUI65QCw_O-n_.png)\n\
    > \n> Still not as good as GPT-3.5\n\nYou right I also tested that model and getting\
    \ a  better results than wizardcoder.... even a text responses are cleaner as\
    \ sentences. "
  created_at: 2023-08-28 07:11:26+00:00
  edited: false
  hidden: false
  id: 64ec56ae233101ed9910d5e8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-08-28T23:56:19.000Z'
    data:
      edited: true
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7379858493804932
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: "<blockquote>\n<blockquote>\n<p>As I thought, <a href=\"https://huggingface.co/TheBloke/Airoboros-c34B-2.1-GGUF\"\
          >airoboros-c34b-2.1.Q8_0.gguf</a> is better than any wizard model:<br>koboldcpp_nocuda.exe\
          \ airoboros-c34b-2.1.Q8_0.gguf --contextsize 4096<br>Prompt:</p>\n<pre><code\
          \ class=\"language-text\">A chat\nUSER: Provide complete working code for\
          \ a realistic looking tree in Python using the Turtle graphics library and\
          \ a recursive algorithm.\nASSISTANT:\n</code></pre>\n<p>Edit: I later discovered\
          \ the the actual correct prompt template includes a period (that might affect\
          \ quality of generation, who knows):</p>\n<pre><code class=\"language-text\"\
          >A chat.\nUSER: Provide complete working code for a realistic looking tree\
          \ in Python using the Turtle graphics library and a recursive algorithm.\n\
          ASSISTANT:\n</code></pre>\n<p>Result (zero-shot):<br><a rel=\"nofollow\"\
          \ href=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/2-SU1cXTEUI65QCw_O-n_.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/2-SU1cXTEUI65QCw_O-n_.png\"\
          ></a></p>\n<p>Still not as good as GPT-3.5</p>\n</blockquote>\n<p>You right\
          \ I also tested that model and getting a  better results than wizardcoder....\
          \ even a text responses are cleaner as sentences.</p>\n</blockquote>\n<p>Stupid\
          \ question .... Did you use 16k ctx?</p>\n<p>Look what I got with 16k ctx\
          \ ....on first attempt</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/BCmW3L5Nh0nISB42fLF8m.png\"\
          ><img alt=\"Screenshot 2023-08-29 005136.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/BCmW3L5Nh0nISB42fLF8m.png\"\
          ></a></p>\n<blockquote>\n<h3 id=\"instruction-provide-complete-working-code-for-a-realistic-looking-tree-in-python-using-the-turtle-graphics-library-and-a-recursive-algorithm\"\
          >Instruction: Provide complete working code for a realistic looking tree\
          \ in Python using the Turtle graphics library and a recursive algorithm.</h3>\n\
          </blockquote>\n<h3 id=\"response-here-is-an-implementation-of-a-recursive-algorithm-to-draw-a-fractal-tree-using-pythons-turtle-library-it-uses-the-sierpinski-triangle-technique-to-create-a-realistic-looking-tree-with-random-branching-size-and-color-variations\"\
          >Response: Here is an implementation of a recursive algorithm to draw a\
          \ fractal tree using Python's turtle library. It uses the Sierpinski triangle\
          \ technique to create a realistic-looking tree with random branching, size,\
          \ and color variations:</h3>\n<pre><code class=\"language-python\"><span\
          \ class=\"hljs-keyword\">import</span> turtle\n<span class=\"hljs-keyword\"\
          >import</span> random\n\n\n<span class=\"hljs-keyword\">def</span> <span\
          \ class=\"hljs-title function_\">draw_branch</span>(<span class=\"hljs-params\"\
          >branch_length, angle, level</span>):\n    <span class=\"hljs-keyword\"\
          >if</span> level == <span class=\"hljs-number\">0</span>:\n        <span\
          \ class=\"hljs-keyword\">return</span>\n\n    <span class=\"hljs-comment\"\
          ># Draw the branch</span>\n    turtle.pensize(level)\n    turtle.forward(branch_length)\n\
          \n    <span class=\"hljs-comment\"># Randomly set the branch's color</span>\n\
          \    r = random.random()\n    g = random.random()\n    b = random.random()\n\
          \    turtle.color(r, g, b)\n\n\n    <span class=\"hljs-comment\"># Turn\
          \ left and right by some randomly generated angle to create the branching\
          \ effect</span>\n    turtle.left(angle)\n    draw_branch(branch_length *\
          \ <span class=\"hljs-number\">0.8</span>, angle * <span class=\"hljs-number\"\
          >1.15</span>, level - <span class=\"hljs-number\">1</span>)  <span class=\"\
          hljs-comment\"># Recursively draw the left branch</span>\n\n    turtle.right(<span\
          \ class=\"hljs-number\">2</span>*angle)\n    draw_branch(branch_length *\
          \ <span class=\"hljs-number\">0.8</span>, angle * <span class=\"hljs-number\"\
          >1.15</span>, level - <span class=\"hljs-number\">1</span>)  <span class=\"\
          hljs-comment\"># Recursively draw the right branch</span>\n\n    turtle.left(angle)\n\
          \    turtle.backward(branch_length)\n\n<span class=\"hljs-comment\"># Set\
          \ up the turtle and screen</span>\nturtle.setup(<span class=\"hljs-number\"\
          >600</span>, <span class=\"hljs-number\">600</span>)\nturtle.speed(<span\
          \ class=\"hljs-number\">0</span>)\nturtle.bgcolor(<span class=\"hljs-string\"\
          >'black'</span>)\n\nturtle.penup()\nturtle.goto(-<span class=\"hljs-number\"\
          >300</span>, -<span class=\"hljs-number\">250</span>)\nturtle.pendown()\n\
          turtle.left(<span class=\"hljs-number\">90</span>)\n\n\n<span class=\"hljs-comment\"\
          ># Start the recursive drawing process with a branch length of 150 and an\
          \ angle of 45 degrees at level 7</span>\ndraw_branch(<span class=\"hljs-number\"\
          >150</span>, <span class=\"hljs-number\">45</span>, <span class=\"hljs-number\"\
          >7</span>)\n\n\nturtle.done()\n</code></pre>\n<p>In this code snippet, we\
          \ define the <code>draw_branch</code> function that takes in three arguments:\
          \ <code>branch_length</code>, <code>angle</code>, and <code>level</code>.\
          \ The branch length controls how long each branch of the tree is, and the\
          \ angle determines the size of the branches as they get smaller. The level\
          \ represents the depth of recursion. At level 0, the algorithm stops drawing\
          \ new branches and just returns.</p>\n<p>Inside the function, we set the\
          \ turtle's pen color to a random RGB value using the <code>random</code>\
          \ module. We then move forward by <code>branch_length</code> pixels, turn\
          \ left by <code>angle</code>, draw the left branch (by calling <code>draw_branch</code>\
          \ again with 80% of the length and the same angle), turn right by twice\
          \ <code>angle</code>, and then draw the right branch. Finally, we come back\
          \ to the original position by moving backwards.</p>\n<p>To use this function,\
          \ we set up the turtle screen and start at a specific location on the canvas\
          \ with <code>turtle.setup</code> and <code>turtle.goto</code>. We also set\
          \ the background color to black using <code>turtle.bgcolor</code> and the\
          \ speed of the drawing process to 0 (fastest) using <code>turtle.speed</code>.\
          \ Then, we start the recursive drawing process with a branch length of 150\
          \ pixels, an angle of 45 degrees, and a level of 7 (which will result in\
          \ approximately 32,0000 branches). Finally, we call <code>turtle.done()</code>\
          \ to display the tree on the screen and wait for user input before exiting.</p>\n\
          <p>The resulting image should look something like this:</p>\n<p><a rel=\"\
          nofollow\" href=\"https://i.imgur.com/3y5jvKF.png\"><img alt=\"Realistic\
          \ Tree\" src=\"https://i.imgur.com/3y5jvKF.png\"></a></p>\n<p>You can adjust\
          \ the initial branch length, angle, and level to get different shapes and\
          \ sizes of trees. Here's an example with longer branches, a smaller angle,\
          \ and a lower level:</p>\n<pre><code class=\"language-python\">draw_branch(<span\
          \ class=\"hljs-number\">250</span>, <span class=\"hljs-number\">30</span>,\
          \ <span class=\"hljs-number\">6</span>)\n</code></pre>\n"
        raw: "> > As I thought, [airoboros-c34b-2.1.Q8_0.gguf](https://huggingface.co/TheBloke/Airoboros-c34B-2.1-GGUF)\
          \ is better than any wizard model:\n> > koboldcpp_nocuda.exe airoboros-c34b-2.1.Q8_0.gguf\
          \ --contextsize 4096\n> > Prompt:\n> > ```text\n> > A chat\n> > USER: Provide\
          \ complete working code for a realistic looking tree in Python using the\
          \ Turtle graphics library and a recursive algorithm.\n> > ASSISTANT:\n>\
          \ > ```\n> > Edit: I later discovered the the actual correct prompt template\
          \ includes a period (that might affect quality of generation, who knows):\n\
          > > ```text\n> > A chat.\n> > USER: Provide complete working code for a\
          \ realistic looking tree in Python using the Turtle graphics library and\
          \ a recursive algorithm.\n> > ASSISTANT:\n> > ```\n> > Result (zero-shot):\n\
          > > ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/2-SU1cXTEUI65QCw_O-n_.png)\n\
          > > \n> > Still not as good as GPT-3.5\n> \n> You right I also tested that\
          \ model and getting a  better results than wizardcoder.... even a text responses\
          \ are cleaner as sentences.\n\nStupid question .... Did you use 16k ctx?\n\
          \n\nLook what I got with 16k ctx ....on first attempt\n\n\n![Screenshot\
          \ 2023-08-29 005136.png](https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/BCmW3L5Nh0nISB42fLF8m.png)\n\
          \n\n\n>  ### Instruction: Provide complete working code for a realistic\
          \ looking tree in Python using the Turtle graphics library and a recursive\
          \ algorithm.\n ### Response: Here is an implementation of a recursive algorithm\
          \ to draw a fractal tree using Python's turtle library. It uses the Sierpinski\
          \ triangle technique to create a realistic-looking tree with random branching,\
          \ size, and color variations:\n\n\n```python\nimport turtle\nimport random\n\
          \n\ndef draw_branch(branch_length, angle, level):\n    if level == 0:\n\
          \        return\n\n    # Draw the branch\n    turtle.pensize(level)\n  \
          \  turtle.forward(branch_length)\n\n    # Randomly set the branch's color\n\
          \    r = random.random()\n    g = random.random()\n    b = random.random()\n\
          \    turtle.color(r, g, b)\n\n\n    # Turn left and right by some randomly\
          \ generated angle to create the branching effect\n    turtle.left(angle)\n\
          \    draw_branch(branch_length * 0.8, angle * 1.15, level - 1)  # Recursively\
          \ draw the left branch\n\n    turtle.right(2*angle)\n    draw_branch(branch_length\
          \ * 0.8, angle * 1.15, level - 1)  # Recursively draw the right branch\n\
          \n    turtle.left(angle)\n    turtle.backward(branch_length)\n\n# Set up\
          \ the turtle and screen\nturtle.setup(600, 600)\nturtle.speed(0)\nturtle.bgcolor('black')\n\
          \nturtle.penup()\nturtle.goto(-300, -250)\nturtle.pendown()\nturtle.left(90)\n\
          \n\n# Start the recursive drawing process with a branch length of 150 and\
          \ an angle of 45 degrees at level 7\ndraw_branch(150, 45, 7)\n\n\nturtle.done()\n\
          ```\n\n\nIn this code snippet, we define the `draw_branch` function that\
          \ takes in three arguments: `branch_length`, `angle`, and `level`. The branch\
          \ length controls how long each branch of the tree is, and the angle determines\
          \ the size of the branches as they get smaller. The level represents the\
          \ depth of recursion. At level 0, the algorithm stops drawing new branches\
          \ and just returns.\n\n\nInside the function, we set the turtle's pen color\
          \ to a random RGB value using the `random` module. We then move forward\
          \ by `branch_length` pixels, turn left by `angle`, draw the left branch\
          \ (by calling `draw_branch` again with 80% of the length and the same angle),\
          \ turn right by twice `angle`, and then draw the right branch. Finally,\
          \ we come back to the original position by moving backwards.\n\n\nTo use\
          \ this function, we set up the turtle screen and start at a specific location\
          \ on the canvas with `turtle.setup` and `turtle.goto`. We also set the background\
          \ color to black using `turtle.bgcolor` and the speed of the drawing process\
          \ to 0 (fastest) using `turtle.speed`. Then, we start the recursive drawing\
          \ process with a branch length of 150 pixels, an angle of 45 degrees, and\
          \ a level of 7 (which will result in approximately 32,0000 branches). Finally,\
          \ we call `turtle.done()` to display the tree on the screen and wait for\
          \ user input before exiting.\n\n\nThe resulting image should look something\
          \ like this:\n\n\n![Realistic Tree](https://i.imgur.com/3y5jvKF.png)\n\n\
          \nYou can adjust the initial branch length, angle, and level to get different\
          \ shapes and sizes of trees. Here's an example with longer branches, a smaller\
          \ angle, and a lower level:\n\n\n```python\ndraw_branch(250, 30, 6)\n```"
        updatedAt: '2023-08-28T23:58:17.353Z'
      numEdits: 1
      reactions: []
    id: 64ed342394cee41a758ef603
    type: comment
  author: mirek190
  content: "> > As I thought, [airoboros-c34b-2.1.Q8_0.gguf](https://huggingface.co/TheBloke/Airoboros-c34B-2.1-GGUF)\
    \ is better than any wizard model:\n> > koboldcpp_nocuda.exe airoboros-c34b-2.1.Q8_0.gguf\
    \ --contextsize 4096\n> > Prompt:\n> > ```text\n> > A chat\n> > USER: Provide\
    \ complete working code for a realistic looking tree in Python using the Turtle\
    \ graphics library and a recursive algorithm.\n> > ASSISTANT:\n> > ```\n> > Edit:\
    \ I later discovered the the actual correct prompt template includes a period\
    \ (that might affect quality of generation, who knows):\n> > ```text\n> > A chat.\n\
    > > USER: Provide complete working code for a realistic looking tree in Python\
    \ using the Turtle graphics library and a recursive algorithm.\n> > ASSISTANT:\n\
    > > ```\n> > Result (zero-shot):\n> > ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6454215a06728ff79a3685bf/2-SU1cXTEUI65QCw_O-n_.png)\n\
    > > \n> > Still not as good as GPT-3.5\n> \n> You right I also tested that model\
    \ and getting a  better results than wizardcoder.... even a text responses are\
    \ cleaner as sentences.\n\nStupid question .... Did you use 16k ctx?\n\n\nLook\
    \ what I got with 16k ctx ....on first attempt\n\n\n![Screenshot 2023-08-29 005136.png](https://cdn-uploads.huggingface.co/production/uploads/6345b208a8c2ff9f13784968/BCmW3L5Nh0nISB42fLF8m.png)\n\
    \n\n\n>  ### Instruction: Provide complete working code for a realistic looking\
    \ tree in Python using the Turtle graphics library and a recursive algorithm.\n\
    \ ### Response: Here is an implementation of a recursive algorithm to draw a fractal\
    \ tree using Python's turtle library. It uses the Sierpinski triangle technique\
    \ to create a realistic-looking tree with random branching, size, and color variations:\n\
    \n\n```python\nimport turtle\nimport random\n\n\ndef draw_branch(branch_length,\
    \ angle, level):\n    if level == 0:\n        return\n\n    # Draw the branch\n\
    \    turtle.pensize(level)\n    turtle.forward(branch_length)\n\n    # Randomly\
    \ set the branch's color\n    r = random.random()\n    g = random.random()\n \
    \   b = random.random()\n    turtle.color(r, g, b)\n\n\n    # Turn left and right\
    \ by some randomly generated angle to create the branching effect\n    turtle.left(angle)\n\
    \    draw_branch(branch_length * 0.8, angle * 1.15, level - 1)  # Recursively\
    \ draw the left branch\n\n    turtle.right(2*angle)\n    draw_branch(branch_length\
    \ * 0.8, angle * 1.15, level - 1)  # Recursively draw the right branch\n\n   \
    \ turtle.left(angle)\n    turtle.backward(branch_length)\n\n# Set up the turtle\
    \ and screen\nturtle.setup(600, 600)\nturtle.speed(0)\nturtle.bgcolor('black')\n\
    \nturtle.penup()\nturtle.goto(-300, -250)\nturtle.pendown()\nturtle.left(90)\n\
    \n\n# Start the recursive drawing process with a branch length of 150 and an angle\
    \ of 45 degrees at level 7\ndraw_branch(150, 45, 7)\n\n\nturtle.done()\n```\n\n\
    \nIn this code snippet, we define the `draw_branch` function that takes in three\
    \ arguments: `branch_length`, `angle`, and `level`. The branch length controls\
    \ how long each branch of the tree is, and the angle determines the size of the\
    \ branches as they get smaller. The level represents the depth of recursion. At\
    \ level 0, the algorithm stops drawing new branches and just returns.\n\n\nInside\
    \ the function, we set the turtle's pen color to a random RGB value using the\
    \ `random` module. We then move forward by `branch_length` pixels, turn left by\
    \ `angle`, draw the left branch (by calling `draw_branch` again with 80% of the\
    \ length and the same angle), turn right by twice `angle`, and then draw the right\
    \ branch. Finally, we come back to the original position by moving backwards.\n\
    \n\nTo use this function, we set up the turtle screen and start at a specific\
    \ location on the canvas with `turtle.setup` and `turtle.goto`. We also set the\
    \ background color to black using `turtle.bgcolor` and the speed of the drawing\
    \ process to 0 (fastest) using `turtle.speed`. Then, we start the recursive drawing\
    \ process with a branch length of 150 pixels, an angle of 45 degrees, and a level\
    \ of 7 (which will result in approximately 32,0000 branches). Finally, we call\
    \ `turtle.done()` to display the tree on the screen and wait for user input before\
    \ exiting.\n\n\nThe resulting image should look something like this:\n\n\n![Realistic\
    \ Tree](https://i.imgur.com/3y5jvKF.png)\n\n\nYou can adjust the initial branch\
    \ length, angle, and level to get different shapes and sizes of trees. Here's\
    \ an example with longer branches, a smaller angle, and a lower level:\n\n\n```python\n\
    draw_branch(250, 30, 6)\n```"
  created_at: 2023-08-28 22:56:19+00:00
  edited: true
  hidden: false
  id: 64ed342394cee41a758ef603
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0fa6d53891ffd28118296b5cf51cb70d.svg
      fullname: Jeff Wadsworth
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jeffwadsworth
      type: user
    createdAt: '2023-09-01T00:25:20.000Z'
    data:
      edited: false
      editors:
      - jeffwadsworth
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9891157150268555
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0fa6d53891ffd28118296b5cf51cb70d.svg
          fullname: Jeff Wadsworth
          isHf: false
          isPro: false
          name: jeffwadsworth
          type: user
        html: '<p>It is not as good as gpt-4.  I had it code a simple tic-tac-toe
          game using monte carlo for the AI.  It mostly worked, but it had an error
          where it was trying to pass 2 arguments to a method that could only accept
          1.  Anyway, I copied the code  into gpt-4 and asked it what was wrong and
          to fix it.  It found every issue (3 of them) and fixed them all perfectly.  The
          model is quite nice (free!), but let''s not kid ourselves about it being
          better than you-know-who.  At least not yet.</p>

          '
        raw: It is not as good as gpt-4.  I had it code a simple tic-tac-toe game
          using monte carlo for the AI.  It mostly worked, but it had an error where
          it was trying to pass 2 arguments to a method that could only accept 1.  Anyway,
          I copied the code  into gpt-4 and asked it what was wrong and to fix it.  It
          found every issue (3 of them) and fixed them all perfectly.  The model is
          quite nice (free!), but let's not kid ourselves about it being better than
          you-know-who.  At least not yet.
        updatedAt: '2023-09-01T00:25:20.866Z'
      numEdits: 0
      reactions: []
    id: 64f12f70f58bc71b60f082cf
    type: comment
  author: jeffwadsworth
  content: It is not as good as gpt-4.  I had it code a simple tic-tac-toe game using
    monte carlo for the AI.  It mostly worked, but it had an error where it was trying
    to pass 2 arguments to a method that could only accept 1.  Anyway, I copied the
    code  into gpt-4 and asked it what was wrong and to fix it.  It found every issue
    (3 of them) and fixed them all perfectly.  The model is quite nice (free!), but
    let's not kid ourselves about it being better than you-know-who.  At least not
    yet.
  created_at: 2023-08-31 23:25:20+00:00
  edited: false
  hidden: false
  id: 64f12f70f58bc71b60f082cf
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/WizardCoder-Python-34B-V1.0-GGUF
repo_type: model
status: open
target_branch: null
title: This model looks insanely good for coding ( 73.2 for humanEval )!
