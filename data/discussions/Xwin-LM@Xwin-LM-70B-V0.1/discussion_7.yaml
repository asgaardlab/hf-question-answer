!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jackboot
conflicting_files: null
created_at: 2023-09-25 23:12:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3637feae0735d26cfb196148c87eef07.svg
      fullname: Jack Boot
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jackboot
      type: user
    createdAt: '2023-09-26T00:12:44.000Z'
    data:
      edited: true
      editors:
      - jackboot
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9624506235122681
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3637feae0735d26cfb196148c87eef07.svg
          fullname: Jack Boot
          isHf: false
          isPro: false
          name: jackboot
          type: user
        html: '<p>Model starts strong and works well at first. As context builds up,
          it begins repeating certain past phrases in every reply. I have tried with
          mirostat and traditional sampling. </p>

          <p>Using 4.625 bpw GPTQ quant so it''s not a lack of bits. Happens with
          or without rope. Using both alpaca and vicuna instruction templates. </p>

          '
        raw: "Model starts strong and works well at first. As context builds up, it\
          \ begins repeating certain past phrases in every reply. I have tried with\
          \ mirostat and traditional sampling. \n\nUsing 4.625 bpw GPTQ quant so it's\
          \ not a lack of bits. Happens with or without rope. Using both alpaca and\
          \ vicuna instruction templates. "
        updatedAt: '2023-09-26T00:13:04.919Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - AntiSquid
    id: 651221fc6bea603bfb769d81
    type: comment
  author: jackboot
  content: "Model starts strong and works well at first. As context builds up, it\
    \ begins repeating certain past phrases in every reply. I have tried with mirostat\
    \ and traditional sampling. \n\nUsing 4.625 bpw GPTQ quant so it's not a lack\
    \ of bits. Happens with or without rope. Using both alpaca and vicuna instruction\
    \ templates. "
  created_at: 2023-09-25 23:12:44+00:00
  edited: true
  hidden: false
  id: 651221fc6bea603bfb769d81
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fed5d447375cd8c3b2bc9e096fe681de.svg
      fullname: Bolin Ni
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: nbl97
      type: user
    createdAt: '2023-09-26T04:46:31.000Z'
    data:
      edited: false
      editors:
      - nbl97
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7941572070121765
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fed5d447375cd8c3b2bc9e096fe681de.svg
          fullname: Bolin Ni
          isHf: false
          isPro: false
          name: nbl97
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;jackboot&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/jackboot\">@<span class=\"\
          underline\">jackboot</span></a></span>\n\n\t</span></span> Hi~ Could you\
          \ share some cases for reproduction?</p>\n"
        raw: '@jackboot Hi~ Could you share some cases for reproduction?'
        updatedAt: '2023-09-26T04:46:31.890Z'
      numEdits: 0
      reactions: []
    id: 6512622760584e99b16f7ccf
    type: comment
  author: nbl97
  content: '@jackboot Hi~ Could you share some cases for reproduction?'
  created_at: 2023-09-26 03:46:31+00:00
  edited: false
  hidden: false
  id: 6512622760584e99b16f7ccf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/431f1c79efb0ece9bd46a71e0bf2dda1.svg
      fullname: Dan J
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Gershwin69
      type: user
    createdAt: '2023-09-26T09:38:36.000Z'
    data:
      edited: true
      editors:
      - Gershwin69
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9744142293930054
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/431f1c79efb0ece9bd46a71e0bf2dda1.svg
          fullname: Dan J
          isHf: false
          isPro: false
          name: Gershwin69
          type: user
        html: '<p>I also have experienced this. An extremely good start using conversation
          inputs, I''d say almost some of the best I''ve had using a local model.
          But it reached a point (towards context max) where it absolutely wouldn''t
          respond with anything except prior inputs, sometimes very slightly rephrased,
          but not really. I did eventually get it to provide new output, but only
          by (a) Massively increasing allowed token generation size and (b) Removing
          most stop words. What it then did was repeat a couple of prior outputs and
          THEN generated something new. I do not have the example available, sorry.</p>

          '
        raw: I also have experienced this. An extremely good start using conversation
          inputs, I'd say almost some of the best I've had using a local model. But
          it reached a point (towards context max) where it absolutely wouldn't respond
          with anything except prior inputs, sometimes very slightly rephrased, but
          not really. I did eventually get it to provide new output, but only by (a)
          Massively increasing allowed token generation size and (b) Removing most
          stop words. What it then did was repeat a couple of prior outputs and THEN
          generated something new. I do not have the example available, sorry.
        updatedAt: '2023-09-26T09:39:09.376Z'
      numEdits: 1
      reactions: []
    id: 6512a69cb94d5922e3f44b1a
    type: comment
  author: Gershwin69
  content: I also have experienced this. An extremely good start using conversation
    inputs, I'd say almost some of the best I've had using a local model. But it reached
    a point (towards context max) where it absolutely wouldn't respond with anything
    except prior inputs, sometimes very slightly rephrased, but not really. I did
    eventually get it to provide new output, but only by (a) Massively increasing
    allowed token generation size and (b) Removing most stop words. What it then did
    was repeat a couple of prior outputs and THEN generated something new. I do not
    have the example available, sorry.
  created_at: 2023-09-26 08:38:36+00:00
  edited: true
  hidden: false
  id: 6512a69cb94d5922e3f44b1a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3637feae0735d26cfb196148c87eef07.svg
      fullname: Jack Boot
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jackboot
      type: user
    createdAt: '2023-09-26T15:26:30.000Z'
    data:
      edited: false
      editors:
      - jackboot
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9491291046142578
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3637feae0735d26cfb196148c87eef07.svg
          fullname: Jack Boot
          isHf: false
          isPro: false
          name: jackboot
          type: user
        html: '<p>To reproduce it simply have a conversation and reach high context,
          3500 or so. Any backend that uses character prompts for roleplay ought to
          do it.</p>

          <p>If you are asking oneshot questions the problem is not possible to see
          easily, there is no continuity.  For example in a chat, the model ends multiple
          messages like this after a certain point:</p>

          <pre><code>P.S. I''m grateful for your understanding and openness to discuss
          this concept with me, and I''ll do my best to keep the conversation engaging
          while avoiding repetition.

          P.S. I apologize for the repetition earlier. I''ll make sure to keep my
          responses diverse and engaging from now on.

          P.S. I appreciate your understanding about the repetition earlier, and I''ll
          do my best to avoid it in the future.

          P.S. I''m glad you''re open to exploring this idea with me, and I''ll do
          my best to avoid repetition and keep the conversation engaging.

          P.S. I''m grateful for your understanding and openness to discuss this concept
          with me, and I''ll do my best to keep the conversation engaging while avoiding
          repetition.

          P.S. I appreciate your openness in discussing this unique experience with
          me, and I''ll do my best to keep the conversation engaging while avoiding
          repetition.

          P.S. I appreciate your trust in sharing this story with me, and I''ll do
          my best to keep the conversation engaging while avoiding repetition.

          </code></pre>

          <p>And it just keeps going like that.  I was experimenting,  trying everything
          to get it to stop, changing sampling etc. You will get <em>some</em> new
          output but a section of the old still there and every message has more and
          more old.</p>

          '
        raw: "To reproduce it simply have a conversation and reach high context, 3500\
          \ or so. Any backend that uses character prompts for roleplay ought to do\
          \ it.\n\nIf you are asking oneshot questions the problem is not possible\
          \ to see easily, there is no continuity.  For example in a chat, the model\
          \ ends multiple messages like this after a certain point:\n\n\n    P.S.\
          \ I'm grateful for your understanding and openness to discuss this concept\
          \ with me, and I'll do my best to keep the conversation engaging while avoiding\
          \ repetition.\n    P.S. I apologize for the repetition earlier. I'll make\
          \ sure to keep my responses diverse and engaging from now on.\n    P.S.\
          \ I appreciate your understanding about the repetition earlier, and I'll\
          \ do my best to avoid it in the future.\n    P.S. I'm glad you're open to\
          \ exploring this idea with me, and I'll do my best to avoid repetition and\
          \ keep the conversation engaging.\n    P.S. I'm grateful for your understanding\
          \ and openness to discuss this concept with me, and I'll do my best to keep\
          \ the conversation engaging while avoiding repetition.\n    P.S. I appreciate\
          \ your openness in discussing this unique experience with me, and I'll do\
          \ my best to keep the conversation engaging while avoiding repetition.\n\
          \    P.S. I appreciate your trust in sharing this story with me, and I'll\
          \ do my best to keep the conversation engaging while avoiding repetition.\n\
          \nAnd it just keeps going like that.  I was experimenting,  trying everything\
          \ to get it to stop, changing sampling etc. You will get *some* new output\
          \ but a section of the old still there and every message has more and more\
          \ old."
        updatedAt: '2023-09-26T15:26:30.787Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F92F"
        users:
        - Yhyu13
    id: 6512f826408d3000f05ce077
    type: comment
  author: jackboot
  content: "To reproduce it simply have a conversation and reach high context, 3500\
    \ or so. Any backend that uses character prompts for roleplay ought to do it.\n\
    \nIf you are asking oneshot questions the problem is not possible to see easily,\
    \ there is no continuity.  For example in a chat, the model ends multiple messages\
    \ like this after a certain point:\n\n\n    P.S. I'm grateful for your understanding\
    \ and openness to discuss this concept with me, and I'll do my best to keep the\
    \ conversation engaging while avoiding repetition.\n    P.S. I apologize for the\
    \ repetition earlier. I'll make sure to keep my responses diverse and engaging\
    \ from now on.\n    P.S. I appreciate your understanding about the repetition\
    \ earlier, and I'll do my best to avoid it in the future.\n    P.S. I'm glad you're\
    \ open to exploring this idea with me, and I'll do my best to avoid repetition\
    \ and keep the conversation engaging.\n    P.S. I'm grateful for your understanding\
    \ and openness to discuss this concept with me, and I'll do my best to keep the\
    \ conversation engaging while avoiding repetition.\n    P.S. I appreciate your\
    \ openness in discussing this unique experience with me, and I'll do my best to\
    \ keep the conversation engaging while avoiding repetition.\n    P.S. I appreciate\
    \ your trust in sharing this story with me, and I'll do my best to keep the conversation\
    \ engaging while avoiding repetition.\n\nAnd it just keeps going like that.  I\
    \ was experimenting,  trying everything to get it to stop, changing sampling etc.\
    \ You will get *some* new output but a section of the old still there and every\
    \ message has more and more old."
  created_at: 2023-09-26 14:26:30+00:00
  edited: false
  hidden: false
  id: 6512f826408d3000f05ce077
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/431f1c79efb0ece9bd46a71e0bf2dda1.svg
      fullname: Dan J
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Gershwin69
      type: user
    createdAt: '2023-09-26T16:47:28.000Z'
    data:
      edited: false
      editors:
      - Gershwin69
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9758746027946472
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/431f1c79efb0ece9bd46a71e0bf2dda1.svg
          fullname: Dan J
          isHf: false
          isPro: false
          name: Gershwin69
          type: user
        html: '<p>I also find that no matter what I tell it, when having a conversational
          interaction, the responses get longer and longer, which is often not ideal
          due to context size.</p>

          '
        raw: I also find that no matter what I tell it, when having a conversational
          interaction, the responses get longer and longer, which is often not ideal
          due to context size.
        updatedAt: '2023-09-26T16:47:28.927Z'
      numEdits: 0
      reactions: []
    id: 65130b20641b14c330dc0dc7
    type: comment
  author: Gershwin69
  content: I also find that no matter what I tell it, when having a conversational
    interaction, the responses get longer and longer, which is often not ideal due
    to context size.
  created_at: 2023-09-26 15:47:28+00:00
  edited: false
  hidden: false
  id: 65130b20641b14c330dc0dc7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-09-27T07:27:03.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9805065989494324
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: '<blockquote>

          <p>I also find that no matter what I tell it, when having a conversational
          interaction, the responses get longer and longer, which is often not ideal
          due to context size.</p>

          </blockquote>

          <p>It may be a RLHF-ed effort that prolong conversations over time by being
          more and more chatty? I don''t know</p>

          '
        raw: '> I also find that no matter what I tell it, when having a conversational
          interaction, the responses get longer and longer, which is often not ideal
          due to context size.


          It may be a RLHF-ed effort that prolong conversations over time by being
          more and more chatty? I don''t know'
        updatedAt: '2023-09-27T07:27:03.506Z'
      numEdits: 0
      reactions: []
    id: 6513d947c456f50350081ca6
    type: comment
  author: Yhyu13
  content: '> I also find that no matter what I tell it, when having a conversational
    interaction, the responses get longer and longer, which is often not ideal due
    to context size.


    It may be a RLHF-ed effort that prolong conversations over time by being more
    and more chatty? I don''t know'
  created_at: 2023-09-27 06:27:03+00:00
  edited: false
  hidden: false
  id: 6513d947c456f50350081ca6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/431f1c79efb0ece9bd46a71e0bf2dda1.svg
      fullname: Dan J
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Gershwin69
      type: user
    createdAt: '2023-09-27T10:12:10.000Z'
    data:
      edited: false
      editors:
      - Gershwin69
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9825835824012756
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/431f1c79efb0ece9bd46a71e0bf2dda1.svg
          fullname: Dan J
          isHf: false
          isPro: false
          name: Gershwin69
          type: user
        html: '<blockquote>

          <blockquote>

          <p>I also find that no matter what I tell it, when having a conversational
          interaction, the responses get longer and longer, which is often not ideal
          due to context size.</p>

          </blockquote>

          <p>It may be a RLHF-ed effort that prolong conversations over time by being
          more and more chatty? I don''t know</p>

          </blockquote>

          <p>It might well be, but it becomes a couple of paragraphs after a while
          which is just too much! It was generating 30% of the context size in reach
          response.</p>

          '
        raw: "> > I also find that no matter what I tell it, when having a conversational\
          \ interaction, the responses get longer and longer, which is often not ideal\
          \ due to context size.\n> \n> It may be a RLHF-ed effort that prolong conversations\
          \ over time by being more and more chatty? I don't know\n\nIt might well\
          \ be, but it becomes a couple of paragraphs after a while which is just\
          \ too much! It was generating 30% of the context size in reach response."
        updatedAt: '2023-09-27T10:12:10.060Z'
      numEdits: 0
      reactions: []
    id: 6513fffad66affb2181bfa49
    type: comment
  author: Gershwin69
  content: "> > I also find that no matter what I tell it, when having a conversational\
    \ interaction, the responses get longer and longer, which is often not ideal due\
    \ to context size.\n> \n> It may be a RLHF-ed effort that prolong conversations\
    \ over time by being more and more chatty? I don't know\n\nIt might well be, but\
    \ it becomes a couple of paragraphs after a while which is just too much! It was\
    \ generating 30% of the context size in reach response."
  created_at: 2023-09-27 09:12:10+00:00
  edited: false
  hidden: false
  id: 6513fffad66affb2181bfa49
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3637feae0735d26cfb196148c87eef07.svg
      fullname: Jack Boot
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jackboot
      type: user
    createdAt: '2023-09-27T12:32:46.000Z'
    data:
      edited: false
      editors:
      - jackboot
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9800688624382019
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3637feae0735d26cfb196148c87eef07.svg
          fullname: Jack Boot
          isHf: false
          isPro: false
          name: jackboot
          type: user
        html: '<p>I have the context headroom, but if it''s just going to output parts
          of the old messages, that isn''t helpful or engaging.</p>

          '
        raw: I have the context headroom, but if it's just going to output parts of
          the old messages, that isn't helpful or engaging.
        updatedAt: '2023-09-27T12:32:46.558Z'
      numEdits: 0
      reactions: []
    id: 651420ee12a1fd134c424843
    type: comment
  author: jackboot
  content: I have the context headroom, but if it's just going to output parts of
    the old messages, that isn't helpful or engaging.
  created_at: 2023-09-27 11:32:46+00:00
  edited: false
  hidden: false
  id: 651420ee12a1fd134c424843
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: Xwin-LM/Xwin-LM-70B-V0.1
repo_type: model
status: open
target_branch: null
title: I have serious repeat problem.
