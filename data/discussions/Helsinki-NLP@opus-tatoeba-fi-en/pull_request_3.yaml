!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sgugger
conflicting_files:
- pytorch_model.bin
created_at: 2023-06-20 14:25:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593126474392-5ef50182b71947201082a4e5.jpeg?w=200&h=200&f=face
      fullname: Sylvain Gugger
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sgugger
      type: user
    createdAt: '2023-06-20T15:25:05.000Z'
    data:
      edited: true
      editors:
      - sgugger
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9755750894546509
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593126474392-5ef50182b71947201082a4e5.jpeg?w=200&h=200&f=face
          fullname: Sylvain Gugger
          isHf: false
          isPro: false
          name: sgugger
          type: user
        html: '<p>There was probably a bug in the initial conversion script that created
          those models, as the weights they have have a<br>different value for <code>lm_head.weight</code>
          and <code>model.decoder.embed_tokens.weight</code>. Those weights are tied
          though.</p>

          <p>This was not a problem until now as the model was tied after the load
          and the (wrong) value of <code>lm_head.weight</code> was<br>replaced by
          the value of <code>model.decoder.embed_tokens.weight</code>. This does not
          work any more if we tie the weights before<br>the load however, as the value
          picked might be the one from <code>lm_head.weight</code> depending on how
          the models are tied.<br>As far as I can see, the model stop generating properly
          on Transformers main.</p>

          <p>This should fix the bug without any side effect. Side note on the diff:
          the new model weights are lighter because<br>PyTorch is smart and does not
          save the <code>lm_head.weight</code> twice.</p>

          '
        raw: 'There was probably a bug in the initial conversion script that created
          those models, as the weights they have have a

          different value for `lm_head.weight` and `model.decoder.embed_tokens.weight`.
          Those weights are tied though.


          This was not a problem until now as the model was tied after the load and
          the (wrong) value of `lm_head.weight` was

          replaced by the value of `model.decoder.embed_tokens.weight`. This does
          not work any more if we tie the weights before

          the load however, as the value picked might be the one from `lm_head.weight`
          depending on how the models are tied.

          As far as I can see, the model stop generating properly on Transformers
          main.


          This should fix the bug without any side effect. Side note on the diff:
          the new model weights are lighter because

          PyTorch is smart and does not save the `lm_head.weight` twice.'
        updatedAt: '2023-06-20T15:27:44.464Z'
      numEdits: 1
      reactions: []
    id: 6491c4d163e4e913aa3ee658
    type: comment
  author: sgugger
  content: 'There was probably a bug in the initial conversion script that created
    those models, as the weights they have have a

    different value for `lm_head.weight` and `model.decoder.embed_tokens.weight`.
    Those weights are tied though.


    This was not a problem until now as the model was tied after the load and the
    (wrong) value of `lm_head.weight` was

    replaced by the value of `model.decoder.embed_tokens.weight`. This does not work
    any more if we tie the weights before

    the load however, as the value picked might be the one from `lm_head.weight` depending
    on how the models are tied.

    As far as I can see, the model stop generating properly on Transformers main.


    This should fix the bug without any side effect. Side note on the diff: the new
    model weights are lighter because

    PyTorch is smart and does not save the `lm_head.weight` twice.'
  created_at: 2023-06-20 14:25:05+00:00
  edited: true
  hidden: false
  id: 6491c4d163e4e913aa3ee658
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593126474392-5ef50182b71947201082a4e5.jpeg?w=200&h=200&f=face
      fullname: Sylvain Gugger
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sgugger
      type: user
    createdAt: '2023-06-20T15:25:05.000Z'
    data:
      oid: 11127d53f371ec18bbc60b36dabc59a8361585b8
      parents:
      - 6f92d93f971a9aad3889b7b0e93123359ba5a7e8
      subject: Fix weights by putting the right value in `lm_head.weight`
    id: 6491c4d10000000000000000
    type: commit
  author: sgugger
  created_at: 2023-06-20 14:25:05+00:00
  id: 6491c4d10000000000000000
  oid: 11127d53f371ec18bbc60b36dabc59a8361585b8
  summary: Fix weights by putting the right value in `lm_head.weight`
  type: commit
is_pull_request: true
merge_commit_oid: null
num: 3
repo_id: Helsinki-NLP/opus-tatoeba-fi-en
repo_type: model
status: open
target_branch: refs/heads/main
title: Fix weights by putting the right value in `lm_head.weight`
