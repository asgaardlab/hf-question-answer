!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rjmehta
conflicting_files: null
created_at: 2023-12-21 17:29:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
      fullname: Raj Mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rjmehta
      type: user
    createdAt: '2023-12-21T17:29:20.000Z'
    data:
      edited: false
      editors:
      - rjmehta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9280617237091064
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
          fullname: Raj Mehta
          isHf: false
          isPro: false
          name: rjmehta
          type: user
        html: '<p>I am using the demo.py  but the model goes OOM even after having
          96Gb of GPU memory. Looks like it is only using single gpu and not distributing
          the model into multiple GPUs.</p>

          '
        raw: I am using the demo.py  but the model goes OOM even after having 96Gb
          of GPU memory. Looks like it is only using single gpu and not distributing
          the model into multiple GPUs.
        updatedAt: '2023-12-21T17:29:20.792Z'
      numEdits: 0
      reactions: []
    id: 658475f02189951844cb2822
    type: comment
  author: rjmehta
  content: I am using the demo.py  but the model goes OOM even after having 96Gb of
    GPU memory. Looks like it is only using single gpu and not distributing the model
    into multiple GPUs.
  created_at: 2023-12-21 17:29:20+00:00
  edited: false
  hidden: false
  id: 658475f02189951844cb2822
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: echo840/Monkey
repo_type: model
status: open
target_branch: null
title: Memory requirement?
