!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TriflingMediator
conflicting_files: null
created_at: 2023-06-19 20:25:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661254177148-6304b9ddbad6ce7fc026cce6.png?w=200&h=200&f=face
      fullname: Robert Wapshott
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TriflingMediator
      type: user
    createdAt: '2023-06-19T21:25:13.000Z'
    data:
      edited: false
      editors:
      - TriflingMediator
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.85441654920578
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661254177148-6304b9ddbad6ce7fc026cce6.png?w=200&h=200&f=face
          fullname: Robert Wapshott
          isHf: false
          isPro: false
          name: TriflingMediator
          type: user
        html: '<p>Hello, I was trying out this image as I was interested to see what
          difference OpenVINO made to Dolly 2.0.</p>

          <p>I got the following error when trying the example script provided.</p>

          <p>Traceback (most recent call last):<br>  File "//script.py", line 6, in
          <br>    tokenizer = AutoTokenizer.from_pretrained(model_id)<br>  File "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py",
          line 709, in from_pretrained<br>    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path,
          *inputs, **kwargs)<br>  File "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py",
          line 1809, in from_pretrained<br>    raise EnvironmentError(<br>OSError:
          Can''t load tokenizer for ''katuni4ka/dolly-v2-3b-ov''. If you were trying
          to load it from ''<a href="https://huggingface.co/models''">https://huggingface.co/models''</a>,
          make sure you don''t have a local directory with the same name. Otherwise,
          make sure ''katuni4ka/dolly-v2-3b-ov'' is the correct path to a directory
          containing all relevant files for a GPTNeoXTokenizerFast tokenizer.</p>

          <p>I''ve tried copying the related tokenizer files from the original Dolly
          V2 project, but this does not seem to have resolved the issue. Are there
          perhaps other files missing that we would need to run this model?</p>

          '
        raw: "Hello, I was trying out this image as I was interested to see what difference\
          \ OpenVINO made to Dolly 2.0.\r\n\r\nI got the following error when trying\
          \ the example script provided.\r\n\r\nTraceback (most recent call last):\r\
          \n  File \"//script.py\", line 6, in <module>\r\n    tokenizer = AutoTokenizer.from_pretrained(model_id)\r\
          \n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 709, in from_pretrained\r\n    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\r\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1809, in from_pretrained\r\n    raise EnvironmentError(\r\nOSError:\
          \ Can't load tokenizer for 'katuni4ka/dolly-v2-3b-ov'. If you were trying\
          \ to load it from 'https://huggingface.co/models', make sure you don't have\
          \ a local directory with the same name. Otherwise, make sure 'katuni4ka/dolly-v2-3b-ov'\
          \ is the correct path to a directory containing all relevant files for a\
          \ GPTNeoXTokenizerFast tokenizer.\r\n\r\nI've tried copying the related\
          \ tokenizer files from the original Dolly V2 project, but this does not\
          \ seem to have resolved the issue. Are there perhaps other files missing\
          \ that we would need to run this model?"
        updatedAt: '2023-06-19T21:25:13.149Z'
      numEdits: 0
      reactions: []
    id: 6490c7b9a88575c0187e440a
    type: comment
  author: TriflingMediator
  content: "Hello, I was trying out this image as I was interested to see what difference\
    \ OpenVINO made to Dolly 2.0.\r\n\r\nI got the following error when trying the\
    \ example script provided.\r\n\r\nTraceback (most recent call last):\r\n  File\
    \ \"//script.py\", line 6, in <module>\r\n    tokenizer = AutoTokenizer.from_pretrained(model_id)\r\
    \n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\"\
    , line 709, in from_pretrained\r\n    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path,\
    \ *inputs, **kwargs)\r\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
    , line 1809, in from_pretrained\r\n    raise EnvironmentError(\r\nOSError: Can't\
    \ load tokenizer for 'katuni4ka/dolly-v2-3b-ov'. If you were trying to load it\
    \ from 'https://huggingface.co/models', make sure you don't have a local directory\
    \ with the same name. Otherwise, make sure 'katuni4ka/dolly-v2-3b-ov' is the correct\
    \ path to a directory containing all relevant files for a GPTNeoXTokenizerFast\
    \ tokenizer.\r\n\r\nI've tried copying the related tokenizer files from the original\
    \ Dolly V2 project, but this does not seem to have resolved the issue. Are there\
    \ perhaps other files missing that we would need to run this model?"
  created_at: 2023-06-19 20:25:13+00:00
  edited: false
  hidden: false
  id: 6490c7b9a88575c0187e440a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: katuni4ka/dolly-v2-3b-ov
repo_type: model
status: open
target_branch: null
title: Can't load tokenizer for 'katuni4ka/dolly-v2-3b-ov'
