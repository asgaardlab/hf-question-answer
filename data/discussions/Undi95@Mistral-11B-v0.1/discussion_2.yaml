!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aslawliet
conflicting_files: null
created_at: 2023-11-26 10:17:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
      fullname: Lawliet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aslawliet
      type: user
    createdAt: '2023-11-26T10:17:19.000Z'
    data:
      edited: true
      editors:
      - aslawliet
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9164866805076599
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
          fullname: Lawliet
          isHf: false
          isPro: false
          name: aslawliet
          type: user
        html: '<p>Off topic question: the llama 2 22b created by chargoddard, suppose
          I make out something like that with Mistral and llama 2 13b, before getting
          it into inference, I will require a fine tune isn''t it, i did get the model
          done but it outputs garbage, haven''t yet fine-tuned though<br>Example output
          was -<br>"--) --) --)" </p>

          '
        raw: 'Off topic question: the llama 2 22b created by chargoddard, suppose
          I make out something like that with Mistral and llama 2 13b, before getting
          it into inference, I will require a fine tune isn''t it, i did get the model
          done but it outputs garbage, haven''t yet fine-tuned though

          Example output was -

          "--) --) --)" '
        updatedAt: '2023-11-26T10:29:08.308Z'
      numEdits: 4
      reactions: []
    id: 65631b2f119e451d4a951ffc
    type: comment
  author: aslawliet
  content: 'Off topic question: the llama 2 22b created by chargoddard, suppose I
    make out something like that with Mistral and llama 2 13b, before getting it into
    inference, I will require a fine tune isn''t it, i did get the model done but
    it outputs garbage, haven''t yet fine-tuned though

    Example output was -

    "--) --) --)" '
  created_at: 2023-11-26 10:17:19+00:00
  edited: true
  hidden: false
  id: 65631b2f119e451d4a951ffc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
      fullname: Undi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Undi95
      type: user
    createdAt: '2023-11-26T10:24:01.000Z'
    data:
      edited: true
      editors:
      - Undi95
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.984354555606842
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
          fullname: Undi
          isHf: false
          isPro: false
          name: Undi95
          type: user
        html: '<p>Mistral can''t be merged with Llama2<br>7B can''t be merged with
          70B<br>So yeah, not, it will not work haha</p>

          <p>As for creating bigger model from smaller one, you can use 2 different
          fine-tune, or do a big one from the two same, and fine-tune on top. </p>

          '
        raw: 'Mistral can''t be merged with Llama2

          7B can''t be merged with 70B

          So yeah, not, it will not work haha


          As for creating bigger model from smaller one, you can use 2 different fine-tune,
          or do a big one from the two same, and fine-tune on top. '
        updatedAt: '2023-11-26T10:24:36.410Z'
      numEdits: 1
      reactions: []
    id: 65631cc17ff2e1b1cfb6f6e0
    type: comment
  author: Undi95
  content: 'Mistral can''t be merged with Llama2

    7B can''t be merged with 70B

    So yeah, not, it will not work haha


    As for creating bigger model from smaller one, you can use 2 different fine-tune,
    or do a big one from the two same, and fine-tune on top. '
  created_at: 2023-11-26 10:24:01+00:00
  edited: true
  hidden: false
  id: 65631cc17ff2e1b1cfb6f6e0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
      fullname: Lawliet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aslawliet
      type: user
    createdAt: '2023-11-26T10:25:02.000Z'
    data:
      edited: true
      editors:
      - aslawliet
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9901297688484192
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
          fullname: Lawliet
          isHf: false
          isPro: false
          name: aslawliet
          type: user
        html: '<blockquote>

          <p>Mistral can''t be merged with Llama2<br>7B can''t be merged with 70B<br>So
          yeah, not, it will not work haha</p>

          </blockquote>

          <p>I didn''t merge, i simply added 16 attention heads</p>

          '
        raw: '> Mistral can''t be merged with Llama2

          > 7B can''t be merged with 70B

          > So yeah, not, it will not work haha


          I didn''t merge, i simply added 16 attention heads'
        updatedAt: '2023-11-26T10:28:44.571Z'
      numEdits: 1
      reactions: []
    id: 65631cfead639c6ab9d18cde
    type: comment
  author: aslawliet
  content: '> Mistral can''t be merged with Llama2

    > 7B can''t be merged with 70B

    > So yeah, not, it will not work haha


    I didn''t merge, i simply added 16 attention heads'
  created_at: 2023-11-26 10:25:02+00:00
  edited: true
  hidden: false
  id: 65631cfead639c6ab9d18cde
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
      fullname: Lawliet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aslawliet
      type: user
    createdAt: '2023-11-26T10:26:11.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
          fullname: Lawliet
          isHf: false
          isPro: false
          name: aslawliet
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-11-26T10:26:42.919Z'
      numEdits: 0
      reactions: []
    id: 65631d43516893ddeba7739d
    type: comment
  author: aslawliet
  content: This comment has been hidden
  created_at: 2023-11-26 10:26:11+00:00
  edited: true
  hidden: true
  id: 65631d43516893ddeba7739d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
      fullname: Lawliet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aslawliet
      type: user
    createdAt: '2023-11-26T10:26:11.000Z'
    data:
      status: closed
    id: 65631d43516893ddeba7739e
    type: status-change
  author: aslawliet
  created_at: 2023-11-26 10:26:11+00:00
  id: 65631d43516893ddeba7739e
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
      fullname: Lawliet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aslawliet
      type: user
    createdAt: '2023-11-26T10:26:15.000Z'
    data:
      status: open
    id: 65631d4778f6dd8d83b0b5d9
    type: status-change
  author: aslawliet
  created_at: 2023-11-26 10:26:15+00:00
  id: 65631d4778f6dd8d83b0b5d9
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
      fullname: Lawliet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aslawliet
      type: user
    createdAt: '2023-11-26T10:27:57.000Z'
    data:
      edited: false
      editors:
      - aslawliet
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9304388761520386
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
          fullname: Lawliet
          isHf: false
          isPro: false
          name: aslawliet
          type: user
        html: '<blockquote>

          <p>Mistral can''t be merged with Llama2<br>7B can''t be merged with 70B<br>So
          yeah, not, it will not work haha</p>

          <p>As for creating bigger model from smaller one, you can use 2 different
          fine-tune, or do a big one from the two same, and fine-tune on top.</p>

          </blockquote>

          <p>I guess mistral 7b and llama 2 13b uses the exact same tokenizer, from
          that perspective, addition of attention heads from llama to mistral can
          be done I guess</p>

          '
        raw: "> Mistral can't be merged with Llama2\n> 7B can't be merged with 70B\n\
          > So yeah, not, it will not work haha\n> \n> As for creating bigger model\
          \ from smaller one, you can use 2 different fine-tune, or do a big one from\
          \ the two same, and fine-tune on top.\n\nI guess mistral 7b and llama 2\
          \ 13b uses the exact same tokenizer, from that perspective, addition of\
          \ attention heads from llama to mistral can be done I guess"
        updatedAt: '2023-11-26T10:27:57.957Z'
      numEdits: 0
      reactions: []
    id: 65631dad30a88a2f1df08cc7
    type: comment
  author: aslawliet
  content: "> Mistral can't be merged with Llama2\n> 7B can't be merged with 70B\n\
    > So yeah, not, it will not work haha\n> \n> As for creating bigger model from\
    \ smaller one, you can use 2 different fine-tune, or do a big one from the two\
    \ same, and fine-tune on top.\n\nI guess mistral 7b and llama 2 13b uses the exact\
    \ same tokenizer, from that perspective, addition of attention heads from llama\
    \ to mistral can be done I guess"
  created_at: 2023-11-26 10:27:57+00:00
  edited: false
  hidden: false
  id: 65631dad30a88a2f1df08cc7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
      fullname: Lawliet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aslawliet
      type: user
    createdAt: '2023-11-26T10:39:45.000Z'
    data:
      edited: false
      editors:
      - aslawliet
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8606095314025879
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
          fullname: Lawliet
          isHf: false
          isPro: false
          name: aslawliet
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Undi95&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Undi95\">@<span class=\"\
          underline\">Undi95</span></a></span>\n\n\t</span></span> please do reply\
          \ to it \U0001F604</p>\n"
        raw: "@Undi95 please do reply to it \U0001F604"
        updatedAt: '2023-11-26T10:39:45.839Z'
      numEdits: 0
      reactions: []
    id: 6563207130a88a2f1df0e16d
    type: comment
  author: aslawliet
  content: "@Undi95 please do reply to it \U0001F604"
  created_at: 2023-11-26 10:39:45+00:00
  edited: false
  hidden: false
  id: 6563207130a88a2f1df0e16d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
      fullname: Undi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Undi95
      type: user
    createdAt: '2023-11-26T10:42:22.000Z'
    data:
      edited: false
      editors:
      - Undi95
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8928911089897156
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
          fullname: Undi
          isHf: false
          isPro: false
          name: Undi95
          type: user
        html: '<p>Layers size of Mistral and Llama2 aren''t the same, you can''t.<br>You
          can try tho, nobody stop you haha</p>

          '
        raw: 'Layers size of Mistral and Llama2 aren''t the same, you can''t.

          You can try tho, nobody stop you haha'
        updatedAt: '2023-11-26T10:42:22.531Z'
      numEdits: 0
      reactions: []
    id: 6563210eed2bca599ecc7326
    type: comment
  author: Undi95
  content: 'Layers size of Mistral and Llama2 aren''t the same, you can''t.

    You can try tho, nobody stop you haha'
  created_at: 2023-11-26 10:42:22+00:00
  edited: false
  hidden: false
  id: 6563210eed2bca599ecc7326
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
      fullname: Lawliet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aslawliet
      type: user
    createdAt: '2023-11-26T10:46:04.000Z'
    data:
      edited: false
      editors:
      - aslawliet
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9413270354270935
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
          fullname: Lawliet
          isHf: false
          isPro: false
          name: aslawliet
          type: user
        html: '<blockquote>

          <p>Layers size of Mistral and Llama2 aren''t the same, you can''t.<br>You
          can try tho, nobody stop you haha</p>

          </blockquote>

          <p>I was not merging layers, I am actually added few query heads from llama
          2 13b to mistral 7b, means actually I increased the hidden_size and num_attention_heads
          of Mistral, rest intermediate_size, num_key_value_heads and num_layers were
          kept the same</p>

          '
        raw: '> Layers size of Mistral and Llama2 aren''t the same, you can''t.

          > You can try tho, nobody stop you haha


          I was not merging layers, I am actually added few query heads from llama
          2 13b to mistral 7b, means actually I increased the hidden_size and num_attention_heads
          of Mistral, rest intermediate_size, num_key_value_heads and num_layers were
          kept the same'
        updatedAt: '2023-11-26T10:46:04.555Z'
      numEdits: 0
      reactions: []
    id: 656321ecb9218ed1a78de45f
    type: comment
  author: aslawliet
  content: '> Layers size of Mistral and Llama2 aren''t the same, you can''t.

    > You can try tho, nobody stop you haha


    I was not merging layers, I am actually added few query heads from llama 2 13b
    to mistral 7b, means actually I increased the hidden_size and num_attention_heads
    of Mistral, rest intermediate_size, num_key_value_heads and num_layers were kept
    the same'
  created_at: 2023-11-26 10:46:04+00:00
  edited: false
  hidden: false
  id: 656321ecb9218ed1a78de45f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
      fullname: Lawliet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aslawliet
      type: user
    createdAt: '2023-11-26T10:48:05.000Z'
    data:
      edited: false
      editors:
      - aslawliet
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4066801965236664
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
          fullname: Lawliet
          isHf: false
          isPro: false
          name: aslawliet
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Undi95&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Undi95\">@<span class=\"\
          underline\">Undi95</span></a></span>\n\n\t</span></span> for your reference\
          \ this was the outcome model's config -</p>\n<pre><code class=\"language-python\"\
          >{\n  <span class=\"hljs-string\">\"architectures\"</span>: [\n    <span\
          \ class=\"hljs-string\">\"MistralForCausalLM\"</span>\n  ],\n  <span class=\"\
          hljs-string\">\"bos_token_id\"</span>: <span class=\"hljs-number\">1</span>,\n\
          \  <span class=\"hljs-string\">\"eos_token_id\"</span>: <span class=\"hljs-number\"\
          >2</span>,\n  <span class=\"hljs-string\">\"hidden_act\"</span>: <span class=\"\
          hljs-string\">\"silu\"</span>,\n  <span class=\"hljs-string\">\"hidden_size\"\
          </span>: <span class=\"hljs-number\">5120</span>,\n  <span class=\"hljs-string\"\
          >\"initializer_range\"</span>: <span class=\"hljs-number\">0.02</span>,\n\
          \  <span class=\"hljs-string\">\"intermediate_size\"</span>: <span class=\"\
          hljs-number\">14336</span>,\n  <span class=\"hljs-string\">\"max_position_embeddings\"\
          </span>: <span class=\"hljs-number\">32768</span>,\n  <span class=\"hljs-string\"\
          >\"model_type\"</span>: <span class=\"hljs-string\">\"mistral\"</span>,\n\
          \  <span class=\"hljs-string\">\"num_attention_heads\"</span>: <span class=\"\
          hljs-number\">40</span>,\n  <span class=\"hljs-string\">\"num_hidden_layers\"\
          </span>: <span class=\"hljs-number\">32</span>,\n  <span class=\"hljs-string\"\
          >\"num_key_value_heads\"</span>: <span class=\"hljs-number\">8</span>,\n\
          \  <span class=\"hljs-string\">\"rms_norm_eps\"</span>: <span class=\"hljs-number\"\
          >1e-05</span>,\n  <span class=\"hljs-string\">\"rope_theta\"</span>: <span\
          \ class=\"hljs-number\">10000.0</span>,\n  <span class=\"hljs-string\">\"\
          sliding_window\"</span>: <span class=\"hljs-number\">4096</span>,\n  <span\
          \ class=\"hljs-string\">\"tie_word_embeddings\"</span>: false,\n  <span\
          \ class=\"hljs-string\">\"torch_dtype\"</span>: <span class=\"hljs-string\"\
          >\"bfloat16\"</span>,\n  <span class=\"hljs-string\">\"transformers_version\"\
          </span>: <span class=\"hljs-string\">\"4.35.0\"</span>,\n  <span class=\"\
          hljs-string\">\"use_cache\"</span>: true,\n  <span class=\"hljs-string\"\
          >\"vocab_size\"</span>: <span class=\"hljs-number\">32000</span>\n}\n</code></pre>\n"
        raw: "@Undi95 for your reference this was the outcome model's config -\n```python\n\
          {\n  \"architectures\": [\n    \"MistralForCausalLM\"\n  ],\n  \"bos_token_id\"\
          : 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\"\
          : 5120,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n\
          \  \"max_position_embeddings\": 32768,\n  \"model_type\": \"mistral\",\n\
          \  \"num_attention_heads\": 40,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\"\
          : 8,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\"\
          : 4096,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\"\
          ,\n  \"transformers_version\": \"4.35.0\",\n  \"use_cache\": true,\n  \"\
          vocab_size\": 32000\n}\n```"
        updatedAt: '2023-11-26T10:48:05.783Z'
      numEdits: 0
      reactions: []
    id: 65632265b29be3f5b6df9345
    type: comment
  author: aslawliet
  content: "@Undi95 for your reference this was the outcome model's config -\n```python\n\
    {\n  \"architectures\": [\n    \"MistralForCausalLM\"\n  ],\n  \"bos_token_id\"\
    : 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\":\
    \ 5120,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"\
    max_position_embeddings\": 32768,\n  \"model_type\": \"mistral\",\n  \"num_attention_heads\"\
    : 40,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"rms_norm_eps\"\
    : 1e-05,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\": 4096,\n  \"tie_word_embeddings\"\
    : false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.35.0\"\
    ,\n  \"use_cache\": true,\n  \"vocab_size\": 32000\n}\n```"
  created_at: 2023-11-26 10:48:05+00:00
  edited: false
  hidden: false
  id: 65632265b29be3f5b6df9345
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
      fullname: Undi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Undi95
      type: user
    createdAt: '2023-11-26T11:07:37.000Z'
    data:
      edited: true
      editors:
      - Undi95
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7204618453979492
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
          fullname: Undi
          isHf: false
          isPro: false
          name: Undi95
          type: user
        html: '<p>I never done this unholy attempt hah!<br>Keep me updated if it work
          out of the box</p>

          '
        raw: 'I never done this unholy attempt hah!

          Keep me updated if it work out of the box'
        updatedAt: '2023-11-26T11:08:41.439Z'
      numEdits: 1
      reactions: []
    id: 656326f9e0a7720b6a3260e2
    type: comment
  author: Undi95
  content: 'I never done this unholy attempt hah!

    Keep me updated if it work out of the box'
  created_at: 2023-11-26 11:07:37+00:00
  edited: true
  hidden: false
  id: 656326f9e0a7720b6a3260e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
      fullname: Lawliet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aslawliet
      type: user
    createdAt: '2023-11-26T11:09:59.000Z'
    data:
      edited: false
      editors:
      - aslawliet
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9475426077842712
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
          fullname: Lawliet
          isHf: false
          isPro: false
          name: aslawliet
          type: user
        html: '<blockquote>

          <p>I never doing this unholy attempt hah!<br>Keep me updated if it work
          out of the box</p>

          </blockquote>

          <p>It doesn''t work out of the box, I just wanted to know that does getting
          garbage output after adding attention heads from another model without fine
          tuning common? also another thing was to confirm that i guess mistral and
          llama uses the exact same tokenizer?</p>

          '
        raw: '> I never doing this unholy attempt hah!

          > Keep me updated if it work out of the box


          It doesn''t work out of the box, I just wanted to know that does getting
          garbage output after adding attention heads from another model without fine
          tuning common? also another thing was to confirm that i guess mistral and
          llama uses the exact same tokenizer?'
        updatedAt: '2023-11-26T11:09:59.853Z'
      numEdits: 0
      reactions: []
    id: 65632787a72f05d2eabd7d14
    type: comment
  author: aslawliet
  content: '> I never doing this unholy attempt hah!

    > Keep me updated if it work out of the box


    It doesn''t work out of the box, I just wanted to know that does getting garbage
    output after adding attention heads from another model without fine tuning common?
    also another thing was to confirm that i guess mistral and llama uses the exact
    same tokenizer?'
  created_at: 2023-11-26 11:09:59+00:00
  edited: false
  hidden: false
  id: 65632787a72f05d2eabd7d14
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
      fullname: Undi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Undi95
      type: user
    createdAt: '2023-11-26T11:20:07.000Z'
    data:
      edited: false
      editors:
      - Undi95
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9526574611663818
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
          fullname: Undi
          isHf: false
          isPro: false
          name: Undi95
          type: user
        html: '<blockquote>

          <blockquote>

          <p>I never doing this unholy attempt hah!<br>Keep me updated if it work
          out of the box</p>

          </blockquote>

          <p>It doesn''t work out of the box, I just wanted to know that does getting
          garbage output after adding attention heads from another model without fine
          tuning common? also another thing was to confirm that i guess mistral and
          llama uses the exact same tokenizer?</p>

          </blockquote>

          <p>I don''t know for the first question, never done that<br>Comparing the
          two tokenizer there is some differences tho<br>You ask me things I don''t
          have answers for hahaha, i''m sorry</p>

          '
        raw: "> > I never doing this unholy attempt hah!\n> > Keep me updated if it\
          \ work out of the box\n> \n> It doesn't work out of the box, I just wanted\
          \ to know that does getting garbage output after adding attention heads\
          \ from another model without fine tuning common? also another thing was\
          \ to confirm that i guess mistral and llama uses the exact same tokenizer?\n\
          \nI don't know for the first question, never done that\nComparing the two\
          \ tokenizer there is some differences tho\nYou ask me things I don't have\
          \ answers for hahaha, i'm sorry"
        updatedAt: '2023-11-26T11:20:07.367Z'
      numEdits: 0
      reactions: []
    id: 656329e784a9fbe322f64875
    type: comment
  author: Undi95
  content: "> > I never doing this unholy attempt hah!\n> > Keep me updated if it\
    \ work out of the box\n> \n> It doesn't work out of the box, I just wanted to\
    \ know that does getting garbage output after adding attention heads from another\
    \ model without fine tuning common? also another thing was to confirm that i guess\
    \ mistral and llama uses the exact same tokenizer?\n\nI don't know for the first\
    \ question, never done that\nComparing the two tokenizer there is some differences\
    \ tho\nYou ask me things I don't have answers for hahaha, i'm sorry"
  created_at: 2023-11-26 11:20:07+00:00
  edited: false
  hidden: false
  id: 656329e784a9fbe322f64875
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
      fullname: Lawliet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aslawliet
      type: user
    createdAt: '2023-11-26T11:21:14.000Z'
    data:
      edited: false
      editors:
      - aslawliet
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9711719155311584
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
          fullname: Lawliet
          isHf: false
          isPro: false
          name: aslawliet
          type: user
        html: "<p>Its okay, I really appreciate your active responses \U0001F60A </p>\n"
        raw: "Its okay, I really appreciate your active responses \U0001F60A "
        updatedAt: '2023-11-26T11:21:14.184Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65632a2a7bdd1b1612b3e610
    id: 65632a2a7bdd1b1612b3e60f
    type: comment
  author: aslawliet
  content: "Its okay, I really appreciate your active responses \U0001F60A "
  created_at: 2023-11-26 11:21:14+00:00
  edited: false
  hidden: false
  id: 65632a2a7bdd1b1612b3e60f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6551e98b7490049d62631325/MVLPiAaRD4MB4d0rNXsw1.jpeg?w=200&h=200&f=face
      fullname: Lawliet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aslawliet
      type: user
    createdAt: '2023-11-26T11:21:14.000Z'
    data:
      status: closed
    id: 65632a2a7bdd1b1612b3e610
    type: status-change
  author: aslawliet
  created_at: 2023-11-26 11:21:14+00:00
  id: 65632a2a7bdd1b1612b3e610
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Undi95/Mistral-11B-v0.1
repo_type: model
status: closed
target_branch: null
title: "Please Reply \U0001F604"
