!!python/object:huggingface_hub.community.DiscussionWithDetails
author: eschmidbauer
conflicting_files: null
created_at: 2023-10-09 13:30:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cfac6bd0b30496b064d5092831e65f3e.svg
      fullname: Emmanuel Schmidbauer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eschmidbauer
      type: user
    createdAt: '2023-10-09T14:30:59.000Z'
    data:
      edited: false
      editors:
      - eschmidbauer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5522266030311584
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cfac6bd0b30496b064d5092831e65f3e.svg
          fullname: Emmanuel Schmidbauer
          isHf: false
          isPro: false
          name: eschmidbauer
          type: user
        html: "<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/61571d3bb8d28825f709ffc2/ieHEYFnk0kChvE6pfckFq.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/61571d3bb8d28825f709ffc2/ieHEYFnk0kChvE6pfckFq.png\"\
          ></a></p>\n<pre><code>&gt;&gt;&gt;\n&gt;&gt;&gt; from transformers import\
          \ AutoProcessor, AutoModelForSpeechSeq2Seq\n&gt;&gt;&gt;\n&gt;&gt;&gt; processor\
          \ = AutoProcessor.from_pretrained(\"Intel/whisper-base-onnx-int4\")\nmodel\
          \ = AutoModelForSpeechSeq2Seq.from_pretrained(\"Intel/whisper-base-onnx-int4\"\
          )\nSpecial tokens have been added in the vocabulary, make sure the associated\
          \ word embeddings are fine-tuned or trained.\n&gt;&gt;&gt; model = AutoModelForSpeechSeq2Seq.from_pretrained(\"\
          Intel/whisper-base-onnx-int4\")\nTraceback (most recent call last):\n  File\
          \ \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"python3.11/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 565, in from_pretrained\n    return model_class.from_pretrained(\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"python3.11/site-packages/transformers/modeling_utils.py\"\
          , line 2972, in from_pretrained\n    raise EnvironmentError(\nOSError: Intel/whisper-base-onnx-int4\
          \ does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt\
          \ or flax_model.msgpack.\n</code></pre>\n"
        raw: "\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/61571d3bb8d28825f709ffc2/ieHEYFnk0kChvE6pfckFq.png)\r\
          \n\r\n\r\n```\r\n>>>\r\n>>> from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\r\
          \n>>>\r\n>>> processor = AutoProcessor.from_pretrained(\"Intel/whisper-base-onnx-int4\"\
          )\r\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\"Intel/whisper-base-onnx-int4\"\
          )\r\nSpecial tokens have been added in the vocabulary, make sure the associated\
          \ word embeddings are fine-tuned or trained.\r\n>>> model = AutoModelForSpeechSeq2Seq.from_pretrained(\"\
          Intel/whisper-base-onnx-int4\")\r\nTraceback (most recent call last):\r\n\
          \  File \"<stdin>\", line 1, in <module>\r\n  File \"python3.11/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 565, in from_pretrained\r\n    return model_class.from_pretrained(\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"python3.11/site-packages/transformers/modeling_utils.py\"\
          , line 2972, in from_pretrained\r\n    raise EnvironmentError(\r\nOSError:\
          \ Intel/whisper-base-onnx-int4 does not appear to have a file named pytorch_model.bin,\
          \ tf_model.h5, model.ckpt or flax_model.msgpack.\r\n```"
        updatedAt: '2023-10-09T14:30:59.956Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - sergey-antonov
    id: 65240ea366ebe051985a6e60
    type: comment
  author: eschmidbauer
  content: "\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/61571d3bb8d28825f709ffc2/ieHEYFnk0kChvE6pfckFq.png)\r\
    \n\r\n\r\n```\r\n>>>\r\n>>> from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\r\
    \n>>>\r\n>>> processor = AutoProcessor.from_pretrained(\"Intel/whisper-base-onnx-int4\"\
    )\r\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\"Intel/whisper-base-onnx-int4\"\
    )\r\nSpecial tokens have been added in the vocabulary, make sure the associated\
    \ word embeddings are fine-tuned or trained.\r\n>>> model = AutoModelForSpeechSeq2Seq.from_pretrained(\"\
    Intel/whisper-base-onnx-int4\")\r\nTraceback (most recent call last):\r\n  File\
    \ \"<stdin>\", line 1, in <module>\r\n  File \"python3.11/site-packages/transformers/models/auto/auto_factory.py\"\
    , line 565, in from_pretrained\r\n    return model_class.from_pretrained(\r\n\
    \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"python3.11/site-packages/transformers/modeling_utils.py\"\
    , line 2972, in from_pretrained\r\n    raise EnvironmentError(\r\nOSError: Intel/whisper-base-onnx-int4\
    \ does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt\
    \ or flax_model.msgpack.\r\n```"
  created_at: 2023-10-09 13:30:59+00:00
  edited: false
  hidden: false
  id: 65240ea366ebe051985a6e60
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/893de2472d88478c6e1b1307d2a5fdd9.svg
      fullname: Wang, Mengni
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: MengniWang
      type: user
    createdAt: '2023-10-16T08:02:13.000Z'
    data:
      edited: false
      editors:
      - MengniWang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9247872829437256
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/893de2472d88478c6e1b1307d2a5fdd9.svg
          fullname: Wang, Mengni
          isHf: false
          isPro: false
          name: MengniWang
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;eschmidbauer&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/eschmidbauer\"\
          >@<span class=\"underline\">eschmidbauer</span></a></span>\n\n\t</span></span>\
          \ , that's because transformers's API doesn't support onnx model inference\
          \ yet.</p>\n"
        raw: Hi @eschmidbauer , that's because transformers's API doesn't support
          onnx model inference yet.
        updatedAt: '2023-10-16T08:02:13.613Z'
      numEdits: 0
      reactions: []
    id: 652cee05f120598322ae3e68
    type: comment
  author: MengniWang
  content: Hi @eschmidbauer , that's because transformers's API doesn't support onnx
    model inference yet.
  created_at: 2023-10-16 07:02:13+00:00
  edited: false
  hidden: false
  id: 652cee05f120598322ae3e68
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Intel/whisper-base-onnx-int4
repo_type: model
status: open
target_branch: null
title: example inference does not work
