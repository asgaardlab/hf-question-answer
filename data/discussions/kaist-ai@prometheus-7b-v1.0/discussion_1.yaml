!!python/object:huggingface_hub.community.DiscussionWithDetails
author: alvarobartt
conflicting_files: null
created_at: 2023-12-18 09:49:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60f0608166e5701b80ed3f02/ZSIRRZgthYnTinV1wGE1N.jpeg?w=200&h=200&f=face
      fullname: Alvaro Bartolome
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alvarobartt
      type: user
    createdAt: '2023-12-18T09:49:21.000Z'
    data:
      edited: true
      editors:
      - alvarobartt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9759965538978577
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60f0608166e5701b80ed3f02/ZSIRRZgthYnTinV1wGE1N.jpeg?w=200&h=200&f=face
          fullname: Alvaro Bartolome
          isHf: false
          isPro: false
          name: alvarobartt
          type: user
        html: "<p>Hi here \U0001F917 </p>\n<p>I was just wondering why the model size\
          \ is the same as a 13B model while it only being 6.7B (~7B)?</p>\n<p>Edit:\
          \ is it because you uploaded the 7b model in fp32 instead of fp16 instead?\
          \ Kudos to <span data-props=\"{&quot;user&quot;:&quot;gabrielmbmb&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/gabrielmbmb\"\
          >@<span class=\"underline\">gabrielmbmb</span></a></span>\n\n\t</span></span>\
          \ for suggesting that could be the issue</p>\n"
        raw: "Hi here \U0001F917 \n\nI was just wondering why the model size is the\
          \ same as a 13B model while it only being 6.7B (~7B)?\n\nEdit: is it because\
          \ you uploaded the 7b model in fp32 instead of fp16 instead? Kudos to @gabrielmbmb\
          \ for suggesting that could be the issue"
        updatedAt: '2023-12-18T10:40:05.511Z'
      numEdits: 3
      reactions: []
    id: 658015a13d586b460a52d7c5
    type: comment
  author: alvarobartt
  content: "Hi here \U0001F917 \n\nI was just wondering why the model size is the\
    \ same as a 13B model while it only being 6.7B (~7B)?\n\nEdit: is it because you\
    \ uploaded the 7b model in fp32 instead of fp16 instead? Kudos to @gabrielmbmb\
    \ for suggesting that could be the issue"
  created_at: 2023-12-18 09:49:21+00:00
  edited: true
  hidden: false
  id: 658015a13d586b460a52d7c5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: kaist-ai/prometheus-7b-v1.0
repo_type: model
status: open
target_branch: null
title: Why is the model size the same as a 13B one?
