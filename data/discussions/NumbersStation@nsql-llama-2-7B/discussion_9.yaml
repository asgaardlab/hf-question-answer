!!python/object:huggingface_hub.community.DiscussionWithDetails
author: baasitsh
conflicting_files: null
created_at: 2023-09-08 00:08:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/23dce55b32120be8d9144e7bbbfc8823.svg
      fullname: Baasit Sharief
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: baasitsh
      type: user
    createdAt: '2023-09-08T01:08:45.000Z'
    data:
      edited: true
      editors:
      - baasitsh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9533188343048096
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/23dce55b32120be8d9144e7bbbfc8823.svg
          fullname: Baasit Sharief
          isHf: false
          isPro: false
          name: baasitsh
          type: user
        html: '<p>Hi,</p>

          <p>I''ve been trying to reproduce the results as shown in the blog but I
          haven''t been able to get any close to the scores mentioned based on the
          official test-suite for sql-eval(<a rel="nofollow" href="https://github.com/taoyds/test-suite-sql-eval">https://github.com/taoyds/test-suite-sql-eval</a>),
          to my surprise when I went to look at the results on the Spider dev set,
          it seemed like the model had around 190 response incomplete and the score
          coming as 0.509 for execution, instead of 0.75.</p>

          <p>So, I wanted to know if I''m doing anything wrong. Currently, I''m simply
          using model.generate without any extra parameters except max_length of 500
          passed (Greedy Search). Are there any generation parameters I need to look
          at or is there any evaluation scripts open-sourced that I can make use of?</p>

          <p>Thanks in advance. </p>

          '
        raw: 'Hi,


          I''ve been trying to reproduce the results as shown in the blog but I haven''t
          been able to get any close to the scores mentioned based on the official
          test-suite for sql-eval(https://github.com/taoyds/test-suite-sql-eval),
          to my surprise when I went to look at the results on the Spider dev set,
          it seemed like the model had around 190 response incomplete and the score
          coming as 0.509 for execution, instead of 0.75.


          So, I wanted to know if I''m doing anything wrong. Currently, I''m simply
          using model.generate without any extra parameters except max_length of 500
          passed (Greedy Search). Are there any generation parameters I need to look
          at or is there any evaluation scripts open-sourced that I can make use of?


          Thanks in advance. '
        updatedAt: '2023-09-08T16:25:13.098Z'
      numEdits: 1
      reactions: []
    id: 64fa741d84bf01577e3e12f1
    type: comment
  author: baasitsh
  content: 'Hi,


    I''ve been trying to reproduce the results as shown in the blog but I haven''t
    been able to get any close to the scores mentioned based on the official test-suite
    for sql-eval(https://github.com/taoyds/test-suite-sql-eval), to my surprise when
    I went to look at the results on the Spider dev set, it seemed like the model
    had around 190 response incomplete and the score coming as 0.509 for execution,
    instead of 0.75.


    So, I wanted to know if I''m doing anything wrong. Currently, I''m simply using
    model.generate without any extra parameters except max_length of 500 passed (Greedy
    Search). Are there any generation parameters I need to look at or is there any
    evaluation scripts open-sourced that I can make use of?


    Thanks in advance. '
  created_at: 2023-09-08 00:08:45+00:00
  edited: true
  hidden: false
  id: 64fa741d84bf01577e3e12f1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-09-09T01:17:14.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6663923263549805
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: '<p>Please use <code>torch.float16</code> or <code>torch.bfloat16</code>
          and set max_new_tokens greater than 300 tokens. The incomplete response
          might be because 1) different dtype 2) not enough max_new_token. </p>

          '
        raw: 'Please use `torch.float16` or `torch.bfloat16` and set max_new_tokens
          greater than 300 tokens. The incomplete response might be because 1) different
          dtype 2) not enough max_new_token. '
        updatedAt: '2023-09-09T01:17:14.443Z'
      numEdits: 0
      reactions: []
    id: 64fbc79a9a62bb2791b1d630
    type: comment
  author: senwu
  content: 'Please use `torch.float16` or `torch.bfloat16` and set max_new_tokens
    greater than 300 tokens. The incomplete response might be because 1) different
    dtype 2) not enough max_new_token. '
  created_at: 2023-09-09 00:17:14+00:00
  edited: false
  hidden: false
  id: 64fbc79a9a62bb2791b1d630
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9a7a6163a786ce71bd3fdf32d7285409.svg
      fullname: David M.
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: djm2131
      type: user
    createdAt: '2023-12-01T20:48:14.000Z'
    data:
      edited: false
      editors:
      - djm2131
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9800844788551331
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9a7a6163a786ce71bd3fdf32d7285409.svg
          fullname: David M.
          isHf: false
          isPro: false
          name: djm2131
          type: user
        html: '<p>For what it''s worth, I had the same experience of trying to reproduce
          the reported Spider benchmark scores and finding that the score I got was
          much lower than advertised. </p>

          <p>There are some examples in their github repo, but I still found low scores
          even after being careful to follow the examples exactly: <a rel="nofollow"
          href="https://github.com/NumbersStationAI/NSQL/tree/main/examples">https://github.com/NumbersStationAI/NSQL/tree/main/examples</a>.</p>

          '
        raw: "For what it's worth, I had the same experience of trying to reproduce\
          \ the reported Spider benchmark scores and finding that the score I got\
          \ was much lower than advertised. \n\nThere are some examples in their github\
          \ repo, but I still found low scores even after being careful to follow\
          \ the examples exactly: https://github.com/NumbersStationAI/NSQL/tree/main/examples."
        updatedAt: '2023-12-01T20:48:14.029Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - baasitsh
    id: 656a468efe7fe0b1e99268e2
    type: comment
  author: djm2131
  content: "For what it's worth, I had the same experience of trying to reproduce\
    \ the reported Spider benchmark scores and finding that the score I got was much\
    \ lower than advertised. \n\nThere are some examples in their github repo, but\
    \ I still found low scores even after being careful to follow the examples exactly:\
    \ https://github.com/NumbersStationAI/NSQL/tree/main/examples."
  created_at: 2023-12-01 20:48:14+00:00
  edited: false
  hidden: false
  id: 656a468efe7fe0b1e99268e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/23dce55b32120be8d9144e7bbbfc8823.svg
      fullname: Baasit Sharief
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: baasitsh
      type: user
    createdAt: '2023-12-01T20:52:32.000Z'
    data:
      edited: false
      editors:
      - baasitsh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9738878607749939
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/23dce55b32120be8d9144e7bbbfc8823.svg
          fullname: Baasit Sharief
          isHf: false
          isPro: false
          name: baasitsh
          type: user
        html: "<blockquote>\n<p>For what it's worth, I had the same experience of\
          \ trying to reproduce the reported Spider benchmark scores and finding that\
          \ the score I got was much lower than advertised.</p>\n</blockquote>\n<p><span\
          \ data-props=\"{&quot;user&quot;:&quot;djm2131&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/djm2131\">@<span class=\"underline\"\
          >djm2131</span></a></span>\n\n\t</span></span> I remember facing the same\
          \ issue even after setting the <code>dtype</code> to <code>torch.bfloat16</code>\
          \ and <code>max_new_tokens</code> to 400. I got somewhere around 0.647.</p>\n"
        raw: '>For what it''s worth, I had the same experience of trying to reproduce
          the reported Spider benchmark scores and finding that the score I got was
          much lower than advertised.


          @djm2131 I remember facing the same issue even after setting the `dtype`
          to `torch.bfloat16` and `max_new_tokens` to 400. I got somewhere around
          0.647.'
        updatedAt: '2023-12-01T20:52:32.861Z'
      numEdits: 0
      reactions: []
    id: 656a47900bbc114fe6b9647f
    type: comment
  author: baasitsh
  content: '>For what it''s worth, I had the same experience of trying to reproduce
    the reported Spider benchmark scores and finding that the score I got was much
    lower than advertised.


    @djm2131 I remember facing the same issue even after setting the `dtype` to `torch.bfloat16`
    and `max_new_tokens` to 400. I got somewhere around 0.647.'
  created_at: 2023-12-01 20:52:32+00:00
  edited: false
  hidden: false
  id: 656a47900bbc114fe6b9647f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-12-06T01:21:10.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8755452632904053
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: '<p>Thanks for your interest in our work!</p>

          <p>Here are three things:</p>

          <ol>

          <li>The model works best with <code>torch.bfloat16</code>.</li>

          <li>Please give enough <code>max_new_token</code> such as 500.</li>

          <li>Please use the code from the <a rel="nofollow" href="https://github.com/taoyds/spider">official
          github</a> and the database schema from the dataset instead of the database
          schema.</li>

          </ol>

          <p>Please let us know if you still have issues.</p>

          '
        raw: "Thanks for your interest in our work!\n\nHere are three things:\n1.\
          \ The model works best with `torch.bfloat16`.\n2. Please give enough `max_new_token`\
          \ such as 500.\n3. Please use the code from the [official github](https://github.com/taoyds/spider)\
          \ and the database schema from the dataset instead of the database schema.\
          \ \n\nPlease let us know if you still have issues."
        updatedAt: '2023-12-06T01:21:10.798Z'
      numEdits: 0
      reactions: []
    id: 656fcc86b4ebaeb855d30f38
    type: comment
  author: senwu
  content: "Thanks for your interest in our work!\n\nHere are three things:\n1. The\
    \ model works best with `torch.bfloat16`.\n2. Please give enough `max_new_token`\
    \ such as 500.\n3. Please use the code from the [official github](https://github.com/taoyds/spider)\
    \ and the database schema from the dataset instead of the database schema. \n\n\
    Please let us know if you still have issues."
  created_at: 2023-12-06 01:21:10+00:00
  edited: false
  hidden: false
  id: 656fcc86b4ebaeb855d30f38
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: NumbersStation/nsql-llama-2-7B
repo_type: model
status: open
target_branch: null
title: Reproducing Spider Eval scores
