!!python/object:huggingface_hub.community.DiscussionWithDetails
author: baconnier
conflicting_files: null
created_at: 2023-09-08 07:27:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6220ecdb10b98c6b47152042/1stnYOunoPQHSCr8gtpNh.png?w=200&h=200&f=face
      fullname: baconnier loic
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: baconnier
      type: user
    createdAt: '2023-09-08T08:27:09.000Z'
    data:
      edited: false
      editors:
      - baconnier
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7942076325416565
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6220ecdb10b98c6b47152042/1stnYOunoPQHSCr8gtpNh.png?w=200&h=200&f=face
          fullname: baconnier loic
          isHf: false
          isPro: false
          name: baconnier
          type: user
        html: '<p>Hi di you plan to make a quantized version or the result will not
          be accurate ?</p>

          '
        raw: Hi di you plan to make a quantized version or the result will not be
          accurate ?
        updatedAt: '2023-09-08T08:27:09.853Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - IshaanShettigar
    id: 64fadadd010f41e4351f5ce6
    type: comment
  author: baconnier
  content: Hi di you plan to make a quantized version or the result will not be accurate
    ?
  created_at: 2023-09-08 07:27:09+00:00
  edited: false
  hidden: false
  id: 64fadadd010f41e4351f5ce6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-09-09T01:13:58.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9041275978088379
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: '<p>That''s on our todo list. Please stay tuned! :)</p>

          '
        raw: That's on our todo list. Please stay tuned! :)
        updatedAt: '2023-09-09T01:13:58.086Z'
      numEdits: 0
      reactions: []
    id: 64fbc6d6fa644654227a987f
    type: comment
  author: senwu
  content: That's on our todo list. Please stay tuned! :)
  created_at: 2023-09-09 00:13:58+00:00
  edited: false
  hidden: false
  id: 64fbc6d6fa644654227a987f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/218ecce022bc03d44f9fffff150ac13f.svg
      fullname: Ishaan Shettigar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: IshaanShettigar
      type: user
    createdAt: '2023-09-19T07:48:44.000Z'
    data:
      edited: false
      editors:
      - IshaanShettigar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9041063785552979
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/218ecce022bc03d44f9fffff150ac13f.svg
          fullname: Ishaan Shettigar
          isHf: false
          isPro: false
          name: IshaanShettigar
          type: user
        html: '<p>Currently we can''t run it on a free tier colab notebook. It gives
          me RAM limit exceeded. So we''d love a quantized version.<br>Any idea if
          this works on the pro tier? and what might be the RAM and VRAM requirements
          to run this?</p>

          '
        raw: 'Currently we can''t run it on a free tier colab notebook. It gives me
          RAM limit exceeded. So we''d love a quantized version.

          Any idea if this works on the pro tier? and what might be the RAM and VRAM
          requirements to run this?'
        updatedAt: '2023-09-19T07:48:44.123Z'
      numEdits: 0
      reactions: []
    id: 6509525cf99720fea127ddd0
    type: comment
  author: IshaanShettigar
  content: 'Currently we can''t run it on a free tier colab notebook. It gives me
    RAM limit exceeded. So we''d love a quantized version.

    Any idea if this works on the pro tier? and what might be the RAM and VRAM requirements
    to run this?'
  created_at: 2023-09-19 06:48:44+00:00
  edited: false
  hidden: false
  id: 6509525cf99720fea127ddd0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ff5fc4fe6383d50b29052e/Vk9R5rKqG-Z_ou-55J9x-.jpeg?w=200&h=200&f=face
      fullname: AayushShah
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AayushShah
      type: user
    createdAt: '2023-10-30T06:07:58.000Z'
    data:
      edited: false
      editors:
      - AayushShah
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8243848085403442
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ff5fc4fe6383d50b29052e/Vk9R5rKqG-Z_ou-55J9x-.jpeg?w=200&h=200&f=face
          fullname: AayushShah
          isHf: false
          isPro: false
          name: AayushShah
          type: user
        html: "<p>Any possibility of this model in the GGUF format? Like available\
          \ in the Bloke's repositories?<br>Or... will I need to convert it manually?</p>\n\
          <p>Please share any link if you guys find one.<br>Alternatively I am opening\
          \ a separate discussion on this project for the same.</p>\n<p>\U0001F37B\
          </p>\n"
        raw: "Any possibility of this model in the GGUF format? Like available in\
          \ the Bloke's repositories?\nOr... will I need to convert it manually?\n\
          \nPlease share any link if you guys find one.\nAlternatively I am opening\
          \ a separate discussion on this project for the same.\n\n\U0001F37B"
        updatedAt: '2023-10-30T06:07:58.166Z'
      numEdits: 0
      reactions: []
    id: 653f483e89f7466f2cd36633
    type: comment
  author: AayushShah
  content: "Any possibility of this model in the GGUF format? Like available in the\
    \ Bloke's repositories?\nOr... will I need to convert it manually?\n\nPlease share\
    \ any link if you guys find one.\nAlternatively I am opening a separate discussion\
    \ on this project for the same.\n\n\U0001F37B"
  created_at: 2023-10-30 05:07:58+00:00
  edited: false
  hidden: false
  id: 653f483e89f7466f2cd36633
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/59be2e242ca294a0bc14d2ce426ec330.svg
      fullname: feng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: flymonk
      type: user
    createdAt: '2023-10-30T06:18:55.000Z'
    data:
      edited: false
      editors:
      - flymonk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3765541613101959
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/59be2e242ca294a0bc14d2ce426ec330.svg
          fullname: feng
          isHf: false
          isPro: false
          name: flymonk
          type: user
        html: '<p>You can use convert tool from llama.cpp to build gguf format.</p>

          '
        raw: You can use convert tool from llama.cpp to build gguf format.
        updatedAt: '2023-10-30T06:18:55.432Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - AayushShah
    id: 653f4acfc2307cc448aa194f
    type: comment
  author: flymonk
  content: You can use convert tool from llama.cpp to build gguf format.
  created_at: 2023-10-30 05:18:55+00:00
  edited: false
  hidden: false
  id: 653f4acfc2307cc448aa194f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ff5fc4fe6383d50b29052e/Vk9R5rKqG-Z_ou-55J9x-.jpeg?w=200&h=200&f=face
      fullname: AayushShah
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AayushShah
      type: user
    createdAt: '2023-10-30T06:19:39.000Z'
    data:
      edited: false
      editors:
      - AayushShah
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9288829565048218
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ff5fc4fe6383d50b29052e/Vk9R5rKqG-Z_ou-55J9x-.jpeg?w=200&h=200&f=face
          fullname: AayushShah
          isHf: false
          isPro: false
          name: AayushShah
          type: user
        html: '<p>Yeah of course, thanks </p>

          '
        raw: 'Yeah of course, thanks '
        updatedAt: '2023-10-30T06:19:39.993Z'
      numEdits: 0
      reactions: []
    id: 653f4afb885338b0110c4e77
    type: comment
  author: AayushShah
  content: 'Yeah of course, thanks '
  created_at: 2023-10-30 05:19:39+00:00
  edited: false
  hidden: false
  id: 653f4afb885338b0110c4e77
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: NumbersStation/nsql-llama-2-7B
repo_type: model
status: open
target_branch: null
title: Quantize version
