!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Aiforfun
conflicting_files: null
created_at: 2023-08-10 16:45:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
      fullname: Amit Kumar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aiforfun
      type: user
    createdAt: '2023-08-10T17:45:19.000Z'
    data:
      edited: false
      editors:
      - Aiforfun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6072744131088257
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
          fullname: Amit Kumar
          isHf: false
          isPro: false
          name: Aiforfun
          type: user
        html: '<p>So far i am pretty satisfy with accuracy of the model but one thing
          is annoying me is, prompt &amp; schema part of model output.<br>What if
          my schema is huge around 250 columns?<br>Output is:<br>CREATE TABLE stadium
          (<br>    stadium_id number,<br>    location text,<br>    name text,<br>    capacity
          number,<br>    highest number,<br>    lowest number,<br>    average number<br>)</p>

          <p>CREATE TABLE singer (<br>    singer_id number,<br>    name text,<br>    country
          text,<br>    song_name text,<br>    song_release_year text,<br>    age number,<br>    is_male
          others<br>)</p>

          <p>CREATE TABLE concert (<br>    concert_id number,<br>    concert_name
          text,<br>    theme text,<br>    stadium_id text,<br>    year text<br>)</p>

          <p>CREATE TABLE singer_in_concert (<br>    concert_id number,<br>    singer_id
          text<br>)</p>

          <p>-- Using valid SQLite, answer the following questions for the tables
          provided above.</p>

          <p>-- What is the maximum, the average, and the minimum capacity of stadiums
          ?</p>

          <p>SELECT MAX(capacity), AVG(capacity), MIN(capacity) FROM stadium<br>Expected
          output is:<br>only generated sql query SELECT MAX(capacity), AVG(capacity),
          MIN(capacity) FROM stadium<br>How can i get only sql query to be generated?</p>

          '
        raw: "So far i am pretty satisfy with accuracy of the model but one thing\
          \ is annoying me is, prompt & schema part of model output.\r\nWhat if my\
          \ schema is huge around 250 columns?\r\nOutput is:\r\nCREATE TABLE stadium\
          \ (\r\n    stadium_id number,\r\n    location text,\r\n    name text,\r\n\
          \    capacity number,\r\n    highest number,\r\n    lowest number,\r\n \
          \   average number\r\n)\r\n\r\nCREATE TABLE singer (\r\n    singer_id number,\r\
          \n    name text,\r\n    country text,\r\n    song_name text,\r\n    song_release_year\
          \ text,\r\n    age number,\r\n    is_male others\r\n)\r\n\r\nCREATE TABLE\
          \ concert (\r\n    concert_id number,\r\n    concert_name text,\r\n    theme\
          \ text,\r\n    stadium_id text,\r\n    year text\r\n)\r\n\r\nCREATE TABLE\
          \ singer_in_concert (\r\n    concert_id number,\r\n    singer_id text\r\n\
          )\r\n\r\n-- Using valid SQLite, answer the following questions for the tables\
          \ provided above.\r\n\r\n-- What is the maximum, the average, and the minimum\
          \ capacity of stadiums ?\r\n\r\nSELECT MAX(capacity), AVG(capacity), MIN(capacity)\
          \ FROM stadium\r\nExpected output is:\r\nonly generated sql query SELECT\
          \ MAX(capacity), AVG(capacity), MIN(capacity) FROM stadium\r\nHow can i\
          \ get only sql query to be generated?"
        updatedAt: '2023-08-10T17:45:19.458Z'
      numEdits: 0
      reactions: []
    id: 64d5222f3be3c57959836660
    type: comment
  author: Aiforfun
  content: "So far i am pretty satisfy with accuracy of the model but one thing is\
    \ annoying me is, prompt & schema part of model output.\r\nWhat if my schema is\
    \ huge around 250 columns?\r\nOutput is:\r\nCREATE TABLE stadium (\r\n    stadium_id\
    \ number,\r\n    location text,\r\n    name text,\r\n    capacity number,\r\n\
    \    highest number,\r\n    lowest number,\r\n    average number\r\n)\r\n\r\n\
    CREATE TABLE singer (\r\n    singer_id number,\r\n    name text,\r\n    country\
    \ text,\r\n    song_name text,\r\n    song_release_year text,\r\n    age number,\r\
    \n    is_male others\r\n)\r\n\r\nCREATE TABLE concert (\r\n    concert_id number,\r\
    \n    concert_name text,\r\n    theme text,\r\n    stadium_id text,\r\n    year\
    \ text\r\n)\r\n\r\nCREATE TABLE singer_in_concert (\r\n    concert_id number,\r\
    \n    singer_id text\r\n)\r\n\r\n-- Using valid SQLite, answer the following questions\
    \ for the tables provided above.\r\n\r\n-- What is the maximum, the average, and\
    \ the minimum capacity of stadiums ?\r\n\r\nSELECT MAX(capacity), AVG(capacity),\
    \ MIN(capacity) FROM stadium\r\nExpected output is:\r\nonly generated sql query\
    \ SELECT MAX(capacity), AVG(capacity), MIN(capacity) FROM stadium\r\nHow can i\
    \ get only sql query to be generated?"
  created_at: 2023-08-10 16:45:19+00:00
  edited: false
  hidden: false
  id: 64d5222f3be3c57959836660
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-08-10T18:32:08.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8887410759925842
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;Aiforfun&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Aiforfun\"\
          >@<span class=\"underline\">Aiforfun</span></a></span>\n\n\t</span></span>\
          \ ,</p>\n<p>Thanks for your interest in our work. We've also provided several\
          \ examples of using our model in the real world and how only to get the\
          \ generated SQL. Please check here: <a rel=\"nofollow\" href=\"https://github.com/NumbersStationAI/NSQL/tree/main/examples\"\
          >https://github.com/NumbersStationAI/NSQL/tree/main/examples</a></p>\n"
        raw: 'Hi @Aiforfun ,


          Thanks for your interest in our work. We''ve also provided several examples
          of using our model in the real world and how only to get the generated SQL.
          Please check here: https://github.com/NumbersStationAI/NSQL/tree/main/examples'
        updatedAt: '2023-08-10T18:32:08.345Z'
      numEdits: 0
      reactions: []
    id: 64d52d285e5f05485ca77376
    type: comment
  author: senwu
  content: 'Hi @Aiforfun ,


    Thanks for your interest in our work. We''ve also provided several examples of
    using our model in the real world and how only to get the generated SQL. Please
    check here: https://github.com/NumbersStationAI/NSQL/tree/main/examples'
  created_at: 2023-08-10 17:32:08+00:00
  edited: false
  hidden: false
  id: 64d52d285e5f05485ca77376
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
      fullname: Amit Kumar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aiforfun
      type: user
    createdAt: '2023-08-11T12:08:22.000Z'
    data:
      edited: false
      editors:
      - Aiforfun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.859748363494873
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
          fullname: Amit Kumar
          isHf: false
          isPro: false
          name: Aiforfun
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;senwu&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/senwu\">@<span class=\"\
          underline\">senwu</span></a></span>\n\n\t</span></span> ,<br>Thanks for\
          \ the reply.<br>My query was more related to DB schema e.g. if i have more\
          \ than 100 DB tables and providing the schema for all those tables makes\
          \ prompt very huge and model takes very long time to generate the query\
          \ and model.generate(input_ids, max_length=600) function returns very huge\
          \ token which are related to DB schema. Then striping out all the schema\
          \ from output to print only generated SQL.<br>Other llms don't generated\
          \ the given prompt back in fact they generate only SQL, so is there any\
          \ option to generate only SQL not the given prompt?<br>Is there any better\
          \ way to give the schema for larger DB tables considering more than 100\
          \ bigger tables?</p>\n"
        raw: 'Hi @senwu ,

          Thanks for the reply.

          My query was more related to DB schema e.g. if i have more than 100 DB tables
          and providing the schema for all those tables makes prompt very huge and
          model takes very long time to generate the query and model.generate(input_ids,
          max_length=600) function returns very huge token which are related to DB
          schema. Then striping out all the schema from output to print only generated
          SQL.

          Other llms don''t generated the given prompt back in fact they generate
          only SQL, so is there any option to generate only SQL not the given prompt?

          Is there any better way to give the schema for larger DB tables considering
          more than 100 bigger tables?'
        updatedAt: '2023-08-11T12:08:22.891Z'
      numEdits: 0
      reactions: []
    id: 64d624b6d7e30889c662ea43
    type: comment
  author: Aiforfun
  content: 'Hi @senwu ,

    Thanks for the reply.

    My query was more related to DB schema e.g. if i have more than 100 DB tables
    and providing the schema for all those tables makes prompt very huge and model
    takes very long time to generate the query and model.generate(input_ids, max_length=600)
    function returns very huge token which are related to DB schema. Then striping
    out all the schema from output to print only generated SQL.

    Other llms don''t generated the given prompt back in fact they generate only SQL,
    so is there any option to generate only SQL not the given prompt?

    Is there any better way to give the schema for larger DB tables considering more
    than 100 bigger tables?'
  created_at: 2023-08-11 11:08:22+00:00
  edited: false
  hidden: false
  id: 64d624b6d7e30889c662ea43
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-08-11T16:19:19.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6335757374763489
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;Aiforfun&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Aiforfun\"\
          >@<span class=\"underline\">Aiforfun</span></a></span>\n\n\t</span></span>\
          \ ,</p>\n<p>The input sequence length will affect the model generation time.\
          \ A longer input sequence will take a longer time for the model to generate\
          \ output assuming the output sequence has the same/similar length. Other\
          \ CausalLM-based FM will also return the original input back as the prefix\
          \ of the generated sequence but you can control the max token length for\
          \ the newly generated output and you can also only print the newly generated\
          \ output by filtering out the original input sequence. Here is an example:</p>\n\
          <pre><code>import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\
          tokenizer = AutoTokenizer.from_pretrained(\"NumbersStation/nsql-llama-2-7B\"\
          )\nmodel = AutoModelForCausalLM.from_pretrained(\"NumbersStation/nsql-llama-2-7B\"\
          , torch_dtype=torch.bfloat16)\n\ntext = \"\"\"CREATE TABLE stadium (\n \
          \   stadium_id number,\n    location text,\n    name text,\n    capacity\
          \ number,\n)\n\n-- Using valid SQLite, answer the following questions for\
          \ the tables provided above.\n\n-- how many stadiums in total?\n\nSELECT\"\
          \"\"\n\ninput_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n\n\
          # generated_ids = model.generate(input_ids, max_length=500)\ngenerated_ids\
          \ = model.generate(input_ids, max_new_tokens=500) # &lt;---- use max_new_tokens\
          \ to control the maximum number of tokens to generate, ignoring the number\
          \ of tokens in the prompt.\n# print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n\
          print(tokenizer.decode(generated_ids[0][len(input_ids[0]):], skip_special_tokens=True))\
          \ # &lt;---- filter out the input sequence\n</code></pre>\n"
        raw: "Hi @Aiforfun ,\n\nThe input sequence length will affect the model generation\
          \ time. A longer input sequence will take a longer time for the model to\
          \ generate output assuming the output sequence has the same/similar length.\
          \ Other CausalLM-based FM will also return the original input back as the\
          \ prefix of the generated sequence but you can control the max token length\
          \ for the newly generated output and you can also only print the newly generated\
          \ output by filtering out the original input sequence. Here is an example:\n\
          \n```\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\
          tokenizer = AutoTokenizer.from_pretrained(\"NumbersStation/nsql-llama-2-7B\"\
          )\nmodel = AutoModelForCausalLM.from_pretrained(\"NumbersStation/nsql-llama-2-7B\"\
          , torch_dtype=torch.bfloat16)\n\ntext = \"\"\"CREATE TABLE stadium (\n \
          \   stadium_id number,\n    location text,\n    name text,\n    capacity\
          \ number,\n)\n\n-- Using valid SQLite, answer the following questions for\
          \ the tables provided above.\n\n-- how many stadiums in total?\n\nSELECT\"\
          \"\"\n\ninput_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n\n\
          # generated_ids = model.generate(input_ids, max_length=500)\ngenerated_ids\
          \ = model.generate(input_ids, max_new_tokens=500) # <---- use max_new_tokens\
          \ to control the maximum number of tokens to generate, ignoring the number\
          \ of tokens in the prompt.\n# print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n\
          print(tokenizer.decode(generated_ids[0][len(input_ids[0]):], skip_special_tokens=True))\
          \ # <---- filter out the input sequence\n```"
        updatedAt: '2023-08-11T16:19:19.539Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Aiforfun
    id: 64d65f87089bc502ce9cda0b
    type: comment
  author: senwu
  content: "Hi @Aiforfun ,\n\nThe input sequence length will affect the model generation\
    \ time. A longer input sequence will take a longer time for the model to generate\
    \ output assuming the output sequence has the same/similar length. Other CausalLM-based\
    \ FM will also return the original input back as the prefix of the generated sequence\
    \ but you can control the max token length for the newly generated output and\
    \ you can also only print the newly generated output by filtering out the original\
    \ input sequence. Here is an example:\n\n```\nimport torch\nfrom transformers\
    \ import AutoTokenizer, AutoModelForCausalLM\ntokenizer = AutoTokenizer.from_pretrained(\"\
    NumbersStation/nsql-llama-2-7B\")\nmodel = AutoModelForCausalLM.from_pretrained(\"\
    NumbersStation/nsql-llama-2-7B\", torch_dtype=torch.bfloat16)\n\ntext = \"\"\"\
    CREATE TABLE stadium (\n    stadium_id number,\n    location text,\n    name text,\n\
    \    capacity number,\n)\n\n-- Using valid SQLite, answer the following questions\
    \ for the tables provided above.\n\n-- how many stadiums in total?\n\nSELECT\"\
    \"\"\n\ninput_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n\n# generated_ids\
    \ = model.generate(input_ids, max_length=500)\ngenerated_ids = model.generate(input_ids,\
    \ max_new_tokens=500) # <---- use max_new_tokens to control the maximum number\
    \ of tokens to generate, ignoring the number of tokens in the prompt.\n# print(tokenizer.decode(generated_ids[0],\
    \ skip_special_tokens=True))\nprint(tokenizer.decode(generated_ids[0][len(input_ids[0]):],\
    \ skip_special_tokens=True)) # <---- filter out the input sequence\n```"
  created_at: 2023-08-11 15:19:19+00:00
  edited: false
  hidden: false
  id: 64d65f87089bc502ce9cda0b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
      fullname: Amit Kumar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aiforfun
      type: user
    createdAt: '2023-08-11T17:33:50.000Z'
    data:
      edited: false
      editors:
      - Aiforfun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9446346163749695
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
          fullname: Amit Kumar
          isHf: false
          isPro: false
          name: Aiforfun
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;senwu&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/senwu\">@<span class=\"\
          underline\">senwu</span></a></span>\n\n\t</span></span> ,<br>Awesome, this\
          \ is what i was looking for. Much appreciated for your prompt response.<br>I\
          \ have another issue since i have more than 100 DB tables and model requires\
          \ tables schema provided in prompt, hence prompt becomes very huge for all\
          \ 100 DB tables' schema.<br>I am trying with prompt chunking but facing\
          \ some issues to make it working, so can you please guide me how to do it\
          \ chunking for very large prompt with NumbersStation/nsql-llama-2-7B model\
          \ or any other better approach to handle very large prompt?</p>\n"
        raw: 'Hi @senwu ,

          Awesome, this is what i was looking for. Much appreciated for your prompt
          response.

          I have another issue since i have more than 100 DB tables and model requires
          tables schema provided in prompt, hence prompt becomes very huge for all
          100 DB tables'' schema.

          I am trying with prompt chunking but facing some issues to make it working,
          so can you please guide me how to do it chunking for very large prompt with
          NumbersStation/nsql-llama-2-7B model or any other better approach to handle
          very large prompt?'
        updatedAt: '2023-08-11T17:33:50.154Z'
      numEdits: 0
      reactions: []
    id: 64d670febcab729cb4aadf1d
    type: comment
  author: Aiforfun
  content: 'Hi @senwu ,

    Awesome, this is what i was looking for. Much appreciated for your prompt response.

    I have another issue since i have more than 100 DB tables and model requires tables
    schema provided in prompt, hence prompt becomes very huge for all 100 DB tables''
    schema.

    I am trying with prompt chunking but facing some issues to make it working, so
    can you please guide me how to do it chunking for very large prompt with NumbersStation/nsql-llama-2-7B
    model or any other better approach to handle very large prompt?'
  created_at: 2023-08-11 16:33:50+00:00
  edited: false
  hidden: false
  id: 64d670febcab729cb4aadf1d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-08-11T18:52:38.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8226822018623352
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: '<p>The NumbersStation/nsql-llama-2-7B model supports context length
          4K so you need to fit your prompt within that restriction. In practice,
          we recommend filtering out irrelevant tables and columns with some retrival
          mechanism to make the prompt fit into the model. Hope it helps.</p>

          '
        raw: The NumbersStation/nsql-llama-2-7B model supports context length 4K so
          you need to fit your prompt within that restriction. In practice, we recommend
          filtering out irrelevant tables and columns with some retrival mechanism
          to make the prompt fit into the model. Hope it helps.
        updatedAt: '2023-08-11T18:52:38.236Z'
      numEdits: 0
      reactions: []
    id: 64d683768f84a7738d8888e7
    type: comment
  author: senwu
  content: The NumbersStation/nsql-llama-2-7B model supports context length 4K so
    you need to fit your prompt within that restriction. In practice, we recommend
    filtering out irrelevant tables and columns with some retrival mechanism to make
    the prompt fit into the model. Hope it helps.
  created_at: 2023-08-11 17:52:38+00:00
  edited: false
  hidden: false
  id: 64d683768f84a7738d8888e7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
      fullname: Amit Kumar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aiforfun
      type: user
    createdAt: '2023-08-14T08:06:28.000Z'
    data:
      edited: false
      editors:
      - Aiforfun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8371087312698364
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
          fullname: Amit Kumar
          isHf: false
          isPro: false
          name: Aiforfun
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;senwu&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/senwu\"\
          >@<span class=\"underline\">senwu</span></a></span>\n\n\t</span></span>\
          \ ,<br>Thanks for the clarification.<br>Could you please guide or any pointer\
          \ here for \"we recommend filtering out irrelevant tables and columns with\
          \ some retrieval mechanism to make the prompt fit into the model\"?<br>How\
          \ can we do it?</p>\n"
        raw: 'Hello @senwu ,

          Thanks for the clarification.

          Could you please guide or any pointer here for "we recommend filtering out
          irrelevant tables and columns with some retrieval mechanism to make the
          prompt fit into the model"?

          How can we do it?'
        updatedAt: '2023-08-14T08:06:28.946Z'
      numEdits: 0
      reactions: []
    id: 64d9e0842668b3a368515ec3
    type: comment
  author: Aiforfun
  content: 'Hello @senwu ,

    Thanks for the clarification.

    Could you please guide or any pointer here for "we recommend filtering out irrelevant
    tables and columns with some retrieval mechanism to make the prompt fit into the
    model"?

    How can we do it?'
  created_at: 2023-08-14 07:06:28+00:00
  edited: false
  hidden: false
  id: 64d9e0842668b3a368515ec3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-08-14T17:23:31.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9459546804428101
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: '<p>One option is to encode the table/column with sentence_transformers
          and filter them by the similarity score.</p>

          '
        raw: One option is to encode the table/column with sentence_transformers and
          filter them by the similarity score.
        updatedAt: '2023-08-14T17:23:31.065Z'
      numEdits: 0
      reactions: []
    id: 64da6313ff83b3386a213788
    type: comment
  author: senwu
  content: One option is to encode the table/column with sentence_transformers and
    filter them by the similarity score.
  created_at: 2023-08-14 16:23:31+00:00
  edited: false
  hidden: false
  id: 64da6313ff83b3386a213788
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
      fullname: Amit Kumar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aiforfun
      type: user
    createdAt: '2023-08-17T09:01:16.000Z'
    data:
      edited: false
      editors:
      - Aiforfun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8840944766998291
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
          fullname: Amit Kumar
          isHf: false
          isPro: false
          name: Aiforfun
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;senwu&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/senwu\"\
          >@<span class=\"underline\">senwu</span></a></span>\n\n\t</span></span>\
          \ ,<br>Thanks for the pointer.<br>What is the right format of prompt for\
          \ few shot learning on NumbersStation/nsql-llama-2-7B model?<br>It is not\
          \ providing in model card.</p>\n"
        raw: 'Hello @senwu ,

          Thanks for the pointer.

          What is the right format of prompt for few shot learning on NumbersStation/nsql-llama-2-7B
          model?

          It is not providing in model card.'
        updatedAt: '2023-08-17T09:01:16.889Z'
      numEdits: 0
      reactions: []
    id: 64dde1dcae450641ed96acc0
    type: comment
  author: Aiforfun
  content: 'Hello @senwu ,

    Thanks for the pointer.

    What is the right format of prompt for few shot learning on NumbersStation/nsql-llama-2-7B
    model?

    It is not providing in model card.'
  created_at: 2023-08-17 08:01:16+00:00
  edited: false
  hidden: false
  id: 64dde1dcae450641ed96acc0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-08-17T17:17:13.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9433450102806091
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: '<p>This particular model is intended for the 0-shot scenario, which
          is the most common real-world use case. If you''re conducting experiments
          and wish to include demonstrations from the same database, you can add several
          question/SQL pairs at the end. If you have any suggestions on how to enable
          multi-database demonstrations, please let us know, and we''ll try to incorporate
          them in the next release.</p>

          '
        raw: This particular model is intended for the 0-shot scenario, which is the
          most common real-world use case. If you're conducting experiments and wish
          to include demonstrations from the same database, you can add several question/SQL
          pairs at the end. If you have any suggestions on how to enable multi-database
          demonstrations, please let us know, and we'll try to incorporate them in
          the next release.
        updatedAt: '2023-08-17T17:17:13.017Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - abicz
    id: 64de561956731bec621ba76a
    type: comment
  author: senwu
  content: This particular model is intended for the 0-shot scenario, which is the
    most common real-world use case. If you're conducting experiments and wish to
    include demonstrations from the same database, you can add several question/SQL
    pairs at the end. If you have any suggestions on how to enable multi-database
    demonstrations, please let us know, and we'll try to incorporate them in the next
    release.
  created_at: 2023-08-17 16:17:13+00:00
  edited: false
  hidden: false
  id: 64de561956731bec621ba76a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f88e7782dc63c076e527adb4b18d1d35.svg
      fullname: Nivetha Balasubramanian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nivetha1012
      type: user
    createdAt: '2023-08-17T17:25:59.000Z'
    data:
      edited: false
      editors:
      - Nivetha1012
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9932037591934204
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f88e7782dc63c076e527adb4b18d1d35.svg
          fullname: Nivetha Balasubramanian
          isHf: false
          isPro: false
          name: Nivetha1012
          type: user
        html: '<p>Hi, will join queries work between tables, I tried but didn''t succeed</p>

          '
        raw: 'Hi, will join queries work between tables, I tried but didn''t succeed

          '
        updatedAt: '2023-08-17T17:25:59.309Z'
      numEdits: 0
      reactions: []
    id: 64de582775f5da105e7199c9
    type: comment
  author: Nivetha1012
  content: 'Hi, will join queries work between tables, I tried but didn''t succeed

    '
  created_at: 2023-08-17 16:25:59+00:00
  edited: false
  hidden: false
  id: 64de582775f5da105e7199c9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-08-18T00:13:28.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9127675294876099
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: '<p>Yes, the model supports joining over multiple tables. You could
          adjust the prompt to give the model more information.</p>

          '
        raw: Yes, the model supports joining over multiple tables. You could adjust
          the prompt to give the model more information.
        updatedAt: '2023-08-18T00:13:28.424Z'
      numEdits: 0
      reactions: []
    id: 64deb7a85a8a9efea8f2f2ab
    type: comment
  author: senwu
  content: Yes, the model supports joining over multiple tables. You could adjust
    the prompt to give the model more information.
  created_at: 2023-08-17 23:13:28+00:00
  edited: false
  hidden: false
  id: 64deb7a85a8a9efea8f2f2ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f88e7782dc63c076e527adb4b18d1d35.svg
      fullname: Nivetha Balasubramanian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nivetha1012
      type: user
    createdAt: '2023-08-18T00:28:44.000Z'
    data:
      edited: false
      editors:
      - Nivetha1012
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9611902832984924
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f88e7782dc63c076e527adb4b18d1d35.svg
          fullname: Nivetha Balasubramanian
          isHf: false
          isPro: false
          name: Nivetha1012
          type: user
        html: "<p>Thanks for your reply, can you please share any examples, when I\
          \ tried I wasn\u2019t able to make that work</p>\n"
        raw: "Thanks for your reply, can you please share any examples, when I tried\
          \ I wasn\u2019t able to make that work"
        updatedAt: '2023-08-18T00:28:44.997Z'
      numEdits: 0
      reactions: []
    id: 64debb3cb85d0ecac73cf716
    type: comment
  author: Nivetha1012
  content: "Thanks for your reply, can you please share any examples, when I tried\
    \ I wasn\u2019t able to make that work"
  created_at: 2023-08-17 23:28:44+00:00
  edited: false
  hidden: false
  id: 64debb3cb85d0ecac73cf716
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-08-18T01:21:51.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5703626275062561
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: "<p>Here is an example:</p>\n<pre><code>import torch\nfrom transformers\
          \ import AutoTokenizer, AutoModelForCausalLM\ntokenizer = AutoTokenizer.from_pretrained(\"\
          NumbersStation/nsql-llama-2-7B\")\nmodel = AutoModelForCausalLM.from_pretrained(\"\
          NumbersStation/nsql-llama-2-7B\", torch_dtype=torch.bfloat16)\n\ntext =\
          \ \"\"\"CREATE TABLE singer (\\n    singer_id number,\\n    name text,\\\
          n    birth_year number,\\n    net_worth_millions number,\\n    citizenship\
          \ text\\n)\\n\\nCREATE TABLE song (\\n    song_id number,\\n    title text,\\\
          n    singer_id number,\\n    sales number,\\n    highest_position number\\\
          n)\\n\\n\\n-- Using valid SQLite, answer the following questions for the\
          \ tables provided above.\\n\\n-- For each singer name, what is the total\
          \ sales for their songs?\\n\\nSELECT\"\"\"\n\ninput_ids = tokenizer(text,\
          \ return_tensors=\"pt\").input_ids\n\ngenerated_ids = model.generate(input_ids,\
          \ max_length=500)\nprint(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n\
          </code></pre>\n<p>The output would be something like this:</p>\n<pre><code>CREATE\
          \ TABLE singer (\n    singer_id number,\n    name text,\n    birth_year\
          \ number,\n    net_worth_millions number,\n    citizenship text\n)\n\nCREATE\
          \ TABLE song (\n    song_id number,\n    title text,\n    singer_id number,\n\
          \    sales number,\n    highest_position number\n)\n\n\n-- Using valid SQLite,\
          \ answer the following questions for the tables provided above.\n\n-- For\
          \ each singer name, what is the total sales for their songs?\n\nSELECT T2.name,\
          \ SUM(T1.sales) FROM song AS T1 JOIN singer AS T2 ON T1.singer_id = T2.singer_id\
          \ GROUP BY T2.name\n</code></pre>\n"
        raw: "Here is an example:\n\n```\nimport torch\nfrom transformers import AutoTokenizer,\
          \ AutoModelForCausalLM\ntokenizer = AutoTokenizer.from_pretrained(\"NumbersStation/nsql-llama-2-7B\"\
          )\nmodel = AutoModelForCausalLM.from_pretrained(\"NumbersStation/nsql-llama-2-7B\"\
          , torch_dtype=torch.bfloat16)\n\ntext = \"\"\"CREATE TABLE singer (\\n \
          \   singer_id number,\\n    name text,\\n    birth_year number,\\n    net_worth_millions\
          \ number,\\n    citizenship text\\n)\\n\\nCREATE TABLE song (\\n    song_id\
          \ number,\\n    title text,\\n    singer_id number,\\n    sales number,\\\
          n    highest_position number\\n)\\n\\n\\n-- Using valid SQLite, answer the\
          \ following questions for the tables provided above.\\n\\n-- For each singer\
          \ name, what is the total sales for their songs?\\n\\nSELECT\"\"\"\n\ninput_ids\
          \ = tokenizer(text, return_tensors=\"pt\").input_ids\n\ngenerated_ids =\
          \ model.generate(input_ids, max_length=500)\nprint(tokenizer.decode(generated_ids[0],\
          \ skip_special_tokens=True))\n```\n\nThe output would be something like\
          \ this:\n```\nCREATE TABLE singer (\n    singer_id number,\n    name text,\n\
          \    birth_year number,\n    net_worth_millions number,\n    citizenship\
          \ text\n)\n\nCREATE TABLE song (\n    song_id number,\n    title text,\n\
          \    singer_id number,\n    sales number,\n    highest_position number\n\
          )\n\n\n-- Using valid SQLite, answer the following questions for the tables\
          \ provided above.\n\n-- For each singer name, what is the total sales for\
          \ their songs?\n\nSELECT T2.name, SUM(T1.sales) FROM song AS T1 JOIN singer\
          \ AS T2 ON T1.singer_id = T2.singer_id GROUP BY T2.name\n```"
        updatedAt: '2023-08-18T01:21:51.075Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Nivetha1012
    id: 64dec7af60bbabf0d5a5c973
    type: comment
  author: senwu
  content: "Here is an example:\n\n```\nimport torch\nfrom transformers import AutoTokenizer,\
    \ AutoModelForCausalLM\ntokenizer = AutoTokenizer.from_pretrained(\"NumbersStation/nsql-llama-2-7B\"\
    )\nmodel = AutoModelForCausalLM.from_pretrained(\"NumbersStation/nsql-llama-2-7B\"\
    , torch_dtype=torch.bfloat16)\n\ntext = \"\"\"CREATE TABLE singer (\\n    singer_id\
    \ number,\\n    name text,\\n    birth_year number,\\n    net_worth_millions number,\\\
    n    citizenship text\\n)\\n\\nCREATE TABLE song (\\n    song_id number,\\n  \
    \  title text,\\n    singer_id number,\\n    sales number,\\n    highest_position\
    \ number\\n)\\n\\n\\n-- Using valid SQLite, answer the following questions for\
    \ the tables provided above.\\n\\n-- For each singer name, what is the total sales\
    \ for their songs?\\n\\nSELECT\"\"\"\n\ninput_ids = tokenizer(text, return_tensors=\"\
    pt\").input_ids\n\ngenerated_ids = model.generate(input_ids, max_length=500)\n\
    print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n```\n\nThe\
    \ output would be something like this:\n```\nCREATE TABLE singer (\n    singer_id\
    \ number,\n    name text,\n    birth_year number,\n    net_worth_millions number,\n\
    \    citizenship text\n)\n\nCREATE TABLE song (\n    song_id number,\n    title\
    \ text,\n    singer_id number,\n    sales number,\n    highest_position number\n\
    )\n\n\n-- Using valid SQLite, answer the following questions for the tables provided\
    \ above.\n\n-- For each singer name, what is the total sales for their songs?\n\
    \nSELECT T2.name, SUM(T1.sales) FROM song AS T1 JOIN singer AS T2 ON T1.singer_id\
    \ = T2.singer_id GROUP BY T2.name\n```"
  created_at: 2023-08-18 00:21:51+00:00
  edited: false
  hidden: false
  id: 64dec7af60bbabf0d5a5c973
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
      fullname: Amit Kumar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aiforfun
      type: user
    createdAt: '2023-08-25T09:32:30.000Z'
    data:
      edited: false
      editors:
      - Aiforfun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8502421379089355
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
          fullname: Amit Kumar
          isHf: false
          isPro: false
          name: Aiforfun
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;senwu&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/senwu\">@<span class=\"\
          underline\">senwu</span></a></span>\n\n\t</span></span> ,<br>I see model\
          \ is facing challenges to generate correct SQL queries if some short of\
          \ calculation is needed in SQL. I tried to generate SQL query which should\
          \ have calculated the ratio in where clause but ratio is not being calculated.<br>CREATE\
          \ TABLE work_order (<br>    id NUMBER,<br>    property_id NUMBER,<br>  \
          \  cost FLOAT,<br>    invoice_amount FLOAT,i<br>    entered_date DATE,<br>\
          \    due_date DATE,<br>    complete_date DATE,<br>    total_workorder NUMBER,<br>\
          \    completed_workorder Number<br>)</p>\n<p>CREATE TABLE property (<br>\
          \    id NUMBER,<br>    property_name TEXT,<br>    area FLOAT,<br>    owner_id\
          \ NUMBER,<br>    city TEXT,<br>    country TEXT<br>)</p>\n<p>CREATE TABLE\
          \ owner (<br>    id NUMBER,<br>    name TEXT,<br>    salary FLOAT<br>)</p>\n\
          <p>-- Using valid sqlite, answer the following questions for the tables\
          \ provided above.<br>-- find property id for which work order ratio is higher\
          \ than 2</p>\n<p>SELECT property_id FROM work_order GROUP BY property_id\
          \ HAVING COUNT(*) &gt; 2</p>\n<p>Correct SQL should be: SELECT property_id\
          \ FROM work_order WHERE (total_workorder - completed_workorder) / total_workorder\
          \ &gt; 2<br>Could you please help what is wrong and what should i do?</p>\n"
        raw: "Hi @senwu ,\nI see model is facing challenges to generate correct SQL\
          \ queries if some short of calculation is needed in SQL. I tried to generate\
          \ SQL query which should have calculated the ratio in where clause but ratio\
          \ is not being calculated.\nCREATE TABLE work_order (\n    id NUMBER,\n\
          \    property_id NUMBER,\n    cost FLOAT,\n    invoice_amount FLOAT,i\n\
          \    entered_date DATE,\n    due_date DATE,\n    complete_date DATE,\n \
          \   total_workorder NUMBER,\n    completed_workorder Number\n)\n\nCREATE\
          \ TABLE property (\n    id NUMBER,\n    property_name TEXT,\n    area FLOAT,\n\
          \    owner_id NUMBER,\n    city TEXT,\n    country TEXT\n)\n\nCREATE TABLE\
          \ owner (\n    id NUMBER,\n    name TEXT,\n    salary FLOAT\n)\n\n-- Using\
          \ valid sqlite, answer the following questions for the tables provided above.\n\
          -- find property id for which work order ratio is higher than 2\n\nSELECT\
          \ property_id FROM work_order GROUP BY property_id HAVING COUNT(*) > 2\n\
          \nCorrect SQL should be: SELECT property_id FROM work_order WHERE (total_workorder\
          \ - completed_workorder) / total_workorder > 2\nCould you please help what\
          \ is wrong and what should i do?"
        updatedAt: '2023-08-25T09:32:30.393Z'
      numEdits: 0
      reactions: []
    id: 64e8752ee690f7366ead4da5
    type: comment
  author: Aiforfun
  content: "Hi @senwu ,\nI see model is facing challenges to generate correct SQL\
    \ queries if some short of calculation is needed in SQL. I tried to generate SQL\
    \ query which should have calculated the ratio in where clause but ratio is not\
    \ being calculated.\nCREATE TABLE work_order (\n    id NUMBER,\n    property_id\
    \ NUMBER,\n    cost FLOAT,\n    invoice_amount FLOAT,i\n    entered_date DATE,\n\
    \    due_date DATE,\n    complete_date DATE,\n    total_workorder NUMBER,\n  \
    \  completed_workorder Number\n)\n\nCREATE TABLE property (\n    id NUMBER,\n\
    \    property_name TEXT,\n    area FLOAT,\n    owner_id NUMBER,\n    city TEXT,\n\
    \    country TEXT\n)\n\nCREATE TABLE owner (\n    id NUMBER,\n    name TEXT,\n\
    \    salary FLOAT\n)\n\n-- Using valid sqlite, answer the following questions\
    \ for the tables provided above.\n-- find property id for which work order ratio\
    \ is higher than 2\n\nSELECT property_id FROM work_order GROUP BY property_id\
    \ HAVING COUNT(*) > 2\n\nCorrect SQL should be: SELECT property_id FROM work_order\
    \ WHERE (total_workorder - completed_workorder) / total_workorder > 2\nCould you\
    \ please help what is wrong and what should i do?"
  created_at: 2023-08-25 08:32:30+00:00
  edited: false
  hidden: false
  id: 64e8752ee690f7366ead4da5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-08-25T17:53:11.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5850636959075928
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: "<p>Try this modified version?</p>\n<pre><code>import torch\nfrom transformers\
          \ import AutoTokenizer, AutoModelForCausalLM\ntokenizer = AutoTokenizer.from_pretrained(\"\
          NumbersStation/nsql-llama-2-7B\")\nmodel = AutoModelForCausalLM.from_pretrained(\"\
          NumbersStation/nsql-llama-2-7B\", torch_dtype=torch.bfloat16).to(0)\n\n\
          text = \"\"\"CREATE TABLE work_order (\n    id NUMBER,\n    property_id\
          \ NUMBER,\n    cost FLOAT,\n    invoice_amount FLOAT,\n    entered_date\
          \ DATE,\n    due_date DATE,\n    complete_date DATE,\n    total_workorder\
          \ NUMBER,\n    completed_workorder Number\n)\n\nCREATE TABLE property (\n\
          \    id NUMBER,\n    property_name TEXT,\n    area FLOAT,\n    owner_id\
          \ NUMBER,\n    city TEXT,\n    country TEXT\n)\n\nCREATE TABLE owner (\n\
          \    id NUMBER,\n    name TEXT,\n    salary FLOAT\n)\n\n-- Using valid SQLite,\
          \ answer the following questions for the tables provided above.\n\n-- find\
          \ property id for which completed work order ratio is lower than 98\n\"\"\
          \"\n\ninput_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(0)\n\
          \ngenerated_ids = model.generate(input_ids, max_length=500)\nprint(tokenizer.decode(generated_ids[0],\
          \ skip_special_tokens=True))\n</code></pre>\n<p>Output:</p>\n<pre><code>SELECT\
          \ property_id FROM work_order WHERE completed_workorder / total_workorder\
          \ &lt; 98\n</code></pre>\n"
        raw: "Try this modified version?\n\n```\nimport torch\nfrom transformers import\
          \ AutoTokenizer, AutoModelForCausalLM\ntokenizer = AutoTokenizer.from_pretrained(\"\
          NumbersStation/nsql-llama-2-7B\")\nmodel = AutoModelForCausalLM.from_pretrained(\"\
          NumbersStation/nsql-llama-2-7B\", torch_dtype=torch.bfloat16).to(0)\n\n\
          text = \"\"\"CREATE TABLE work_order (\n    id NUMBER,\n    property_id\
          \ NUMBER,\n    cost FLOAT,\n    invoice_amount FLOAT,\n    entered_date\
          \ DATE,\n    due_date DATE,\n    complete_date DATE,\n    total_workorder\
          \ NUMBER,\n    completed_workorder Number\n)\n\nCREATE TABLE property (\n\
          \    id NUMBER,\n    property_name TEXT,\n    area FLOAT,\n    owner_id\
          \ NUMBER,\n    city TEXT,\n    country TEXT\n)\n\nCREATE TABLE owner (\n\
          \    id NUMBER,\n    name TEXT,\n    salary FLOAT\n)\n\n-- Using valid SQLite,\
          \ answer the following questions for the tables provided above.\n\n-- find\
          \ property id for which completed work order ratio is lower than 98\n\"\"\
          \"\n\ninput_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(0)\n\
          \ngenerated_ids = model.generate(input_ids, max_length=500)\nprint(tokenizer.decode(generated_ids[0],\
          \ skip_special_tokens=True))\n```\n\nOutput:\n```\nSELECT property_id FROM\
          \ work_order WHERE completed_workorder / total_workorder < 98\n```"
        updatedAt: '2023-08-25T17:53:11.081Z'
      numEdits: 0
      reactions: []
    id: 64e8ea87bfb2aa06a412041e
    type: comment
  author: senwu
  content: "Try this modified version?\n\n```\nimport torch\nfrom transformers import\
    \ AutoTokenizer, AutoModelForCausalLM\ntokenizer = AutoTokenizer.from_pretrained(\"\
    NumbersStation/nsql-llama-2-7B\")\nmodel = AutoModelForCausalLM.from_pretrained(\"\
    NumbersStation/nsql-llama-2-7B\", torch_dtype=torch.bfloat16).to(0)\n\ntext =\
    \ \"\"\"CREATE TABLE work_order (\n    id NUMBER,\n    property_id NUMBER,\n \
    \   cost FLOAT,\n    invoice_amount FLOAT,\n    entered_date DATE,\n    due_date\
    \ DATE,\n    complete_date DATE,\n    total_workorder NUMBER,\n    completed_workorder\
    \ Number\n)\n\nCREATE TABLE property (\n    id NUMBER,\n    property_name TEXT,\n\
    \    area FLOAT,\n    owner_id NUMBER,\n    city TEXT,\n    country TEXT\n)\n\n\
    CREATE TABLE owner (\n    id NUMBER,\n    name TEXT,\n    salary FLOAT\n)\n\n\
    -- Using valid SQLite, answer the following questions for the tables provided\
    \ above.\n\n-- find property id for which completed work order ratio is lower\
    \ than 98\n\"\"\"\n\ninput_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(0)\n\
    \ngenerated_ids = model.generate(input_ids, max_length=500)\nprint(tokenizer.decode(generated_ids[0],\
    \ skip_special_tokens=True))\n```\n\nOutput:\n```\nSELECT property_id FROM work_order\
    \ WHERE completed_workorder / total_workorder < 98\n```"
  created_at: 2023-08-25 16:53:11+00:00
  edited: false
  hidden: false
  id: 64e8ea87bfb2aa06a412041e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
      fullname: Amit Kumar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aiforfun
      type: user
    createdAt: '2023-08-26T11:17:55.000Z'
    data:
      edited: false
      editors:
      - Aiforfun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8603057861328125
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
          fullname: Amit Kumar
          isHf: false
          isPro: false
          name: Aiforfun
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;senwu&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/senwu\">@<span class=\"\
          underline\">senwu</span></a></span>\n\n\t</span></span> ,<br>Sorry for the\
          \ confusion.<br>My question was --find property id for which non completed\
          \ work order ratio is higher than 2<br>So generated query should be SELECT\
          \ property_id FROM work_order WHERE (total_workorder - completed_workorder)\
          \ / total_workorder &gt; 2<br>But model generated query is SELECT property_id\
          \ FROM work_order WHERE completed_workorder / total_workorder &gt; 2</p>\n"
        raw: 'Hi @senwu ,

          Sorry for the confusion.

          My question was --find property id for which non completed work order ratio
          is higher than 2

          So generated query should be SELECT property_id FROM work_order WHERE (total_workorder
          - completed_workorder) / total_workorder > 2

          But model generated query is SELECT property_id FROM work_order WHERE completed_workorder
          / total_workorder > 2'
        updatedAt: '2023-08-26T11:17:55.747Z'
      numEdits: 0
      reactions: []
    id: 64e9df63d014af2062d9e6f7
    type: comment
  author: Aiforfun
  content: 'Hi @senwu ,

    Sorry for the confusion.

    My question was --find property id for which non completed work order ratio is
    higher than 2

    So generated query should be SELECT property_id FROM work_order WHERE (total_workorder
    - completed_workorder) / total_workorder > 2

    But model generated query is SELECT property_id FROM work_order WHERE completed_workorder
    / total_workorder > 2'
  created_at: 2023-08-26 10:17:55+00:00
  edited: false
  hidden: false
  id: 64e9df63d014af2062d9e6f7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-08-26T18:53:07.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8211730122566223
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;Aiforfun&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Aiforfun\"\
          >@<span class=\"underline\">Aiforfun</span></a></span>\n\n\t</span></span>\
          \ ,<br>After another look at your example, I think the issue is about the\
          \ schema since the work_order table is at the granularity of work order\
          \ which means each row is a work order. The <code>total_workorder NUMBER</code>\
          \ is measuring the total work orders for an entire property. Meanwhile the\
          \ <code>completed_workorder NUMBER</code> is a boolean over a single work\
          \ order. So these two attributes don\u2019t type check with the schema.\
          \ Instead, you can have an <code>is_completed_workorder NUMBER</code> to\
          \ indicate the work order status with the total worker attribute. Here is\
          \ the updated schema:</p>\n<pre><code>CREATE TABLE work_order (\n    id\
          \ NUMBER,\n    property_id NUMBER,\n    cost FLOAT,\n    invoice_amount\
          \ FLOAT,\n    entered_date DATE,\n    due_date DATE,\n    complete_date\
          \ DATE,\n    is_completed_workorder NUMBER\n)\nCREATE TABLE property (\n\
          \    id NUMBER,\n    property_name TEXT,\n    area FLOAT,\n    owner_id\
          \ NUMBER,\n    city TEXT,\n    country TEXT\n)\nCREATE TABLE owner (\n \
          \   id NUMBER,\n    name TEXT,\n    salary FLOAT\n)\n</code></pre>\n<p>And\
          \ for the question about <code>Give me the ratio of not completed to total\
          \ work orders</code>, the model outputs:</p>\n<pre><code>SELECT (SELECT\
          \ COUNT(*) FROM work_order WHERE is_completed_workorder = 0) / (SELECT COUNT(*)\
          \ FROM work_order)\n</code></pre>\n"
        raw: "Hi @Aiforfun ,\nAfter another look at your example, I think the issue\
          \ is about the schema since the work_order table is at the granularity of\
          \ work order which means each row is a work order. The `total_workorder\
          \ NUMBER` is measuring the total work orders for an entire property. Meanwhile\
          \ the `completed_workorder NUMBER` is a boolean over a single work order.\
          \ So these two attributes don\u2019t type check with the schema. Instead,\
          \ you can have an `is_completed_workorder NUMBER` to indicate the work order\
          \ status with the total worker attribute. Here is the updated schema:\n\
          ```\nCREATE TABLE work_order (\n    id NUMBER,\n    property_id NUMBER,\n\
          \    cost FLOAT,\n    invoice_amount FLOAT,\n    entered_date DATE,\n  \
          \  due_date DATE,\n    complete_date DATE,\n    is_completed_workorder NUMBER\n\
          )\nCREATE TABLE property (\n    id NUMBER,\n    property_name TEXT,\n  \
          \  area FLOAT,\n    owner_id NUMBER,\n    city TEXT,\n    country TEXT\n\
          )\nCREATE TABLE owner (\n    id NUMBER,\n    name TEXT,\n    salary FLOAT\n\
          )\n```\nAnd for the question about `Give me the ratio of not completed to\
          \ total work orders`, the model outputs:\n```\nSELECT (SELECT COUNT(*) FROM\
          \ work_order WHERE is_completed_workorder = 0) / (SELECT COUNT(*) FROM work_order)\n\
          ```"
        updatedAt: '2023-08-26T18:53:07.569Z'
      numEdits: 0
      reactions: []
    id: 64ea4a134b996ef709c9ce35
    type: comment
  author: senwu
  content: "Hi @Aiforfun ,\nAfter another look at your example, I think the issue\
    \ is about the schema since the work_order table is at the granularity of work\
    \ order which means each row is a work order. The `total_workorder NUMBER` is\
    \ measuring the total work orders for an entire property. Meanwhile the `completed_workorder\
    \ NUMBER` is a boolean over a single work order. So these two attributes don\u2019\
    t type check with the schema. Instead, you can have an `is_completed_workorder\
    \ NUMBER` to indicate the work order status with the total worker attribute. Here\
    \ is the updated schema:\n```\nCREATE TABLE work_order (\n    id NUMBER,\n   \
    \ property_id NUMBER,\n    cost FLOAT,\n    invoice_amount FLOAT,\n    entered_date\
    \ DATE,\n    due_date DATE,\n    complete_date DATE,\n    is_completed_workorder\
    \ NUMBER\n)\nCREATE TABLE property (\n    id NUMBER,\n    property_name TEXT,\n\
    \    area FLOAT,\n    owner_id NUMBER,\n    city TEXT,\n    country TEXT\n)\n\
    CREATE TABLE owner (\n    id NUMBER,\n    name TEXT,\n    salary FLOAT\n)\n```\n\
    And for the question about `Give me the ratio of not completed to total work orders`,\
    \ the model outputs:\n```\nSELECT (SELECT COUNT(*) FROM work_order WHERE is_completed_workorder\
    \ = 0) / (SELECT COUNT(*) FROM work_order)\n```"
  created_at: 2023-08-26 17:53:07+00:00
  edited: false
  hidden: false
  id: 64ea4a134b996ef709c9ce35
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
      fullname: Amit Kumar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aiforfun
      type: user
    createdAt: '2023-08-28T17:10:29.000Z'
    data:
      edited: false
      editors:
      - Aiforfun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8840468525886536
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d30565c770db8351da8729ecdb801941.svg
          fullname: Amit Kumar
          isHf: false
          isPro: false
          name: Aiforfun
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;senwu&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/senwu\">@<span class=\"\
          underline\">senwu</span></a></span>\n\n\t</span></span> ,<br>I want to train\
          \ NumbersStation/nsql-llama-2-7B on my own dataset so i have to prepare\
          \ my own dataset similar to the dataset you shared in github.</p>\n<p>So\
          \ what would be the right approach, pretrain and then fine tune or directly\
          \ fine tune as per fin tune notebook you shared in github?</p>\n<p>What\
          \ are all hyperparameters shall i consider in fine tuning to get best accuracy\
          \ in generation of sql?</p>\n"
        raw: 'Hi @senwu ,

          I want to train NumbersStation/nsql-llama-2-7B on my own dataset so i have
          to prepare my own dataset similar to the dataset you shared in github.


          So what would be the right approach, pretrain and then fine tune or directly
          fine tune as per fin tune notebook you shared in github?


          What are all hyperparameters shall i consider in fine tuning to get best
          accuracy in generation of sql?'
        updatedAt: '2023-08-28T17:10:29.984Z'
      numEdits: 0
      reactions: []
    id: 64ecd50585c5f714ce24c6bc
    type: comment
  author: Aiforfun
  content: 'Hi @senwu ,

    I want to train NumbersStation/nsql-llama-2-7B on my own dataset so i have to
    prepare my own dataset similar to the dataset you shared in github.


    So what would be the right approach, pretrain and then fine tune or directly fine
    tune as per fin tune notebook you shared in github?


    What are all hyperparameters shall i consider in fine tuning to get best accuracy
    in generation of sql?'
  created_at: 2023-08-28 16:10:29+00:00
  edited: false
  hidden: false
  id: 64ecd50585c5f714ce24c6bc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-08-28T20:26:35.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7446441650390625
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: '<p>You can directly fine-tune with your own instruct data for your
          own finetune. You can do full fine-tuning or do parameter-efficient fine-tuning
          (e.g., lora (<a rel="nofollow" href="https://github.com/NumbersStationAI/NSQL/blob/main/examples/finetune.ipynb">notebook</a>)).
          You probably need to turn the learning rate (for example 1e-5) and batch
          size based on your task.</p>

          '
        raw: You can directly fine-tune with your own instruct data for your own finetune.
          You can do full fine-tuning or do parameter-efficient fine-tuning (e.g.,
          lora ([notebook](https://github.com/NumbersStationAI/NSQL/blob/main/examples/finetune.ipynb))).
          You probably need to turn the learning rate (for example 1e-5) and batch
          size based on your task.
        updatedAt: '2023-08-28T20:26:35.141Z'
      numEdits: 0
      reactions: []
    id: 64ed02fb645d318187a3466c
    type: comment
  author: senwu
  content: You can directly fine-tune with your own instruct data for your own finetune.
    You can do full fine-tuning or do parameter-efficient fine-tuning (e.g., lora
    ([notebook](https://github.com/NumbersStationAI/NSQL/blob/main/examples/finetune.ipynb))).
    You probably need to turn the learning rate (for example 1e-5) and batch size
    based on your task.
  created_at: 2023-08-28 19:26:35+00:00
  edited: false
  hidden: false
  id: 64ed02fb645d318187a3466c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4f7804ccb83263cacd802f69fa76a90a.svg
      fullname: Robert Zheng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: skard
      type: user
    createdAt: '2023-10-22T08:35:26.000Z'
    data:
      edited: false
      editors:
      - skard
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.716304361820221
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4f7804ccb83263cacd802f69fa76a90a.svg
          fullname: Robert Zheng
          isHf: false
          isPro: false
          name: skard
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;senwu&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/senwu\">@<span class=\"\
          underline\">senwu</span></a></span>\n\n\t</span></span> ,<br>What is the\
          \ right format of prompt  on NumbersStation/nsql-llama-2-7B model? Just\
          \ as don't use LEFT JOIN\u3002</p>\n"
        raw: "Hi @senwu ,\nWhat is the right format of prompt  on NumbersStation/nsql-llama-2-7B\
          \ model? Just as don't use LEFT JOIN\u3002\n\n"
        updatedAt: '2023-10-22T08:35:26.355Z'
      numEdits: 0
      reactions: []
    id: 6534decedc1c6f1ed706dc3d
    type: comment
  author: skard
  content: "Hi @senwu ,\nWhat is the right format of prompt  on NumbersStation/nsql-llama-2-7B\
    \ model? Just as don't use LEFT JOIN\u3002\n\n"
  created_at: 2023-10-22 07:35:26+00:00
  edited: false
  hidden: false
  id: 6534decedc1c6f1ed706dc3d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2023-11-06T23:19:18.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7095690965652466
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: '<p>You can find the prompt format in the model readme.</p>

          '
        raw: You can find the prompt format in the model readme.
        updatedAt: '2023-11-06T23:19:18.376Z'
      numEdits: 0
      reactions: []
    id: 654974764aecf5964cac5af8
    type: comment
  author: senwu
  content: You can find the prompt format in the model readme.
  created_at: 2023-11-06 23:19:18+00:00
  edited: false
  hidden: false
  id: 654974764aecf5964cac5af8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8107c82ca08e95522023cfcbf0251293.svg
      fullname: Aanchal Arora
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aanchal01
      type: user
    createdAt: '2023-12-20T04:56:27.000Z'
    data:
      edited: false
      editors:
      - Aanchal01
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8964503407478333
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8107c82ca08e95522023cfcbf0251293.svg
          fullname: Aanchal Arora
          isHf: false
          isPro: false
          name: Aanchal01
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;senwu&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/senwu\">@<span class=\"\
          underline\">senwu</span></a></span>\n\n\t</span></span> ,</p>\n<ol>\n<li>NumbersStation/nsql-llama-2-7B\
          \ model is not making joins at all for me. My tables contain string dtype\
          \ and require no calculation. When I ask for multiple variables from multiple\
          \ tables, it hallucinates and links all variables to a single table with\
          \ the primary key of that table only. How do I ensure it is making joins\
          \ properly?</li>\n<li>How do I add more information like column metadata/description\
          \ in the prompt? Could you provide an example for the same. Right now my\
          \ prompt is exactly in the model readme prompt format that you guys have\
          \ provided. </li>\n<li>If the question asked contains a variable that is\
          \ present in multiple tables, can I have the output contain all of those\
          \ tables instead of just one? Currently, it is giving me the variable from\
          \ just 1 table.<br>Looking forward to your reply. Thanks in advance.</li>\n\
          </ol>\n"
        raw: "Hi @senwu ,\n1. NumbersStation/nsql-llama-2-7B model is not making joins\
          \ at all for me. My tables contain string dtype and require no calculation.\
          \ When I ask for multiple variables from multiple tables, it hallucinates\
          \ and links all variables to a single table with the primary key of that\
          \ table only. How do I ensure it is making joins properly?\n2. How do I\
          \ add more information like column metadata/description in the prompt? Could\
          \ you provide an example for the same. Right now my prompt is exactly in\
          \ the model readme prompt format that you guys have provided. \n3. If the\
          \ question asked contains a variable that is present in multiple tables,\
          \ can I have the output contain all of those tables instead of just one?\
          \ Currently, it is giving me the variable from just 1 table.\nLooking forward\
          \ to your reply. Thanks in advance."
        updatedAt: '2023-12-20T04:56:27.634Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - abicz
    id: 658273fb862ee4df74c0db03
    type: comment
  author: Aanchal01
  content: "Hi @senwu ,\n1. NumbersStation/nsql-llama-2-7B model is not making joins\
    \ at all for me. My tables contain string dtype and require no calculation. When\
    \ I ask for multiple variables from multiple tables, it hallucinates and links\
    \ all variables to a single table with the primary key of that table only. How\
    \ do I ensure it is making joins properly?\n2. How do I add more information like\
    \ column metadata/description in the prompt? Could you provide an example for\
    \ the same. Right now my prompt is exactly in the model readme prompt format that\
    \ you guys have provided. \n3. If the question asked contains a variable that\
    \ is present in multiple tables, can I have the output contain all of those tables\
    \ instead of just one? Currently, it is giving me the variable from just 1 table.\n\
    Looking forward to your reply. Thanks in advance."
  created_at: 2023-12-20 04:56:27+00:00
  edited: false
  hidden: false
  id: 658273fb862ee4df74c0db03
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/b7iswzNotep380Gdo71Y3.jpeg?w=200&h=200&f=face
      fullname: Arkadiusz Bicz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abicz
      type: user
    createdAt: '2024-01-10T15:25:26.000Z'
    data:
      edited: true
      editors:
      - abicz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9617091417312622
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/b7iswzNotep380Gdo71Y3.jpeg?w=200&h=200&f=face
          fullname: Arkadiusz Bicz
          isHf: false
          isPro: false
          name: abicz
          type: user
        html: '<p>It would be great if the model supported a few-shot learning.  It
          would allow the system to learn based on previous mistakes, where users
          can guide the model on what SQL they expect. Please let me know how can
          I help?  Can I provide training examples?</p>

          '
        raw: It would be great if the model supported a few-shot learning.  It would
          allow the system to learn based on previous mistakes, where users can guide
          the model on what SQL they expect. Please let me know how can I help?  Can
          I provide training examples?
        updatedAt: '2024-01-10T15:27:40.265Z'
      numEdits: 1
      reactions: []
    id: 659eb6e6971dfae92279f4d1
    type: comment
  author: abicz
  content: It would be great if the model supported a few-shot learning.  It would
    allow the system to learn based on previous mistakes, where users can guide the
    model on what SQL they expect. Please let me know how can I help?  Can I provide
    training examples?
  created_at: 2024-01-10 15:25:26+00:00
  edited: true
  hidden: false
  id: 659eb6e6971dfae92279f4d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
      fullname: Sen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: senwu
      type: user
    createdAt: '2024-01-15T14:34:19.000Z'
    data:
      edited: false
      editors:
      - senwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9697070717811584
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4682fe1fe9d9219f46b73bbe2e7b08.svg
          fullname: Sen Wu
          isHf: false
          isPro: false
          name: senwu
          type: user
        html: '<p>Yes, it would be great if you can share training examples</p>

          '
        raw: Yes, it would be great if you can share training examples
        updatedAt: '2024-01-15T14:34:19.123Z'
      numEdits: 0
      reactions: []
    id: 65a5426b224f96d8ccb0c0de
    type: comment
  author: senwu
  content: Yes, it would be great if you can share training examples
  created_at: 2024-01-15 14:34:19+00:00
  edited: false
  hidden: false
  id: 65a5426b224f96d8ccb0c0de
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: NumbersStation/nsql-llama-2-7B
repo_type: model
status: open
target_branch: null
title: Why prompt and schema is generated as part of model output?
