!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rombodawg
conflicting_files: null
created_at: 2023-08-31 16:51:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
      fullname: rombo dawg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rombodawg
      type: user
    createdAt: '2023-08-31T17:51:53.000Z'
    data:
      edited: false
      editors:
      - rombodawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.881675660610199
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
          fullname: rombo dawg
          isHf: false
          isPro: false
          name: rombodawg
          type: user
        html: '<p>What does this model score on human eval? Does it get close to wizardcoder34b?</p>

          '
        raw: What does this model score on human eval? Does it get close to wizardcoder34b?
        updatedAt: '2023-08-31T17:51:53.552Z'
      numEdits: 0
      reactions: []
    id: 64f0d3395d3c4aa31b04a955
    type: comment
  author: rombodawg
  content: What does this model score on human eval? Does it get close to wizardcoder34b?
  created_at: 2023-08-31 16:51:53+00:00
  edited: false
  hidden: false
  id: 64f0d3395d3c4aa31b04a955
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63010c7359ab5d9dc09d2378/3lGpN0ls5Zhf6rcd_83pz.png?w=200&h=200&f=face
      fullname: ff670
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ff670
      type: user
    createdAt: '2023-09-01T03:29:34.000Z'
    data:
      edited: false
      editors:
      - ff670
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9594621658325195
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63010c7359ab5d9dc09d2378/3lGpN0ls5Zhf6rcd_83pz.png?w=200&h=200&f=face
          fullname: ff670
          isHf: false
          isPro: false
          name: ff670
          type: user
        html: '<p>Hi, this model is our first attempt, and currently we believe its
          coding ability is close to or slightly lower than OpenBuddy 70B.</p>

          <p>If its coding ability can be further improved in the future, we will
          consider conducting more benchmarks.</p>

          <p>Also, please note that the scores of HumanEval are easily influenced
          by the training set, and due to the complexity of the model''s training
          data, even the model authors find it difficult to judge whether the training
          set is completely disjoint with the test questions. Therefore, we believe
          that benchmarks like HumanEval may be somewhat misleading, and a model that
          surpasses GPT-4 on HumanEval may not necessarily have stronger coding ability.
          </p>

          <p>Given that there is still a lack of evaluation mechanisms that can align
          with human coding ability, we still recommend that users use multiple models
          in practice and make judgments based on their own scenarios.</p>

          '
        raw: "Hi, this model is our first attempt, and currently we believe its coding\
          \ ability is close to or slightly lower than OpenBuddy 70B.\n\nIf its coding\
          \ ability can be further improved in the future, we will consider conducting\
          \ more benchmarks.\n\nAlso, please note that the scores of HumanEval are\
          \ easily influenced by the training set, and due to the complexity of the\
          \ model's training data, even the model authors find it difficult to judge\
          \ whether the training set is completely disjoint with the test questions.\
          \ Therefore, we believe that benchmarks like HumanEval may be somewhat misleading,\
          \ and a model that surpasses GPT-4 on HumanEval may not necessarily have\
          \ stronger coding ability. \n\nGiven that there is still a lack of evaluation\
          \ mechanisms that can align with human coding ability, we still recommend\
          \ that users use multiple models in practice and make judgments based on\
          \ their own scenarios."
        updatedAt: '2023-09-01T03:29:34.228Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mirek190
    id: 64f15a9ed0546fc2416344d9
    type: comment
  author: ff670
  content: "Hi, this model is our first attempt, and currently we believe its coding\
    \ ability is close to or slightly lower than OpenBuddy 70B.\n\nIf its coding ability\
    \ can be further improved in the future, we will consider conducting more benchmarks.\n\
    \nAlso, please note that the scores of HumanEval are easily influenced by the\
    \ training set, and due to the complexity of the model's training data, even the\
    \ model authors find it difficult to judge whether the training set is completely\
    \ disjoint with the test questions. Therefore, we believe that benchmarks like\
    \ HumanEval may be somewhat misleading, and a model that surpasses GPT-4 on HumanEval\
    \ may not necessarily have stronger coding ability. \n\nGiven that there is still\
    \ a lack of evaluation mechanisms that can align with human coding ability, we\
    \ still recommend that users use multiple models in practice and make judgments\
    \ based on their own scenarios."
  created_at: 2023-09-01 02:29:34+00:00
  edited: false
  hidden: false
  id: 64f15a9ed0546fc2416344d9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
      fullname: rombo dawg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rombodawg
      type: user
    createdAt: '2023-09-01T04:32:27.000Z'
    data:
      edited: false
      editors:
      - rombodawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9343029856681824
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
          fullname: rombo dawg
          isHf: false
          isPro: false
          name: rombodawg
          type: user
        html: '<p>You are correct that there is no true comparison for human coding
          capabilities, but a score on a benchmark is still the best way to compare
          models at the moment. So ill still look forward to the score</p>

          '
        raw: You are correct that there is no true comparison for human coding capabilities,
          but a score on a benchmark is still the best way to compare models at the
          moment. So ill still look forward to the score
        updatedAt: '2023-09-01T04:32:27.111Z'
      numEdits: 0
      reactions: []
    id: 64f1695bfe205baf65ba2e2d
    type: comment
  author: rombodawg
  content: You are correct that there is no true comparison for human coding capabilities,
    but a score on a benchmark is still the best way to compare models at the moment.
    So ill still look forward to the score
  created_at: 2023-09-01 03:32:27+00:00
  edited: false
  hidden: false
  id: 64f1695bfe205baf65ba2e2d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: OpenBuddy/openbuddy-coder-34b-v11-bf16
repo_type: model
status: open
target_branch: null
title: Humaneval scored???
