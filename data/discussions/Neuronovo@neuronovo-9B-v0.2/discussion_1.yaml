!!python/object:huggingface_hub.community.DiscussionWithDetails
author: georgewalker
conflicting_files: null
created_at: 2024-01-10 19:27:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cdba3c70a0c2e69d548bd44f70552d7b.svg
      fullname: George Walker
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: georgewalker
      type: user
    createdAt: '2024-01-10T19:27:06.000Z'
    data:
      edited: false
      editors:
      - georgewalker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.83871990442276
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cdba3c70a0c2e69d548bd44f70552d7b.svg
          fullname: George Walker
          isHf: false
          isPro: false
          name: georgewalker
          type: user
        html: '<p>Like 4/5 top ''7B'' models on the leaderboard, this is actually
          a ~9B, downstream of <a href="https://huggingface.co/zyh3826/GML-Mistral-merged-v1">https://huggingface.co/zyh3826/GML-Mistral-merged-v1</a>,
          a merge that combined the first 32 layers (ie all of them) of Mistral-7B
          with the last 8 layers of another Mistral finetune, creating a model that
          is about 9B parameters.</p>

          '
        raw: Like 4/5 top '7B' models on the leaderboard, this is actually a ~9B,
          downstream of https://huggingface.co/zyh3826/GML-Mistral-merged-v1, a merge
          that combined the first 32 layers (ie all of them) of Mistral-7B with the
          last 8 layers of another Mistral finetune, creating a model that is about
          9B parameters.
        updatedAt: '2024-01-10T19:27:06.868Z'
      numEdits: 0
      reactions: []
    id: 659eef8a2ff607463dcb08bf
    type: comment
  author: georgewalker
  content: Like 4/5 top '7B' models on the leaderboard, this is actually a ~9B, downstream
    of https://huggingface.co/zyh3826/GML-Mistral-merged-v1, a merge that combined
    the first 32 layers (ie all of them) of Mistral-7B with the last 8 layers of another
    Mistral finetune, creating a model that is about 9B parameters.
  created_at: 2024-01-10 19:27:06+00:00
  edited: false
  hidden: false
  id: 659eef8a2ff607463dcb08bf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
      fullname: Maxime Labonne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mlabonne
      type: user
    createdAt: '2024-01-15T07:58:22.000Z'
    data:
      edited: false
      editors:
      - mlabonne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9718614816665649
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
          fullname: Maxime Labonne
          isHf: false
          isPro: false
          name: mlabonne
          type: user
        html: "<p>Nice work <span data-props=\"{&quot;user&quot;:&quot;KoconJan&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/KoconJan\"\
          >@<span class=\"underline\">KoconJan</span></a></span>\n\n\t</span></span>\
          \ but it would be nice indeed. :)</p>\n"
        raw: Nice work @KoconJan but it would be nice indeed. :)
        updatedAt: '2024-01-15T07:58:22.119Z'
      numEdits: 0
      reactions: []
    id: 65a4e59e01ed2b702dd59b1d
    type: comment
  author: mlabonne
  content: Nice work @KoconJan but it would be nice indeed. :)
  created_at: 2024-01-15 07:58:22+00:00
  edited: false
  hidden: false
  id: 65a4e59e01ed2b702dd59b1d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1616869339153-noauth.jpeg?w=200&h=200&f=face
      fullname: Jan Kocon
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: KoconJan
      type: user
    createdAt: '2024-01-15T20:50:04.000Z'
    data:
      edited: false
      editors:
      - KoconJan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8393394947052002
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1616869339153-noauth.jpeg?w=200&h=200&f=face
          fullname: Jan Kocon
          isHf: false
          isPro: false
          name: KoconJan
          type: user
        html: '<p>done</p>

          '
        raw: done
        updatedAt: '2024-01-15T20:50:04.650Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mlabonne
    id: 65a59a7cb26c0f0134d838bc
    type: comment
  author: KoconJan
  content: done
  created_at: 2024-01-15 20:50:04+00:00
  edited: false
  hidden: false
  id: 65a59a7cb26c0f0134d838bc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Neuronovo/neuronovo-9B-v0.2
repo_type: model
status: open
target_branch: null
title: This is not a 7B. It's a ~9B. Please label appropriately.
