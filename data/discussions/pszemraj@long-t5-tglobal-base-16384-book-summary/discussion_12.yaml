!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MonsterMMORPG
conflicting_files: null
created_at: 2022-10-28 20:46:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672531901326-6345bd89fe134dfd7a0dba40.png?w=200&h=200&f=face
      fullname: "Furkan G\xF6z\xFCkara"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MonsterMMORPG
      type: user
    createdAt: '2022-10-28T21:46:49.000Z'
    data:
      edited: false
      editors:
      - MonsterMMORPG
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672531901326-6345bd89fe134dfd7a0dba40.png?w=200&h=200&f=face
          fullname: "Furkan G\xF6z\xFCkara"
          isHf: false
          isPro: false
          name: MonsterMMORPG
          type: user
        html: '<p>Please expand the example usage with more hyper parameters and with
          explanation of them</p>

          <p>Currently your example does not provide any hyper parameter :/</p>

          <p>Also can we see the progress somehow like 10% completed 15% completed
          etc? </p>

          '
        raw: "Please expand the example usage with more hyper parameters and with\
          \ explanation of them\r\n\r\nCurrently your example does not provide any\
          \ hyper parameter :/\r\n\r\nAlso can we see the progress somehow like 10%\
          \ completed 15% completed etc? "
        updatedAt: '2022-10-28T21:46:49.209Z'
      numEdits: 0
      reactions: []
    id: 635c4dc9177df3f16e9a16b3
    type: comment
  author: MonsterMMORPG
  content: "Please expand the example usage with more hyper parameters and with explanation\
    \ of them\r\n\r\nCurrently your example does not provide any hyper parameter :/\r\
    \n\r\nAlso can we see the progress somehow like 10% completed 15% completed etc? "
  created_at: 2022-10-28 20:46:49+00:00
  edited: false
  hidden: false
  id: 635c4dc9177df3f16e9a16b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
      fullname: Peter Szemraj
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: pszemraj
      type: user
    createdAt: '2022-10-29T00:50:56.000Z'
    data:
      edited: true
      editors:
      - pszemraj
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
          fullname: Peter Szemraj
          isHf: false
          isPro: false
          name: pszemraj
          type: user
        html: "<p>hi <span data-props=\"{&quot;user&quot;:&quot;MonsterMMORPG&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/MonsterMMORPG\"\
          >@<span class=\"underline\">MonsterMMORPG</span></a></span>\n\n\t</span></span>,\
          \ thanks for your interest in the model! Some hyperparameters are used <a\
          \ rel=\"nofollow\" href=\"https://colab.research.google.com/gist/pszemraj/d9a0495861776168fd5cdcd7731bc4ee/example-long-t5-tglobal-base-16384-book-summary.ipynb\"\
          >in the colab example on the model card</a>, but it doesn't have much in\
          \ terms of allowing for easy parameter changing. I'd recommend looking at\
          \ and adapting code <a href=\"https://huggingface.co/spaces/pszemraj/document-summarization/blob/main/summarize.py#L84\"\
          >from the summarize.py</a> script in the hf spaces demo for this model.\
          \ If you run inference in shorter \"token batches\" like 4096 at a time,\
          \ you will see a progress bar (otherwise not, since it's one massive batch\
          \ that is going through at a time).</p>\n<p>Unfortunately, despite the methods\
          \ implemented for the \"long\" summarization models to make handling long\
          \ sequences possible, it can still be quite a memory intensive. I <a href=\"\
          https://huggingface.co/pszemraj/led-base-book-summary/discussions/6#634f61798d0f051a45091ee5\"\
          >wrote up some comments on inference hyperparameters here</a> for <code>pszemraj/led-base-book-summary</code>,\
          \ I'd say it's the same for this model except that perhaps <code>encoder_no_repeat_ngram_size</code>\
          \ is slightly less critical than for LED base. </p>\n<p>Additionally, I've\
          \ only trained on the ampere series GPUs (not run inference). Your mileage\
          \ may vary, but since you have a 30XX GPU, try enabling <a rel=\"nofollow\"\
          \ href=\"%5Bencoder_no_repeat_ngram_size%5D(https://huggingface.co/docs/transformers/v4.23.1/en/perf_train_gpu_one#tf32)\"\
          >the tf32 data type and see if that helps</a></p>\n"
        raw: "hi @MonsterMMORPG, thanks for your interest in the model! Some hyperparameters\
          \ are used [in the colab example on the model card](https://colab.research.google.com/gist/pszemraj/d9a0495861776168fd5cdcd7731bc4ee/example-long-t5-tglobal-base-16384-book-summary.ipynb),\
          \ but it doesn't have much in terms of allowing for easy parameter changing.\
          \ I'd recommend looking at and adapting code [from the summarize.py](https://huggingface.co/spaces/pszemraj/document-summarization/blob/main/summarize.py#L84)\
          \ script in the hf spaces demo for this model. If you run inference in shorter\
          \ \"token batches\" like 4096 at a time, you will see a progress bar (otherwise\
          \ not, since it's one massive batch that is going through at a time).\n\n\
          Unfortunately, despite the methods implemented for the \"long\" summarization\
          \ models to make handling long sequences possible, it can still be quite\
          \ a memory intensive. I [wrote up some comments on inference hyperparameters\
          \ here](https://huggingface.co/pszemraj/led-base-book-summary/discussions/6#634f61798d0f051a45091ee5)\
          \ for `pszemraj/led-base-book-summary`, I'd say it's the same for this model\
          \ except that perhaps `encoder_no_repeat_ngram_size` is slightly less critical\
          \ than for LED base. \n\nAdditionally, I've only trained on the ampere series\
          \ GPUs (not run inference). Your mileage may vary, but since you have a\
          \ 30XX GPU, try enabling [the tf32 data type and see if that helps]([encoder_no_repeat_ngram_size](https://huggingface.co/docs/transformers/v4.23.1/en/perf_train_gpu_one#tf32))"
        updatedAt: '2022-10-29T00:53:55.852Z'
      numEdits: 2
      reactions: []
    id: 635c78f094619871d0d63c6b
    type: comment
  author: pszemraj
  content: "hi @MonsterMMORPG, thanks for your interest in the model! Some hyperparameters\
    \ are used [in the colab example on the model card](https://colab.research.google.com/gist/pszemraj/d9a0495861776168fd5cdcd7731bc4ee/example-long-t5-tglobal-base-16384-book-summary.ipynb),\
    \ but it doesn't have much in terms of allowing for easy parameter changing. I'd\
    \ recommend looking at and adapting code [from the summarize.py](https://huggingface.co/spaces/pszemraj/document-summarization/blob/main/summarize.py#L84)\
    \ script in the hf spaces demo for this model. If you run inference in shorter\
    \ \"token batches\" like 4096 at a time, you will see a progress bar (otherwise\
    \ not, since it's one massive batch that is going through at a time).\n\nUnfortunately,\
    \ despite the methods implemented for the \"long\" summarization models to make\
    \ handling long sequences possible, it can still be quite a memory intensive.\
    \ I [wrote up some comments on inference hyperparameters here](https://huggingface.co/pszemraj/led-base-book-summary/discussions/6#634f61798d0f051a45091ee5)\
    \ for `pszemraj/led-base-book-summary`, I'd say it's the same for this model except\
    \ that perhaps `encoder_no_repeat_ngram_size` is slightly less critical than for\
    \ LED base. \n\nAdditionally, I've only trained on the ampere series GPUs (not\
    \ run inference). Your mileage may vary, but since you have a 30XX GPU, try enabling\
    \ [the tf32 data type and see if that helps]([encoder_no_repeat_ngram_size](https://huggingface.co/docs/transformers/v4.23.1/en/perf_train_gpu_one#tf32))"
  created_at: 2022-10-28 23:50:56+00:00
  edited: true
  hidden: false
  id: 635c78f094619871d0d63c6b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672531901326-6345bd89fe134dfd7a0dba40.png?w=200&h=200&f=face
      fullname: "Furkan G\xF6z\xFCkara"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MonsterMMORPG
      type: user
    createdAt: '2022-10-29T10:31:49.000Z'
    data:
      edited: true
      editors:
      - MonsterMMORPG
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672531901326-6345bd89fe134dfd7a0dba40.png?w=200&h=200&f=face
          fullname: "Furkan G\xF6z\xFCkara"
          isHf: false
          isPro: false
          name: MonsterMMORPG
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;pszemraj&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/pszemraj\">@<span class=\"\
          underline\">pszemraj</span></a></span>\n\n\t</span></span>  ty very much\
          \ for answers. I have tried many models here with searching 16384 but none\
          \ of the produces a good result when compared to classical models as facebook/bart-large-cnn.\
          \ I use the following methodology. Actually I would prefer to split input\
          \ into 1024 tokenized equal chunks but i don't know how to do</p>\n<p><a\
          \ rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/1667039714011-6345bd89fe134dfd7a0dba40.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/1667039714011-6345bd89fe134dfd7a0dba40.png\"\
          ></a></p>\n<p>However when I use a 16k model results are not very good when\
          \ compared to traditional models as above</p>\n<p>So which hyper parameters\
          \ should I use</p>\n<p>for example for long-t5-tglobal-base-16384-book-summary\
          \ are below ones good enough?</p>\n<p>what does repetition_penalty do<br>early_stopping\
          \ effect?<br>no_repeat_ngram_size?<br>encoder_no_repeat_ngram_size ?<br>num_beams\
          \ effect?</p>\n<p>any other parameters that can affect performance?</p>\n\
          <p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/1667039601255-6345bd89fe134dfd7a0dba40.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/1667039601255-6345bd89fe134dfd7a0dba40.png\"\
          ></a></p>\n"
        raw: '@pszemraj  ty very much for answers. I have tried many models here with
          searching 16384 but none of the produces a good result when compared to
          classical models as facebook/bart-large-cnn. I use the following methodology.
          Actually I would prefer to split input into 1024 tokenized equal chunks
          but i don''t know how to do


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1667039714011-6345bd89fe134dfd7a0dba40.png)


          However when I use a 16k model results are not very good when compared to
          traditional models as above


          So which hyper parameters should I use


          for example for long-t5-tglobal-base-16384-book-summary are below ones good
          enough?


          what does repetition_penalty do

          early_stopping effect?

          no_repeat_ngram_size?

          encoder_no_repeat_ngram_size ?

          num_beams effect?


          any other parameters that can affect performance?


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1667039601255-6345bd89fe134dfd7a0dba40.png)'
        updatedAt: '2022-10-29T10:35:19.280Z'
      numEdits: 2
      reactions: []
    id: 635d0115e7aef2358a9d2bb6
    type: comment
  author: MonsterMMORPG
  content: '@pszemraj  ty very much for answers. I have tried many models here with
    searching 16384 but none of the produces a good result when compared to classical
    models as facebook/bart-large-cnn. I use the following methodology. Actually I
    would prefer to split input into 1024 tokenized equal chunks but i don''t know
    how to do


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1667039714011-6345bd89fe134dfd7a0dba40.png)


    However when I use a 16k model results are not very good when compared to traditional
    models as above


    So which hyper parameters should I use


    for example for long-t5-tglobal-base-16384-book-summary are below ones good enough?


    what does repetition_penalty do

    early_stopping effect?

    no_repeat_ngram_size?

    encoder_no_repeat_ngram_size ?

    num_beams effect?


    any other parameters that can affect performance?


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1667039601255-6345bd89fe134dfd7a0dba40.png)'
  created_at: 2022-10-29 09:31:49+00:00
  edited: true
  hidden: false
  id: 635d0115e7aef2358a9d2bb6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672531901326-6345bd89fe134dfd7a0dba40.png?w=200&h=200&f=face
      fullname: "Furkan G\xF6z\xFCkara"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MonsterMMORPG
      type: user
    createdAt: '2022-10-29T10:53:48.000Z'
    data:
      edited: false
      editors:
      - MonsterMMORPG
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672531901326-6345bd89fe134dfd7a0dba40.png?w=200&h=200&f=face
          fullname: "Furkan G\xF6z\xFCkara"
          isHf: false
          isPro: false
          name: MonsterMMORPG
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;pszemraj&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/pszemraj\">@<span class=\"\
          underline\">pszemraj</span></a></span>\n\n\t</span></span>  Here comparison\
          \ between facebook/bart-large-cnn and pszemraj/long-t5-tglobal-base-16384-book-summary\
          \ on a long speech text data</p>\n<p>Also tf32 made huge speed boost ty\
          \ for the tips </p>\n<p>facebook/bart-large-cnn : <a rel=\"nofollow\" href=\"\
          https://justpaste.it/6jhhd\">https://justpaste.it/6jhhd</a></p>\n<p>pszemraj/long-t5-tglobal-base-16384-book-summary\
          \ : <a rel=\"nofollow\" href=\"https://justpaste.it/8wa8v\">https://justpaste.it/8wa8v</a></p>\n\
          <p>long speech text data : <a rel=\"nofollow\" href=\"https://justpaste.it/3a1pn\"\
          >https://justpaste.it/3a1pn</a></p>\n"
        raw: "@pszemraj  Here comparison between facebook/bart-large-cnn and pszemraj/long-t5-tglobal-base-16384-book-summary\
          \ on a long speech text data\n\nAlso tf32 made huge speed boost ty for the\
          \ tips \n\nfacebook/bart-large-cnn : https://justpaste.it/6jhhd\n\npszemraj/long-t5-tglobal-base-16384-book-summary\
          \ : https://justpaste.it/8wa8v\n\nlong speech text data : https://justpaste.it/3a1pn"
        updatedAt: '2022-10-29T10:53:48.853Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - pszemraj
    id: 635d063c06a944e347bad289
    type: comment
  author: MonsterMMORPG
  content: "@pszemraj  Here comparison between facebook/bart-large-cnn and pszemraj/long-t5-tglobal-base-16384-book-summary\
    \ on a long speech text data\n\nAlso tf32 made huge speed boost ty for the tips\
    \ \n\nfacebook/bart-large-cnn : https://justpaste.it/6jhhd\n\npszemraj/long-t5-tglobal-base-16384-book-summary\
    \ : https://justpaste.it/8wa8v\n\nlong speech text data : https://justpaste.it/3a1pn"
  created_at: 2022-10-29 09:53:48+00:00
  edited: false
  hidden: false
  id: 635d063c06a944e347bad289
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
      fullname: Peter Szemraj
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: pszemraj
      type: user
    createdAt: '2022-12-15T22:54:58.000Z'
    data:
      edited: true
      editors:
      - pszemraj
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
          fullname: Peter Szemraj
          isHf: false
          isPro: false
          name: pszemraj
          type: user
        html: '<p>thanks for the comparisons! I''m going to change the status to "closed"
          as I think we''ve gotten to somewhat of a convergence point. feel free to
          reopen as issue if needed, or we can just comment on this thread/discuss
          in discord.</p>

          <p>for anyone coming across this later, I added <a href="https://huggingface.co/blog/how-to-generate">a
          link to this hf blog post</a> which is a solid starting point for understanding
          the beam search parameters.</p>

          '
        raw: 'thanks for the comparisons! I''m going to change the status to "closed"
          as I think we''ve gotten to somewhat of a convergence point. feel free to
          reopen as issue if needed, or we can just comment on this thread/discuss
          in discord.


          for anyone coming across this later, I added [a link to this hf blog post](https://huggingface.co/blog/how-to-generate)
          which is a solid starting point for understanding the beam search parameters.'
        updatedAt: '2022-12-15T22:55:07.663Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - MonsterMMORPG
      relatedEventId: 639ba5c234967bcf455b2329
    id: 639ba5c234967bcf455b2328
    type: comment
  author: pszemraj
  content: 'thanks for the comparisons! I''m going to change the status to "closed"
    as I think we''ve gotten to somewhat of a convergence point. feel free to reopen
    as issue if needed, or we can just comment on this thread/discuss in discord.


    for anyone coming across this later, I added [a link to this hf blog post](https://huggingface.co/blog/how-to-generate)
    which is a solid starting point for understanding the beam search parameters.'
  created_at: 2022-12-15 22:54:58+00:00
  edited: true
  hidden: false
  id: 639ba5c234967bcf455b2328
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
      fullname: Peter Szemraj
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: pszemraj
      type: user
    createdAt: '2022-12-15T22:54:58.000Z'
    data:
      status: closed
    id: 639ba5c234967bcf455b2329
    type: status-change
  author: pszemraj
  created_at: 2022-12-15 22:54:58+00:00
  id: 639ba5c234967bcf455b2329
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: pszemraj/long-t5-tglobal-base-16384-book-summary
repo_type: model
status: closed
target_branch: null
title: Please expand the example usage with more hyper parameters and with explanation
  of them
