!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Mavisfsew
conflicting_files: null
created_at: 2023-10-24 01:43:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c02a1c94e3d3164463cf26aab41e22f7.svg
      fullname: Hoot
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Mavisfsew
      type: user
    createdAt: '2023-10-24T02:43:42.000Z'
    data:
      edited: false
      editors:
      - Mavisfsew
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.791793167591095
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c02a1c94e3d3164463cf26aab41e22f7.svg
          fullname: Hoot
          isHf: false
          isPro: false
          name: Mavisfsew
          type: user
        html: '<p>Please I''m getting error trimg to fine tune the model. Please this
          is the folder stricture<br>Mydataset/lj_speech/metadata.csv<br>Mydataset/lj_speech/wavs/audio1.wav</p>

          <p>I am getting key error when trying to load the dataset. Please provide
          me sample code  or solution. </p>

          '
        raw: "Please I'm getting error trimg to fine tune the model. Please this is\
          \ the folder stricture  \r\nMydataset/lj_speech/metadata.csv       \r\n\
          Mydataset/lj_speech/wavs/audio1.wav\r\n\r\nI am getting key error when trying\
          \ to load the dataset. Please provide me sample code  or solution. "
        updatedAt: '2023-10-24T02:43:42.709Z'
      numEdits: 0
      reactions: []
    id: 65372f5e62dd8126cf8d47f4
    type: comment
  author: Mavisfsew
  content: "Please I'm getting error trimg to fine tune the model. Please this is\
    \ the folder stricture  \r\nMydataset/lj_speech/metadata.csv       \r\nMydataset/lj_speech/wavs/audio1.wav\r\
    \n\r\nI am getting key error when trying to load the dataset. Please provide me\
    \ sample code  or solution. "
  created_at: 2023-10-24 01:43:42+00:00
  edited: false
  hidden: false
  id: 65372f5e62dd8126cf8d47f4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-10-26T18:03:02.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8590998649597168
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Mavisfsew&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Mavisfsew\"\
          >@<span class=\"underline\">Mavisfsew</span></a></span>\n\n\t</span></span>\
          \ - do you have a reproducible code snippet to load the audio data? You\
          \ could, for instance, push the datasets to the Hugging Face Hub and write\
          \ a short code snippet that loads this dataset. If you share that here,\
          \ I'd be happy to take a look!</p>\n"
        raw: Hey @Mavisfsew - do you have a reproducible code snippet to load the
          audio data? You could, for instance, push the datasets to the Hugging Face
          Hub and write a short code snippet that loads this dataset. If you share
          that here, I'd be happy to take a look!
        updatedAt: '2023-10-26T18:03:02.594Z'
      numEdits: 0
      reactions: []
    id: 653aa9d67c01c693a17af563
    type: comment
  author: sanchit-gandhi
  content: Hey @Mavisfsew - do you have a reproducible code snippet to load the audio
    data? You could, for instance, push the datasets to the Hugging Face Hub and write
    a short code snippet that loads this dataset. If you share that here, I'd be happy
    to take a look!
  created_at: 2023-10-26 17:03:02+00:00
  edited: false
  hidden: false
  id: 653aa9d67c01c693a17af563
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c02a1c94e3d3164463cf26aab41e22f7.svg
      fullname: Hoot
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Mavisfsew
      type: user
    createdAt: '2023-10-27T00:19:10.000Z'
    data:
      edited: false
      editors:
      - Mavisfsew
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.551442563533783
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c02a1c94e3d3164463cf26aab41e22f7.svg
          fullname: Hoot
          isHf: false
          isPro: false
          name: Mavisfsew
          type: user
        html: '<p>Please here is the code. I used the LJ_Speech dataset and its on
          huggingface. </p>

          <p>from transformers import VitsModel, AutoTokenizer<br>from transformers
          import TrainingArguments, Trainer<br>from datasets import load_dataset<br>import
          os<br>import pandas as pd</p>

          <h1 id="ensure-the-dataset-is-downloaded-and-prepared">Ensure the dataset
          is downloaded and prepared</h1>

          <p>dataset = load_dataset("lj_speech")</p>

          <p>model_name = "facebook/mms-tts-eng"<br>model = VitsModel.from_pretrained(model_name)<br>tokenizer
          = AutoTokenizer.from_pretrained(model_name)</p>

          <p>def tokenize_function(examples):<br>    return tokenizer(examples["text"],
          padding="max_length", truncation=True)</p>

          <p>training_args = TrainingArguments(<br>    output_dir="./output",<br>    per_device_train_batch_size=8,<br>    num_train_epochs=5,<br>    evaluation_strategy="steps",<br>    eval_steps=500,<br>    save_steps=500,<br>)</p>

          <h1 id="initialize-the-trainer">Initialize the Trainer.</h1>

          <p>trainer = Trainer(<br>    model=model,<br>    args=training_args,<br>    data_collator=tokenize_function,<br>    train_dataset=dataset["train"],<br>    eval_dataset=dataset["validation"],<br>)</p>

          <p>trainer.train()</p>

          '
        raw: "Please here is the code. I used the LJ_Speech dataset and its on huggingface.\
          \ \n\nfrom transformers import VitsModel, AutoTokenizer\nfrom transformers\
          \ import TrainingArguments, Trainer\nfrom datasets import load_dataset\n\
          import os\nimport pandas as pd\n\n# Ensure the dataset is downloaded and\
          \ prepared\ndataset = load_dataset(\"lj_speech\")\n\nmodel_name = \"facebook/mms-tts-eng\"\
          \nmodel = VitsModel.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\
          \ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"\
          ], padding=\"max_length\", truncation=True)\n\ntraining_args = TrainingArguments(\n\
          \    output_dir=\"./output\",\n    per_device_train_batch_size=8,\n    num_train_epochs=5,\n\
          \    evaluation_strategy=\"steps\",\n    eval_steps=500,\n    save_steps=500,\n\
          )\n\n# Initialize the Trainer.\ntrainer = Trainer(\n    model=model,\n \
          \   args=training_args,\n    data_collator=tokenize_function,\n    train_dataset=dataset[\"\
          train\"],\n    eval_dataset=dataset[\"validation\"],\n)\n\ntrainer.train()"
        updatedAt: '2023-10-27T00:19:10.072Z'
      numEdits: 0
      reactions: []
    id: 653b01fe1f981e43045eb4d1
    type: comment
  author: Mavisfsew
  content: "Please here is the code. I used the LJ_Speech dataset and its on huggingface.\
    \ \n\nfrom transformers import VitsModel, AutoTokenizer\nfrom transformers import\
    \ TrainingArguments, Trainer\nfrom datasets import load_dataset\nimport os\nimport\
    \ pandas as pd\n\n# Ensure the dataset is downloaded and prepared\ndataset = load_dataset(\"\
    lj_speech\")\n\nmodel_name = \"facebook/mms-tts-eng\"\nmodel = VitsModel.from_pretrained(model_name)\n\
    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize_function(examples):\n\
    \    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\
    \ntraining_args = TrainingArguments(\n    output_dir=\"./output\",\n    per_device_train_batch_size=8,\n\
    \    num_train_epochs=5,\n    evaluation_strategy=\"steps\",\n    eval_steps=500,\n\
    \    save_steps=500,\n)\n\n# Initialize the Trainer.\ntrainer = Trainer(\n   \
    \ model=model,\n    args=training_args,\n    data_collator=tokenize_function,\n\
    \    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"validation\"\
    ],\n)\n\ntrainer.train()"
  created_at: 2023-10-26 23:19:10+00:00
  edited: false
  hidden: false
  id: 653b01fe1f981e43045eb4d1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: facebook/mms-tts-eng
repo_type: model
status: open
target_branch: null
title: Key error and unable to load dataset
