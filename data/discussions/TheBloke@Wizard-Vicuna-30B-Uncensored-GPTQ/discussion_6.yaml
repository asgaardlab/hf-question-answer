!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Appolonius
conflicting_files: null
created_at: 2023-06-02 10:10:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f882447e7e8c4799cd7c25251079413f.svg
      fullname: Appolonius
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Appolonius
      type: user
    createdAt: '2023-06-02T11:10:32.000Z'
    data:
      edited: false
      editors:
      - Appolonius
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f882447e7e8c4799cd7c25251079413f.svg
          fullname: Appolonius
          isHf: false
          isPro: false
          name: Appolonius
          type: user
        html: '<p>the full error after downloading this model with the Text Generation
          Web UI (automatic windows install)<br>I''m currently downloading these models
          found elsewhere and going to place them in the model folder. is this normal?</p>

          <p>Traceback (most recent call last):<br>  File "C:\Users\Appolonius\Desktop\oobabooga_windows\text-generation-webui\server.py",
          line 1097, in <br>    shared.model, shared.tokenizer = load_model(shared.model_name)<br>  File
          "C:\Users\Appolonius\Desktop\oobabooga_windows\text-generation-webui\modules\models.py",
          line 97, in load_model<br>    output = load_func(model_name)<br>  File "C:\Users\Appolonius\Desktop\oobabooga_windows\text-generation-webui\modules\models.py",
          line 155, in huggingface_loader<br>    model = LoaderClass.from_pretrained(Path(f"{shared.args.model_dir}/{model_name}"),
          low_cpu_mem_usage=True, torch_dtype=torch.bfloat16 if shared.args.bf16 else
          torch.float16, trust_remote_code=shared.args.trust_remote_code)<br>  File
          "C:\Users\Appolonius\Desktop\oobabooga_windows\installer_files\env\lib\site-packages\transformers\models\auto\auto_factory.py",
          line 472, in from_pretrained<br>    return model_class.from_pretrained(<br>  File
          "C:\Users\Appolonius\Desktop\oobabooga_windows\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
          line 2406, in from_pretrained<br>    raise EnvironmentError(<br>OSError:
          Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or
          flax_model.msgpack found in directory models\TheBloke_Wizard-Vicuna-30B-Uncensored-GPTQ.<br>Press
          any key to continue . . .</p>

          '
        raw: "the full error after downloading this model with the Text Generation\
          \ Web UI (automatic windows install)\r\nI'm currently downloading these\
          \ models found elsewhere and going to place them in the model folder. is\
          \ this normal?\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\\
          Users\\Appolonius\\Desktop\\oobabooga_windows\\text-generation-webui\\server.py\"\
          , line 1097, in <module>\r\n    shared.model, shared.tokenizer = load_model(shared.model_name)\r\
          \n  File \"C:\\Users\\Appolonius\\Desktop\\oobabooga_windows\\text-generation-webui\\\
          modules\\models.py\", line 97, in load_model\r\n    output = load_func(model_name)\r\
          \n  File \"C:\\Users\\Appolonius\\Desktop\\oobabooga_windows\\text-generation-webui\\\
          modules\\models.py\", line 155, in huggingface_loader\r\n    model = LoaderClass.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}\"), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16\
          \ if shared.args.bf16 else torch.float16, trust_remote_code=shared.args.trust_remote_code)\r\
          \n  File \"C:\\Users\\Appolonius\\Desktop\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\",\
          \ line 472, in from_pretrained\r\n    return model_class.from_pretrained(\r\
          \n  File \"C:\\Users\\Appolonius\\Desktop\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\modeling_utils.py\", line 2406, in\
          \ from_pretrained\r\n    raise EnvironmentError(\r\nOSError: Error no file\
          \ named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
          \ found in directory models\\TheBloke_Wizard-Vicuna-30B-Uncensored-GPTQ.\r\
          \nPress any key to continue . . ."
        updatedAt: '2023-06-02T11:10:32.842Z'
      numEdits: 0
      reactions: []
    id: 6479ce28a81f5f7707872df8
    type: comment
  author: Appolonius
  content: "the full error after downloading this model with the Text Generation Web\
    \ UI (automatic windows install)\r\nI'm currently downloading these models found\
    \ elsewhere and going to place them in the model folder. is this normal?\r\n\r\
    \nTraceback (most recent call last):\r\n  File \"C:\\Users\\Appolonius\\Desktop\\\
    oobabooga_windows\\text-generation-webui\\server.py\", line 1097, in <module>\r\
    \n    shared.model, shared.tokenizer = load_model(shared.model_name)\r\n  File\
    \ \"C:\\Users\\Appolonius\\Desktop\\oobabooga_windows\\text-generation-webui\\\
    modules\\models.py\", line 97, in load_model\r\n    output = load_func(model_name)\r\
    \n  File \"C:\\Users\\Appolonius\\Desktop\\oobabooga_windows\\text-generation-webui\\\
    modules\\models.py\", line 155, in huggingface_loader\r\n    model = LoaderClass.from_pretrained(Path(f\"\
    {shared.args.model_dir}/{model_name}\"), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16\
    \ if shared.args.bf16 else torch.float16, trust_remote_code=shared.args.trust_remote_code)\r\
    \n  File \"C:\\Users\\Appolonius\\Desktop\\oobabooga_windows\\installer_files\\\
    env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 472,\
    \ in from_pretrained\r\n    return model_class.from_pretrained(\r\n  File \"C:\\\
    Users\\Appolonius\\Desktop\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\modeling_utils.py\", line 2406, in from_pretrained\r\n    raise\
    \ EnvironmentError(\r\nOSError: Error no file named pytorch_model.bin, tf_model.h5,\
    \ model.ckpt.index or flax_model.msgpack found in directory models\\TheBloke_Wizard-Vicuna-30B-Uncensored-GPTQ.\r\
    \nPress any key to continue . . ."
  created_at: 2023-06-02 10:10:32+00:00
  edited: false
  hidden: false
  id: 6479ce28a81f5f7707872df8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb02369c7b9d725bf313dbe81707422f.svg
      fullname: Petter Thowsen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pelatho
      type: user
    createdAt: '2023-06-02T14:21:08.000Z'
    data:
      edited: false
      editors:
      - pelatho
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb02369c7b9d725bf313dbe81707422f.svg
          fullname: Petter Thowsen
          isHf: false
          isPro: false
          name: pelatho
          type: user
        html: '<p>I''m also getting this error when trying to build a template for
          running this model on banana.dev</p>

          '
        raw: I'm also getting this error when trying to build a template for running
          this model on banana.dev
        updatedAt: '2023-06-02T14:21:08.172Z'
      numEdits: 0
      reactions: []
    id: 6479fad4a84498f2af4bb6fa
    type: comment
  author: pelatho
  content: I'm also getting this error when trying to build a template for running
    this model on banana.dev
  created_at: 2023-06-02 13:21:08+00:00
  edited: false
  hidden: false
  id: 6479fad4a84498f2af4bb6fa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/893a69e690040931b3a3a78d40eabb5a.svg
      fullname: Robert Barnett
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: theappointed
      type: user
    createdAt: '2023-06-04T06:05:02.000Z'
    data:
      edited: false
      editors:
      - theappointed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9791679978370667
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/893a69e690040931b3a3a78d40eabb5a.svg
          fullname: Robert Barnett
          isHf: false
          isPro: false
          name: theappointed
          type: user
        html: '<p>I get the same error on my device. I have some of the files from
          other model but not all of them. Does anyone know where I can get them from?</p>

          '
        raw: I get the same error on my device. I have some of the files from other
          model but not all of them. Does anyone know where I can get them from?
        updatedAt: '2023-06-04T06:05:02.437Z'
      numEdits: 0
      reactions: []
    id: 647c298e1c0644de8d1afce2
    type: comment
  author: theappointed
  content: I get the same error on my device. I have some of the files from other
    model but not all of them. Does anyone know where I can get them from?
  created_at: 2023-06-04 05:05:02+00:00
  edited: false
  hidden: false
  id: 647c298e1c0644de8d1afce2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bc303770417db89dea04196dc6e00c81.svg
      fullname: Guru Prakash
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guruprk
      type: user
    createdAt: '2023-06-04T06:30:05.000Z'
    data:
      edited: false
      editors:
      - guruprk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.41636690497398376
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bc303770417db89dea04196dc6e00c81.svg
          fullname: Guru Prakash
          isHf: false
          isPro: false
          name: guruprk
          type: user
        html: '<p>Are you using the latest version of webui?</p>

          '
        raw: Are you using the latest version of webui?
        updatedAt: '2023-06-04T06:30:05.405Z'
      numEdits: 0
      reactions: []
    id: 647c2f6dc788767ab5c3073c
    type: comment
  author: guruprk
  content: Are you using the latest version of webui?
  created_at: 2023-06-04 05:30:05+00:00
  edited: false
  hidden: false
  id: 647c2f6dc788767ab5c3073c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/893a69e690040931b3a3a78d40eabb5a.svg
      fullname: Robert Barnett
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: theappointed
      type: user
    createdAt: '2023-06-04T09:11:57.000Z'
    data:
      edited: false
      editors:
      - theappointed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.968961238861084
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/893a69e690040931b3a3a78d40eabb5a.svg
          fullname: Robert Barnett
          isHf: false
          isPro: false
          name: theappointed
          type: user
        html: '<p>I believe so. I tried downloading it from scratch again, and also
          running the update.</p>

          '
        raw: I believe so. I tried downloading it from scratch again, and also running
          the update.
        updatedAt: '2023-06-04T09:11:57.240Z'
      numEdits: 0
      reactions: []
    id: 647c555d60dfe0f35d4b5fea
    type: comment
  author: theappointed
  content: I believe so. I tried downloading it from scratch again, and also running
    the update.
  created_at: 2023-06-04 08:11:57+00:00
  edited: false
  hidden: false
  id: 647c555d60dfe0f35d4b5fea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-04T09:45:55.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8506553173065186
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p>This error means GPTQ parameters are not set.  For those using text-generation-webui,\
          \ please see the instructions in the README.</p>\n<p><span data-props=\"\
          {&quot;user&quot;:&quot;pelatho&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/pelatho\">@<span class=\"underline\">pelatho</span></a></span>\n\
          \n\t</span></span> to use this with Python code , please check out AutoGPTQ.\
          \  It can load GPTQ quantised models like this.  You can't load GPTQ models\
          \ with transformers on its own, you need to AutoGPTQ.</p>\n"
        raw: 'This error means GPTQ parameters are not set.  For those using text-generation-webui,
          please see the instructions in the README.


          @pelatho to use this with Python code , please check out AutoGPTQ.  It can
          load GPTQ quantised models like this.  You can''t load GPTQ models with
          transformers on its own, you need to AutoGPTQ.'
        updatedAt: '2023-06-04T09:45:55.257Z'
      numEdits: 0
      reactions: []
    id: 647c5d531c0644de8d20a110
    type: comment
  author: TheBloke
  content: 'This error means GPTQ parameters are not set.  For those using text-generation-webui,
    please see the instructions in the README.


    @pelatho to use this with Python code , please check out AutoGPTQ.  It can load
    GPTQ quantised models like this.  You can''t load GPTQ models with transformers
    on its own, you need to AutoGPTQ.'
  created_at: 2023-06-04 08:45:55+00:00
  edited: false
  hidden: false
  id: 647c5d531c0644de8d20a110
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/96ffa5a1634161a6db4b5b97e2ec47a8.svg
      fullname: M C
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DissentingPotato
      type: user
    createdAt: '2023-06-19T04:28:50.000Z'
    data:
      edited: false
      editors:
      - DissentingPotato
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9084622859954834
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/96ffa5a1634161a6db4b5b97e2ec47a8.svg
          fullname: M C
          isHf: false
          isPro: false
          name: DissentingPotato
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> </p>\n<p>Directly\
          \ from readme<br>\"  * Note that you do not need to set GPTQ parameters\
          \ any more. These should all be set to default values, as they are now set\
          \ automatically from the file <code>quantize_config.json</code>.\"</p>\n\
          <p>Got that in the folder so I don't think that's the issue.</p>\n<p>Also\
          \ getting the same error and reinstalled using the directions in the readme...\
          \ still got the same issue.</p>\n"
        raw: "@TheBloke \n\nDirectly from readme\n\"  * Note that you do not need\
          \ to set GPTQ parameters any more. These should all be set to default values,\
          \ as they are now set automatically from the file `quantize_config.json`.\"\
          \n\nGot that in the folder so I don't think that's the issue.\n\nAlso getting\
          \ the same error and reinstalled using the directions in the readme... still\
          \ got the same issue.\n"
        updatedAt: '2023-06-19T04:28:50.491Z'
      numEdits: 0
      reactions: []
    id: 648fd982dd775153e51fec19
    type: comment
  author: DissentingPotato
  content: "@TheBloke \n\nDirectly from readme\n\"  * Note that you do not need to\
    \ set GPTQ parameters any more. These should all be set to default values, as\
    \ they are now set automatically from the file `quantize_config.json`.\"\n\nGot\
    \ that in the folder so I don't think that's the issue.\n\nAlso getting the same\
    \ error and reinstalled using the directions in the readme... still got the same\
    \ issue.\n"
  created_at: 2023-06-19 03:28:50+00:00
  edited: false
  hidden: false
  id: 648fd982dd775153e51fec19
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-20T10:10:25.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7847234606742859
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;DissentingPotato&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/DissentingPotato\"\
          >@<span class=\"underline\">DissentingPotato</span></a></span>\n\n\t</span></span>\
          \ show me a screenshot of your models folder, and the contents of the <code>TheBloke_Wizard-Vicuna-30B-Uncensored-GPTQ</code>\
          \ folder under that.</p>\n"
        raw: '@DissentingPotato show me a screenshot of your models folder, and the
          contents of the `TheBloke_Wizard-Vicuna-30B-Uncensored-GPTQ` folder under
          that.'
        updatedAt: '2023-06-20T10:10:25.040Z'
      numEdits: 0
      reactions: []
    id: 64917b11c13c3e6727df85ca
    type: comment
  author: TheBloke
  content: '@DissentingPotato show me a screenshot of your models folder, and the
    contents of the `TheBloke_Wizard-Vicuna-30B-Uncensored-GPTQ` folder under that.'
  created_at: 2023-06-20 09:10:25+00:00
  edited: false
  hidden: false
  id: 64917b11c13c3e6727df85ca
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ
repo_type: model
status: open
target_branch: null
title: 'OSError: Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index
  or flax_model.msgpack'
