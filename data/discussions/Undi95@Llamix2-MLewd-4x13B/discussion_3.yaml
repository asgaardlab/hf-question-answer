!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Cheesekeeper73
conflicting_files: null
created_at: 2023-12-15 18:00:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0337e6c32398a58a423501bcd5794d88.svg
      fullname: Geoff Nussbaum
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Cheesekeeper73
      type: user
    createdAt: '2023-12-15T18:00:24.000Z'
    data:
      edited: false
      editors:
      - Cheesekeeper73
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9727063775062561
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0337e6c32398a58a423501bcd5794d88.svg
          fullname: Geoff Nussbaum
          isHf: false
          isPro: false
          name: Cheesekeeper73
          type: user
        html: '<p>I''m really keen to try this model, but I can''t seem to get the
          GGUF version to load. I upgraded Llama.cpp to version 2.23 but i just get
          an assert error. Same issue trying to load through transformers. Are there
          any other components that need to be upgraded? Thanks... </p>

          '
        raw: 'I''m really keen to try this model, but I can''t seem to get the GGUF
          version to load. I upgraded Llama.cpp to version 2.23 but i just get an
          assert error. Same issue trying to load through transformers. Are there
          any other components that need to be upgraded? Thanks... '
        updatedAt: '2023-12-15T18:00:24.363Z'
      numEdits: 0
      reactions: []
    id: 657c943849ec77d48e4395fb
    type: comment
  author: Cheesekeeper73
  content: 'I''m really keen to try this model, but I can''t seem to get the GGUF
    version to load. I upgraded Llama.cpp to version 2.23 but i just get an assert
    error. Same issue trying to load through transformers. Are there any other components
    that need to be upgraded? Thanks... '
  created_at: 2023-12-15 18:00:24+00:00
  edited: false
  hidden: false
  id: 657c943849ec77d48e4395fb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
      fullname: Undi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Undi95
      type: user
    createdAt: '2023-12-15T18:09:47.000Z'
    data:
      edited: false
      editors:
      - Undi95
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9329433441162109
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
          fullname: Undi
          isHf: false
          isPro: false
          name: Undi95
          type: user
        html: '<p>Last Llama.cpp or Ooba or Kobold load it fine for me, are you sure
          you''re on last version?</p>

          '
        raw: Last Llama.cpp or Ooba or Kobold load it fine for me, are you sure you're
          on last version?
        updatedAt: '2023-12-15T18:09:47.664Z'
      numEdits: 0
      reactions: []
    id: 657c966b3480ce8aae4a985d
    type: comment
  author: Undi95
  content: Last Llama.cpp or Ooba or Kobold load it fine for me, are you sure you're
    on last version?
  created_at: 2023-12-15 18:09:47+00:00
  edited: false
  hidden: false
  id: 657c966b3480ce8aae4a985d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0337e6c32398a58a423501bcd5794d88.svg
      fullname: Geoff Nussbaum
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Cheesekeeper73
      type: user
    createdAt: '2023-12-15T18:25:17.000Z'
    data:
      edited: true
      editors:
      - Cheesekeeper73
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.964205265045166
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0337e6c32398a58a423501bcd5794d88.svg
          fullname: Geoff Nussbaum
          isHf: false
          isPro: false
          name: Cheesekeeper73
          type: user
        html: '<p>Hey, thanks for getting back to me, big fan of your models. I upgraded/recompiled
          Llama.cpp to version 2.23 which should be the most recent. Haven''t tried
          do a full update on Ooba yet so I''ll give that a try. It''s 2am here so
          probably a tomorrow thing :). I''ll let you know. Thanks very much... </p>

          '
        raw: 'Hey, thanks for getting back to me, big fan of your models. I upgraded/recompiled
          Llama.cpp to version 2.23 which should be the most recent. Haven''t tried
          do a full update on Ooba yet so I''ll give that a try. It''s 2am here so
          probably a tomorrow thing :). I''ll let you know. Thanks very much... '
        updatedAt: '2023-12-15T18:25:40.143Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Undi95
    id: 657c9a0da2ef321675a152f0
    type: comment
  author: Cheesekeeper73
  content: 'Hey, thanks for getting back to me, big fan of your models. I upgraded/recompiled
    Llama.cpp to version 2.23 which should be the most recent. Haven''t tried do a
    full update on Ooba yet so I''ll give that a try. It''s 2am here so probably a
    tomorrow thing :). I''ll let you know. Thanks very much... '
  created_at: 2023-12-15 18:25:17+00:00
  edited: true
  hidden: false
  id: 657c9a0da2ef321675a152f0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/633a39ec8f27255b6b571101/7J_BcRm7ua0WZNIGwEzlo.png?w=200&h=200&f=face
      fullname: Cedrick Hesketh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lazyDataScientist
      type: user
    createdAt: '2023-12-15T20:07:48.000Z'
    data:
      edited: false
      editors:
      - lazyDataScientist
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.891094446182251
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/633a39ec8f27255b6b571101/7J_BcRm7ua0WZNIGwEzlo.png?w=200&h=200&f=face
          fullname: Cedrick Hesketh
          isHf: false
          isPro: false
          name: lazyDataScientist
          type: user
        html: '<p>Try reducing the <code>n_ctx</code> to below 10,000 or to 4096.
          The latest version of Ooba (Text gen webui) has this issue where it fails
          to load models if the value is too high.</p>

          '
        raw: Try reducing the ```n_ctx``` to below 10,000 or to 4096. The latest version
          of Ooba (Text gen webui) has this issue where it fails to load models if
          the value is too high.
        updatedAt: '2023-12-15T20:07:48.354Z'
      numEdits: 0
      reactions: []
    id: 657cb2143687559a672b7ff7
    type: comment
  author: lazyDataScientist
  content: Try reducing the ```n_ctx``` to below 10,000 or to 4096. The latest version
    of Ooba (Text gen webui) has this issue where it fails to load models if the value
    is too high.
  created_at: 2023-12-15 20:07:48+00:00
  edited: false
  hidden: false
  id: 657cb2143687559a672b7ff7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
      fullname: Undi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Undi95
      type: user
    createdAt: '2023-12-15T20:11:05.000Z'
    data:
      edited: true
      editors:
      - Undi95
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9540483951568604
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
          fullname: Undi
          isHf: false
          isPro: false
          name: Undi95
          type: user
        html: '<p>It worked for me at 32k context loaded with Transformer on an A100
          on runpod</p>

          '
        raw: It worked for me at 32k context loaded with Transformer on an A100 on
          runpod
        updatedAt: '2023-12-15T20:11:10.838Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Renegadesoffun
    id: 657cb2d93c65a5be2ad79706
    type: comment
  author: Undi95
  content: It worked for me at 32k context loaded with Transformer on an A100 on runpod
  created_at: 2023-12-15 20:11:05+00:00
  edited: true
  hidden: false
  id: 657cb2d93c65a5be2ad79706
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0337e6c32398a58a423501bcd5794d88.svg
      fullname: Geoff Nussbaum
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Cheesekeeper73
      type: user
    createdAt: '2023-12-16T05:47:30.000Z'
    data:
      edited: false
      editors:
      - Cheesekeeper73
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9688832759857178
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0337e6c32398a58a423501bcd5794d88.svg
          fullname: Geoff Nussbaum
          isHf: false
          isPro: false
          name: Cheesekeeper73
          type: user
        html: '<p>A full Ooba update did the trick, so it must have been more than
          just the llama component. Only just started using it, but I love the way
          this model writes. I recently found and started using a min-P preset, and
          so far it has provided the best output I have seen from all of the models
          I''ve been playing with. Highly recommended if you haven''t tried it out.
          Thanks for your help - and for the models. I check the new releases every
          day, always particularly hoping to see one of yours......</p>

          '
        raw: A full Ooba update did the trick, so it must have been more than just
          the llama component. Only just started using it, but I love the way this
          model writes. I recently found and started using a min-P preset, and so
          far it has provided the best output I have seen from all of the models I've
          been playing with. Highly recommended if you haven't tried it out. Thanks
          for your help - and for the models. I check the new releases every day,
          always particularly hoping to see one of yours......
        updatedAt: '2023-12-16T05:47:30.241Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Undi95
    id: 657d39f2504da7f6f39e2b44
    type: comment
  author: Cheesekeeper73
  content: A full Ooba update did the trick, so it must have been more than just the
    llama component. Only just started using it, but I love the way this model writes.
    I recently found and started using a min-P preset, and so far it has provided
    the best output I have seen from all of the models I've been playing with. Highly
    recommended if you haven't tried it out. Thanks for your help - and for the models.
    I check the new releases every day, always particularly hoping to see one of yours......
  created_at: 2023-12-16 05:47:30+00:00
  edited: false
  hidden: false
  id: 657d39f2504da7f6f39e2b44
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
      fullname: Devon M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Delcos
      type: user
    createdAt: '2023-12-17T23:12:26.000Z'
    data:
      edited: false
      editors:
      - Delcos
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.961966335773468
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
          fullname: Devon M
          isHf: false
          isPro: false
          name: Delcos
          type: user
        html: '<blockquote>

          <p>A full Ooba update did the trick, so it must have been more than just
          the llama component. Only just started using it, but I love the way this
          model writes. I recently found and started using a min-P preset, and so
          far it has provided the best output I have seen from all of the models I''ve
          been playing with. Highly recommended if you haven''t tried it out. Thanks
          for your help - and for the models. I check the new releases every day,
          always particularly hoping to see one of yours......</p>

          </blockquote>

          <p>Just min_p? Share if possible, ty.</p>

          '
        raw: '> A full Ooba update did the trick, so it must have been more than just
          the llama component. Only just started using it, but I love the way this
          model writes. I recently found and started using a min-P preset, and so
          far it has provided the best output I have seen from all of the models I''ve
          been playing with. Highly recommended if you haven''t tried it out. Thanks
          for your help - and for the models. I check the new releases every day,
          always particularly hoping to see one of yours......


          Just min_p? Share if possible, ty.'
        updatedAt: '2023-12-17T23:12:26.757Z'
      numEdits: 0
      reactions: []
    id: 657f805a3c65a5be2a4e69c0
    type: comment
  author: Delcos
  content: '> A full Ooba update did the trick, so it must have been more than just
    the llama component. Only just started using it, but I love the way this model
    writes. I recently found and started using a min-P preset, and so far it has provided
    the best output I have seen from all of the models I''ve been playing with. Highly
    recommended if you haven''t tried it out. Thanks for your help - and for the models.
    I check the new releases every day, always particularly hoping to see one of yours......


    Just min_p? Share if possible, ty.'
  created_at: 2023-12-17 23:12:26+00:00
  edited: false
  hidden: false
  id: 657f805a3c65a5be2a4e69c0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0337e6c32398a58a423501bcd5794d88.svg
      fullname: Geoff Nussbaum
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Cheesekeeper73
      type: user
    createdAt: '2023-12-18T08:43:49.000Z'
    data:
      edited: false
      editors:
      - Cheesekeeper73
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8643953204154968
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0337e6c32398a58a423501bcd5794d88.svg
          fullname: Geoff Nussbaum
          isHf: false
          isPro: false
          name: Cheesekeeper73
          type: user
        html: '<p>Try the settings here:<br>"<a rel="nofollow" href="https://www.reddit.com/r/LocalLLaMA/comments/17vonjo/your_settings_are_probably_hurting_your_model_why/&quot;">https://www.reddit.com/r/LocalLLaMA/comments/17vonjo/your_settings_are_probably_hurting_your_model_why/"</a></p>

          <p>I found they give a nice writing quality boost to pretty much everything.
          Would be interested to hear if you get the same impression.</p>

          '
        raw: 'Try the settings here:

          "https://www.reddit.com/r/LocalLLaMA/comments/17vonjo/your_settings_are_probably_hurting_your_model_why/"


          I found they give a nice writing quality boost to pretty much everything.
          Would be interested to hear if you get the same impression.'
        updatedAt: '2023-12-18T08:43:49.922Z'
      numEdits: 0
      reactions: []
    id: 65800645a2ef321675357922
    type: comment
  author: Cheesekeeper73
  content: 'Try the settings here:

    "https://www.reddit.com/r/LocalLLaMA/comments/17vonjo/your_settings_are_probably_hurting_your_model_why/"


    I found they give a nice writing quality boost to pretty much everything. Would
    be interested to hear if you get the same impression.'
  created_at: 2023-12-18 08:43:49+00:00
  edited: false
  hidden: false
  id: 65800645a2ef321675357922
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Undi95/Llamix2-MLewd-4x13B
repo_type: model
status: open
target_branch: null
title: How to load in text generation web ui?
