!!python/object:huggingface_hub.community.DiscussionWithDetails
author: makeColabFree
conflicting_files: null
created_at: 2023-07-19 13:11:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/004c0b46e0a545d484841c96be7dd31a.svg
      fullname: MAx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: makeColabFree
      type: user
    createdAt: '2023-07-19T14:11:40.000Z'
    data:
      edited: true
      editors:
      - makeColabFree
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9575556516647339
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/004c0b46e0a545d484841c96be7dd31a.svg
          fullname: MAx
          isHf: false
          isPro: false
          name: makeColabFree
          type: user
        html: '<p>Hi everyone,</p>

          <p>I was wondering why I recieve this error message, since I thought this
          model would support context lengths of up to 4000 tokens?</p>

          <p>Btw, thanks for open sourcing this model! :)</p>

          <p>Edit: This actually refers to the meta version.</p>

          '
        raw: 'Hi everyone,


          I was wondering why I recieve this error message, since I thought this model
          would support context lengths of up to 4000 tokens?


          Btw, thanks for open sourcing this model! :)


          Edit: This actually refers to the meta version.'
        updatedAt: '2023-07-19T14:12:52.727Z'
      numEdits: 1
      reactions: []
    id: 64b7ef1ca00eab5bcdf4f6fb
    type: comment
  author: makeColabFree
  content: 'Hi everyone,


    I was wondering why I recieve this error message, since I thought this model would
    support context lengths of up to 4000 tokens?


    Btw, thanks for open sourcing this model! :)


    Edit: This actually refers to the meta version.'
  created_at: 2023-07-19 13:11:40+00:00
  edited: true
  hidden: false
  id: 64b7ef1ca00eab5bcdf4f6fb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/620954c0c11a57389ba013d2/FlIIlobCg_OSmD4Gf0idt.jpeg?w=200&h=200&f=face
      fullname: Daryl Autar
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: daryl149
      type: user
    createdAt: '2023-07-19T14:17:31.000Z'
    data:
      edited: false
      editors:
      - daryl149
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9194161891937256
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/620954c0c11a57389ba013d2/FlIIlobCg_OSmD4Gf0idt.jpeg?w=200&h=200&f=face
          fullname: Daryl Autar
          isHf: false
          isPro: false
          name: daryl149
          type: user
        html: '<p>Please report issues with meta''s version in their own repo: <a
          rel="nofollow" href="https://github.com/facebookresearch/llama/issues/">https://github.com/facebookresearch/llama/issues/</a><br>Otherwise
          it confuses people using the weights from here.</p>

          '
        raw: 'Please report issues with meta''s version in their own repo: https://github.com/facebookresearch/llama/issues/

          Otherwise it confuses people using the weights from here.'
        updatedAt: '2023-07-19T14:17:31.131Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64b7f07bbe30d6567a87e298
    id: 64b7f07bbe30d6567a87e295
    type: comment
  author: daryl149
  content: 'Please report issues with meta''s version in their own repo: https://github.com/facebookresearch/llama/issues/

    Otherwise it confuses people using the weights from here.'
  created_at: 2023-07-19 13:17:31+00:00
  edited: false
  hidden: false
  id: 64b7f07bbe30d6567a87e295
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/620954c0c11a57389ba013d2/FlIIlobCg_OSmD4Gf0idt.jpeg?w=200&h=200&f=face
      fullname: Daryl Autar
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: daryl149
      type: user
    createdAt: '2023-07-19T14:17:31.000Z'
    data:
      status: closed
    id: 64b7f07bbe30d6567a87e298
    type: status-change
  author: daryl149
  created_at: 2023-07-19 13:17:31+00:00
  id: 64b7f07bbe30d6567a87e298
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/004c0b46e0a545d484841c96be7dd31a.svg
      fullname: MAx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: makeColabFree
      type: user
    createdAt: '2023-07-20T10:43:22.000Z'
    data:
      edited: false
      editors:
      - makeColabFree
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9302821755409241
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/004c0b46e0a545d484841c96be7dd31a.svg
          fullname: MAx
          isHf: false
          isPro: false
          name: makeColabFree
          type: user
        html: '<p>I opened an issue as suggested: <a rel="nofollow" href="https://github.com/facebookresearch/llama/issues/450">https://github.com/facebookresearch/llama/issues/450</a></p>

          <p> Do you have any trouble with input sequences longer than 1000 tokens,
          though?</p>

          '
        raw: "I opened an issue as suggested: https://github.com/facebookresearch/llama/issues/450\n\
          \n Do you have any trouble with input sequences longer than 1000 tokens,\
          \ though?"
        updatedAt: '2023-07-20T10:43:22.501Z'
      numEdits: 0
      reactions: []
    id: 64b90fca25b0493d517fd8c4
    type: comment
  author: makeColabFree
  content: "I opened an issue as suggested: https://github.com/facebookresearch/llama/issues/450\n\
    \n Do you have any trouble with input sequences longer than 1000 tokens, though?"
  created_at: 2023-07-20 09:43:22+00:00
  edited: false
  hidden: false
  id: 64b90fca25b0493d517fd8c4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: daryl149/llama-2-7b-chat-hf
repo_type: model
status: closed
target_branch: null
title: 'Error Message: "{"error":"Input validation error: `inputs` must have less
  than 1000 tokens. Given: 1254","error_type":"validation"}"'
