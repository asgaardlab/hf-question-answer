!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sanjay-dev-ds-28
conflicting_files: null
created_at: 2023-08-18 16:40:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c10d17c972493566380d6cd39eaeb05a.svg
      fullname: Sanjay
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanjay-dev-ds-28
      type: user
    createdAt: '2023-08-18T17:40:11.000Z'
    data:
      edited: false
      editors:
      - sanjay-dev-ds-28
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5038610696792603
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c10d17c972493566380d6cd39eaeb05a.svg
          fullname: Sanjay
          isHf: false
          isPro: false
          name: sanjay-dev-ds-28
          type: user
        html: '<p>!CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python
          --force-reinstall --upgrade --no-cache-dir --verbose</p>

          <p>n_gpu_layers = 40  # Change this value based on your model and your GPU
          VRAM pool.<br>n_batch = 256  # Should be between 1 and n_ctx, consider the
          amount of VRAM in your GPU.</p>

          <h1 id="loading-model">Loading model,</h1>

          <p>llm = LlamaCpp(<br>    model_path=model_path,<br>    max_tokens=256,<br>    n_gpu_layers=n_gpu_layers,<br>    n_batch=n_batch,<br>    callback_manager=callback_manager,<br>    n_ctx=1024,<br>    verbose=False,<br>)</p>

          <p>ValidationError: 1 validation error for LlamaCpp<br><strong>root</strong><br>  Could
          not load Llama model from path: /root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/47d28ef5de4f3de523c421f325a2e4e039035bab/llama-2-13b-chat.ggmlv3.q5_1.bin.
          Received error fileno (type=value_error)</p>

          '
        raw: "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python\
          \ --force-reinstall --upgrade --no-cache-dir --verbose\r\n\r\n\r\n\r\n\r\
          \nn_gpu_layers = 40  # Change this value based on your model and your GPU\
          \ VRAM pool.\r\nn_batch = 256  # Should be between 1 and n_ctx, consider\
          \ the amount of VRAM in your GPU.\r\n\r\n# Loading model,\r\nllm = LlamaCpp(\r\
          \n    model_path=model_path,\r\n    max_tokens=256,\r\n    n_gpu_layers=n_gpu_layers,\r\
          \n    n_batch=n_batch,\r\n    callback_manager=callback_manager,\r\n   \
          \ n_ctx=1024,\r\n    verbose=False,\r\n)\r\n\r\n\r\n\r\nValidationError:\
          \ 1 validation error for LlamaCpp\r\n__root__\r\n  Could not load Llama\
          \ model from path: /root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/47d28ef5de4f3de523c421f325a2e4e039035bab/llama-2-13b-chat.ggmlv3.q5_1.bin.\
          \ Received error fileno (type=value_error)"
        updatedAt: '2023-08-18T17:40:11.730Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F614"
        users:
        - zenitica
        - Brobles
        - Varosa
    id: 64dfacfb4ab6962b21a4dd50
    type: comment
  author: sanjay-dev-ds-28
  content: "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python\
    \ --force-reinstall --upgrade --no-cache-dir --verbose\r\n\r\n\r\n\r\n\r\nn_gpu_layers\
    \ = 40  # Change this value based on your model and your GPU VRAM pool.\r\nn_batch\
    \ = 256  # Should be between 1 and n_ctx, consider the amount of VRAM in your\
    \ GPU.\r\n\r\n# Loading model,\r\nllm = LlamaCpp(\r\n    model_path=model_path,\r\
    \n    max_tokens=256,\r\n    n_gpu_layers=n_gpu_layers,\r\n    n_batch=n_batch,\r\
    \n    callback_manager=callback_manager,\r\n    n_ctx=1024,\r\n    verbose=False,\r\
    \n)\r\n\r\n\r\n\r\nValidationError: 1 validation error for LlamaCpp\r\n__root__\r\
    \n  Could not load Llama model from path: /root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/47d28ef5de4f3de523c421f325a2e4e039035bab/llama-2-13b-chat.ggmlv3.q5_1.bin.\
    \ Received error fileno (type=value_error)"
  created_at: 2023-08-18 16:40:11+00:00
  edited: false
  hidden: false
  id: 64dfacfb4ab6962b21a4dd50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/38c19f7b03908e8a17a92a2940290d1e.svg
      fullname: karima
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: karimasbar
      type: user
    createdAt: '2023-08-22T16:26:22.000Z'
    data:
      edited: false
      editors:
      - karimasbar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8417139053344727
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/38c19f7b03908e8a17a92a2940290d1e.svg
          fullname: karima
          isHf: false
          isPro: false
          name: karimasbar
          type: user
        html: '<p>same problem</p>

          '
        raw: same problem
        updatedAt: '2023-08-22T16:26:22.445Z'
      numEdits: 0
      reactions: []
    id: 64e4e1ae398134c2af7fb600
    type: comment
  author: karimasbar
  content: same problem
  created_at: 2023-08-22 15:26:22+00:00
  edited: false
  hidden: false
  id: 64e4e1ae398134c2af7fb600
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ec7c46a8890442ec6d4608aad382240.svg
      fullname: Borja Robles
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Brobles
      type: user
    createdAt: '2023-08-29T14:26:59.000Z'
    data:
      edited: false
      editors:
      - Brobles
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8474408984184265
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ec7c46a8890442ec6d4608aad382240.svg
          fullname: Borja Robles
          isHf: false
          isPro: false
          name: Brobles
          type: user
        html: '<p>Same problem :(</p>

          '
        raw: Same problem :(
        updatedAt: '2023-08-29T14:26:59.152Z'
      numEdits: 0
      reactions: []
    id: 64ee00331dd80863562dc87e
    type: comment
  author: Brobles
  content: Same problem :(
  created_at: 2023-08-29 13:26:59+00:00
  edited: false
  hidden: false
  id: 64ee00331dd80863562dc87e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/950776037909f20547028242591f5879.svg
      fullname: David King
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: actionpace
      type: user
    createdAt: '2023-08-29T14:38:33.000Z'
    data:
      edited: false
      editors:
      - actionpace
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.31630629301071167
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/950776037909f20547028242591f5879.svg
          fullname: David King
          isHf: false
          isPro: false
          name: actionpace
          type: user
        html: '<p>llama.cpp and llama-cpp-python only support GGUF (not GGML) after
          a certain version - so try this<br>!CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1
          pip -qq install --upgrade --force-reinstall llama-cpp-python==0.1.78 --no-cache-dir</p>

          '
        raw: 'llama.cpp and llama-cpp-python only support GGUF (not GGML) after a
          certain version - so try this

          !CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip -qq install --upgrade
          --force-reinstall llama-cpp-python==0.1.78 --no-cache-dir'
        updatedAt: '2023-08-29T14:38:33.492Z'
      numEdits: 0
      reactions: []
    id: 64ee02e934e45674a4dc381f
    type: comment
  author: actionpace
  content: 'llama.cpp and llama-cpp-python only support GGUF (not GGML) after a certain
    version - so try this

    !CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip -qq install --upgrade --force-reinstall
    llama-cpp-python==0.1.78 --no-cache-dir'
  created_at: 2023-08-29 13:38:33+00:00
  edited: false
  hidden: false
  id: 64ee02e934e45674a4dc381f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-08-29T14:41:03.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9766017198562622
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I will be making GGUFs for these models tonight, so they''re coming
          very soon</p>

          '
        raw: I will be making GGUFs for these models tonight, so they're coming very
          soon
        updatedAt: '2023-08-29T14:41:03.877Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - Brobles
        - actionpace
    id: 64ee037f98af15326b375d78
    type: comment
  author: TheBloke
  content: I will be making GGUFs for these models tonight, so they're coming very
    soon
  created_at: 2023-08-29 13:41:03+00:00
  edited: false
  hidden: false
  id: 64ee037f98af15326b375d78
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ec7c46a8890442ec6d4608aad382240.svg
      fullname: Borja Robles
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Brobles
      type: user
    createdAt: '2023-08-29T14:46:00.000Z'
    data:
      edited: false
      editors:
      - Brobles
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5471161007881165
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ec7c46a8890442ec6d4608aad382240.svg
          fullname: Borja Robles
          isHf: false
          isPro: false
          name: Brobles
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;actionpace&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/actionpace\">@<span class=\"\
          underline\">actionpace</span></a></span>\n\n\t</span></span> tried <code>!CMAKE_ARGS=\"\
          -DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip -qq install --upgrade --force-reinstall\
          \ llama-cpp-python==0.1.78 --no-cache-dir</code> with the same result :(</p>\n\
          <p>So we will have to wait for the GGUFs versions :)</p>\n"
        raw: '@actionpace tried `!CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip
          -qq install --upgrade --force-reinstall llama-cpp-python==0.1.78 --no-cache-dir`
          with the same result :(


          So we will have to wait for the GGUFs versions :)'
        updatedAt: '2023-08-29T14:46:00.918Z'
      numEdits: 0
      reactions: []
    id: 64ee04a8604efd1e2093b836
    type: comment
  author: Brobles
  content: '@actionpace tried `!CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip -qq
    install --upgrade --force-reinstall llama-cpp-python==0.1.78 --no-cache-dir` with
    the same result :(


    So we will have to wait for the GGUFs versions :)'
  created_at: 2023-08-29 13:46:00+00:00
  edited: false
  hidden: false
  id: 64ee04a8604efd1e2093b836
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662098610747-noauth.jpeg?w=200&h=200&f=face
      fullname: Akarshan Biswas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: akarshanbiswas
      type: user
    createdAt: '2023-08-29T14:49:34.000Z'
    data:
      edited: false
      editors:
      - akarshanbiswas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9670668244361877
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662098610747-noauth.jpeg?w=200&h=200&f=face
          fullname: Akarshan Biswas
          isHf: false
          isPro: false
          name: akarshanbiswas
          type: user
        html: '<p>Have you tried my version in my repo?</p>

          '
        raw: Have you tried my version in my repo?
        updatedAt: '2023-08-29T14:49:34.332Z'
      numEdits: 0
      reactions: []
    id: 64ee057ed87d89ad1919a20a
    type: comment
  author: akarshanbiswas
  content: Have you tried my version in my repo?
  created_at: 2023-08-29 13:49:34+00:00
  edited: false
  hidden: false
  id: 64ee057ed87d89ad1919a20a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ec7c46a8890442ec6d4608aad382240.svg
      fullname: Borja Robles
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Brobles
      type: user
    createdAt: '2023-08-29T15:12:12.000Z'
    data:
      edited: false
      editors:
      - Brobles
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3511071801185608
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ec7c46a8890442ec6d4608aad382240.svg
          fullname: Borja Robles
          isHf: false
          isPro: false
          name: Brobles
          type: user
        html: "<p>yup <span data-props=\"{&quot;user&quot;:&quot;akarshanbiswas&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/akarshanbiswas\"\
          >@<span class=\"underline\">akarshanbiswas</span></a></span>\n\n\t</span></span>\
          \ same result </p>\n<pre><code>/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\
          \ in __init__(__pydantic_self__, **data)\n    339         values, fields_set,\
          \ validation_error = validate_model(__pydantic_self__.__class__, data)\n\
          \    340         if validation_error:\n--&gt; 341             raise validation_error\n\
          \    342         try:\n    343             object_setattr(__pydantic_self__,\
          \ '__dict__', values)\n\nValidationError: 1 validation error for LlamaCpp\n\
          __root__\n  Could not load Llama model from path: /root/.cache/huggingface/hub/models--akarshanbiswas--llama-2-chat-13b-gguf/snapshots/141acdcfecba05f5c0e046ee0339863fc9621004/ggml-llama-2-13b-chat-q4_k_m.gguf.\
          \ Received error fileno (type=value_error)\n</code></pre>\n"
        raw: "yup @akarshanbiswas same result \n\n```\n/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\
          \ in __init__(__pydantic_self__, **data)\n    339         values, fields_set,\
          \ validation_error = validate_model(__pydantic_self__.__class__, data)\n\
          \    340         if validation_error:\n--> 341             raise validation_error\n\
          \    342         try:\n    343             object_setattr(__pydantic_self__,\
          \ '__dict__', values)\n\nValidationError: 1 validation error for LlamaCpp\n\
          __root__\n  Could not load Llama model from path: /root/.cache/huggingface/hub/models--akarshanbiswas--llama-2-chat-13b-gguf/snapshots/141acdcfecba05f5c0e046ee0339863fc9621004/ggml-llama-2-13b-chat-q4_k_m.gguf.\
          \ Received error fileno (type=value_error)\n```"
        updatedAt: '2023-08-29T15:12:12.228Z'
      numEdits: 0
      reactions: []
    id: 64ee0acc1d7aadc1b14b5b47
    type: comment
  author: Brobles
  content: "yup @akarshanbiswas same result \n\n```\n/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\
    \ in __init__(__pydantic_self__, **data)\n    339         values, fields_set,\
    \ validation_error = validate_model(__pydantic_self__.__class__, data)\n    340\
    \         if validation_error:\n--> 341             raise validation_error\n \
    \   342         try:\n    343             object_setattr(__pydantic_self__, '__dict__',\
    \ values)\n\nValidationError: 1 validation error for LlamaCpp\n__root__\n  Could\
    \ not load Llama model from path: /root/.cache/huggingface/hub/models--akarshanbiswas--llama-2-chat-13b-gguf/snapshots/141acdcfecba05f5c0e046ee0339863fc9621004/ggml-llama-2-13b-chat-q4_k_m.gguf.\
    \ Received error fileno (type=value_error)\n```"
  created_at: 2023-08-29 14:12:12+00:00
  edited: false
  hidden: false
  id: 64ee0acc1d7aadc1b14b5b47
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662098610747-noauth.jpeg?w=200&h=200&f=face
      fullname: Akarshan Biswas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: akarshanbiswas
      type: user
    createdAt: '2023-08-29T16:03:42.000Z'
    data:
      edited: true
      editors:
      - akarshanbiswas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.18264853954315186
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662098610747-noauth.jpeg?w=200&h=200&f=face
          fullname: Akarshan Biswas
          isHf: false
          isPro: false
          name: akarshanbiswas
          type: user
        html: '<p>It works correctly here.</p>

          <p>Edit: replaced the console log with a screenshot:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/63119cc5af10c9efa1e9b620/y8dVYLYBShhmxELsdPMDZ.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/63119cc5af10c9efa1e9b620/y8dVYLYBShhmxELsdPMDZ.png"></a></p>

          <p>Which version of llama.cpp python are you using?</p>

          '
        raw: 'It works correctly here.



          Edit: replaced the console log with a screenshot:


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/63119cc5af10c9efa1e9b620/y8dVYLYBShhmxELsdPMDZ.png)


          Which version of llama.cpp python are you using?

          '
        updatedAt: '2023-08-29T16:07:55.657Z'
      numEdits: 1
      reactions: []
    id: 64ee16de6ac1fee4240b4b50
    type: comment
  author: akarshanbiswas
  content: 'It works correctly here.



    Edit: replaced the console log with a screenshot:


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/63119cc5af10c9efa1e9b620/y8dVYLYBShhmxELsdPMDZ.png)


    Which version of llama.cpp python are you using?

    '
  created_at: 2023-08-29 15:03:42+00:00
  edited: true
  hidden: false
  id: 64ee16de6ac1fee4240b4b50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ec7c46a8890442ec6d4608aad382240.svg
      fullname: Borja Robles
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Brobles
      type: user
    createdAt: '2023-08-29T16:30:41.000Z'
    data:
      edited: false
      editors:
      - Brobles
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.42099201679229736
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ec7c46a8890442ec6d4608aad382240.svg
          fullname: Borja Robles
          isHf: false
          isPro: false
          name: Brobles
          type: user
        html: "<p>I just do </p>\n<p><code>!pip install llama-cpp-python</code></p>\n\
          <p>and then </p>\n<p><code>!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1\
          \ pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir\
          \ --verbose</code></p>\n<p>also tried with</p>\n<p><code>!CMAKE_ARGS=\"\
          -DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip -qq install --upgrade --force-reinstall\
          \ llama-cpp-python==0.1.78 --no-cache-dir</code></p>\n<pre><code>model_name_or_path\
          \ = \"akarshanbiswas/llama-2-chat-13b-gguf\"\nmodel_basename = \"ggml-llama-2-13b-chat-q4_k_m.gguf\"\
          \nmodel_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n\
          \nn_gpu_layers = 40\nn_batch = 256 \n\n# Loading model,\nllm = LlamaCpp(\n\
          \    model_path=model_path,\n    max_tokens=256,\n    n_gpu_layers=n_gpu_layers,\n\
          \    n_batch=n_batch,\n    callback_manager=callback_manager,\n    n_ctx=1024,\n\
          \    verbose=False,\n)\n</code></pre>\n"
        raw: "I just do \n\n`!pip install llama-cpp-python`\n\nand then \n\n`!CMAKE_ARGS=\"\
          -DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python --force-reinstall\
          \ --upgrade --no-cache-dir --verbose`\n\nalso tried with\n\n`!CMAKE_ARGS=\"\
          -DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip -qq install --upgrade --force-reinstall\
          \ llama-cpp-python==0.1.78 --no-cache-dir`\n\n```\nmodel_name_or_path =\
          \ \"akarshanbiswas/llama-2-chat-13b-gguf\"\nmodel_basename = \"ggml-llama-2-13b-chat-q4_k_m.gguf\"\
          \nmodel_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n\
          \nn_gpu_layers = 40\nn_batch = 256 \n\n# Loading model,\nllm = LlamaCpp(\n\
          \    model_path=model_path,\n    max_tokens=256,\n    n_gpu_layers=n_gpu_layers,\n\
          \    n_batch=n_batch,\n    callback_manager=callback_manager,\n    n_ctx=1024,\n\
          \    verbose=False,\n)\n```\n\n\n"
        updatedAt: '2023-08-29T16:30:41.389Z'
      numEdits: 0
      reactions: []
    id: 64ee1d318f8f8ac22cc32929
    type: comment
  author: Brobles
  content: "I just do \n\n`!pip install llama-cpp-python`\n\nand then \n\n`!CMAKE_ARGS=\"\
    -DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python --force-reinstall\
    \ --upgrade --no-cache-dir --verbose`\n\nalso tried with\n\n`!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\"\
    \ FORCE_CMAKE=1 pip -qq install --upgrade --force-reinstall llama-cpp-python==0.1.78\
    \ --no-cache-dir`\n\n```\nmodel_name_or_path = \"akarshanbiswas/llama-2-chat-13b-gguf\"\
    \nmodel_basename = \"ggml-llama-2-13b-chat-q4_k_m.gguf\"\nmodel_path = hf_hub_download(repo_id=model_name_or_path,\
    \ filename=model_basename)\n\nn_gpu_layers = 40\nn_batch = 256 \n\n# Loading model,\n\
    llm = LlamaCpp(\n    model_path=model_path,\n    max_tokens=256,\n    n_gpu_layers=n_gpu_layers,\n\
    \    n_batch=n_batch,\n    callback_manager=callback_manager,\n    n_ctx=1024,\n\
    \    verbose=False,\n)\n```\n\n\n"
  created_at: 2023-08-29 15:30:41+00:00
  edited: false
  hidden: false
  id: 64ee1d318f8f8ac22cc32929
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662098610747-noauth.jpeg?w=200&h=200&f=face
      fullname: Akarshan Biswas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: akarshanbiswas
      type: user
    createdAt: '2023-08-29T17:16:27.000Z'
    data:
      edited: false
      editors:
      - akarshanbiswas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8707284331321716
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662098610747-noauth.jpeg?w=200&h=200&f=face
          fullname: Akarshan Biswas
          isHf: false
          isPro: false
          name: akarshanbiswas
          type: user
        html: '<p>Try downloading it using browser. Save it to a location and pass
          the file path to the class</p>

          '
        raw: Try downloading it using browser. Save it to a location and pass the
          file path to the class
        updatedAt: '2023-08-29T17:16:27.539Z'
      numEdits: 0
      reactions: []
    id: 64ee27ebad8275dcb0a33a20
    type: comment
  author: akarshanbiswas
  content: Try downloading it using browser. Save it to a location and pass the file
    path to the class
  created_at: 2023-08-29 16:16:27+00:00
  edited: false
  hidden: false
  id: 64ee27ebad8275dcb0a33a20
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ec7c46a8890442ec6d4608aad382240.svg
      fullname: Borja Robles
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Brobles
      type: user
    createdAt: '2023-08-29T19:36:53.000Z'
    data:
      edited: false
      editors:
      - Brobles
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7692365646362305
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ec7c46a8890442ec6d4608aad382240.svg
          fullname: Borja Robles
          isHf: false
          isPro: false
          name: Brobles
          type: user
        html: '<p>Same result on collab sorry :(</p>

          '
        raw: Same result on collab sorry :(
        updatedAt: '2023-08-29T19:36:53.286Z'
      numEdits: 0
      reactions: []
    id: 64ee48d5c50ab3b33995a32a
    type: comment
  author: Brobles
  content: Same result on collab sorry :(
  created_at: 2023-08-29 18:36:53+00:00
  edited: false
  hidden: false
  id: 64ee48d5c50ab3b33995a32a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64ee40e897de8d23d18c0a3d/uCQj1Gb0uU57rl1vTDefn.png?w=200&h=200&f=face
      fullname: Abe Estrada
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AbeEstrada
      type: user
    createdAt: '2023-08-29T20:10:08.000Z'
    data:
      edited: false
      editors:
      - AbeEstrada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3988971710205078
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64ee40e897de8d23d18c0a3d/uCQj1Gb0uU57rl1vTDefn.png?w=200&h=200&f=face
          fullname: Abe Estrada
          isHf: false
          isPro: false
          name: AbeEstrada
          type: user
        html: '<p>Try with:</p>

          <pre><code>curl -OL https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/resolve/main/llama-2-13b-chat.ggmlv3.q5_1.bin

          </code></pre>

          '
        raw: 'Try with:


          ```

          curl -OL https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/resolve/main/llama-2-13b-chat.ggmlv3.q5_1.bin

          ```'
        updatedAt: '2023-08-29T20:10:08.573Z'
      numEdits: 0
      reactions: []
    id: 64ee50a068616f1453e8a5a4
    type: comment
  author: AbeEstrada
  content: 'Try with:


    ```

    curl -OL https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/resolve/main/llama-2-13b-chat.ggmlv3.q5_1.bin

    ```'
  created_at: 2023-08-29 19:10:08+00:00
  edited: false
  hidden: false
  id: 64ee50a068616f1453e8a5a4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64ee40e897de8d23d18c0a3d/uCQj1Gb0uU57rl1vTDefn.png?w=200&h=200&f=face
      fullname: Abe Estrada
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AbeEstrada
      type: user
    createdAt: '2023-08-29T20:11:49.000Z'
    data:
      edited: false
      editors:
      - AbeEstrada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6809816956520081
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64ee40e897de8d23d18c0a3d/uCQj1Gb0uU57rl1vTDefn.png?w=200&h=200&f=face
          fullname: Abe Estrada
          isHf: false
          isPro: false
          name: AbeEstrada
          type: user
        html: '<p>Oh, I see, you need the GGUF version</p>

          <p><a href="https://huggingface.co/TheBloke/CodeLlama-13B-GGUF">https://huggingface.co/TheBloke/CodeLlama-13B-GGUF</a></p>

          '
        raw: 'Oh, I see, you need the GGUF version


          https://huggingface.co/TheBloke/CodeLlama-13B-GGUF'
        updatedAt: '2023-08-29T20:11:49.544Z'
      numEdits: 0
      reactions: []
    id: 64ee5105d679ae3f90fdf353
    type: comment
  author: AbeEstrada
  content: 'Oh, I see, you need the GGUF version


    https://huggingface.co/TheBloke/CodeLlama-13B-GGUF'
  created_at: 2023-08-29 19:11:49+00:00
  edited: false
  hidden: false
  id: 64ee5105d679ae3f90fdf353
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fe385d505e30ace0476e153e81cb188d.svg
      fullname: Abdelrahman Ahmed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AbdelrahmanAhmed
      type: user
    createdAt: '2023-08-30T12:19:35.000Z'
    data:
      edited: false
      editors:
      - AbdelrahmanAhmed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9857876300811768
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fe385d505e30ace0476e153e81cb188d.svg
          fullname: Abdelrahman Ahmed
          isHf: false
          isPro: false
          name: AbdelrahmanAhmed
          type: user
        html: '<p>I have the same problem and couldn''t find any solution yet</p>

          '
        raw: I have the same problem and couldn't find any solution yet
        updatedAt: '2023-08-30T12:19:35.675Z'
      numEdits: 0
      reactions: []
    id: 64ef33d70abcf3d88629d3dd
    type: comment
  author: AbdelrahmanAhmed
  content: I have the same problem and couldn't find any solution yet
  created_at: 2023-08-30 11:19:35+00:00
  edited: false
  hidden: false
  id: 64ef33d70abcf3d88629d3dd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fe385d505e30ace0476e153e81cb188d.svg
      fullname: Abdelrahman Ahmed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AbdelrahmanAhmed
      type: user
    createdAt: '2023-09-01T11:36:15.000Z'
    data:
      edited: false
      editors:
      - AbdelrahmanAhmed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6041996479034424
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fe385d505e30ace0476e153e81cb188d.svg
          fullname: Abdelrahman Ahmed
          isHf: false
          isPro: false
          name: AbdelrahmanAhmed
          type: user
        html: '<p>Fix for "Could not load Llama model from path":</p>

          <p>Download GGUF model from this link:<br><a href="https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF">https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF</a></p>

          <h1 id="code-example">Code Example:</h1>

          <p>model_name_or_path = "TheBloke/CodeLlama-13B-Python-GGUF"<br>model_basename
          = "codellama-13b-python.Q5_K_M.gguf"<br>model_path = hf_hub_download(repo_id=model_name_or_path,
          filename=model_basename)</p>

          <h1 id="then-change-verbosefalse-to-verbosetrue-like-the-following-code">Then
          Change "verbose=False" to "verbose=True" like the following code:</h1>

          <p>llm = LlamaCpp(<br>    model_path=model_path,<br>    max_tokens=256,<br>    n_gpu_layers=n_gpu_layers,<br>    n_batch=n_batch,<br>    callback_manager=callback_manager,<br>    n_ctx=1024,<br>    verbose=True,<br>)</p>

          '
        raw: "Fix for \"Could not load Llama model from path\":\n\nDownload GGUF model\
          \ from this link: \nhttps://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF\n\
          \n# Code Example:\nmodel_name_or_path = \"TheBloke/CodeLlama-13B-Python-GGUF\"\
          \nmodel_basename = \"codellama-13b-python.Q5_K_M.gguf\"\nmodel_path = hf_hub_download(repo_id=model_name_or_path,\
          \ filename=model_basename)\n\n# Then Change \"verbose=False\" to \"verbose=True\"\
          \ like the following code: \nllm = LlamaCpp(\n    model_path=model_path,\n\
          \    max_tokens=256,\n    n_gpu_layers=n_gpu_layers,\n    n_batch=n_batch,\n\
          \    callback_manager=callback_manager,\n    n_ctx=1024,\n    verbose=True,\n\
          )"
        updatedAt: '2023-09-01T11:36:15.402Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - krenova
        - dev7halo
    id: 64f1ccaf53a3c01bf1f230cb
    type: comment
  author: AbdelrahmanAhmed
  content: "Fix for \"Could not load Llama model from path\":\n\nDownload GGUF model\
    \ from this link: \nhttps://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF\n\
    \n# Code Example:\nmodel_name_or_path = \"TheBloke/CodeLlama-13B-Python-GGUF\"\
    \nmodel_basename = \"codellama-13b-python.Q5_K_M.gguf\"\nmodel_path = hf_hub_download(repo_id=model_name_or_path,\
    \ filename=model_basename)\n\n# Then Change \"verbose=False\" to \"verbose=True\"\
    \ like the following code: \nllm = LlamaCpp(\n    model_path=model_path,\n   \
    \ max_tokens=256,\n    n_gpu_layers=n_gpu_layers,\n    n_batch=n_batch,\n    callback_manager=callback_manager,\n\
    \    n_ctx=1024,\n    verbose=True,\n)"
  created_at: 2023-09-01 10:36:15+00:00
  edited: false
  hidden: false
  id: 64f1ccaf53a3c01bf1f230cb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ea07617e41fde07943b9048d45875634.svg
      fullname: Paulina John
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: paulinajohn
      type: user
    createdAt: '2023-09-06T10:34:28.000Z'
    data:
      edited: false
      editors:
      - paulinajohn
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9929368495941162
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ea07617e41fde07943b9048d45875634.svg
          fullname: Paulina John
          isHf: false
          isPro: false
          name: paulinajohn
          type: user
        html: "<p>Please <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>,\
          \ is there GGUF for 7B-Chat yet? I can't seem to find one.</p>\n"
        raw: Please @TheBloke, is there GGUF for 7B-Chat yet? I can't seem to find
          one.
        updatedAt: '2023-09-06T10:34:28.622Z'
      numEdits: 0
      reactions: []
    id: 64f855b4c3c12b377ca1b332
    type: comment
  author: paulinajohn
  content: Please @TheBloke, is there GGUF for 7B-Chat yet? I can't seem to find one.
  created_at: 2023-09-06 09:34:28+00:00
  edited: false
  hidden: false
  id: 64f855b4c3c12b377ca1b332
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-09-06T10:34:59.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.38376837968826294
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Here you go: <a href="https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF">https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF</a></p>

          '
        raw: 'Here you go: https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF'
        updatedAt: '2023-09-06T10:34:59.154Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - paulinajohn
        - ramshankerg
    id: 64f855d3e7584abc62523e1d
    type: comment
  author: TheBloke
  content: 'Here you go: https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF'
  created_at: 2023-09-06 09:34:59+00:00
  edited: false
  hidden: false
  id: 64f855d3e7584abc62523e1d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ea07617e41fde07943b9048d45875634.svg
      fullname: Paulina John
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: paulinajohn
      type: user
    createdAt: '2023-09-06T10:44:49.000Z'
    data:
      edited: false
      editors:
      - paulinajohn
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6781166195869446
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ea07617e41fde07943b9048d45875634.svg
          fullname: Paulina John
          isHf: false
          isPro: false
          name: paulinajohn
          type: user
        html: "<p>Thank you, <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ </p>\n"
        raw: 'Thank you, @TheBloke '
        updatedAt: '2023-09-06T10:44:49.858Z'
      numEdits: 0
      reactions: []
    id: 64f85821bcf14b0c9173fc37
    type: comment
  author: paulinajohn
  content: 'Thank you, @TheBloke '
  created_at: 2023-09-06 09:44:49+00:00
  edited: false
  hidden: false
  id: 64f85821bcf14b0c9173fc37
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b26392823de1fedda61ba7ead4416633.svg
      fullname: krenova
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: krenova
      type: user
    createdAt: '2023-09-15T09:44:07.000Z'
    data:
      edited: false
      editors:
      - krenova
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6641514301300049
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b26392823de1fedda61ba7ead4416633.svg
          fullname: krenova
          isHf: false
          isPro: false
          name: krenova
          type: user
        html: '<blockquote>

          <p>Fix for "Could not load Llama model from path":</p>

          <p>Download GGUF model from this link:<br><a href="https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF">https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF</a></p>

          <h1 id="code-example">Code Example:</h1>

          <p>model_name_or_path = "TheBloke/CodeLlama-13B-Python-GGUF"<br>model_basename
          = "codellama-13b-python.Q5_K_M.gguf"<br>model_path = hf_hub_download(repo_id=model_name_or_path,
          filename=model_basename)</p>

          <h1 id="then-change-verbosefalse-to-verbosetrue-like-the-following-code">Then
          Change "verbose=False" to "verbose=True" like the following code:</h1>

          <p>llm = LlamaCpp(<br>    model_path=model_path,<br>    max_tokens=256,<br>    n_gpu_layers=n_gpu_layers,<br>    n_batch=n_batch,<br>    callback_manager=callback_manager,<br>    n_ctx=1024,<br>    verbose=True,<br>)</p>

          </blockquote>

          <p>Thank you. This worked for me. Any ideas why this might be the case?</p>

          '
        raw: "> Fix for \"Could not load Llama model from path\":\n> \n> Download\
          \ GGUF model from this link: \n> https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF\n\
          > \n> # Code Example:\n> model_name_or_path = \"TheBloke/CodeLlama-13B-Python-GGUF\"\
          \n> model_basename = \"codellama-13b-python.Q5_K_M.gguf\"\n> model_path\
          \ = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n\
          > \n> # Then Change \"verbose=False\" to \"verbose=True\" like the following\
          \ code: \n> llm = LlamaCpp(\n>     model_path=model_path,\n>     max_tokens=256,\n\
          >     n_gpu_layers=n_gpu_layers,\n>     n_batch=n_batch,\n>     callback_manager=callback_manager,\n\
          >     n_ctx=1024,\n>     verbose=True,\n> )\n\nThank you. This worked for\
          \ me. Any ideas why this might be the case?"
        updatedAt: '2023-09-15T09:44:07.461Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - dev7halo
        - ramshankerg
    id: 65042767da2d88e201100541
    type: comment
  author: krenova
  content: "> Fix for \"Could not load Llama model from path\":\n> \n> Download GGUF\
    \ model from this link: \n> https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF\n\
    > \n> # Code Example:\n> model_name_or_path = \"TheBloke/CodeLlama-13B-Python-GGUF\"\
    \n> model_basename = \"codellama-13b-python.Q5_K_M.gguf\"\n> model_path = hf_hub_download(repo_id=model_name_or_path,\
    \ filename=model_basename)\n> \n> # Then Change \"verbose=False\" to \"verbose=True\"\
    \ like the following code: \n> llm = LlamaCpp(\n>     model_path=model_path,\n\
    >     max_tokens=256,\n>     n_gpu_layers=n_gpu_layers,\n>     n_batch=n_batch,\n\
    >     callback_manager=callback_manager,\n>     n_ctx=1024,\n>     verbose=True,\n\
    > )\n\nThank you. This worked for me. Any ideas why this might be the case?"
  created_at: 2023-09-15 08:44:07+00:00
  edited: false
  hidden: false
  id: 65042767da2d88e201100541
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: TheBloke/Llama-2-13B-chat-GGML
repo_type: model
status: open
target_branch: null
title: Help needed to load model
