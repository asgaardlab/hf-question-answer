!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rombodawg
conflicting_files: null
created_at: 2023-07-18 18:02:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
      fullname: rombo dawg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rombodawg
      type: user
    createdAt: '2023-07-18T19:02:08.000Z'
    data:
      edited: false
      editors:
      - rombodawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9339004158973694
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
          fullname: rombo dawg
          isHf: false
          isPro: false
          name: rombodawg
          type: user
        html: "<p>I cant believe meta just released these models! I am super exited\
          \ for the 70b param quantization. And eventually (hopefully) we'll have\
          \ a guanaco V2 \U0001F601\U0001F601</p>\n"
        raw: "I cant believe meta just released these models! I am super exited for\
          \ the 70b param quantization. And eventually (hopefully) we'll have a guanaco\
          \ V2 \U0001F601\U0001F601"
        updatedAt: '2023-07-18T19:02:08.585Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - wolfram
        - Nondzu
        - olafthefrog
        - algorithm
    id: 64b6e1b07aa8052ef2c91d21
    type: comment
  author: rombodawg
  content: "I cant believe meta just released these models! I am super exited for\
    \ the 70b param quantization. And eventually (hopefully) we'll have a guanaco\
    \ V2 \U0001F601\U0001F601"
  created_at: 2023-07-18 18:02:08+00:00
  edited: false
  hidden: false
  id: 64b6e1b07aa8052ef2c91d21
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-18T19:04:49.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.968695342540741
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yeah me too!  FYI there won''t be any Llama 2 70B GGMLs for a little
          bit, as it uses new modelling code which will need to be specially added
          to llama.cpp.  I don''t know ETA, but probably it''ll be done quite quickly
          </p>

          '
        raw: 'Yeah me too!  FYI there won''t be any Llama 2 70B GGMLs for a little
          bit, as it uses new modelling code which will need to be specially added
          to llama.cpp.  I don''t know ETA, but probably it''ll be done quite quickly '
        updatedAt: '2023-07-18T19:04:49.063Z'
      numEdits: 0
      reactions:
      - count: 9
        reaction: "\U0001F44D"
        users:
        - rombodawg
        - wolfram
        - Nondzu
        - Shinku
        - Joseph717171
        - jeffwadsworth
        - algorithm
        - lawrencewu
        - Damonts
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - martind1
        - DaTruAndi
    id: 64b6e251d3711dd619e46f36
    type: comment
  author: TheBloke
  content: 'Yeah me too!  FYI there won''t be any Llama 2 70B GGMLs for a little bit,
    as it uses new modelling code which will need to be specially added to llama.cpp.  I
    don''t know ETA, but probably it''ll be done quite quickly '
  created_at: 2023-07-18 18:04:49+00:00
  edited: false
  hidden: false
  id: 64b6e251d3711dd619e46f36
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/449e58a7d8e11555f0abb4ba3c67ec75.svg
      fullname: Wubbbi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Wubbbi
      type: user
    createdAt: '2023-07-18T20:11:51.000Z'
    data:
      edited: false
      editors:
      - Wubbbi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9651987552642822
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/449e58a7d8e11555f0abb4ba3c67ec75.svg
          fullname: Wubbbi
          isHf: false
          isPro: false
          name: Wubbbi
          type: user
        html: '<blockquote>

          <p>Yeah me too!  FYI there won''t be any Llama 2 70B GGMLs for a little
          bit, as it uses new modelling code which will need to be specially added
          to llama.cpp.  I don''t know ETA, but probably it''ll be done quite quickly</p>

          </blockquote>

          <p>My biggest dream is that my 12GB GPU would handle 70B models. Sadge times
          indeed :(</p>

          '
        raw: '> Yeah me too!  FYI there won''t be any Llama 2 70B GGMLs for a little
          bit, as it uses new modelling code which will need to be specially added
          to llama.cpp.  I don''t know ETA, but probably it''ll be done quite quickly


          My biggest dream is that my 12GB GPU would handle 70B models. Sadge times
          indeed :('
        updatedAt: '2023-07-18T20:11:51.212Z'
      numEdits: 0
      reactions: []
    id: 64b6f20753d91a364aa088f8
    type: comment
  author: Wubbbi
  content: '> Yeah me too!  FYI there won''t be any Llama 2 70B GGMLs for a little
    bit, as it uses new modelling code which will need to be specially added to llama.cpp.  I
    don''t know ETA, but probably it''ll be done quite quickly


    My biggest dream is that my 12GB GPU would handle 70B models. Sadge times indeed
    :('
  created_at: 2023-07-18 19:11:51+00:00
  edited: false
  hidden: false
  id: 64b6f20753d91a364aa088f8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a9ef52b63df40d94b30dc5b5884f37ee.svg
      fullname: Eric Skiff
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ericskiff
      type: user
    createdAt: '2023-07-18T21:09:02.000Z'
    data:
      edited: true
      editors:
      - ericskiff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9411224722862244
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a9ef52b63df40d94b30dc5b5884f37ee.svg
          fullname: Eric Skiff
          isHf: false
          isPro: false
          name: ericskiff
          type: user
        html: '<p>I pulled this down and started testing immediately, and I''m blown
          away. It''s comparing favorably with Airoboros-65B and ChatGPT-3.5 in my
          story writing tasks, and on my M2 Studio (60 GPU cores), and running inference
          at 25.89 tokens per second. The 4k context works fantastically as well</p>

          '
        raw: I pulled this down and started testing immediately, and I'm blown away.
          It's comparing favorably with Airoboros-65B and ChatGPT-3.5 in my story
          writing tasks, and on my M2 Studio (60 GPU cores), and running inference
          at 25.89 tokens per second. The 4k context works fantastically as well
        updatedAt: '2023-07-18T21:09:16.716Z'
      numEdits: 1
      reactions: []
    id: 64b6ff6e90b38df833762d37
    type: comment
  author: ericskiff
  content: I pulled this down and started testing immediately, and I'm blown away.
    It's comparing favorably with Airoboros-65B and ChatGPT-3.5 in my story writing
    tasks, and on my M2 Studio (60 GPU cores), and running inference at 25.89 tokens
    per second. The 4k context works fantastically as well
  created_at: 2023-07-18 20:09:02+00:00
  edited: true
  hidden: false
  id: 64b6ff6e90b38df833762d37
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/73817095ff29882e6448bbaf05eee03c.svg
      fullname: Timon Lankester
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 7erminalVelociraptor
      type: user
    createdAt: '2023-07-19T15:39:15.000Z'
    data:
      edited: false
      editors:
      - 7erminalVelociraptor
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9838230013847351
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/73817095ff29882e6448bbaf05eee03c.svg
          fullname: Timon Lankester
          isHf: false
          isPro: false
          name: 7erminalVelociraptor
          type: user
        html: '<p>Honestly I''m more excited to see the release of the somewhere between
          30b and 40b. For v1, even though 65b is better the sweet spot seemed to
          be around 30b/33b models, and that is also where you can find a lot of cool
          fine tunes. </p>

          '
        raw: 'Honestly I''m more excited to see the release of the somewhere between
          30b and 40b. For v1, even though 65b is better the sweet spot seemed to
          be around 30b/33b models, and that is also where you can find a lot of cool
          fine tunes. '
        updatedAt: '2023-07-19T15:39:15.550Z'
      numEdits: 0
      reactions: []
    id: 64b803a3fa7eabaae50df07c
    type: comment
  author: 7erminalVelociraptor
  content: 'Honestly I''m more excited to see the release of the somewhere between
    30b and 40b. For v1, even though 65b is better the sweet spot seemed to be around
    30b/33b models, and that is also where you can find a lot of cool fine tunes. '
  created_at: 2023-07-19 14:39:15+00:00
  edited: false
  hidden: false
  id: 64b803a3fa7eabaae50df07c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64749339e0b188d3cb2143fd/BLMB-b8o7Av2JErHEiNv6.png?w=200&h=200&f=face
      fullname: mbx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mambiux
      type: user
    createdAt: '2023-07-21T16:09:08.000Z'
    data:
      edited: true
      editors:
      - mambiux
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5262079238891602
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64749339e0b188d3cb2143fd/BLMB-b8o7Av2JErHEiNv6.png?w=200&h=200&f=face
          fullname: mbx
          isHf: false
          isPro: false
          name: mambiux
          type: user
        html: '<p>Im running Airoboros 65B llama.cpp CPU Only, on a PowerEdge R620
          maxed with a custom BabyAgi +Tool langchain implementation - and i prefer
          it to using chatgpt, no need for GPU, I feel llama2-13B is good but I would
          love to try a 70B GGML, but for now i would stick to Airoboros 65B</p>

          '
        raw: 'Im running Airoboros 65B llama.cpp CPU Only, on a PowerEdge R620 maxed
          with a custom BabyAgi +Tool langchain implementation - and i prefer it to
          using chatgpt, no need for GPU, I feel llama2-13B is good but I would love
          to try a 70B GGML, but for now i would stick to Airoboros 65B


          '
        updatedAt: '2023-07-21T16:45:10.443Z'
      numEdits: 1
      reactions: []
    id: 64baada4c6e77d66f4524eb5
    type: comment
  author: mambiux
  content: 'Im running Airoboros 65B llama.cpp CPU Only, on a PowerEdge R620 maxed
    with a custom BabyAgi +Tool langchain implementation - and i prefer it to using
    chatgpt, no need for GPU, I feel llama2-13B is good but I would love to try a
    70B GGML, but for now i would stick to Airoboros 65B


    '
  created_at: 2023-07-21 15:09:08+00:00
  edited: true
  hidden: false
  id: 64baada4c6e77d66f4524eb5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-22T17:12:41.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9880364537239075
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I tried the llama.cpp PR last night and unfortunately couldn''t
          get it working. It is being worked on though, so hopefully soon.</p>

          '
        raw: I tried the llama.cpp PR last night and unfortunately couldn't get it
          working. It is being worked on though, so hopefully soon.
        updatedAt: '2023-07-22T17:12:41.454Z'
      numEdits: 0
      reactions: []
    id: 64bc0e09e38420aabab0a4a5
    type: comment
  author: TheBloke
  content: I tried the llama.cpp PR last night and unfortunately couldn't get it working.
    It is being worked on though, so hopefully soon.
  created_at: 2023-07-22 16:12:41+00:00
  edited: false
  hidden: false
  id: 64bc0e09e38420aabab0a4a5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
      fullname: rombo dawg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rombodawg
      type: user
    createdAt: '2023-07-22T17:15:48.000Z'
    data:
      edited: false
      editors:
      - rombodawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9238768815994263
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
          fullname: rombo dawg
          isHf: false
          isPro: false
          name: rombodawg
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mambiux&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mambiux\">@<span class=\"\
          underline\">mambiux</span></a></span>\n\n\t</span></span> gauanco 65b is\
          \ a better model than airoboros, by alot, use that one</p>\n"
        raw: '@mambiux gauanco 65b is a better model than airoboros, by alot, use
          that one'
        updatedAt: '2023-07-22T17:15:48.715Z'
      numEdits: 0
      reactions: []
    id: 64bc0ec478b89c4aa4d7cc67
    type: comment
  author: rombodawg
  content: '@mambiux gauanco 65b is a better model than airoboros, by alot, use that
    one'
  created_at: 2023-07-22 16:15:48+00:00
  edited: false
  hidden: false
  id: 64bc0ec478b89c4aa4d7cc67
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64749339e0b188d3cb2143fd/BLMB-b8o7Av2JErHEiNv6.png?w=200&h=200&f=face
      fullname: mbx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mambiux
      type: user
    createdAt: '2023-07-24T21:52:45.000Z'
    data:
      edited: false
      editors:
      - mambiux
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9411577582359314
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64749339e0b188d3cb2143fd/BLMB-b8o7Av2JErHEiNv6.png?w=200&h=200&f=face
          fullname: mbx
          isHf: false
          isPro: false
          name: mambiux
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;rombodawg&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/rombodawg\">@<span class=\"\
          underline\">rombodawg</span></a></span>\n\n\t</span></span> I have tried\
          \ guanaco, my steup uses agents and tools, python scripts and some clojure\
          \ wichcraft, i have tried them all models, this have worked the best:  Airoboros-65B,\
          \ WizardLM-30B-Uncensored, 13b-chimera, superplatty-30b, Currently experimenting\
          \ with all the flavors i can get my hands on of LLama-2 but so far results\
          \ havent been great i feel it has heavy restrictions, and a really big bias\
          \ for \"As a responsible AI\" it ensures to  much of a \"safe and respectful\
          \ interaction\"</p>\n"
        raw: '@rombodawg I have tried guanaco, my steup uses agents and tools, python
          scripts and some clojure wichcraft, i have tried them all models, this have
          worked the best:  Airoboros-65B, WizardLM-30B-Uncensored, 13b-chimera, superplatty-30b,
          Currently experimenting with all the flavors i can get my hands on of LLama-2
          but so far results havent been great i feel it has heavy restrictions, and
          a really big bias for "As a responsible AI" it ensures to  much of a "safe
          and respectful interaction"

          '
        updatedAt: '2023-07-24T21:52:45.875Z'
      numEdits: 0
      reactions: []
    id: 64bef2ad805e5b645748ad0f
    type: comment
  author: mambiux
  content: '@rombodawg I have tried guanaco, my steup uses agents and tools, python
    scripts and some clojure wichcraft, i have tried them all models, this have worked
    the best:  Airoboros-65B, WizardLM-30B-Uncensored, 13b-chimera, superplatty-30b,
    Currently experimenting with all the flavors i can get my hands on of LLama-2
    but so far results havent been great i feel it has heavy restrictions, and a really
    big bias for "As a responsible AI" it ensures to  much of a "safe and respectful
    interaction"

    '
  created_at: 2023-07-24 20:52:45+00:00
  edited: false
  hidden: false
  id: 64bef2ad805e5b645748ad0f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
      fullname: rombo dawg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rombodawg
      type: user
    createdAt: '2023-07-24T22:00:14.000Z'
    data:
      edited: false
      editors:
      - rombodawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8145564794540405
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
          fullname: rombo dawg
          isHf: false
          isPro: false
          name: rombodawg
          type: user
        html: '<p>Oh yea i use it in oobagooba where you can force uncensor it with
          the "start reply with" feature</p>

          '
        raw: Oh yea i use it in oobagooba where you can force uncensor it with the
          "start reply with" feature
        updatedAt: '2023-07-24T22:00:14.281Z'
      numEdits: 0
      reactions: []
    id: 64bef46eb7375f6b8497f9ca
    type: comment
  author: rombodawg
  content: Oh yea i use it in oobagooba where you can force uncensor it with the "start
    reply with" feature
  created_at: 2023-07-24 21:00:14+00:00
  edited: false
  hidden: false
  id: 64bef46eb7375f6b8497f9ca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64749339e0b188d3cb2143fd/BLMB-b8o7Av2JErHEiNv6.png?w=200&h=200&f=face
      fullname: mbx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mambiux
      type: user
    createdAt: '2023-07-24T22:45:20.000Z'
    data:
      edited: false
      editors:
      - mambiux
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9802159070968628
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64749339e0b188d3cb2143fd/BLMB-b8o7Av2JErHEiNv6.png?w=200&h=200&f=face
          fullname: mbx
          isHf: false
          isPro: false
          name: mambiux
          type: user
        html: '<p>I see, Let just say i want to stay away from the GUI as much as
          posible, all my setup is CLI , thanks ill check out the feature</p>

          '
        raw: I see, Let just say i want to stay away from the GUI as much as posible,
          all my setup is CLI , thanks ill check out the feature
        updatedAt: '2023-07-24T22:45:20.475Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - rombodawg
    id: 64beff002915a87970b2ebab
    type: comment
  author: mambiux
  content: I see, Let just say i want to stay away from the GUI as much as posible,
    all my setup is CLI , thanks ill check out the feature
  created_at: 2023-07-24 21:45:20+00:00
  edited: false
  hidden: false
  id: 64beff002915a87970b2ebab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
      fullname: rombo dawg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rombodawg
      type: user
    createdAt: '2023-07-24T22:46:54.000Z'
    data:
      edited: false
      editors:
      - rombodawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8843188285827637
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
          fullname: rombo dawg
          isHf: false
          isPro: false
          name: rombodawg
          type: user
        html: '<p>Oh i gotcha, i personally love oobagooba, all the features and loaders
          are awesome. Especially making every single model uncensored no matter what
          is great</p>

          '
        raw: Oh i gotcha, i personally love oobagooba, all the features and loaders
          are awesome. Especially making every single model uncensored no matter what
          is great
        updatedAt: '2023-07-24T22:46:54.289Z'
      numEdits: 0
      reactions: []
    id: 64beff5eafd1e46c5545a661
    type: comment
  author: rombodawg
  content: Oh i gotcha, i personally love oobagooba, all the features and loaders
    are awesome. Especially making every single model uncensored no matter what is
    great
  created_at: 2023-07-24 21:46:54+00:00
  edited: false
  hidden: false
  id: 64beff5eafd1e46c5545a661
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Llama-2-13B-chat-GGML
repo_type: model
status: open
target_branch: null
title: Holy stuff this is huge!!!! Cant wait for 70b GGML model!!!!
