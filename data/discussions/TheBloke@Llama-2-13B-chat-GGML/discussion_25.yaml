!!python/object:huggingface_hub.community.DiscussionWithDetails
author: shivammehta
conflicting_files: null
created_at: 2023-11-17 11:46:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2e441d2ae599b51824fb9db8d2a89fff.svg
      fullname: mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shivammehta
      type: user
    createdAt: '2023-11-17T11:46:33.000Z'
    data:
      edited: true
      editors:
      - shivammehta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.96849524974823
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2e441d2ae599b51824fb9db8d2a89fff.svg
          fullname: mehta
          isHf: false
          isPro: false
          name: shivammehta
          type: user
        html: '<p>When experimenting with this model, I''ve observed occasional discrepancies
          in its output. Sometimes it provides the correct response, and sometimes
          times it doesn''t, even when presented with the same or similar questions.
          I have two inquiries: Why does this occur, and how can we address this issue?<br>For
          example -<br>Output Does not arrive at the correct answer or sometimes simply
          throws up a hallucinated answer. The highlighted block shows that the LLM
          wrongly provides the action field due to which the agent ends up saying
          its an invalid tool.</p>

          <p>Code - </p>

          <p>from huggingface_hub import hf_hub_download<br>from langchain.llms import
          LlamaCpp<br>from langchain.agents import create_csv_agent</p>

          <p>MODEL_ID = "TheBloke/Llama-2-13B-chat-GGUF"<br>MODEL_BASENAME = "llama-2-13b-chat.Q5_K_M.gguf"</p>

          <p>CONTEXT_WINDOW_SIZE = 4096<br>MAX_NEW_TOKENS = 1024</p>

          <p>model_path = hf_hub_download(<br>            repo_id=MODEL_ID,<br>            filename=MODEL_BASENAME,<br>            resume_download=True,<br>            cache_dir="./models",<br>        )<br>kwargs
          = {<br>            "model_path": model_path,<br>            "n_ctx": CONTEXT_WINDOW_SIZE,<br>            "max_tokens":
          MAX_NEW_TOKENS,<br>            "n_gpu_layers":4<br>        }<br>llm = LlamaCpp(<br>    model_path=model_path,<br>    temperature=0.1,<br>    n_ctx=4096,<br>    max_tokens=1024,<br>    n_batch=100,<br>    top_p=1,<br>    verbose=True,<br>    n_gpu_layers=100)</p>

          <p>agent = create_csv_agent(llm, [''./Data/Employees.csv'',''./Data/Verticals.csv''],
          verbose=True)<br>response = agent.run("Which vertical name has the most
          number of resignations")<br>print(response)</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6453a499fc2b5f69e8fb0fde/_J5BfFWYgAGPbq6L6XHE8.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6453a499fc2b5f69e8fb0fde/_J5BfFWYgAGPbq6L6XHE8.png"></a></p>

          <p>QUERY:</p>

          <ol>

          <li>How to correct such actions provided by the LLM ?</li>

          <li>Occasionally, we encounter OutputParserException Errors, How should
          one go about solving such errors ?</li>

          </ol>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6453a499fc2b5f69e8fb0fde/p0Tl-IArHIdFx_eyZOEO1.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6453a499fc2b5f69e8fb0fde/p0Tl-IArHIdFx_eyZOEO1.png"></a></p>

          '
        raw: "When experimenting with this model, I've observed occasional discrepancies\
          \ in its output. Sometimes it provides the correct response, and sometimes\
          \ times it doesn't, even when presented with the same or similar questions.\
          \ I have two inquiries: Why does this occur, and how can we address this\
          \ issue?\nFor example - \nOutput Does not arrive at the correct answer or\
          \ sometimes simply throws up a hallucinated answer. The highlighted block\
          \ shows that the LLM wrongly provides the action field due to which the\
          \ agent ends up saying its an invalid tool.\n\nCode - \n\nfrom huggingface_hub\
          \ import hf_hub_download\nfrom langchain.llms import LlamaCpp\nfrom langchain.agents\
          \ import create_csv_agent\n\nMODEL_ID = \"TheBloke/Llama-2-13B-chat-GGUF\"\
          \nMODEL_BASENAME = \"llama-2-13b-chat.Q5_K_M.gguf\"\n\nCONTEXT_WINDOW_SIZE\
          \ = 4096\nMAX_NEW_TOKENS = 1024\n\nmodel_path = hf_hub_download(\n     \
          \       repo_id=MODEL_ID,\n            filename=MODEL_BASENAME,\n      \
          \      resume_download=True,\n            cache_dir=\"./models\",\n    \
          \    )\nkwargs = {\n            \"model_path\": model_path,\n          \
          \  \"n_ctx\": CONTEXT_WINDOW_SIZE,\n            \"max_tokens\": MAX_NEW_TOKENS,\n\
          \            \"n_gpu_layers\":4\n        }\nllm = LlamaCpp(\n    model_path=model_path,\n\
          \    temperature=0.1,\n    n_ctx=4096,\n    max_tokens=1024,\n    n_batch=100,\n\
          \    top_p=1,\n    verbose=True,\n    n_gpu_layers=100)\n\nagent = create_csv_agent(llm,\
          \ ['./Data/Employees.csv','./Data/Verticals.csv'], verbose=True)\nresponse\
          \ = agent.run(\"Which vertical name has the most number of resignations\"\
          )\nprint(response)\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6453a499fc2b5f69e8fb0fde/_J5BfFWYgAGPbq6L6XHE8.png)\n\
          \nQUERY:\n1. How to correct such actions provided by the LLM ?\n2. Occasionally,\
          \ we encounter OutputParserException Errors, How should one go about solving\
          \ such errors ?\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6453a499fc2b5f69e8fb0fde/p0Tl-IArHIdFx_eyZOEO1.png)\n"
        updatedAt: '2023-11-17T11:56:17.349Z'
      numEdits: 1
      reactions: []
    id: 65575299776d24e3627add35
    type: comment
  author: shivammehta
  content: "When experimenting with this model, I've observed occasional discrepancies\
    \ in its output. Sometimes it provides the correct response, and sometimes times\
    \ it doesn't, even when presented with the same or similar questions. I have two\
    \ inquiries: Why does this occur, and how can we address this issue?\nFor example\
    \ - \nOutput Does not arrive at the correct answer or sometimes simply throws\
    \ up a hallucinated answer. The highlighted block shows that the LLM wrongly provides\
    \ the action field due to which the agent ends up saying its an invalid tool.\n\
    \nCode - \n\nfrom huggingface_hub import hf_hub_download\nfrom langchain.llms\
    \ import LlamaCpp\nfrom langchain.agents import create_csv_agent\n\nMODEL_ID =\
    \ \"TheBloke/Llama-2-13B-chat-GGUF\"\nMODEL_BASENAME = \"llama-2-13b-chat.Q5_K_M.gguf\"\
    \n\nCONTEXT_WINDOW_SIZE = 4096\nMAX_NEW_TOKENS = 1024\n\nmodel_path = hf_hub_download(\n\
    \            repo_id=MODEL_ID,\n            filename=MODEL_BASENAME,\n       \
    \     resume_download=True,\n            cache_dir=\"./models\",\n        )\n\
    kwargs = {\n            \"model_path\": model_path,\n            \"n_ctx\": CONTEXT_WINDOW_SIZE,\n\
    \            \"max_tokens\": MAX_NEW_TOKENS,\n            \"n_gpu_layers\":4\n\
    \        }\nllm = LlamaCpp(\n    model_path=model_path,\n    temperature=0.1,\n\
    \    n_ctx=4096,\n    max_tokens=1024,\n    n_batch=100,\n    top_p=1,\n    verbose=True,\n\
    \    n_gpu_layers=100)\n\nagent = create_csv_agent(llm, ['./Data/Employees.csv','./Data/Verticals.csv'],\
    \ verbose=True)\nresponse = agent.run(\"Which vertical name has the most number\
    \ of resignations\")\nprint(response)\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6453a499fc2b5f69e8fb0fde/_J5BfFWYgAGPbq6L6XHE8.png)\n\
    \nQUERY:\n1. How to correct such actions provided by the LLM ?\n2. Occasionally,\
    \ we encounter OutputParserException Errors, How should one go about solving such\
    \ errors ?\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6453a499fc2b5f69e8fb0fde/p0Tl-IArHIdFx_eyZOEO1.png)\n"
  created_at: 2023-11-17 11:46:33+00:00
  edited: true
  hidden: false
  id: 65575299776d24e3627add35
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 25
repo_id: TheBloke/Llama-2-13B-chat-GGML
repo_type: model
status: open
target_branch: null
title: 'Addressing Inconsistencies in Model Outputs: Understanding and Solutions'
