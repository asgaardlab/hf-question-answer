!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nsegev
conflicting_files: null
created_at: 2023-09-14 21:00:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1914f88b666d45b226db5b20908a312f.svg
      fullname: Noam
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nsegev
      type: user
    createdAt: '2023-09-14T22:00:31.000Z'
    data:
      edited: false
      editors:
      - nsegev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6830588579177856
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1914f88b666d45b226db5b20908a312f.svg
          fullname: Noam
          isHf: false
          isPro: false
          name: nsegev
          type: user
        html: '<p>I''m trying to deploy the model with 4-bit quantizaion on sagemaker
          using the following configuration:<br>config = {<br>        ''HF_MODEL_ID'':
          ''tiiuae/falcon-180B-chat'',<br>        ''SM_NUM_GPUS'': json.dumps(8),<br>        ''MAX_TOTAL_TOKENS'':
          json.dumps(2048),<br>        ''MAX_INPUT_LENGTH'': json.dumps(2048 - MAX_NEW_TOKENS),<br>        ''HUGGING_FACE_HUB_TOKEN'':
          ,<br>        ''HF_MODEL_QUANTIZE'': ''bitsandbytes-nf4'',<br>    }</p>

          <p>I''m receiving an unexpected error "NotImplementedError: Tensor Parallelism
          is not implemented for 14 not divisible by 8"<br>Looks like it comes from
          the FlashRWLargeAttention class from the line "if self.num_groups % process_group.size()
          != 0"</p>

          <p>As far as I can understand, the number 14 is n_head_kv, but why is it
          14?<br>Where is the number 14 coming from? </p>

          '
        raw: "I'm trying to deploy the model with 4-bit quantizaion on sagemaker using\
          \ the following configuration:\r\nconfig = {\r\n        'HF_MODEL_ID': 'tiiuae/falcon-180B-chat',\r\
          \n        'SM_NUM_GPUS': json.dumps(8),\r\n        'MAX_TOTAL_TOKENS': json.dumps(2048),\r\
          \n        'MAX_INPUT_LENGTH': json.dumps(2048 - MAX_NEW_TOKENS),\r\n   \
          \     'HUGGING_FACE_HUB_TOKEN': <MY_TOKEN>,\r\n        'HF_MODEL_QUANTIZE':\
          \ 'bitsandbytes-nf4',\r\n    }\r\n\r\nI'm receiving an unexpected error\
          \ \"NotImplementedError: Tensor Parallelism is not implemented for 14 not\
          \ divisible by 8\"\r\nLooks like it comes from the FlashRWLargeAttention\
          \ class from the line \"if self.num_groups % process_group.size() != 0\"\
          \r\n\r\nAs far as I can understand, the number 14 is n_head_kv, but why\
          \ is it 14?\r\nWhere is the number 14 coming from? "
        updatedAt: '2023-09-14T22:00:31.932Z'
      numEdits: 0
      reactions: []
    id: 6503827f0905dd866fcee9e1
    type: comment
  author: nsegev
  content: "I'm trying to deploy the model with 4-bit quantizaion on sagemaker using\
    \ the following configuration:\r\nconfig = {\r\n        'HF_MODEL_ID': 'tiiuae/falcon-180B-chat',\r\
    \n        'SM_NUM_GPUS': json.dumps(8),\r\n        'MAX_TOTAL_TOKENS': json.dumps(2048),\r\
    \n        'MAX_INPUT_LENGTH': json.dumps(2048 - MAX_NEW_TOKENS),\r\n        'HUGGING_FACE_HUB_TOKEN':\
    \ <MY_TOKEN>,\r\n        'HF_MODEL_QUANTIZE': 'bitsandbytes-nf4',\r\n    }\r\n\
    \r\nI'm receiving an unexpected error \"NotImplementedError: Tensor Parallelism\
    \ is not implemented for 14 not divisible by 8\"\r\nLooks like it comes from the\
    \ FlashRWLargeAttention class from the line \"if self.num_groups % process_group.size()\
    \ != 0\"\r\n\r\nAs far as I can understand, the number 14 is n_head_kv, but why\
    \ is it 14?\r\nWhere is the number 14 coming from? "
  created_at: 2023-09-14 21:00:31+00:00
  edited: false
  hidden: false
  id: 6503827f0905dd866fcee9e1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a0df37a4d60aea0d56ca9d7a911b0ba.svg
      fullname: Diogo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Diogo-V
      type: user
    createdAt: '2023-09-19T00:41:05.000Z'
    data:
      edited: false
      editors:
      - Diogo-V
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9295198917388916
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a0df37a4d60aea0d56ca9d7a911b0ba.svg
          fullname: Diogo
          isHf: false
          isPro: false
          name: Diogo-V
          type: user
        html: '<p>Getting the same error too. Any idea why this is happening and how
          can it be solved?</p>

          '
        raw: Getting the same error too. Any idea why this is happening and how can
          it be solved?
        updatedAt: '2023-09-19T00:41:05.399Z'
      numEdits: 0
      reactions: []
    id: 6508ee214afcb7378d29bc57
    type: comment
  author: Diogo-V
  content: Getting the same error too. Any idea why this is happening and how can
    it be solved?
  created_at: 2023-09-18 23:41:05+00:00
  edited: false
  hidden: false
  id: 6508ee214afcb7378d29bc57
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1914f88b666d45b226db5b20908a312f.svg
      fullname: Noam
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nsegev
      type: user
    createdAt: '2023-10-01T17:20:16.000Z'
    data:
      edited: false
      editors:
      - nsegev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9540631175041199
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1914f88b666d45b226db5b20908a312f.svg
          fullname: Noam
          isHf: false
          isPro: false
          name: nsegev
          type: user
        html: '<blockquote>

          <p>Getting the same error too. Any idea why this is happening and how can
          it be solved?</p>

          </blockquote>

          <p>It was fixed in TGI version 1.1.0 (recently released)</p>

          '
        raw: '> Getting the same error too. Any idea why this is happening and how
          can it be solved?


          It was fixed in TGI version 1.1.0 (recently released)'
        updatedAt: '2023-10-01T17:20:16.754Z'
      numEdits: 0
      reactions: []
    id: 6519aa50107446b24cb764a1
    type: comment
  author: nsegev
  content: '> Getting the same error too. Any idea why this is happening and how can
    it be solved?


    It was fixed in TGI version 1.1.0 (recently released)'
  created_at: 2023-10-01 16:20:16+00:00
  edited: false
  hidden: false
  id: 6519aa50107446b24cb764a1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: tiiuae/falcon-180B-chat
repo_type: model
status: open
target_branch: null
title: Error on num_kv_heads when using TGI
