!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tarasglek
conflicting_files: null
created_at: 2023-07-27 08:07:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/de9eb98cb434031f8bdc28608214692c.svg
      fullname: Taras Glek
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tarasglek
      type: user
    createdAt: '2023-07-27T09:07:12.000Z'
    data:
      edited: false
      editors:
      - tarasglek
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8127338290214539
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/de9eb98cb434031f8bdc28608214692c.svg
          fullname: Taras Glek
          isHf: false
          isPro: false
          name: tarasglek
          type: user
        html: '<p>I see that you have figures below 4gb. How do I reproduce that?  When
          I use BitsAndBytesConfig(load_in_4bit=True), I get memory usage of 4.3gigs
          of VRAM on cuda.</p>

          '
        raw: I see that you have figures below 4gb. How do I reproduce that?  When
          I use BitsAndBytesConfig(load_in_4bit=True), I get memory usage of 4.3gigs
          of VRAM on cuda.
        updatedAt: '2023-07-27T09:07:12.107Z'
      numEdits: 0
      reactions: []
    id: 64c233c064e3e59137dd2f63
    type: comment
  author: tarasglek
  content: I see that you have figures below 4gb. How do I reproduce that?  When I
    use BitsAndBytesConfig(load_in_4bit=True), I get memory usage of 4.3gigs of VRAM
    on cuda.
  created_at: 2023-07-27 08:07:12+00:00
  edited: false
  hidden: false
  id: 64c233c064e3e59137dd2f63
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679080567124-6414bbe095fb6f824b2035a5.jpeg?w=200&h=200&f=face
      fullname: Daria Soboleva
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: daria-soboleva
      type: user
    createdAt: '2023-07-28T22:40:13.000Z'
    data:
      edited: false
      editors:
      - daria-soboleva
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7549222707748413
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679080567124-6414bbe095fb6f824b2035a5.jpeg?w=200&h=200&f=face
          fullname: Daria Soboleva
          isHf: false
          isPro: false
          name: daria-soboleva
          type: user
        html: '<blockquote>

          <p>I see that you have figures below 4gb. How do I reproduce that?  When
          I use BitsAndBytesConfig(load_in_4bit=True), I get memory usage of 4.3gigs
          of VRAM on cuda.</p>

          </blockquote>

          <p>We used redpajama cpp</p>

          '
        raw: '> I see that you have figures below 4gb. How do I reproduce that?  When
          I use BitsAndBytesConfig(load_in_4bit=True), I get memory usage of 4.3gigs
          of VRAM on cuda.


          We used redpajama cpp'
        updatedAt: '2023-07-28T22:40:13.279Z'
      numEdits: 0
      reactions: []
    id: 64c443cd4c9bebfa6a9a5224
    type: comment
  author: daria-soboleva
  content: '> I see that you have figures below 4gb. How do I reproduce that?  When
    I use BitsAndBytesConfig(load_in_4bit=True), I get memory usage of 4.3gigs of
    VRAM on cuda.


    We used redpajama cpp'
  created_at: 2023-07-28 21:40:13+00:00
  edited: false
  hidden: false
  id: 64c443cd4c9bebfa6a9a5224
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652501708302-noauth.jpeg?w=200&h=200&f=face
      fullname: Corianas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Corianas
      type: user
    createdAt: '2023-07-31T22:45:50.000Z'
    data:
      edited: false
      editors:
      - Corianas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5530100464820862
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652501708302-noauth.jpeg?w=200&h=200&f=face
          fullname: Corianas
          isHf: false
          isPro: false
          name: Corianas
          type: user
        html: '<p>I use oobabooga/text-generation-webui.<br>on the load models page,
          select 8bit, or 4 bit, and cpu if you want. I find 8bit fits in 8gig gpu
          nicely, though not for full context window....</p>

          '
        raw: 'I use oobabooga/text-generation-webui.

          on the load models page, select 8bit, or 4 bit, and cpu if you want. I find
          8bit fits in 8gig gpu nicely, though not for full context window....

          '
        updatedAt: '2023-07-31T22:45:50.768Z'
      numEdits: 0
      reactions: []
    id: 64c8399e7dba66c3a7c20199
    type: comment
  author: Corianas
  content: 'I use oobabooga/text-generation-webui.

    on the load models page, select 8bit, or 4 bit, and cpu if you want. I find 8bit
    fits in 8gig gpu nicely, though not for full context window....

    '
  created_at: 2023-07-31 21:45:50+00:00
  edited: false
  hidden: false
  id: 64c8399e7dba66c3a7c20199
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fbdc193a07ef87e2e3388180b5eee723.svg
      fullname: Benjamin Anderson
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andersonbcdefg
      type: user
    createdAt: '2023-08-02T07:34:15.000Z'
    data:
      edited: false
      editors:
      - andersonbcdefg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9551960229873657
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fbdc193a07ef87e2e3388180b5eee723.svg
          fullname: Benjamin Anderson
          isHf: false
          isPro: false
          name: andersonbcdefg
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;daria-soboleva&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/daria-soboleva\"\
          >@<span class=\"underline\">daria-soboleva</span></a></span>\n\n\t</span></span>\
          \ would you be able to release or share code for the conversion to GGML?\
          \ it's not clear how to do that conversion with this special model that\
          \ doesn't exactly match any existing model.</p>\n"
        raw: '@daria-soboleva would you be able to release or share code for the conversion
          to GGML? it''s not clear how to do that conversion with this special model
          that doesn''t exactly match any existing model.'
        updatedAt: '2023-08-02T07:34:15.829Z'
      numEdits: 0
      reactions: []
    id: 64ca06f76c2d4ce2c9567c60
    type: comment
  author: andersonbcdefg
  content: '@daria-soboleva would you be able to release or share code for the conversion
    to GGML? it''s not clear how to do that conversion with this special model that
    doesn''t exactly match any existing model.'
  created_at: 2023-08-02 06:34:15+00:00
  edited: false
  hidden: false
  id: 64ca06f76c2d4ce2c9567c60
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679080567124-6414bbe095fb6f824b2035a5.jpeg?w=200&h=200&f=face
      fullname: Daria Soboleva
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: daria-soboleva
      type: user
    createdAt: '2023-08-02T17:53:29.000Z'
    data:
      edited: false
      editors:
      - daria-soboleva
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9461763501167297
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679080567124-6414bbe095fb6f824b2035a5.jpeg?w=200&h=200&f=face
          fullname: Daria Soboleva
          isHf: false
          isPro: false
          name: daria-soboleva
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;andersonbcdefg&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/andersonbcdefg\"\
          >@<span class=\"underline\">andersonbcdefg</span></a></span>\n\n\t</span></span>\
          \ we understand the demand that quantized version of the btlm has and def\
          \ scoping up the work to make it accessible by the community! </p>\n"
        raw: '@andersonbcdefg we understand the demand that quantized version of the
          btlm has and def scoping up the work to make it accessible by the community! '
        updatedAt: '2023-08-02T17:53:29.398Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - yahma
        - Aryanne
        - sudhir2016
    id: 64ca98190d0e2410ee6828cb
    type: comment
  author: daria-soboleva
  content: '@andersonbcdefg we understand the demand that quantized version of the
    btlm has and def scoping up the work to make it accessible by the community! '
  created_at: 2023-08-02 16:53:29+00:00
  edited: false
  hidden: false
  id: 64ca98190d0e2410ee6828cb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/24b748c32136cb291d9390abef06e96b.svg
      fullname: William Fouvy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fouvy
      type: user
    createdAt: '2023-12-03T02:00:23.000Z'
    data:
      edited: false
      editors:
      - fouvy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8895336985588074
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/24b748c32136cb291d9390abef06e96b.svg
          fullname: William Fouvy
          isHf: false
          isPro: false
          name: fouvy
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;tarasglek&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/tarasglek\">@<span class=\"\
          underline\">tarasglek</span></a></span>\n\n\t</span></span> Would you share\
          \ you code about how to load in 4bit? I got Segmentation fault (core dumped)\
          \ when I load model in quant 4bit.</p>\n"
        raw: '@tarasglek Would you share you code about how to load in 4bit? I got
          Segmentation fault (core dumped) when I load model in quant 4bit.'
        updatedAt: '2023-12-03T02:00:23.446Z'
      numEdits: 0
      reactions: []
    id: 656be137c497edf0a771fe36
    type: comment
  author: fouvy
  content: '@tarasglek Would you share you code about how to load in 4bit? I got Segmentation
    fault (core dumped) when I load model in quant 4bit.'
  created_at: 2023-12-03 02:00:23+00:00
  edited: false
  hidden: false
  id: 656be137c497edf0a771fe36
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-12-09T22:16:15.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9786926507949829
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;daria-soboleva&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/daria-soboleva\"\
          >@<span class=\"underline\">daria-soboleva</span></a></span>\n\n\t</span></span>\
          \ I'm curious about this, too. So there is a redpajama ccp, have not known\
          \ that exists.<br>did you do anything special with the library to make your\
          \ quanization work? </p>\n"
        raw: "@daria-soboleva I'm curious about this, too. So there is a redpajama\
          \ ccp, have not known that exists. \ndid you do anything special with the\
          \ library to make your quanization work? "
        updatedAt: '2023-12-09T22:16:15.038Z'
      numEdits: 0
      reactions: []
    id: 6574e72fc79162da90d3f098
    type: comment
  author: KnutJaegersberg
  content: "@daria-soboleva I'm curious about this, too. So there is a redpajama ccp,\
    \ have not known that exists. \ndid you do anything special with the library to\
    \ make your quanization work? "
  created_at: 2023-12-09 22:16:15+00:00
  edited: false
  hidden: false
  id: 6574e72fc79162da90d3f098
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: cerebras/btlm-3b-8k-base
repo_type: model
status: open
target_branch: null
title: How to reproduce quantized memory usage?
