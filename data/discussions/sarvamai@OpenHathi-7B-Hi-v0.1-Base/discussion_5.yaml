!!python/object:huggingface_hub.community.DiscussionWithDetails
author: one-thing
conflicting_files: null
created_at: 2023-12-16 15:20:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/21003427cc06fea920af3d9361d9063f.svg
      fullname: AMIT KUMAR
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: one-thing
      type: user
    createdAt: '2023-12-16T15:20:22.000Z'
    data:
      edited: true
      editors:
      - one-thing
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6041259169578552
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/21003427cc06fea920af3d9361d9063f.svg
          fullname: AMIT KUMAR
          isHf: false
          isPro: false
          name: one-thing
          type: user
        html: "<p>Tokenizer is splitting the words that are in vocab like<br>('\u2581\
          \u0935\u093F\u0927\u093E\u092F\u0915\u094B\u0902', 33821) </p>\n<p>tokenizer.tokenize(\"\
          <em>\u0935\u093F\u0927\u093E\u092F\u0915\u094B\u0902\")<br>output<br>['\u2581\
          </em>', '\u0935\u093F', '\u0927\u093E', '\u092F', '\u0915\u094B\u0902']</p>\n\
          <p>Observed this with many words : \u092C\u093F\u0936\u094D\u0928\u094B\u0908\
          \ , \u090F\u092C\u0940\u0935\u0940\u092A\u0940...... </p>\n<p><a rel=\"\
          nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/641deedd8f9507b613ec7ab7/d9ZVu2LmelV0CgFIiAFy0.png\"\
          ><img alt=\"Screenshot 2023-12-16 at 8.43.05 PM.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/641deedd8f9507b613ec7ab7/d9ZVu2LmelV0CgFIiAFy0.png\"\
          ></a></p>\n"
        raw: "Tokenizer is splitting the words that are in vocab like \n('\u2581\u0935\
          \u093F\u0927\u093E\u092F\u0915\u094B\u0902', 33821) \n\ntokenizer.tokenize(\"\
          _\u0935\u093F\u0927\u093E\u092F\u0915\u094B\u0902\")\noutput\n['\u2581_',\
          \ '\u0935\u093F', '\u0927\u093E', '\u092F', '\u0915\u094B\u0902']\n\nObserved\
          \ this with many words : \u092C\u093F\u0936\u094D\u0928\u094B\u0908 , \u090F\
          \u092C\u0940\u0935\u0940\u092A\u0940...... \n\n![Screenshot 2023-12-16 at\
          \ 8.43.05 PM.png](https://cdn-uploads.huggingface.co/production/uploads/641deedd8f9507b613ec7ab7/d9ZVu2LmelV0CgFIiAFy0.png)\n"
        updatedAt: '2023-12-16T15:21:33.976Z'
      numEdits: 1
      reactions: []
    id: 657dc03656f66469185d6576
    type: comment
  author: one-thing
  content: "Tokenizer is splitting the words that are in vocab like \n('\u2581\u0935\
    \u093F\u0927\u093E\u092F\u0915\u094B\u0902', 33821) \n\ntokenizer.tokenize(\"\
    _\u0935\u093F\u0927\u093E\u092F\u0915\u094B\u0902\")\noutput\n['\u2581_', '\u0935\
    \u093F', '\u0927\u093E', '\u092F', '\u0915\u094B\u0902']\n\nObserved this with\
    \ many words : \u092C\u093F\u0936\u094D\u0928\u094B\u0908 , \u090F\u092C\u0940\
    \u0935\u0940\u092A\u0940...... \n\n![Screenshot 2023-12-16 at 8.43.05 PM.png](https://cdn-uploads.huggingface.co/production/uploads/641deedd8f9507b613ec7ab7/d9ZVu2LmelV0CgFIiAFy0.png)\n"
  created_at: 2023-12-16 15:20:22+00:00
  edited: true
  hidden: false
  id: 657dc03656f66469185d6576
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60270a7c32856987162c641a/yNO2n0MMOiTqRaHFD2bv1.jpeg?w=200&h=200&f=face
      fullname: Rahul Aralikatte
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: rahular
      type: user
    createdAt: '2023-12-19T19:40:54.000Z'
    data:
      edited: false
      editors:
      - rahular
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8851886987686157
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60270a7c32856987162c641a/yNO2n0MMOiTqRaHFD2bv1.jpeg?w=200&h=200&f=face
          fullname: Rahul Aralikatte
          isHf: false
          isPro: false
          name: rahular
          type: user
        html: '<p>Thank you for pointing this out. It seems that letting HF auto-identify
          the tokenizer type has some issues. Please use <code>LlamaTokenizer</code>
          instead of <code>AutoTokenizer</code>.</p>

          '
        raw: Thank you for pointing this out. It seems that letting HF auto-identify
          the tokenizer type has some issues. Please use `LlamaTokenizer` instead
          of `AutoTokenizer`.
        updatedAt: '2023-12-19T19:40:54.412Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - akashmjn
    id: 6581f1c61c4454dde6c57f4a
    type: comment
  author: rahular
  content: Thank you for pointing this out. It seems that letting HF auto-identify
    the tokenizer type has some issues. Please use `LlamaTokenizer` instead of `AutoTokenizer`.
  created_at: 2023-12-19 19:40:54+00:00
  edited: false
  hidden: false
  id: 6581f1c61c4454dde6c57f4a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60270a7c32856987162c641a/yNO2n0MMOiTqRaHFD2bv1.jpeg?w=200&h=200&f=face
      fullname: Rahul Aralikatte
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: rahular
      type: user
    createdAt: '2023-12-22T20:37:06.000Z'
    data:
      status: closed
    id: 6585f372604b32d140e4c04d
    type: status-change
  author: rahular
  created_at: 2023-12-22 20:37:06+00:00
  id: 6585f372604b32d140e4c04d
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: sarvamai/OpenHathi-7B-Hi-v0.1-Base
repo_type: model
status: closed
target_branch: null
title: tokenizer splitting words those are in vocab
