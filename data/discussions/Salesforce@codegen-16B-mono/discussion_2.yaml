!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Badilator
conflicting_files: null
created_at: 2023-02-24 14:28:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/35655c0e6c7b18129f470a5948888860.svg
      fullname: Aldo Benetti
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Badilator
      type: user
    createdAt: '2023-02-24T14:28:23.000Z'
    data:
      edited: false
      editors:
      - Badilator
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/35655c0e6c7b18129f470a5948888860.svg
          fullname: Aldo Benetti
          isHf: false
          isPro: false
          name: Badilator
          type: user
        html: '<p>import sys<br>import requests<br>from kaggle_secrets import UserSecretsClient<br>user_secrets
          = UserSecretsClient()<br>YOUR_API_KEY = user_secrets.get_secret("YOUR_API_KEY")</p>

          <p>if YOUR_API_KEY == "":<br>    sys.exit("API key not found in secrets.")</p>

          <p>API_URL = "<a rel="nofollow" href="https://api-inference.huggingface.co/models/Salesforce/codegen-16B-mono&quot;">https://api-inference.huggingface.co/models/Salesforce/codegen-16B-mono"</a><br>headers
          = {"Authorization": f"Bearer {YOUR_API_KEY}"}</p>

          <p>def query(payload):<br>    response = requests.post(API_URL, headers=headers,
          json=payload)<br>    return response.json()</p>

          <p>prompt="""def download_file(url, directory):<br>    """<br>    This function
          downloads a file from a URL and saves it to a user-specified directory using
          the filename from the end of the URL.<br>    Args:<br>        url (str):
          The URL of the file to be downloaded.<br>        directory (str): The directory
          where the file should be saved. If the directory does not exist, it will
          be created.<br>    Raises:<br>        ValueError: If the URL is not valid.<br>    Returns:<br>        None<br>    """"""<br>pre_prompt="""Q:\n\nComplete
          the code of the following function:\n\n"""<br>post_prompt="\n\nA:\n\n"<br>output
          = query({<br>    "inputs": pre_prompt+prompt+post_prompt,<br>    "parameters":
          {"temperature": 0.1,<br>                   "repetition_penalty": 1.1,<br>                   "max_new_tokens":250,<br>                   "max_time":120,<br>                   "return_full_text":False,<br>                   "num_return_sequences":1,<br>                   "do_sample":True,<br>                  },<br>    "options":
          {"use_cache":False,<br>                "wait_for_model":True,<br>                },<br>})</p>

          <p>if type(output) == list:<br>    generated_text = output[0][''generated_text'']<br>else:<br>    sys.exit(output[''error''])</p>

          <p>stop_seq=''\n\n\n''<br>stop_idx = generated_text.find(stop_seq)<br>if
          stop_idx != -1:<br>    generated_text=generated_text[:stop_idx].strip()<br>else:<br>    generated_text=generated_text.strip()<br>print(post_prompt+generated_text)</p>

          '
        raw: "import sys\r\nimport requests\r\nfrom kaggle_secrets import UserSecretsClient\r\
          \nuser_secrets = UserSecretsClient()\r\nYOUR_API_KEY = user_secrets.get_secret(\"\
          YOUR_API_KEY\")\r\n\r\nif YOUR_API_KEY == \"\":\r\n    sys.exit(\"API key\
          \ not found in secrets.\")\r\n\r\nAPI_URL = \"https://api-inference.huggingface.co/models/Salesforce/codegen-16B-mono\"\
          \r\nheaders = {\"Authorization\": f\"Bearer {YOUR_API_KEY}\"}\r\n\r\ndef\
          \ query(payload):\r\n    response = requests.post(API_URL, headers=headers,\
          \ json=payload)\r\n    return response.json()\r\n\r\nprompt=\"\"\"def download_file(url,\
          \ directory):\r\n    \\\"\\\"\\\"\r\n    This function downloads a file\
          \ from a URL and saves it to a user-specified directory using the filename\
          \ from the end of the URL.  \r\n    Args:\r\n        url (str): The URL\
          \ of the file to be downloaded.\r\n        directory (str): The directory\
          \ where the file should be saved. If the directory does not exist, it will\
          \ be created.\r\n    Raises:\r\n        ValueError: If the URL is not valid.\r\
          \n    Returns:\r\n        None\r\n    \\\"\\\"\\\"\"\"\"\r\npre_prompt=\"\
          \"\"Q:\\n\\nComplete the code of the following function:\\n\\n\"\"\"\r\n\
          post_prompt=\"\\n\\nA:\\n\\n\"\r\noutput = query({\r\n    \"inputs\": pre_prompt+prompt+post_prompt,\r\
          \n    \"parameters\": {\"temperature\": 0.1,\r\n                   \"repetition_penalty\"\
          : 1.1,\r\n                   \"max_new_tokens\":250,\r\n               \
          \    \"max_time\":120,\r\n                   \"return_full_text\":False,\r\
          \n                   \"num_return_sequences\":1,\r\n                   \"\
          do_sample\":True,\r\n                  },\r\n    \"options\": {\"use_cache\"\
          :False,\r\n                \"wait_for_model\":True,\r\n                },\r\
          \n})\r\n\r\nif type(output) == list:\r\n    generated_text = output[0]['generated_text']\r\
          \nelse:\r\n    sys.exit(output['error'])\r\n    \r\nstop_seq='\\n\\n\\n'\r\
          \nstop_idx = generated_text.find(stop_seq)\r\nif stop_idx != -1:\r\n   \
          \ generated_text=generated_text[:stop_idx].strip()\r\nelse:\r\n    generated_text=generated_text.strip()\r\
          \nprint(post_prompt+generated_text)"
        updatedAt: '2023-02-24T14:28:23.384Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - glicerico
    id: 63f8c987bb0239977112b2d6
    type: comment
  author: Badilator
  content: "import sys\r\nimport requests\r\nfrom kaggle_secrets import UserSecretsClient\r\
    \nuser_secrets = UserSecretsClient()\r\nYOUR_API_KEY = user_secrets.get_secret(\"\
    YOUR_API_KEY\")\r\n\r\nif YOUR_API_KEY == \"\":\r\n    sys.exit(\"API key not\
    \ found in secrets.\")\r\n\r\nAPI_URL = \"https://api-inference.huggingface.co/models/Salesforce/codegen-16B-mono\"\
    \r\nheaders = {\"Authorization\": f\"Bearer {YOUR_API_KEY}\"}\r\n\r\ndef query(payload):\r\
    \n    response = requests.post(API_URL, headers=headers, json=payload)\r\n   \
    \ return response.json()\r\n\r\nprompt=\"\"\"def download_file(url, directory):\r\
    \n    \\\"\\\"\\\"\r\n    This function downloads a file from a URL and saves\
    \ it to a user-specified directory using the filename from the end of the URL.\
    \  \r\n    Args:\r\n        url (str): The URL of the file to be downloaded.\r\
    \n        directory (str): The directory where the file should be saved. If the\
    \ directory does not exist, it will be created.\r\n    Raises:\r\n        ValueError:\
    \ If the URL is not valid.\r\n    Returns:\r\n        None\r\n    \\\"\\\"\\\"\
    \"\"\"\r\npre_prompt=\"\"\"Q:\\n\\nComplete the code of the following function:\\\
    n\\n\"\"\"\r\npost_prompt=\"\\n\\nA:\\n\\n\"\r\noutput = query({\r\n    \"inputs\"\
    : pre_prompt+prompt+post_prompt,\r\n    \"parameters\": {\"temperature\": 0.1,\r\
    \n                   \"repetition_penalty\": 1.1,\r\n                   \"max_new_tokens\"\
    :250,\r\n                   \"max_time\":120,\r\n                   \"return_full_text\"\
    :False,\r\n                   \"num_return_sequences\":1,\r\n                \
    \   \"do_sample\":True,\r\n                  },\r\n    \"options\": {\"use_cache\"\
    :False,\r\n                \"wait_for_model\":True,\r\n                },\r\n\
    })\r\n\r\nif type(output) == list:\r\n    generated_text = output[0]['generated_text']\r\
    \nelse:\r\n    sys.exit(output['error'])\r\n    \r\nstop_seq='\\n\\n\\n'\r\nstop_idx\
    \ = generated_text.find(stop_seq)\r\nif stop_idx != -1:\r\n    generated_text=generated_text[:stop_idx].strip()\r\
    \nelse:\r\n    generated_text=generated_text.strip()\r\nprint(post_prompt+generated_text)"
  created_at: 2023-02-24 14:28:23+00:00
  edited: false
  hidden: false
  id: 63f8c987bb0239977112b2d6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3302c9feb2e5c1966b4f30002909bc6a.svg
      fullname: Patrick Deubel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pdeubel
      type: user
    createdAt: '2023-03-07T21:31:14.000Z'
    data:
      edited: false
      editors:
      - pdeubel
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3302c9feb2e5c1966b4f30002909bc6a.svg
          fullname: Patrick Deubel
          isHf: false
          isPro: false
          name: pdeubel
          type: user
        html: '<p>Your code is a bit unformatted but there might be an error when
          you define <code>prompt</code>:  After <code>"""def download_file(url, directory):</code>
          you have an additional <code>"""</code> in the next line which closes the
          string. Thus the next lines are Python interpreted.</p>

          <p>Other than that, I also have a time out: I specified <code>"options":
          {"wait_for_model": True}</code> in the API request and after some time the
          function returns but the <code>response.json()[0][''generated_text'']</code>
          has the following output:</p>

          <pre><code>''Error:M o d e l   S a l e s f o r c e / c o d e g e n - 1 6
          B - m o n o   t i m e   o u t''

          </code></pre>

          <p>I suppose the model is too large for the inference API, see <a rel="nofollow"
          href="https://discuss.huggingface.co/t/cannot-run-large-models-using-api-token/31844/2">https://discuss.huggingface.co/t/cannot-run-large-models-using-api-token/31844/2</a></p>

          '
        raw: 'Your code is a bit unformatted but there might be an error when you
          define `prompt`:  After `"""def download_file(url, directory):` you have
          an additional `"""` in the next line which closes the string. Thus the next
          lines are Python interpreted.


          Other than that, I also have a time out: I specified `"options": {"wait_for_model":
          True}` in the API request and after some time the function returns but the
          `response.json()[0][''generated_text'']` has the following output:

          ```

          ''Error:M o d e l   S a l e s f o r c e / c o d e g e n - 1 6 B - m o n
          o   t i m e   o u t''

          ```


          I suppose the model is too large for the inference API, see https://discuss.huggingface.co/t/cannot-run-large-models-using-api-token/31844/2'
        updatedAt: '2023-03-07T21:31:14.931Z'
      numEdits: 0
      reactions: []
    id: 6407ad22b6a7b1d3aaec1260
    type: comment
  author: pdeubel
  content: 'Your code is a bit unformatted but there might be an error when you define
    `prompt`:  After `"""def download_file(url, directory):` you have an additional
    `"""` in the next line which closes the string. Thus the next lines are Python
    interpreted.


    Other than that, I also have a time out: I specified `"options": {"wait_for_model":
    True}` in the API request and after some time the function returns but the `response.json()[0][''generated_text'']`
    has the following output:

    ```

    ''Error:M o d e l   S a l e s f o r c e / c o d e g e n - 1 6 B - m o n o   t
    i m e   o u t''

    ```


    I suppose the model is too large for the inference API, see https://discuss.huggingface.co/t/cannot-run-large-models-using-api-token/31844/2'
  created_at: 2023-03-07 21:31:14+00:00
  edited: false
  hidden: false
  id: 6407ad22b6a7b1d3aaec1260
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Salesforce/codegen-16B-mono
repo_type: model
status: open
target_branch: null
title: Not working  in inference api. Goes in timeout after 120 sec.
