!!python/object:huggingface_hub.community.DiscussionWithDetails
author: macadeliccc
conflicting_files: null
created_at: 2023-11-21 19:59:46+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6455cc8d679315e4ef16fbec/NcB1yDz0ZBtXXFiApnFyl.png?w=200&h=200&f=face
      fullname: Tim Dolan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: macadeliccc
      type: user
    createdAt: '2023-11-21T19:59:46.000Z'
    data:
      edited: true
      editors:
      - macadeliccc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9727743864059448
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6455cc8d679315e4ef16fbec/NcB1yDz0ZBtXXFiApnFyl.png?w=200&h=200&f=face
          fullname: Tim Dolan
          isHf: false
          isPro: false
          name: macadeliccc
          type: user
        html: '<p>Edit: Doesnt fit on 4090 at all. I had just made an assumption based
          on every other 7b model, but the demo code wasnt using cuda because it didn''t
          fit</p>

          '
        raw: 'Edit: Doesnt fit on 4090 at all. I had just made an assumption based
          on every other 7b model, but the demo code wasnt using cuda because it didn''t
          fit'
        updatedAt: '2023-11-22T02:32:34.347Z'
      numEdits: 4
      reactions: []
    id: 655d0c3289546ea4b389039f
    type: comment
  author: macadeliccc
  content: 'Edit: Doesnt fit on 4090 at all. I had just made an assumption based on
    every other 7b model, but the demo code wasnt using cuda because it didn''t fit'
  created_at: 2023-11-21 19:59:46+00:00
  edited: true
  hidden: false
  id: 655d0c3289546ea4b389039f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/93f19d73e000d2b455fdb29d5c723f23.svg
      fullname: Manuele Lucchi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gesoo99
      type: user
    createdAt: '2023-11-22T23:22:44.000Z'
    data:
      edited: false
      editors:
      - gesoo99
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9777433276176453
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/93f19d73e000d2b455fdb29d5c723f23.svg
          fullname: Manuele Lucchi
          isHf: false
          isPro: false
          name: gesoo99
          type: user
        html: '<p>I made it work on a 3050 Ti Laptop so it''s probably something with
          the settings</p>

          '
        raw: I made it work on a 3050 Ti Laptop so it's probably something with the
          settings
        updatedAt: '2023-11-22T23:22:44.805Z'
      numEdits: 0
      reactions: []
    id: 655e8d44f9829d0918e4bd19
    type: comment
  author: gesoo99
  content: I made it work on a 3050 Ti Laptop so it's probably something with the
    settings
  created_at: 2023-11-22 23:22:44+00:00
  edited: false
  hidden: false
  id: 655e8d44f9829d0918e4bd19
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6455cc8d679315e4ef16fbec/NcB1yDz0ZBtXXFiApnFyl.png?w=200&h=200&f=face
      fullname: Tim Dolan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: macadeliccc
      type: user
    createdAt: '2023-11-23T03:41:58.000Z'
    data:
      edited: false
      editors:
      - macadeliccc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9716973304748535
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6455cc8d679315e4ef16fbec/NcB1yDz0ZBtXXFiApnFyl.png?w=200&h=200&f=face
          fullname: Tim Dolan
          isHf: false
          isPro: false
          name: macadeliccc
          type: user
        html: '<p>honestly thats really weird I have not had that issue with any other
          7b model. Are you explicitly putting  the model and tokenizer onto the GPU?
          If not then its likely to just use system memory with the demo code</p>

          '
        raw: honestly thats really weird I have not had that issue with any other
          7b model. Are you explicitly putting  the model and tokenizer onto the GPU?
          If not then its likely to just use system memory with the demo code
        updatedAt: '2023-11-23T03:41:58.706Z'
      numEdits: 0
      reactions: []
    id: 655eca062ff001a46a4c1446
    type: comment
  author: macadeliccc
  content: honestly thats really weird I have not had that issue with any other 7b
    model. Are you explicitly putting  the model and tokenizer onto the GPU? If not
    then its likely to just use system memory with the demo code
  created_at: 2023-11-23 03:41:58+00:00
  edited: false
  hidden: false
  id: 655eca062ff001a46a4c1446
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12a6350562c441b57052791cbb91c611.svg
      fullname: Vasileios Kreouzis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kreouzisv
      type: user
    createdAt: '2023-11-23T15:25:37.000Z'
    data:
      edited: false
      editors:
      - kreouzisv
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9220254421234131
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12a6350562c441b57052791cbb91c611.svg
          fullname: Vasileios Kreouzis
          isHf: false
          isPro: false
          name: kreouzisv
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;macadeliccc&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/macadeliccc\"\
          >@<span class=\"underline\">macadeliccc</span></a></span>\n\n\t</span></span>\
          \  model is loaded into system memory not GPU memory, GPU memory handles\
          \ compute. I am running it on 61 GB RAM and it occupies roughly 97% of system\
          \ memory, so you would need something around that to do inference using\
          \ a 4090. </p>\n"
        raw: '@macadeliccc  model is loaded into system memory not GPU memory, GPU
          memory handles compute. I am running it on 61 GB RAM and it occupies roughly
          97% of system memory, so you would need something around that to do inference
          using a 4090. '
        updatedAt: '2023-11-23T15:25:37.315Z'
      numEdits: 0
      reactions: []
    id: 655f6ef1b9673a4249cdd6fe
    type: comment
  author: kreouzisv
  content: '@macadeliccc  model is loaded into system memory not GPU memory, GPU memory
    handles compute. I am running it on 61 GB RAM and it occupies roughly 97% of system
    memory, so you would need something around that to do inference using a 4090. '
  created_at: 2023-11-23 15:25:37+00:00
  edited: false
  hidden: false
  id: 655f6ef1b9673a4249cdd6fe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6455cc8d679315e4ef16fbec/NcB1yDz0ZBtXXFiApnFyl.png?w=200&h=200&f=face
      fullname: Tim Dolan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: macadeliccc
      type: user
    createdAt: '2023-11-23T15:52:04.000Z'
    data:
      edited: false
      editors:
      - macadeliccc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9286546111106873
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6455cc8d679315e4ef16fbec/NcB1yDz0ZBtXXFiApnFyl.png?w=200&h=200&f=face
          fullname: Tim Dolan
          isHf: false
          isPro: false
          name: macadeliccc
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;kreouzisv&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/kreouzisv\">@<span class=\"\
          underline\">kreouzisv</span></a></span>\n\n\t</span></span> Thank you. I\
          \ have just been using the 8Bit quants from TheBloke with llama.cpp and\
          \ GPU acceleration. Seems to be much more efficient than the raw model.</p>\n"
        raw: '@kreouzisv Thank you. I have just been using the 8Bit quants from TheBloke
          with llama.cpp and GPU acceleration. Seems to be much more efficient than
          the raw model.'
        updatedAt: '2023-11-23T15:52:04.388Z'
      numEdits: 0
      reactions: []
    id: 655f752434fdf07d795a0e73
    type: comment
  author: macadeliccc
  content: '@kreouzisv Thank you. I have just been using the 8Bit quants from TheBloke
    with llama.cpp and GPU acceleration. Seems to be much more efficient than the
    raw model.'
  created_at: 2023-11-23 15:52:04+00:00
  edited: false
  hidden: false
  id: 655f752434fdf07d795a0e73
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: microsoft/Orca-2-7b
repo_type: model
status: open
target_branch: null
title: Inference takes roughly 3 minutes on a 4090
