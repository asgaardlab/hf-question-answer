!!python/object:huggingface_hub.community.DiscussionWithDetails
author: robin4286
conflicting_files: null
created_at: 2023-06-08 04:40:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ea15e0b062933cc7f09f895040ccd02c.svg
      fullname: Robin Jay
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: robin4286
      type: user
    createdAt: '2023-06-08T05:40:07.000Z'
    data:
      edited: false
      editors:
      - robin4286
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5558246970176697
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ea15e0b062933cc7f09f895040ccd02c.svg
          fullname: Robin Jay
          isHf: false
          isPro: false
          name: robin4286
          type: user
        html: "<p>Hello,</p>\n<p>I am using the TheBloke Runpod config, when I leave\
          \ .safetensors I get stuff like:<br>USER: What time is it<br>ASSISTANT:\uFFFD\
          \u2011met\xC3mente SamGTzeti\uFFFD\uFFFD\uFFFD\uFFFD Dum Nueistoletr\uFFFD\
          \xD0\uFFFD\xC3\uFFFD\xC3\uFFFD\xC3\xC4Span\xC3\xC2\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\xC3\xC3\xC3</p>\n<p>But when deleting the .safetensors and using the\
          \ .pt I now get:<br>size mismatch for model.embed_tokens.weight: copying\
          \ a param with shape torch.Size([32001, 4096]) from checkpoint, the shape\
          \ in current model is torch.Size([32000, 4096]).</p>\n<p>Thank you!</p>\n"
        raw: "Hello,\r\n\r\nI am using the TheBloke Runpod config, when I leave .safetensors\
          \ I get stuff like:\r\nUSER: What time is it\r\nASSISTANT:\uFFFD\u2011met\xC3\
          mente SamGTzeti\uFFFD\uFFFD\uFFFD\uFFFD Dum Nueistoletr\uFFFD\xD0\uFFFD\xC3\
          \uFFFD\xC3\uFFFD\xC3\xC4Span\xC3\xC2\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
          \xC3\r\n\r\nBut when deleting the .safetensors and using the .pt I now get:\r\
          \nsize mismatch for model.embed_tokens.weight: copying a param with shape\
          \ torch.Size([32001, 4096]) from checkpoint, the shape in current model\
          \ is torch.Size([32000, 4096]).\r\n\r\nThank you!"
        updatedAt: '2023-06-08T05:40:07.130Z'
      numEdits: 0
      reactions: []
    id: 648169b7cacb1c4a069a58f5
    type: comment
  author: robin4286
  content: "Hello,\r\n\r\nI am using the TheBloke Runpod config, when I leave .safetensors\
    \ I get stuff like:\r\nUSER: What time is it\r\nASSISTANT:\uFFFD\u2011met\xC3\
    mente SamGTzeti\uFFFD\uFFFD\uFFFD\uFFFD Dum Nueistoletr\uFFFD\xD0\uFFFD\xC3\uFFFD\
    \xC3\uFFFD\xC3\xC4Span\xC3\xC2\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
    \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
    \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
    \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
    \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
    \xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\xC3\
    \xC3\xC3\xC3\xC3\xC3\xC3\r\n\r\nBut when deleting the .safetensors and using the\
    \ .pt I now get:\r\nsize mismatch for model.embed_tokens.weight: copying a param\
    \ with shape torch.Size([32001, 4096]) from checkpoint, the shape in current model\
    \ is torch.Size([32000, 4096]).\r\n\r\nThank you!"
  created_at: 2023-06-08 04:40:07+00:00
  edited: false
  hidden: false
  id: 648169b7cacb1c4a069a58f5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/vicuna-7B-v0-GPTQ
repo_type: model
status: open
target_branch: null
title: GPTQ Compatibility Issues with WebUI
