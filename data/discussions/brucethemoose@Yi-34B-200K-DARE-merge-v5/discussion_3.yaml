!!python/object:huggingface_hub.community.DiscussionWithDetails
author: adamo1139
conflicting_files: null
created_at: 2023-12-21 01:00:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3f7d24c9cfa2f12d2fd42fcc0a8d820a.svg
      fullname: Adam
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: adamo1139
      type: user
    createdAt: '2023-12-21T01:00:49.000Z'
    data:
      edited: false
      editors:
      - adamo1139
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8463847041130066
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3f7d24c9cfa2f12d2fd42fcc0a8d820a.svg
          fullname: Adam
          isHf: false
          isPro: false
          name: adamo1139
          type: user
        html: '<p>I was curious how this one would pan out on the leaderboard, but
          it failed evaluation for some reason.<br><a href="https://huggingface.co/datasets/open-llm-leaderboard/requests/blob/main/brucethemoose/Yi-34B-200K-DARE-merge-v5_eval_request_False_bfloat16_Original.json">https://huggingface.co/datasets/open-llm-leaderboard/requests/blob/main/brucethemoose/Yi-34B-200K-DARE-merge-v5_eval_request_False_bfloat16_Original.json</a></p>

          '
        raw: "I was curious how this one would pan out on the leaderboard, but it\
          \ failed evaluation for some reason.\r\nhttps://huggingface.co/datasets/open-llm-leaderboard/requests/blob/main/brucethemoose/Yi-34B-200K-DARE-merge-v5_eval_request_False_bfloat16_Original.json\r\
          \n"
        updatedAt: '2023-12-21T01:00:49.226Z'
      numEdits: 0
      reactions: []
    id: 65838e41948899c453967abb
    type: comment
  author: adamo1139
  content: "I was curious how this one would pan out on the leaderboard, but it failed\
    \ evaluation for some reason.\r\nhttps://huggingface.co/datasets/open-llm-leaderboard/requests/blob/main/brucethemoose/Yi-34B-200K-DARE-merge-v5_eval_request_False_bfloat16_Original.json\r\
    \n"
  created_at: 2023-12-21 01:00:49+00:00
  edited: false
  hidden: false
  id: 65838e41948899c453967abb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
      fullname: brucethemoose
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: brucethemoose
      type: user
    createdAt: '2023-12-21T02:26:45.000Z'
    data:
      edited: true
      editors:
      - brucethemoose
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9591249227523804
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
          fullname: brucethemoose
          isHf: false
          isPro: false
          name: brucethemoose
          type: user
        html: '<p>The 200K models are unreliable on the leaderboard. I think they
          can make the evaluation servers OOM because they try to load the 200k context.
          </p>

          <p>HF staff just have to manually fix it,  perhaps we should bring their
          attention to it in a post on the request page? I don''t even care about
          the leaderboard position really, I just want the best 200k model possible
          and want a datapoint against the other merges and 200Ks :P</p>

          '
        raw: "The 200K models are unreliable on the leaderboard. I think they can\
          \ make the evaluation servers OOM because they try to load the 200k context.\
          \ \n\nHF staff just have to manually fix it,  perhaps we should bring their\
          \ attention to it in a post on the request page? I don't even care about\
          \ the leaderboard position really, I just want the best 200k model possible\
          \ and want a datapoint against the other merges and 200Ks :P"
        updatedAt: '2023-12-21T02:58:48.462Z'
      numEdits: 2
      reactions: []
    id: 6583a265c327dc81ff0b6a8a
    type: comment
  author: brucethemoose
  content: "The 200K models are unreliable on the leaderboard. I think they can make\
    \ the evaluation servers OOM because they try to load the 200k context. \n\nHF\
    \ staff just have to manually fix it,  perhaps we should bring their attention\
    \ to it in a post on the request page? I don't even care about the leaderboard\
    \ position really, I just want the best 200k model possible and want a datapoint\
    \ against the other merges and 200Ks :P"
  created_at: 2023-12-21 02:26:45+00:00
  edited: true
  hidden: false
  id: 6583a265c327dc81ff0b6a8a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3f7d24c9cfa2f12d2fd42fcc0a8d820a.svg
      fullname: Adam
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: adamo1139
      type: user
    createdAt: '2023-12-21T08:52:35.000Z'
    data:
      edited: false
      editors:
      - adamo1139
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.917779266834259
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3f7d24c9cfa2f12d2fd42fcc0a8d820a.svg
          fullname: Adam
          isHf: false
          isPro: false
          name: adamo1139
          type: user
        html: '<p>I will open a discussion on the leaderboard community page about
          this later today (in 12 hours) unless I see you doing it first.<br>I assume
          you''ve tried the model yourself via exl2/gguf quants only due to limited
          vram, yes? Can you check whether it loads in transformers if you set load_in_4bit=True
          and manually edit max_position_embeddings to a lower value? I have limited
          bandwidth so I can''t download it this month to verify that myself. </p>

          '
        raw: 'I will open a discussion on the leaderboard community page about this
          later today (in 12 hours) unless I see you doing it first.

          I assume you''ve tried the model yourself via exl2/gguf quants only due
          to limited vram, yes? Can you check whether it loads in transformers if
          you set load_in_4bit=True and manually edit max_position_embeddings to a
          lower value? I have limited bandwidth so I can''t download it this month
          to verify that myself. '
        updatedAt: '2023-12-21T08:52:35.747Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - brucethemoose
    id: 6583fcd3bed3689928f91d97
    type: comment
  author: adamo1139
  content: 'I will open a discussion on the leaderboard community page about this
    later today (in 12 hours) unless I see you doing it first.

    I assume you''ve tried the model yourself via exl2/gguf quants only due to limited
    vram, yes? Can you check whether it loads in transformers if you set load_in_4bit=True
    and manually edit max_position_embeddings to a lower value? I have limited bandwidth
    so I can''t download it this month to verify that myself. '
  created_at: 2023-12-21 08:52:35+00:00
  edited: false
  hidden: false
  id: 6583fcd3bed3689928f91d97
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
      fullname: brucethemoose
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: brucethemoose
      type: user
    createdAt: '2023-12-21T08:58:39.000Z'
    data:
      edited: true
      editors:
      - brucethemoose
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9477148652076721
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
          fullname: brucethemoose
          isHf: false
          isPro: false
          name: brucethemoose
          type: user
        html: '<p>Yeah, bnb transformers is how I always test them first, before quantizing.
          In  fact I go through a few merge variants with bnb 4 bit and pick the best
          one.</p>

          <p>Transformers is quite a RAM hog at long context though. I can fit 3K
          context with bnb, and 47K context with exllamav2 4bpw.</p>

          '
        raw: 'Yeah, bnb transformers is how I always test them first, before quantizing.
          In  fact I go through a few merge variants with bnb 4 bit and pick the best
          one.


          Transformers is quite a RAM hog at long context though. I can fit 3K context
          with bnb, and 47K context with exllamav2 4bpw.'
        updatedAt: '2023-12-21T09:01:43.476Z'
      numEdits: 4
      reactions: []
    id: 6583fe3fe09e5df0308c3375
    type: comment
  author: brucethemoose
  content: 'Yeah, bnb transformers is how I always test them first, before quantizing.
    In  fact I go through a few merge variants with bnb 4 bit and pick the best one.


    Transformers is quite a RAM hog at long context though. I can fit 3K context with
    bnb, and 47K context with exllamav2 4bpw.'
  created_at: 2023-12-21 08:58:39+00:00
  edited: true
  hidden: false
  id: 6583fe3fe09e5df0308c3375
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/3f7d24c9cfa2f12d2fd42fcc0a8d820a.svg
      fullname: Adam
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: adamo1139
      type: user
    createdAt: '2023-12-28T22:36:47.000Z'
    data:
      status: closed
    id: 658df87f188f3934c6e4c6fd
    type: status-change
  author: adamo1139
  created_at: 2023-12-28 22:36:47+00:00
  id: 658df87f188f3934c6e4c6fd
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: brucethemoose/Yi-34B-200K-DARE-merge-v5
repo_type: model
status: closed
target_branch: null
title: Leaderboard evaluation failed.
