!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Firejowl
conflicting_files: null
created_at: 2023-11-08 08:56:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6522227494f3a1a209fe0ff3/u8q5HgylvERjDH3Uc-aut.png?w=200&h=200&f=face
      fullname: Sage
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Firejowl
      type: user
    createdAt: '2023-11-08T08:56:29.000Z'
    data:
      edited: false
      editors:
      - Firejowl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.931117832660675
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6522227494f3a1a209fe0ff3/u8q5HgylvERjDH3Uc-aut.png?w=200&h=200&f=face
          fullname: Sage
          isHf: false
          isPro: false
          name: Firejowl
          type: user
        html: '<p>Dear DeepSeek AI Team,</p>

          <p>Greetings! I am reaching out to discuss the DeepSeek-Coder-6.7b-Instruct
          model and how its accessibility could be further improved. As someone eager
          to utilize this model, I''ve encountered constraints due to the limitations
          of lower-end hardware. Therefore, I propose the consideration of model sharding
          as a potential enhancement.</p>

          <p>The introduction of a sharded version would be a significant step towards
          inclusivity, allowing those with less powerful machines to still take advantage
          of the model''s capabilities. This not only benefits individual hobbyists
          and researchers with resource constraints but also enhances the utility
          of the model on cloud-based platforms where optimized resource usage is
          essential, such as Google Colab and Kaggle.</p>

          <p>Understanding that model sharding entails technical complexities, I am
          hopeful that its implementation could widen the user base and foster a more
          diverse range of applications and innovations.</p>

          <p>I am keen to hear your perspective on this suggestion and any other possible
          options to assist users like myself in overcoming hardware limitations.</p>

          <p>Thank you for your pioneering work and for considering this request.</p>

          '
        raw: "Dear DeepSeek AI Team,\r\n\r\nGreetings! I am reaching out to discuss\
          \ the DeepSeek-Coder-6.7b-Instruct model and how its accessibility could\
          \ be further improved. As someone eager to utilize this model, I've encountered\
          \ constraints due to the limitations of lower-end hardware. Therefore, I\
          \ propose the consideration of model sharding as a potential enhancement.\r\
          \n\r\nThe introduction of a sharded version would be a significant step\
          \ towards inclusivity, allowing those with less powerful machines to still\
          \ take advantage of the model's capabilities. This not only benefits individual\
          \ hobbyists and researchers with resource constraints but also enhances\
          \ the utility of the model on cloud-based platforms where optimized resource\
          \ usage is essential, such as Google Colab and Kaggle.\r\n\r\nUnderstanding\
          \ that model sharding entails technical complexities, I am hopeful that\
          \ its implementation could widen the user base and foster a more diverse\
          \ range of applications and innovations.\r\n\r\nI am keen to hear your perspective\
          \ on this suggestion and any other possible options to assist users like\
          \ myself in overcoming hardware limitations.\r\n\r\nThank you for your pioneering\
          \ work and for considering this request."
        updatedAt: '2023-11-08T08:56:29.196Z'
      numEdits: 0
      reactions: []
    id: 654b4d3d52a854b7b8ebc51d
    type: comment
  author: Firejowl
  content: "Dear DeepSeek AI Team,\r\n\r\nGreetings! I am reaching out to discuss\
    \ the DeepSeek-Coder-6.7b-Instruct model and how its accessibility could be further\
    \ improved. As someone eager to utilize this model, I've encountered constraints\
    \ due to the limitations of lower-end hardware. Therefore, I propose the consideration\
    \ of model sharding as a potential enhancement.\r\n\r\nThe introduction of a sharded\
    \ version would be a significant step towards inclusivity, allowing those with\
    \ less powerful machines to still take advantage of the model's capabilities.\
    \ This not only benefits individual hobbyists and researchers with resource constraints\
    \ but also enhances the utility of the model on cloud-based platforms where optimized\
    \ resource usage is essential, such as Google Colab and Kaggle.\r\n\r\nUnderstanding\
    \ that model sharding entails technical complexities, I am hopeful that its implementation\
    \ could widen the user base and foster a more diverse range of applications and\
    \ innovations.\r\n\r\nI am keen to hear your perspective on this suggestion and\
    \ any other possible options to assist users like myself in overcoming hardware\
    \ limitations.\r\n\r\nThank you for your pioneering work and for considering this\
    \ request."
  created_at: 2023-11-08 08:56:29+00:00
  edited: false
  hidden: false
  id: 654b4d3d52a854b7b8ebc51d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6398203609f12714ed1935c2/uXgl0LgKnFYjq1Wz39-a6.jpeg?w=200&h=200&f=face
      fullname: Chester111
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Chester111
      type: user
    createdAt: '2023-11-09T07:46:38.000Z'
    data:
      edited: false
      editors:
      - Chester111
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9252910017967224
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6398203609f12714ed1935c2/uXgl0LgKnFYjq1Wz39-a6.jpeg?w=200&h=200&f=face
          fullname: Chester111
          isHf: false
          isPro: false
          name: Chester111
          type: user
        html: '<p>I don''t really get it. Do you want to finetune this model or just
          run inference with it? If you want to finetune it on low-end hardware, I''d
          recommend QLoRA algorithm; if you want to run inference only, I''d recommend
          running a quantized version of the model (e.g.: <a href="https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-AWQ">the
          one from TheBloke</a>).<br>Model Sharding is not for your use case I guess.</p>

          '
        raw: 'I don''t really get it. Do you want to finetune this model or just run
          inference with it? If you want to finetune it on low-end hardware, I''d
          recommend QLoRA algorithm; if you want to run inference only, I''d recommend
          running a quantized version of the model (e.g.: [the one from TheBloke](https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-AWQ)).

          Model Sharding is not for your use case I guess.'
        updatedAt: '2023-11-09T07:46:38.040Z'
      numEdits: 0
      reactions: []
      relatedEventId: 654c8e5e4081746099ad3d27
    id: 654c8e5e4081746099ad3d24
    type: comment
  author: Chester111
  content: 'I don''t really get it. Do you want to finetune this model or just run
    inference with it? If you want to finetune it on low-end hardware, I''d recommend
    QLoRA algorithm; if you want to run inference only, I''d recommend running a quantized
    version of the model (e.g.: [the one from TheBloke](https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-AWQ)).

    Model Sharding is not for your use case I guess.'
  created_at: 2023-11-09 07:46:38+00:00
  edited: false
  hidden: false
  id: 654c8e5e4081746099ad3d24
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6398203609f12714ed1935c2/uXgl0LgKnFYjq1Wz39-a6.jpeg?w=200&h=200&f=face
      fullname: Chester111
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Chester111
      type: user
    createdAt: '2023-11-09T07:46:38.000Z'
    data:
      status: closed
    id: 654c8e5e4081746099ad3d27
    type: status-change
  author: Chester111
  created_at: 2023-11-09 07:46:38+00:00
  id: 654c8e5e4081746099ad3d27
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6522227494f3a1a209fe0ff3/u8q5HgylvERjDH3Uc-aut.png?w=200&h=200&f=face
      fullname: Sage
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Firejowl
      type: user
    createdAt: '2023-11-09T08:36:24.000Z'
    data:
      edited: false
      editors:
      - Firejowl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8655622005462646
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6522227494f3a1a209fe0ff3/u8q5HgylvERjDH3Uc-aut.png?w=200&h=200&f=face
          fullname: Sage
          isHf: false
          isPro: false
          name: Firejowl
          type: user
        html: '<p>If you shard the model you can run it through transformers on either
          cloud platform. This removes inference rate limits and allows people who
          don''t have less financial capabilities to still access modern technology.
          </p>

          <p>Here is an example:<br><a rel="nofollow" href="https://youtu.be/c_S_KGRUzoY">https://youtu.be/c_S_KGRUzoY</a></p>

          '
        raw: "If you shard the model you can run it through transformers on either\
          \ cloud platform. This removes inference rate limits and allows people who\
          \ don't have less financial capabilities to still access modern technology.\
          \ \n\nHere is an example:\nhttps://youtu.be/c_S_KGRUzoY"
        updatedAt: '2023-11-09T08:36:24.680Z'
      numEdits: 0
      reactions: []
      relatedEventId: 654c9a081fbef019f2d6d727
    id: 654c9a081fbef019f2d6d720
    type: comment
  author: Firejowl
  content: "If you shard the model you can run it through transformers on either cloud\
    \ platform. This removes inference rate limits and allows people who don't have\
    \ less financial capabilities to still access modern technology. \n\nHere is an\
    \ example:\nhttps://youtu.be/c_S_KGRUzoY"
  created_at: 2023-11-09 08:36:24+00:00
  edited: false
  hidden: false
  id: 654c9a081fbef019f2d6d720
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6522227494f3a1a209fe0ff3/u8q5HgylvERjDH3Uc-aut.png?w=200&h=200&f=face
      fullname: Sage
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Firejowl
      type: user
    createdAt: '2023-11-09T08:36:24.000Z'
    data:
      status: open
    id: 654c9a081fbef019f2d6d727
    type: status-change
  author: Firejowl
  created_at: 2023-11-09 08:36:24+00:00
  id: 654c9a081fbef019f2d6d727
  new_status: open
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: deepseek-ai/deepseek-coder-6.7b-instruct
repo_type: model
status: open
target_branch: null
title: 'Enhancement Request: Model Sharding for DeepSeek-Coder-6.7b-Instruct'
