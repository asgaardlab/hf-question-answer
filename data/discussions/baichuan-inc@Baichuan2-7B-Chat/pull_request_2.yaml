!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tianweidut
conflicting_files: []
created_at: 2023-09-06 07:25:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f12e127a1c96301617eb9b0f4d4f21eb.svg
      fullname: liutianwei
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tianweidut
      type: user
    createdAt: '2023-09-06T08:25:03.000Z'
    data:
      edited: true
      editors:
      - tianweidut
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.488616943359375
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f12e127a1c96301617eb9b0f4d4f21eb.svg
          fullname: liutianwei
          isHf: false
          isPro: false
          name: tianweidut
          type: user
        html: '<p>Reproduce:</p>

          <pre><code class="language-python"><span class="hljs-meta">&gt;&gt;&gt;
          </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span>
          AutoModelForCausalLM

          <span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span
          class="hljs-string">"pretrained/baichuan2-7b/base,, load_in_8bit=True, device_map="</span>auto<span
          class="hljs-string">", trust_remote_code=True)</span>

          <span class="hljs-string">[2023-09-06 16:03:27,691] [INFO] [real_accelerator.py:110:get_accelerator]
          Setting ds_accelerator to cuda (auto detect)</span>

          <span class="hljs-string">2023-09-06 16:03:28.999241: I tensorflow/core/platform/cpu_feature_guard.cc:182]
          This TensorFlow binary is optimized to use available CPU instructions in
          performance-critical operations.</span>

          <span class="hljs-string">To enable the following instructions: AVX2 AVX512F
          FMA, in other operations, rebuild TensorFlow with the appropriate compiler
          flags.</span>

          <span class="hljs-string">2023-09-06 16:03:30.314803: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38]
          TF-TRT Warning: Could not find TensorRT</span>

          <span class="hljs-string">Traceback (most recent call last):</span>

          <span class="hljs-string">  File "</span>&lt;stdin&gt;<span class="hljs-string">",
          line 1, in &lt;module&gt;</span>

          <span class="hljs-string">  File "</span>/home/liutianwei/.conda/envs/starwhale/lib/python3<span
          class="hljs-number">.9</span>/site-packages/transformers/models/auto/auto_factory.py<span
          class="hljs-string">", line 488, in from_pretrained</span>

          <span class="hljs-string">    return model_class.from_pretrained(</span>

          <span class="hljs-string">  File "</span>/home/liutianwei/.cache/huggingface/modules/transformers_modules/base/modeling_baichuan.py<span
          class="hljs-string">", line 779, in from_pretrained</span>

          <span class="hljs-string">    return super(BaichuanForCausalLM, cls).from_pretrained(</span>

          <span class="hljs-string">  File "</span>/home/liutianwei/.conda/envs/starwhale/lib/python3<span
          class="hljs-number">.9</span>/site-packages/transformers/modeling_utils.py<span
          class="hljs-string">", line 2700, in from_pretrained</span>

          <span class="hljs-string">    model = cls(config, *model_args, **model_kwargs)</span>

          <span class="hljs-string">  File "</span>/home/liutianwei/.cache/huggingface/modules/transformers_modules/base/modeling_baichuan.py<span
          class="hljs-string">", line 638, in __init__</span>

          <span class="hljs-string">    and config.quantization_config["</span>load_in_4bit<span
          class="hljs-string">"]</span>

          <span class="hljs-string">TypeError: ''BitsAndBytesConfig'' object is not
          subscriptable</span>

          <span class="hljs-string">&gt;&gt;&gt; </span>

          </code></pre>

          '
        raw: "Reproduce:\n\n```python\n>>> from transformers import AutoModelForCausalLM\n\
          >>> model = AutoModelForCausalLM.from_pretrained(\"pretrained/baichuan2-7b/base,,\
          \ load_in_8bit=True, device_map=\"auto\", trust_remote_code=True)\n[2023-09-06\
          \ 16:03:27,691] [INFO] [real_accelerator.py:110:get_accelerator] Setting\
          \ ds_accelerator to cuda (auto detect)\n2023-09-06 16:03:28.999241: I tensorflow/core/platform/cpu_feature_guard.cc:182]\
          \ This TensorFlow binary is optimized to use available CPU instructions\
          \ in performance-critical operations.\nTo enable the following instructions:\
          \ AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate\
          \ compiler flags.\n2023-09-06 16:03:30.314803: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38]\
          \ TF-TRT Warning: Could not find TensorRT\nTraceback (most recent call last):\n\
          \  File \"<stdin>\", line 1, in <module>\n  File \"/home/liutianwei/.conda/envs/starwhale/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 488, in from_pretrained\n    return model_class.from_pretrained(\n\
          \  File \"/home/liutianwei/.cache/huggingface/modules/transformers_modules/base/modeling_baichuan.py\"\
          , line 779, in from_pretrained\n    return super(BaichuanForCausalLM, cls).from_pretrained(\n\
          \  File \"/home/liutianwei/.conda/envs/starwhale/lib/python3.9/site-packages/transformers/modeling_utils.py\"\
          , line 2700, in from_pretrained\n    model = cls(config, *model_args, **model_kwargs)\n\
          \  File \"/home/liutianwei/.cache/huggingface/modules/transformers_modules/base/modeling_baichuan.py\"\
          , line 638, in __init__\n    and config.quantization_config[\"load_in_4bit\"\
          ]\nTypeError: 'BitsAndBytesConfig' object is not subscriptable\n>>> \n```"
        updatedAt: '2023-09-06T08:29:13.739Z'
      numEdits: 1
      reactions: []
    id: 64f8375f20ca770b6ea83027
    type: comment
  author: tianweidut
  content: "Reproduce:\n\n```python\n>>> from transformers import AutoModelForCausalLM\n\
    >>> model = AutoModelForCausalLM.from_pretrained(\"pretrained/baichuan2-7b/base,,\
    \ load_in_8bit=True, device_map=\"auto\", trust_remote_code=True)\n[2023-09-06\
    \ 16:03:27,691] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator\
    \ to cuda (auto detect)\n2023-09-06 16:03:28.999241: I tensorflow/core/platform/cpu_feature_guard.cc:182]\
    \ This TensorFlow binary is optimized to use available CPU instructions in performance-critical\
    \ operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other\
    \ operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-09-06\
    \ 16:03:30.314803: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT\
    \ Warning: Could not find TensorRT\nTraceback (most recent call last):\n  File\
    \ \"<stdin>\", line 1, in <module>\n  File \"/home/liutianwei/.conda/envs/starwhale/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\"\
    , line 488, in from_pretrained\n    return model_class.from_pretrained(\n  File\
    \ \"/home/liutianwei/.cache/huggingface/modules/transformers_modules/base/modeling_baichuan.py\"\
    , line 779, in from_pretrained\n    return super(BaichuanForCausalLM, cls).from_pretrained(\n\
    \  File \"/home/liutianwei/.conda/envs/starwhale/lib/python3.9/site-packages/transformers/modeling_utils.py\"\
    , line 2700, in from_pretrained\n    model = cls(config, *model_args, **model_kwargs)\n\
    \  File \"/home/liutianwei/.cache/huggingface/modules/transformers_modules/base/modeling_baichuan.py\"\
    , line 638, in __init__\n    and config.quantization_config[\"load_in_4bit\"]\n\
    TypeError: 'BitsAndBytesConfig' object is not subscriptable\n>>> \n```"
  created_at: 2023-09-06 07:25:03+00:00
  edited: true
  hidden: false
  id: 64f8375f20ca770b6ea83027
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/f12e127a1c96301617eb9b0f4d4f21eb.svg
      fullname: liutianwei
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tianweidut
      type: user
    createdAt: '2023-09-06T08:25:03.000Z'
    data:
      oid: 9a7c3dced4d22873a20854bdb2bfb0514d03a9a7
      parents:
      - e7fddd32197f66aba9304659ce6fb7ca52fe2e55
      subject: fix `load_in_8bit=True` issue
    id: 64f8375f0000000000000000
    type: commit
  author: tianweidut
  created_at: 2023-09-06 07:25:03+00:00
  id: 64f8375f0000000000000000
  oid: 9a7c3dced4d22873a20854bdb2bfb0514d03a9a7
  summary: fix `load_in_8bit=True` issue
  type: commit
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/f12e127a1c96301617eb9b0f4d4f21eb.svg
      fullname: liutianwei
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tianweidut
      type: user
    createdAt: '2023-09-06T08:27:58.000Z'
    data:
      from: fix `load_in_8bit=True` issue
      to: fix 'BitsAndBytesConfig' object is not subscriptable issue
    id: 64f8380e05961fa1278113a3
    type: title-change
  author: tianweidut
  created_at: 2023-09-06 07:27:58+00:00
  id: 64f8380e05961fa1278113a3
  new_title: fix 'BitsAndBytesConfig' object is not subscriptable issue
  old_title: fix `load_in_8bit=True` issue
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/cd9725a883f4cc4ae64a3f35697e6533.svg
      fullname: wuzhiying2023
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: wuzhiying2023
      type: user
    createdAt: '2023-09-06T08:38:44.000Z'
    data:
      status: merged
    id: 64f83a94f6b80fae5aa2e4fd
    type: status-change
  author: wuzhiying2023
  created_at: 2023-09-06 07:38:44+00:00
  id: 64f83a94f6b80fae5aa2e4fd
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 2ce891951e000c36c65442608a0b95fd09b405dc
num: 2
repo_id: baichuan-inc/Baichuan2-7B-Chat
repo_type: model
status: merged
target_branch: refs/heads/main
title: fix 'BitsAndBytesConfig' object is not subscriptable issue
