!!python/object:huggingface_hub.community.DiscussionWithDetails
author: wempoo
conflicting_files: null
created_at: 2023-07-20 17:55:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b58cb4a215ee408acf929141974a94c0.svg
      fullname: DZ
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wempoo
      type: user
    createdAt: '2023-07-20T18:55:54.000Z'
    data:
      edited: false
      editors:
      - wempoo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5145999193191528
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b58cb4a215ee408acf929141974a94c0.svg
          fullname: DZ
          isHf: false
          isPro: false
          name: wempoo
          type: user
        html: '<p>I''m getting error: </p>

          <p><code>CUDA extension not installed. Traceback (most recent call last):   File
          "app.py", line 11, in &lt;module&gt;     model = AutoGPTQForCausalLM.from_quantized(model_name_or_path,   File
          "/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/auto.py",
          line 94, in from_quantized     return quant_func(   File "/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_base.py",
          line 749, in from_quantized     make_quant(   File "/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py",
          line 92, in make_quant     make_quant(   File "/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py",
          line 92, in make_quant     make_quant(   File "/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py",
          line 92, in make_quant     make_quant(   [Previous line repeated 1 more
          time]   File "/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py",
          line 84, in make_quant     new_layer = QuantLinear(   File "/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/nn_modules/qlinear/qlinear_cuda_old.py",
          line 83, in __init__     self.autogptq_cuda = autogptq_cuda_256 NameError:
          name ''autogptq_cuda_256'' is not defined</code></p>

          <p>How to fix it?</p>

          '
        raw: "I'm getting error: \r\n\r\n```CUDA extension not installed.\r\nTraceback\
          \ (most recent call last):\r\n  File \"app.py\", line 11, in <module>\r\n\
          \    model = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\r\n\
          \  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/auto.py\"\
          , line 94, in from_quantized\r\n    return quant_func(\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_base.py\"\
          , line 749, in from_quantized\r\n    make_quant(\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py\"\
          , line 92, in make_quant\r\n    make_quant(\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py\"\
          , line 92, in make_quant\r\n    make_quant(\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py\"\
          , line 92, in make_quant\r\n    make_quant(\r\n  [Previous line repeated\
          \ 1 more time]\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py\"\
          , line 84, in make_quant\r\n    new_layer = QuantLinear(\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/nn_modules/qlinear/qlinear_cuda_old.py\"\
          , line 83, in __init__\r\n    self.autogptq_cuda = autogptq_cuda_256\r\n\
          NameError: name 'autogptq_cuda_256' is not defined```\r\n\r\nHow to fix\
          \ it?"
        updatedAt: '2023-07-20T18:55:54.187Z'
      numEdits: 0
      reactions: []
    id: 64b9833a88d2d8267482c159
    type: comment
  author: wempoo
  content: "I'm getting error: \r\n\r\n```CUDA extension not installed.\r\nTraceback\
    \ (most recent call last):\r\n  File \"app.py\", line 11, in <module>\r\n    model\
    \ = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/auto.py\"\
    , line 94, in from_quantized\r\n    return quant_func(\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_base.py\"\
    , line 749, in from_quantized\r\n    make_quant(\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py\"\
    , line 92, in make_quant\r\n    make_quant(\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py\"\
    , line 92, in make_quant\r\n    make_quant(\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py\"\
    , line 92, in make_quant\r\n    make_quant(\r\n  [Previous line repeated 1 more\
    \ time]\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py\"\
    , line 84, in make_quant\r\n    new_layer = QuantLinear(\r\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/auto_gptq/nn_modules/qlinear/qlinear_cuda_old.py\"\
    , line 83, in __init__\r\n    self.autogptq_cuda = autogptq_cuda_256\r\nNameError:\
    \ name 'autogptq_cuda_256' is not defined```\r\n\r\nHow to fix it?"
  created_at: 2023-07-20 17:55:54+00:00
  edited: false
  hidden: false
  id: 64b9833a88d2d8267482c159
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-20T19:12:22.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7832194566726685
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>This error indicates AutoGPTQ is not compiling on your system.   You
          can try:</p>

          <pre><code>pip3 uninstall -y auto-gptq

          GITHUB_ACTIONS=true pip3 install auto-gptq

          </code></pre>

          <p>If that doesn''t work, please report on the AutoGPTQ Github.</p>

          '
        raw: 'This error indicates AutoGPTQ is not compiling on your system.   You
          can try:

          ```

          pip3 uninstall -y auto-gptq

          GITHUB_ACTIONS=true pip3 install auto-gptq

          ```


          If that doesn''t work, please report on the AutoGPTQ Github.'
        updatedAt: '2023-07-20T19:12:22.493Z'
      numEdits: 0
      reactions: []
    id: 64b98716008feb6c1ad57b44
    type: comment
  author: TheBloke
  content: 'This error indicates AutoGPTQ is not compiling on your system.   You can
    try:

    ```

    pip3 uninstall -y auto-gptq

    GITHUB_ACTIONS=true pip3 install auto-gptq

    ```


    If that doesn''t work, please report on the AutoGPTQ Github.'
  created_at: 2023-07-20 18:12:22+00:00
  edited: false
  hidden: false
  id: 64b98716008feb6c1ad57b44
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: TheBloke/Llama-2-70B-Chat-GPTQ
repo_type: model
status: open
target_branch: null
title: 'Error encountered: CUDA extension not installed while running.'
