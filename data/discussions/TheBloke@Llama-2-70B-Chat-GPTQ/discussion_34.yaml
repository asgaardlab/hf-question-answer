!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Teja-Gollapudi
conflicting_files: null
created_at: 2023-08-14 18:50:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62bcdae6e75a73c22a18b031/2jkNvSxIzXtpfMNfFaj9i.png?w=200&h=200&f=face
      fullname: Teja Gollapudi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Teja-Gollapudi
      type: user
    createdAt: '2023-08-14T19:50:08.000Z'
    data:
      edited: false
      editors:
      - Teja-Gollapudi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.923033595085144
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62bcdae6e75a73c22a18b031/2jkNvSxIzXtpfMNfFaj9i.png?w=200&h=200&f=face
          fullname: Teja Gollapudi
          isHf: false
          isPro: false
          name: Teja-Gollapudi
          type: user
        html: '<p>Hi,<br>Are there any benchmark comparisions for the Quantized model
          vs the full model?<br>I want to gauge the performance drop introduced by
          quantization.  </p>

          <p>Thank you!</p>

          '
        raw: "Hi, \r\nAre there any benchmark comparisions for the Quantized model\
          \ vs the full model? \r\nI want to gauge the performance drop introduced\
          \ by quantization.  \r\n\r\n\r\nThank you!"
        updatedAt: '2023-08-14T19:50:08.238Z'
      numEdits: 0
      reactions: []
    id: 64da8570d4d94f5027064b9b
    type: comment
  author: Teja-Gollapudi
  content: "Hi, \r\nAre there any benchmark comparisions for the Quantized model vs\
    \ the full model? \r\nI want to gauge the performance drop introduced by quantization.\
    \  \r\n\r\n\r\nThank you!"
  created_at: 2023-08-14 18:50:08+00:00
  edited: false
  hidden: false
  id: 64da8570d4d94f5027064b9b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62bcdae6e75a73c22a18b031/2jkNvSxIzXtpfMNfFaj9i.png?w=200&h=200&f=face
      fullname: Teja Gollapudi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Teja-Gollapudi
      type: user
    createdAt: '2023-08-14T19:50:27.000Z'
    data:
      from: 'Benchmark comparison '
      to: Performance Drop due to quantization?
    id: 64da8583322a5774e08af244
    type: title-change
  author: Teja-Gollapudi
  created_at: 2023-08-14 18:50:27+00:00
  id: 64da8583322a5774e08af244
  new_title: Performance Drop due to quantization?
  old_title: 'Benchmark comparison '
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a432cb967f96114cb4cfd9429a4ccc25.svg
      fullname: Yudhiesh Ravindranath
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yravindranath
      type: user
    createdAt: '2023-09-11T02:33:35.000Z'
    data:
      edited: true
      editors:
      - yravindranath
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7483896613121033
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a432cb967f96114cb4cfd9429a4ccc25.svg
          fullname: Yudhiesh Ravindranath
          isHf: false
          isPro: false
          name: yravindranath
          type: user
        html: '<p>Did you manage to find any comparison?</p>

          '
        raw: Did you manage to find any comparison?
        updatedAt: '2023-09-11T02:35:06.208Z'
      numEdits: 1
      reactions: []
    id: 64fe7c7f58718aaa9327ce6c
    type: comment
  author: yravindranath
  content: Did you manage to find any comparison?
  created_at: 2023-09-11 01:33:35+00:00
  edited: true
  hidden: false
  id: 64fe7c7f58718aaa9327ce6c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62bcdae6e75a73c22a18b031/2jkNvSxIzXtpfMNfFaj9i.png?w=200&h=200&f=face
      fullname: Teja Gollapudi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Teja-Gollapudi
      type: user
    createdAt: '2023-09-11T04:51:30.000Z'
    data:
      edited: false
      editors:
      - Teja-Gollapudi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9849520325660706
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62bcdae6e75a73c22a18b031/2jkNvSxIzXtpfMNfFaj9i.png?w=200&h=200&f=face
          fullname: Teja Gollapudi
          isHf: false
          isPro: false
          name: Teja-Gollapudi
          type: user
        html: "<p>Never got around to doing it \U0001F615. </p>\n"
        raw: "Never got around to doing it \U0001F615. "
        updatedAt: '2023-09-11T04:51:30.684Z'
      numEdits: 0
      reactions: []
    id: 64fe9cd28931c23ad13127fd
    type: comment
  author: Teja-Gollapudi
  content: "Never got around to doing it \U0001F615. "
  created_at: 2023-09-11 03:51:30+00:00
  edited: false
  hidden: false
  id: 64fe9cd28931c23ad13127fd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
      fullname: Yatharth  Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YaTharThShaRma999
      type: user
    createdAt: '2023-09-12T00:25:25.000Z'
    data:
      edited: false
      editors:
      - YaTharThShaRma999
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9919222593307495
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
          fullname: Yatharth  Sharma
          isHf: false
          isPro: false
          name: YaTharThShaRma999
          type: user
        html: '<p>4 bits are roughly 95 percent as accurate as full precision model
          </p>

          '
        raw: '4 bits are roughly 95 percent as accurate as full precision model '
        updatedAt: '2023-09-12T00:25:25.665Z'
      numEdits: 0
      reactions: []
    id: 64ffaff569219ce3e4853ee5
    type: comment
  author: YaTharThShaRma999
  content: '4 bits are roughly 95 percent as accurate as full precision model '
  created_at: 2023-09-11 23:25:25+00:00
  edited: false
  hidden: false
  id: 64ffaff569219ce3e4853ee5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f104f1aca89820820b4f6d843b8d9186.svg
      fullname: Eslam Hussein
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ehussein
      type: user
    createdAt: '2023-09-21T03:39:28.000Z'
    data:
      edited: false
      editors:
      - ehussein
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6739545464515686
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f104f1aca89820820b4f6d843b8d9186.svg
          fullname: Eslam Hussein
          isHf: false
          isPro: false
          name: ehussein
          type: user
        html: '<p>I found a couple of subreddits discussing that topic:</p>

          <p><a rel="nofollow" href="https://www.reddit.com/r/LocalLLaMA/comments/15zz81s/llama2_quantized_model_vs_regular_one_whats_the/">https://www.reddit.com/r/LocalLLaMA/comments/15zz81s/llama2_quantized_model_vs_regular_one_whats_the/</a></p>

          <p><a rel="nofollow" href="https://www.reddit.com/r/LocalLLaMA/comments/15rh3op/effects_of_quantization_of_arc_benchmark/?utm_source=share&amp;utm_medium=android_app&amp;utm_name=androidcss&amp;utm_term=1&amp;utm_content=1">https://www.reddit.com/r/LocalLLaMA/comments/15rh3op/effects_of_quantization_of_arc_benchmark/?utm_source=share&amp;utm_medium=android_app&amp;utm_name=androidcss&amp;utm_term=1&amp;utm_content=1</a></p>

          '
        raw: 'I found a couple of subreddits discussing that topic:


          https://www.reddit.com/r/LocalLLaMA/comments/15zz81s/llama2_quantized_model_vs_regular_one_whats_the/


          https://www.reddit.com/r/LocalLLaMA/comments/15rh3op/effects_of_quantization_of_arc_benchmark/?utm_source=share&utm_medium=android_app&utm_name=androidcss&utm_term=1&utm_content=1'
        updatedAt: '2023-09-21T03:39:28.457Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - MaziyarPanahi
    id: 650bbaf0a5a63e427ad02577
    type: comment
  author: ehussein
  content: 'I found a couple of subreddits discussing that topic:


    https://www.reddit.com/r/LocalLLaMA/comments/15zz81s/llama2_quantized_model_vs_regular_one_whats_the/


    https://www.reddit.com/r/LocalLLaMA/comments/15rh3op/effects_of_quantization_of_arc_benchmark/?utm_source=share&utm_medium=android_app&utm_name=androidcss&utm_term=1&utm_content=1'
  created_at: 2023-09-21 02:39:28+00:00
  edited: false
  hidden: false
  id: 650bbaf0a5a63e427ad02577
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 34
repo_id: TheBloke/Llama-2-70B-Chat-GPTQ
repo_type: model
status: open
target_branch: null
title: Performance Drop due to quantization?
