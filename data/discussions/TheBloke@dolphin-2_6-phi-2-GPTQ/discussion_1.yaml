!!python/object:huggingface_hub.community.DiscussionWithDetails
author: awelker
conflicting_files: null
created_at: 2024-01-03 15:18:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/29b6e2dc31d7a3194ff957418a515533.svg
      fullname: Andree
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: awelker
      type: user
    createdAt: '2024-01-03T15:18:23.000Z'
    data:
      edited: false
      editors:
      - awelker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5178960561752319
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/29b6e2dc31d7a3194ff957418a515533.svg
          fullname: Andree
          isHf: false
          isPro: false
          name: awelker
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> tried with several\
          \ ways to load it but wasn't able to. Could you please have a look at it?</p>\n\
          <p>Thanks in advance.<br>e.g. ExLlamav2 error log<br>Traceback (most recent\
          \ call last):</p>\n<p>File \"...\\text-generation-webui\\modules\\ui_model_menu.py\"\
          , line 213, in load_model_wrapper</p>\n<p>shared.model, shared.tokenizer\
          \ = load_model(selected_model, loader)<br>File \"...\\text-generation-webui\\\
          modules\\models.py\", line 87, in load_model</p>\n<p>output = load_func_map<a\
          \ rel=\"nofollow\" href=\"model_name\">loader</a><br>File \"...\\text-generation-webui\\\
          modules\\models.py\", line 385, in ExLlamav2_loader</p>\n<p>model, tokenizer\
          \ = Exllamav2Model.from_pretrained(model_name)<br>File \"...\\text-generation-webui\\\
          modules\\exllamav2.py\", line 44, in from_pretrained</p>\n<p>config.prepare()<br>File\
          \ \"...\\text-generation-webui\\installer_files\\env\\lib\\site-packages\\\
          exllamav2\\config.py\", line 150, in prepare</p>\n<p>self.hidden_size =\
          \ read_config[\"hidden_size\"]<br>KeyError: 'hidden_size'</p>\n"
        raw: "@TheBloke tried with several ways to load it but wasn't able to. Could\
          \ you please have a look at it?\r\n\r\nThanks in advance.\r\ne.g. ExLlamav2\
          \ error log\r\nTraceback (most recent call last):\r\n\r\nFile \"...\\text-generation-webui\\\
          modules\\ui_model_menu.py\", line 213, in load_model_wrapper\r\n\r\nshared.model,\
          \ shared.tokenizer = load_model(selected_model, loader)\r\nFile \"...\\\
          text-generation-webui\\modules\\models.py\", line 87, in load_model\r\n\r\
          \noutput = load_func_map[loader](model_name)\r\nFile \"...\\text-generation-webui\\\
          modules\\models.py\", line 385, in ExLlamav2_loader\r\n\r\nmodel, tokenizer\
          \ = Exllamav2Model.from_pretrained(model_name)\r\nFile \"...\\text-generation-webui\\\
          modules\\exllamav2.py\", line 44, in from_pretrained\r\n\r\nconfig.prepare()\r\
          \nFile \"...\\text-generation-webui\\installer_files\\env\\lib\\site-packages\\\
          exllamav2\\config.py\", line 150, in prepare\r\n\r\nself.hidden_size = read_config[\"\
          hidden_size\"]\r\nKeyError: 'hidden_size'"
        updatedAt: '2024-01-03T15:18:23.815Z'
      numEdits: 0
      reactions: []
    id: 65957abf21199504031d6f50
    type: comment
  author: awelker
  content: "@TheBloke tried with several ways to load it but wasn't able to. Could\
    \ you please have a look at it?\r\n\r\nThanks in advance.\r\ne.g. ExLlamav2 error\
    \ log\r\nTraceback (most recent call last):\r\n\r\nFile \"...\\text-generation-webui\\\
    modules\\ui_model_menu.py\", line 213, in load_model_wrapper\r\n\r\nshared.model,\
    \ shared.tokenizer = load_model(selected_model, loader)\r\nFile \"...\\text-generation-webui\\\
    modules\\models.py\", line 87, in load_model\r\n\r\noutput = load_func_map[loader](model_name)\r\
    \nFile \"...\\text-generation-webui\\modules\\models.py\", line 385, in ExLlamav2_loader\r\
    \n\r\nmodel, tokenizer = Exllamav2Model.from_pretrained(model_name)\r\nFile \"\
    ...\\text-generation-webui\\modules\\exllamav2.py\", line 44, in from_pretrained\r\
    \n\r\nconfig.prepare()\r\nFile \"...\\text-generation-webui\\installer_files\\\
    env\\lib\\site-packages\\exllamav2\\config.py\", line 150, in prepare\r\n\r\n\
    self.hidden_size = read_config[\"hidden_size\"]\r\nKeyError: 'hidden_size'"
  created_at: 2024-01-03 15:18:23+00:00
  edited: false
  hidden: false
  id: 65957abf21199504031d6f50
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/dolphin-2_6-phi-2-GPTQ
repo_type: model
status: open
target_branch: null
title: No Loader can Load this model into ooba text-gen-webui
