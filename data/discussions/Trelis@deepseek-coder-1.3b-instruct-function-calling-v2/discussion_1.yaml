!!python/object:huggingface_hub.community.DiscussionWithDetails
author: santhosh-ai
conflicting_files: null
created_at: 2023-11-14 12:42:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/63ef7763175327b860cb8661985c89e5.svg
      fullname: yamana
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: santhosh-ai
      type: user
    createdAt: '2023-11-14T12:42:17.000Z'
    data:
      edited: false
      editors:
      - santhosh-ai
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9659340381622314
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/63ef7763175327b860cb8661985c89e5.svg
          fullname: yamana
          isHf: false
          isPro: false
          name: santhosh-ai
          type: user
        html: '<p>Hi Ronan,</p>

          <p>I would like to confirm on the domain for the specific model. It looks
          that works only with code based questions. How it works on specific (call
          center)other domains. ?<br>Note:<br>I have seen from "DeepSeek Coder is
          composed of a series of code language models, each trained from scratch
          on 2T tokens, with a composition of 87% code and 13% natural language in
          both English and Chinese."</p>

          <p>Please clarify on this.</p>

          <p>Thanks,<br>santhosh</p>

          '
        raw: "Hi Ronan,\r\n\r\nI would like to confirm on the domain for the specific\
          \ model. It looks that works only with code based questions. How it works\
          \ on specific (call center)other domains. ?\r\nNote:\r\nI have seen from\
          \ \"DeepSeek Coder is composed of a series of code language models, each\
          \ trained from scratch on 2T tokens, with a composition of 87% code and\
          \ 13% natural language in both English and Chinese.\"\r\n\r\nPlease clarify\
          \ on this.\r\n\r\nThanks,\r\nsanthosh"
        updatedAt: '2023-11-14T12:42:17.237Z'
      numEdits: 0
      reactions: []
    id: 65536b29a8e7cc4d1364384c
    type: comment
  author: santhosh-ai
  content: "Hi Ronan,\r\n\r\nI would like to confirm on the domain for the specific\
    \ model. It looks that works only with code based questions. How it works on specific\
    \ (call center)other domains. ?\r\nNote:\r\nI have seen from \"DeepSeek Coder\
    \ is composed of a series of code language models, each trained from scratch on\
    \ 2T tokens, with a composition of 87% code and 13% natural language in both English\
    \ and Chinese.\"\r\n\r\nPlease clarify on this.\r\n\r\nThanks,\r\nsanthosh"
  created_at: 2023-11-14 12:42:17+00:00
  edited: false
  hidden: false
  id: 65536b29a8e7cc4d1364384c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-11-14T13:25:10.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9815537929534912
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>I just added a demo video to the model card.</p>

          <p>Yeah, it''s a coder model and is missing general knowledge, but responds
          well to language - I guess that 13% is enough, it''s about 260B tokens so
          that''s quite a bit.</p>

          '
        raw: 'I just added a demo video to the model card.


          Yeah, it''s a coder model and is missing general knowledge, but responds
          well to language - I guess that 13% is enough, it''s about 260B tokens so
          that''s quite a bit.'
        updatedAt: '2023-11-14T13:25:10.413Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65537536a37c0a3610fbb0d7
    id: 65537536a37c0a3610fbb0d5
    type: comment
  author: RonanMcGovern
  content: 'I just added a demo video to the model card.


    Yeah, it''s a coder model and is missing general knowledge, but responds well
    to language - I guess that 13% is enough, it''s about 260B tokens so that''s quite
    a bit.'
  created_at: 2023-11-14 13:25:10+00:00
  edited: false
  hidden: false
  id: 65537536a37c0a3610fbb0d5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-11-14T13:25:10.000Z'
    data:
      status: closed
    id: 65537536a37c0a3610fbb0d7
    type: status-change
  author: RonanMcGovern
  created_at: 2023-11-14 13:25:10+00:00
  id: 65537536a37c0a3610fbb0d7
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/63ef7763175327b860cb8661985c89e5.svg
      fullname: yamana
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: santhosh-ai
      type: user
    createdAt: '2023-11-15T12:04:17.000Z'
    data:
      edited: false
      editors:
      - santhosh-ai
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9548481702804565
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/63ef7763175327b860cb8661985c89e5.svg
          fullname: yamana
          isHf: false
          isPro: false
          name: santhosh-ai
          type: user
        html: '<p>I tried with below prompt and got the below response.</p>

          <p>prompt = "hello, how to book a ticket?"</p>

          <p>result = "I''m sorry, but as an AI Programming Assistant, I''m only able
          to provide assistance with computer science-related questions. I''m unable
          to help with booking tickets or other non-computer science related tasks.<br>"</p>

          <p>Please help on this.</p>

          '
        raw: 'I tried with below prompt and got the below response.


          prompt = "hello, how to book a ticket?"


          result = "I''m sorry, but as an AI Programming Assistant, I''m only able
          to provide assistance with computer science-related questions. I''m unable
          to help with booking tickets or other non-computer science related tasks.

          "


          Please help on this.'
        updatedAt: '2023-11-15T12:04:17.389Z'
      numEdits: 0
      reactions: []
    id: 6554b3c1bb20b21a0e7adac9
    type: comment
  author: santhosh-ai
  content: 'I tried with below prompt and got the below response.


    prompt = "hello, how to book a ticket?"


    result = "I''m sorry, but as an AI Programming Assistant, I''m only able to provide
    assistance with computer science-related questions. I''m unable to help with booking
    tickets or other non-computer science related tasks.

    "


    Please help on this.'
  created_at: 2023-11-15 12:04:17+00:00
  edited: false
  hidden: false
  id: 6554b3c1bb20b21a0e7adac9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/63ef7763175327b860cb8661985c89e5.svg
      fullname: yamana
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: santhosh-ai
      type: user
    createdAt: '2023-11-15T12:04:32.000Z'
    data:
      status: open
    id: 6554b3d055895fc734480788
    type: status-change
  author: santhosh-ai
  created_at: 2023-11-15 12:04:32+00:00
  id: 6554b3d055895fc734480788
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-11-15T14:36:23.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8749990463256836
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>Can you post a full code example, including showing the prompt,
          how you tokenize the prompt and how send it to the model.</p>

          <p>I can then replicate to troubleshoot.</p>

          '
        raw: 'Can you post a full code example, including showing the prompt, how
          you tokenize the prompt and how send it to the model.


          I can then replicate to troubleshoot.'
        updatedAt: '2023-11-15T14:36:23.657Z'
      numEdits: 0
      reactions: []
    id: 6554d767504a713ca5f1f6b5
    type: comment
  author: RonanMcGovern
  content: 'Can you post a full code example, including showing the prompt, how you
    tokenize the prompt and how send it to the model.


    I can then replicate to troubleshoot.'
  created_at: 2023-11-15 14:36:23+00:00
  edited: false
  hidden: false
  id: 6554d767504a713ca5f1f6b5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/63ef7763175327b860cb8661985c89e5.svg
      fullname: yamana
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: santhosh-ai
      type: user
    createdAt: '2023-11-16T06:19:52.000Z'
    data:
      edited: false
      editors:
      - santhosh-ai
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5727172493934631
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/63ef7763175327b860cb8661985c89e5.svg
          fullname: yamana
          isHf: false
          isPro: false
          name: santhosh-ai
          type: user
        html: '<p>I tried with open source model to check the model response. </p>

          <p>Code: =======================</p>

          <p>from transformers import AutoTokenizer, AutoModelForCausalLM<br>tokenizer
          = AutoTokenizer.from_pretrained("deepseek-ai/deepseek-coder-1.3b-instruct",
          trust_remote_code=True)<br>model = AutoModelForCausalLM.from_pretrained("deepseek-ai/deepseek-coder-1.3b-instruct",
          trust_remote_code=True).cuda()<br>messages=[<br>    { ''role'': ''user'',
          ''content'': "hello, how to book a ticket?"}<br>]</p>

          <p>inputs = tokenizer.apply_chat_template(messages, return_tensors="pt").to(model.device)</p>

          <p>outputs = model.generate(inputs, max_new_tokens=512, do_sample=False,
          top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=32021)<br>print(tokenizer.decode(outputs[0][len(inputs[0]):],
          skip_special_tokens=True))</p>

          <p>Result: ==========================</p>

          <p>I''m sorry, but as an AI Programming Assistant, I''m only able to provide
          assistance with computer science-related questions. I''m unable to help
          with booking tickets or other non-computer science related tasks.</p>

          '
        raw: "I tried with open source model to check the model response. \n\nCode:\
          \ =======================\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\
          tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-instruct\"\
          , trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\"\
          deepseek-ai/deepseek-coder-1.3b-instruct\", trust_remote_code=True).cuda()\n\
          messages=[\n    { 'role': 'user', 'content': \"hello, how to book a ticket?\"\
          }\n]\n\ninputs = tokenizer.apply_chat_template(messages, return_tensors=\"\
          pt\").to(model.device)\n\noutputs = model.generate(inputs, max_new_tokens=512,\
          \ do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=32021)\n\
          print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))\n\
          \nResult: ==========================\n\nI'm sorry, but as an AI Programming\
          \ Assistant, I'm only able to provide assistance with computer science-related\
          \ questions. I'm unable to help with booking tickets or other non-computer\
          \ science related tasks.\n\n"
        updatedAt: '2023-11-16T06:19:52.330Z'
      numEdits: 0
      reactions: []
    id: 6555b4882d2276f52c4c2451
    type: comment
  author: santhosh-ai
  content: "I tried with open source model to check the model response. \n\nCode:\
    \ =======================\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\
    tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-instruct\"\
    , trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-instruct\"\
    , trust_remote_code=True).cuda()\nmessages=[\n    { 'role': 'user', 'content':\
    \ \"hello, how to book a ticket?\"}\n]\n\ninputs = tokenizer.apply_chat_template(messages,\
    \ return_tensors=\"pt\").to(model.device)\n\noutputs = model.generate(inputs,\
    \ max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1,\
    \ eos_token_id=32021)\nprint(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))\n\
    \nResult: ==========================\n\nI'm sorry, but as an AI Programming Assistant,\
    \ I'm only able to provide assistance with computer science-related questions.\
    \ I'm unable to help with booking tickets or other non-computer science related\
    \ tasks.\n\n"
  created_at: 2023-11-16 06:19:52+00:00
  edited: false
  hidden: false
  id: 6555b4882d2276f52c4c2451
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-11-16T10:49:42.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7512625455856323
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: "<p>Yup, that's because using apply_chat_template appends a restrictive\
          \ system message (it's a bit sneaky):</p>\n<pre><code># Run a sample for\
          \ Deepseek coder\n\nmessages = [\n    # {'role': 'system', 'content': \"\
          &lt;FUNCTIONS&gt;sample functions&lt;/FUNCTIONS&gt;\"},\n    {'role': 'user',\
          \ 'content': \"How are you today?\"}\n]\n\n# Apply the chat template to\
          \ the messages\ninputs = tokenizer_A.apply_chat_template(messages, return_tensors=\"\
          pt\")\n\n# Assuming `inputs` contains the tensor you provided\ndecoded_input\
          \ = tokenizer_A.decode(inputs[0], skip_special_tokens=False)\n\nprint(decoded_input)\n\
          </code></pre>\n<p>if you print those inputs, you'll get:</p>\n<pre><code>You\
          \ are an AI programming assistant, utilizing the Deepseek Coder model, developed\
          \ by Deepseek Company, and you only answer questions related to computer\
          \ science. For politically sensitive questions, security and privacy issues,\
          \ and other non-computer science questions, you will refuse to answer.\n\
          ### Instruction:\nHow are you today?\n### Response:\n</code></pre>\n<p>That's\
          \ why it's better to use the prompt template I gave in the card and manually\
          \ put the prompt together with:</p>\n<pre><code># B_INST, E_INST = \"\\\
          n### Instruction:\\n\", \"\\n### Response:\\n\" #DeepSeek Coder Style\n\
          prompt = f\"{B_FUNC}{function_list.strip()}{E_FUNC}{B_INST}{user_prompt.strip()}{E_INST}\\\
          n\\n\"\n</code></pre>\n<p>or without functions:</p>\n<pre><code>prompt =\
          \ f\"{B_INST}{user_prompt.strip()}{E_INST}\\n\\n\"\n</code></pre>\n<p>If\
          \ that still doesn't work, but I think it will, then I can fine-tune the\
          \ non-instruct version for you.</p>\n"
        raw: "Yup, that's because using apply_chat_template appends a restrictive\
          \ system message (it's a bit sneaky):\n```\n# Run a sample for Deepseek\
          \ coder\n\nmessages = [\n    # {'role': 'system', 'content': \"<FUNCTIONS>sample\
          \ functions</FUNCTIONS>\"},\n    {'role': 'user', 'content': \"How are you\
          \ today?\"}\n]\n\n# Apply the chat template to the messages\ninputs = tokenizer_A.apply_chat_template(messages,\
          \ return_tensors=\"pt\")\n\n# Assuming `inputs` contains the tensor you\
          \ provided\ndecoded_input = tokenizer_A.decode(inputs[0], skip_special_tokens=False)\n\
          \nprint(decoded_input)\n```\nif you print those inputs, you'll get:\n```\n\
          You are an AI programming assistant, utilizing the Deepseek Coder model,\
          \ developed by Deepseek Company, and you only answer questions related to\
          \ computer science. For politically sensitive questions, security and privacy\
          \ issues, and other non-computer science questions, you will refuse to answer.\n\
          ### Instruction:\nHow are you today?\n### Response:\n```\nThat's why it's\
          \ better to use the prompt template I gave in the card and manually put\
          \ the prompt together with:\n```\n# B_INST, E_INST = \"\\n### Instruction:\\\
          n\", \"\\n### Response:\\n\" #DeepSeek Coder Style\nprompt = f\"{B_FUNC}{function_list.strip()}{E_FUNC}{B_INST}{user_prompt.strip()}{E_INST}\\\
          n\\n\"\n```\nor without functions:\n```\nprompt = f\"{B_INST}{user_prompt.strip()}{E_INST}\\\
          n\\n\"\n```\nIf that still doesn't work, but I think it will, then I can\
          \ fine-tune the non-instruct version for you."
        updatedAt: '2023-11-16T10:49:42.054Z'
      numEdits: 0
      reactions: []
    id: 6555f3c61f241e8adb39a0e4
    type: comment
  author: RonanMcGovern
  content: "Yup, that's because using apply_chat_template appends a restrictive system\
    \ message (it's a bit sneaky):\n```\n# Run a sample for Deepseek coder\n\nmessages\
    \ = [\n    # {'role': 'system', 'content': \"<FUNCTIONS>sample functions</FUNCTIONS>\"\
    },\n    {'role': 'user', 'content': \"How are you today?\"}\n]\n\n# Apply the\
    \ chat template to the messages\ninputs = tokenizer_A.apply_chat_template(messages,\
    \ return_tensors=\"pt\")\n\n# Assuming `inputs` contains the tensor you provided\n\
    decoded_input = tokenizer_A.decode(inputs[0], skip_special_tokens=False)\n\nprint(decoded_input)\n\
    ```\nif you print those inputs, you'll get:\n```\nYou are an AI programming assistant,\
    \ utilizing the Deepseek Coder model, developed by Deepseek Company, and you only\
    \ answer questions related to computer science. For politically sensitive questions,\
    \ security and privacy issues, and other non-computer science questions, you will\
    \ refuse to answer.\n### Instruction:\nHow are you today?\n### Response:\n```\n\
    That's why it's better to use the prompt template I gave in the card and manually\
    \ put the prompt together with:\n```\n# B_INST, E_INST = \"\\n### Instruction:\\\
    n\", \"\\n### Response:\\n\" #DeepSeek Coder Style\nprompt = f\"{B_FUNC}{function_list.strip()}{E_FUNC}{B_INST}{user_prompt.strip()}{E_INST}\\\
    n\\n\"\n```\nor without functions:\n```\nprompt = f\"{B_INST}{user_prompt.strip()}{E_INST}\\\
    n\\n\"\n```\nIf that still doesn't work, but I think it will, then I can fine-tune\
    \ the non-instruct version for you."
  created_at: 2023-11-16 10:49:42+00:00
  edited: false
  hidden: false
  id: 6555f3c61f241e8adb39a0e4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-12-05T15:04:04.000Z'
    data:
      status: closed
    id: 656f3be4d07017133e3cba23
    type: status-change
  author: RonanMcGovern
  created_at: 2023-12-05 15:04:04+00:00
  id: 656f3be4d07017133e3cba23
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Trelis/deepseek-coder-1.3b-instruct-function-calling-v2
repo_type: model
status: closed
target_branch: null
title: Confirmation on domain
