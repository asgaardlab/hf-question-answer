!!python/object:huggingface_hub.community.DiscussionWithDetails
author: paulcx
conflicting_files: null
created_at: 2023-12-26 00:39:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d7ed94d15cf8cc1bf8108d2f2d211ee5.svg
      fullname: XX
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: paulcx
      type: user
    createdAt: '2023-12-26T00:39:44.000Z'
    data:
      edited: false
      editors:
      - paulcx
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8352420330047607
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d7ed94d15cf8cc1bf8108d2f2d211ee5.svg
          fullname: XX
          isHf: false
          isPro: false
          name: paulcx
          type: user
        html: '<p>the response is empty string</p>

          '
        raw: the response is empty string
        updatedAt: '2023-12-26T00:39:44.008Z'
      numEdits: 0
      reactions: []
    id: 658a20d0af21ea88a47568b6
    type: comment
  author: paulcx
  content: the response is empty string
  created_at: 2023-12-26 00:39:44+00:00
  edited: false
  hidden: false
  id: 658a20d0af21ea88a47568b6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2024-01-09T11:51:28.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4282703697681427
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>same</p>

          '
        raw: same
        updatedAt: '2024-01-09T11:51:28.975Z'
      numEdits: 0
      reactions: []
    id: 659d3340a68b88b6a787424d
    type: comment
  author: RonanMcGovern
  content: same
  created_at: 2024-01-09 11:51:28+00:00
  edited: false
  hidden: false
  id: 659d3340a68b88b6a787424d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fc2628bb2d56c4584ef79ddd6f92c932.svg
      fullname: Christoph Raab
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cdawg
      type: user
    createdAt: '2024-01-09T17:48:19.000Z'
    data:
      edited: true
      editors:
      - cdawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9606561064720154
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fc2628bb2d56c4584ef79ddd6f92c932.svg
          fullname: Christoph Raab
          isHf: false
          isPro: false
          name: cdawg
          type: user
        html: '<p>I am also unable to launch this model with TGI in general. The version
          by ID ''ybelkada/Mixtral-8x7B-Instruct-v0.1-AWQ'' is working as expected.
          I assume this is a problem not related to the model type Mixtral.</p>

          '
        raw: I am also unable to launch this model with TGI in general. The version
          by ID 'ybelkada/Mixtral-8x7B-Instruct-v0.1-AWQ' is working as expected.
          I assume this is a problem not related to the model type Mixtral.
        updatedAt: '2024-01-09T17:48:50.586Z'
      numEdits: 2
      reactions: []
    id: 659d86e3ec9f8f337f105cd0
    type: comment
  author: cdawg
  content: I am also unable to launch this model with TGI in general. The version
    by ID 'ybelkada/Mixtral-8x7B-Instruct-v0.1-AWQ' is working as expected. I assume
    this is a problem not related to the model type Mixtral.
  created_at: 2024-01-09 17:48:19+00:00
  edited: true
  hidden: false
  id: 659d86e3ec9f8f337f105cd0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2024-01-09T19:09:10.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9343446493148804
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: "<p>Ooh, nice <span data-props=\"{&quot;user&quot;:&quot;cdawg&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/cdawg\"\
          >@<span class=\"underline\">cdawg</span></a></span>\n\n\t</span></span>\
          \ - that was a great tip. I just got that running well on runpod with <a\
          \ rel=\"nofollow\" href=\"https://runpod.io/gsc?template=546m57v73a&amp;ref=jmfkcdio\"\
          >this template</a>.</p>\n<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ - fyi, there seems to be something about this AWQ that is different to\
          \ what Younes did. Separately I had issues quantizing AWQ myself (and I'm\
          \ not sure how you or Younes got around that), issue <a rel=\"nofollow\"\
          \ href=\"https://github.com/casper-hansen/AutoAWQ/issues/300\">here</a>.</p>\n"
        raw: 'Ooh, nice @cdawg - that was a great tip. I just got that running well
          on runpod with [this template](https://runpod.io/gsc?template=546m57v73a&ref=jmfkcdio).


          @TheBloke - fyi, there seems to be something about this AWQ that is different
          to what Younes did. Separately I had issues quantizing AWQ myself (and I''m
          not sure how you or Younes got around that), issue [here](https://github.com/casper-hansen/AutoAWQ/issues/300).'
        updatedAt: '2024-01-09T19:09:10.646Z'
      numEdits: 0
      reactions: []
    id: 659d99d6962de309f01ef638
    type: comment
  author: RonanMcGovern
  content: 'Ooh, nice @cdawg - that was a great tip. I just got that running well
    on runpod with [this template](https://runpod.io/gsc?template=546m57v73a&ref=jmfkcdio).


    @TheBloke - fyi, there seems to be something about this AWQ that is different
    to what Younes did. Separately I had issues quantizing AWQ myself (and I''m not
    sure how you or Younes got around that), issue [here](https://github.com/casper-hansen/AutoAWQ/issues/300).'
  created_at: 2024-01-09 19:09:10+00:00
  edited: false
  hidden: false
  id: 659d99d6962de309f01ef638
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1657710754048-noauth.jpeg?w=200&h=200&f=face
      fullname: Mohammad Dahab
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: m-dahab
      type: user
    createdAt: '2024-01-15T05:43:36.000Z'
    data:
      edited: false
      editors:
      - m-dahab
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9012172818183899
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1657710754048-noauth.jpeg?w=200&h=200&f=face
          fullname: Mohammad Dahab
          isHf: false
          isPro: false
          name: m-dahab
          type: user
        html: "<blockquote>\n<p>I am also unable to launch this model with TGI in\
          \ general. The version by ID 'ybelkada/Mixtral-8x7B-Instruct-v0.1-AWQ' is\
          \ working as expected. I assume this is a problem not related to the model\
          \ type Mixtral.</p>\n</blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;cdawg&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/cdawg\"\
          >@<span class=\"underline\">cdawg</span></a></span>\n\n\t</span></span>\
          \ I did download 'ybelkada/Mixtral-8x7B-Instruct-v0.1-AWQ' but I'm running\
          \ into the same issue:</p>\n<p>NotImplementedError: awq quantization is\
          \ not supported for AutoModel</p>\n<p>I'm running <code>text-generation-launcher\
          \ 1.3.4</code>.</p>\n<p>Would you kindly share your config?</p>\n"
        raw: '> I am also unable to launch this model with TGI in general. The version
          by ID ''ybelkada/Mixtral-8x7B-Instruct-v0.1-AWQ'' is working as expected.
          I assume this is a problem not related to the model type Mixtral.


          @cdawg I did download ''ybelkada/Mixtral-8x7B-Instruct-v0.1-AWQ'' but I''m
          running into the same issue:


          NotImplementedError: awq quantization is not supported for AutoModel


          I''m running `text-generation-launcher 1.3.4`.


          Would you kindly share your config?'
        updatedAt: '2024-01-15T05:43:36.393Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - swapnil3597
    id: 65a4c608d13926ca4b93e0b4
    type: comment
  author: m-dahab
  content: '> I am also unable to launch this model with TGI in general. The version
    by ID ''ybelkada/Mixtral-8x7B-Instruct-v0.1-AWQ'' is working as expected. I assume
    this is a problem not related to the model type Mixtral.


    @cdawg I did download ''ybelkada/Mixtral-8x7B-Instruct-v0.1-AWQ'' but I''m running
    into the same issue:


    NotImplementedError: awq quantization is not supported for AutoModel


    I''m running `text-generation-launcher 1.3.4`.


    Would you kindly share your config?'
  created_at: 2024-01-15 05:43:36+00:00
  edited: false
  hidden: false
  id: 65a4c608d13926ca4b93e0b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2024-01-15T08:54:31.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6107171773910522
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>You can try running with the "latest" TGI and it should work.</p>

          <p>See this template for the config: <a rel="nofollow" href="https://runpod.io/gsc?template=546m57v73a&amp;ref=jmfkcdio">https://runpod.io/gsc?template=546m57v73a&amp;ref=jmfkcdio</a></p>

          '
        raw: 'You can try running with the "latest" TGI and it should work.


          See this template for the config: https://runpod.io/gsc?template=546m57v73a&ref=jmfkcdio

          '
        updatedAt: '2024-01-15T08:54:31.279Z'
      numEdits: 0
      reactions: []
    id: 65a4f2c7e8fe70d60c72bf70
    type: comment
  author: RonanMcGovern
  content: 'You can try running with the "latest" TGI and it should work.


    See this template for the config: https://runpod.io/gsc?template=546m57v73a&ref=jmfkcdio

    '
  created_at: 2024-01-15 08:54:31+00:00
  edited: false
  hidden: false
  id: 65a4f2c7e8fe70d60c72bf70
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1657710754048-noauth.jpeg?w=200&h=200&f=face
      fullname: Mohammad Dahab
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: m-dahab
      type: user
    createdAt: '2024-01-15T09:04:58.000Z'
    data:
      edited: false
      editors:
      - m-dahab
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9895057082176208
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1657710754048-noauth.jpeg?w=200&h=200&f=face
          fullname: Mohammad Dahab
          isHf: false
          isPro: false
          name: m-dahab
          type: user
        html: "<p>Sorry, I didn't mention that I only have CPUs as part of an oc cluster.</p>\n\
          <p><span data-props=\"{&quot;user&quot;:&quot;RonanMcGovern&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/RonanMcGovern\">@<span\
          \ class=\"underline\">RonanMcGovern</span></a></span>\n\n\t</span></span>\
          \ Did you get that running on CPUs?</p>\n"
        raw: 'Sorry, I didn''t mention that I only have CPUs as part of an oc cluster.


          @RonanMcGovern Did you get that running on CPUs?'
        updatedAt: '2024-01-15T09:04:58.299Z'
      numEdits: 0
      reactions: []
    id: 65a4f53a8ac0602820f8c93f
    type: comment
  author: m-dahab
  content: 'Sorry, I didn''t mention that I only have CPUs as part of an oc cluster.


    @RonanMcGovern Did you get that running on CPUs?'
  created_at: 2024-01-15 09:04:58+00:00
  edited: false
  hidden: false
  id: 65a4f53a8ac0602820f8c93f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2024-01-15T09:17:24.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9520350098609924
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>I''m not sure if you can run AWQ on CPUs because AWQ requires Ampere
          GPUs.</p>

          <p>Maybe there is a way but I sense that running llama cpp is may be easier
          than using TGI. They have a server you can run as well.</p>

          '
        raw: 'I''m not sure if you can run AWQ on CPUs because AWQ requires Ampere
          GPUs.


          Maybe there is a way but I sense that running llama cpp is may be easier
          than using TGI. They have a server you can run as well.'
        updatedAt: '2024-01-15T09:17:24.504Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - m-dahab
    id: 65a4f8249acab19980a08dcd
    type: comment
  author: RonanMcGovern
  content: 'I''m not sure if you can run AWQ on CPUs because AWQ requires Ampere GPUs.


    Maybe there is a way but I sense that running llama cpp is may be easier than
    using TGI. They have a server you can run as well.'
  created_at: 2024-01-15 09:17:24+00:00
  edited: false
  hidden: false
  id: 65a4f8249acab19980a08dcd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fc2628bb2d56c4584ef79ddd6f92c932.svg
      fullname: Christoph Raab
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cdawg
      type: user
    createdAt: '2024-01-15T15:26:00.000Z'
    data:
      edited: false
      editors:
      - cdawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6293578147888184
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fc2628bb2d56c4584ef79ddd6f92c932.svg
          fullname: Christoph Raab
          isHf: false
          isPro: false
          name: cdawg
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;m-dahab&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/m-dahab\">@<span class=\"\
          underline\">m-dahab</span></a></span>\n\n\t</span></span> I launch the model\
          \ with <code>text-generation-launcher --model-id=$MODEL_PATH --port=80 --max-best-of=1\
          \  --max-input-length=4096 --max-batch-prefill-tokens=4096 --max-total-tokens=9192\
          \ --json-output --validation-workers 4 --quantize=awq</code>. But as <span\
          \ data-props=\"{&quot;user&quot;:&quot;RonanMcGovern&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/RonanMcGovern\">@<span\
          \ class=\"underline\">RonanMcGovern</span></a></span>\n\n\t</span></span>\
          \ pointed out, i think you need a gpu with AWQ supportd. I think A10, A100\
          \ or H100 would be good. </p>\n"
        raw: '@m-dahab I launch the model with `text-generation-launcher --model-id=$MODEL_PATH
          --port=80 --max-best-of=1  --max-input-length=4096 --max-batch-prefill-tokens=4096
          --max-total-tokens=9192 --json-output --validation-workers 4 --quantize=awq`.
          But as @RonanMcGovern pointed out, i think you need a gpu with AWQ supportd.
          I think A10, A100 or H100 would be good. '
        updatedAt: '2024-01-15T15:26:00.627Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - m-dahab
    id: 65a54e882138495d16022c82
    type: comment
  author: cdawg
  content: '@m-dahab I launch the model with `text-generation-launcher --model-id=$MODEL_PATH
    --port=80 --max-best-of=1  --max-input-length=4096 --max-batch-prefill-tokens=4096
    --max-total-tokens=9192 --json-output --validation-workers 4 --quantize=awq`.
    But as @RonanMcGovern pointed out, i think you need a gpu with AWQ supportd. I
    think A10, A100 or H100 would be good. '
  created_at: 2024-01-15 15:26:00+00:00
  edited: false
  hidden: false
  id: 65a54e882138495d16022c82
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Mixtral-8x7B-Instruct-v0.1-AWQ
repo_type: model
status: open
target_branch: null
title: Not supported for TGI > 1.3 ?
