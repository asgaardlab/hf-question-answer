!!python/object:huggingface_hub.community.DiscussionWithDetails
author: OwenHong
conflicting_files: null
created_at: 2023-09-05 11:32:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bae58708463d0f5b511cf5c3c4774d3b.svg
      fullname: OwenHong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: OwenHong
      type: user
    createdAt: '2023-09-05T12:32:26.000Z'
    data:
      edited: false
      editors:
      - OwenHong
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6142622232437134
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bae58708463d0f5b511cf5c3c4774d3b.svg
          fullname: OwenHong
          isHf: false
          isPro: false
          name: OwenHong
          type: user
        html: "<p>I am an iOS developer with only a basic understanding of PyTorch\
          \ and machine learning. I tried to convert the Taiyi model to the CoreML\
          \ format. Below is my code. Although I successfully exported the model,\
          \ the text feature vectors inferred on the client side often fail to retrieve\
          \ relevant images. Could you please help me check if my convert process\
          \ is correct? I would really appreciate it.</p>\n<pre><code>!pip install\
          \ coremltools==7.0b2\n!pip install transformers\nimport torch\nfrom transformers\
          \ import BertForSequenceClassification, BertConfig, BertTokenizer\nfrom\
          \ transformers import CLIPProcessor, CLIPModel\nimport numpy as np\nimport\
          \ coremltools as ct\n\ntext_tokenizer = BertTokenizer.from_pretrained(\"\
          IDEA-CCNL/Taiyi-CLIP-Roberta-102M-Chinese\")\ntext_encoder = BertForSequenceClassification.from_pretrained(\"\
          IDEA-CCNL/Taiyi-CLIP-Roberta-102M-Chinese\",return_dict=False)\nexample_input\
          \ = text_tokenizer([\"\u5C0F\u72D7\"], return_tensors='pt', max_length=75,\
          \ padding='max_length')[\"input_ids\"]\ntraced_model = torch.jit.trace(text_encoder,\
          \ example_input, strict=False)\ntext_encoder_model = ct.convert(\n     \
          \       traced_model,\n            convert_to=\"mlprogram\",\n         \
          \   minimum_deployment_target=ct.target.iOS16,\n            inputs=[ct.TensorType(name=\"\
          prompt\",\n                                 shape=example_input.shape)],\n\
          \            outputs=[ct.TensorType(name=\"embOutput\", dtype=np.float32)],\n\
          \        )\ntext_encoder_model.save(\"TextEncoder_float32_taiyi.mlpackage\"\
          )\n</code></pre>\n<p>Here is the convert log:<br>#WARNING:coremltools:Tuple\
          \ detected at graph output. This will be flattened in the converted model.<br>#Converting\
          \ PyTorch Frontend ==&gt; MIL Ops:   0%|          | 0/639 [00:00&lt;?, ?\
          \ ops/s]WARNING:coremltools:Core ML embedding (gather) #layer does not support\
          \ any inputs besides the weights and indices. Those given will be ignored.<br>#Converting\
          \ PyTorch Frontend ==&gt; MIL Ops: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2589| 637/639 [00:00&lt;00:00, 2247.71 ops/s]<br>#Running\
          \ MIL frontend_pytorch pipeline: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 120.25 passes/s]<br>#Running\
          \ MIL default pipeline: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588| 66/66 [00:21&lt;00:00,  3.08 passes/s]<br>#Running MIL backend_mlprogram\
          \ pipeline: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          | 11/11 [00:00&lt;00:00, 76.27 passes/s]</p>\n"
        raw: "I am an iOS developer with only a basic understanding of PyTorch and\
          \ machine learning. I tried to convert the Taiyi model to the CoreML format.\
          \ Below is my code. Although I successfully exported the model, the text\
          \ feature vectors inferred on the client side often fail to retrieve relevant\
          \ images. Could you please help me check if my convert process is correct?\
          \ I would really appreciate it.\r\n```\r\n!pip install coremltools==7.0b2\r\
          \n!pip install transformers\r\nimport torch\r\nfrom transformers import\
          \ BertForSequenceClassification, BertConfig, BertTokenizer\r\nfrom transformers\
          \ import CLIPProcessor, CLIPModel\r\nimport numpy as np\r\nimport coremltools\
          \ as ct\r\n\r\ntext_tokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-102M-Chinese\"\
          )\r\ntext_encoder = BertForSequenceClassification.from_pretrained(\"IDEA-CCNL/Taiyi-CLIP-Roberta-102M-Chinese\"\
          ,return_dict=False)\r\nexample_input = text_tokenizer([\"\u5C0F\u72D7\"\
          ], return_tensors='pt', max_length=75, padding='max_length')[\"input_ids\"\
          ]\r\ntraced_model = torch.jit.trace(text_encoder, example_input, strict=False)\r\
          \ntext_encoder_model = ct.convert(\r\n            traced_model,\r\n    \
          \        convert_to=\"mlprogram\",\r\n            minimum_deployment_target=ct.target.iOS16,\r\
          \n            inputs=[ct.TensorType(name=\"prompt\",\r\n               \
          \                  shape=example_input.shape)],\r\n            outputs=[ct.TensorType(name=\"\
          embOutput\", dtype=np.float32)],\r\n        )\r\ntext_encoder_model.save(\"\
          TextEncoder_float32_taiyi.mlpackage\")\r\n```\r\nHere is the convert log:\r\
          \n#WARNING:coremltools:Tuple detected at graph output. This will be flattened\
          \ in the converted model.\r\n#Converting PyTorch Frontend ==> MIL Ops: \
          \  0%|          | 0/639 [00:00<?, ? ops/s]WARNING:coremltools:Core ML embedding\
          \ (gather) #layer does not support any inputs besides the weights and indices.\
          \ Those given will be ignored.\r\n#Converting PyTorch Frontend ==> MIL Ops:\
          \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 637/639\
          \ [00:00<00:00, 2247.71 ops/s]\r\n#Running MIL frontend_pytorch pipeline:\
          \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5\
          \ [00:00<00:00, 120.25 passes/s]\r\n#Running MIL default pipeline: 100%|\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 66/66 [00:21<00:00,\
          \  3.08 passes/s]\r\n#Running MIL backend_mlprogram pipeline: 100%|\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11/11 [00:00<00:00,\
          \ 76.27 passes/s]"
        updatedAt: '2023-09-05T12:32:26.331Z'
      numEdits: 0
      reactions: []
    id: 64f71fda7c77bf9c8ab8e5ce
    type: comment
  author: OwenHong
  content: "I am an iOS developer with only a basic understanding of PyTorch and machine\
    \ learning. I tried to convert the Taiyi model to the CoreML format. Below is\
    \ my code. Although I successfully exported the model, the text feature vectors\
    \ inferred on the client side often fail to retrieve relevant images. Could you\
    \ please help me check if my convert process is correct? I would really appreciate\
    \ it.\r\n```\r\n!pip install coremltools==7.0b2\r\n!pip install transformers\r\
    \nimport torch\r\nfrom transformers import BertForSequenceClassification, BertConfig,\
    \ BertTokenizer\r\nfrom transformers import CLIPProcessor, CLIPModel\r\nimport\
    \ numpy as np\r\nimport coremltools as ct\r\n\r\ntext_tokenizer = BertTokenizer.from_pretrained(\"\
    IDEA-CCNL/Taiyi-CLIP-Roberta-102M-Chinese\")\r\ntext_encoder = BertForSequenceClassification.from_pretrained(\"\
    IDEA-CCNL/Taiyi-CLIP-Roberta-102M-Chinese\",return_dict=False)\r\nexample_input\
    \ = text_tokenizer([\"\u5C0F\u72D7\"], return_tensors='pt', max_length=75, padding='max_length')[\"\
    input_ids\"]\r\ntraced_model = torch.jit.trace(text_encoder, example_input, strict=False)\r\
    \ntext_encoder_model = ct.convert(\r\n            traced_model,\r\n          \
    \  convert_to=\"mlprogram\",\r\n            minimum_deployment_target=ct.target.iOS16,\r\
    \n            inputs=[ct.TensorType(name=\"prompt\",\r\n                     \
    \            shape=example_input.shape)],\r\n            outputs=[ct.TensorType(name=\"\
    embOutput\", dtype=np.float32)],\r\n        )\r\ntext_encoder_model.save(\"TextEncoder_float32_taiyi.mlpackage\"\
    )\r\n```\r\nHere is the convert log:\r\n#WARNING:coremltools:Tuple detected at\
    \ graph output. This will be flattened in the converted model.\r\n#Converting\
    \ PyTorch Frontend ==> MIL Ops:   0%|          | 0/639 [00:00<?, ? ops/s]WARNING:coremltools:Core\
    \ ML embedding (gather) #layer does not support any inputs besides the weights\
    \ and indices. Those given will be ignored.\r\n#Converting PyTorch Frontend ==>\
    \ MIL Ops: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589|\
    \ 637/639 [00:00<00:00, 2247.71 ops/s]\r\n#Running MIL frontend_pytorch pipeline:\
    \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00<00:00,\
    \ 120.25 passes/s]\r\n#Running MIL default pipeline: 100%|\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588| 66/66 [00:21<00:00,  3.08 passes/s]\r\n\
    #Running MIL backend_mlprogram pipeline: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588| 11/11 [00:00<00:00, 76.27 passes/s]"
  created_at: 2023-09-05 11:32:26+00:00
  edited: false
  hidden: false
  id: 64f71fda7c77bf9c8ab8e5ce
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: IDEA-CCNL/Taiyi-CLIP-Roberta-102M-Chinese
repo_type: model
status: open
target_branch: null
title: Convert text_encoder to CoreML by coremltools
