!!python/object:huggingface_hub.community.DiscussionWithDetails
author: brucethemoose
conflicting_files: null
created_at: 2023-11-07 05:37:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
      fullname: brucethemoose
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: brucethemoose
      type: user
    createdAt: '2023-11-07T05:37:55.000Z'
    data:
      edited: false
      editors:
      - brucethemoose
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.948431134223938
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
          fullname: brucethemoose
          isHf: false
          isPro: false
          name: brucethemoose
          type: user
        html: '<p>This Lora works well! It makes Yi-34B-200K understand Alpaca syntax
          (even though that''s not even the base model for this lora) and seems to
          keep it coherent.</p>

          <p>Not sure how it works at extremely long context. We shall see.</p>

          '
        raw: "This Lora works well! It makes Yi-34B-200K understand Alpaca syntax\
          \ (even though that's not even the base model for this lora) and seems to\
          \ keep it coherent.\r\n\r\nNot sure how it works at extremely long context.\
          \ We shall see."
        updatedAt: '2023-11-07T05:37:55.327Z'
      numEdits: 0
      reactions: []
    id: 6549cd33212b5bd749ca0f39
    type: comment
  author: brucethemoose
  content: "This Lora works well! It makes Yi-34B-200K understand Alpaca syntax (even\
    \ though that's not even the base model for this lora) and seems to keep it coherent.\r\
    \n\r\nNot sure how it works at extremely long context. We shall see."
  created_at: 2023-11-07 05:37:55+00:00
  edited: false
  hidden: false
  id: 6549cd33212b5bd749ca0f39
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661737644873-noauth.jpeg?w=200&h=200&f=face
      fullname: triad party
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: TriadParty
      type: user
    createdAt: '2023-11-07T06:35:23.000Z'
    data:
      edited: false
      editors:
      - TriadParty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9397674798965454
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661737644873-noauth.jpeg?w=200&h=200&f=face
          fullname: triad party
          isHf: false
          isPro: false
          name: TriadParty
          type: user
        html: '<blockquote>

          <p>This Lora works well! It makes Yi-34B-200K understand Alpaca syntax (even
          though that''s not even the base model for this lora) and seems to keep
          it coherent.</p>

          <p>Not sure how it works at extremely long context. We shall see.</p>

          </blockquote>

          <p>Thanks, if you have some good datasets or advices to improve the chat,
          let me know</p>

          '
        raw: "> This Lora works well! It makes Yi-34B-200K understand Alpaca syntax\
          \ (even though that's not even the base model for this lora) and seems to\
          \ keep it coherent.\n> \n> Not sure how it works at extremely long context.\
          \ We shall see.\n\nThanks, if you have some good datasets or advices to\
          \ improve the chat, let me know"
        updatedAt: '2023-11-07T06:35:23.656Z'
      numEdits: 0
      reactions: []
    id: 6549daab3ce45eb76417f8d5
    type: comment
  author: TriadParty
  content: "> This Lora works well! It makes Yi-34B-200K understand Alpaca syntax\
    \ (even though that's not even the base model for this lora) and seems to keep\
    \ it coherent.\n> \n> Not sure how it works at extremely long context. We shall\
    \ see.\n\nThanks, if you have some good datasets or advices to improve the chat,\
    \ let me know"
  created_at: 2023-11-07 06:35:23+00:00
  edited: false
  hidden: false
  id: 6549daab3ce45eb76417f8d5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6391f799f112e7097aea0b8d/TYUzVrosZd6s04jQ8IG-U.jpeg?w=200&h=200&f=face
      fullname: "Timon K\xE4ch"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CyberTimon
      type: user
    createdAt: '2023-11-07T07:56:43.000Z'
    data:
      edited: false
      editors:
      - CyberTimon
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9516124129295349
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6391f799f112e7097aea0b8d/TYUzVrosZd6s04jQ8IG-U.jpeg?w=200&h=200&f=face
          fullname: "Timon K\xE4ch"
          isHf: false
          isPro: false
          name: CyberTimon
          type: user
        html: '<p>If you have time, maybe you can finetune it on this, or even just
          on a small part of this? <a href="https://huggingface.co/datasets/jondurbin/airoboros-2.2.1">https://huggingface.co/datasets/jondurbin/airoboros-2.2.1</a><br>Thank
          you very much</p>

          '
        raw: 'If you have time, maybe you can finetune it on this, or even just on
          a small part of this? https://huggingface.co/datasets/jondurbin/airoboros-2.2.1

          Thank you very much'
        updatedAt: '2023-11-07T07:56:43.687Z'
      numEdits: 0
      reactions: []
    id: 6549edbb5cd49b32f62f5e98
    type: comment
  author: CyberTimon
  content: 'If you have time, maybe you can finetune it on this, or even just on a
    small part of this? https://huggingface.co/datasets/jondurbin/airoboros-2.2.1

    Thank you very much'
  created_at: 2023-11-07 07:56:43+00:00
  edited: false
  hidden: false
  id: 6549edbb5cd49b32f62f5e98
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661737644873-noauth.jpeg?w=200&h=200&f=face
      fullname: triad party
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: TriadParty
      type: user
    createdAt: '2023-11-07T09:06:54.000Z'
    data:
      edited: false
      editors:
      - TriadParty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9646419286727905
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661737644873-noauth.jpeg?w=200&h=200&f=face
          fullname: triad party
          isHf: false
          isPro: false
          name: TriadParty
          type: user
        html: '<blockquote>

          <p>If you have time, maybe you can finetune it on this, or even just on
          a small part of this? <a href="https://huggingface.co/datasets/jondurbin/airoboros-2.2.1">https://huggingface.co/datasets/jondurbin/airoboros-2.2.1</a><br>Thank
          you very much</p>

          </blockquote>

          <p>Thanks, I''ve seen that there are some new dataset, such as <a href="https://huggingface.co/datasets/jondurbin/airoboros-3.1">https://huggingface.co/datasets/jondurbin/airoboros-3.1</a>
          . And I can''t recognize their difference. Will it be better than old ones?</p>

          '
        raw: '> If you have time, maybe you can finetune it on this, or even just
          on a small part of this? https://huggingface.co/datasets/jondurbin/airoboros-2.2.1

          > Thank you very much


          Thanks, I''ve seen that there are some new dataset, such as https://huggingface.co/datasets/jondurbin/airoboros-3.1
          . And I can''t recognize their difference. Will it be better than old ones?'
        updatedAt: '2023-11-07T09:06:54.822Z'
      numEdits: 0
      reactions: []
    id: 6549fe2e137b501e3169cb53
    type: comment
  author: TriadParty
  content: '> If you have time, maybe you can finetune it on this, or even just on
    a small part of this? https://huggingface.co/datasets/jondurbin/airoboros-2.2.1

    > Thank you very much


    Thanks, I''ve seen that there are some new dataset, such as https://huggingface.co/datasets/jondurbin/airoboros-3.1
    . And I can''t recognize their difference. Will it be better than old ones?'
  created_at: 2023-11-07 09:06:54+00:00
  edited: false
  hidden: false
  id: 6549fe2e137b501e3169cb53
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6391f799f112e7097aea0b8d/TYUzVrosZd6s04jQ8IG-U.jpeg?w=200&h=200&f=face
      fullname: "Timon K\xE4ch"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CyberTimon
      type: user
    createdAt: '2023-11-07T13:28:30.000Z'
    data:
      edited: false
      editors:
      - CyberTimon
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9564077258110046
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6391f799f112e7097aea0b8d/TYUzVrosZd6s04jQ8IG-U.jpeg?w=200&h=200&f=face
          fullname: "Timon K\xE4ch"
          isHf: false
          isPro: false
          name: CyberTimon
          type: user
        html: '<blockquote>

          <blockquote>

          <p>If you have time, maybe you can finetune it on this, or even just on
          a small part of this? <a href="https://huggingface.co/datasets/jondurbin/airoboros-2.2.1">https://huggingface.co/datasets/jondurbin/airoboros-2.2.1</a><br>Thank
          you very much</p>

          </blockquote>

          <p>Thanks, I''ve seen that there are some new dataset, such as <a href="https://huggingface.co/datasets/jondurbin/airoboros-3.1">https://huggingface.co/datasets/jondurbin/airoboros-3.1</a>
          . And I can''t recognize their difference. Will it be better than old ones?</p>

          </blockquote>

          <p>That''s a interesting question. In my opinion, I like 2.2.1 more, because
          it''s in ShareGPT format and seems less buggy. Others prefer 3.1. It''s
          up to you what you train on, but I would love to see Vicuna ShareGPT 2.2.1.
          But if you want to use 3.1, please use the no_mathjson version, because
          the mathjson version is known to make the model dumber.</p>

          <p>Kind regards and thanks</p>

          '
        raw: "> > If you have time, maybe you can finetune it on this, or even just\
          \ on a small part of this? https://huggingface.co/datasets/jondurbin/airoboros-2.2.1\n\
          > > Thank you very much\n> \n> Thanks, I've seen that there are some new\
          \ dataset, such as https://huggingface.co/datasets/jondurbin/airoboros-3.1\
          \ . And I can't recognize their difference. Will it be better than old ones?\n\
          \nThat's a interesting question. In my opinion, I like 2.2.1 more, because\
          \ it's in ShareGPT format and seems less buggy. Others prefer 3.1. It's\
          \ up to you what you train on, but I would love to see Vicuna ShareGPT 2.2.1.\
          \ But if you want to use 3.1, please use the no_mathjson version, because\
          \ the mathjson version is known to make the model dumber.\n\nKind regards\
          \ and thanks"
        updatedAt: '2023-11-07T13:28:30.463Z'
      numEdits: 0
      reactions: []
    id: 654a3b7e32d67f12f8663f30
    type: comment
  author: CyberTimon
  content: "> > If you have time, maybe you can finetune it on this, or even just\
    \ on a small part of this? https://huggingface.co/datasets/jondurbin/airoboros-2.2.1\n\
    > > Thank you very much\n> \n> Thanks, I've seen that there are some new dataset,\
    \ such as https://huggingface.co/datasets/jondurbin/airoboros-3.1 . And I can't\
    \ recognize their difference. Will it be better than old ones?\n\nThat's a interesting\
    \ question. In my opinion, I like 2.2.1 more, because it's in ShareGPT format\
    \ and seems less buggy. Others prefer 3.1. It's up to you what you train on, but\
    \ I would love to see Vicuna ShareGPT 2.2.1. But if you want to use 3.1, please\
    \ use the no_mathjson version, because the mathjson version is known to make the\
    \ model dumber.\n\nKind regards and thanks"
  created_at: 2023-11-07 13:28:30+00:00
  edited: false
  hidden: false
  id: 654a3b7e32d67f12f8663f30
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
      fullname: brucethemoose
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: brucethemoose
      type: user
    createdAt: '2023-11-07T15:57:07.000Z'
    data:
      edited: true
      editors:
      - brucethemoose
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9295600652694702
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
          fullname: brucethemoose
          isHf: false
          isPro: false
          name: brucethemoose
          type: user
        html: '<blockquote>

          <blockquote>

          <p>This Lora works well! It makes Yi-34B-200K understand Alpaca syntax (even
          though that''s not even the base model for this lora) and seems to keep
          it coherent.</p>

          <p>Not sure how it works at extremely long context. We shall see.</p>

          </blockquote>

          <p>Thanks, if you have some good datasets or advices to improve the chat,
          let me know</p>

          </blockquote>

          <p>CoT is good!</p>

          <p>CollectiveCognition seems to be very effective, and its so small that
          you could match the format to another dataset and throw it in.</p>

          <p><a href="https://huggingface.co/CollectiveCognition">https://huggingface.co/CollectiveCognition</a></p>

          <p>Or maybe Ultrachat, if you just use the highest rated (all 5) responses:
          <a href="https://huggingface.co/datasets/openbmb/UltraFeedback/viewer/default/train?p=1&amp;row=118">https://huggingface.co/datasets/openbmb/UltraFeedback/viewer/default/train?p=1&amp;row=118</a></p>

          <p>Really, the big thing would just be to use the Yi 200K model as a base
          model, and train it with a longish context.</p>

          '
        raw: "> > This Lora works well! It makes Yi-34B-200K understand Alpaca syntax\
          \ (even though that's not even the base model for this lora) and seems to\
          \ keep it coherent.\n> > \n> > Not sure how it works at extremely long context.\
          \ We shall see.\n> \n> Thanks, if you have some good datasets or advices\
          \ to improve the chat, let me know\n\nCoT is good!\n\nCollectiveCognition\
          \ seems to be very effective, and its so small that you could match the\
          \ format to another dataset and throw it in.\n\nhttps://huggingface.co/CollectiveCognition\n\
          \nOr maybe Ultrachat, if you just use the highest rated (all 5) responses:\
          \ https://huggingface.co/datasets/openbmb/UltraFeedback/viewer/default/train?p=1&row=118\n\
          \nReally, the big thing would just be to use the Yi 200K model as a base\
          \ model, and train it with a longish context."
        updatedAt: '2023-11-07T16:14:13.288Z'
      numEdits: 2
      reactions: []
    id: 654a5e53c70ba116b119583b
    type: comment
  author: brucethemoose
  content: "> > This Lora works well! It makes Yi-34B-200K understand Alpaca syntax\
    \ (even though that's not even the base model for this lora) and seems to keep\
    \ it coherent.\n> > \n> > Not sure how it works at extremely long context. We\
    \ shall see.\n> \n> Thanks, if you have some good datasets or advices to improve\
    \ the chat, let me know\n\nCoT is good!\n\nCollectiveCognition seems to be very\
    \ effective, and its so small that you could match the format to another dataset\
    \ and throw it in.\n\nhttps://huggingface.co/CollectiveCognition\n\nOr maybe Ultrachat,\
    \ if you just use the highest rated (all 5) responses: https://huggingface.co/datasets/openbmb/UltraFeedback/viewer/default/train?p=1&row=118\n\
    \nReally, the big thing would just be to use the Yi 200K model as a base model,\
    \ and train it with a longish context."
  created_at: 2023-11-07 15:57:07+00:00
  edited: true
  hidden: false
  id: 654a5e53c70ba116b119583b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TriadParty/Yi-34b-alpaca-cot-lora
repo_type: model
status: open
target_branch: null
title: Good!
