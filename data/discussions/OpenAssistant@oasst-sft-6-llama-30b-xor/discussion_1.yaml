!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ByteSized
conflicting_files: null
created_at: 2023-04-22 18:22:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/89eeb2386413816cb205d5febda99d93.svg
      fullname: Elijah Kulpinski
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ByteSized
      type: user
    createdAt: '2023-04-22T19:22:01.000Z'
    data:
      edited: true
      editors:
      - ByteSized
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/89eeb2386413816cb205d5febda99d93.svg
          fullname: Elijah Kulpinski
          isHf: false
          isPro: false
          name: ByteSized
          type: user
        html: '<p>I logged my experience following the old ReadMe.md on the discord
          channel help-each-other 04/22/23 at 4:33 am and noticed how impactful the
          dependency versions were when troubleshooting and wanted to start a conversation
          on any non-recommended versions people got working for them. For me, I managed
          to get the following working:</p>

          <p>-Torch at v2.0.0, at 1.13.0 the script "ran" but gave zero output due
          to not actually running beyond the import torch statement.<br>-I uninstalled
          and reinstalled NumPy, Torch, Transformers, Tokenizers, Jax, Accelerate,
          SentencePiece and ArgParse. Then I ran xor_codec.py which worked perfectly!</p>

          <p>My reinstalled dependency versions I used were:<br>-Accelerate: 0.18.0<br>-ArgParse:
          1.4.0<br>-Jax: 0.4.8<br>-NumPy: 1.24.2<br>-Tokenizers: 0.13.3<br>-Torch:
          2.0.0<br>-Transformers (with llama): 4.28.0<br>-SentencePiece: 0.1.98</p>

          '
        raw: 'I logged my experience following the old ReadMe.md on the discord channel
          help-each-other 04/22/23 at 4:33 am and noticed how impactful the dependency
          versions were when troubleshooting and wanted to start a conversation on
          any non-recommended versions people got working for them. For me, I managed
          to get the following working:


          -Torch at v2.0.0, at 1.13.0 the script "ran" but gave zero output due to
          not actually running beyond the import torch statement.

          -I uninstalled and reinstalled NumPy, Torch, Transformers, Tokenizers, Jax,
          Accelerate, SentencePiece and ArgParse. Then I ran xor_codec.py which worked
          perfectly!


          My reinstalled dependency versions I used were:

          -Accelerate: 0.18.0

          -ArgParse: 1.4.0

          -Jax: 0.4.8

          -NumPy: 1.24.2

          -Tokenizers: 0.13.3

          -Torch: 2.0.0

          -Transformers (with llama): 4.28.0

          -SentencePiece: 0.1.98'
        updatedAt: '2023-04-22T19:26:10.983Z'
      numEdits: 2
      reactions: []
    id: 644433d92c6c12d0bb509381
    type: comment
  author: ByteSized
  content: 'I logged my experience following the old ReadMe.md on the discord channel
    help-each-other 04/22/23 at 4:33 am and noticed how impactful the dependency versions
    were when troubleshooting and wanted to start a conversation on any non-recommended
    versions people got working for them. For me, I managed to get the following working:


    -Torch at v2.0.0, at 1.13.0 the script "ran" but gave zero output due to not actually
    running beyond the import torch statement.

    -I uninstalled and reinstalled NumPy, Torch, Transformers, Tokenizers, Jax, Accelerate,
    SentencePiece and ArgParse. Then I ran xor_codec.py which worked perfectly!


    My reinstalled dependency versions I used were:

    -Accelerate: 0.18.0

    -ArgParse: 1.4.0

    -Jax: 0.4.8

    -NumPy: 1.24.2

    -Tokenizers: 0.13.3

    -Torch: 2.0.0

    -Transformers (with llama): 4.28.0

    -SentencePiece: 0.1.98'
  created_at: 2023-04-22 18:22:01+00:00
  edited: true
  hidden: false
  id: 644433d92c6c12d0bb509381
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b37d0ca991cec7656ef9519c2032bdf5.svg
      fullname: Bow Wow
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tsumeone
      type: user
    createdAt: '2023-04-22T19:42:57.000Z'
    data:
      edited: false
      editors:
      - tsumeone
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b37d0ca991cec7656ef9519c2032bdf5.svg
          fullname: Bow Wow
          isHf: false
          isPro: false
          name: tsumeone
          type: user
        html: '<p>I tried this on Windows with all the recommended stuff except I
          used Torch v2.0.0.  The .bin files turned out correctly, but .config files
          did not.  Did the same but on Linux (all recommended requirements, except
          I used Torch 2.0.0) and it turned out fine.  I know it''s essentially an
          unwritten statement that Linux is required for most of this ML stuff since
          that''s what everyone develops on, but figured I''d throw in my experience
          here in case anyone ran into that.</p>

          '
        raw: I tried this on Windows with all the recommended stuff except I used
          Torch v2.0.0.  The .bin files turned out correctly, but .config files did
          not.  Did the same but on Linux (all recommended requirements, except I
          used Torch 2.0.0) and it turned out fine.  I know it's essentially an unwritten
          statement that Linux is required for most of this ML stuff since that's
          what everyone develops on, but figured I'd throw in my experience here in
          case anyone ran into that.
        updatedAt: '2023-04-22T19:42:57.104Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Tiger37
    id: 644438c15298d19c9c02e484
    type: comment
  author: tsumeone
  content: I tried this on Windows with all the recommended stuff except I used Torch
    v2.0.0.  The .bin files turned out correctly, but .config files did not.  Did
    the same but on Linux (all recommended requirements, except I used Torch 2.0.0)
    and it turned out fine.  I know it's essentially an unwritten statement that Linux
    is required for most of this ML stuff since that's what everyone develops on,
    but figured I'd throw in my experience here in case anyone ran into that.
  created_at: 2023-04-22 18:42:57+00:00
  edited: false
  hidden: false
  id: 644438c15298d19c9c02e484
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/20d40755196d07a3e9ce2ac65d322d10.svg
      fullname: Nico Bosshard
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nicoboss
      type: user
    createdAt: '2023-04-22T20:39:47.000Z'
    data:
      edited: false
      editors:
      - nicoboss
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/20d40755196d07a3e9ce2ac65d322d10.svg
          fullname: Nico Bosshard
          isHf: false
          isPro: false
          name: nicoboss
          type: user
        html: '<blockquote>

          <p>I tried this on Windows with all the recommended stuff except I used
          Torch v2.0.0.  The .bin files turned out correctly, but .config files did
          not.  Did the same but on Linux (all recommended requirements, except I
          used Torch 2.0.0) and it turned out fine.  I know it''s essentially an unwritten
          statement that Linux is required for most of this ML stuff since that''s
          what everyone develops on, but figured I''d throw in my experience here
          in case anyone ran into that.</p>

          </blockquote>

          <p>The only thing wrong on Windows when using the recommended versions is
          the line ending being CRLF instead of LF for the following 5 files. Just
          use Notepad++ (Edit =&gt; EOL Conversion =&gt; LF) to convert them to the
          proper line-ending and the hashes will match.</p>

          <p>CRLF line-endings (Windows):<br>0535e243e10a8ecf23bc49ed3590ed10 *./config.json<br>d200625bb1bcee9e13e1ae30d248b146
          *./generation_config.json<br>65d69efafc2ed43ec0a5e9b5c3f922c7 *./pytorch_model.bin.index.json<br>6e047cb153d02be1fe3d3e48ff2db212
          *./special_tokens_map.json<br>a00577426803c15aaf3ae8b864d1e9e6 *./tokenizer_config.json</p>

          <p>LF line-endings (Linux):<br>598538f18fed1877b41f77de034c0c8a *./config.json<br>aee09e21813368c49baaece120125ae3
          *./generation_config.json<br>fecfda4fba7bfd911e187a85db5fa2ef *./pytorch_model.bin.index.json<br>6b2e0a735969660e720c27061ef3f3d3
          *./special_tokens_map.json<br>edd1a5897748864768b1fab645b31491 *./tokenizer_config.json</p>

          '
        raw: '> I tried this on Windows with all the recommended stuff except I used
          Torch v2.0.0.  The .bin files turned out correctly, but .config files did
          not.  Did the same but on Linux (all recommended requirements, except I
          used Torch 2.0.0) and it turned out fine.  I know it''s essentially an unwritten
          statement that Linux is required for most of this ML stuff since that''s
          what everyone develops on, but figured I''d throw in my experience here
          in case anyone ran into that.


          The only thing wrong on Windows when using the recommended versions is the
          line ending being CRLF instead of LF for the following 5 files. Just use
          Notepad++ (Edit => EOL Conversion => LF) to convert them to the proper line-ending
          and the hashes will match.


          CRLF line-endings (Windows):

          0535e243e10a8ecf23bc49ed3590ed10 *./config.json

          d200625bb1bcee9e13e1ae30d248b146 *./generation_config.json

          65d69efafc2ed43ec0a5e9b5c3f922c7 *./pytorch_model.bin.index.json

          6e047cb153d02be1fe3d3e48ff2db212 *./special_tokens_map.json

          a00577426803c15aaf3ae8b864d1e9e6 *./tokenizer_config.json


          LF line-endings (Linux):

          598538f18fed1877b41f77de034c0c8a *./config.json

          aee09e21813368c49baaece120125ae3 *./generation_config.json

          fecfda4fba7bfd911e187a85db5fa2ef *./pytorch_model.bin.index.json

          6b2e0a735969660e720c27061ef3f3d3 *./special_tokens_map.json

          edd1a5897748864768b1fab645b31491 *./tokenizer_config.json'
        updatedAt: '2023-04-22T20:39:47.423Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\u2764\uFE0F"
        users:
        - tsumeone
        - ByteSized
        - andreaskoepf
        - Tiger37
        - JoshuaJacobsen
    id: 64444613c63001ae6355dda7
    type: comment
  author: nicoboss
  content: '> I tried this on Windows with all the recommended stuff except I used
    Torch v2.0.0.  The .bin files turned out correctly, but .config files did not.  Did
    the same but on Linux (all recommended requirements, except I used Torch 2.0.0)
    and it turned out fine.  I know it''s essentially an unwritten statement that
    Linux is required for most of this ML stuff since that''s what everyone develops
    on, but figured I''d throw in my experience here in case anyone ran into that.


    The only thing wrong on Windows when using the recommended versions is the line
    ending being CRLF instead of LF for the following 5 files. Just use Notepad++
    (Edit => EOL Conversion => LF) to convert them to the proper line-ending and the
    hashes will match.


    CRLF line-endings (Windows):

    0535e243e10a8ecf23bc49ed3590ed10 *./config.json

    d200625bb1bcee9e13e1ae30d248b146 *./generation_config.json

    65d69efafc2ed43ec0a5e9b5c3f922c7 *./pytorch_model.bin.index.json

    6e047cb153d02be1fe3d3e48ff2db212 *./special_tokens_map.json

    a00577426803c15aaf3ae8b864d1e9e6 *./tokenizer_config.json


    LF line-endings (Linux):

    598538f18fed1877b41f77de034c0c8a *./config.json

    aee09e21813368c49baaece120125ae3 *./generation_config.json

    fecfda4fba7bfd911e187a85db5fa2ef *./pytorch_model.bin.index.json

    6b2e0a735969660e720c27061ef3f3d3 *./special_tokens_map.json

    edd1a5897748864768b1fab645b31491 *./tokenizer_config.json'
  created_at: 2023-04-22 19:39:47+00:00
  edited: false
  hidden: false
  id: 64444613c63001ae6355dda7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: OpenAssistant/oasst-sft-6-llama-30b-xor
repo_type: model
status: open
target_branch: null
title: Dependency Versions
