!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Akhalee
conflicting_files: null
created_at: 2023-04-28 07:40:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0e0ecdde48c83174ef589347b3c634db.svg
      fullname: shyfoo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Akhalee
      type: user
    createdAt: '2023-04-28T08:40:53.000Z'
    data:
      edited: false
      editors:
      - Akhalee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0e0ecdde48c83174ef589347b3c634db.svg
          fullname: shyfoo
          isHf: false
          isPro: false
          name: Akhalee
          type: user
        html: '<p>What happened?</p>

          '
        raw: What happened?
        updatedAt: '2023-04-28T08:40:53.372Z'
      numEdits: 0
      reactions: []
    id: 644b86956ebb3ebf72642bbc
    type: comment
  author: Akhalee
  content: What happened?
  created_at: 2023-04-28 07:40:53+00:00
  edited: false
  hidden: false
  id: 644b86956ebb3ebf72642bbc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/MlZYhM-Qyc43EBwEg7lIf.png?w=200&h=200&f=face
      fullname: Olamedia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: olamedia
      type: user
    createdAt: '2023-04-29T16:54:40.000Z'
    data:
      edited: false
      editors:
      - olamedia
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/MlZYhM-Qyc43EBwEg7lIf.png?w=200&h=200&f=face
          fullname: Olamedia
          isHf: false
          isPro: false
          name: olamedia
          type: user
        html: '<p>open it in editor, it seems the xor requires exact md5 sums not
          only for model, but for json files too</p>

          '
        raw: open it in editor, it seems the xor requires exact md5 sums not only
          for model, but for json files too
        updatedAt: '2023-04-29T16:54:40.072Z'
      numEdits: 0
      reactions: []
    id: 644d4bd0fa94e93b0ec841ab
    type: comment
  author: olamedia
  content: open it in editor, it seems the xor requires exact md5 sums not only for
    model, but for json files too
  created_at: 2023-04-29 15:54:40+00:00
  edited: false
  hidden: false
  id: 644d4bd0fa94e93b0ec841ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/MlZYhM-Qyc43EBwEg7lIf.png?w=200&h=200&f=face
      fullname: Olamedia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: olamedia
      type: user
    createdAt: '2023-04-29T17:08:57.000Z'
    data:
      edited: false
      editors:
      - olamedia
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/MlZYhM-Qyc43EBwEg7lIf.png?w=200&h=200&f=face
          fullname: Olamedia
          isHf: false
          isPro: false
          name: olamedia
          type: user
        html: '<p>It seems, the problem can be with CRLF on windows vs LF line endings
          in converted LLaMA model configs.</p>

          '
        raw: It seems, the problem can be with CRLF on windows vs LF line endings
          in converted LLaMA model configs.
        updatedAt: '2023-04-29T17:08:57.973Z'
      numEdits: 0
      reactions: []
    id: 644d4f290dc952d245a216d8
    type: comment
  author: olamedia
  content: It seems, the problem can be with CRLF on windows vs LF line endings in
    converted LLaMA model configs.
  created_at: 2023-04-29 16:08:57+00:00
  edited: false
  hidden: false
  id: 644d4f290dc952d245a216d8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0e0ecdde48c83174ef589347b3c634db.svg
      fullname: shyfoo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Akhalee
      type: user
    createdAt: '2023-05-09T03:20:53.000Z'
    data:
      edited: false
      editors:
      - Akhalee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0e0ecdde48c83174ef589347b3c634db.svg
          fullname: shyfoo
          isHf: false
          isPro: false
          name: Akhalee
          type: user
        html: '<blockquote>

          <p>It seems, the problem can be with CRLF on windows vs LF line endings
          in converted LLaMA model configs.</p>

          </blockquote>

          <p>I just downloaded the config.json and did not change it. Could you give
          more details? I have not idea what you say, thanks.</p>

          '
        raw: '> It seems, the problem can be with CRLF on windows vs LF line endings
          in converted LLaMA model configs.


          I just downloaded the config.json and did not change it. Could you give
          more details? I have not idea what you say, thanks.'
        updatedAt: '2023-05-09T03:20:53.479Z'
      numEdits: 0
      reactions: []
    id: 6459bc15232e5f0712c052a9
    type: comment
  author: Akhalee
  content: '> It seems, the problem can be with CRLF on windows vs LF line endings
    in converted LLaMA model configs.


    I just downloaded the config.json and did not change it. Could you give more details?
    I have not idea what you say, thanks.'
  created_at: 2023-05-09 02:20:53+00:00
  edited: false
  hidden: false
  id: 6459bc15232e5f0712c052a9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/MlZYhM-Qyc43EBwEg7lIf.png?w=200&h=200&f=face
      fullname: Olamedia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: olamedia
      type: user
    createdAt: '2023-05-09T13:14:03.000Z'
    data:
      edited: false
      editors:
      - olamedia
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/MlZYhM-Qyc43EBwEg7lIf.png?w=200&h=200&f=face
          fullname: Olamedia
          isHf: false
          isPro: false
          name: olamedia
          type: user
        html: '<blockquote>

          <p>I just downloaded the config.json and did not change it. Could you give
          more details? I have not idea what you say, thanks.</p>

          </blockquote>

          <p>repository contains model diffs, not the model itself. you need to get
          llama model and config files with exact checksums as in readme and to follow
          readme instructions</p>

          '
        raw: '> I just downloaded the config.json and did not change it. Could you
          give more details? I have not idea what you say, thanks.


          repository contains model diffs, not the model itself. you need to get llama
          model and config files with exact checksums as in readme and to follow readme
          instructions'
        updatedAt: '2023-05-09T13:14:03.732Z'
      numEdits: 0
      reactions: []
    id: 645a471b18dab594c5b9ce65
    type: comment
  author: olamedia
  content: '> I just downloaded the config.json and did not change it. Could you give
    more details? I have not idea what you say, thanks.


    repository contains model diffs, not the model itself. you need to get llama model
    and config files with exact checksums as in readme and to follow readme instructions'
  created_at: 2023-05-09 12:14:03+00:00
  edited: false
  hidden: false
  id: 645a471b18dab594c5b9ce65
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0e0ecdde48c83174ef589347b3c634db.svg
      fullname: shyfoo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Akhalee
      type: user
    createdAt: '2023-05-09T13:27:16.000Z'
    data:
      edited: true
      editors:
      - Akhalee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0e0ecdde48c83174ef589347b3c634db.svg
          fullname: shyfoo
          isHf: false
          isPro: false
          name: Akhalee
          type: user
        html: '<p>ok</p>

          '
        raw: ok
        updatedAt: '2023-05-09T13:28:11.675Z'
      numEdits: 1
      reactions: []
    id: 645a4a34c4e2df57a4d1a7d8
    type: comment
  author: Akhalee
  content: ok
  created_at: 2023-05-09 12:27:16+00:00
  edited: true
  hidden: false
  id: 645a4a34c4e2df57a4d1a7d8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0e0ecdde48c83174ef589347b3c634db.svg
      fullname: shyfoo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Akhalee
      type: user
    createdAt: '2023-05-09T13:27:51.000Z'
    data:
      edited: false
      editors:
      - Akhalee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0e0ecdde48c83174ef589347b3c634db.svg
          fullname: shyfoo
          isHf: false
          isPro: false
          name: Akhalee
          type: user
        html: '<blockquote>

          <blockquote>

          <p>I just downloaded the config.json and did not change it. Could you give
          more details? I have not idea what you say, thanks.</p>

          </blockquote>

          <p>repository contains model diffs, not the model itself. you need to get
          llama model and config files with exact checksums as in readme and to follow
          readme instructions</p>

          </blockquote>

          <p>thanks for your immediate reply! i will have a try.</p>

          '
        raw: "> > I just downloaded the config.json and did not change it. Could you\
          \ give more details? I have not idea what you say, thanks.\n> \n> repository\
          \ contains model diffs, not the model itself. you need to get llama model\
          \ and config files with exact checksums as in readme and to follow readme\
          \ instructions\n\nthanks for your immediate reply! i will have a try."
        updatedAt: '2023-05-09T13:27:51.129Z'
      numEdits: 0
      reactions: []
    id: 645a4a57c4e2df57a4d1af20
    type: comment
  author: Akhalee
  content: "> > I just downloaded the config.json and did not change it. Could you\
    \ give more details? I have not idea what you say, thanks.\n> \n> repository contains\
    \ model diffs, not the model itself. you need to get llama model and config files\
    \ with exact checksums as in readme and to follow readme instructions\n\nthanks\
    \ for your immediate reply! i will have a try."
  created_at: 2023-05-09 12:27:51+00:00
  edited: false
  hidden: false
  id: 645a4a57c4e2df57a4d1af20
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 27
repo_id: OpenAssistant/oasst-sft-6-llama-30b-xor
repo_type: model
status: open
target_branch: null
title: 'OSError: It looks like the config file at ''./data/config.json'' is not a
  valid JSON file.'
