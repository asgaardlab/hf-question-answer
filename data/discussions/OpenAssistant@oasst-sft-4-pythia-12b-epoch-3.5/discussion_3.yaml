!!python/object:huggingface_hub.community.DiscussionWithDetails
author: gsaivinay
conflicting_files: null
created_at: 2023-04-16 08:39:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ad4bb6fe31efe3634e349f59d6d57b79.svg
      fullname: SVG
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gsaivinay
      type: user
    createdAt: '2023-04-16T09:39:07.000Z'
    data:
      edited: false
      editors:
      - gsaivinay
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ad4bb6fe31efe3634e349f59d6d57b79.svg
          fullname: SVG
          isHf: false
          isPro: false
          name: gsaivinay
          type: user
        html: '<p>Hello, Greetings.</p>

          <p>Thanks for open sourcing this awesome model. Could anybody please answer
          few technical questions like</p>

          <p>-&gt; what is the max context length for this model.<br>-&gt; does this
          model uses same parameters as in any other text-generation model like temperature,
          sampling, top_p, top_k etc.,<br>-&gt; what are the example prompts to use
          this model for use cases like context based QA, etc.,</p>

          '
        raw: "Hello, Greetings.\r\n\r\nThanks for open sourcing this awesome model.\
          \ Could anybody please answer few technical questions like\r\n\r\n-> what\
          \ is the max context length for this model.\r\n-> does this model uses same\
          \ parameters as in any other text-generation model like temperature, sampling,\
          \ top_p, top_k etc.,\r\n-> what are the example prompts to use this model\
          \ for use cases like context based QA, etc.,"
        updatedAt: '2023-04-16T09:39:07.814Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - julian-schelb
    id: 643bc23b9f5d314db2d8d067
    type: comment
  author: gsaivinay
  content: "Hello, Greetings.\r\n\r\nThanks for open sourcing this awesome model.\
    \ Could anybody please answer few technical questions like\r\n\r\n-> what is the\
    \ max context length for this model.\r\n-> does this model uses same parameters\
    \ as in any other text-generation model like temperature, sampling, top_p, top_k\
    \ etc.,\r\n-> what are the example prompts to use this model for use cases like\
    \ context based QA, etc.,"
  created_at: 2023-04-16 08:39:07+00:00
  edited: false
  hidden: false
  id: 643bc23b9f5d314db2d8d067
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5
repo_type: model
status: open
target_branch: null
title: Some Technical and Usage Information
