!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kmargatina
conflicting_files: null
created_at: 2022-09-28 16:58:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7982a97774742086eace7906203cad9a.svg
      fullname: Katerina Margatina
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kmargatina
      type: user
    createdAt: '2022-09-28T17:58:31.000Z'
    data:
      edited: false
      editors:
      - kmargatina
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7982a97774742086eace7906203cad9a.svg
          fullname: Katerina Margatina
          isHf: false
          isPro: false
          name: kmargatina
          type: user
        html: '<p>How can I reproduce the results for the bias/fairness evaluation?
          It is not clear from the paper how you cast CrowS-Pairs, WinoGender and
          WinoBias as classification tasks. Did you use specific templates for these
          tasks?</p>

          <p>"For each dataset, we evaluate between 5 and 10 prompts.": What does
          this mean?</p>

          <p>Thank you in advance!</p>

          '
        raw: "How can I reproduce the results for the bias/fairness evaluation? It\
          \ is not clear from the paper how you cast CrowS-Pairs, WinoGender and WinoBias\
          \ as classification tasks. Did you use specific templates for these tasks?\r\
          \n\r\n\"For each dataset, we evaluate between 5 and 10 prompts.\": What\
          \ does this mean?\r\n\r\nThank you in advance!"
        updatedAt: '2022-09-28T17:58:31.506Z'
      numEdits: 0
      reactions: []
    id: 63348b47259c518276ebebe4
    type: comment
  author: kmargatina
  content: "How can I reproduce the results for the bias/fairness evaluation? It is\
    \ not clear from the paper how you cast CrowS-Pairs, WinoGender and WinoBias as\
    \ classification tasks. Did you use specific templates for these tasks?\r\n\r\n\
    \"For each dataset, we evaluate between 5 and 10 prompts.\": What does this mean?\r\
    \n\r\nThank you in advance!"
  created_at: 2022-09-28 16:58:31+00:00
  edited: false
  hidden: false
  id: 63348b47259c518276ebebe4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619623771844-5ecea265968f6028e0559fa5.jpeg?w=200&h=200&f=face
      fullname: Victor Sanh
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: true
      name: VictorSanh
      type: user
    createdAt: '2022-09-29T14:54:25.000Z'
    data:
      edited: false
      editors:
      - VictorSanh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619623771844-5ecea265968f6028e0559fa5.jpeg?w=200&h=200&f=face
          fullname: Victor Sanh
          isHf: true
          isPro: true
          name: VictorSanh
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;kmargatina&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/kmargatina\"\
          >@<span class=\"underline\">kmargatina</span></a></span>\n\n\t</span></span>\
          \ ,</p>\n<p>You will find the prompts used for the bias&amp;fairness evaluations\
          \ directly on promptsource (<a rel=\"nofollow\" href=\"https://github.com/bigscience-workshop/promptsource\"\
          >https://github.com/bigscience-workshop/promptsource</a>).<br>If you want\
          \ to limit variance and risk of version mismatch with the numbers reported\
          \ in the card, I would recommend taking the v0.1 or v0.2 version of the\
          \ repo.</p>\n<p>Victor</p>\n"
        raw: 'Hi @kmargatina ,


          You will find the prompts used for the bias&fairness evaluations directly
          on promptsource (https://github.com/bigscience-workshop/promptsource).

          If you want to limit variance and risk of version mismatch with the numbers
          reported in the card, I would recommend taking the v0.1 or v0.2 version
          of the repo.


          Victor'
        updatedAt: '2022-09-29T14:54:25.957Z'
      numEdits: 0
      reactions: []
    id: 6335b1a161655638745d93e0
    type: comment
  author: VictorSanh
  content: 'Hi @kmargatina ,


    You will find the prompts used for the bias&fairness evaluations directly on promptsource
    (https://github.com/bigscience-workshop/promptsource).

    If you want to limit variance and risk of version mismatch with the numbers reported
    in the card, I would recommend taking the v0.1 or v0.2 version of the repo.


    Victor'
  created_at: 2022-09-29 13:54:25+00:00
  edited: false
  hidden: false
  id: 6335b1a161655638745d93e0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7982a97774742086eace7906203cad9a.svg
      fullname: Katerina Margatina
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kmargatina
      type: user
    createdAt: '2022-09-29T15:17:12.000Z'
    data:
      edited: false
      editors:
      - kmargatina
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7982a97774742086eace7906203cad9a.svg
          fullname: Katerina Margatina
          isHf: false
          isPro: false
          name: kmargatina
          type: user
        html: '<p>Thank you Victor!</p>

          '
        raw: Thank you Victor!
        updatedAt: '2022-09-29T15:17:12.372Z'
      numEdits: 0
      reactions: []
    id: 6335b6f8d184e6b53c47b601
    type: comment
  author: kmargatina
  content: Thank you Victor!
  created_at: 2022-09-29 14:17:12+00:00
  edited: false
  hidden: false
  id: 6335b6f8d184e6b53c47b601
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619623771844-5ecea265968f6028e0559fa5.jpeg?w=200&h=200&f=face
      fullname: Victor Sanh
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: true
      name: VictorSanh
      type: user
    createdAt: '2022-09-29T15:24:31.000Z'
    data:
      status: closed
    id: 6335b8af4067f020755c842e
    type: status-change
  author: VictorSanh
  created_at: 2022-09-29 14:24:31+00:00
  id: 6335b8af4067f020755c842e
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: bigscience/T0
repo_type: model
status: closed
target_branch: null
title: Bias/Fairness evaluation unclear
