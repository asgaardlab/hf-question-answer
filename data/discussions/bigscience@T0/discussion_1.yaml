!!python/object:huggingface_hub.community.DiscussionWithDetails
author: latitude
conflicting_files: null
created_at: 2022-05-25 19:20:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9d56ff540a95d44b791149922d4b93dd.svg
      fullname: Latitude
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: latitude
      type: user
    createdAt: '2022-05-25T20:20:14.000Z'
    data:
      edited: false
      editors:
      - latitude
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9d56ff540a95d44b791149922d4b93dd.svg
          fullname: Latitude
          isHf: false
          isPro: false
          name: latitude
          type: user
        html: '<p>Is there a way to use the Inference API for T0pp to fill in multiple
          tokens (including an unknown number of tokens) that have been masked (rather
          than question answering, which seems to be the default behavior)? If not,
          can you show an example of how to do it in my own code?</p>

          '
        raw: Is there a way to use the Inference API for T0pp to fill in multiple
          tokens (including an unknown number of tokens) that have been masked (rather
          than question answering, which seems to be the default behavior)? If not,
          can you show an example of how to do it in my own code?
        updatedAt: '2022-05-25T20:20:14.000Z'
      numEdits: 0
      reactions: []
    id: 628e8f7e54698ce61d1d20b2
    type: comment
  author: latitude
  content: Is there a way to use the Inference API for T0pp to fill in multiple tokens
    (including an unknown number of tokens) that have been masked (rather than question
    answering, which seems to be the default behavior)? If not, can you show an example
    of how to do it in my own code?
  created_at: 2022-05-25 19:20:14+00:00
  edited: false
  hidden: false
  id: 628e8f7e54698ce61d1d20b2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: bigscience/T0
repo_type: model
status: open
target_branch: null
title: Filling in masked tokens?
