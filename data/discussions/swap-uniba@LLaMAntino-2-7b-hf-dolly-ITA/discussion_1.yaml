!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ffedericoni
conflicting_files: null
created_at: 2023-12-30 09:06:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c1b7c5e3be2380904e116dfa72222b51.svg
      fullname: Fabrizio Federiconi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ffedericoni
      type: user
    createdAt: '2023-12-30T09:06:47.000Z'
    data:
      edited: false
      editors:
      - ffedericoni
      hidden: false
      identifiedLanguage:
        language: it
        probability: 0.9866044521331787
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c1b7c5e3be2380904e116dfa72222b51.svg
          fullname: Fabrizio Federiconi
          isHf: false
          isPro: false
          name: ffedericoni
          type: user
        html: "<p>Grazie per questi modelli in italiano.<br>Pensate di fornire versioni\
          \ pi\xF9 piccole, ad esempio quantizzate a 4 bit nei formati GGUF/AWQ?</p>\n"
        raw: "Grazie per questi modelli in italiano. \r\nPensate di fornire versioni\
          \ pi\xF9 piccole, ad esempio quantizzate a 4 bit nei formati GGUF/AWQ?"
        updatedAt: '2023-12-30T09:06:47.714Z'
      numEdits: 0
      reactions: []
    id: 658fdda7a41c3cbad571cba2
    type: comment
  author: ffedericoni
  content: "Grazie per questi modelli in italiano. \r\nPensate di fornire versioni\
    \ pi\xF9 piccole, ad esempio quantizzate a 4 bit nei formati GGUF/AWQ?"
  created_at: 2023-12-30 09:06:47+00:00
  edited: false
  hidden: false
  id: 658fdda7a41c3cbad571cba2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/63545a8e91a88bd8464a5683054e48ff.svg
      fullname: Marco Polignano
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: m-polignano-uniba
      type: user
    createdAt: '2024-01-19T16:22:15.000Z'
    data:
      edited: false
      editors:
      - m-polignano-uniba
      hidden: false
      identifiedLanguage:
        language: it
        probability: 0.9273261427879333
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/63545a8e91a88bd8464a5683054e48ff.svg
          fullname: Marco Polignano
          isHf: false
          isPro: false
          name: m-polignano-uniba
          type: user
        html: "<p>Ciao, attualmente puoi caricare il modello in versione quantizzata\
          \ usando Bitsandbytes (<a href=\"https://huggingface.co/blog/4bit-transformers-bitsandbytes\"\
          >https://huggingface.co/blog/4bit-transformers-bitsandbytes</a>). Probabilmente\
          \ rilasceremo delle versioni gi\xE0 quantizzate prossimamente. Nel frattempo\
          \ se sei interessato al topic ti consiglio di seguire la guida di llama.cpp\
          \ (<a rel=\"nofollow\" href=\"https://github.com/ggerganov/llama.cpp\">https://github.com/ggerganov/llama.cpp</a>)</p>\n"
        raw: "Ciao, attualmente puoi caricare il modello in versione quantizzata usando\
          \ Bitsandbytes (https://huggingface.co/blog/4bit-transformers-bitsandbytes).\
          \ Probabilmente rilasceremo delle versioni gi\xE0 quantizzate prossimamente.\
          \ Nel frattempo se sei interessato al topic ti consiglio di seguire la guida\
          \ di llama.cpp (https://github.com/ggerganov/llama.cpp)"
        updatedAt: '2024-01-19T16:22:15.753Z'
      numEdits: 0
      reactions: []
    id: 65aaa1b76a55aac02ab0939a
    type: comment
  author: m-polignano-uniba
  content: "Ciao, attualmente puoi caricare il modello in versione quantizzata usando\
    \ Bitsandbytes (https://huggingface.co/blog/4bit-transformers-bitsandbytes). Probabilmente\
    \ rilasceremo delle versioni gi\xE0 quantizzate prossimamente. Nel frattempo se\
    \ sei interessato al topic ti consiglio di seguire la guida di llama.cpp (https://github.com/ggerganov/llama.cpp)"
  created_at: 2024-01-19 16:22:15+00:00
  edited: false
  hidden: false
  id: 65aaa1b76a55aac02ab0939a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: swap-uniba/LLaMAntino-2-7b-hf-dolly-ITA
repo_type: model
status: open
target_branch: null
title: Quantization?
