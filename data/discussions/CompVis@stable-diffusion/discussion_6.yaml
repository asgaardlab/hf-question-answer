!!python/object:huggingface_hub.community.DiscussionWithDetails
author: wass-grass
conflicting_files: null
created_at: 2022-08-27 12:01:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ebd38f38c6ab96dc9ac50fae8f3abad.svg
      fullname: wass
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wass-grass
      type: user
    createdAt: '2022-08-27T13:01:57.000Z'
    data:
      edited: false
      editors:
      - wass-grass
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ebd38f38c6ab96dc9ac50fae8f3abad.svg
          fullname: wass
          isHf: false
          isPro: false
          name: wass-grass
          type: user
        html: '<p>Hello, the title says it all. Which minimal system requirements
          needed to run this model ? Which GPU and How much VRAM approximately? </p>

          <p>Many thanks</p>

          '
        raw: "Hello, the title says it all. Which minimal system requirements needed\
          \ to run this model ? Which GPU and How much VRAM approximately? \r\n\r\n\
          Many thanks"
        updatedAt: '2022-08-27T13:01:57.217Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - BryceW
        - MaxLohMusic
    id: 630a15c511f10445166b06ee
    type: comment
  author: wass-grass
  content: "Hello, the title says it all. Which minimal system requirements needed\
    \ to run this model ? Which GPU and How much VRAM approximately? \r\n\r\nMany\
    \ thanks"
  created_at: 2022-08-27 12:01:57+00:00
  edited: false
  hidden: false
  id: 630a15c511f10445166b06ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653497705818-noauth.png?w=200&h=200&f=face
      fullname: Nathan Lambert
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: natolambert
      type: user
    createdAt: '2022-08-30T19:35:23.000Z'
    data:
      edited: false
      editors:
      - natolambert
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653497705818-noauth.png?w=200&h=200&f=face
          fullname: Nathan Lambert
          isHf: false
          isPro: false
          name: natolambert
          type: user
        html: '<p>I think the minimum requirements are about 6900 MiB of GPU memory
          (see the <a href="https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/fp16">fp16
          branch</a>). That''s also used for this <a rel="nofollow" href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb">colab</a>.</p>

          <p>For a safe bet, the announcement blog originally said 10gb, now there
          is some <a rel="nofollow" href="https://twitter.com/EMostaque/status/1557862289394515973">twitter
          discussion</a> around 5.1 gb, but not sure how to do that.</p>

          '
        raw: 'I think the minimum requirements are about 6900 MiB of GPU memory (see
          the [fp16 branch](https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/fp16)).
          That''s also used for this [colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb).


          For a safe bet, the announcement blog originally said 10gb, now there is
          some [twitter discussion](https://twitter.com/EMostaque/status/1557862289394515973)
          around 5.1 gb, but not sure how to do that.'
        updatedAt: '2022-08-30T19:35:23.233Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - wass-grass
    id: 630e667bc6b1d1bccb81f38e
    type: comment
  author: natolambert
  content: 'I think the minimum requirements are about 6900 MiB of GPU memory (see
    the [fp16 branch](https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/fp16)).
    That''s also used for this [colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb).


    For a safe bet, the announcement blog originally said 10gb, now there is some
    [twitter discussion](https://twitter.com/EMostaque/status/1557862289394515973)
    around 5.1 gb, but not sure how to do that.'
  created_at: 2022-08-30 18:35:23+00:00
  edited: false
  hidden: false
  id: 630e667bc6b1d1bccb81f38e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/14180fdbf80c733a5205104e61283c36.svg
      fullname: Filarius
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Filarius
      type: user
    createdAt: '2022-08-31T07:32:45.000Z'
    data:
      edited: false
      editors:
      - Filarius
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/14180fdbf80c733a5205104e61283c36.svg
          fullname: Filarius
          isHf: false
          isPro: false
          name: Filarius
          type: user
        html: '<p>for weights version 1.4 with code from  <a rel="nofollow" href="https://github.com/hlky/stable-diffusion/">https://github.com/hlky/stable-diffusion/</a>
          and  <a rel="nofollow" href="https://github.com/hlky/stable-diffusion-webui/">https://github.com/hlky/stable-diffusion-webui/</a>   you
          can run with half precision and needs up to 8 Gb VRAM for 512x512 image
          size<br>with "webui.py --optimized" it run iterative and need only about
          4 Gb VRAM, but works about 4 times slower than 8Gb VRAM version<br>also
          you can look into Stable Diffusion Reddit wiki to check for new CPU-only
          versions</p>

          '
        raw: 'for weights version 1.4 with code from  https://github.com/hlky/stable-diffusion/
          and  https://github.com/hlky/stable-diffusion-webui/   you can run with
          half precision and needs up to 8 Gb VRAM for 512x512 image size

          with "webui.py --optimized" it run iterative and need only about 4 Gb VRAM,
          but works about 4 times slower than 8Gb VRAM version

          also you can look into Stable Diffusion Reddit wiki to check for new CPU-only
          versions'
        updatedAt: '2022-08-31T07:32:45.090Z'
      numEdits: 0
      reactions: []
    id: 630f0e9d4dbbbb6f667cb3cf
    type: comment
  author: Filarius
  content: 'for weights version 1.4 with code from  https://github.com/hlky/stable-diffusion/
    and  https://github.com/hlky/stable-diffusion-webui/   you can run with half precision
    and needs up to 8 Gb VRAM for 512x512 image size

    with "webui.py --optimized" it run iterative and need only about 4 Gb VRAM, but
    works about 4 times slower than 8Gb VRAM version

    also you can look into Stable Diffusion Reddit wiki to check for new CPU-only
    versions'
  created_at: 2022-08-31 06:32:45+00:00
  edited: false
  hidden: false
  id: 630f0e9d4dbbbb6f667cb3cf
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: CompVis/stable-diffusion
repo_type: model
status: open
target_branch: null
title: GPU specs to run the model
