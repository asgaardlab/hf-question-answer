!!python/object:huggingface_hub.community.DiscussionWithDetails
author: JoaoLages
conflicting_files: null
created_at: 2023-09-01 09:20:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/00a48762ed17bd95905ee6b56882072b.svg
      fullname: "Jo\xE3o Lages"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JoaoLages
      type: user
    createdAt: '2023-09-01T10:20:19.000Z'
    data:
      edited: false
      editors:
      - JoaoLages
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.48203346133232117
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/00a48762ed17bd95905ee6b56882072b.svg
          fullname: "Jo\xE3o Lages"
          isHf: false
          isPro: false
          name: JoaoLages
          type: user
        html: "<pre><code>from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"\
          Salesforce/codet5p-220m-py\")\n\ncode = \"\"\"\n    # this is a code comment\n\
          \    &lt;extra_id_0&gt;\n\"\"\"\n\nprint(tokenizer.decode(tokenizer(aux)[\"\
          input_ids\"]))\n</code></pre>\n<p>output:</p>\n<pre><code>&lt;s&gt;\n  \
          \  # this is a code comment&lt;extra_id_0&gt;\n&lt;/s&gt;\n</code></pre>\n\
          <p>It seems that \\t\\n is not being encoded (or decoded) properly :(</p>\n"
        raw: "```\r\nfrom transformers import AutoTokenizer\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
          Salesforce/codet5p-220m-py\")\r\n\r\ncode = \"\"\"\r\n    # this is a code\
          \ comment\r\n    <extra_id_0>\r\n\"\"\"\r\n\r\nprint(tokenizer.decode(tokenizer(aux)[\"\
          input_ids\"]))\r\n```\r\n\r\noutput:\r\n```\r\n<s>\r\n    # this is a code\
          \ comment<extra_id_0>\r\n</s>\r\n```\r\n\r\nIt seems that \\t\\n is not\
          \ being encoded (or decoded) properly :("
        updatedAt: '2023-09-01T10:20:19.442Z'
      numEdits: 0
      reactions: []
    id: 64f1bae3ed5646bf5eea5d18
    type: comment
  author: JoaoLages
  content: "```\r\nfrom transformers import AutoTokenizer\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
    Salesforce/codet5p-220m-py\")\r\n\r\ncode = \"\"\"\r\n    # this is a code comment\r\
    \n    <extra_id_0>\r\n\"\"\"\r\n\r\nprint(tokenizer.decode(tokenizer(aux)[\"input_ids\"\
    ]))\r\n```\r\n\r\noutput:\r\n```\r\n<s>\r\n    # this is a code comment<extra_id_0>\r\
    \n</s>\r\n```\r\n\r\nIt seems that \\t\\n is not being encoded (or decoded) properly\
    \ :("
  created_at: 2023-09-01 09:20:19+00:00
  edited: false
  hidden: false
  id: 64f1bae3ed5646bf5eea5d18
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/00a48762ed17bd95905ee6b56882072b.svg
      fullname: "Jo\xE3o Lages"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JoaoLages
      type: user
    createdAt: '2023-09-01T10:28:09.000Z'
    data:
      edited: true
      editors:
      - JoaoLages
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7882266640663147
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/00a48762ed17bd95905ee6b56882072b.svg
          fullname: "Jo\xE3o Lages"
          isHf: false
          isPro: false
          name: JoaoLages
          type: user
        html: "<p>I just found out that \\n and \\t have the exact same token id \U0001F610\
          </p>\n<pre><code>tokenizer.convert_tokens_to_ids([\"\\n\", \"\\t\"])\nOut[35]:\
          \ [3, 3]\n</code></pre>\n<p><strong>Edit:</strong> yes, they are both the\
          \ UNK id</p>\n<pre><code>tokenizer.unk_token_id\nOut[39]: 3\n</code></pre>\n"
        raw: "I just found out that \\n and \\t have the exact same token id \U0001F610\
          \n\n```\ntokenizer.convert_tokens_to_ids([\"\\n\", \"\\t\"])\nOut[35]: [3,\
          \ 3]\n```\n\n**Edit:** yes, they are both the UNK id\n```\ntokenizer.unk_token_id\n\
          Out[39]: 3\n```"
        updatedAt: '2023-09-01T10:31:50.872Z'
      numEdits: 1
      reactions: []
    id: 64f1bcb998375ab81481e796
    type: comment
  author: JoaoLages
  content: "I just found out that \\n and \\t have the exact same token id \U0001F610\
    \n\n```\ntokenizer.convert_tokens_to_ids([\"\\n\", \"\\t\"])\nOut[35]: [3, 3]\n\
    ```\n\n**Edit:** yes, they are both the UNK id\n```\ntokenizer.unk_token_id\n\
    Out[39]: 3\n```"
  created_at: 2023-09-01 09:28:09+00:00
  edited: true
  hidden: false
  id: 64f1bcb998375ab81481e796
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/00a48762ed17bd95905ee6b56882072b.svg
      fullname: "Jo\xE3o Lages"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JoaoLages
      type: user
    createdAt: '2023-09-01T10:44:14.000Z'
    data:
      edited: false
      editors:
      - JoaoLages
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5164400935173035
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/00a48762ed17bd95905ee6b56882072b.svg
          fullname: "Jo\xE3o Lages"
          isHf: false
          isPro: false
          name: JoaoLages
          type: user
        html: '<p>It seems that the problem is with \n and \t before the special tokens:</p>

          <pre><code>aux

          Out[58]: ''\t\n# this is a code comment\n\t&lt;extra_id_0&gt;''

          tokenizer.decode(tokenizer(aux)["input_ids"], skip_special_tokens=False)

          Out[59]: ''&lt;s&gt;\t\n# this is a code comment&lt;extra_id_0&gt;&lt;/s&gt;''

          </code></pre>

          <pre><code>aux

          Out[62]: ''\n# this is a code comment\n&lt;extra_id_0&gt;''

          tokenizer.decode(tokenizer(aux)["input_ids"], skip_special_tokens=False)

          Out[63]: ''&lt;s&gt;\n# this is a code comment&lt;extra_id_0&gt;&lt;/s&gt;''

          </code></pre>

          '
        raw: 'It seems that the problem is with \n and \t before the special tokens:

          ```

          aux

          Out[58]: ''\t\n# this is a code comment\n\t<extra_id_0>''

          tokenizer.decode(tokenizer(aux)["input_ids"], skip_special_tokens=False)

          Out[59]: ''<s>\t\n# this is a code comment<extra_id_0></s>''

          ```


          ```

          aux

          Out[62]: ''\n# this is a code comment\n<extra_id_0>''

          tokenizer.decode(tokenizer(aux)["input_ids"], skip_special_tokens=False)

          Out[63]: ''<s>\n# this is a code comment<extra_id_0></s>''

          ```

          '
        updatedAt: '2023-09-01T10:44:14.340Z'
      numEdits: 0
      reactions: []
    id: 64f1c07e1dcd9b972121361d
    type: comment
  author: JoaoLages
  content: 'It seems that the problem is with \n and \t before the special tokens:

    ```

    aux

    Out[58]: ''\t\n# this is a code comment\n\t<extra_id_0>''

    tokenizer.decode(tokenizer(aux)["input_ids"], skip_special_tokens=False)

    Out[59]: ''<s>\t\n# this is a code comment<extra_id_0></s>''

    ```


    ```

    aux

    Out[62]: ''\n# this is a code comment\n<extra_id_0>''

    tokenizer.decode(tokenizer(aux)["input_ids"], skip_special_tokens=False)

    Out[63]: ''<s>\n# this is a code comment<extra_id_0></s>''

    ```

    '
  created_at: 2023-09-01 09:44:14+00:00
  edited: false
  hidden: false
  id: 64f1c07e1dcd9b972121361d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: Salesforce/codet5p-220m
repo_type: model
status: open
target_branch: null
title: "\U0001F6A8\U0001F6A8Big bug in Tokenizer!!\U0001F6A8\U0001F6A8"
