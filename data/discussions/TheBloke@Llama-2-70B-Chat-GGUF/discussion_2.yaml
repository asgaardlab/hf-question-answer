!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TeaCult
conflicting_files: null
created_at: 2023-10-06 13:25:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c6feba914ead95667e0aa31a90081133.svg
      fullname: "Gediz G\xDCRSU"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TeaCult
      type: user
    createdAt: '2023-10-06T14:25:16.000Z'
    data:
      edited: false
      editors:
      - TeaCult
      hidden: false
      identifiedLanguage:
        language: tr
        probability: 0.5250505805015564
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c6feba914ead95667e0aa31a90081133.svg
          fullname: "Gediz G\xDCRSU"
          isHf: false
          isPro: false
          name: TeaCult
          type: user
        html: "<p>People says it is not multilingual but it translates a lot better\
          \ than many translation neural nets. It was a suprise.<br>It keeps original\
          \ terms but do not loose the meaning which is most important chatGPT 3.5\
          \  - 4 nllb-3B , google translate , they all loose the meaning while translating.\
          \ </p>\n<p>It is not perfect but seems promising somehow. It was suprising\
          \ to me. </p>\n<p>A Neural-Guided Dynamic Symbolic Network for<br>Exploring\
          \ Mathematical Expressions from Data<br>Wenqiang Li1,2,4 Weijun Li1,3,4,\u2217\
          \ Lina Yu1,3,4,\u2217 Min Wu1,3,4<br>Jingyi Liu1,3,4 Yanjie Li1,3,4<br>1<br>Institute\
          \ of Semiconductors, Chinese Academy of Sciences, Beijing, China<br>2School\
          \ of Electronic, Electrical and Communication Engineering, University of<br>Chinese\
          \ Academy of Sciences, Beijing, China<br>3School of Integrated Circuits,\
          \ University of Chinese Academy of Sciences, Beijing, China<br>4Beijing\
          \ Key Laboratory of Semiconductor Neural Network Intelligent Sensing and<br>Computing\
          \ Technology, Beijing, China<br>Abstract<br>Symbolic regression (SR) is\
          \ a powerful technique for discovering the underlying<br>mathematical expressions\
          \ from observed data. Inspired by the success of deep<br>learning, recent\
          \ efforts have focused on two categories for SR methods. One is using<br>a\
          \ neural network or genetic programming to search the expression tree directly.<br>Although\
          \ this has shown promising results, the large search space poses difficulties<br>in\
          \ learning constant factors and processing high-dimensional problems. Another<br>approach\
          \ is leveraging a transformer-based model training on synthetic data and<br>offers\
          \ advantages in inference speed. However, this method is limited to fixed<br>small\
          \ numbers of dimensions and may encounter inference problems when given<br>data\
          \ is out-of-distribution compared to the synthetic data. In this work, we\
          \ propose<br>DYSYMNET, a novel neural-guided Dynamic Symbolic Network for\
          \ SR. Instead of<br>searching for expressions within a large search space,\
          \ we explore DYSYMNET with<br>various structures and optimize them to identify\
          \ expressions that better-fitting the<br>data. With a topology structure\
          \ like neural networks, DYSYMNET not only tackles<br>the challenge of high-dimensional\
          \ problems but also proves effective in optimizing<br>constants. Based on\
          \ extensive numerical experiments using low-dimensional<br>public standard\
          \ benchmarks and the well-known SRBench with more variables,<br>our method\
          \ achieves state-of-the-art performance in terms of fitting accuracy and<br>robustness\
          \ to noise.</p>\n<p>///////////////////////////////////////////////<br>Sure,\
          \ I'd be happy to help! Here's a translation of the paper's abstract into\
          \ Turkish:</p>\n<p>\xD6zet</p>\n<p>Symbolik regressiyon (SR) observed data'dan\
          \ underlying mathematical expressions'u ke\u015Ffetmek i\xE7in bir\xE7ok\
          \ teknik geli\u015Ftirilmi\u015Ftir. Bu \xE7al\u0131\u015Fman\u0131n ana\
          \ kat\u0131l\u0131mc\u0131lar\u0131, daha y\xFCksek boyutlu problemler ve\
          \ constant factors \xF6\u011Frenmek i\xE7in neural a\u011Flar veya genetik\
          \ programlamay\u0131 kullanarak expression a\u011Fac\u0131n\u0131 arad\u0131\
          \u011F\u0131 categorilerdir. Bu yakla\u015F\u0131mlar\u0131n birincisi,\
          \ arama mevkiindeki b\xFCy\xFCk aral\u0131k ve y\xFCksek boyutlu problemlerde\
          \ \xE7ok daha zor olur. \u0130kincisi ise, synthetic veriler ile e\u011F\
          itilen transformer tabanl\u0131 bir model kullanarak h\u0131zl\u0131 tahmin\
          \ edebilir. Ancak bu yakla\u015F\u0131m, sabit say\u0131sal dimensiyonlarda\
          \ ki\xE7i olarak kullan\u0131labilir ve veri gelirine uygun \u015Fekilde\
          \ s\u0131n\u0131fland\u0131r\u0131lamayacaktad\u0131r. Bu \xE7al\u0131\u015F\
          man\u0131n amac\u0131, DYSYMNET'u geli\u015Ftirmek ve bunu kullanarak SR\
          \ y\xF6ntemlerindeki bu s\u0131n\u0131rlamalar\u0131 a\u015Fmaktad\u0131\
          r.</p>\n<p>DYSYMNET, veri gelirine g\xF6re daha iyi uyumlu olan ifadeler\
          \ ke\u015Ffetmek i\xE7in \xE7e\u015Fitli yap\u0131lar\u0131 ve optimize\
          \ edilmesini sa\u011Flar. Neural a\u011Flar\u0131n topology yap\u0131s\u0131\
          na benzer \u015Fekilde, DYSYMNET y\xFCksek boyutlu problemlerine de daha\
          \ etkili bir \u015Fekilde cevirebilir ve constant faktorlerin optimize edilmesinde\
          \ de etkileyebilir.</p>\n<p>Bu \xE7al\u0131\u015Fman\u0131n sonu\xE7lar\u0131\
          , standard veri setlerini kullanarak yapay zeka ile ilgili bir\xE7ok deneme\
          \ ger\xE7ekle\u015Ftirilmi\u015Ftir ve SRBench'te daha fazla de\u011Fi\u015F\
          ken olup b\xFCy\xFCk boyutlu problemlerle kar\u015F\u0131la\u015Ft\u0131\
          r\u0131lm\u0131\u015Ft\u0131r. Sonu\xE7lar, DYSYMNET'un performans\u0131\
          n\u0131 g\xF6stererek state-of-the-art derecede fitted accuracy ve noise\
          \ ile kar\u015F\u0131la\u015Ft\u0131rmalarda daha y\xFCksek birperformans\
          \ sa\u011Flamas\u0131n\u0131 g\xF6stermektedir.</p>\n"
        raw: "People says it is not multilingual but it translates a lot better than\
          \ many translation neural nets. It was a suprise. \r\nIt keeps original\
          \ terms but do not loose the meaning which is most important chatGPT 3.5\
          \  - 4 nllb-3B , google translate , they all loose the meaning while translating.\
          \ \r\n\r\nIt is not perfect but seems promising somehow. It was suprising\
          \ to me. \r\n\r\nA Neural-Guided Dynamic Symbolic Network for\r\nExploring\
          \ Mathematical Expressions from Data\r\nWenqiang Li1,2,4 Weijun Li1,3,4,\u2217\
          \ Lina Yu1,3,4,\u2217 Min Wu1,3,4\r\nJingyi Liu1,3,4 Yanjie Li1,3,4\r\n\
          1\r\nInstitute of Semiconductors, Chinese Academy of Sciences, Beijing,\
          \ China\r\n2School of Electronic, Electrical and Communication Engineering,\
          \ University of\r\nChinese Academy of Sciences, Beijing, China\r\n3School\
          \ of Integrated Circuits, University of Chinese Academy of Sciences, Beijing,\
          \ China\r\n4Beijing Key Laboratory of Semiconductor Neural Network Intelligent\
          \ Sensing and\r\nComputing Technology, Beijing, China\r\nAbstract\r\nSymbolic\
          \ regression (SR) is a powerful technique for discovering the underlying\r\
          \nmathematical expressions from observed data. Inspired by the success of\
          \ deep\r\nlearning, recent efforts have focused on two categories for SR\
          \ methods. One is using\r\na neural network or genetic programming to search\
          \ the expression tree directly.\r\nAlthough this has shown promising results,\
          \ the large search space poses difficulties\r\nin learning constant factors\
          \ and processing high-dimensional problems. Another\r\napproach is leveraging\
          \ a transformer-based model training on synthetic data and\r\noffers advantages\
          \ in inference speed. However, this method is limited to fixed\r\nsmall\
          \ numbers of dimensions and may encounter inference problems when given\r\
          \ndata is out-of-distribution compared to the synthetic data. In this work,\
          \ we propose\r\nDYSYMNET, a novel neural-guided Dynamic Symbolic Network\
          \ for SR. Instead of\r\nsearching for expressions within a large search\
          \ space, we explore DYSYMNET with\r\nvarious structures and optimize them\
          \ to identify expressions that better-fitting the\r\ndata. With a topology\
          \ structure like neural networks, DYSYMNET not only tackles\r\nthe challenge\
          \ of high-dimensional problems but also proves effective in optimizing\r\
          \nconstants. Based on extensive numerical experiments using low-dimensional\r\
          \npublic standard benchmarks and the well-known SRBench with more variables,\r\
          \nour method achieves state-of-the-art performance in terms of fitting accuracy\
          \ and\r\nrobustness to noise.\r\n\r\n///////////////////////////////////////////////\r\
          \nSure, I'd be happy to help! Here's a translation of the paper's abstract\
          \ into Turkish:\r\n\r\n\xD6zet\r\n\r\nSymbolik regressiyon (SR) observed\
          \ data'dan underlying mathematical expressions'u ke\u015Ffetmek i\xE7in\
          \ bir\xE7ok teknik geli\u015Ftirilmi\u015Ftir. Bu \xE7al\u0131\u015Fman\u0131\
          n ana kat\u0131l\u0131mc\u0131lar\u0131, daha y\xFCksek boyutlu problemler\
          \ ve constant factors \xF6\u011Frenmek i\xE7in neural a\u011Flar veya genetik\
          \ programlamay\u0131 kullanarak expression a\u011Fac\u0131n\u0131 arad\u0131\
          \u011F\u0131 categorilerdir. Bu yakla\u015F\u0131mlar\u0131n birincisi,\
          \ arama mevkiindeki b\xFCy\xFCk aral\u0131k ve y\xFCksek boyutlu problemlerde\
          \ \xE7ok daha zor olur. \u0130kincisi ise, synthetic veriler ile e\u011F\
          itilen transformer tabanl\u0131 bir model kullanarak h\u0131zl\u0131 tahmin\
          \ edebilir. Ancak bu yakla\u015F\u0131m, sabit say\u0131sal dimensiyonlarda\
          \ ki\xE7i olarak kullan\u0131labilir ve veri gelirine uygun \u015Fekilde\
          \ s\u0131n\u0131fland\u0131r\u0131lamayacaktad\u0131r. Bu \xE7al\u0131\u015F\
          man\u0131n amac\u0131, DYSYMNET'u geli\u015Ftirmek ve bunu kullanarak SR\
          \ y\xF6ntemlerindeki bu s\u0131n\u0131rlamalar\u0131 a\u015Fmaktad\u0131\
          r.\r\n\r\nDYSYMNET, veri gelirine g\xF6re daha iyi uyumlu olan ifadeler\
          \ ke\u015Ffetmek i\xE7in \xE7e\u015Fitli yap\u0131lar\u0131 ve optimize\
          \ edilmesini sa\u011Flar. Neural a\u011Flar\u0131n topology yap\u0131s\u0131\
          na benzer \u015Fekilde, DYSYMNET y\xFCksek boyutlu problemlerine de daha\
          \ etkili bir \u015Fekilde cevirebilir ve constant faktorlerin optimize edilmesinde\
          \ de etkileyebilir.\r\n\r\nBu \xE7al\u0131\u015Fman\u0131n sonu\xE7lar\u0131\
          , standard veri setlerini kullanarak yapay zeka ile ilgili bir\xE7ok deneme\
          \ ger\xE7ekle\u015Ftirilmi\u015Ftir ve SRBench'te daha fazla de\u011Fi\u015F\
          ken olup b\xFCy\xFCk boyutlu problemlerle kar\u015F\u0131la\u015Ft\u0131\
          r\u0131lm\u0131\u015Ft\u0131r. Sonu\xE7lar, DYSYMNET'un performans\u0131\
          n\u0131 g\xF6stererek state-of-the-art derecede fitted accuracy ve noise\
          \ ile kar\u015F\u0131la\u015Ft\u0131rmalarda daha y\xFCksek birperformans\
          \ sa\u011Flamas\u0131n\u0131 g\xF6stermektedir."
        updatedAt: '2023-10-06T14:25:16.123Z'
      numEdits: 0
      reactions: []
    id: 652018cc9ac84fd9b3036a57
    type: comment
  author: TeaCult
  content: "People says it is not multilingual but it translates a lot better than\
    \ many translation neural nets. It was a suprise. \r\nIt keeps original terms\
    \ but do not loose the meaning which is most important chatGPT 3.5  - 4 nllb-3B\
    \ , google translate , they all loose the meaning while translating. \r\n\r\n\
    It is not perfect but seems promising somehow. It was suprising to me. \r\n\r\n\
    A Neural-Guided Dynamic Symbolic Network for\r\nExploring Mathematical Expressions\
    \ from Data\r\nWenqiang Li1,2,4 Weijun Li1,3,4,\u2217 Lina Yu1,3,4,\u2217 Min\
    \ Wu1,3,4\r\nJingyi Liu1,3,4 Yanjie Li1,3,4\r\n1\r\nInstitute of Semiconductors,\
    \ Chinese Academy of Sciences, Beijing, China\r\n2School of Electronic, Electrical\
    \ and Communication Engineering, University of\r\nChinese Academy of Sciences,\
    \ Beijing, China\r\n3School of Integrated Circuits, University of Chinese Academy\
    \ of Sciences, Beijing, China\r\n4Beijing Key Laboratory of Semiconductor Neural\
    \ Network Intelligent Sensing and\r\nComputing Technology, Beijing, China\r\n\
    Abstract\r\nSymbolic regression (SR) is a powerful technique for discovering the\
    \ underlying\r\nmathematical expressions from observed data. Inspired by the success\
    \ of deep\r\nlearning, recent efforts have focused on two categories for SR methods.\
    \ One is using\r\na neural network or genetic programming to search the expression\
    \ tree directly.\r\nAlthough this has shown promising results, the large search\
    \ space poses difficulties\r\nin learning constant factors and processing high-dimensional\
    \ problems. Another\r\napproach is leveraging a transformer-based model training\
    \ on synthetic data and\r\noffers advantages in inference speed. However, this\
    \ method is limited to fixed\r\nsmall numbers of dimensions and may encounter\
    \ inference problems when given\r\ndata is out-of-distribution compared to the\
    \ synthetic data. In this work, we propose\r\nDYSYMNET, a novel neural-guided\
    \ Dynamic Symbolic Network for SR. Instead of\r\nsearching for expressions within\
    \ a large search space, we explore DYSYMNET with\r\nvarious structures and optimize\
    \ them to identify expressions that better-fitting the\r\ndata. With a topology\
    \ structure like neural networks, DYSYMNET not only tackles\r\nthe challenge of\
    \ high-dimensional problems but also proves effective in optimizing\r\nconstants.\
    \ Based on extensive numerical experiments using low-dimensional\r\npublic standard\
    \ benchmarks and the well-known SRBench with more variables,\r\nour method achieves\
    \ state-of-the-art performance in terms of fitting accuracy and\r\nrobustness\
    \ to noise.\r\n\r\n///////////////////////////////////////////////\r\nSure, I'd\
    \ be happy to help! Here's a translation of the paper's abstract into Turkish:\r\
    \n\r\n\xD6zet\r\n\r\nSymbolik regressiyon (SR) observed data'dan underlying mathematical\
    \ expressions'u ke\u015Ffetmek i\xE7in bir\xE7ok teknik geli\u015Ftirilmi\u015F\
    tir. Bu \xE7al\u0131\u015Fman\u0131n ana kat\u0131l\u0131mc\u0131lar\u0131, daha\
    \ y\xFCksek boyutlu problemler ve constant factors \xF6\u011Frenmek i\xE7in neural\
    \ a\u011Flar veya genetik programlamay\u0131 kullanarak expression a\u011Fac\u0131\
    n\u0131 arad\u0131\u011F\u0131 categorilerdir. Bu yakla\u015F\u0131mlar\u0131\
    n birincisi, arama mevkiindeki b\xFCy\xFCk aral\u0131k ve y\xFCksek boyutlu problemlerde\
    \ \xE7ok daha zor olur. \u0130kincisi ise, synthetic veriler ile e\u011Fitilen\
    \ transformer tabanl\u0131 bir model kullanarak h\u0131zl\u0131 tahmin edebilir.\
    \ Ancak bu yakla\u015F\u0131m, sabit say\u0131sal dimensiyonlarda ki\xE7i olarak\
    \ kullan\u0131labilir ve veri gelirine uygun \u015Fekilde s\u0131n\u0131fland\u0131\
    r\u0131lamayacaktad\u0131r. Bu \xE7al\u0131\u015Fman\u0131n amac\u0131, DYSYMNET'u\
    \ geli\u015Ftirmek ve bunu kullanarak SR y\xF6ntemlerindeki bu s\u0131n\u0131\
    rlamalar\u0131 a\u015Fmaktad\u0131r.\r\n\r\nDYSYMNET, veri gelirine g\xF6re daha\
    \ iyi uyumlu olan ifadeler ke\u015Ffetmek i\xE7in \xE7e\u015Fitli yap\u0131lar\u0131\
    \ ve optimize edilmesini sa\u011Flar. Neural a\u011Flar\u0131n topology yap\u0131\
    s\u0131na benzer \u015Fekilde, DYSYMNET y\xFCksek boyutlu problemlerine de daha\
    \ etkili bir \u015Fekilde cevirebilir ve constant faktorlerin optimize edilmesinde\
    \ de etkileyebilir.\r\n\r\nBu \xE7al\u0131\u015Fman\u0131n sonu\xE7lar\u0131,\
    \ standard veri setlerini kullanarak yapay zeka ile ilgili bir\xE7ok deneme ger\xE7\
    ekle\u015Ftirilmi\u015Ftir ve SRBench'te daha fazla de\u011Fi\u015Fken olup b\xFC\
    y\xFCk boyutlu problemlerle kar\u015F\u0131la\u015Ft\u0131r\u0131lm\u0131\u015F\
    t\u0131r. Sonu\xE7lar, DYSYMNET'un performans\u0131n\u0131 g\xF6stererek state-of-the-art\
    \ derecede fitted accuracy ve noise ile kar\u015F\u0131la\u015Ft\u0131rmalarda\
    \ daha y\xFCksek birperformans sa\u011Flamas\u0131n\u0131 g\xF6stermektedir."
  created_at: 2023-10-06 13:25:16+00:00
  edited: false
  hidden: false
  id: 652018cc9ac84fd9b3036a57
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/Llama-2-70B-Chat-GGUF
repo_type: model
status: open
target_branch: null
title: Almost multilingual
