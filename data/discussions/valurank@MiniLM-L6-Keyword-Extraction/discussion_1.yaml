!!python/object:huggingface_hub.community.DiscussionWithDetails
author: irensaltali
conflicting_files: null
created_at: 2023-05-24 07:27:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673521811377-63bfe342177bc4d05e474eaa.jpeg?w=200&h=200&f=face
      fullname: "\u0130ren Saltal\u0131"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: irensaltali
      type: user
    createdAt: '2023-05-24T08:27:19.000Z'
    data:
      edited: false
      editors:
      - irensaltali
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673521811377-63bfe342177bc4d05e474eaa.jpeg?w=200&h=200&f=face
          fullname: "\u0130ren Saltal\u0131"
          isHf: false
          isPro: false
          name: irensaltali
          type: user
        html: '<p>I''m getting a float array if I apply to code at README. How can
          I get the same value with hosted endpoint?</p>

          '
        raw: I'm getting a float array if I apply to code at README. How can I get
          the same value with hosted endpoint?
        updatedAt: '2023-05-24T08:27:19.971Z'
      numEdits: 0
      reactions: []
    id: 646dca672fd5a8eb8c50f3bb
    type: comment
  author: irensaltali
  content: I'm getting a float array if I apply to code at README. How can I get the
    same value with hosted endpoint?
  created_at: 2023-05-24 07:27:19+00:00
  edited: false
  hidden: false
  id: 646dca672fd5a8eb8c50f3bb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673521811377-63bfe342177bc4d05e474eaa.jpeg?w=200&h=200&f=face
      fullname: "\u0130ren Saltal\u0131"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: irensaltali
      type: user
    createdAt: '2023-05-24T09:04:02.000Z'
    data:
      edited: false
      editors:
      - irensaltali
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673521811377-63bfe342177bc4d05e474eaa.jpeg?w=200&h=200&f=face
          fullname: "\u0130ren Saltal\u0131"
          isHf: false
          isPro: false
          name: irensaltali
          type: user
        html: "<p>I solved it. Here is the code:</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\"\
          >import</span> AutoTokenizer, AutoModel\n<span class=\"hljs-keyword\">import</span>\
          \ torch\n<span class=\"hljs-keyword\">import</span> torch.nn.functional\
          \ <span class=\"hljs-keyword\">as</span> F\n\n<span class=\"hljs-comment\"\
          ># Mean Pooling - Take attention mask into account for correct averaging</span>\n\
          <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\"\
          >mean_pooling</span>(<span class=\"hljs-params\">model_output, attention_mask</span>):\n\
          \    token_embeddings = model_output[<span class=\"hljs-number\">0</span>]\n\
          \    input_mask_expanded = attention_mask.unsqueeze(-<span class=\"hljs-number\"\
          >1</span>).expand(token_embeddings.size()).<span class=\"hljs-built_in\"\
          >float</span>()\n    <span class=\"hljs-keyword\">return</span> torch.<span\
          \ class=\"hljs-built_in\">sum</span>(token_embeddings * input_mask_expanded,\
          \ <span class=\"hljs-number\">1</span>) / torch.clamp(input_mask_expanded.<span\
          \ class=\"hljs-built_in\">sum</span>(<span class=\"hljs-number\">1</span>),\
          \ <span class=\"hljs-built_in\">min</span>=<span class=\"hljs-number\">1e-9</span>)\n\
          \n<span class=\"hljs-comment\"># Sentences we want sentence embeddings for</span>\n\
          sentences = [<span class=\"hljs-string\">\"This is an example sentence\"\
          </span>, <span class=\"hljs-string\">\"Each sentence is converted\"</span>]\n\
          \n<span class=\"hljs-comment\"># Load model from HuggingFace Hub</span>\n\
          tokenizer = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">'sentence-transformers/all-MiniLM-L6-v2'</span>)\n\
          model = AutoModel.from_pretrained(<span class=\"hljs-string\">'sentence-transformers/all-MiniLM-L6-v2'</span>)\n\
          \n<span class=\"hljs-comment\"># Tokenize sentences</span>\nencoded_input\
          \ = tokenizer(sentences, padding=<span class=\"hljs-literal\">True</span>,\
          \ truncation=<span class=\"hljs-literal\">True</span>, return_tensors=<span\
          \ class=\"hljs-string\">'pt'</span>)\n\n<span class=\"hljs-comment\"># Compute\
          \ token embeddings</span>\n<span class=\"hljs-keyword\">with</span> torch.no_grad():\n\
          model_output = model(**encoded_input)\n\n<span class=\"hljs-comment\">#\
          \ Perform pooling</span>\nsentence_embeddings = mean_pooling(model_output,\
          \ encoded_input[<span class=\"hljs-string\">'attention_mask'</span>])\n\n\
          <span class=\"hljs-comment\"># Normalize embeddings</span>\nsentence_embeddings_normalized\
          \ = F.normalize(sentence_embeddings, p=<span class=\"hljs-number\">2</span>,\
          \ dim=<span class=\"hljs-number\">1</span>)\n\n<span class=\"hljs-comment\"\
          ># Calculate cosine similarities between first sentence and all others</span>\n\
          first_sentence_embedding = sentence_embeddings_normalized[<span class=\"\
          hljs-number\">0</span>].unsqueeze(<span class=\"hljs-number\">0</span>)\n\
          cosine_similarities = F.cosine_similarity(first_sentence_embedding, sentence_embeddings_normalized)\n\
          \n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\"\
          >\"Cosine similarities between first and other sentences:\"</span>)\n<span\
          \ class=\"hljs-built_in\">print</span>(cosine_similarities)\n</code></pre>\n"
        raw: "I solved it. Here is the code:\n```python\nfrom transformers import\
          \ AutoTokenizer, AutoModel\nimport torch\nimport torch.nn.functional as\
          \ F\n\n# Mean Pooling - Take attention mask into account for correct averaging\n\
          def mean_pooling(model_output, attention_mask):\n    token_embeddings =\
          \ model_output[0]\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n\
          \    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1),\
          \ min=1e-9)\n\n# Sentences we want sentence embeddings for\nsentences =\
          \ [\"This is an example sentence\", \"Each sentence is converted\"]\n\n\
          # Load model from HuggingFace Hub\ntokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n\
          model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n\
          \n# Tokenize sentences\nencoded_input = tokenizer(sentences, padding=True,\
          \ truncation=True, return_tensors='pt')\n\n# Compute token embeddings\n\
          with torch.no_grad():\nmodel_output = model(**encoded_input)\n\n# Perform\
          \ pooling\nsentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n\
          \n# Normalize embeddings\nsentence_embeddings_normalized = F.normalize(sentence_embeddings,\
          \ p=2, dim=1)\n\n# Calculate cosine similarities between first sentence\
          \ and all others\nfirst_sentence_embedding = sentence_embeddings_normalized[0].unsqueeze(0)\n\
          cosine_similarities = F.cosine_similarity(first_sentence_embedding, sentence_embeddings_normalized)\n\
          \nprint(\"Cosine similarities between first and other sentences:\")\nprint(cosine_similarities)\n\
          ```"
        updatedAt: '2023-05-24T09:04:02.732Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - victor
      relatedEventId: 646dd3029105e2cc56984691
    id: 646dd3029105e2cc56984690
    type: comment
  author: irensaltali
  content: "I solved it. Here is the code:\n```python\nfrom transformers import AutoTokenizer,\
    \ AutoModel\nimport torch\nimport torch.nn.functional as F\n\n# Mean Pooling -\
    \ Take attention mask into account for correct averaging\ndef mean_pooling(model_output,\
    \ attention_mask):\n    token_embeddings = model_output[0]\n    input_mask_expanded\
    \ = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n   \
    \ return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1),\
    \ min=1e-9)\n\n# Sentences we want sentence embeddings for\nsentences = [\"This\
    \ is an example sentence\", \"Each sentence is converted\"]\n\n# Load model from\
    \ HuggingFace Hub\ntokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n\
    model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n\n\
    # Tokenize sentences\nencoded_input = tokenizer(sentences, padding=True, truncation=True,\
    \ return_tensors='pt')\n\n# Compute token embeddings\nwith torch.no_grad():\n\
    model_output = model(**encoded_input)\n\n# Perform pooling\nsentence_embeddings\
    \ = mean_pooling(model_output, encoded_input['attention_mask'])\n\n# Normalize\
    \ embeddings\nsentence_embeddings_normalized = F.normalize(sentence_embeddings,\
    \ p=2, dim=1)\n\n# Calculate cosine similarities between first sentence and all\
    \ others\nfirst_sentence_embedding = sentence_embeddings_normalized[0].unsqueeze(0)\n\
    cosine_similarities = F.cosine_similarity(first_sentence_embedding, sentence_embeddings_normalized)\n\
    \nprint(\"Cosine similarities between first and other sentences:\")\nprint(cosine_similarities)\n\
    ```"
  created_at: 2023-05-24 08:04:02+00:00
  edited: false
  hidden: false
  id: 646dd3029105e2cc56984690
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673521811377-63bfe342177bc4d05e474eaa.jpeg?w=200&h=200&f=face
      fullname: "\u0130ren Saltal\u0131"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: irensaltali
      type: user
    createdAt: '2023-05-24T09:04:02.000Z'
    data:
      status: closed
    id: 646dd3029105e2cc56984691
    type: status-change
  author: irensaltali
  created_at: 2023-05-24 08:04:02+00:00
  id: 646dd3029105e2cc56984691
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: valurank/MiniLM-L6-Keyword-Extraction
repo_type: model
status: closed
target_branch: null
title: I don't get same value with hosted API
