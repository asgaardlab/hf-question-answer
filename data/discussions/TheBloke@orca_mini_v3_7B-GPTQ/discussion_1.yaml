!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Flerndip
conflicting_files: null
created_at: 2023-08-24 16:16:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b8e1f374595d5902da026b9424710ec1.svg
      fullname: Gary Schiffer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Flerndip
      type: user
    createdAt: '2023-08-24T17:16:01.000Z'
    data:
      edited: false
      editors:
      - Flerndip
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5250637531280518
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b8e1f374595d5902da026b9424710ec1.svg
          fullname: Gary Schiffer
          isHf: false
          isPro: false
          name: Flerndip
          type: user
        html: "<p>This is one of many recent models that seem to throw python \"extra\
          \ data\" errors when I attempt to load them into oobabooga.  I can't be\
          \ the only one experiencing this problem, can I?</p>\n<p>The model seems\
          \ to have downloaded into oobabooga correctly, including the desired branch,\
          \ and yet...</p>\n<p>This is what appears under the model loader in oobabooga\
          \ after I try to load the model into ExLlama or AutoGPTQ:</p>\n<p>Traceback\
          \ (most recent call last):</p>\n<p>File \u201CC:\\Users\\flern\\ooba2\\\
          text-generation-webui\\modules\\ui_model_menu.py\u201D, line 185, in load_model_wrapper</p>\n\
          <p>shared.model, shared.tokenizer = load_model(shared.model_name, loader)<br>File\
          \ \u201CC:\\Users\\flern\\ooba2\\text-generation-webui\\modules\\models.py\u201D\
          , line 79, in load_model</p>\n<p>output = load_func_map<a rel=\"nofollow\"\
          \ href=\"model_name\">loader</a><br>File \u201CC:\\Users\\flern\\ooba2\\\
          text-generation-webui\\modules\\models.py\u201D, line 317, in ExLlama_loader</p>\n\
          <p>model, tokenizer = ExllamaModel.from_pretrained(model_name)<br>File \u201C\
          C:\\Users\\flern\\ooba2\\text-generation-webui\\modules\\exllama.py\u201D\
          , line 51, in from_pretrained</p>\n<p>config = ExLlamaConfig(str(model_config_path))<br>File\
          \ \u201CC:\\Users\\flern\\ooba2\\installer_files\\env\\lib\\site-packages\\\
          exllama\\model.py\u201D, line 46, in init</p>\n<p>read_config = json.load(f)<br>File\
          \ \u201CC:\\Users\\flern\\ooba2\\installer_files\\env\\lib\\json_init_.py\u201D\
          , line 293, in load</p>\n<p>return loads(fp.read(),<br>File \u201CC:\\Users\\\
          flern\\ooba2\\installer_files\\env\\lib\\json_init_.py\u201D, line 346,\
          \ in loads</p>\n<p>return _default_decoder.decode(s)<br>File \u201CC:\\\
          Users\\flern\\ooba2\\installer_files\\env\\lib\\json\\decoder.py\u201D,\
          \ line 340, in decode</p>\n<p>raise JSONDecodeError(\"Extra data\", s, end)<br>json.decoder.JSONDecodeError:\
          \ Extra data: line 26 column 2 (char 679)</p>\n"
        raw: "This is one of many recent models that seem to throw python \"extra\
          \ data\" errors when I attempt to load them into oobabooga.  I can't be\
          \ the only one experiencing this problem, can I?\r\n\r\nThe model seems\
          \ to have downloaded into oobabooga correctly, including the desired branch,\
          \ and yet...\r\n\r\nThis is what appears under the model loader in oobabooga\
          \ after I try to load the model into ExLlama or AutoGPTQ:\r\n\r\n\r\n\r\n\
          Traceback (most recent call last):\r\n\r\nFile \u201CC:\\Users\\flern\\\
          ooba2\\text-generation-webui\\modules\\ui_model_menu.py\u201D, line 185,\
          \ in load_model_wrapper\r\n\r\nshared.model, shared.tokenizer = load_model(shared.model_name,\
          \ loader)\r\nFile \u201CC:\\Users\\flern\\ooba2\\text-generation-webui\\\
          modules\\models.py\u201D, line 79, in load_model\r\n\r\noutput = load_func_map[loader](model_name)\r\
          \nFile \u201CC:\\Users\\flern\\ooba2\\text-generation-webui\\modules\\models.py\u201D\
          , line 317, in ExLlama_loader\r\n\r\nmodel, tokenizer = ExllamaModel.from_pretrained(model_name)\r\
          \nFile \u201CC:\\Users\\flern\\ooba2\\text-generation-webui\\modules\\exllama.py\u201D\
          , line 51, in from_pretrained\r\n\r\nconfig = ExLlamaConfig(str(model_config_path))\r\
          \nFile \u201CC:\\Users\\flern\\ooba2\\installer_files\\env\\lib\\site-packages\\\
          exllama\\model.py\u201D, line 46, in init\r\n\r\nread_config = json.load(f)\r\
          \nFile \u201CC:\\Users\\flern\\ooba2\\installer_files\\env\\lib\\json_init_.py\u201D\
          , line 293, in load\r\n\r\nreturn loads(fp.read(),\r\nFile \u201CC:\\Users\\\
          flern\\ooba2\\installer_files\\env\\lib\\json_init_.py\u201D, line 346,\
          \ in loads\r\n\r\nreturn _default_decoder.decode(s)\r\nFile \u201CC:\\Users\\\
          flern\\ooba2\\installer_files\\env\\lib\\json\\decoder.py\u201D, line 340,\
          \ in decode\r\n\r\nraise JSONDecodeError(\"Extra data\", s, end)\r\njson.decoder.JSONDecodeError:\
          \ Extra data: line 26 column 2 (char 679)\r\n\r\n\r\n"
        updatedAt: '2023-08-24T17:16:01.832Z'
      numEdits: 0
      reactions: []
    id: 64e790519f8952a1c0f8d489
    type: comment
  author: Flerndip
  content: "This is one of many recent models that seem to throw python \"extra data\"\
    \ errors when I attempt to load them into oobabooga.  I can't be the only one\
    \ experiencing this problem, can I?\r\n\r\nThe model seems to have downloaded\
    \ into oobabooga correctly, including the desired branch, and yet...\r\n\r\nThis\
    \ is what appears under the model loader in oobabooga after I try to load the\
    \ model into ExLlama or AutoGPTQ:\r\n\r\n\r\n\r\nTraceback (most recent call last):\r\
    \n\r\nFile \u201CC:\\Users\\flern\\ooba2\\text-generation-webui\\modules\\ui_model_menu.py\u201D\
    , line 185, in load_model_wrapper\r\n\r\nshared.model, shared.tokenizer = load_model(shared.model_name,\
    \ loader)\r\nFile \u201CC:\\Users\\flern\\ooba2\\text-generation-webui\\modules\\\
    models.py\u201D, line 79, in load_model\r\n\r\noutput = load_func_map[loader](model_name)\r\
    \nFile \u201CC:\\Users\\flern\\ooba2\\text-generation-webui\\modules\\models.py\u201D\
    , line 317, in ExLlama_loader\r\n\r\nmodel, tokenizer = ExllamaModel.from_pretrained(model_name)\r\
    \nFile \u201CC:\\Users\\flern\\ooba2\\text-generation-webui\\modules\\exllama.py\u201D\
    , line 51, in from_pretrained\r\n\r\nconfig = ExLlamaConfig(str(model_config_path))\r\
    \nFile \u201CC:\\Users\\flern\\ooba2\\installer_files\\env\\lib\\site-packages\\\
    exllama\\model.py\u201D, line 46, in init\r\n\r\nread_config = json.load(f)\r\n\
    File \u201CC:\\Users\\flern\\ooba2\\installer_files\\env\\lib\\json_init_.py\u201D\
    , line 293, in load\r\n\r\nreturn loads(fp.read(),\r\nFile \u201CC:\\Users\\flern\\\
    ooba2\\installer_files\\env\\lib\\json_init_.py\u201D, line 346, in loads\r\n\r\
    \nreturn _default_decoder.decode(s)\r\nFile \u201CC:\\Users\\flern\\ooba2\\installer_files\\\
    env\\lib\\json\\decoder.py\u201D, line 340, in decode\r\n\r\nraise JSONDecodeError(\"\
    Extra data\", s, end)\r\njson.decoder.JSONDecodeError: Extra data: line 26 column\
    \ 2 (char 679)\r\n\r\n\r\n"
  created_at: 2023-08-24 16:16:01+00:00
  edited: false
  hidden: false
  id: 64e790519f8952a1c0f8d489
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b8e1f374595d5902da026b9424710ec1.svg
      fullname: Gary Schiffer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Flerndip
      type: user
    createdAt: '2023-08-27T06:41:03.000Z'
    data:
      edited: false
      editors:
      - Flerndip
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9884620308876038
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b8e1f374595d5902da026b9424710ec1.svg
          fullname: Gary Schiffer
          isHf: false
          isPro: false
          name: Flerndip
          type: user
        html: '<p>I deleted the model folder and re-downloaded and the problem went
          away so I probably just broke it and saved bad settings over it at some
          point. </p>

          '
        raw: 'I deleted the model folder and re-downloaded and the problem went away
          so I probably just broke it and saved bad settings over it at some point. '
        updatedAt: '2023-08-27T06:41:03.261Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64eaefff2800cf7e9ca0db5c
    id: 64eaefff2800cf7e9ca0db5a
    type: comment
  author: Flerndip
  content: 'I deleted the model folder and re-downloaded and the problem went away
    so I probably just broke it and saved bad settings over it at some point. '
  created_at: 2023-08-27 05:41:03+00:00
  edited: false
  hidden: false
  id: 64eaefff2800cf7e9ca0db5a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/b8e1f374595d5902da026b9424710ec1.svg
      fullname: Gary Schiffer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Flerndip
      type: user
    createdAt: '2023-08-27T06:41:03.000Z'
    data:
      status: closed
    id: 64eaefff2800cf7e9ca0db5c
    type: status-change
  author: Flerndip
  created_at: 2023-08-27 05:41:03+00:00
  id: 64eaefff2800cf7e9ca0db5c
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/orca_mini_v3_7B-GPTQ
repo_type: model
status: closed
target_branch: null
title: errors loading recent models
