!!python/object:huggingface_hub.community.DiscussionWithDetails
author: KrishnaKaasyap
conflicting_files: null
created_at: 2023-10-17 04:17:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/236c771e6c5a25ef6ed5e1bc061e30b8.svg
      fullname: Krishna Kaasyap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KrishnaKaasyap
      type: user
    createdAt: '2023-10-17T05:17:09.000Z'
    data:
      edited: false
      editors:
      - KrishnaKaasyap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9251604676246643
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/236c771e6c5a25ef6ed5e1bc061e30b8.svg
          fullname: Krishna Kaasyap
          isHf: false
          isPro: false
          name: KrishnaKaasyap
          type: user
        html: "<p>I tried the model for both summarisation of a 1000 token length\
          \ legal case law and creating Q&amp;A pairs from a 1500 token case law.</p>\n\
          <p>In summarising the case law, the model performed at par with \U0001F917\
          's Zephyr 7B (Mistral fine tuned) model. But in creating Q&amp;A pairs -\
          \ it performed worse than Zephyr 7B.</p>\n<p>Comparing with LLaMA 2 70B\
          \ chat (which is RLHF model) - the summarisation from your model  is almost\
          \ similar to LLaMA 2 70B.</p>\n<p>LLaMA 2 70B is visibly great when creating\
          \ Q&amp;A pairs than both Zephyr and your model. And it is obvious because\
          \ first it is a RLHF  model and it is whooping 10 times bigger.</p>\n<p>But\
          \ what I'm amazed is yours is probably the only 32k context length 7B model\
          \ out there apart from <span data-props=\"{&quot;user&quot;:&quot;vipul&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/vipul\"\
          >@<span class=\"underline\">vipul</span></a></span>\n\n\t</span></span>\
          \ 's Together AI LLaMA 7B 32K model. And yours is the only one that is almost\
          \ entirely trained on synthetic data!</p>\n<p>Since you're in the first\
          \ epoch of training, I'm expecting visible improvements after reaching third\
          \ or fourth epoch.</p>\n<p>Great job dude. \U0001F44C\U0001F3FC</p>\n"
        raw: "I tried the model for both summarisation of a 1000 token length legal\
          \ case law and creating Q&A pairs from a 1500 token case law.\r\n\r\nIn\
          \ summarising the case law, the model performed at par with \U0001F917's\
          \ Zephyr 7B (Mistral fine tuned) model. But in creating Q&A pairs - it performed\
          \ worse than Zephyr 7B.\r\n\r\nComparing with LLaMA 2 70B chat (which is\
          \ RLHF model) - the summarisation from your model  is almost similar to\
          \ LLaMA 2 70B.\r\n\r\nLLaMA 2 70B is visibly great when creating Q&A pairs\
          \ than both Zephyr and your model. And it is obvious because first it is\
          \ a RLHF  model and it is whooping 10 times bigger.\r\n\r\nBut what I'm\
          \ amazed is yours is probably the only 32k context length 7B model out there\
          \ apart from @vipul 's Together AI LLaMA 7B 32K model. And yours is the\
          \ only one that is almost entirely trained on synthetic data!\r\n\r\nSince\
          \ you're in the first epoch of training, I'm expecting visible improvements\
          \ after reaching third or fourth epoch.\r\n\r\nGreat job dude. \U0001F44C\
          \U0001F3FC"
        updatedAt: '2023-10-17T05:17:09.388Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\U0001F44D"
        users:
        - emrgnt-cmplxty
        - Schoffo
        - gnomealone
        - Beck777
        - AxAI
    id: 652e18d5b70ac2162b9a025a
    type: comment
  author: KrishnaKaasyap
  content: "I tried the model for both summarisation of a 1000 token length legal\
    \ case law and creating Q&A pairs from a 1500 token case law.\r\n\r\nIn summarising\
    \ the case law, the model performed at par with \U0001F917's Zephyr 7B (Mistral\
    \ fine tuned) model. But in creating Q&A pairs - it performed worse than Zephyr\
    \ 7B.\r\n\r\nComparing with LLaMA 2 70B chat (which is RLHF model) - the summarisation\
    \ from your model  is almost similar to LLaMA 2 70B.\r\n\r\nLLaMA 2 70B is visibly\
    \ great when creating Q&A pairs than both Zephyr and your model. And it is obvious\
    \ because first it is a RLHF  model and it is whooping 10 times bigger.\r\n\r\n\
    But what I'm amazed is yours is probably the only 32k context length 7B model\
    \ out there apart from @vipul 's Together AI LLaMA 7B 32K model. And yours is\
    \ the only one that is almost entirely trained on synthetic data!\r\n\r\nSince\
    \ you're in the first epoch of training, I'm expecting visible improvements after\
    \ reaching third or fourth epoch.\r\n\r\nGreat job dude. \U0001F44C\U0001F3FC"
  created_at: 2023-10-17 04:17:09+00:00
  edited: false
  hidden: false
  id: 652e18d5b70ac2162b9a025a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ba5d988373bb13f8760f56bf38e59428.svg
      fullname: Owen Colegrove
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: emrgnt-cmplxty
      type: user
    createdAt: '2023-10-17T21:55:10.000Z'
    data:
      edited: false
      editors:
      - emrgnt-cmplxty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9732021689414978
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ba5d988373bb13f8760f56bf38e59428.svg
          fullname: Owen Colegrove
          isHf: false
          isPro: false
          name: emrgnt-cmplxty
          type: user
        html: '<p>Thanks so much for your positive feedback, I''m glad you enjoyed
          the experience.</p>

          <p>The direct comparison with Zephyr is great for me to keep in mind.</p>

          <p>I will re-run your suggested experiments after the second, third, etc.
          epochs.</p>

          '
        raw: 'Thanks so much for your positive feedback, I''m glad you enjoyed the
          experience.


          The direct comparison with Zephyr is great for me to keep in mind.


          I will re-run your suggested experiments after the second, third, etc. epochs.

          '
        updatedAt: '2023-10-17T21:55:10.977Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - rjmehta
        - Beck777
      - count: 2
        reaction: "\U0001F44D"
        users:
        - PrimeD
        - dzupin
      - count: 1
        reaction: "\U0001F91D"
        users:
        - KrishnaKaasyap
    id: 652f02be5280b2cd039f3d10
    type: comment
  author: emrgnt-cmplxty
  content: 'Thanks so much for your positive feedback, I''m glad you enjoyed the experience.


    The direct comparison with Zephyr is great for me to keep in mind.


    I will re-run your suggested experiments after the second, third, etc. epochs.

    '
  created_at: 2023-10-17 20:55:10+00:00
  edited: false
  hidden: false
  id: 652f02be5280b2cd039f3d10
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/efacf65b052b236d859b56506576fa97.svg
      fullname: gnome
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gnomealone
      type: user
    createdAt: '2023-10-22T18:09:42.000Z'
    data:
      edited: false
      editors:
      - gnomealone
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9078226089477539
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/efacf65b052b236d859b56506576fa97.svg
          fullname: gnome
          isHf: false
          isPro: false
          name: gnomealone
          type: user
        html: "<blockquote>\n<p>I tried the model for both summarisation of a 1000\
          \ token length legal case law and creating Q&amp;A pairs from a 1500 token\
          \ case law.</p>\n<p>In summarising the case law, the model performed at\
          \ par with \U0001F917's Zephyr 7B (Mistral fine tuned) model. But in creating\
          \ Q&amp;A pairs - it performed worse than Zephyr 7B.</p>\n<p>Comparing with\
          \ LLaMA 2 70B chat (which is RLHF model) - the summarisation from your model\
          \  is almost similar to LLaMA 2 70B.</p>\n<p>LLaMA 2 70B is visibly great\
          \ when creating Q&amp;A pairs than both Zephyr and your model. And it is\
          \ obvious because first it is a RLHF  model and it is whooping 10 times\
          \ bigger.</p>\n<p>But what I'm amazed is yours is probably the only 32k\
          \ context length 7B model out there apart from <span data-props=\"{&quot;user&quot;:&quot;vipul&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/vipul\"\
          >@<span class=\"underline\">vipul</span></a></span>\n\n\t</span></span>\
          \ 's Together AI LLaMA 7B 32K model. And yours is the only one that is almost\
          \ entirely trained on synthetic data!</p>\n<p>Since you're in the first\
          \ epoch of training, I'm expecting visible improvements after reaching third\
          \ or fourth epoch.</p>\n<p>Great job dude. \U0001F44C\U0001F3FC</p>\n</blockquote>\n\
          <p>do you use the default system prompt ?  if not what prompts give you\
          \ better results?</p>\n"
        raw: "> I tried the model for both summarisation of a 1000 token length legal\
          \ case law and creating Q&A pairs from a 1500 token case law.\n> \n> In\
          \ summarising the case law, the model performed at par with \U0001F917's\
          \ Zephyr 7B (Mistral fine tuned) model. But in creating Q&A pairs - it performed\
          \ worse than Zephyr 7B.\n> \n> Comparing with LLaMA 2 70B chat (which is\
          \ RLHF model) - the summarisation from your model  is almost similar to\
          \ LLaMA 2 70B.\n> \n> LLaMA 2 70B is visibly great when creating Q&A pairs\
          \ than both Zephyr and your model. And it is obvious because first it is\
          \ a RLHF  model and it is whooping 10 times bigger.\n> \n> But what I'm\
          \ amazed is yours is probably the only 32k context length 7B model out there\
          \ apart from @vipul 's Together AI LLaMA 7B 32K model. And yours is the\
          \ only one that is almost entirely trained on synthetic data!\n> \n> Since\
          \ you're in the first epoch of training, I'm expecting visible improvements\
          \ after reaching third or fourth epoch.\n> \n> Great job dude. \U0001F44C\
          \U0001F3FC\n\ndo you use the default system prompt ?  if not what prompts\
          \ give you better results?"
        updatedAt: '2023-10-22T18:09:42.814Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - KrishnaKaasyap
    id: 65356566cb8a5a17e7836432
    type: comment
  author: gnomealone
  content: "> I tried the model for both summarisation of a 1000 token length legal\
    \ case law and creating Q&A pairs from a 1500 token case law.\n> \n> In summarising\
    \ the case law, the model performed at par with \U0001F917's Zephyr 7B (Mistral\
    \ fine tuned) model. But in creating Q&A pairs - it performed worse than Zephyr\
    \ 7B.\n> \n> Comparing with LLaMA 2 70B chat (which is RLHF model) - the summarisation\
    \ from your model  is almost similar to LLaMA 2 70B.\n> \n> LLaMA 2 70B is visibly\
    \ great when creating Q&A pairs than both Zephyr and your model. And it is obvious\
    \ because first it is a RLHF  model and it is whooping 10 times bigger.\n> \n\
    > But what I'm amazed is yours is probably the only 32k context length 7B model\
    \ out there apart from @vipul 's Together AI LLaMA 7B 32K model. And yours is\
    \ the only one that is almost entirely trained on synthetic data!\n> \n> Since\
    \ you're in the first epoch of training, I'm expecting visible improvements after\
    \ reaching third or fourth epoch.\n> \n> Great job dude. \U0001F44C\U0001F3FC\n\
    \ndo you use the default system prompt ?  if not what prompts give you better\
    \ results?"
  created_at: 2023-10-22 17:09:42+00:00
  edited: false
  hidden: false
  id: 65356566cb8a5a17e7836432
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/236c771e6c5a25ef6ed5e1bc061e30b8.svg
      fullname: Krishna Kaasyap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KrishnaKaasyap
      type: user
    createdAt: '2023-10-24T03:26:11.000Z'
    data:
      edited: false
      editors:
      - KrishnaKaasyap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8941916227340698
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/236c771e6c5a25ef6ed5e1bc061e30b8.svg
          fullname: Krishna Kaasyap
          isHf: false
          isPro: false
          name: KrishnaKaasyap
          type: user
        html: "<blockquote>\n<p>do you use the default system prompt ?  if not what\
          \ prompts give you better results?</p>\n</blockquote>\n<p>I used the default\
          \ system prompt. I don't think any 7B models or even 70B models out there\
          \ can be properly steered or controlled by changing system prompt.</p>\n\
          <p>Even GPT 3.5 couldn't properly be steered until late July and only after\
          \ improving the model and including function calling - it was able to consider\
          \ the system message as intended by the user.</p>\n<p>Now for summarisation\
          \ - I employed a specific style of prompt engineering by giving it the exact\
          \ format it needed at the start and finish of my prompt.</p>\n<p>For five\
          \ different examples I tested - it produced results almost similar to LLaMA\
          \ 2 70B chat (RLHF) model.</p>\n<p>Here's the prompt for summarisation -</p>\n\
          <p>You're a professor and expert on Indian income tax laws. Now explain\
          \ the below case law in the given format -</p>\n<ol>\n<li>Case name</li>\n\
          <li>In favour of</li>\n<li>Judges</li>\n<li>Counsel name</li>\n<li>Decision\
          \ date</li>\n<li>Appeal no</li>\n<li>Short summary of headnote</li>\n<li>Detailed\
          \ analysis of headnote</li>\n<li>Sections and their relative acts mentioned\
          \ in the case law</li>\n<li>Final judgement given and the reason for giving\
          \ such judgement</li>\n</ol>\n<p>---Text Starts---</p>\n<p>{Inserted text\
          \ from my legal case law which is almost 1000 - 1200 tokens}</p>\n<p>---Text\
          \ Ends---</p>\n<p>Be specific and accurate. Take a deep breath and work\
          \ on this problem step by step.</p>\n<p>\u2022\u2022\u2022\u2022\u2022\u2022\
          \u2022</p>\n<p>Now coming to generating Q&amp;A from the text given as output\
          \ here's the prompt I used -</p>\n<p>LLaMA 2 70B did it far better than\
          \ any open source model including this model and Zephyr. GPT 3.5 via Open\
          \ AI playground did it even better than LLaMA 2 70B.</p>\n<p>Here's the\
          \ prompt -</p>\n<p>Now create five (5) detailed and complex scholarly question\
          \ and answer sets based on the case law and explanation given above.</p>\n\
          <p>Mention technical details like - case name, sections and their relative\
          \ acts - in each and every question &amp; answer pair.</p>\n<p>Take a deep\
          \ breath and work on this problem step by step.</p>\n<p>Answer in the below\
          \ format -</p>\n<p>{\"prompt\": \"\", \"completion\": \"\"}</p>\n<p>{\"\
          prompt\": \"\", \"completion\": \"\"}</p>\n<p>{\"prompt\": \"\", \"completion\"\
          : \"\"}</p>\n<p>Most of the time it didn't even followed the given format\
          \ - and even followed, the generated Q&amp;A are very bland and unoriginal.</p>\n\
          <p>Hope this helps <span data-props=\"{&quot;user&quot;:&quot;gnomealone&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/gnomealone\"\
          >@<span class=\"underline\">gnomealone</span></a></span>\n\n\t</span></span>\
          \ , thanks. \U0001F44D\U0001F3FB</p>\n"
        raw: "> \n> do you use the default system prompt ?  if not what prompts give\
          \ you better results?\n\nI used the default system prompt. I don't think\
          \ any 7B models or even 70B models out there can be properly steered or\
          \ controlled by changing system prompt.\n\nEven GPT 3.5 couldn't properly\
          \ be steered until late July and only after improving the model and including\
          \ function calling - it was able to consider the system message as intended\
          \ by the user.\n\nNow for summarisation - I employed a specific style of\
          \ prompt engineering by giving it the exact format it needed at the start\
          \ and finish of my prompt.\n\nFor five different examples I tested - it\
          \ produced results almost similar to LLaMA 2 70B chat (RLHF) model.\n\n\
          Here's the prompt for summarisation -\n\nYou're a professor and expert on\
          \ Indian income tax laws. Now explain the below case law in the given format\
          \ -\n\n1) Case name\n2) In favour of\n3) Judges\n4) Counsel name\n5) Decision\
          \ date\n6) Appeal no\n7) Short summary of headnote\n8) Detailed analysis\
          \ of headnote\n9) Sections and their relative acts mentioned in the case\
          \ law\n10) Final judgement given and the reason for giving such judgement\n\
          \n---Text Starts---\n\n{Inserted text from my legal case law which is almost\
          \ 1000 - 1200 tokens}\n\n---Text Ends---\n\nBe specific and accurate. Take\
          \ a deep breath and work on this problem step by step.\n\n\n\u2022\u2022\
          \u2022\u2022\u2022\u2022\u2022\n\nNow coming to generating Q&A from the\
          \ text given as output here's the prompt I used -\n\nLLaMA 2 70B did it\
          \ far better than any open source model including this model and Zephyr.\
          \ GPT 3.5 via Open AI playground did it even better than LLaMA 2 70B.\n\n\
          \nHere's the prompt -\n\nNow create five (5) detailed and complex scholarly\
          \ question and answer sets based on the case law and explanation given above.\n\
          \nMention technical details like - case name, sections and their relative\
          \ acts - in each and every question & answer pair.\n\nTake a deep breath\
          \ and work on this problem step by step.\n\nAnswer in the below format -\n\
          \n{\"prompt\": \"<question text>\", \"completion\": \"<answer text>\"}\n\
          \n{\"prompt\": \"<question text>\", \"completion\": \"<answer text>\"}\n\
          \n{\"prompt\": \"<question text>\", \"completion\": \"<answer text>\"}\n\
          \nMost of the time it didn't even followed the given format - and even followed,\
          \ the generated Q&A are very bland and unoriginal.\n\nHope this helps @gnomealone\
          \ , thanks. \U0001F44D\U0001F3FB"
        updatedAt: '2023-10-24T03:26:11.642Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - gnomealone
    id: 65373953fb6eb06b92b70c6d
    type: comment
  author: KrishnaKaasyap
  content: "> \n> do you use the default system prompt ?  if not what prompts give\
    \ you better results?\n\nI used the default system prompt. I don't think any 7B\
    \ models or even 70B models out there can be properly steered or controlled by\
    \ changing system prompt.\n\nEven GPT 3.5 couldn't properly be steered until late\
    \ July and only after improving the model and including function calling - it\
    \ was able to consider the system message as intended by the user.\n\nNow for\
    \ summarisation - I employed a specific style of prompt engineering by giving\
    \ it the exact format it needed at the start and finish of my prompt.\n\nFor five\
    \ different examples I tested - it produced results almost similar to LLaMA 2\
    \ 70B chat (RLHF) model.\n\nHere's the prompt for summarisation -\n\nYou're a\
    \ professor and expert on Indian income tax laws. Now explain the below case law\
    \ in the given format -\n\n1) Case name\n2) In favour of\n3) Judges\n4) Counsel\
    \ name\n5) Decision date\n6) Appeal no\n7) Short summary of headnote\n8) Detailed\
    \ analysis of headnote\n9) Sections and their relative acts mentioned in the case\
    \ law\n10) Final judgement given and the reason for giving such judgement\n\n\
    ---Text Starts---\n\n{Inserted text from my legal case law which is almost 1000\
    \ - 1200 tokens}\n\n---Text Ends---\n\nBe specific and accurate. Take a deep breath\
    \ and work on this problem step by step.\n\n\n\u2022\u2022\u2022\u2022\u2022\u2022\
    \u2022\n\nNow coming to generating Q&A from the text given as output here's the\
    \ prompt I used -\n\nLLaMA 2 70B did it far better than any open source model\
    \ including this model and Zephyr. GPT 3.5 via Open AI playground did it even\
    \ better than LLaMA 2 70B.\n\n\nHere's the prompt -\n\nNow create five (5) detailed\
    \ and complex scholarly question and answer sets based on the case law and explanation\
    \ given above.\n\nMention technical details like - case name, sections and their\
    \ relative acts - in each and every question & answer pair.\n\nTake a deep breath\
    \ and work on this problem step by step.\n\nAnswer in the below format -\n\n{\"\
    prompt\": \"<question text>\", \"completion\": \"<answer text>\"}\n\n{\"prompt\"\
    : \"<question text>\", \"completion\": \"<answer text>\"}\n\n{\"prompt\": \"<question\
    \ text>\", \"completion\": \"<answer text>\"}\n\nMost of the time it didn't even\
    \ followed the given format - and even followed, the generated Q&A are very bland\
    \ and unoriginal.\n\nHope this helps @gnomealone , thanks. \U0001F44D\U0001F3FB"
  created_at: 2023-10-24 02:26:11+00:00
  edited: false
  hidden: false
  id: 65373953fb6eb06b92b70c6d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: SciPhi/SciPhi-Mistral-7B-32k
repo_type: model
status: open
target_branch: null
title: Just tested with some legal text - and here's my opinion/human eval.
