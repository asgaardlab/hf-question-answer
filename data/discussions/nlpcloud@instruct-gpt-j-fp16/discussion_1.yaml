!!python/object:huggingface_hub.community.DiscussionWithDetails
author: iRanadheer
conflicting_files: null
created_at: 2023-03-19 01:30:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a3e71090f856e407ee3b7ef7587acee3.svg
      fullname: Ranadheer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iRanadheer
      type: user
    createdAt: '2023-03-19T02:30:00.000Z'
    data:
      edited: false
      editors:
      - iRanadheer
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a3e71090f856e407ee3b7ef7587acee3.svg
          fullname: Ranadheer
          isHf: false
          isPro: false
          name: iRanadheer
          type: user
        html: '<p>Hey, finetuning the GPTJ with Stanford alpaca instructions is a
          great idea, I''m looking for something like this, it''s great to see someone
          has already done a great job.</p>

          <p>I''m trying to do few-shot learning (classification) with the GPT-J model,
          but it doesn''t seem to do a good job. I have tried the alpaca model (LORA),
          and it has increased the accuracy, but it''s still not enough. So, I''ve
          come across your instruct-gptj model. I tried the few-shot learning, it
          doesn''t seem to understand few-shot learning now, does it? I got very bad
          results all over. Maybe I''m doing something completely wrong. I was looking
          for the documentation for this model and it says that I don''t need the
          few-shot learning as the model can understand the instructions. </p>

          <p>what if I want to do the few-shot and provide a few examples for each
          class? will it work? Do you have any sample prompts? or have you not tested
          this? I''m very curious to know. </p>

          '
        raw: "Hey, finetuning the GPTJ with Stanford alpaca instructions is a great\
          \ idea, I'm looking for something like this, it's great to see someone has\
          \ already done a great job.\r\n\r\nI'm trying to do few-shot learning (classification)\
          \ with the GPT-J model, but it doesn't seem to do a good job. I have tried\
          \ the alpaca model (LORA), and it has increased the accuracy, but it's still\
          \ not enough. So, I've come across your instruct-gptj model. I tried the\
          \ few-shot learning, it doesn't seem to understand few-shot learning now,\
          \ does it? I got very bad results all over. Maybe I'm doing something completely\
          \ wrong. I was looking for the documentation for this model and it says\
          \ that I don't need the few-shot learning as the model can understand the\
          \ instructions. \r\n\r\nwhat if I want to do the few-shot and provide a\
          \ few examples for each class? will it work? Do you have any sample prompts?\
          \ or have you not tested this? I'm very curious to know. "
        updatedAt: '2023-03-19T02:30:00.094Z'
      numEdits: 0
      reactions: []
    id: 641673a86541a51ac797bf46
    type: comment
  author: iRanadheer
  content: "Hey, finetuning the GPTJ with Stanford alpaca instructions is a great\
    \ idea, I'm looking for something like this, it's great to see someone has already\
    \ done a great job.\r\n\r\nI'm trying to do few-shot learning (classification)\
    \ with the GPT-J model, but it doesn't seem to do a good job. I have tried the\
    \ alpaca model (LORA), and it has increased the accuracy, but it's still not enough.\
    \ So, I've come across your instruct-gptj model. I tried the few-shot learning,\
    \ it doesn't seem to understand few-shot learning now, does it? I got very bad\
    \ results all over. Maybe I'm doing something completely wrong. I was looking\
    \ for the documentation for this model and it says that I don't need the few-shot\
    \ learning as the model can understand the instructions. \r\n\r\nwhat if I want\
    \ to do the few-shot and provide a few examples for each class? will it work?\
    \ Do you have any sample prompts? or have you not tested this? I'm very curious\
    \ to know. "
  created_at: 2023-03-19 01:30:00+00:00
  edited: false
  hidden: false
  id: 641673a86541a51ac797bf46
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678959361486-6412e2653e3f06f67efaf21d.jpeg?w=200&h=200&f=face
      fullname: Julien Salinas
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: juliensalinas
      type: user
    createdAt: '2023-03-20T10:09:39.000Z'
    data:
      edited: false
      editors:
      - juliensalinas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678959361486-6412e2653e3f06f67efaf21d.jpeg?w=200&h=200&f=face
          fullname: Julien Salinas
          isHf: false
          isPro: false
          name: juliensalinas
          type: user
        html: '<p>Thanks, and cool to see that you had the same idea :)<br>In our
          tests this model seems to still perform correctly for few-shot learning,
          even if fine-tuned for instructions. For to be honest I don''t really see
          why you would use this model if you are trying to perform text classification
          with few-shot learning.<br>Maybe you can have a look at our guide to see
          how to perform few-shot learning for classification: <a rel="nofollow" href="https://nlpcloud.com/effectively-using-gpt-j-gpt-neo-gpt-3-alternatives-few-shot-learning.html#zero-shot-text-classification">https://nlpcloud.com/effectively-using-gpt-j-gpt-neo-gpt-3-alternatives-few-shot-learning.html#zero-shot-text-classification</a></p>

          '
        raw: 'Thanks, and cool to see that you had the same idea :)

          In our tests this model seems to still perform correctly for few-shot learning,
          even if fine-tuned for instructions. For to be honest I don''t really see
          why you would use this model if you are trying to perform text classification
          with few-shot learning.

          Maybe you can have a look at our guide to see how to perform few-shot learning
          for classification: https://nlpcloud.com/effectively-using-gpt-j-gpt-neo-gpt-3-alternatives-few-shot-learning.html#zero-shot-text-classification'
        updatedAt: '2023-03-20T10:09:39.424Z'
      numEdits: 0
      reactions: []
    id: 641830e378ed80cfdb0036a1
    type: comment
  author: juliensalinas
  content: 'Thanks, and cool to see that you had the same idea :)

    In our tests this model seems to still perform correctly for few-shot learning,
    even if fine-tuned for instructions. For to be honest I don''t really see why
    you would use this model if you are trying to perform text classification with
    few-shot learning.

    Maybe you can have a look at our guide to see how to perform few-shot learning
    for classification: https://nlpcloud.com/effectively-using-gpt-j-gpt-neo-gpt-3-alternatives-few-shot-learning.html#zero-shot-text-classification'
  created_at: 2023-03-20 09:09:39+00:00
  edited: false
  hidden: false
  id: 641830e378ed80cfdb0036a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a3e71090f856e407ee3b7ef7587acee3.svg
      fullname: Ranadheer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iRanadheer
      type: user
    createdAt: '2023-03-20T10:32:34.000Z'
    data:
      edited: false
      editors:
      - iRanadheer
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a3e71090f856e407ee3b7ef7587acee3.svg
          fullname: Ranadheer
          isHf: false
          isPro: false
          name: iRanadheer
          type: user
        html: '<p>I have tried GPT-J and NEO for few-shot learning. the quality is
          not good enough. In fact, I tested a few examples on your playground, I
          think it''s more or less the same. Did you retrain or fine-tune the gptj
          model before you create an API?</p>

          '
        raw: I have tried GPT-J and NEO for few-shot learning. the quality is not
          good enough. In fact, I tested a few examples on your playground, I think
          it's more or less the same. Did you retrain or fine-tune the gptj model
          before you create an API?
        updatedAt: '2023-03-20T10:32:34.039Z'
      numEdits: 0
      reactions: []
    id: 64183642bae18e1c37b6e37c
    type: comment
  author: iRanadheer
  content: I have tried GPT-J and NEO for few-shot learning. the quality is not good
    enough. In fact, I tested a few examples on your playground, I think it's more
    or less the same. Did you retrain or fine-tune the gptj model before you create
    an API?
  created_at: 2023-03-20 09:32:34+00:00
  edited: false
  hidden: false
  id: 64183642bae18e1c37b6e37c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678959361486-6412e2653e3f06f67efaf21d.jpeg?w=200&h=200&f=face
      fullname: Julien Salinas
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: juliensalinas
      type: user
    createdAt: '2023-03-21T09:02:49.000Z'
    data:
      edited: false
      editors:
      - juliensalinas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678959361486-6412e2653e3f06f67efaf21d.jpeg?w=200&h=200&f=face
          fullname: Julien Salinas
          isHf: false
          isPro: false
          name: juliensalinas
          type: user
        html: '<p>"I think it''s more or less the same" --&gt; I am not exactly sure
          what you mean by that.<br>Maybe you can copy paste a few-shot example here
          so I can advise, and so it benefits everyone who is reading this?</p>

          <p>"Did you retrain or fine-tune the gptj model" --&gt; Yes this instruct
          GPT-J model is a fine-tuned version of GPT-J</p>

          '
        raw: '"I think it''s more or less the same" --> I am not exactly sure what
          you mean by that.

          Maybe you can copy paste a few-shot example here so I can advise, and so
          it benefits everyone who is reading this?


          "Did you retrain or fine-tune the gptj model" --> Yes this instruct GPT-J
          model is a fine-tuned version of GPT-J'
        updatedAt: '2023-03-21T09:02:49.539Z'
      numEdits: 0
      reactions: []
    id: 641972b959097c6418e7be77
    type: comment
  author: juliensalinas
  content: '"I think it''s more or less the same" --> I am not exactly sure what you
    mean by that.

    Maybe you can copy paste a few-shot example here so I can advise, and so it benefits
    everyone who is reading this?


    "Did you retrain or fine-tune the gptj model" --> Yes this instruct GPT-J model
    is a fine-tuned version of GPT-J'
  created_at: 2023-03-21 08:02:49+00:00
  edited: false
  hidden: false
  id: 641972b959097c6418e7be77
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660775548920-628d998a2b60ec0f336cc1eb.png?w=200&h=200&f=face
      fullname: Carl Silva
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: silvacarl
      type: user
    createdAt: '2023-03-21T16:03:26.000Z'
    data:
      edited: false
      editors:
      - silvacarl
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660775548920-628d998a2b60ec0f336cc1eb.png?w=200&h=200&f=face
          fullname: Carl Silva
          isHf: false
          isPro: true
          name: silvacarl
          type: user
        html: '<p>if you want to see something insane, try nlpcloud''s GPT_Neo fien
          tuned mdoel.</p>

          '
        raw: if you want to see something insane, try nlpcloud's GPT_Neo fien tuned
          mdoel.
        updatedAt: '2023-03-21T16:03:26.688Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - juliensalinas
    id: 6419d54ef0415b2ec8385e4f
    type: comment
  author: silvacarl
  content: if you want to see something insane, try nlpcloud's GPT_Neo fien tuned
    mdoel.
  created_at: 2023-03-21 15:03:26+00:00
  edited: false
  hidden: false
  id: 6419d54ef0415b2ec8385e4f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: nlpcloud/instruct-gpt-j-fp16
repo_type: model
status: open
target_branch: null
title: Few shot learning
