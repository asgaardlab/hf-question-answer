!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Alexziyu
conflicting_files: null
created_at: 2023-11-11 08:57:28+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0aaa6982fd0beb5f792a4bf5f38e321.svg
      fullname: Ziyu Wang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Alexziyu
      type: user
    createdAt: '2023-11-11T08:57:28.000Z'
    data:
      edited: false
      editors:
      - Alexziyu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9266173243522644
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0aaa6982fd0beb5f792a4bf5f38e321.svg
          fullname: Ziyu Wang
          isHf: false
          isPro: false
          name: Alexziyu
          type: user
        html: '<p>How to use this unfine-tuned pre-trained model to perform its pre-trained
          task ---- generating html representations of screenshots? Thanks</p>

          '
        raw: How to use this unfine-tuned pre-trained model to perform its pre-trained
          task ---- generating html representations of screenshots? Thanks
        updatedAt: '2023-11-11T08:57:28.796Z'
      numEdits: 0
      reactions: []
    id: 654f41f82adb0688a0c5e21b
    type: comment
  author: Alexziyu
  content: How to use this unfine-tuned pre-trained model to perform its pre-trained
    task ---- generating html representations of screenshots? Thanks
  created_at: 2023-11-11 08:57:28+00:00
  edited: false
  hidden: false
  id: 654f41f82adb0688a0c5e21b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
      fullname: Lysandre
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lysandre
      type: user
    createdAt: '2023-11-13T16:11:54.000Z'
    data:
      edited: false
      editors:
      - lysandre
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.679378867149353
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
          fullname: Lysandre
          isHf: true
          isPro: false
          name: lysandre
          type: user
        html: "<p>Maybe <span data-props=\"{&quot;user&quot;:&quot;Molbap&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Molbap\"\
          >@<span class=\"underline\">Molbap</span></a></span>\n\n\t</span></span>\
          \ can help out :)</p>\n"
        raw: Maybe @Molbap can help out :)
        updatedAt: '2023-11-13T16:11:54.226Z'
      numEdits: 0
      reactions: []
    id: 65524aca09c73282c8b253b0
    type: comment
  author: lysandre
  content: Maybe @Molbap can help out :)
  created_at: 2023-11-13 16:11:54+00:00
  edited: false
  hidden: false
  id: 65524aca09c73282c8b253b0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
      fullname: Pablo Montalvo
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Molbap
      type: user
    createdAt: '2023-11-13T17:55:05.000Z'
    data:
      edited: false
      editors:
      - Molbap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8829212188720703
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
          fullname: Pablo Montalvo
          isHf: true
          isPro: false
          name: Molbap
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Alexziyu&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Alexziyu\"\
          >@<span class=\"underline\">Alexziyu</span></a></span>\n\n\t</span></span>\
          \ , I'm not 100% certain it can actually be done, because what pix2struct\
          \ has been trained on is a simplified html code of webpages.<br>As a matter\
          \ of fact this issue was brought up in the official repo a few times:</p>\n\
          <p><a rel=\"nofollow\" href=\"https://github.com/google-research/pix2struct/issues/1\"\
          >https://github.com/google-research/pix2struct/issues/1</a><br><a rel=\"\
          nofollow\" href=\"https://github.com/google-research/pix2struct/issues/38\"\
          >https://github.com/google-research/pix2struct/issues/38</a></p>\n<p> However\
          \ for instance if you feed the beginning of such a simplified structure\
          \ as a prompt, you start getting html elements of the image. I used a screenshot\
          \ of  the Google landing page, use <code>&lt;&lt;</code> as a prompt,  I'm\
          \ starting to get some html-like outputs. This is after initializing processor\
          \ and model from <code>pix2struct-base</code>.</p>\n<pre><code class=\"\
          language-python\">img = Image.<span class=\"hljs-built_in\">open</span>(<span\
          \ class=\"hljs-string\">\"google_homepage.png\"</span>).convert(<span class=\"\
          hljs-string\">'RGB'</span>)\ninputs = processor(text=<span class=\"hljs-string\"\
          >\"&lt;&lt;\"</span>, images=img, return_tensors=<span class=\"hljs-string\"\
          >'pt'</span>)                                                          \
          \                                                                      \
          \                                                                      \
          \        \nprocessor.decode(model.generate(**inputs, max_new_tokens=<span\
          \ class=\"hljs-number\">100</span>)[<span class=\"hljs-number\">0</span>])\
          \                                                                      \
          \                                                                      \
          \                                                                   \n&gt;&gt;\
          \ <span class=\"hljs-string\">'&lt;pad&gt; &lt;&lt;&lt;/s&gt;&gt; &lt;img_src=logo_google\
          \ img_alt=google&gt;&gt;&lt;/s&gt;'</span>\n</code></pre>\n<p>The reason\
          \ for that is that the simplified representation of html uses <code>&gt;</code>,\
          \ <code>&lt;</code> and so on for divisions and structures. I would suggest\
          \ experimenting around this, but if there is a specific pretraining prompt,\
          \ I don't know it. I'm also interested to know more!</p>\n"
        raw: "Hey @Alexziyu , I'm not 100% certain it can actually be done, because\
          \ what pix2struct has been trained on is a simplified html code of webpages.\n\
          As a matter of fact this issue was brought up in the official repo a few\
          \ times:\n \nhttps://github.com/google-research/pix2struct/issues/1\nhttps://github.com/google-research/pix2struct/issues/38\n\
          \n However for instance if you feed the beginning of such a simplified structure\
          \ as a prompt, you start getting html elements of the image. I used a screenshot\
          \ of  the Google landing page, use `<<` as a prompt,  I'm starting to get\
          \ some html-like outputs. This is after initializing processor and model\
          \ from `pix2struct-base`.\n\n```python\nimg = Image.open(\"google_homepage.png\"\
          ).convert('RGB')\ninputs = processor(text=\"<<\", images=img, return_tensors='pt')\
          \                                                                      \
          \                                                                      \
          \                                                                  \nprocessor.decode(model.generate(**inputs,\
          \ max_new_tokens=100)[0])                                              \
          \                                                                      \
          \                                                                      \
          \                     \n>> '<pad> <<</s>> <img_src=logo_google img_alt=google>></s>'\n\
          ```\nThe reason for that is that the simplified representation of html uses\
          \ `>`, `<` and so on for divisions and structures. I would suggest experimenting\
          \ around this, but if there is a specific pretraining prompt, I don't know\
          \ it. I'm also interested to know more!"
        updatedAt: '2023-11-13T17:55:05.373Z'
      numEdits: 0
      reactions: []
    id: 655262f91f7100eda051f4b4
    type: comment
  author: Molbap
  content: "Hey @Alexziyu , I'm not 100% certain it can actually be done, because\
    \ what pix2struct has been trained on is a simplified html code of webpages.\n\
    As a matter of fact this issue was brought up in the official repo a few times:\n\
    \ \nhttps://github.com/google-research/pix2struct/issues/1\nhttps://github.com/google-research/pix2struct/issues/38\n\
    \n However for instance if you feed the beginning of such a simplified structure\
    \ as a prompt, you start getting html elements of the image. I used a screenshot\
    \ of  the Google landing page, use `<<` as a prompt,  I'm starting to get some\
    \ html-like outputs. This is after initializing processor and model from `pix2struct-base`.\n\
    \n```python\nimg = Image.open(\"google_homepage.png\").convert('RGB')\ninputs\
    \ = processor(text=\"<<\", images=img, return_tensors='pt')                  \
    \                                                                            \
    \                                                                            \
    \                                    \nprocessor.decode(model.generate(**inputs,\
    \ max_new_tokens=100)[0])                                                    \
    \                                                                            \
    \                                                                            \
    \   \n>> '<pad> <<</s>> <img_src=logo_google img_alt=google>></s>'\n```\nThe reason\
    \ for that is that the simplified representation of html uses `>`, `<` and so\
    \ on for divisions and structures. I would suggest experimenting around this,\
    \ but if there is a specific pretraining prompt, I don't know it. I'm also interested\
    \ to know more!"
  created_at: 2023-11-13 17:55:05+00:00
  edited: false
  hidden: false
  id: 655262f91f7100eda051f4b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0aaa6982fd0beb5f792a4bf5f38e321.svg
      fullname: Ziyu Wang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Alexziyu
      type: user
    createdAt: '2023-11-13T21:00:42.000Z'
    data:
      edited: false
      editors:
      - Alexziyu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9901429414749146
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0aaa6982fd0beb5f792a4bf5f38e321.svg
          fullname: Ziyu Wang
          isHf: false
          isPro: false
          name: Alexziyu
          type: user
        html: '<p>so I need "&lt;&lt;" as a prompt? May I ask how do you know that?
          I will try it, thank you very much!!</p>

          '
        raw: so I need "<<" as a prompt? May I ask how do you know that? I will try
          it, thank you very much!!
        updatedAt: '2023-11-13T21:00:42.447Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - Molbap
    id: 65528e7a1f7100eda05bd032
    type: comment
  author: Alexziyu
  content: so I need "<<" as a prompt? May I ask how do you know that? I will try
    it, thank you very much!!
  created_at: 2023-11-13 21:00:42+00:00
  edited: false
  hidden: false
  id: 65528e7a1f7100eda05bd032
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
      fullname: Pablo Montalvo
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Molbap
      type: user
    createdAt: '2023-11-13T22:40:12.000Z'
    data:
      edited: false
      editors:
      - Molbap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9719895720481873
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64789feb79f2d49511ed7db4/IzaIwiVgnkTZHrcLDQk0C.jpeg?w=200&h=200&f=face
          fullname: Pablo Montalvo
          isHf: true
          isPro: false
          name: Molbap
          type: user
        html: '<p>I do not think it is enough, but it''s something that will mimic
          the simplified html from the pretraining objective. But I think it is missing
          a special pretraining token and perhaps a prompt structure, but some html
          elements can be recovered.</p>

          '
        raw: I do not think it is enough, but it's something that will mimic the simplified
          html from the pretraining objective. But I think it is missing a special
          pretraining token and perhaps a prompt structure, but some html elements
          can be recovered.
        updatedAt: '2023-11-13T22:40:12.628Z'
      numEdits: 0
      reactions: []
    id: 6552a5cc09c73282c8c6b963
    type: comment
  author: Molbap
  content: I do not think it is enough, but it's something that will mimic the simplified
    html from the pretraining objective. But I think it is missing a special pretraining
    token and perhaps a prompt structure, but some html elements can be recovered.
  created_at: 2023-11-13 22:40:12+00:00
  edited: false
  hidden: false
  id: 6552a5cc09c73282c8c6b963
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
      fullname: Ross Wightman
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rwightman
      type: user
    createdAt: '2023-11-14T00:53:45.000Z'
    data:
      edited: false
      editors:
      - rwightman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9319642782211304
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
          fullname: Ross Wightman
          isHf: true
          isPro: false
          name: rwightman
          type: user
        html: '<p>These models are not supposed to need any prompt in terms of decoder
          input ids, prompts should be rendered onto the image. </p>

          <p>I wonder if something else is wrong, because yeah, this appears unable
          to really generate much of relevance to the input image...</p>

          '
        raw: "These models are not supposed to need any prompt in terms of decoder\
          \ input ids, prompts should be rendered onto the image. \n\nI wonder if\
          \ something else is wrong, because yeah, this appears unable to really generate\
          \ much of relevance to the input image..."
        updatedAt: '2023-11-14T00:53:45.982Z'
      numEdits: 0
      reactions: []
    id: 6552c5197c19c73546b027ab
    type: comment
  author: rwightman
  content: "These models are not supposed to need any prompt in terms of decoder input\
    \ ids, prompts should be rendered onto the image. \n\nI wonder if something else\
    \ is wrong, because yeah, this appears unable to really generate much of relevance\
    \ to the input image..."
  created_at: 2023-11-14 00:53:45+00:00
  edited: false
  hidden: false
  id: 6552c5197c19c73546b027ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
      fullname: Ross Wightman
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rwightman
      type: user
    createdAt: '2023-11-14T01:14:58.000Z'
    data:
      edited: true
      editors:
      - rwightman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9167632460594177
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
          fullname: Ross Wightman
          isHf: true
          isPro: false
          name: rwightman
          type: user
        html: "<p>Further, trying to feed images into the 'unfine-tuned' models in\
          \ transformers if I get anything other than a few tokens it'll be gibberish\
          \ (wrt to the image) like </p>\n<p><code>'&lt;pad&gt;&lt;/s&gt; for business\
          \ and personal reasons.&gt; &lt;The only way to get the full picture is\
          \ to use the html element of the image.&gt; &lt;The first step is to get\
          \ the html element of the image.&gt; &lt;The second step is to get the html\
          \ element of the image.&gt; &lt;The third step is to get the html element\
          \ of the image.&gt; &lt;The third step is to get the html element of the\
          \ image.&gt; &lt;The second step is to get the'</code></p>\n<p>or </p>\n\
          <p><code>&lt;pad&gt;&lt;/s&gt; for commercial purposes.&gt; &lt;International\
          \ shipments are expected to be made in the next few weeks.&gt; &lt;Please\
          \ be aware that the shipping costs are not included in the price.&gt; &lt;If\
          \ you are not sure what you are getting, please contact me.&gt; &lt;I am\
          \ not a professional engineer, but I do have a good understanding of the\
          \ technical aspects of the industry.&gt; &lt;I am a professional engineer,\
          \ but I am not a professional engineer.&gt; &lt;I am a professional engineer,\
          \ but']</code></p>\n<p>Wheras, using the demo app in the pix2struct original\
          \ (flax) impl, I can get something if the text is reasonably sized. This\
          \ output is for same web page on Amazon.ca as the second gibbersh above...</p>\n\
          <p><code>&lt;img_alt=Frog and Toad Storybook Favorites: Includes 4 Stories\
          \ Plus Stickers! Hardcover \u2013 Sticker Book, Feb. 19 2019 img_src=9781442400000_cover_middle_low&gt;</code></p>\n\
          <p>Image is a window snapshot of upper left corner, zoomed in (in a narrow\
          \ window) of this <a rel=\"nofollow\" href=\"https://www.amazon.ca/Frog-Toad-Storybook-Favorites-Stickers/dp/0062883127\"\
          >https://www.amazon.ca/Frog-Toad-Storybook-Favorites-Stickers/dp/0062883127</a></p>\n"
        raw: "Further, trying to feed images into the 'unfine-tuned' models in transformers\
          \ if I get anything other than a few tokens it'll be gibberish (wrt to the\
          \ image) like \n\n```'<pad></s> for business and personal reasons.> <The\
          \ only way to get the full picture is to use the html element of the image.>\
          \ <The first step is to get the html element of the image.> <The second\
          \ step is to get the html element of the image.> <The third step is to get\
          \ the html element of the image.> <The third step is to get the html element\
          \ of the image.> <The second step is to get the'```\n\nor \n\n```<pad></s>\
          \ for commercial purposes.> <International shipments are expected to be\
          \ made in the next few weeks.> <Please be aware that the shipping costs\
          \ are not included in the price.> <If you are not sure what you are getting,\
          \ please contact me.> <I am not a professional engineer, but I do have a\
          \ good understanding of the technical aspects of the industry.> <I am a\
          \ professional engineer, but I am not a professional engineer.> <I am a\
          \ professional engineer, but']```\n\nWheras, using the demo app in the pix2struct\
          \ original (flax) impl, I can get something if the text is reasonably sized.\
          \ This output is for same web page on Amazon.ca as the second gibbersh above...\n\
          \n```<img_alt=Frog and Toad Storybook Favorites: Includes 4 Stories Plus\
          \ Stickers! Hardcover \u2013 Sticker Book, Feb. 19 2019 img_src=9781442400000_cover_middle_low>```\n\
          \nImage is a window snapshot of upper left corner, zoomed in (in a narrow\
          \ window) of this https://www.amazon.ca/Frog-Toad-Storybook-Favorites-Stickers/dp/0062883127"
        updatedAt: '2023-11-14T01:15:18.044Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - julien-c
    id: 6552ca1273a5a6f9385971c5
    type: comment
  author: rwightman
  content: "Further, trying to feed images into the 'unfine-tuned' models in transformers\
    \ if I get anything other than a few tokens it'll be gibberish (wrt to the image)\
    \ like \n\n```'<pad></s> for business and personal reasons.> <The only way to\
    \ get the full picture is to use the html element of the image.> <The first step\
    \ is to get the html element of the image.> <The second step is to get the html\
    \ element of the image.> <The third step is to get the html element of the image.>\
    \ <The third step is to get the html element of the image.> <The second step is\
    \ to get the'```\n\nor \n\n```<pad></s> for commercial purposes.> <International\
    \ shipments are expected to be made in the next few weeks.> <Please be aware that\
    \ the shipping costs are not included in the price.> <If you are not sure what\
    \ you are getting, please contact me.> <I am not a professional engineer, but\
    \ I do have a good understanding of the technical aspects of the industry.> <I\
    \ am a professional engineer, but I am not a professional engineer.> <I am a professional\
    \ engineer, but']```\n\nWheras, using the demo app in the pix2struct original\
    \ (flax) impl, I can get something if the text is reasonably sized. This output\
    \ is for same web page on Amazon.ca as the second gibbersh above...\n\n```<img_alt=Frog\
    \ and Toad Storybook Favorites: Includes 4 Stories Plus Stickers! Hardcover \u2013\
    \ Sticker Book, Feb. 19 2019 img_src=9781442400000_cover_middle_low>```\n\nImage\
    \ is a window snapshot of upper left corner, zoomed in (in a narrow window) of\
    \ this https://www.amazon.ca/Frog-Toad-Storybook-Favorites-Stickers/dp/0062883127"
  created_at: 2023-11-14 01:14:58+00:00
  edited: true
  hidden: false
  id: 6552ca1273a5a6f9385971c5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
      fullname: Ross Wightman
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rwightman
      type: user
    createdAt: '2023-11-14T01:22:05.000Z'
    data:
      edited: false
      editors:
      - rwightman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.853540301322937
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
          fullname: Ross Wightman
          isHf: true
          isPro: false
          name: rwightman
          type: user
        html: '<p>And one last comment, while the info re the exact rules and html
          subset used for the pretrain are sadly not specified, I feel you can piece
          together some of it by paying close attention to the tokenizer, look for
          the html tags! And also, this paper reference in pix2struct in relation
          to Simplified HTML might have some clues <a rel="nofollow" href="https://openreview.net/forum?id=P-pPW1nxf1r">https://openreview.net/forum?id=P-pPW1nxf1r</a></p>

          '
        raw: 'And one last comment, while the info re the exact rules and html subset
          used for the pretrain are sadly not specified, I feel you can piece together
          some of it by paying close attention to the tokenizer, look for the html
          tags! And also, this paper reference in pix2struct in relation to Simplified
          HTML might have some clues https://openreview.net/forum?id=P-pPW1nxf1r

          '
        updatedAt: '2023-11-14T01:22:05.349Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - julien-c
    id: 6552cbbd9e7aff78789a0923
    type: comment
  author: rwightman
  content: 'And one last comment, while the info re the exact rules and html subset
    used for the pretrain are sadly not specified, I feel you can piece together some
    of it by paying close attention to the tokenizer, look for the html tags! And
    also, this paper reference in pix2struct in relation to Simplified HTML might
    have some clues https://openreview.net/forum?id=P-pPW1nxf1r

    '
  created_at: 2023-11-14 01:22:05+00:00
  edited: false
  hidden: false
  id: 6552cbbd9e7aff78789a0923
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0aaa6982fd0beb5f792a4bf5f38e321.svg
      fullname: Ziyu Wang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Alexziyu
      type: user
    createdAt: '2023-11-14T02:23:53.000Z'
    data:
      edited: false
      editors:
      - Alexziyu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9950858950614929
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0aaa6982fd0beb5f792a4bf5f38e321.svg
          fullname: Ziyu Wang
          isHf: false
          isPro: false
          name: Alexziyu
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;rwightman&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/rwightman\"\
          >@<span class=\"underline\">rwightman</span></a></span>\n\n\t</span></span>\
          \ <span data-props=\"{&quot;user&quot;:&quot;Molbap&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Molbap\">@<span class=\"\
          underline\">Molbap</span></a></span>\n\n\t</span></span>  I was actually\
          \ trying to replicate the pre-training results, but it looks like the model\
          \ didn't work very well. It was really weird and I wondered if I should\
          \ try to contact the author of the paper, after all there were so many people\
          \ with the same question</p>\n"
        raw: Thanks @rwightman @Molbap  I was actually trying to replicate the pre-training
          results, but it looks like the model didn't work very well. It was really
          weird and I wondered if I should try to contact the author of the paper,
          after all there were so many people with the same question
        updatedAt: '2023-11-14T02:23:53.852Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - julien-c
        - Molbap
    id: 6552da39131813fc41e08e06
    type: comment
  author: Alexziyu
  content: Thanks @rwightman @Molbap  I was actually trying to replicate the pre-training
    results, but it looks like the model didn't work very well. It was really weird
    and I wondered if I should try to contact the author of the paper, after all there
    were so many people with the same question
  created_at: 2023-11-14 02:23:53+00:00
  edited: false
  hidden: false
  id: 6552da39131813fc41e08e06
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: google/pix2struct-base
repo_type: model
status: open
target_branch: null
title: How to use this model to extract html structure from image?
