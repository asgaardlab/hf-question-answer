!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ischlag
conflicting_files: null
created_at: 2022-09-01 17:36:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5bced71b6d507e621ec159ada94480f0.svg
      fullname: Imanol Schlag
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ischlag
      type: user
    createdAt: '2022-09-01T18:36:29.000Z'
    data:
      edited: false
      editors:
      - ischlag
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5bced71b6d507e621ec159ada94480f0.svg
          fullname: Imanol Schlag
          isHf: false
          isPro: false
          name: ischlag
          type: user
        html: '<p>1.) The model card has the same code for all tk-instruct models.
          There is no separate vocab for the 11b models so I guess it is the same
          as the 3b model? It does seem to work but it would be nice if this could
          be confirmed.</p>

          <p>2.) The tokenizer, as described by the model card, ignores newlines and
          certain whitespaces. I think that those whitespaces are necessary in order
          to follow the input template as described by the tk-instruct paper. How
          do we change the tokenizer.encode such that it does not ignore whitespace?
          </p>

          '
        raw: "1.) The model card has the same code for all tk-instruct models. There\
          \ is no separate vocab for the 11b models so I guess it is the same as the\
          \ 3b model? It does seem to work but it would be nice if this could be confirmed.\r\
          \n\r\n2.) The tokenizer, as described by the model card, ignores newlines\
          \ and certain whitespaces. I think that those whitespaces are necessary\
          \ in order to follow the input template as described by the tk-instruct\
          \ paper. How do we change the tokenizer.encode such that it does not ignore\
          \ whitespace? "
        updatedAt: '2022-09-01T18:36:29.646Z'
      numEdits: 0
      reactions: []
    id: 6310fbadd43c55e811f8522a
    type: comment
  author: ischlag
  content: "1.) The model card has the same code for all tk-instruct models. There\
    \ is no separate vocab for the 11b models so I guess it is the same as the 3b\
    \ model? It does seem to work but it would be nice if this could be confirmed.\r\
    \n\r\n2.) The tokenizer, as described by the model card, ignores newlines and\
    \ certain whitespaces. I think that those whitespaces are necessary in order to\
    \ follow the input template as described by the tk-instruct paper. How do we change\
    \ the tokenizer.encode such that it does not ignore whitespace? "
  created_at: 2022-09-01 17:36:29+00:00
  edited: false
  hidden: false
  id: 6310fbadd43c55e811f8522a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5bced71b6d507e621ec159ada94480f0.svg
      fullname: Imanol Schlag
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ischlag
      type: user
    createdAt: '2022-09-01T18:56:08.000Z'
    data:
      edited: false
      editors:
      - ischlag
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5bced71b6d507e621ec159ada94480f0.svg
          fullname: Imanol Schlag
          isHf: false
          isPro: false
          name: ischlag
          type: user
        html: '<p>Regarding 2) something that has been proposed but DOESNT work is:
          </p>

          <p>from tokenizers import AddedToken<br>tokenizer.add_special_tokens({"additional_special_tokens":
          [AddedToken("\n"), AddedToken("\t")]}</p>

          <p>But this adds a whitespace character after the newline:<br>x = tokenizer.encode("A\nB\n\nC\t\t\tD",
          return_tensors="pt")<br>tokenizer.decode(x[0], skip_special_tokens=False)  #
          ''A\n B\n\n C\t\t\t D''</p>

          <p>The newline character is in the vocab so I guess the sentencepiece preprocessing
          is removing it.<br>''\n'' in tokenizer.vocab.keys(). # True</p>

          '
        raw: "Regarding 2) something that has been proposed but DOESNT work is: \n\
          \nfrom tokenizers import AddedToken\ntokenizer.add_special_tokens({\"additional_special_tokens\"\
          : [AddedToken(\"\\n\"), AddedToken(\"\\t\")]}\n\nBut this adds a whitespace\
          \ character after the newline:\nx = tokenizer.encode(\"A\\nB\\n\\nC\\t\\\
          t\\tD\", return_tensors=\"pt\")\ntokenizer.decode(x[0], skip_special_tokens=False)\
          \  # 'A\\n B\\n\\n C\\t\\t\\t D</s>'\n\nThe newline character is in the\
          \ vocab so I guess the sentencepiece preprocessing is removing it. \n'\\\
          n' in tokenizer.vocab.keys(). # True"
        updatedAt: '2022-09-01T18:56:08.860Z'
      numEdits: 0
      reactions: []
    id: 63110048af1fce227a3ceedb
    type: comment
  author: ischlag
  content: "Regarding 2) something that has been proposed but DOESNT work is: \n\n\
    from tokenizers import AddedToken\ntokenizer.add_special_tokens({\"additional_special_tokens\"\
    : [AddedToken(\"\\n\"), AddedToken(\"\\t\")]}\n\nBut this adds a whitespace character\
    \ after the newline:\nx = tokenizer.encode(\"A\\nB\\n\\nC\\t\\t\\tD\", return_tensors=\"\
    pt\")\ntokenizer.decode(x[0], skip_special_tokens=False)  # 'A\\n B\\n\\n C\\\
    t\\t\\t D</s>'\n\nThe newline character is in the vocab so I guess the sentencepiece\
    \ preprocessing is removing it. \n'\\n' in tokenizer.vocab.keys(). # True"
  created_at: 2022-09-01 17:56:08+00:00
  edited: false
  hidden: false
  id: 63110048af1fce227a3ceedb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5bced71b6d507e621ec159ada94480f0.svg
      fullname: Imanol Schlag
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ischlag
      type: user
    createdAt: '2022-09-02T01:07:59.000Z'
    data:
      edited: false
      editors:
      - ischlag
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5bced71b6d507e621ec159ada94480f0.svg
          fullname: Imanol Schlag
          isHf: false
          isPro: false
          name: ischlag
          type: user
        html: '<p>Ok, so I''m pretty sure now that there are no whitespaces in any
          t5 model and the formatting of the template as presented in the paper is
          being removed by the tokenizer.</p>

          '
        raw: Ok, so I'm pretty sure now that there are no whitespaces in any t5 model
          and the formatting of the template as presented in the paper is being removed
          by the tokenizer.
        updatedAt: '2022-09-02T01:07:59.176Z'
      numEdits: 0
      reactions: []
    id: 6311576f253b152eb211cfa9
    type: comment
  author: ischlag
  content: Ok, so I'm pretty sure now that there are no whitespaces in any t5 model
    and the formatting of the template as presented in the paper is being removed
    by the tokenizer.
  created_at: 2022-09-02 00:07:59+00:00
  edited: false
  hidden: false
  id: 6311576f253b152eb211cfa9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/858ce56df314107cb63920d1a511b146.svg
      fullname: Yizhong Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: yizhongw
      type: user
    createdAt: '2022-09-02T01:43:30.000Z'
    data:
      edited: false
      editors:
      - yizhongw
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/858ce56df314107cb63920d1a511b146.svg
          fullname: Yizhong Wang
          isHf: false
          isPro: false
          name: yizhongw
          type: user
        html: '<p>Re 1), yeah the vocab for 11b and 3b should be the same.<br>Re 2),
          <code>\n</code> is not in the original T5 vocab. T5 will replace them with
          a blank space during tokenization. When training the models, we didn''t
          have special processing here. I don''t have good suggestions for modifying
          the T5 vocab. But the way you did looks reasonable to me if you can retrain
          the model.</p>

          '
        raw: 'Re 1), yeah the vocab for 11b and 3b should be the same.

          Re 2), `\n` is not in the original T5 vocab. T5 will replace them with a
          blank space during tokenization. When training the models, we didn''t have
          special processing here. I don''t have good suggestions for modifying the
          T5 vocab. But the way you did looks reasonable to me if you can retrain
          the model.'
        updatedAt: '2022-09-02T01:43:30.666Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - ischlag
    id: 63115fc2fa95534e218ce2e3
    type: comment
  author: yizhongw
  content: 'Re 1), yeah the vocab for 11b and 3b should be the same.

    Re 2), `\n` is not in the original T5 vocab. T5 will replace them with a blank
    space during tokenization. When training the models, we didn''t have special processing
    here. I don''t have good suggestions for modifying the T5 vocab. But the way you
    did looks reasonable to me if you can retrain the model.'
  created_at: 2022-09-02 00:43:30+00:00
  edited: false
  hidden: false
  id: 63115fc2fa95534e218ce2e3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5bced71b6d507e621ec159ada94480f0.svg
      fullname: Imanol Schlag
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ischlag
      type: user
    createdAt: '2022-09-03T05:39:49.000Z'
    data:
      edited: false
      editors:
      - ischlag
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5bced71b6d507e621ec159ada94480f0.svg
          fullname: Imanol Schlag
          isHf: false
          isPro: false
          name: ischlag
          type: user
        html: '<p>thanks for clarifying</p>

          '
        raw: thanks for clarifying
        updatedAt: '2022-09-03T05:39:49.626Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6312e8a5f568fb0098fb15ee
    id: 6312e8a5f568fb0098fb15ed
    type: comment
  author: ischlag
  content: thanks for clarifying
  created_at: 2022-09-03 04:39:49+00:00
  edited: false
  hidden: false
  id: 6312e8a5f568fb0098fb15ed
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/5bced71b6d507e621ec159ada94480f0.svg
      fullname: Imanol Schlag
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ischlag
      type: user
    createdAt: '2022-09-03T05:39:49.000Z'
    data:
      status: closed
    id: 6312e8a5f568fb0098fb15ee
    type: status-change
  author: ischlag
  created_at: 2022-09-03 04:39:49+00:00
  id: 6312e8a5f568fb0098fb15ee
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: allenai/tk-instruct-11b-def-pos-neg-expl
repo_type: model
status: closed
target_branch: null
title: 'tokenizer newline issue and incorrect model card '
