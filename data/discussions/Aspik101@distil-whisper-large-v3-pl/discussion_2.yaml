!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sanchit-gandhi
conflicting_files: null
created_at: 2024-01-12 14:51:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2024-01-12T14:51:22.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8839949369430542
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Aspik101&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Aspik101\"\
          >@<span class=\"underline\">Aspik101</span></a></span>\n\n\t</span></span>!\
          \ Super cool to see that you distilled Whisper large-v3 on Polish! Out of\
          \ curiosity, did you use pseudo-label targets? Or the text labels from the\
          \ Common Voice dataset? I tried an experiment distilling large-v3 for German\
          \ directly on the text labels provided in the Common Voice dataset (not\
          \ pseudo-labels): <a href=\"https://huggingface.co/sanchit-gandhi/distil-whisper-large-v3-de-kd\"\
          >https://huggingface.co/sanchit-gandhi/distil-whisper-large-v3-de-kd</a></p>\n\
          <p>=&gt; this gave a model with 6.3% WER on the CV German dev set, which\
          \ was ~1.5% lower WER than using shrink and fine-tune. Therefore, this approach\
          \ forms a nice intermediate between fine-tuning and full distillation: we\
          \ use the KD objective, but the text labels from the CV dataset. It\u2019\
          s quite quick to get working, since we can skip the lengthy pseudo-labelling\
          \ step, but quite clearly outperforms a simple shrink and fine-tune, so\
          \ forms a nice baseline on the way to full distillation (using pseudo-labels).</p>\n\
          <p>I left some detailed instructions for reproducing the run here: <a href=\"\
          https://huggingface.co/sanchit-gandhi/distil-whisper-large-v3-de-kd#training-procedure\"\
          >https://huggingface.co/sanchit-gandhi/distil-whisper-large-v3-de-kd#training-procedure</a><br>You\
          \ can simply swap the language (\"de\") for your language of choice</p>\n\
          <p>Of course, if you've done full KD and trained on the pseudo-label targets,\
          \ you'll probably have achieved similar (if not better) performance to using\
          \ the text label targets with KD! Interested in hearing what objective you\
          \ used, and also what datasets you trained on!</p>\n<p>If you're interested\
          \ in discussing more about training tips, definitely join our Whisper Distillation\
          \ Slack channels. Details can be found in this LinkedIn post:<br><a rel=\"\
          nofollow\" href=\"https://www.linkedin.com/posts/sanchit-gandhi_distil-whisper-training-code-now-available-activity-7131004471806980096-FYmQ?utm_source=share&amp;utm_medium=member_desktop\"\
          >https://www.linkedin.com/posts/sanchit-gandhi_distil-whisper-training-code-now-available-activity-7131004471806980096-FYmQ?utm_source=share&amp;utm_medium=member_desktop</a></p>\n"
        raw: "Hey @Aspik101! Super cool to see that you distilled Whisper large-v3\
          \ on Polish! Out of curiosity, did you use pseudo-label targets? Or the\
          \ text labels from the Common Voice dataset? I tried an experiment distilling\
          \ large-v3 for German directly on the text labels provided in the Common\
          \ Voice dataset (not pseudo-labels): https://huggingface.co/sanchit-gandhi/distil-whisper-large-v3-de-kd\r\
          \n\r\n=> this gave a model with 6.3% WER on the CV German dev set, which\
          \ was ~1.5% lower WER than using shrink and fine-tune. Therefore, this approach\
          \ forms a nice intermediate between fine-tuning and full distillation: we\
          \ use the KD objective, but the text labels from the CV dataset. It\u2019\
          s quite quick to get working, since we can skip the lengthy pseudo-labelling\
          \ step, but quite clearly outperforms a simple shrink and fine-tune, so\
          \ forms a nice baseline on the way to full distillation (using pseudo-labels).\r\
          \n\r\nI left some detailed instructions for reproducing the run here: https://huggingface.co/sanchit-gandhi/distil-whisper-large-v3-de-kd#training-procedure\r\
          \nYou can simply swap the language (\"de\") for your language of choice\r\
          \n\r\nOf course, if you've done full KD and trained on the pseudo-label\
          \ targets, you'll probably have achieved similar (if not better) performance\
          \ to using the text label targets with KD! Interested in hearing what objective\
          \ you used, and also what datasets you trained on!\r\n\r\nIf you're interested\
          \ in discussing more about training tips, definitely join our Whisper Distillation\
          \ Slack channels. Details can be found in this LinkedIn post:\r\nhttps://www.linkedin.com/posts/sanchit-gandhi_distil-whisper-training-code-now-available-activity-7131004471806980096-FYmQ?utm_source=share&utm_medium=member_desktop"
        updatedAt: '2024-01-12T14:51:22.634Z'
      numEdits: 0
      reactions: []
    id: 65a151eadacb2a978c32824d
    type: comment
  author: sanchit-gandhi
  content: "Hey @Aspik101! Super cool to see that you distilled Whisper large-v3 on\
    \ Polish! Out of curiosity, did you use pseudo-label targets? Or the text labels\
    \ from the Common Voice dataset? I tried an experiment distilling large-v3 for\
    \ German directly on the text labels provided in the Common Voice dataset (not\
    \ pseudo-labels): https://huggingface.co/sanchit-gandhi/distil-whisper-large-v3-de-kd\r\
    \n\r\n=> this gave a model with 6.3% WER on the CV German dev set, which was ~1.5%\
    \ lower WER than using shrink and fine-tune. Therefore, this approach forms a\
    \ nice intermediate between fine-tuning and full distillation: we use the KD objective,\
    \ but the text labels from the CV dataset. It\u2019s quite quick to get working,\
    \ since we can skip the lengthy pseudo-labelling step, but quite clearly outperforms\
    \ a simple shrink and fine-tune, so forms a nice baseline on the way to full distillation\
    \ (using pseudo-labels).\r\n\r\nI left some detailed instructions for reproducing\
    \ the run here: https://huggingface.co/sanchit-gandhi/distil-whisper-large-v3-de-kd#training-procedure\r\
    \nYou can simply swap the language (\"de\") for your language of choice\r\n\r\n\
    Of course, if you've done full KD and trained on the pseudo-label targets, you'll\
    \ probably have achieved similar (if not better) performance to using the text\
    \ label targets with KD! Interested in hearing what objective you used, and also\
    \ what datasets you trained on!\r\n\r\nIf you're interested in discussing more\
    \ about training tips, definitely join our Whisper Distillation Slack channels.\
    \ Details can be found in this LinkedIn post:\r\nhttps://www.linkedin.com/posts/sanchit-gandhi_distil-whisper-training-code-now-available-activity-7131004471806980096-FYmQ?utm_source=share&utm_medium=member_desktop"
  created_at: 2024-01-12 14:51:22+00:00
  edited: false
  hidden: false
  id: 65a151eadacb2a978c32824d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/28865acb5c579c1daf6ad14f4ee3b8a8.svg
      fullname: Pik
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Aspik101
      type: user
    createdAt: '2024-01-12T15:19:31.000Z'
    data:
      edited: false
      editors:
      - Aspik101
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.943627119064331
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/28865acb5c579c1daf6ad14f4ee3b8a8.svg
          fullname: Pik
          isHf: false
          isPro: false
          name: Aspik101
          type: user
        html: '<p>Hi sanchit.<br>I used pseudo-label targets. The model was trained
          on the Common Voice 13, FLEURS, and VoxPopuli dataset. I mention it in the
          post <a rel="nofollow" href="https://www.linkedin.com/feed/update/urn:li:activity:7135694818164289536">https://www.linkedin.com/feed/update/urn:li:activity:7135694818164289536</a>.<br>However,
          I will also check your approach ;)</p>

          <p>While we''re talking, did you manage to get the timestamp for the calls
          as well? I can''t do this in my model...</p>

          '
        raw: 'Hi sanchit.

          I used pseudo-label targets. The model was trained on the Common Voice 13,
          FLEURS, and VoxPopuli dataset. I mention it in the post https://www.linkedin.com/feed/update/urn:li:activity:7135694818164289536.

          However, I will also check your approach ;)



          While we''re talking, did you manage to get the timestamp for the calls
          as well? I can''t do this in my model...'
        updatedAt: '2024-01-12T15:19:31.681Z'
      numEdits: 0
      reactions: []
    id: 65a15883c5bc4056687d4d05
    type: comment
  author: Aspik101
  content: 'Hi sanchit.

    I used pseudo-label targets. The model was trained on the Common Voice 13, FLEURS,
    and VoxPopuli dataset. I mention it in the post https://www.linkedin.com/feed/update/urn:li:activity:7135694818164289536.

    However, I will also check your approach ;)



    While we''re talking, did you manage to get the timestamp for the calls as well?
    I can''t do this in my model...'
  created_at: 2024-01-12 15:19:31+00:00
  edited: false
  hidden: false
  id: 65a15883c5bc4056687d4d05
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2024-01-12T16:05:16.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5677677392959595
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Very cool! Thanks for sharing details <span data-props=\"{&quot;user&quot;:&quot;Aspik101&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Aspik101\"\
          >@<span class=\"underline\">Aspik101</span></a></span>\n\n\t</span></span>!</p>\n\
          <p>For timestamps, we need to ensure three things:</p>\n<ol>\n<li>Pseudo-label\
          \ the transcription with timestamps: set <code>--return_timestamps=True</code>\
          \ in the pseudo-labelling step here: <a rel=\"nofollow\" href=\"https://github.com/huggingface/distil-whisper/tree/main/training#1-pseudo-labelling\"\
          >https://github.com/huggingface/distil-whisper/tree/main/training#1-pseudo-labelling</a></li>\n\
          <li>Train on the transcriptions with timestamps:  set <code>--timestamp_probability=0.5</code>\
          \ in the training set here: <a rel=\"nofollow\" href=\"https://github.com/huggingface/distil-whisper/tree/main/training#3-training\"\
          >https://github.com/huggingface/distil-whisper/tree/main/training#3-training</a>\
          \ (note that it defaults to 0.2, which should be sufficient for training\
          \ the model on the timestamp task)</li>\n<li>Inference with timestamps enabled:\
          \ see how we set <code>return_timestamps=True</code> in the call to the\
          \ pipeline</li>\n</ol>\n<pre><code class=\"language-python\"><span class=\"\
          hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\">from</span>\
          \ transformers <span class=\"hljs-keyword\">import</span> AutoModelForSpeechSeq2Seq,\
          \ AutoProcessor, pipeline\n<span class=\"hljs-keyword\">from</span> datasets\
          \ <span class=\"hljs-keyword\">import</span> load_dataset\n\n\ndevice =\
          \ <span class=\"hljs-string\">\"cuda:0\"</span> <span class=\"hljs-keyword\"\
          >if</span> torch.cuda.is_available() <span class=\"hljs-keyword\">else</span>\
          \ <span class=\"hljs-string\">\"cpu\"</span>\ntorch_dtype = torch.float16\
          \ <span class=\"hljs-keyword\">if</span> torch.cuda.is_available() <span\
          \ class=\"hljs-keyword\">else</span> torch.float32\n\nmodel_id = <span class=\"\
          hljs-string\">\"Aspik101/distil-whisper-large-v3-pl\"</span>\n\nmodel =\
          \ AutoModelForSpeechSeq2Seq.from_pretrained(\n    model_id, torch_dtype=torch_dtype,\
          \ low_cpu_mem_usage=<span class=\"hljs-literal\">True</span>, use_safetensors=<span\
          \ class=\"hljs-literal\">True</span>\n)\nmodel.to(device)\n\nprocessor =\
          \ AutoProcessor.from_pretrained(model_id)\n\npipe = pipeline(\n    <span\
          \ class=\"hljs-string\">\"automatic-speech-recognition\"</span>,\n    model=model,\n\
          \    tokenizer=processor.tokenizer,\n    feature_extractor=processor.feature_extractor,\n\
          \    max_new_tokens=<span class=\"hljs-number\">128</span>,\n    torch_dtype=torch_dtype,\n\
          \    device=device,\n)\n\ndataset = load_dataset(<span class=\"hljs-string\"\
          >\"mozilla-foundation/common_voice_16_0\"</span>, <span class=\"hljs-string\"\
          >\"pl\"</span>, split=<span class=\"hljs-string\">\"validation\"</span>,\
          \ streaming=<span class=\"hljs-literal\">True</span>)\nsample = <span class=\"\
          hljs-built_in\">next</span>(<span class=\"hljs-built_in\">iter</span>(dataset))[<span\
          \ class=\"hljs-string\">\"audio\"</span>]\n\nresult = pipe(sample, return_timestamps=<span\
          \ class=\"hljs-literal\">True</span>)\n<span class=\"hljs-built_in\">print</span>(result[<span\
          \ class=\"hljs-string\">\"chunks\"</span>])\n</code></pre>\n<p><strong>Print\
          \ Output:</strong></p>\n<pre><code>[{'timestamp': (0.0, 3.98), 'text': '\
          \ odpowiedzia\u0142 zwak i wzruszy\u0142 ramionami.'}]\n</code></pre>\n\
          <p>=&gt; looks like you followed the pseudo-labelling and training steps\
          \ as required! You could try increasing the timestamp probability to give\
          \ more training examples with timestamps</p>\n"
        raw: "Very cool! Thanks for sharing details @Aspik101!\n\nFor timestamps,\
          \ we need to ensure three things:\n1. Pseudo-label the transcription with\
          \ timestamps: set `--return_timestamps=True` in the pseudo-labelling step\
          \ here: https://github.com/huggingface/distil-whisper/tree/main/training#1-pseudo-labelling\n\
          2. Train on the transcriptions with timestamps:  set `--timestamp_probability=0.5`\
          \ in the training set here: https://github.com/huggingface/distil-whisper/tree/main/training#3-training\
          \ (note that it defaults to 0.2, which should be sufficient for training\
          \ the model on the timestamp task)\n3. Inference with timestamps enabled:\
          \ see how we set `return_timestamps=True` in the call to the pipeline\n\
          ```python\nimport torch\nfrom transformers import AutoModelForSpeechSeq2Seq,\
          \ AutoProcessor, pipeline\nfrom datasets import load_dataset\n\n\ndevice\
          \ = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ntorch_dtype =\
          \ torch.float16 if torch.cuda.is_available() else torch.float32\n\nmodel_id\
          \ = \"Aspik101/distil-whisper-large-v3-pl\"\n\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\n\
          \    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n\
          )\nmodel.to(device)\n\nprocessor = AutoProcessor.from_pretrained(model_id)\n\
          \npipe = pipeline(\n    \"automatic-speech-recognition\",\n    model=model,\n\
          \    tokenizer=processor.tokenizer,\n    feature_extractor=processor.feature_extractor,\n\
          \    max_new_tokens=128,\n    torch_dtype=torch_dtype,\n    device=device,\n\
          )\n\ndataset = load_dataset(\"mozilla-foundation/common_voice_16_0\", \"\
          pl\", split=\"validation\", streaming=True)\nsample = next(iter(dataset))[\"\
          audio\"]\n\nresult = pipe(sample, return_timestamps=True)\nprint(result[\"\
          chunks\"])\n```\n**Print Output:**\n```\n[{'timestamp': (0.0, 3.98), 'text':\
          \ ' odpowiedzia\u0142 zwak i wzruszy\u0142 ramionami.'}]\n```\n=> looks\
          \ like you followed the pseudo-labelling and training steps as required!\
          \ You could try increasing the timestamp probability to give more training\
          \ examples with timestamps"
        updatedAt: '2024-01-12T16:05:51.255Z'
      numEdits: 1
      reactions: []
    id: 65a1633cdc138bd115345bb8
    type: comment
  author: sanchit-gandhi
  content: "Very cool! Thanks for sharing details @Aspik101!\n\nFor timestamps, we\
    \ need to ensure three things:\n1. Pseudo-label the transcription with timestamps:\
    \ set `--return_timestamps=True` in the pseudo-labelling step here: https://github.com/huggingface/distil-whisper/tree/main/training#1-pseudo-labelling\n\
    2. Train on the transcriptions with timestamps:  set `--timestamp_probability=0.5`\
    \ in the training set here: https://github.com/huggingface/distil-whisper/tree/main/training#3-training\
    \ (note that it defaults to 0.2, which should be sufficient for training the model\
    \ on the timestamp task)\n3. Inference with timestamps enabled: see how we set\
    \ `return_timestamps=True` in the call to the pipeline\n```python\nimport torch\n\
    from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n\
    from datasets import load_dataset\n\n\ndevice = \"cuda:0\" if torch.cuda.is_available()\
    \ else \"cpu\"\ntorch_dtype = torch.float16 if torch.cuda.is_available() else\
    \ torch.float32\n\nmodel_id = \"Aspik101/distil-whisper-large-v3-pl\"\n\nmodel\
    \ = AutoModelForSpeechSeq2Seq.from_pretrained(\n    model_id, torch_dtype=torch_dtype,\
    \ low_cpu_mem_usage=True, use_safetensors=True\n)\nmodel.to(device)\n\nprocessor\
    \ = AutoProcessor.from_pretrained(model_id)\n\npipe = pipeline(\n    \"automatic-speech-recognition\"\
    ,\n    model=model,\n    tokenizer=processor.tokenizer,\n    feature_extractor=processor.feature_extractor,\n\
    \    max_new_tokens=128,\n    torch_dtype=torch_dtype,\n    device=device,\n)\n\
    \ndataset = load_dataset(\"mozilla-foundation/common_voice_16_0\", \"pl\", split=\"\
    validation\", streaming=True)\nsample = next(iter(dataset))[\"audio\"]\n\nresult\
    \ = pipe(sample, return_timestamps=True)\nprint(result[\"chunks\"])\n```\n**Print\
    \ Output:**\n```\n[{'timestamp': (0.0, 3.98), 'text': ' odpowiedzia\u0142 zwak\
    \ i wzruszy\u0142 ramionami.'}]\n```\n=> looks like you followed the pseudo-labelling\
    \ and training steps as required! You could try increasing the timestamp probability\
    \ to give more training examples with timestamps"
  created_at: 2024-01-12 16:05:16+00:00
  edited: true
  hidden: false
  id: 65a1633cdc138bd115345bb8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/28865acb5c579c1daf6ad14f4ee3b8a8.svg
      fullname: Pik
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Aspik101
      type: user
    createdAt: '2024-01-13T10:37:47.000Z'
    data:
      edited: false
      editors:
      - Aspik101
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7921085953712463
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/28865acb5c579c1daf6ad14f4ee3b8a8.svg
          fullname: Pik
          isHf: false
          isPro: false
          name: Aspik101
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ Thanks a lot! </p>\n"
        raw: '@sanchit-gandhi Thanks a lot! '
        updatedAt: '2024-01-13T10:37:47.140Z'
      numEdits: 0
      reactions: []
    id: 65a267fb3581a68c4101b188
    type: comment
  author: Aspik101
  content: '@sanchit-gandhi Thanks a lot! '
  created_at: 2024-01-13 10:37:47+00:00
  edited: false
  hidden: false
  id: 65a267fb3581a68c4101b188
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Aspik101/distil-whisper-large-v3-pl
repo_type: model
status: open
target_branch: null
title: Model Discussion
