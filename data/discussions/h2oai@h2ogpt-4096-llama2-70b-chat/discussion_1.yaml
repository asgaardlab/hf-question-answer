!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MQXR
conflicting_files: null
created_at: 2023-08-30 08:49:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b3d501a80dbbc9bb0267ece4a36241fd.svg
      fullname: Mohammed alqaisi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MQXR
      type: user
    createdAt: '2023-08-30T09:49:59.000Z'
    data:
      edited: false
      editors:
      - MQXR
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7901567220687866
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b3d501a80dbbc9bb0267ece4a36241fd.svg
          fullname: Mohammed alqaisi
          isHf: false
          isPro: false
          name: MQXR
          type: user
        html: '<p>Hey, I hope you are doing well,<br>I have installed the folder using
          these commands (git lfs install, git clone <a href="https://huggingface.co/h2oai/h2ogpt-4096-llama2-70b-chat">https://huggingface.co/h2oai/h2ogpt-4096-llama2-70b-chat</a>)
          and I have the folder installed successfully my question is how can I start
          using the model, I have used previously this command (python generate.py
          --base_model=''h2ogpt-4096-llama2-70b-chat''  --score_model=None --langchain_mode=''UserData''
          --user_path=user_path) to start another model can I do the same here?</p>

          '
        raw: "Hey, I hope you are doing well,\r\nI have installed the folder using\
          \ these commands (git lfs install, git clone https://huggingface.co/h2oai/h2ogpt-4096-llama2-70b-chat)\
          \ and I have the folder installed successfully my question is how can I\
          \ start using the model, I have used previously this command (python generate.py\
          \ --base_model='h2ogpt-4096-llama2-70b-chat'  --score_model=None --langchain_mode='UserData'\
          \ --user_path=user_path) to start another model can I do the same here?"
        updatedAt: '2023-08-30T09:49:59.268Z'
      numEdits: 0
      reactions: []
    id: 64ef10c77d6345d8902e7beb
    type: comment
  author: MQXR
  content: "Hey, I hope you are doing well,\r\nI have installed the folder using these\
    \ commands (git lfs install, git clone https://huggingface.co/h2oai/h2ogpt-4096-llama2-70b-chat)\
    \ and I have the folder installed successfully my question is how can I start\
    \ using the model, I have used previously this command (python generate.py --base_model='h2ogpt-4096-llama2-70b-chat'\
    \  --score_model=None --langchain_mode='UserData' --user_path=user_path) to start\
    \ another model can I do the same here?"
  created_at: 2023-08-30 08:49:59+00:00
  edited: false
  hidden: false
  id: 64ef10c77d6345d8902e7beb
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: h2oai/h2ogpt-4096-llama2-70b-chat
repo_type: model
status: open
target_branch: null
title: Starting up the model
