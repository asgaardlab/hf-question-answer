!!python/object:huggingface_hub.community.DiscussionWithDetails
author: atarashansky
conflicting_files: null
created_at: 2022-08-16 19:54:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a872e4d2f01216debf40daa446e90ab9.svg
      fullname: Alexander Tarashansky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: atarashansky
      type: user
    createdAt: '2022-08-16T20:54:08.000Z'
    data:
      edited: false
      editors:
      - atarashansky
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a872e4d2f01216debf40daa446e90ab9.svg
          fullname: Alexander Tarashansky
          isHf: false
          isPro: false
          name: atarashansky
          type: user
        html: '<p>Anyone have a solid understanding of what the different parameters
          are doing? I have an intuitive understanding of <code>scale</code> in theory
          but I haven''t been able to fully rationalize its effects on the resulting
          image. The best I can say is that turning the guidance up will sacrifice
          details in favor of highlighting coarser features. Turning the guidance
          down will include more details but it starts getting chaotic.</p>

          <p>What about the number of inference steps? Is this something that asymptotes
          (i.e. above a certain point there''s no difference between 100 vs 500 vs
          5000, etc)?</p>

          <p>Also, I noticed something strange - I compared #steps=50 vs #steps=51
          - the first iteration will produce nearly-identical samples. The following
          iterations are randomized. Why is that?</p>

          <p>Any other parameters that are worth tuning?</p>

          '
        raw: "Anyone have a solid understanding of what the different parameters are\
          \ doing? I have an intuitive understanding of `scale` in theory but I haven't\
          \ been able to fully rationalize its effects on the resulting image. The\
          \ best I can say is that turning the guidance up will sacrifice details\
          \ in favor of highlighting coarser features. Turning the guidance down will\
          \ include more details but it starts getting chaotic.\r\n\r\nWhat about\
          \ the number of inference steps? Is this something that asymptotes (i.e.\
          \ above a certain point there's no difference between 100 vs 500 vs 5000,\
          \ etc)?\r\n\r\nAlso, I noticed something strange - I compared #steps=50\
          \ vs #steps=51 - the first iteration will produce nearly-identical samples.\
          \ The following iterations are randomized. Why is that?\r\n\r\nAny other\
          \ parameters that are worth tuning?\r\n"
        updatedAt: '2022-08-16T20:54:08.488Z'
      numEdits: 0
      reactions: []
    id: 62fc03f0610dae1bcd0771a6
    type: comment
  author: atarashansky
  content: "Anyone have a solid understanding of what the different parameters are\
    \ doing? I have an intuitive understanding of `scale` in theory but I haven't\
    \ been able to fully rationalize its effects on the resulting image. The best\
    \ I can say is that turning the guidance up will sacrifice details in favor of\
    \ highlighting coarser features. Turning the guidance down will include more details\
    \ but it starts getting chaotic.\r\n\r\nWhat about the number of inference steps?\
    \ Is this something that asymptotes (i.e. above a certain point there's no difference\
    \ between 100 vs 500 vs 5000, etc)?\r\n\r\nAlso, I noticed something strange -\
    \ I compared #steps=50 vs #steps=51 - the first iteration will produce nearly-identical\
    \ samples. The following iterations are randomized. Why is that?\r\n\r\nAny other\
    \ parameters that are worth tuning?\r\n"
  created_at: 2022-08-16 19:54:08+00:00
  edited: false
  hidden: false
  id: 62fc03f0610dae1bcd0771a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6c8bcf891a337169a3a439f4065df751.svg
      fullname: Greg Turk
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gturk1
      type: user
    createdAt: '2022-08-16T21:32:55.000Z'
    data:
      edited: false
      editors:
      - gturk1
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6c8bcf891a337169a3a439f4065df751.svg
          fullname: Greg Turk
          isHf: false
          isPro: false
          name: gturk1
          type: user
        html: '<p>The best way to explore the parameters is to stick with one prompt
          and one random number seed, and vary the one parameter that you want to
          understand better.  Then you can directly see how changing the parameter
          affects that specific image.</p>

          <p>Here is a parameter sweep for one prompt and seed:</p>

          <p><a rel="nofollow" href="https://docs.google.com/spreadsheets/d/1SYQhyJaKkkY0cmPd0WQvPwEX188l5FZxzukkC7IQDw4/edit#gid=0">https://docs.google.com/spreadsheets/d/1SYQhyJaKkkY0cmPd0WQvPwEX188l5FZxzukkC7IQDw4/edit#gid=0</a><br>s
          = steps<br>cfg = scale (I think)</p>

          <p>My vague understanding is that scale dictates how closely the image generation
          is controlled by the text prompt.  I have not played with it at all.</p>

          <p>Steps refers to how many "un-diffusion'' steps are taken towards something
          that matches the prompt.  The biggest effect of steps will be in the very
          first few (1, 2, 3, 4, 5).  Then the image usually "settles" into roughly
          the way it will look somewhere between 10 and 20 steps.  In many cases there
          is a point of diminishing returns in the number of steps that are taken.
          But every once in a while you can see visible changes with higher step values.
          I don''t think this is anything that can be predicted ahead of time for
          a given prompt.</p>

          <p>There is also a parameter called eta that I have not tried out.  I would
          be interested in learning what effect it has on the results.</p>

          '
        raw: 'The best way to explore the parameters is to stick with one prompt and
          one random number seed, and vary the one parameter that you want to understand
          better.  Then you can directly see how changing the parameter affects that
          specific image.


          Here is a parameter sweep for one prompt and seed:


          https://docs.google.com/spreadsheets/d/1SYQhyJaKkkY0cmPd0WQvPwEX188l5FZxzukkC7IQDw4/edit#gid=0

          s = steps

          cfg = scale (I think)


          My vague understanding is that scale dictates how closely the image generation
          is controlled by the text prompt.  I have not played with it at all.


          Steps refers to how many "un-diffusion'' steps are taken towards something
          that matches the prompt.  The biggest effect of steps will be in the very
          first few (1, 2, 3, 4, 5).  Then the image usually "settles" into roughly
          the way it will look somewhere between 10 and 20 steps.  In many cases there
          is a point of diminishing returns in the number of steps that are taken.
          But every once in a while you can see visible changes with higher step values.
          I don''t think this is anything that can be predicted ahead of time for
          a given prompt.


          There is also a parameter called eta that I have not tried out.  I would
          be interested in learning what effect it has on the results.'
        updatedAt: '2022-08-16T21:32:55.543Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - terekita
        - diegogd
    id: 62fc0d07a80632fbd47cfc82
    type: comment
  author: gturk1
  content: 'The best way to explore the parameters is to stick with one prompt and
    one random number seed, and vary the one parameter that you want to understand
    better.  Then you can directly see how changing the parameter affects that specific
    image.


    Here is a parameter sweep for one prompt and seed:


    https://docs.google.com/spreadsheets/d/1SYQhyJaKkkY0cmPd0WQvPwEX188l5FZxzukkC7IQDw4/edit#gid=0

    s = steps

    cfg = scale (I think)


    My vague understanding is that scale dictates how closely the image generation
    is controlled by the text prompt.  I have not played with it at all.


    Steps refers to how many "un-diffusion'' steps are taken towards something that
    matches the prompt.  The biggest effect of steps will be in the very first few
    (1, 2, 3, 4, 5).  Then the image usually "settles" into roughly the way it will
    look somewhere between 10 and 20 steps.  In many cases there is a point of diminishing
    returns in the number of steps that are taken. But every once in a while you can
    see visible changes with higher step values. I don''t think this is anything that
    can be predicted ahead of time for a given prompt.


    There is also a parameter called eta that I have not tried out.  I would be interested
    in learning what effect it has on the results.'
  created_at: 2022-08-16 20:32:55+00:00
  edited: false
  hidden: false
  id: 62fc0d07a80632fbd47cfc82
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a872e4d2f01216debf40daa446e90ab9.svg
      fullname: Alexander Tarashansky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: atarashansky
      type: user
    createdAt: '2022-08-16T22:41:20.000Z'
    data:
      edited: false
      editors:
      - atarashansky
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a872e4d2f01216debf40daa446e90ab9.svg
          fullname: Alexander Tarashansky
          isHf: false
          isPro: false
          name: atarashansky
          type: user
        html: '<p>Thanks for the google doc. It''s really interesting - at high scale,
          there seems to be a sharp phase transition at higher step counts where the
          image suddenly gains clarity.</p>

          '
        raw: Thanks for the google doc. It's really interesting - at high scale, there
          seems to be a sharp phase transition at higher step counts where the image
          suddenly gains clarity.
        updatedAt: '2022-08-16T22:41:20.314Z'
      numEdits: 0
      reactions: []
    id: 62fc1d10610dae1bcd0836d6
    type: comment
  author: atarashansky
  content: Thanks for the google doc. It's really interesting - at high scale, there
    seems to be a sharp phase transition at higher step counts where the image suddenly
    gains clarity.
  created_at: 2022-08-16 21:41:20+00:00
  edited: false
  hidden: false
  id: 62fc1d10610dae1bcd0836d6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0178588332440964401be37f4be8fb2e.svg
      fullname: Masaki Yokoyama
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TeuMasaki
      type: user
    createdAt: '2022-08-18T14:34:39.000Z'
    data:
      edited: true
      editors:
      - TeuMasaki
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0178588332440964401be37f4be8fb2e.svg
          fullname: Masaki Yokoyama
          isHf: false
          isPro: false
          name: TeuMasaki
          type: user
        html: '<p>This site may also interest you: </p>

          <p><a rel="nofollow" href="https://botbox.dev/stable-diffusion-settings-guide/">https://botbox.dev/stable-diffusion-settings-guide/</a><br>Above
          site is about Discord beta test though, thus comparison about different
          sampler is partialy irrelevant.  Since only DDIM (without --plms param)
          and PLMS (with --plms param) are avalable within this repo''s model.</p>

          <blockquote>

          <p> It''s really interesting - at high scale, there seems to be a sharp
          phase transition at higher step counts where the image suddenly gains clarity.</p>

          </blockquote>

          <p>I can confirm this effect as well.  If guidance scale is high enough
          ( --scale 15 ~ 20), difference between 100 steps and 150 steps starts to
          matter.</p>

          '
        raw: "This site may also interest you: \n\nhttps://botbox.dev/stable-diffusion-settings-guide/\n\
          Above site is about Discord beta test though, thus comparison about different\
          \ sampler is partialy irrelevant.  Since only DDIM (without --plms param)\
          \ and PLMS (with --plms param) are avalable within this repo's model.\n\n\
          >  It's really interesting - at high scale, there seems to be a sharp phase\
          \ transition at higher step counts where the image suddenly gains clarity.\n\
          \nI can confirm this effect as well.  If guidance scale is high enough (\
          \ --scale 15 ~ 20), difference between 100 steps and 150 steps starts to\
          \ matter."
        updatedAt: '2022-08-18T14:35:07.626Z'
      numEdits: 1
      reactions: []
    id: 62fe4dffe9061c0170d12959
    type: comment
  author: TeuMasaki
  content: "This site may also interest you: \n\nhttps://botbox.dev/stable-diffusion-settings-guide/\n\
    Above site is about Discord beta test though, thus comparison about different\
    \ sampler is partialy irrelevant.  Since only DDIM (without --plms param) and\
    \ PLMS (with --plms param) are avalable within this repo's model.\n\n>  It's really\
    \ interesting - at high scale, there seems to be a sharp phase transition at higher\
    \ step counts where the image suddenly gains clarity.\n\nI can confirm this effect\
    \ as well.  If guidance scale is high enough ( --scale 15 ~ 20), difference between\
    \ 100 steps and 150 steps starts to matter."
  created_at: 2022-08-18 13:34:39+00:00
  edited: true
  hidden: false
  id: 62fe4dffe9061c0170d12959
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: CompVis/stable-diffusion-v-1-3-original
repo_type: model
status: open
target_branch: null
title: A guide to tuning parameters
