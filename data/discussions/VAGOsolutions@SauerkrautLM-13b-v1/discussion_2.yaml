!!python/object:huggingface_hub.community.DiscussionWithDetails
author: xpgx1
conflicting_files: null
created_at: 2023-10-13 19:04:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6357e2e3a680a9d532c84146/gcW4PlIVy8jBBBb8aeh3K.png?w=200&h=200&f=face
      fullname: Santa Clause
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xpgx1
      type: user
    createdAt: '2023-10-13T20:04:48.000Z'
    data:
      edited: true
      editors:
      - xpgx1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6561099886894226
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6357e2e3a680a9d532c84146/gcW4PlIVy8jBBBb8aeh3K.png?w=200&h=200&f=face
          fullname: Santa Clause
          isHf: false
          isPro: false
          name: xpgx1
          type: user
        html: '<p>Seems like another rather valuable german finetuned model - but
          do you plan on providing quantized versions of it as well?</p>

          <p>Danke sehr und auf Wiedersehen,<br>A fellow LLM enthusiast</p>

          <p>Edit: Entirely overlooked the planned GPTQ ones =)</p>

          '
        raw: 'Seems like another rather valuable german finetuned model - but do you
          plan on providing quantized versions of it as well?


          Danke sehr und auf Wiedersehen,

          A fellow LLM enthusiast


          Edit: Entirely overlooked the planned GPTQ ones =)'
        updatedAt: '2023-10-13T20:30:44.151Z'
      numEdits: 1
      reactions: []
    id: 6529a2e060e706730574a06c
    type: comment
  author: xpgx1
  content: 'Seems like another rather valuable german finetuned model - but do you
    plan on providing quantized versions of it as well?


    Danke sehr und auf Wiedersehen,

    A fellow LLM enthusiast


    Edit: Entirely overlooked the planned GPTQ ones =)'
  created_at: 2023-10-13 19:04:48+00:00
  edited: true
  hidden: false
  id: 6529a2e060e706730574a06c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6357e2e3a680a9d532c84146/gcW4PlIVy8jBBBb8aeh3K.png?w=200&h=200&f=face
      fullname: Santa Clause
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xpgx1
      type: user
    createdAt: '2023-10-13T20:30:10.000Z'
    data:
      status: closed
    id: 6529a8d2f6390fe048b8847d
    type: status-change
  author: xpgx1
  created_at: 2023-10-13 19:30:10+00:00
  id: 6529a8d2f6390fe048b8847d
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/65189dea66e78720a750f9a9/D-oSwjCcfQOzZG2w_SvEM.png?w=200&h=200&f=face
      fullname: Daryoush Vaziri
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: DaryoushV
      type: user
    createdAt: '2023-10-13T20:33:31.000Z'
    data:
      edited: false
      editors:
      - DaryoushV
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8848868608474731
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/65189dea66e78720a750f9a9/D-oSwjCcfQOzZG2w_SvEM.png?w=200&h=200&f=face
          fullname: Daryoush Vaziri
          isHf: false
          isPro: false
          name: DaryoushV
          type: user
        html: '<p>Yes definitely. On reddit you already find GGUF Versions a community
          member provided (<a rel="nofollow" href="https://www.reddit.com/r/LocalLLaMA/comments/176xaew/introducing_sauerkrautlmv1_our_german_language/">https://www.reddit.com/r/LocalLLaMA/comments/176xaew/introducing_sauerkrautlmv1_our_german_language/</a>)
          . Their performance seems to be lower though, according to a comment of
          a reddit user. We couldn''t test it thoroughly by now, so no reliable data
          for GGUF yet. We will provide GPTQ Versions soon as well and add them to
          hugging face of course.</p>

          <p>Best regards und auf Wiedersehen ;-)</p>

          '
        raw: 'Yes definitely. On reddit you already find GGUF Versions a community
          member provided (https://www.reddit.com/r/LocalLLaMA/comments/176xaew/introducing_sauerkrautlmv1_our_german_language/)
          . Their performance seems to be lower though, according to a comment of
          a reddit user. We couldn''t test it thoroughly by now, so no reliable data
          for GGUF yet. We will provide GPTQ Versions soon as well and add them to
          hugging face of course.


          Best regards und auf Wiedersehen ;-)

          '
        updatedAt: '2023-10-13T20:33:31.002Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - xpgx1
    id: 6529a99b95f4676fe1e0e5fd
    type: comment
  author: DaryoushV
  content: 'Yes definitely. On reddit you already find GGUF Versions a community member
    provided (https://www.reddit.com/r/LocalLLaMA/comments/176xaew/introducing_sauerkrautlmv1_our_german_language/)
    . Their performance seems to be lower though, according to a comment of a reddit
    user. We couldn''t test it thoroughly by now, so no reliable data for GGUF yet.
    We will provide GPTQ Versions soon as well and add them to hugging face of course.


    Best regards und auf Wiedersehen ;-)

    '
  created_at: 2023-10-13 19:33:31+00:00
  edited: false
  hidden: false
  id: 6529a99b95f4676fe1e0e5fd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: VAGOsolutions/SauerkrautLM-13b-v1
repo_type: model
status: closed
target_branch: null
title: AWQ and GPTQ (quantized) permutations? =)
