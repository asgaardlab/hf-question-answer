!!python/object:huggingface_hub.community.DiscussionWithDetails
author: spanielrassler
conflicting_files: null
created_at: 2023-05-31 00:21:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0d146e4b922a325b69d3d509965ed60.svg
      fullname: Frankie G
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: spanielrassler
      type: user
    createdAt: '2023-05-31T01:21:59.000Z'
    data:
      edited: false
      editors:
      - spanielrassler
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0d146e4b922a325b69d3d509965ed60.svg
          fullname: Frankie G
          isHf: false
          isPro: false
          name: spanielrassler
          type: user
        html: "<p>This is a GPTQ model, correct? Or am I wrong? I although I know\
          \ they can be converted to ggml according to <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ perplexity suffers noticeably when this conversion is done.</p>\n<p>I\
          \ don't really understand the what's happening 'behind the scenes' with\
          \ these models, so sorry if this doesn't make sense :) Long story short,\
          \ I want to try this model in llama.cpp and I need a ggml model to do so.\
          \ I can do the conversion myself from .bin or .py files but that's about\
          \ it.</p>\n"
        raw: "This is a GPTQ model, correct? Or am I wrong? I although I know they\
          \ can be converted to ggml according to @TheBloke perplexity suffers noticeably\
          \ when this conversion is done.\r\n\r\nI don't really understand the what's\
          \ happening 'behind the scenes' with these models, so sorry if this doesn't\
          \ make sense :) Long story short, I want to try this model in llama.cpp\
          \ and I need a ggml model to do so. I can do the conversion myself from\
          \ .bin or .py files but that's about it."
        updatedAt: '2023-05-31T01:21:59.490Z'
      numEdits: 0
      reactions: []
    id: 6476a1373d8d1cb79190afa3
    type: comment
  author: spanielrassler
  content: "This is a GPTQ model, correct? Or am I wrong? I although I know they can\
    \ be converted to ggml according to @TheBloke perplexity suffers noticeably when\
    \ this conversion is done.\r\n\r\nI don't really understand the what's happening\
    \ 'behind the scenes' with these models, so sorry if this doesn't make sense :)\
    \ Long story short, I want to try this model in llama.cpp and I need a ggml model\
    \ to do so. I can do the conversion myself from .bin or .py files but that's about\
    \ it."
  created_at: 2023-05-31 00:21:59+00:00
  edited: false
  hidden: false
  id: 6476a1373d8d1cb79190afa3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63d625232e397d9f8e1eccac/AOZv_jnPhcj9t6thSs11d.png?w=200&h=200&f=face
      fullname: YellowRoseCx
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Monero
      type: user
    createdAt: '2023-05-31T05:55:23.000Z'
    data:
      edited: false
      editors:
      - Monero
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63d625232e397d9f8e1eccac/AOZv_jnPhcj9t6thSs11d.png?w=200&h=200&f=face
          fullname: YellowRoseCx
          isHf: false
          isPro: false
          name: Monero
          type: user
        html: '<p>here you go! :) the fp16 model<br><a href="https://huggingface.co/Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b/">https://huggingface.co/Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b/</a>
          looking forward to seeing the GGML versions!</p>

          '
        raw: 'here you go! :) the fp16 model

          https://huggingface.co/Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b/
          looking forward to seeing the GGML versions!'
        updatedAt: '2023-05-31T05:55:23.612Z'
      numEdits: 0
      reactions: []
    id: 6476e14b26ec66674c71b72b
    type: comment
  author: Monero
  content: 'here you go! :) the fp16 model

    https://huggingface.co/Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b/ looking
    forward to seeing the GGML versions!'
  created_at: 2023-05-31 04:55:23+00:00
  edited: false
  hidden: false
  id: 6476e14b26ec66674c71b72b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0d146e4b922a325b69d3d509965ed60.svg
      fullname: Frankie G
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: spanielrassler
      type: user
    createdAt: '2023-05-31T16:38:44.000Z'
    data:
      edited: false
      editors:
      - spanielrassler
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0d146e4b922a325b69d3d509965ed60.svg
          fullname: Frankie G
          isHf: false
          isPro: false
          name: spanielrassler
          type: user
        html: "<p>Thanks!! I'll do my best. I'm not <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ so not very good at this yet but at least I should be able to put  up\
          \ :)</p>\n"
        raw: Thanks!! I'll do my best. I'm not @TheBloke so not very good at this
          yet but at least I should be able to put <something> up :)
        updatedAt: '2023-05-31T16:38:44.719Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - Monero
      relatedEventId: 64777814f911e9e76c64b577
    id: 64777814f911e9e76c64b575
    type: comment
  author: spanielrassler
  content: Thanks!! I'll do my best. I'm not @TheBloke so not very good at this yet
    but at least I should be able to put <something> up :)
  created_at: 2023-05-31 15:38:44+00:00
  edited: false
  hidden: false
  id: 64777814f911e9e76c64b575
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/a0d146e4b922a325b69d3d509965ed60.svg
      fullname: Frankie G
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: spanielrassler
      type: user
    createdAt: '2023-05-31T16:38:44.000Z'
    data:
      status: closed
    id: 64777814f911e9e76c64b577
    type: status-change
  author: spanielrassler
  created_at: 2023-05-31 15:38:44+00:00
  id: 64777814f911e9e76c64b577
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Monero/WizardLM-SuperCOT-StoryTelling-30b-4bit
repo_type: model
status: closed
target_branch: null
title: Do you happen to have a non-GPTQ version of this model so I could convert to
  ggml for use with llama.cpp
