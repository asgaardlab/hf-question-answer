!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nicoleds
conflicting_files: null
created_at: 2023-06-27 08:49:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7622c1e940db9d5cfb4ae599c608d5c8.svg
      fullname: Nicole
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nicoleds
      type: user
    createdAt: '2023-06-27T09:49:49.000Z'
    data:
      edited: false
      editors:
      - nicoleds
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4130586087703705
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7622c1e940db9d5cfb4ae599c608d5c8.svg
          fullname: Nicole
          isHf: false
          isPro: false
          name: nicoleds
          type: user
        html: '<p>My code below returns (RuntimeError: probability tensor contains
          either <code>inf</code>, <code>nan</code> or element &lt; 0) :</p>

          <p>from transformers import AutoTokenizer, AutoModelForCausalLM<br>tokenizer
          = AutoTokenizer.from_pretrained("amazon/LightGPT")<br> model = AutoModelForCausalLM.from_pretrained("amazon/LightGPT")</p>

          <p>from transformers import pipeline, TextStreamer<br>from langchain.llms
          import HuggingFacePipeline<br>import torch</p>

          <p> streamer = TextStreamer(tokenizer, skip_prompt=True)<br>pipe = pipeline(<br>        "text-generation",<br>        model=model,<br>        tokenizer=tokenizer,<br>        max_length=3000,<br>        top_p=0,<br>        repetition_penalty=1.15,<br>        streamer=streamer<br>    )      </p>

          <p> llm = HuggingFacePipeline(pipeline=pipe)</p>

          <h1 id="create-the-chain-to-answer-questions">create the chain to answer
          questions</h1>

          <p>chain_type_kwargs = {"prompt": PROMPT}</p>

          <p>chain = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=retriever,
          chain_type_kwargs=chain_type_kwargs, return_source_documents=True)</p>

          '
        raw: "My code below returns (RuntimeError: probability tensor contains either\
          \ `inf`, `nan` or element < 0) :\r\n\r\nfrom transformers import AutoTokenizer,\
          \ AutoModelForCausalLM\r\ntokenizer = AutoTokenizer.from_pretrained(\"amazon/LightGPT\"\
          )    \r\n model = AutoModelForCausalLM.from_pretrained(\"amazon/LightGPT\"\
          )\r\n\r\nfrom transformers import pipeline, TextStreamer\r\nfrom langchain.llms\
          \ import HuggingFacePipeline\r\nimport torch\r\n    \r\n streamer = TextStreamer(tokenizer,\
          \ skip_prompt=True)\r\npipe = pipeline(\r\n        \"text-generation\",\r\
          \n        model=model, \r\n        tokenizer=tokenizer,        \r\n    \
          \    max_length=3000,      \r\n        top_p=0,\r\n        repetition_penalty=1.15,\r\
          \n        streamer=streamer\r\n    )      \r\n\r\n    \r\n llm = HuggingFacePipeline(pipeline=pipe)\r\
          \n   \r\n # create the chain to answer questions \r\nchain_type_kwargs =\
          \ {\"prompt\": PROMPT}\r\n   \r\nchain = RetrievalQA.from_chain_type(llm=llm,\
          \ chain_type=\"stuff\", retriever=retriever, chain_type_kwargs=chain_type_kwargs,\
          \ return_source_documents=True)"
        updatedAt: '2023-06-27T09:49:49.319Z'
      numEdits: 0
      reactions: []
    id: 649ab0bdda0713eae7277879
    type: comment
  author: nicoleds
  content: "My code below returns (RuntimeError: probability tensor contains either\
    \ `inf`, `nan` or element < 0) :\r\n\r\nfrom transformers import AutoTokenizer,\
    \ AutoModelForCausalLM\r\ntokenizer = AutoTokenizer.from_pretrained(\"amazon/LightGPT\"\
    )    \r\n model = AutoModelForCausalLM.from_pretrained(\"amazon/LightGPT\")\r\n\
    \r\nfrom transformers import pipeline, TextStreamer\r\nfrom langchain.llms import\
    \ HuggingFacePipeline\r\nimport torch\r\n    \r\n streamer = TextStreamer(tokenizer,\
    \ skip_prompt=True)\r\npipe = pipeline(\r\n        \"text-generation\",\r\n  \
    \      model=model, \r\n        tokenizer=tokenizer,        \r\n        max_length=3000,\
    \      \r\n        top_p=0,\r\n        repetition_penalty=1.15,\r\n        streamer=streamer\r\
    \n    )      \r\n\r\n    \r\n llm = HuggingFacePipeline(pipeline=pipe)\r\n   \r\
    \n # create the chain to answer questions \r\nchain_type_kwargs = {\"prompt\"\
    : PROMPT}\r\n   \r\nchain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"\
    stuff\", retriever=retriever, chain_type_kwargs=chain_type_kwargs, return_source_documents=True)"
  created_at: 2023-06-27 08:49:49+00:00
  edited: false
  hidden: false
  id: 649ab0bdda0713eae7277879
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f258ee558ab7383e0a38c2d7a653b062.svg
      fullname: Chen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: chenwuml
      type: user
    createdAt: '2023-06-29T07:44:41.000Z'
    data:
      edited: false
      editors:
      - chenwuml
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8749811053276062
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f258ee558ab7383e0a38c2d7a653b062.svg
          fullname: Chen Wu
          isHf: false
          isPro: false
          name: chenwuml
          type: user
        html: '<p>Could you please report the full Python stack trace? How long is
          the PROMPT (in terms of len(PROMPT) or token/word count)?</p>

          <p>Also, I was wondering if you replace "max_length=3000" with "max_length=2048",  will
          the same error persist? thanks</p>

          '
        raw: 'Could you please report the full Python stack trace? How long is the
          PROMPT (in terms of len(PROMPT) or token/word count)?


          Also, I was wondering if you replace "max_length=3000" with "max_length=2048",  will
          the same error persist? thanks'
        updatedAt: '2023-06-29T07:44:41.796Z'
      numEdits: 0
      reactions: []
    id: 649d36691ce85c6d3915b976
    type: comment
  author: chenwuml
  content: 'Could you please report the full Python stack trace? How long is the PROMPT
    (in terms of len(PROMPT) or token/word count)?


    Also, I was wondering if you replace "max_length=3000" with "max_length=2048",  will
    the same error persist? thanks'
  created_at: 2023-06-29 06:44:41+00:00
  edited: false
  hidden: false
  id: 649d36691ce85c6d3915b976
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: amazon/LightGPT
repo_type: model
status: open
target_branch: null
title: 'RuntimeError: probability tensor contains either `inf`, `nan` or element <
  0'
