!!python/object:huggingface_hub.community.DiscussionWithDetails
author: cyx123
conflicting_files: null
created_at: 2023-04-09 06:51:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/547e4921b05c69b6c5bf0382a2d82fba.svg
      fullname: sad asd
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cyx123
      type: user
    createdAt: '2023-04-09T07:51:01.000Z'
    data:
      edited: false
      editors:
      - cyx123
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/547e4921b05c69b6c5bf0382a2d82fba.svg
          fullname: sad asd
          isHf: false
          isPro: false
          name: cyx123
          type: user
        html: '<p>Do anyone here own 3060 12g? Can please share some experience about
          how long does it take to reply a message, need layer to CPU or something
          even more.</p>

          '
        raw: Do anyone here own 3060 12g? Can please share some experience about how
          long does it take to reply a message, need layer to CPU or something even
          more.
        updatedAt: '2023-04-09T07:51:01.740Z'
      numEdits: 0
      reactions: []
    id: 64326e6507bad11484a6b3d7
    type: comment
  author: cyx123
  content: Do anyone here own 3060 12g? Can please share some experience about how
    long does it take to reply a message, need layer to CPU or something even more.
  created_at: 2023-04-09 06:51:01+00:00
  edited: false
  hidden: false
  id: 64326e6507bad11484a6b3d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3f2dbc6c33eb09e4e3b1f5d907607578.svg
      fullname: RGTails
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RGTails
      type: user
    createdAt: '2023-04-09T12:14:17.000Z'
    data:
      edited: false
      editors:
      - RGTails
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3f2dbc6c33eb09e4e3b1f5d907607578.svg
          fullname: RGTails
          isHf: false
          isPro: false
          name: RGTails
          type: user
        html: '<blockquote>

          <p>Do anyone here own 3060 12g? Can please share some experience about how
          long does it take to reply a message, need layer to CPU or something even
          more.</p>

          </blockquote>

          <p>For my part I have the same graphics card as you, however an i7 processor.
          The time that I have the response I send and the one I receive is around
          2s, it also depends on the number of tokens.<br>On the other hand was not
          someone English, when I ask the model to speak to me in another language
          this one does not manage to speak to me correctly. I guess he must have
          trained his model with it. <a href="https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered">https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered</a></p>

          <p>I''m not an expert either.</p>

          '
        raw: '> Do anyone here own 3060 12g? Can please share some experience about
          how long does it take to reply a message, need layer to CPU or something
          even more.


          For my part I have the same graphics card as you, however an i7 processor.
          The time that I have the response I send and the one I receive is around
          2s, it also depends on the number of tokens.

          On the other hand was not someone English, when I ask the model to speak
          to me in another language this one does not manage to speak to me correctly.
          I guess he must have trained his model with it. https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered


          I''m not an expert either.'
        updatedAt: '2023-04-09T12:14:17.036Z'
      numEdits: 0
      reactions: []
    id: 6432ac19028e0ea13acfc5d4
    type: comment
  author: RGTails
  content: '> Do anyone here own 3060 12g? Can please share some experience about
    how long does it take to reply a message, need layer to CPU or something even
    more.


    For my part I have the same graphics card as you, however an i7 processor. The
    time that I have the response I send and the one I receive is around 2s, it also
    depends on the number of tokens.

    On the other hand was not someone English, when I ask the model to speak to me
    in another language this one does not manage to speak to me correctly. I guess
    he must have trained his model with it. https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered


    I''m not an expert either.'
  created_at: 2023-04-09 11:14:17+00:00
  edited: false
  hidden: false
  id: 6432ac19028e0ea13acfc5d4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/547e4921b05c69b6c5bf0382a2d82fba.svg
      fullname: sad asd
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cyx123
      type: user
    createdAt: '2023-04-09T13:22:53.000Z'
    data:
      edited: false
      editors:
      - cyx123
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/547e4921b05c69b6c5bf0382a2d82fba.svg
          fullname: sad asd
          isHf: false
          isPro: false
          name: cyx123
          type: user
        html: '<blockquote>

          <blockquote>

          <p>Do anyone here own 3060 12g? Can please share some experience about how
          long does it take to reply a message, need layer to CPU or something even
          more.</p>

          </blockquote>

          <p>For my part I have the same graphics card as you, however an i7 processor.
          The time that I have the response I send and the one I receive is around
          2s, it also depends on the number of tokens.<br>On the other hand was not
          someone English, when I ask the model to speak to me in another language
          this one does not manage to speak to me correctly. I guess he must have
          trained his model with it. <a href="https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered">https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered</a></p>

          <p>I''m not an expert either.</p>

          </blockquote>

          <p>Thx very much actually i''m using 1660s. Right now thinking to upgrade
          3060 or 3080 within this year =w=</p>

          '
        raw: "> > Do anyone here own 3060 12g? Can please share some experience about\
          \ how long does it take to reply a message, need layer to CPU or something\
          \ even more.\n> \n> For my part I have the same graphics card as you, however\
          \ an i7 processor. The time that I have the response I send and the one\
          \ I receive is around 2s, it also depends on the number of tokens.\n> On\
          \ the other hand was not someone English, when I ask the model to speak\
          \ to me in another language this one does not manage to speak to me correctly.\
          \ I guess he must have trained his model with it. https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered\n\
          > \n> I'm not an expert either.\n\nThx very much actually i'm using 1660s.\
          \ Right now thinking to upgrade 3060 or 3080 within this year =w="
        updatedAt: '2023-04-09T13:22:53.118Z'
      numEdits: 0
      reactions: []
    id: 6432bc2dc8e2047bd9f7f4b4
    type: comment
  author: cyx123
  content: "> > Do anyone here own 3060 12g? Can please share some experience about\
    \ how long does it take to reply a message, need layer to CPU or something even\
    \ more.\n> \n> For my part I have the same graphics card as you, however an i7\
    \ processor. The time that I have the response I send and the one I receive is\
    \ around 2s, it also depends on the number of tokens.\n> On the other hand was\
    \ not someone English, when I ask the model to speak to me in another language\
    \ this one does not manage to speak to me correctly. I guess he must have trained\
    \ his model with it. https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered\n\
    > \n> I'm not an expert either.\n\nThx very much actually i'm using 1660s. Right\
    \ now thinking to upgrade 3060 or 3080 within this year =w="
  created_at: 2023-04-09 12:22:53+00:00
  edited: false
  hidden: false
  id: 6432bc2dc8e2047bd9f7f4b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d9a4f031e1f5044f7b8c9f0b9f11453c.svg
      fullname: Alfred
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Alfred88
      type: user
    createdAt: '2023-04-10T05:49:27.000Z'
    data:
      edited: true
      editors:
      - Alfred88
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d9a4f031e1f5044f7b8c9f0b9f11453c.svg
          fullname: Alfred
          isHf: false
          isPro: false
          name: Alfred88
          type: user
        html: '<p>I have 3060 12gb.This model fits into the video memory with maximum
          context tokens and works at an acceptable speed.I''m using occam fork of
          Kobold Ai and TavernAI as GUI.</p>

          '
        raw: I have 3060 12gb.This model fits into the video memory with maximum context
          tokens and works at an acceptable speed.I'm using occam fork of Kobold Ai
          and TavernAI as GUI.
        updatedAt: '2023-04-10T05:53:00.261Z'
      numEdits: 1
      reactions: []
    id: 6433a3675c65189fe4f5622d
    type: comment
  author: Alfred88
  content: I have 3060 12gb.This model fits into the video memory with maximum context
    tokens and works at an acceptable speed.I'm using occam fork of Kobold Ai and
    TavernAI as GUI.
  created_at: 2023-04-10 04:49:27+00:00
  edited: true
  hidden: false
  id: 6433a3675c65189fe4f5622d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 11
repo_id: anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g
repo_type: model
status: open
target_branch: null
title: Does this model able to run on 3060 12g?
