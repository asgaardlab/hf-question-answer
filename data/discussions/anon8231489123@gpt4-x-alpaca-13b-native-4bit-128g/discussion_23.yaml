!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ShifraSec
conflicting_files: null
created_at: 2023-04-11 00:34:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dd4a5347fbc36e3b7a8c15a3363d24a0.svg
      fullname: M Eltahir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShifraSec
      type: user
    createdAt: '2023-04-11T01:34:09.000Z'
    data:
      edited: true
      editors:
      - ShifraSec
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dd4a5347fbc36e3b7a8c15a3363d24a0.svg
          fullname: M Eltahir
          isHf: false
          isPro: false
          name: ShifraSec
          type: user
        html: "<h3 id=\"background\">Background:</h3>\n<p>Using OpenPlayGround to\
          \ connection to the model and getting eternal server error 500, so started\
          \ to investigate my connection to the model.</p>\n<h3 id=\"steps-to-reproduce\"\
          >Steps to reproduce</h3>\n<p>run a python REPL (or while in code)...</p>\n\
          <pre><code>&gt;&gt; from transformers import AutoTokenizer, AutoModelForCausalLM\n\
          </code></pre>\n<p>fine  then ...</p>\n<pre><code>&gt;&gt;&gt; tokenizer\
          \ = AutoTokenizer.from_pretrained(\"anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\"\
          )\n</code></pre>\n<p>gives me this error:</p>\n<pre><code>ValueError: Tokenizer\
          \ class LlamaTokenizer does not exist or is not currently imported. \n</code></pre>\n\
          <hr>\n<h3 id=\"notes\">Notes:</h3>\n<ol>\n<li><p>tried to:</p>\n<pre><code>pip\
          \ install --upgrade transformers\n</code></pre>\n</li>\n</ol>\n<p> still\
          \ didn't work.</p>\n<ol start=\"2\">\n<li><p>My system info:</p>\n<pre><code>OS:\
          \ MacOS M1 13.3 \n\nPip version: pip 23.0.1\n\npython version: Python 3.11.0\n\
          </code></pre>\n</li>\n</ol>\n"
        raw: "### Background:\n\nUsing OpenPlayGround to connection to the model and\
          \ getting eternal server error 500, so started to investigate my connection\
          \ to the model.\n\n### Steps to reproduce\n\nrun a python REPL (or while\
          \ in code)...\n```\n>> from transformers import AutoTokenizer, AutoModelForCausalLM\n\
          ```\n\nfine  then ...\n\n```\n>>> tokenizer = AutoTokenizer.from_pretrained(\"\
          anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\")\n```\n\ngives me this\
          \ error:\n\n```\nValueError: Tokenizer class LlamaTokenizer does not exist\
          \ or is not currently imported. \n```\n\n-----\n### Notes: \n\n1. tried\
          \ to:\n\n   ```\n   pip install --upgrade transformers\n   ```\n\n still\
          \ didn't work.\n\n2. My system info:\n\n   ```\n   OS: MacOS M1 13.3 \n\
          \   \n   Pip version: pip 23.0.1\n\n   python version: Python 3.11.0\n \
          \  ```"
        updatedAt: '2023-04-11T01:41:01.223Z'
      numEdits: 1
      reactions: []
    id: 6434b911546e16f17a17f9b3
    type: comment
  author: ShifraSec
  content: "### Background:\n\nUsing OpenPlayGround to connection to the model and\
    \ getting eternal server error 500, so started to investigate my connection to\
    \ the model.\n\n### Steps to reproduce\n\nrun a python REPL (or while in code)...\n\
    ```\n>> from transformers import AutoTokenizer, AutoModelForCausalLM\n```\n\n\
    fine  then ...\n\n```\n>>> tokenizer = AutoTokenizer.from_pretrained(\"anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\"\
    )\n```\n\ngives me this error:\n\n```\nValueError: Tokenizer class LlamaTokenizer\
    \ does not exist or is not currently imported. \n```\n\n-----\n### Notes: \n\n\
    1. tried to:\n\n   ```\n   pip install --upgrade transformers\n   ```\n\n still\
    \ didn't work.\n\n2. My system info:\n\n   ```\n   OS: MacOS M1 13.3 \n   \n \
    \  Pip version: pip 23.0.1\n\n   python version: Python 3.11.0\n   ```"
  created_at: 2023-04-11 00:34:09+00:00
  edited: true
  hidden: false
  id: 6434b911546e16f17a17f9b3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 23
repo_id: anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g
repo_type: model
status: open
target_branch: null
title: 'ValueError: Tokenizer class LlamaTokenizer does not exist or is not currently
  imported. (while using Transformers)'
