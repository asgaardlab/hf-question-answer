!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Tulakor
conflicting_files: null
created_at: 2023-10-31 16:45:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7326e8a48af24595e59cf0719b747c8.svg
      fullname: Tulakor
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tulakor
      type: user
    createdAt: '2023-10-31T17:45:56.000Z'
    data:
      edited: false
      editors:
      - Tulakor
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.34472352266311646
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7326e8a48af24595e59cf0719b747c8.svg
          fullname: Tulakor
          isHf: false
          isPro: false
          name: Tulakor
          type: user
        html: '<p>ive downloaded <a rel="nofollow" href="https://github.com/oobabooga/text-generation-webui">https://github.com/oobabooga/text-generation-webui</a>
          and <a href="https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g">https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g</a>
          and put it in models. When i try to load gpt4-x-alpaca-13b-native-4bit-128g
          i get an error<br>Traceback (most recent call last):</p>

          <p>File "/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/modeling_utils.py",
          line 484, in load_state_dict</p>

          <p>return torch.load(checkpoint_file, map_location=map_location)</p>

          <pre><code>   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/torch/serialization.py",
          line 986, in load</p>

          <p>with _open_file_like(f, ''rb'') as opened_file:</p>

          <pre><code> ^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/torch/serialization.py",
          line 435, in _open_file_like</p>

          <p>return _open_file(name_or_buffer, mode)</p>

          <pre><code>   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/torch/serialization.py",
          line 416, in init</p>

          <p>super().<strong>init</strong>(open(name, mode))</p>

          <pre><code>             ^^^^^^^^^^^^^^^^

          </code></pre>

          <p>FileNotFoundError: [Errno 2] No such file or directory: ''models/gpt4-x-alpaca-13b-native-4bit-128g/pytorch_model-00001-of-00006.bin''</p>

          <p>During handling of the above exception, another exception occurred:</p>

          <p>Traceback (most recent call last):</p>

          <p>File "/home/user/AI/text-generation-webui/modules/ui_model_menu.py",
          line 206, in load_model_wrapper</p>

          <p>shared.model, shared.tokenizer = load_model(shared.model_name, loader)</p>

          <pre><code>                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/user/AI/text-generation-webui/modules/models.py", line 84,
          in load_model</p>

          <p>output = load_func_map<a rel="nofollow" href="model_name">loader</a></p>

          <pre><code>     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/user/AI/text-generation-webui/modules/models.py", line 141,
          in huggingface_loader</p>

          <p>model = LoaderClass.from_pretrained(path_to_model, **params)</p>

          <pre><code>    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py",
          line 565, in from_pretrained</p>

          <p>return model_class.from_pretrained(</p>

          <pre><code>   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/modeling_utils.py",
          line 3307, in from_pretrained</p>

          <p>) = cls._load_pretrained_model(</p>

          <pre><code>^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/modeling_utils.py",
          line 3681, in _load_pretrained_model</p>

          <p>state_dict = load_state_dict(shard_file)</p>

          <pre><code>         ^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/modeling_utils.py",
          line 487, in load_state_dict</p>

          <p>with open(checkpoint_file) as f:</p>

          <pre><code> ^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>FileNotFoundError: [Errno 2] No such file or directory: ''models/gpt4-x-alpaca-13b-native-4bit-128g/pytorch_model-00001-of-00006.bin''</p>

          '
        raw: "ive downloaded https://github.com/oobabooga/text-generation-webui and\
          \ https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\
          \ and put it in models. When i try to load gpt4-x-alpaca-13b-native-4bit-128g\
          \ i get an error\r\nTraceback (most recent call last):\r\n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/modeling_utils.py\"\
          , line 484, in load_state_dict\r\n\r\nreturn torch.load(checkpoint_file,\
          \ map_location=map_location)\r\n\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/torch/serialization.py\"\
          , line 986, in load\r\n\r\nwith _open_file_like(f, 'rb') as opened_file:\r\
          \n\r\n     ^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/torch/serialization.py\"\
          , line 435, in _open_file_like\r\n\r\nreturn _open_file(name_or_buffer,\
          \ mode)\r\n\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/torch/serialization.py\"\
          , line 416, in init\r\n\r\nsuper().__init__(open(name, mode))\r\n\r\n  \
          \               ^^^^^^^^^^^^^^^^\r\n\r\nFileNotFoundError: [Errno 2] No\
          \ such file or directory: 'models/gpt4-x-alpaca-13b-native-4bit-128g/pytorch_model-00001-of-00006.bin'\r\
          \n\r\nDuring handling of the above exception, another exception occurred:\r\
          \n\r\nTraceback (most recent call last):\r\n\r\nFile \"/home/user/AI/text-generation-webui/modules/ui_model_menu.py\"\
          , line 206, in load_model_wrapper\r\n\r\nshared.model, shared.tokenizer\
          \ = load_model(shared.model_name, loader)\r\n\r\n                      \
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/user/AI/text-generation-webui/modules/models.py\"\
          , line 84, in load_model\r\n\r\noutput = load_func_map[loader](model_name)\r\
          \n\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/user/AI/text-generation-webui/modules/models.py\"\
          , line 141, in huggingface_loader\r\n\r\nmodel = LoaderClass.from_pretrained(path_to_model,\
          \ **params)\r\n\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 565, in from_pretrained\r\n\r\nreturn model_class.from_pretrained(\r\
          \n\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/modeling_utils.py\"\
          , line 3307, in from_pretrained\r\n\r\n) = cls._load_pretrained_model(\r\
          \n\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/modeling_utils.py\"\
          , line 3681, in _load_pretrained_model\r\n\r\nstate_dict = load_state_dict(shard_file)\r\
          \n\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/modeling_utils.py\"\
          , line 487, in load_state_dict\r\n\r\nwith open(checkpoint_file) as f:\r\
          \n\r\n     ^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFileNotFoundError: [Errno 2] No\
          \ such file or directory: 'models/gpt4-x-alpaca-13b-native-4bit-128g/pytorch_model-00001-of-00006.bin'"
        updatedAt: '2023-10-31T17:45:56.156Z'
      numEdits: 0
      reactions: []
    id: 65413d54c446a9a48ba854c1
    type: comment
  author: Tulakor
  content: "ive downloaded https://github.com/oobabooga/text-generation-webui and\
    \ https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g and\
    \ put it in models. When i try to load gpt4-x-alpaca-13b-native-4bit-128g i get\
    \ an error\r\nTraceback (most recent call last):\r\n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/modeling_utils.py\"\
    , line 484, in load_state_dict\r\n\r\nreturn torch.load(checkpoint_file, map_location=map_location)\r\
    \n\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile\
    \ \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/torch/serialization.py\"\
    , line 986, in load\r\n\r\nwith _open_file_like(f, 'rb') as opened_file:\r\n\r\
    \n     ^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/torch/serialization.py\"\
    , line 435, in _open_file_like\r\n\r\nreturn _open_file(name_or_buffer, mode)\r\
    \n\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/torch/serialization.py\"\
    , line 416, in init\r\n\r\nsuper().__init__(open(name, mode))\r\n\r\n        \
    \         ^^^^^^^^^^^^^^^^\r\n\r\nFileNotFoundError: [Errno 2] No such file or\
    \ directory: 'models/gpt4-x-alpaca-13b-native-4bit-128g/pytorch_model-00001-of-00006.bin'\r\
    \n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\
    \nTraceback (most recent call last):\r\n\r\nFile \"/home/user/AI/text-generation-webui/modules/ui_model_menu.py\"\
    , line 206, in load_model_wrapper\r\n\r\nshared.model, shared.tokenizer = load_model(shared.model_name,\
    \ loader)\r\n\r\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n\r\nFile \"/home/user/AI/text-generation-webui/modules/models.py\", line 84,\
    \ in load_model\r\n\r\noutput = load_func_map[loader](model_name)\r\n\r\n    \
    \     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/user/AI/text-generation-webui/modules/models.py\"\
    , line 141, in huggingface_loader\r\n\r\nmodel = LoaderClass.from_pretrained(path_to_model,\
    \ **params)\r\n\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\"\
    , line 565, in from_pretrained\r\n\r\nreturn model_class.from_pretrained(\r\n\r\
    \n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/modeling_utils.py\"\
    , line 3307, in from_pretrained\r\n\r\n) = cls._load_pretrained_model(\r\n\r\n\
    \    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/modeling_utils.py\"\
    , line 3681, in _load_pretrained_model\r\n\r\nstate_dict = load_state_dict(shard_file)\r\
    \n\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/user/AI/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/modeling_utils.py\"\
    , line 487, in load_state_dict\r\n\r\nwith open(checkpoint_file) as f:\r\n\r\n\
    \     ^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFileNotFoundError: [Errno 2] No such file or\
    \ directory: 'models/gpt4-x-alpaca-13b-native-4bit-128g/pytorch_model-00001-of-00006.bin'"
  created_at: 2023-10-31 16:45:56+00:00
  edited: false
  hidden: false
  id: 65413d54c446a9a48ba854c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/83423a0a2f38cbdd7cab561a1d62f231.svg
      fullname: Gavin Stewart
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nhippie
      type: user
    createdAt: '2023-11-03T16:56:19.000Z'
    data:
      edited: false
      editors:
      - nhippie
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9836525321006775
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/83423a0a2f38cbdd7cab561a1d62f231.svg
          fullname: Gavin Stewart
          isHf: false
          isPro: false
          name: nhippie
          type: user
        html: '<p>I''m having the same issue.  Hope someone can chime in with a solution.</p>

          '
        raw: I'm having the same issue.  Hope someone can chime in with a solution.
        updatedAt: '2023-11-03T16:56:19.426Z'
      numEdits: 0
      reactions: []
    id: 65452633f2b9cff9e96e982d
    type: comment
  author: nhippie
  content: I'm having the same issue.  Hope someone can chime in with a solution.
  created_at: 2023-11-03 15:56:19+00:00
  edited: false
  hidden: false
  id: 65452633f2b9cff9e96e982d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/83423a0a2f38cbdd7cab561a1d62f231.svg
      fullname: Gavin Stewart
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nhippie
      type: user
    createdAt: '2023-11-03T16:58:16.000Z'
    data:
      edited: false
      editors:
      - nhippie
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9244120717048645
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/83423a0a2f38cbdd7cab561a1d62f231.svg
          fullname: Gavin Stewart
          isHf: false
          isPro: false
          name: nhippie
          type: user
        html: '<p>I''m trying to run it with CPU (I don''t have Nvidia GPU).  Also,
          I am running Oobabooga Text Generation UI inside Pinokio.</p>

          '
        raw: I'm trying to run it with CPU (I don't have Nvidia GPU).  Also, I am
          running Oobabooga Text Generation UI inside Pinokio.
        updatedAt: '2023-11-03T16:58:16.593Z'
      numEdits: 0
      reactions: []
    id: 654526a8a5c6064dd1a5124f
    type: comment
  author: nhippie
  content: I'm trying to run it with CPU (I don't have Nvidia GPU).  Also, I am running
    Oobabooga Text Generation UI inside Pinokio.
  created_at: 2023-11-03 15:58:16+00:00
  edited: false
  hidden: false
  id: 654526a8a5c6064dd1a5124f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 54
repo_id: anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g
repo_type: model
status: open
target_branch: null
title: Model cant be loaded
