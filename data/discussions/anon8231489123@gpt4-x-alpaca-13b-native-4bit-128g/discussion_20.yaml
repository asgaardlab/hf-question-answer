!!python/object:huggingface_hub.community.DiscussionWithDetails
author: splork
conflicting_files: null
created_at: 2023-04-10 11:54:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/00ab943d8e49eef94073c2d48f32b1f8.svg
      fullname: florp
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: splork
      type: user
    createdAt: '2023-04-10T12:54:57.000Z'
    data:
      edited: false
      editors:
      - splork
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/00ab943d8e49eef94073c2d48f32b1f8.svg
          fullname: florp
          isHf: false
          isPro: false
          name: splork
          type: user
        html: '<p>Has anyone experienced this problem and managed to get this working?</p>

          '
        raw: Has anyone experienced this problem and managed to get this working?
        updatedAt: '2023-04-10T12:54:57.067Z'
      numEdits: 0
      reactions: []
    id: 643407214b34368fdb014352
    type: comment
  author: splork
  content: Has anyone experienced this problem and managed to get this working?
  created_at: 2023-04-10 11:54:57+00:00
  edited: false
  hidden: false
  id: 643407214b34368fdb014352
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cdbf9f739c3968cb79898a1367df6b1b.svg
      fullname: Khalid alqahtani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: khalidmq
      type: user
    createdAt: '2023-04-10T13:40:54.000Z'
    data:
      edited: false
      editors:
      - khalidmq
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cdbf9f739c3968cb79898a1367df6b1b.svg
          fullname: Khalid alqahtani
          isHf: false
          isPro: false
          name: khalidmq
          type: user
        html: '<p>same issue. still trying to figure it out.</p>

          '
        raw: same issue. still trying to figure it out.
        updatedAt: '2023-04-10T13:40:54.034Z'
      numEdits: 0
      reactions: []
    id: 643411e65408e9c12afaeeab
    type: comment
  author: khalidmq
  content: same issue. still trying to figure it out.
  created_at: 2023-04-10 12:40:54+00:00
  edited: false
  hidden: false
  id: 643411e65408e9c12afaeeab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/uSYwhk3qIhFrAMgHdU9mJ.png?w=200&h=200&f=face
      fullname: Andrew
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AndrewDrD
      type: user
    createdAt: '2023-04-10T15:39:05.000Z'
    data:
      edited: false
      editors:
      - AndrewDrD
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/uSYwhk3qIhFrAMgHdU9mJ.png?w=200&h=200&f=face
          fullname: Andrew
          isHf: false
          isPro: false
          name: AndrewDrD
          type: user
        html: '<p>+1 I have the same issue</p>

          '
        raw: +1 I have the same issue
        updatedAt: '2023-04-10T15:39:05.262Z'
      numEdits: 0
      reactions: []
    id: 64342d995408e9c12afbdac6
    type: comment
  author: AndrewDrD
  content: +1 I have the same issue
  created_at: 2023-04-10 14:39:05+00:00
  edited: false
  hidden: false
  id: 64342d995408e9c12afbdac6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ab033a24f08211f2458f12fac5d7e7cb.svg
      fullname: Danny Skeff
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DannySK
      type: user
    createdAt: '2023-04-10T16:30:31.000Z'
    data:
      edited: false
      editors:
      - DannySK
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ab033a24f08211f2458f12fac5d7e7cb.svg
          fullname: Danny Skeff
          isHf: false
          isPro: false
          name: DannySK
          type: user
        html: '<p>Yep, me too.</p>

          '
        raw: Yep, me too.
        updatedAt: '2023-04-10T16:30:31.684Z'
      numEdits: 0
      reactions: []
    id: 643439a78d68561d704f5c2e
    type: comment
  author: DannySK
  content: Yep, me too.
  created_at: 2023-04-10 15:30:31+00:00
  edited: false
  hidden: false
  id: 643439a78d68561d704f5c2e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1675512244297-63d3aa7c640bb0f77173178c.jpeg?w=200&h=200&f=face
      fullname: ItBurnZ
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Itburnz
      type: user
    createdAt: '2023-04-10T17:06:47.000Z'
    data:
      edited: true
      editors:
      - Itburnz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1675512244297-63d3aa7c640bb0f77173178c.jpeg?w=200&h=200&f=face
          fullname: ItBurnZ
          isHf: false
          isPro: false
          name: Itburnz
          type: user
        html: '<p>use ''GIT_LFS_SKIP_SMUDGE=1'' before the git clone command to clone
          all the files except the large files.  </p>

          <p>example:<br>GIT_LFS_SKIP_SMUDGE=1 git clone <a href="https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g">https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g</a></p>

          <p>Manually download the file that you need using wget or clicking the file
          link and pressing download button provided by HF on the HF page</p>

          <p>examaple:<br>wget <a href="https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g/blob/main/gpt4-x-alpaca-13b-ggml-q4_1-from-gptq-4bit-128g/ggml-model-q4_1.bin">https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g/blob/main/gpt4-x-alpaca-13b-ggml-q4_1-from-gptq-4bit-128g/ggml-model-q4_1.bin</a></p>

          <p>if you are going to use llama.cpp and run it CPU only, then you need
          the ggml model <a href="https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g/blob/main/gpt4-x-alpaca-13b-ggml-q4_1-from-gptq-4bit-128g/ggml-model-q4_1.bin">https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g/blob/main/gpt4-x-alpaca-13b-ggml-q4_1-from-gptq-4bit-128g/ggml-model-q4_1.bin</a></p>

          <p>if you are going to use OodaBooga with GPU, then download the Cuda GPTQ<br><a
          href="https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g/blob/main/gpt-x-alpaca-13b-native-4bit-128g-cuda.pt">https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g/blob/main/gpt-x-alpaca-13b-native-4bit-128g-cuda.pt</a></p>

          '
        raw: "use 'GIT_LFS_SKIP_SMUDGE=1' before the git clone command to clone all\
          \ the files except the large files.  \n\nexample:\nGIT_LFS_SKIP_SMUDGE=1\
          \ git clone https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\n\
          \nManually download the file that you need using wget or clicking the file\
          \ link and pressing download button provided by HF on the HF page\n\nexamaple:\
          \ \nwget https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g/blob/main/gpt4-x-alpaca-13b-ggml-q4_1-from-gptq-4bit-128g/ggml-model-q4_1.bin\n\
          \nif you are going to use llama.cpp and run it CPU only, then you need the\
          \ ggml model https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g/blob/main/gpt4-x-alpaca-13b-ggml-q4_1-from-gptq-4bit-128g/ggml-model-q4_1.bin\n\
          \nif you are going to use OodaBooga with GPU, then download the Cuda GPTQ\n\
          https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g/blob/main/gpt-x-alpaca-13b-native-4bit-128g-cuda.pt"
        updatedAt: '2023-04-10T17:12:34.460Z'
      numEdits: 2
      reactions: []
    id: 643442278d68561d704f9d1a
    type: comment
  author: Itburnz
  content: "use 'GIT_LFS_SKIP_SMUDGE=1' before the git clone command to clone all\
    \ the files except the large files.  \n\nexample:\nGIT_LFS_SKIP_SMUDGE=1 git clone\
    \ https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\n\n\
    Manually download the file that you need using wget or clicking the file link\
    \ and pressing download button provided by HF on the HF page\n\nexamaple: \nwget\
    \ https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g/blob/main/gpt4-x-alpaca-13b-ggml-q4_1-from-gptq-4bit-128g/ggml-model-q4_1.bin\n\
    \nif you are going to use llama.cpp and run it CPU only, then you need the ggml\
    \ model https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g/blob/main/gpt4-x-alpaca-13b-ggml-q4_1-from-gptq-4bit-128g/ggml-model-q4_1.bin\n\
    \nif you are going to use OodaBooga with GPU, then download the Cuda GPTQ\nhttps://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g/blob/main/gpt-x-alpaca-13b-native-4bit-128g-cuda.pt"
  created_at: 2023-04-10 16:06:47+00:00
  edited: true
  hidden: false
  id: 643442278d68561d704f9d1a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6df16c7af5b90baa74a77b3108abc77a.svg
      fullname: po
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jack2pot
      type: user
    createdAt: '2023-04-11T00:11:15.000Z'
    data:
      edited: false
      editors:
      - jack2pot
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6df16c7af5b90baa74a77b3108abc77a.svg
          fullname: po
          isHf: false
          isPro: false
          name: jack2pot
          type: user
        html: '<p>Using GIT_LFS_SKIP_SMUDGE=1 Gives this error:  is not recognized
          as an internal or external command, operable program, or batch file</p>

          '
        raw: 'Using GIT_LFS_SKIP_SMUDGE=1 Gives this error:  is not recognized as
          an internal or external command, operable program, or batch file'
        updatedAt: '2023-04-11T00:11:15.317Z'
      numEdits: 0
      reactions: []
    id: 6434a5a3a5ee15b2ed3a77b9
    type: comment
  author: jack2pot
  content: 'Using GIT_LFS_SKIP_SMUDGE=1 Gives this error:  is not recognized as an
    internal or external command, operable program, or batch file'
  created_at: 2023-04-10 23:11:15+00:00
  edited: false
  hidden: false
  id: 6434a5a3a5ee15b2ed3a77b9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/66b176843c0201860b6138e14495e87e.svg
      fullname: Wyatt Meckler
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lostinthesauce
      type: user
    createdAt: '2023-04-11T00:30:03.000Z'
    data:
      edited: false
      editors:
      - lostinthesauce
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/66b176843c0201860b6138e14495e87e.svg
          fullname: Wyatt Meckler
          isHf: false
          isPro: false
          name: lostinthesauce
          type: user
        html: '<p>Got the same response as above when trying to use it</p>

          '
        raw: Got the same response as above when trying to use it
        updatedAt: '2023-04-11T00:30:03.137Z'
      numEdits: 0
      reactions: []
    id: 6434aa0b938d07505bba9f6f
    type: comment
  author: lostinthesauce
  content: Got the same response as above when trying to use it
  created_at: 2023-04-10 23:30:03+00:00
  edited: false
  hidden: false
  id: 6434aa0b938d07505bba9f6f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/17acce4d136ec7c3814d13102e2bf9ea.svg
      fullname: nCoder
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: n-Coder
      type: user
    createdAt: '2023-04-11T03:15:03.000Z'
    data:
      edited: true
      editors:
      - n-Coder
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/17acce4d136ec7c3814d13102e2bf9ea.svg
          fullname: nCoder
          isHf: false
          isPro: false
          name: n-Coder
          type: user
        html: '<p>The download is probably still going in the background. It just
          takes ages and there is no visual feedback like a progress bar.</p>

          <p>However, Git has seems to have some bugs on Windows when downloading
          files &gt;4GB and will probably just save a truncated file anyway, so better
          set the corresponding environment variable to skip huge files (temporary,
          only applies to the current CMD session) before doing the clone and download
          + overwrite them manually:</p>

          <p>git lfs install<br>set GIT_LFS_SKIP_SMUDGE=1<br>git clone <a href="https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g">https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g</a></p>

          <p>The clone command should only take a few seconds and create 1KB placeholder
          files for the huge ones (.pt, .safetensors, .bin etc).<br>Now download that
          big checkpoint file manually and OVERWRITE the placeholder.</p>

          <p>When in doubt,  "git status" should tell you which files are affected.<br>(You
          might need to "cd" to the new directory first: "cd gpt4-x-alpaca-13b-native-4bit-128g")</p>

          '
        raw: 'The download is probably still going in the background. It just takes
          ages and there is no visual feedback like a progress bar.


          However, Git has seems to have some bugs on Windows when downloading files
          >4GB and will probably just save a truncated file anyway, so better set
          the corresponding environment variable to skip huge files (temporary, only
          applies to the current CMD session) before doing the clone and download
          + overwrite them manually:


          git lfs install

          set GIT_LFS_SKIP_SMUDGE=1

          git clone https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g


          The clone command should only take a few seconds and create 1KB placeholder
          files for the huge ones (.pt, .safetensors, .bin etc).

          Now download that big checkpoint file manually and OVERWRITE the placeholder.


          When in doubt,  "git status" should tell you which files are affected.

          (You might need to "cd" to the new directory first: "cd gpt4-x-alpaca-13b-native-4bit-128g")'
        updatedAt: '2023-04-11T04:01:26.715Z'
      numEdits: 4
      reactions:
      - count: 6
        reaction: "\U0001F44D"
        users:
        - teniu
        - sergit
        - Shittoshop
        - Qishuai
        - fieryaleeco
        - patrol90
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - Shittoshop
        - fieryaleeco
    id: 6434d0b75408e9c12a0049aa
    type: comment
  author: n-Coder
  content: 'The download is probably still going in the background. It just takes
    ages and there is no visual feedback like a progress bar.


    However, Git has seems to have some bugs on Windows when downloading files >4GB
    and will probably just save a truncated file anyway, so better set the corresponding
    environment variable to skip huge files (temporary, only applies to the current
    CMD session) before doing the clone and download + overwrite them manually:


    git lfs install

    set GIT_LFS_SKIP_SMUDGE=1

    git clone https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g


    The clone command should only take a few seconds and create 1KB placeholder files
    for the huge ones (.pt, .safetensors, .bin etc).

    Now download that big checkpoint file manually and OVERWRITE the placeholder.


    When in doubt,  "git status" should tell you which files are affected.

    (You might need to "cd" to the new directory first: "cd gpt4-x-alpaca-13b-native-4bit-128g")'
  created_at: 2023-04-11 02:15:03+00:00
  edited: true
  hidden: false
  id: 6434d0b75408e9c12a0049aa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b799931f41be46d6c7b18963b436920a.svg
      fullname: Matt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luthis
      type: user
    createdAt: '2023-05-09T22:10:58.000Z'
    data:
      edited: false
      editors:
      - luthis
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b799931f41be46d6c7b18963b436920a.svg
          fullname: Matt
          isHf: false
          isPro: false
          name: luthis
          type: user
        html: '<p>I had the same issue, but checking in .git/lfs/incomplete I can
          see those large files there, so it''s actually just downloading and not
          giving visual feedback.</p>

          <p>I just left it to finish.</p>

          '
        raw: 'I had the same issue, but checking in .git/lfs/incomplete I can see
          those large files there, so it''s actually just downloading and not giving
          visual feedback.


          I just left it to finish.'
        updatedAt: '2023-05-09T22:10:58.578Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - SnowballzzZZ
        - aloksharma1
    id: 645ac4f2bf3f9fbb8c6d65e0
    type: comment
  author: luthis
  content: 'I had the same issue, but checking in .git/lfs/incomplete I can see those
    large files there, so it''s actually just downloading and not giving visual feedback.


    I just left it to finish.'
  created_at: 2023-05-09 21:10:58+00:00
  edited: false
  hidden: false
  id: 645ac4f2bf3f9fbb8c6d65e0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676588582686-noauth.png?w=200&h=200&f=face
      fullname: Alec B
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fieryaleeco
      type: user
    createdAt: '2023-09-11T14:21:32.000Z'
    data:
      edited: false
      editors:
      - fieryaleeco
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9711095690727234
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676588582686-noauth.png?w=200&h=200&f=face
          fullname: Alec B
          isHf: false
          isPro: false
          name: fieryaleeco
          type: user
        html: '<p>I am having this issue. As per the responses I added the flag before
          I cloned the repository. (to avoid it downloading the 10GB &amp; 5GB files
          I have already downloaded)</p>

          <p>Upon running the clone command again it gets to 85% on filtering, my
          network usage goes through the roof &amp; now I guess I just have to wait
          out the unknown time.</p>

          <p>Why didn''t the flag work?</p>

          <p>No idea when it''s going to finish so time to go to bed &amp; hope it''s
          done when I wake up.</p>

          '
        raw: 'I am having this issue. As per the responses I added the flag before
          I cloned the repository. (to avoid it downloading the 10GB & 5GB files I
          have already downloaded)


          Upon running the clone command again it gets to 85% on filtering, my network
          usage goes through the roof & now I guess I just have to wait out the unknown
          time.


          Why didn''t the flag work?


          No idea when it''s going to finish so time to go to bed & hope it''s done
          when I wake up.'
        updatedAt: '2023-09-11T14:21:32.353Z'
      numEdits: 0
      reactions: []
    id: 64ff226c999811902e4f85da
    type: comment
  author: fieryaleeco
  content: 'I am having this issue. As per the responses I added the flag before I
    cloned the repository. (to avoid it downloading the 10GB & 5GB files I have already
    downloaded)


    Upon running the clone command again it gets to 85% on filtering, my network usage
    goes through the roof & now I guess I just have to wait out the unknown time.


    Why didn''t the flag work?


    No idea when it''s going to finish so time to go to bed & hope it''s done when
    I wake up.'
  created_at: 2023-09-11 13:21:32+00:00
  edited: false
  hidden: false
  id: 64ff226c999811902e4f85da
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/67c25b350cd5813c155d20537fcdb859.svg
      fullname: Dustin Bortner
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dustin-rcg
      type: user
    createdAt: '2023-09-15T20:11:29.000Z'
    data:
      edited: true
      editors:
      - dustin-rcg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9755726456642151
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/67c25b350cd5813c155d20537fcdb859.svg
          fullname: Dustin Bortner
          isHf: false
          isPro: false
          name: dustin-rcg
          type: user
        html: '<p>+1. would be nice to see the status in the console. For now, I open
          up Activity Monitor, go to Network tab, and see that git-lfs is there and
          that it is receiving.</p>

          '
        raw: +1. would be nice to see the status in the console. For now, I open up
          Activity Monitor, go to Network tab, and see that git-lfs is there and that
          it is receiving.
        updatedAt: '2023-09-15T20:14:45.391Z'
      numEdits: 2
      reactions: []
    id: 6504ba71ffc738079c448c6b
    type: comment
  author: dustin-rcg
  content: +1. would be nice to see the status in the console. For now, I open up
    Activity Monitor, go to Network tab, and see that git-lfs is there and that it
    is receiving.
  created_at: 2023-09-15 19:11:29+00:00
  edited: true
  hidden: false
  id: 6504ba71ffc738079c448c6b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/73363e5a14069ad13a54c618b9758c33.svg
      fullname: testmbo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thisisatestmbo
      type: user
    createdAt: '2023-10-11T01:52:16.000Z'
    data:
      edited: false
      editors:
      - thisisatestmbo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9610675573348999
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/73363e5a14069ad13a54c618b9758c33.svg
          fullname: testmbo
          isHf: false
          isPro: false
          name: thisisatestmbo
          type: user
        html: '<p>I think it is downloading in the background even though it is not
          logging it-<br>I see my network consumption up accordingly even though I
          am "stuck" on filtering content step of clone.</p>

          <p>Patience will probably be the winner</p>

          '
        raw: 'I think it is downloading in the background even though it is not logging
          it-

          I see my network consumption up accordingly even though I am "stuck" on
          filtering content step of clone.


          Patience will probably be the winner'
        updatedAt: '2023-10-11T01:52:16.017Z'
      numEdits: 0
      reactions: []
    id: 6525ffd0b36077356b445132
    type: comment
  author: thisisatestmbo
  content: 'I think it is downloading in the background even though it is not logging
    it-

    I see my network consumption up accordingly even though I am "stuck" on filtering
    content step of clone.


    Patience will probably be the winner'
  created_at: 2023-10-11 00:52:16+00:00
  edited: false
  hidden: false
  id: 6525ffd0b36077356b445132
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6702120b6b4d22f801e6a8a300d407c6.svg
      fullname: Ben
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mccninja
      type: user
    createdAt: '2023-10-25T20:12:23.000Z'
    data:
      edited: false
      editors:
      - mccninja
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9607595801353455
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6702120b6b4d22f801e6a8a300d407c6.svg
          fullname: Ben
          isHf: false
          isPro: false
          name: mccninja
          type: user
        html: '<blockquote>

          <p>I think it is downloading in the background even though it is not logging
          it-<br>I see my network consumption up accordingly even though I am "stuck"
          on filtering content step of clone.</p>

          <p>Patience will probably be the winner</p>

          </blockquote>

          <p>how long did it take to downlaod</p>

          '
        raw: "> I think it is downloading in the background even though it is not\
          \ logging it-\n> I see my network consumption up accordingly even though\
          \ I am \"stuck\" on filtering content step of clone.\n> \n> Patience will\
          \ probably be the winner\n\nhow long did it take to downlaod\n"
        updatedAt: '2023-10-25T20:12:23.274Z'
      numEdits: 0
      reactions: []
    id: 653976a7690022ca51e10955
    type: comment
  author: mccninja
  content: "> I think it is downloading in the background even though it is not logging\
    \ it-\n> I see my network consumption up accordingly even though I am \"stuck\"\
    \ on filtering content step of clone.\n> \n> Patience will probably be the winner\n\
    \nhow long did it take to downlaod\n"
  created_at: 2023-10-25 19:12:23+00:00
  edited: false
  hidden: false
  id: 653976a7690022ca51e10955
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 20
repo_id: anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g
repo_type: model
status: open
target_branch: null
title: 'Stuck at "Filtering content: 40% (2/5)" when cloning repository'
