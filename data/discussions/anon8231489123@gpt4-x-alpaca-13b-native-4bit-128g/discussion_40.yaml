!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Wildstar50
conflicting_files: null
created_at: 2023-05-04 01:56:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fe62f9fefe5d2e80dc37839ae44ac2be.svg
      fullname: R M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Wildstar50
      type: user
    createdAt: '2023-05-04T02:56:33.000Z'
    data:
      edited: false
      editors:
      - Wildstar50
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fe62f9fefe5d2e80dc37839ae44ac2be.svg
          fullname: R M
          isHf: false
          isPro: false
          name: Wildstar50
          type: user
        html: '<p>Curious, per the title.  Would an 8-bit version of this model perform
          noticeably better and still fit into a 3090 / 4090?</p>

          '
        raw: Curious, per the title.  Would an 8-bit version of this model perform
          noticeably better and still fit into a 3090 / 4090?
        updatedAt: '2023-05-04T02:56:33.085Z'
      numEdits: 0
      reactions: []
    id: 64531ee19ed588cdc4d3a6d1
    type: comment
  author: Wildstar50
  content: Curious, per the title.  Would an 8-bit version of this model perform noticeably
    better and still fit into a 3090 / 4090?
  created_at: 2023-05-04 01:56:33+00:00
  edited: false
  hidden: false
  id: 64531ee19ed588cdc4d3a6d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/04297acee24206d3972d73a2bc960ee8.svg
      fullname: tp
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Onix22
      type: user
    createdAt: '2023-05-07T23:52:34.000Z'
    data:
      edited: false
      editors:
      - Onix22
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/04297acee24206d3972d73a2bc960ee8.svg
          fullname: tp
          isHf: false
          isPro: false
          name: Onix22
          type: user
        html: '<p>there are no 8 bit models you just load 16 bit in 8 bit mode<br>but
          8 bit is very slow for some reason. response quality is slightly better.<br>rather
          than using 13b in 8 bit mode you better use 30b in 4 bit mode or even 3
          bit mode</p>

          '
        raw: "there are no 8 bit models you just load 16 bit in 8 bit mode \nbut 8\
          \ bit is very slow for some reason. response quality is slightly better.\n\
          rather than using 13b in 8 bit mode you better use 30b in 4 bit mode or\
          \ even 3 bit mode"
        updatedAt: '2023-05-07T23:52:34.391Z'
      numEdits: 0
      reactions: []
    id: 645839c2116c6b3c62e54809
    type: comment
  author: Onix22
  content: "there are no 8 bit models you just load 16 bit in 8 bit mode \nbut 8 bit\
    \ is very slow for some reason. response quality is slightly better.\nrather than\
    \ using 13b in 8 bit mode you better use 30b in 4 bit mode or even 3 bit mode"
  created_at: 2023-05-07 22:52:34+00:00
  edited: false
  hidden: false
  id: 645839c2116c6b3c62e54809
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fe62f9fefe5d2e80dc37839ae44ac2be.svg
      fullname: R M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Wildstar50
      type: user
    createdAt: '2023-05-08T00:57:37.000Z'
    data:
      edited: false
      editors:
      - Wildstar50
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fe62f9fefe5d2e80dc37839ae44ac2be.svg
          fullname: R M
          isHf: false
          isPro: false
          name: Wildstar50
          type: user
        html: '<p>Excellent, thanks!</p>

          '
        raw: Excellent, thanks!
        updatedAt: '2023-05-08T00:57:37.049Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64584901116c6b3c62e6bcff
    id: 64584901116c6b3c62e6bcfe
    type: comment
  author: Wildstar50
  content: Excellent, thanks!
  created_at: 2023-05-07 23:57:37+00:00
  edited: false
  hidden: false
  id: 64584901116c6b3c62e6bcfe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/fe62f9fefe5d2e80dc37839ae44ac2be.svg
      fullname: R M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Wildstar50
      type: user
    createdAt: '2023-05-08T00:57:37.000Z'
    data:
      status: closed
    id: 64584901116c6b3c62e6bcff
    type: status-change
  author: Wildstar50
  created_at: 2023-05-07 23:57:37+00:00
  id: 64584901116c6b3c62e6bcff
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 40
repo_id: anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g
repo_type: model
status: closed
target_branch: null
title: If 4-bit = 8GB model would 8-bit = 16GB?  And how much better would it be?
