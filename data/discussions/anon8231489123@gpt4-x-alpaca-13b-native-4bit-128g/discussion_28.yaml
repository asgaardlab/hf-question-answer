!!python/object:huggingface_hub.community.DiscussionWithDetails
author: planetfrog
conflicting_files: null
created_at: 2023-04-11 19:06:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3148cd27ef6f92c23599bae12d0af88b.svg
      fullname: Sean
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: planetfrog
      type: user
    createdAt: '2023-04-11T20:06:03.000Z'
    data:
      edited: false
      editors:
      - planetfrog
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3148cd27ef6f92c23599bae12d0af88b.svg
          fullname: Sean
          isHf: false
          isPro: false
          name: planetfrog
          type: user
        html: '<p><a rel="nofollow" href="https://youtu.be/ByV5w1ES38A">https://youtu.be/ByV5w1ES38A</a></p>

          <p>hope this helps someone. I just followed the instructions, then moved
          this model / files to the new models folder.</p>

          '
        raw: "https://youtu.be/ByV5w1ES38A\r\n\r\nhope this helps someone. I just\
          \ followed the instructions, then moved this model / files to the new models\
          \ folder."
        updatedAt: '2023-04-11T20:06:03.233Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - gocaga1618
    id: 6435bdaba4bd75c62cbf7307
    type: comment
  author: planetfrog
  content: "https://youtu.be/ByV5w1ES38A\r\n\r\nhope this helps someone. I just followed\
    \ the instructions, then moved this model / files to the new models folder."
  created_at: 2023-04-11 19:06:03+00:00
  edited: false
  hidden: false
  id: 6435bdaba4bd75c62cbf7307
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3148cd27ef6f92c23599bae12d0af88b.svg
      fullname: Sean
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: planetfrog
      type: user
    createdAt: '2023-04-11T20:09:05.000Z'
    data:
      edited: true
      editors:
      - planetfrog
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3148cd27ef6f92c23599bae12d0af88b.svg
          fullname: Sean
          isHf: false
          isPro: false
          name: planetfrog
          type: user
        html: "<h2 id=\"start-webuibat-file\">Start-webui.bat file:</h2>\n<p><span\
          \ data-props=\"{&quot;user&quot;:&quot;echo&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/echo\">@<span class=\"underline\">echo</span></a></span>\n\
          \n\t</span></span> off</p>\n<p><span data-props=\"{&quot;user&quot;:&quot;echo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/echo\"\
          >@<span class=\"underline\">echo</span></a></span>\n\n\t</span></span> Starting\
          \ the web UI...</p>\n<p>cd /D \"%~dp0\"</p>\n<p>set MAMBA_ROOT_PREFIX=%cd%\\\
          installer_files\\mamba<br>set INSTALL_ENV_DIR=%cd%\\installer_files\\env</p>\n\
          <p>if not exist \"%MAMBA_ROOT_PREFIX%\\condabin\\micromamba.bat\" (<br>\
          \  call \"%MAMBA_ROOT_PREFIX%\\micromamba.exe\" shell hook &gt;nul 2&gt;&amp;1<br>)<br>call\
          \ \"%MAMBA_ROOT_PREFIX%\\condabin\\micromamba.bat\" activate \"%INSTALL_ENV_DIR%\"\
          \ || ( echo MicroMamba hook not found. &amp;&amp; goto end )<br>cd text-generation-webui</p>\n\
          <p>call python server.py --auto-devices --cai-chat --threads 8 --wbits 4\
          \ --groupsize 128 </p>\n<p>:end<br>pause</p>\n<hr>\n<p>Also adjusted the\
          \ HDD virtual memory setting to be managed by applications</p>\n"
        raw: "Start-webui.bat file:\n-----------------------------------\n@echo off\n\
          \n@echo Starting the web UI...\n\ncd /D \"%~dp0\"\n\nset MAMBA_ROOT_PREFIX=%cd%\\\
          installer_files\\mamba\nset INSTALL_ENV_DIR=%cd%\\installer_files\\env\n\
          \nif not exist \"%MAMBA_ROOT_PREFIX%\\condabin\\micromamba.bat\" (\n  call\
          \ \"%MAMBA_ROOT_PREFIX%\\micromamba.exe\" shell hook >nul 2>&1\n)\ncall\
          \ \"%MAMBA_ROOT_PREFIX%\\condabin\\micromamba.bat\" activate \"%INSTALL_ENV_DIR%\"\
          \ || ( echo MicroMamba hook not found. && goto end )\ncd text-generation-webui\n\
          \ncall python server.py --auto-devices --cai-chat --threads 8 --wbits 4\
          \ --groupsize 128 \n\n:end\npause\n------------------------------------------\n\
          \nAlso adjusted the HDD virtual memory setting to be managed by applications"
        updatedAt: '2023-04-11T20:10:03.911Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - gocaga1618
        - Thamis
    id: 6435be61569e1a4b0cc56a29
    type: comment
  author: planetfrog
  content: "Start-webui.bat file:\n-----------------------------------\n@echo off\n\
    \n@echo Starting the web UI...\n\ncd /D \"%~dp0\"\n\nset MAMBA_ROOT_PREFIX=%cd%\\\
    installer_files\\mamba\nset INSTALL_ENV_DIR=%cd%\\installer_files\\env\n\nif not\
    \ exist \"%MAMBA_ROOT_PREFIX%\\condabin\\micromamba.bat\" (\n  call \"%MAMBA_ROOT_PREFIX%\\\
    micromamba.exe\" shell hook >nul 2>&1\n)\ncall \"%MAMBA_ROOT_PREFIX%\\condabin\\\
    micromamba.bat\" activate \"%INSTALL_ENV_DIR%\" || ( echo MicroMamba hook not\
    \ found. && goto end )\ncd text-generation-webui\n\ncall python server.py --auto-devices\
    \ --cai-chat --threads 8 --wbits 4 --groupsize 128 \n\n:end\npause\n------------------------------------------\n\
    \nAlso adjusted the HDD virtual memory setting to be managed by applications"
  created_at: 2023-04-11 19:09:05+00:00
  edited: true
  hidden: false
  id: 6435be61569e1a4b0cc56a29
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3db91ddae463eb283d731afa5c03d888.svg
      fullname: alkhanzi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alkhanzi
      type: user
    createdAt: '2023-04-15T19:41:02.000Z'
    data:
      edited: false
      editors:
      - alkhanzi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3db91ddae463eb283d731afa5c03d888.svg
          fullname: alkhanzi
          isHf: false
          isPro: false
          name: alkhanzi
          type: user
        html: '<p>Hmmm I just downloaded this model and loaded it with the oobabooga
          UI - no changes to any settings / configuration file. I see 9GB memory used
          while loading the model and it goes upto 11.2 GB during inference. (same
          GPU)</p>

          '
        raw: Hmmm I just downloaded this model and loaded it with the oobabooga UI
          - no changes to any settings / configuration file. I see 9GB memory used
          while loading the model and it goes upto 11.2 GB during inference. (same
          GPU)
        updatedAt: '2023-04-15T19:41:02.104Z'
      numEdits: 0
      reactions: []
    id: 643afdce101fbcb9402f54d8
    type: comment
  author: alkhanzi
  content: Hmmm I just downloaded this model and loaded it with the oobabooga UI -
    no changes to any settings / configuration file. I see 9GB memory used while loading
    the model and it goes upto 11.2 GB during inference. (same GPU)
  created_at: 2023-04-15 18:41:02+00:00
  edited: false
  hidden: false
  id: 643afdce101fbcb9402f54d8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643fe32e388f31f64ccbb550/Rz3XnVEqkvsxvDzfydhv8.png?w=200&h=200&f=face
      fullname: Mat Boc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Thamis
      type: user
    createdAt: '2023-04-19T13:13:45.000Z'
    data:
      edited: true
      editors:
      - Thamis
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643fe32e388f31f64ccbb550/Rz3XnVEqkvsxvDzfydhv8.png?w=200&h=200&f=face
          fullname: Mat Boc
          isHf: false
          isPro: false
          name: Thamis
          type: user
        html: '<p>Wow that was a huge help, been struggling to get a working environment
          !</p>

          <p>You can easily run any models using this method.</p>

          '
        raw: 'Wow that was a huge help, been struggling to get a working environment
          !


          You can easily run any models using this method.'
        updatedAt: '2023-04-20T09:14:37.239Z'
      numEdits: 1
      reactions: []
    id: 643fe9092113f7dfcb4c8757
    type: comment
  author: Thamis
  content: 'Wow that was a huge help, been struggling to get a working environment
    !


    You can easily run any models using this method.'
  created_at: 2023-04-19 12:13:45+00:00
  edited: true
  hidden: false
  id: 643fe9092113f7dfcb4c8757
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 28
repo_id: anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g
repo_type: model
status: open
target_branch: null
title: Running an rtx3060 with 12GBvram - managed to get this model working on method
  in link in description
