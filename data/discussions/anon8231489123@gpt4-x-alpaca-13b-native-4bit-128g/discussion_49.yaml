!!python/object:huggingface_hub.community.DiscussionWithDetails
author: LeonTu07
conflicting_files: null
created_at: 2023-07-11 06:48:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cecd3a259d268f6a75cb64a42f53cd59.svg
      fullname: Leon Tuschick
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LeonTu07
      type: user
    createdAt: '2023-07-11T07:48:10.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/cecd3a259d268f6a75cb64a42f53cd59.svg
          fullname: Leon Tuschick
          isHf: false
          isPro: false
          name: LeonTu07
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-08-16T20:05:01.583Z'
      numEdits: 1
      reactions: []
    id: 64ad093a39fcfebff8cd185b
    type: comment
  author: LeonTu07
  content: This comment has been hidden
  created_at: 2023-07-11 06:48:10+00:00
  edited: true
  hidden: true
  id: 64ad093a39fcfebff8cd185b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 49
repo_id: anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g
repo_type: model
status: open
target_branch: null
title: The model weights are not tied and json-files are different from the original
  LlamaTokenizer file?
