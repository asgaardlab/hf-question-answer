!!python/object:huggingface_hub.community.DiscussionWithDetails
author: xiao111
conflicting_files: null
created_at: 2023-05-09 13:11:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8ddcd18bca58cf2fc217c35fba261948.svg
      fullname: junxian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xiao111
      type: user
    createdAt: '2023-05-09T14:11:42.000Z'
    data:
      edited: false
      editors:
      - xiao111
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8ddcd18bca58cf2fc217c35fba261948.svg
          fullname: junxian
          isHf: false
          isPro: false
          name: xiao111
          type: user
        html: "<ol>\n<li>\u5C1D\u8BD5\u5728 m2 \u4E0A\u5FAE\u8C03 chatglm-6b-int4\
          \ \u62A5\u9519\uFF0C\u770B\u8D77\u6765\u662F kernels == None\uFF0C\u5F53\
          \u52A0\u8F7D from cpm_kernels.kernels.base import LazyKernelCModule, KernelFunction,\
          \ round_up \u5F02\u5E38\uFF1B</li>\n</ol>\n<pre><code>Traceback (most recent\
          \ call last):\n  File \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/main.py\"\
          , line 433, in &lt;module&gt;\n    main()\n  File \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/main.py\"\
          , line 372, in main\n    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n\
          \                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n \
          \ File \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/trainer.py\"\
          , line 1635, in train\n    return inner_training_loop(\n           ^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/trainer.py\"\
          , line 1904, in _inner_training_loop\n    tr_loss_step = self.training_step(model,\
          \ inputs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File\
          \ \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/trainer.py\", line\
          \ 2647, in training_step\n    loss = self.compute_loss(model, inputs)\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/trainer.py\"\
          , line 2679, in compute_loss\n    outputs = model(**inputs)\n          \
          \    ^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1502, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1511, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/modeling_chatglm.py\"\
          , line 1190, in forward\n    transformer_outputs = self.transformer(\n \
          \                         ^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1502, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1511, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/modeling_chatglm.py\"\
          , line 985, in forward\n    layer_ret = torch.utils.checkpoint.checkpoint(\n\
          \                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/utils/checkpoint.py\"\
          , line 356, in checkpoint\n    return CheckpointFunction.apply(function,\
          \ preserve, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/autograd/function.py\"\
          , line 506, in apply\n    return super().apply(*args, **kwargs)  # type:\
          \ ignore[misc]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/utils/checkpoint.py\"\
          , line 175, in forward\n    outputs = run_function(*args)\n            \
          \  ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1502, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1511, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/modeling_chatglm.py\"\
          , line 627, in forward\n    attention_outputs = self.attention(\n      \
          \                  ^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1502, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1511, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/modeling_chatglm.py\"\
          , line 445, in forward\n    mixed_raw_layer = self.query_key_value(hidden_states)\n\
          \                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1502, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1511, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/quantization.py\"\
          , line 391, in forward\n    output = W8A16Linear.apply(input, self.weight,\
          \ self.weight_scale, self.weight_bit_width)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/autograd/function.py\"\
          , line 506, in apply\n    return super().apply(*args, **kwargs)  # type:\
          \ ignore[misc]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/quantization.py\"\
          , line 56, in forward\n    weight = extract_weight_to_half(quant_w, scale_w,\
          \ weight_bit_width)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/quantization.py\"\
          , line 274, in extract_weight_to_half\n    func = kernels.int4WeightExtractionHalf\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'NoneType'\
          \ object has no attribute 'int4WeightExtractionHalf'\n</code></pre>\n"
        raw: "1. \u5C1D\u8BD5\u5728 m2 \u4E0A\u5FAE\u8C03 chatglm-6b-int4 \u62A5\u9519\
          \uFF0C\u770B\u8D77\u6765\u662F kernels == None\uFF0C\u5F53\u52A0\u8F7D from\
          \ cpm_kernels.kernels.base import LazyKernelCModule, KernelFunction, round_up\
          \ \u5F02\u5E38\uFF1B\r\n```\r\nTraceback (most recent call last):\r\n  File\
          \ \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/main.py\", line\
          \ 433, in <module>\r\n    main()\r\n  File \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/main.py\"\
          , line 372, in main\r\n    train_result = trainer.train(resume_from_checkpoint=checkpoint)\r\
          \n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\
          \  File \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/trainer.py\"\
          , line 1635, in train\r\n    return inner_training_loop(\r\n           ^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/trainer.py\"\
          , line 1904, in _inner_training_loop\r\n    tr_loss_step = self.training_step(model,\
          \ inputs)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File\
          \ \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/trainer.py\", line\
          \ 2647, in training_step\r\n    loss = self.compute_loss(model, inputs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/trainer.py\"\
          , line 2679, in compute_loss\r\n    outputs = model(**inputs)\r\n      \
          \        ^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1502, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
          /Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1511, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/modeling_chatglm.py\"\
          , line 1190, in forward\r\n    transformer_outputs = self.transformer(\r\
          \n                          ^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1502, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
          /Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1511, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/modeling_chatglm.py\"\
          , line 985, in forward\r\n    layer_ret = torch.utils.checkpoint.checkpoint(\r\
          \n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/utils/checkpoint.py\"\
          , line 356, in checkpoint\r\n    return CheckpointFunction.apply(function,\
          \ preserve, *args)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/autograd/function.py\"\
          , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type:\
          \ ignore[misc]\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
          /Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/utils/checkpoint.py\"\
          , line 175, in forward\r\n    outputs = run_function(*args)\r\n        \
          \      ^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1502, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
          /Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1511, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/modeling_chatglm.py\"\
          , line 627, in forward\r\n    attention_outputs = self.attention(\r\n  \
          \                      ^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1502, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
          /Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1511, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/modeling_chatglm.py\"\
          , line 445, in forward\r\n    mixed_raw_layer = self.query_key_value(hidden_states)\r\
          \n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
          /Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1502, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
          /Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1511, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/quantization.py\"\
          , line 391, in forward\r\n    output = W8A16Linear.apply(input, self.weight,\
          \ self.weight_scale, self.weight_bit_width)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/autograd/function.py\"\
          , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type:\
          \ ignore[misc]\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
          /Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/quantization.py\"\
          , line 56, in forward\r\n    weight = extract_weight_to_half(quant_w, scale_w,\
          \ weight_bit_width)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/quantization.py\"\
          , line 274, in extract_weight_to_half\r\n    func = kernels.int4WeightExtractionHalf\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'NoneType'\
          \ object has no attribute 'int4WeightExtractionHalf'\r\n```"
        updatedAt: '2023-05-09T14:11:42.758Z'
      numEdits: 0
      reactions: []
    id: 645a549e1a2421208143e366
    type: comment
  author: xiao111
  content: "1. \u5C1D\u8BD5\u5728 m2 \u4E0A\u5FAE\u8C03 chatglm-6b-int4 \u62A5\u9519\
    \uFF0C\u770B\u8D77\u6765\u662F kernels == None\uFF0C\u5F53\u52A0\u8F7D from cpm_kernels.kernels.base\
    \ import LazyKernelCModule, KernelFunction, round_up \u5F02\u5E38\uFF1B\r\n```\r\
    \nTraceback (most recent call last):\r\n  File \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/main.py\"\
    , line 433, in <module>\r\n    main()\r\n  File \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/main.py\"\
    , line 372, in main\r\n    train_result = trainer.train(resume_from_checkpoint=checkpoint)\r\
    \n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File\
    \ \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/trainer.py\", line 1635,\
    \ in train\r\n    return inner_training_loop(\r\n           ^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/trainer.py\", line\
    \ 1904, in _inner_training_loop\r\n    tr_loss_step = self.training_step(model,\
    \ inputs)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
    /Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/trainer.py\", line 2647, in\
    \ training_step\r\n    loss = self.compute_loss(model, inputs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"/Users/diaojunxian/Documents/agi/ChatGLM-6B/ptuning/trainer.py\", line\
    \ 2679, in compute_loss\r\n    outputs = model(**inputs)\r\n              ^^^^^^^^^^^^^^^\r\
    \n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1502, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1511, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n   \
    \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/modeling_chatglm.py\"\
    , line 1190, in forward\r\n    transformer_outputs = self.transformer(\r\n   \
    \                       ^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1502, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1511, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n   \
    \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/modeling_chatglm.py\"\
    , line 985, in forward\r\n    layer_ret = torch.utils.checkpoint.checkpoint(\r\
    \n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/utils/checkpoint.py\"\
    , line 356, in checkpoint\r\n    return CheckpointFunction.apply(function, preserve,\
    \ *args)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\
    \  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/autograd/function.py\"\
    , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/utils/checkpoint.py\"\
    , line 175, in forward\r\n    outputs = run_function(*args)\r\n              ^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1502, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1511, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n   \
    \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/modeling_chatglm.py\"\
    , line 627, in forward\r\n    attention_outputs = self.attention(\r\n        \
    \                ^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1502, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1511, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n   \
    \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/modeling_chatglm.py\"\
    , line 445, in forward\r\n    mixed_raw_layer = self.query_key_value(hidden_states)\r\
    \n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1502, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1511, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n   \
    \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/quantization.py\"\
    , line 391, in forward\r\n    output = W8A16Linear.apply(input, self.weight, self.weight_scale,\
    \ self.weight_bit_width)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"/Users/diaojunxian/anaconda3/envs/py3.11/lib/python3.11/site-packages/torch/autograd/function.py\"\
    , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/quantization.py\"\
    , line 56, in forward\r\n    weight = extract_weight_to_half(quant_w, scale_w,\
    \ weight_bit_width)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"/Users/diaojunxian/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4/quantization.py\"\
    , line 274, in extract_weight_to_half\r\n    func = kernels.int4WeightExtractionHalf\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'NoneType' object\
    \ has no attribute 'int4WeightExtractionHalf'\r\n```"
  created_at: 2023-05-09 13:11:42+00:00
  edited: false
  hidden: false
  id: 645a549e1a2421208143e366
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/83a709bf11204e3c79126c006cbed5a8.svg
      fullname: Colin Ye
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ColinYeee
      type: user
    createdAt: '2023-06-08T07:47:33.000Z'
    data:
      edited: false
      editors:
      - ColinYeee
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9871212244033813
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/83a709bf11204e3c79126c006cbed5a8.svg
          fullname: Colin Ye
          isHf: false
          isPro: false
          name: ColinYeee
          type: user
        html: "<p>\u5728M1\uFF0Cpython=3.8.16\u8C03\u8BD5\u4E0A\u9762\u9047\u5230\u540C\
          \u6837\u7684\u95EE\u9898\uFF0C\u53D1\u751F\u5728\u63A8\u7406\u7684\u73AF\
          \u8282\u3002\u5728\u5176\u4ED6\u5730\u65B9\u770B\u5230\u8BF4\u662FN\u5361\
          \u7B97\u529B\u4E0D\u591F\uFF0C\u4F46\u6211\u7528\u7684\u662Fmps\uFF0C\u96BE\
          \u9053\u4E5F\u662F\u7B97\u529B\u4E0D\u591F\u5F15\u8D77\u7684</p>\n"
        raw: "\u5728M1\uFF0Cpython=3.8.16\u8C03\u8BD5\u4E0A\u9762\u9047\u5230\u540C\
          \u6837\u7684\u95EE\u9898\uFF0C\u53D1\u751F\u5728\u63A8\u7406\u7684\u73AF\
          \u8282\u3002\u5728\u5176\u4ED6\u5730\u65B9\u770B\u5230\u8BF4\u662FN\u5361\
          \u7B97\u529B\u4E0D\u591F\uFF0C\u4F46\u6211\u7528\u7684\u662Fmps\uFF0C\u96BE\
          \u9053\u4E5F\u662F\u7B97\u529B\u4E0D\u591F\u5F15\u8D77\u7684"
        updatedAt: '2023-06-08T07:47:33.083Z'
      numEdits: 0
      reactions: []
    id: 64818795722e358ebf833c77
    type: comment
  author: ColinYeee
  content: "\u5728M1\uFF0Cpython=3.8.16\u8C03\u8BD5\u4E0A\u9762\u9047\u5230\u540C\u6837\
    \u7684\u95EE\u9898\uFF0C\u53D1\u751F\u5728\u63A8\u7406\u7684\u73AF\u8282\u3002\
    \u5728\u5176\u4ED6\u5730\u65B9\u770B\u5230\u8BF4\u662FN\u5361\u7B97\u529B\u4E0D\
    \u591F\uFF0C\u4F46\u6211\u7528\u7684\u662Fmps\uFF0C\u96BE\u9053\u4E5F\u662F\u7B97\
    \u529B\u4E0D\u591F\u5F15\u8D77\u7684"
  created_at: 2023-06-08 06:47:33+00:00
  edited: false
  hidden: false
  id: 64818795722e358ebf833c77
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8ddcd18bca58cf2fc217c35fba261948.svg
      fullname: junxian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xiao111
      type: user
    createdAt: '2023-06-08T14:16:21.000Z'
    data:
      edited: false
      editors:
      - xiao111
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9972906708717346
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8ddcd18bca58cf2fc217c35fba261948.svg
          fullname: junxian
          isHf: false
          isPro: false
          name: xiao111
          type: user
        html: "<blockquote>\n<p>\u5728M1\uFF0Cpython=3.8.16\u8C03\u8BD5\u4E0A\u9762\
          \u9047\u5230\u540C\u6837\u7684\u95EE\u9898\uFF0C\u53D1\u751F\u5728\u63A8\
          \u7406\u7684\u73AF\u8282\u3002\u5728\u5176\u4ED6\u5730\u65B9\u770B\u5230\
          \u8BF4\u662FN\u5361\u7B97\u529B\u4E0D\u591F\uFF0C\u4F46\u6211\u7528\u7684\
          \u662Fmps\uFF0C\u96BE\u9053\u4E5F\u662F\u7B97\u529B\u4E0D\u591F\u5F15\u8D77\
          \u7684</p>\n</blockquote>\n<p>\u4E0D\u662F\u7684\uFF0C\u662F\u56E0\u4E3A\
          \u672C\u8EAB\u8BBE\u7F6E\u7684\u95EE\u9898\u8D70\u5230\u4E86 cuda \u8FD9\
          \u4E2Aelse \u5206\u652F\uFF0C\u7528 cpu \u8BAD\u7EC3\u770B\u770B\uFF1B</p>\n"
        raw: "> \u5728M1\uFF0Cpython=3.8.16\u8C03\u8BD5\u4E0A\u9762\u9047\u5230\u540C\
          \u6837\u7684\u95EE\u9898\uFF0C\u53D1\u751F\u5728\u63A8\u7406\u7684\u73AF\
          \u8282\u3002\u5728\u5176\u4ED6\u5730\u65B9\u770B\u5230\u8BF4\u662FN\u5361\
          \u7B97\u529B\u4E0D\u591F\uFF0C\u4F46\u6211\u7528\u7684\u662Fmps\uFF0C\u96BE\
          \u9053\u4E5F\u662F\u7B97\u529B\u4E0D\u591F\u5F15\u8D77\u7684\n\n\u4E0D\u662F\
          \u7684\uFF0C\u662F\u56E0\u4E3A\u672C\u8EAB\u8BBE\u7F6E\u7684\u95EE\u9898\
          \u8D70\u5230\u4E86 cuda \u8FD9\u4E2Aelse \u5206\u652F\uFF0C\u7528 cpu \u8BAD\
          \u7EC3\u770B\u770B\uFF1B"
        updatedAt: '2023-06-08T14:16:21.740Z'
      numEdits: 0
      reactions: []
    id: 6481e2b515c5dc529069c58d
    type: comment
  author: xiao111
  content: "> \u5728M1\uFF0Cpython=3.8.16\u8C03\u8BD5\u4E0A\u9762\u9047\u5230\u540C\
    \u6837\u7684\u95EE\u9898\uFF0C\u53D1\u751F\u5728\u63A8\u7406\u7684\u73AF\u8282\
    \u3002\u5728\u5176\u4ED6\u5730\u65B9\u770B\u5230\u8BF4\u662FN\u5361\u7B97\u529B\
    \u4E0D\u591F\uFF0C\u4F46\u6211\u7528\u7684\u662Fmps\uFF0C\u96BE\u9053\u4E5F\u662F\
    \u7B97\u529B\u4E0D\u591F\u5F15\u8D77\u7684\n\n\u4E0D\u662F\u7684\uFF0C\u662F\u56E0\
    \u4E3A\u672C\u8EAB\u8BBE\u7F6E\u7684\u95EE\u9898\u8D70\u5230\u4E86 cuda \u8FD9\
    \u4E2Aelse \u5206\u652F\uFF0C\u7528 cpu \u8BAD\u7EC3\u770B\u770B\uFF1B"
  created_at: 2023-06-08 13:16:21+00:00
  edited: false
  hidden: false
  id: 6481e2b515c5dc529069c58d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: THUDM/chatglm-6b-int4
repo_type: model
status: open
target_branch: null
title: "mac M2 \u4E0A\u5C1D\u8BD5\u5FAE\u8C03  chatglm-6b-int4 \u5931\u8D25"
