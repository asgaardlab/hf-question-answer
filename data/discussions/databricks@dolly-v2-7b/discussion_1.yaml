!!python/object:huggingface_hub.community.DiscussionWithDetails
author: JakubKubajek
conflicting_files: null
created_at: 2023-04-13 08:10:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1616186510095-noauth.jpeg?w=200&h=200&f=face
      fullname: Jakub Kubajek
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JakubKubajek
      type: user
    createdAt: '2023-04-13T09:10:34.000Z'
    data:
      edited: false
      editors:
      - JakubKubajek
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1616186510095-noauth.jpeg?w=200&h=200&f=face
          fullname: Jakub Kubajek
          isHf: false
          isPro: false
          name: JakubKubajek
          type: user
        html: '<p>Hi,<br>thank you for the great work you did with the model. I just
          started testing it and I got one strange outcome. I told the model (dolly-v2-6-9b)
          to summarize the abstract of one scientific article and in the first try
          it just copy-pasted it. The second output is correct, however, I wanted
          to share with you the first outcome as it is the potential bug and limitation.</p>

          <p>Prompt:<br><code>"Summarize the following abstract of the scientific
          article: Recently, diffusion models have emerged as a new paradigm for generative
          models. Despite the success in domains using continuous signals such as
          vision and audio, adapting diffusion models to natural language is under-explored
          due to the discrete nature of texts, especially for conditional generation.
          We tackle this challenge by proposing DiffuSeq: a diffusion model designed
          for sequence-to-sequence (Seq2Seq) text generation tasks. Upon extensive
          evaluation over a wide range of Seq2Seq tasks, we find DiffuSeq achieving
          comparable or even better performance than six established baselines, including
          a state-of-the-art model that is based on pre-trained language models. Apart
          from quality, an intriguing property of DiffuSeq is its high diversity during
          generation, which is desired in many Seq2Seq tasks. We further include a
          theoretical analysis revealing the connection between DiffuSeq and autoregressive/non-autoregressive
          models. Bringing together theoretical analysis and empirical evidence, we
          demonstrate the great potential of diffusion models in complex conditional
          language generation tasks."</code></p>

          <p>First Output:<br><code>"Recently, diffusion models have emerged as a
          new paradigm for generative models. Despite the success in domains using
          continuous signals such as vision and audio, adapting diffusion models to
          natural language is under-explored due to the discrete nature of texts,
          especially for conditional generation.\nWe tackle this challenge by proposing
          DiffuSeq: a diffusion model designed for sequence-to-sequence (Seq2Seq)
          text generation tasks. Upon extensive evaluation over a wide range of Seq2Seq
          tasks, we find DiffuSeq achieving comparable or even better performance
          than six established baselines, including a state-of-the-art model that
          is based on pre-trained language models. Apart from quality, an intriguing
          property of DiffuSeq is its high diversity during generation, which is desired
          in many Seq2Seq tasks. We further include a theoretical analysis revealing
          the connection between DiffuSeq and autoregressive/non-autoregressive models.
          Bringing together theoretical analysis and empirical evidence, we demonstrate
          the great potential of diffusion models in complex conditional language
          generation tasks."</code></p>

          <p>Second Output:<br><code>"This paper proposes DiffuSeq, a new diffusion
          model for sequence to sequence (Seq2Seq) text generation tasks. It shows
          that DiffuSeq achieves competitive performance compared to the state-of-the-art
          model on several benchmarks. In addition, the analysis provides a new insight
          on the connection between DiffuSeq and autoregressive/non-autoregressive
          models."</code></p>

          '
        raw: "Hi,\r\nthank you for the great work you did with the model. I just started\
          \ testing it and I got one strange outcome. I told the model (dolly-v2-6-9b)\
          \ to summarize the abstract of one scientific article and in the first try\
          \ it just copy-pasted it. The second output is correct, however, I wanted\
          \ to share with you the first outcome as it is the potential bug and limitation.\r\
          \n\r\nPrompt: \r\n```\"Summarize the following abstract of the scientific\
          \ article: Recently, diffusion models have emerged as a new paradigm for\
          \ generative models. Despite the success in domains using continuous signals\
          \ such as vision and audio, adapting diffusion models to natural language\
          \ is under-explored due to the discrete nature of texts, especially for\
          \ conditional generation. We tackle this challenge by proposing DiffuSeq:\
          \ a diffusion model designed for sequence-to-sequence (Seq2Seq) text generation\
          \ tasks. Upon extensive evaluation over a wide range of Seq2Seq tasks, we\
          \ find DiffuSeq achieving comparable or even better performance than six\
          \ established baselines, including a state-of-the-art model that is based\
          \ on pre-trained language models. Apart from quality, an intriguing property\
          \ of DiffuSeq is its high diversity during generation, which is desired\
          \ in many Seq2Seq tasks. We further include a theoretical analysis revealing\
          \ the connection between DiffuSeq and autoregressive/non-autoregressive\
          \ models. Bringing together theoretical analysis and empirical evidence,\
          \ we demonstrate the great potential of diffusion models in complex conditional\
          \ language generation tasks.\"```\r\n\r\nFirst Output: \r\n```\"Recently,\
          \ diffusion models have emerged as a new paradigm for generative models.\
          \ Despite the success in domains using continuous signals such as vision\
          \ and audio, adapting diffusion models to natural language is under-explored\
          \ due to the discrete nature of texts, especially for conditional generation.\\\
          nWe tackle this challenge by proposing DiffuSeq: a diffusion model designed\
          \ for sequence-to-sequence (Seq2Seq) text generation tasks. Upon extensive\
          \ evaluation over a wide range of Seq2Seq tasks, we find DiffuSeq achieving\
          \ comparable or even better performance than six established baselines,\
          \ including a state-of-the-art model that is based on pre-trained language\
          \ models. Apart from quality, an intriguing property of DiffuSeq is its\
          \ high diversity during generation, which is desired in many Seq2Seq tasks.\
          \ We further include a theoretical analysis revealing the connection between\
          \ DiffuSeq and autoregressive/non-autoregressive models. Bringing together\
          \ theoretical analysis and empirical evidence, we demonstrate the great\
          \ potential of diffusion models in complex conditional language generation\
          \ tasks.\"```\r\n\r\nSecond Output: \r\n```\"This paper proposes DiffuSeq,\
          \ a new diffusion model for sequence to sequence (Seq2Seq) text generation\
          \ tasks. It shows that DiffuSeq achieves competitive performance compared\
          \ to the state-of-the-art model on several benchmarks. In addition, the\
          \ analysis provides a new insight on the connection between DiffuSeq and\
          \ autoregressive/non-autoregressive models.\"```"
        updatedAt: '2023-04-13T09:10:34.406Z'
      numEdits: 0
      reactions: []
    id: 6437c70a51c7ebfc813c1e01
    type: comment
  author: JakubKubajek
  content: "Hi,\r\nthank you for the great work you did with the model. I just started\
    \ testing it and I got one strange outcome. I told the model (dolly-v2-6-9b) to\
    \ summarize the abstract of one scientific article and in the first try it just\
    \ copy-pasted it. The second output is correct, however, I wanted to share with\
    \ you the first outcome as it is the potential bug and limitation.\r\n\r\nPrompt:\
    \ \r\n```\"Summarize the following abstract of the scientific article: Recently,\
    \ diffusion models have emerged as a new paradigm for generative models. Despite\
    \ the success in domains using continuous signals such as vision and audio, adapting\
    \ diffusion models to natural language is under-explored due to the discrete nature\
    \ of texts, especially for conditional generation. We tackle this challenge by\
    \ proposing DiffuSeq: a diffusion model designed for sequence-to-sequence (Seq2Seq)\
    \ text generation tasks. Upon extensive evaluation over a wide range of Seq2Seq\
    \ tasks, we find DiffuSeq achieving comparable or even better performance than\
    \ six established baselines, including a state-of-the-art model that is based\
    \ on pre-trained language models. Apart from quality, an intriguing property of\
    \ DiffuSeq is its high diversity during generation, which is desired in many Seq2Seq\
    \ tasks. We further include a theoretical analysis revealing the connection between\
    \ DiffuSeq and autoregressive/non-autoregressive models. Bringing together theoretical\
    \ analysis and empirical evidence, we demonstrate the great potential of diffusion\
    \ models in complex conditional language generation tasks.\"```\r\n\r\nFirst Output:\
    \ \r\n```\"Recently, diffusion models have emerged as a new paradigm for generative\
    \ models. Despite the success in domains using continuous signals such as vision\
    \ and audio, adapting diffusion models to natural language is under-explored due\
    \ to the discrete nature of texts, especially for conditional generation.\\nWe\
    \ tackle this challenge by proposing DiffuSeq: a diffusion model designed for\
    \ sequence-to-sequence (Seq2Seq) text generation tasks. Upon extensive evaluation\
    \ over a wide range of Seq2Seq tasks, we find DiffuSeq achieving comparable or\
    \ even better performance than six established baselines, including a state-of-the-art\
    \ model that is based on pre-trained language models. Apart from quality, an intriguing\
    \ property of DiffuSeq is its high diversity during generation, which is desired\
    \ in many Seq2Seq tasks. We further include a theoretical analysis revealing the\
    \ connection between DiffuSeq and autoregressive/non-autoregressive models. Bringing\
    \ together theoretical analysis and empirical evidence, we demonstrate the great\
    \ potential of diffusion models in complex conditional language generation tasks.\"\
    ```\r\n\r\nSecond Output: \r\n```\"This paper proposes DiffuSeq, a new diffusion\
    \ model for sequence to sequence (Seq2Seq) text generation tasks. It shows that\
    \ DiffuSeq achieves competitive performance compared to the state-of-the-art model\
    \ on several benchmarks. In addition, the analysis provides a new insight on the\
    \ connection between DiffuSeq and autoregressive/non-autoregressive models.\"\
    ```"
  created_at: 2023-04-13 08:10:34+00:00
  edited: false
  hidden: false
  id: 6437c70a51c7ebfc813c1e01
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1616186510095-noauth.jpeg?w=200&h=200&f=face
      fullname: Jakub Kubajek
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JakubKubajek
      type: user
    createdAt: '2023-04-13T09:33:15.000Z'
    data:
      edited: false
      editors:
      - JakubKubajek
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1616186510095-noauth.jpeg?w=200&h=200&f=face
          fullname: Jakub Kubajek
          isHf: false
          isPro: false
          name: JakubKubajek
          type: user
        html: '<p>I do further experiments (now with summarization of multiple film
          reviews) and this tendency of the model to copy-paste parts of the input
          is clearly visible. I guess that your dataset may have multiple examples
          of summaries where people to provide more examples just copy-pasted parts
          of the input that seemed the most relevant instead of writing a true abstractive
          summary.</p>

          '
        raw: I do further experiments (now with summarization of multiple film reviews)
          and this tendency of the model to copy-paste parts of the input is clearly
          visible. I guess that your dataset may have multiple examples of summaries
          where people to provide more examples just copy-pasted parts of the input
          that seemed the most relevant instead of writing a true abstractive summary.
        updatedAt: '2023-04-13T09:33:15.479Z'
      numEdits: 0
      reactions: []
    id: 6437cc5b6227bd68299c499c
    type: comment
  author: JakubKubajek
  content: I do further experiments (now with summarization of multiple film reviews)
    and this tendency of the model to copy-paste parts of the input is clearly visible.
    I guess that your dataset may have multiple examples of summaries where people
    to provide more examples just copy-pasted parts of the input that seemed the most
    relevant instead of writing a true abstractive summary.
  created_at: 2023-04-13 08:33:15+00:00
  edited: false
  hidden: false
  id: 6437cc5b6227bd68299c499c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
      fullname: Matthew Hayes
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: matthayes
      type: user
    createdAt: '2023-04-13T15:42:26.000Z'
    data:
      edited: false
      editors:
      - matthayes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
          fullname: Matthew Hayes
          isHf: false
          isPro: false
          name: matthayes
          type: user
        html: '<p>Hey thanks for reporting this. I can try some experiments. Can you
          also try formatting the prompt like this?</p>

          <pre><code>instruction


          Input:

          &lt;context goes here&gt;

          </code></pre>

          <p>This is how the model was trained when there was context usually.</p>

          '
        raw: 'Hey thanks for reporting this. I can try some experiments. Can you also
          try formatting the prompt like this?


          ```

          instruction


          Input:

          <context goes here>

          ```


          This is how the model was trained when there was context usually.'
        updatedAt: '2023-04-13T15:42:26.005Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - AayushShah
      - count: 1
        reaction: "\U0001F44D"
        users:
        - AayushShah
    id: 643822e26227bd68299f1ba4
    type: comment
  author: matthayes
  content: 'Hey thanks for reporting this. I can try some experiments. Can you also
    try formatting the prompt like this?


    ```

    instruction


    Input:

    <context goes here>

    ```


    This is how the model was trained when there was context usually.'
  created_at: 2023-04-13 14:42:26+00:00
  edited: false
  hidden: false
  id: 643822e26227bd68299f1ba4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
      fullname: Matthew Hayes
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: matthayes
      type: user
    createdAt: '2023-04-17T19:51:28.000Z'
    data:
      edited: false
      editors:
      - matthayes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
          fullname: Matthew Hayes
          isHf: false
          isPro: false
          name: matthayes
          type: user
        html: "<p>I updated the pipeline code and also updated the model card with\
          \ new example, including how to use the pipeline with LangChain.  You might\
          \ find this easier to use.  You can follow the model card for how to create\
          \ the <code>llm_context_chain</code> I use below.  I did some tests with\
          \ your example and also found the 7b tends to repeats or restates the text\
          \ slightly differently.  This could mean there is underrepresentation of\
          \ summarization examples in the training data.  The <code>dolly-v2-12b</code>\
          \ model seems to do a better job at this.  Maybe a larger model is needed\
          \ for this type of task.</p>\n<pre><code>context = \"\"\"Recently, diffusion\
          \ models have emerged as a new paradigm for generative models. Despite the\
          \ success in domains using continuous signals such as vision and audio,\
          \ adapting diffusion models to natural language is under-explored due to\
          \ the discrete nature of texts, especially for conditional generation. We\
          \ tackle this challenge by proposing DiffuSeq: a diffusion model designed\
          \ for sequence-to-sequence (Seq2Seq) text generation tasks. Upon extensive\
          \ evaluation over a wide range of Seq2Seq tasks, we find DiffuSeq achieving\
          \ comparable or even better performance than six established baselines,\
          \ including a state-of-the-art model that is based on pre-trained language\
          \ models. Apart from quality, an intriguing property of DiffuSeq is its\
          \ high diversity during generation, which is desired in many Seq2Seq tasks.\
          \ We further include a theoretical analysis revealing the connection between\
          \ DiffuSeq and autoregressive/non-autoregressive models. Bringing together\
          \ theoretical analysis and empirical evidence, we demonstrate the great\
          \ potential of diffusion models in complex conditional language generation\
          \ tasks.\"\"\"\n\nfor _ in range(3):\n  print(llm_context_chain.predict(instruction=\"\
          Summarize the following abstract of the scientific article\", context=context).lstrip())\n\
          \  print(\"=========\")\n</code></pre>\n<p>Samples from 12b model:</p>\n\
          <pre><code>DiffuSeq is a conditional text generation model that adapts diffusion\
          \ models to discrete signals such as text. DiffuSeq achieves comparable\
          \ or even better performance than several baselines on a wide range of Seq2Seq\
          \ tasks. An intriguing property of DiffuSeq is its high diversity during\
          \ generation, which is desired in many Seq2Seq tasks.\n=========\nDiffuSeq\
          \ is a diffusion model designed for sequence-to-sequence (Seq2Seq) text\
          \ generation tasks. To the best of our knowledge, it is the first end-to-end\
          \ diffusive model trained from scratch for this task. We conduct extensive\
          \ experiments on a wide range of Seq2Seq tasks and find that DiffuSeq outperforms\
          \ six strong baselines and even a state-of-the-art model based on pre-trained\
          \ language models on all the evaluated metrics. A interesting property of\
          \ DiffuSeq is its high diversity during generation, which is desired in\
          \ many Seq2Seq tasks. We further provide a theoretical analysis that reveals\
          \ the connection between DiffuSeq and autoregressive/non-autoregressive\
          \ models and show that DiffuSeq is capable of producing more diverse and\
          \ better quality responses compared with the previous models by including\
          \ additional priors.\n=========\nDiffuSeq is a diffusion model designed\
          \ for sequence-to-sequence text generation tasks. It achieves comparable\
          \ or even better performance than six established baselines on a number\
          \ of Seq2Seq tasks. Extensive experiments demonstrate that DiffuSeq generates\
          \ text with high diversity, which is desired in many Seq2Seq tasks.\n=========\n\
          DiffuSeq is a sequence-to-sequence text generation model that is based on\
          \ the diffusion model. It has comparable or even better performance than\
          \ several state-of-the-art models on a wide range of text generation tasks.\
          \ The model achieves this performance through including a theoretical analysis\
          \ that reveals the model is a kind of autoregressive model. In addition,\
          \ the model also has a quality property that is desired in many text generation\
          \ tasks.\n=========\nA new sequence to sequence text generation model, DiffuSeq,\
          \ is proposed that achieves comparable or better performance than established\
          \ baselines on a number of text generation tasks. The model is shown to\
          \ achieve this performance through sharing the same variationallower bound\
          \ from the VELA framework, however, the input and output codewords are represented\
          \ as independent diffusion processes, allowing the model to capture the\
          \ discrete nature of text, especially for conditional generation. The model\
          \ is shown to have a intuitive connection to both autoregressive models\
          \ and non-autoregressive models, and analysis of the model can be used to\
          \ explain empirical results on the performance of the model.\n=========\n\
          DiffuSeq is a neural network model achieving comparable or better performance\
          \ than six state-of-the-art Seq2Seq models on a range of Seq2Seq tasks.\
          \ The DiffuSeq model is a diffusion model, which can generate sequences\
          \ by propagating a token in a one-step discrete manner. The model is evaluated\
          \ on a dataset with a wide range of Seq2Seq tasks including summarization,\
          \ question answering, recommendation, and language generation. The analysis\
          \ reveals that the DiffuSeq model is related to autoregressive/non-autoregressive\
          \ models, and the theory can help understand the empirical results of the\
          \ model.\n=========\n</code></pre>\n"
        raw: "I updated the pipeline code and also updated the model card with new\
          \ example, including how to use the pipeline with LangChain.  You might\
          \ find this easier to use.  You can follow the model card for how to create\
          \ the `llm_context_chain` I use below.  I did some tests with your example\
          \ and also found the 7b tends to repeats or restates the text slightly differently.\
          \  This could mean there is underrepresentation of summarization examples\
          \ in the training data.  The `dolly-v2-12b` model seems to do a better job\
          \ at this.  Maybe a larger model is needed for this type of task.\n\n```\n\
          context = \"\"\"Recently, diffusion models have emerged as a new paradigm\
          \ for generative models. Despite the success in domains using continuous\
          \ signals such as vision and audio, adapting diffusion models to natural\
          \ language is under-explored due to the discrete nature of texts, especially\
          \ for conditional generation. We tackle this challenge by proposing DiffuSeq:\
          \ a diffusion model designed for sequence-to-sequence (Seq2Seq) text generation\
          \ tasks. Upon extensive evaluation over a wide range of Seq2Seq tasks, we\
          \ find DiffuSeq achieving comparable or even better performance than six\
          \ established baselines, including a state-of-the-art model that is based\
          \ on pre-trained language models. Apart from quality, an intriguing property\
          \ of DiffuSeq is its high diversity during generation, which is desired\
          \ in many Seq2Seq tasks. We further include a theoretical analysis revealing\
          \ the connection between DiffuSeq and autoregressive/non-autoregressive\
          \ models. Bringing together theoretical analysis and empirical evidence,\
          \ we demonstrate the great potential of diffusion models in complex conditional\
          \ language generation tasks.\"\"\"\n\nfor _ in range(3):\n  print(llm_context_chain.predict(instruction=\"\
          Summarize the following abstract of the scientific article\", context=context).lstrip())\n\
          \  print(\"=========\")\n```\n\nSamples from 12b model:\n\n```\nDiffuSeq\
          \ is a conditional text generation model that adapts diffusion models to\
          \ discrete signals such as text. DiffuSeq achieves comparable or even better\
          \ performance than several baselines on a wide range of Seq2Seq tasks. An\
          \ intriguing property of DiffuSeq is its high diversity during generation,\
          \ which is desired in many Seq2Seq tasks.\n=========\nDiffuSeq is a diffusion\
          \ model designed for sequence-to-sequence (Seq2Seq) text generation tasks.\
          \ To the best of our knowledge, it is the first end-to-end diffusive model\
          \ trained from scratch for this task. We conduct extensive experiments on\
          \ a wide range of Seq2Seq tasks and find that DiffuSeq outperforms six strong\
          \ baselines and even a state-of-the-art model based on pre-trained language\
          \ models on all the evaluated metrics. A interesting property of DiffuSeq\
          \ is its high diversity during generation, which is desired in many Seq2Seq\
          \ tasks. We further provide a theoretical analysis that reveals the connection\
          \ between DiffuSeq and autoregressive/non-autoregressive models and show\
          \ that DiffuSeq is capable of producing more diverse and better quality\
          \ responses compared with the previous models by including additional priors.\n\
          =========\nDiffuSeq is a diffusion model designed for sequence-to-sequence\
          \ text generation tasks. It achieves comparable or even better performance\
          \ than six established baselines on a number of Seq2Seq tasks. Extensive\
          \ experiments demonstrate that DiffuSeq generates text with high diversity,\
          \ which is desired in many Seq2Seq tasks.\n=========\nDiffuSeq is a sequence-to-sequence\
          \ text generation model that is based on the diffusion model. It has comparable\
          \ or even better performance than several state-of-the-art models on a wide\
          \ range of text generation tasks. The model achieves this performance through\
          \ including a theoretical analysis that reveals the model is a kind of autoregressive\
          \ model. In addition, the model also has a quality property that is desired\
          \ in many text generation tasks.\n=========\nA new sequence to sequence\
          \ text generation model, DiffuSeq, is proposed that achieves comparable\
          \ or better performance than established baselines on a number of text generation\
          \ tasks. The model is shown to achieve this performance through sharing\
          \ the same variationallower bound from the VELA framework, however, the\
          \ input and output codewords are represented as independent diffusion processes,\
          \ allowing the model to capture the discrete nature of text, especially\
          \ for conditional generation. The model is shown to have a intuitive connection\
          \ to both autoregressive models and non-autoregressive models, and analysis\
          \ of the model can be used to explain empirical results on the performance\
          \ of the model.\n=========\nDiffuSeq is a neural network model achieving\
          \ comparable or better performance than six state-of-the-art Seq2Seq models\
          \ on a range of Seq2Seq tasks. The DiffuSeq model is a diffusion model,\
          \ which can generate sequences by propagating a token in a one-step discrete\
          \ manner. The model is evaluated on a dataset with a wide range of Seq2Seq\
          \ tasks including summarization, question answering, recommendation, and\
          \ language generation. The analysis reveals that the DiffuSeq model is related\
          \ to autoregressive/non-autoregressive models, and the theory can help understand\
          \ the empirical results of the model.\n=========\n```"
        updatedAt: '2023-04-17T19:51:28.394Z'
      numEdits: 0
      reactions: []
    id: 643da34051e2958ef6ce0ab7
    type: comment
  author: matthayes
  content: "I updated the pipeline code and also updated the model card with new example,\
    \ including how to use the pipeline with LangChain.  You might find this easier\
    \ to use.  You can follow the model card for how to create the `llm_context_chain`\
    \ I use below.  I did some tests with your example and also found the 7b tends\
    \ to repeats or restates the text slightly differently.  This could mean there\
    \ is underrepresentation of summarization examples in the training data.  The\
    \ `dolly-v2-12b` model seems to do a better job at this.  Maybe a larger model\
    \ is needed for this type of task.\n\n```\ncontext = \"\"\"Recently, diffusion\
    \ models have emerged as a new paradigm for generative models. Despite the success\
    \ in domains using continuous signals such as vision and audio, adapting diffusion\
    \ models to natural language is under-explored due to the discrete nature of texts,\
    \ especially for conditional generation. We tackle this challenge by proposing\
    \ DiffuSeq: a diffusion model designed for sequence-to-sequence (Seq2Seq) text\
    \ generation tasks. Upon extensive evaluation over a wide range of Seq2Seq tasks,\
    \ we find DiffuSeq achieving comparable or even better performance than six established\
    \ baselines, including a state-of-the-art model that is based on pre-trained language\
    \ models. Apart from quality, an intriguing property of DiffuSeq is its high diversity\
    \ during generation, which is desired in many Seq2Seq tasks. We further include\
    \ a theoretical analysis revealing the connection between DiffuSeq and autoregressive/non-autoregressive\
    \ models. Bringing together theoretical analysis and empirical evidence, we demonstrate\
    \ the great potential of diffusion models in complex conditional language generation\
    \ tasks.\"\"\"\n\nfor _ in range(3):\n  print(llm_context_chain.predict(instruction=\"\
    Summarize the following abstract of the scientific article\", context=context).lstrip())\n\
    \  print(\"=========\")\n```\n\nSamples from 12b model:\n\n```\nDiffuSeq is a\
    \ conditional text generation model that adapts diffusion models to discrete signals\
    \ such as text. DiffuSeq achieves comparable or even better performance than several\
    \ baselines on a wide range of Seq2Seq tasks. An intriguing property of DiffuSeq\
    \ is its high diversity during generation, which is desired in many Seq2Seq tasks.\n\
    =========\nDiffuSeq is a diffusion model designed for sequence-to-sequence (Seq2Seq)\
    \ text generation tasks. To the best of our knowledge, it is the first end-to-end\
    \ diffusive model trained from scratch for this task. We conduct extensive experiments\
    \ on a wide range of Seq2Seq tasks and find that DiffuSeq outperforms six strong\
    \ baselines and even a state-of-the-art model based on pre-trained language models\
    \ on all the evaluated metrics. A interesting property of DiffuSeq is its high\
    \ diversity during generation, which is desired in many Seq2Seq tasks. We further\
    \ provide a theoretical analysis that reveals the connection between DiffuSeq\
    \ and autoregressive/non-autoregressive models and show that DiffuSeq is capable\
    \ of producing more diverse and better quality responses compared with the previous\
    \ models by including additional priors.\n=========\nDiffuSeq is a diffusion model\
    \ designed for sequence-to-sequence text generation tasks. It achieves comparable\
    \ or even better performance than six established baselines on a number of Seq2Seq\
    \ tasks. Extensive experiments demonstrate that DiffuSeq generates text with high\
    \ diversity, which is desired in many Seq2Seq tasks.\n=========\nDiffuSeq is a\
    \ sequence-to-sequence text generation model that is based on the diffusion model.\
    \ It has comparable or even better performance than several state-of-the-art models\
    \ on a wide range of text generation tasks. The model achieves this performance\
    \ through including a theoretical analysis that reveals the model is a kind of\
    \ autoregressive model. In addition, the model also has a quality property that\
    \ is desired in many text generation tasks.\n=========\nA new sequence to sequence\
    \ text generation model, DiffuSeq, is proposed that achieves comparable or better\
    \ performance than established baselines on a number of text generation tasks.\
    \ The model is shown to achieve this performance through sharing the same variationallower\
    \ bound from the VELA framework, however, the input and output codewords are represented\
    \ as independent diffusion processes, allowing the model to capture the discrete\
    \ nature of text, especially for conditional generation. The model is shown to\
    \ have a intuitive connection to both autoregressive models and non-autoregressive\
    \ models, and analysis of the model can be used to explain empirical results on\
    \ the performance of the model.\n=========\nDiffuSeq is a neural network model\
    \ achieving comparable or better performance than six state-of-the-art Seq2Seq\
    \ models on a range of Seq2Seq tasks. The DiffuSeq model is a diffusion model,\
    \ which can generate sequences by propagating a token in a one-step discrete manner.\
    \ The model is evaluated on a dataset with a wide range of Seq2Seq tasks including\
    \ summarization, question answering, recommendation, and language generation.\
    \ The analysis reveals that the DiffuSeq model is related to autoregressive/non-autoregressive\
    \ models, and the theory can help understand the empirical results of the model.\n\
    =========\n```"
  created_at: 2023-04-17 18:51:28+00:00
  edited: false
  hidden: false
  id: 643da34051e2958ef6ce0ab7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
      fullname: Matthew Hayes
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: matthayes
      type: user
    createdAt: '2023-04-17T19:51:53.000Z'
    data:
      edited: false
      editors:
      - matthayes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
          fullname: Matthew Hayes
          isHf: false
          isPro: false
          name: matthayes
          type: user
        html: '<p>I''ll go ahead and close this but take note to look into more summarization
          examples in the future.</p>

          '
        raw: I'll go ahead and close this but take note to look into more summarization
          examples in the future.
        updatedAt: '2023-04-17T19:51:53.977Z'
      numEdits: 0
      reactions: []
      relatedEventId: 643da35946c2cebe83baeb0e
    id: 643da35946c2cebe83baeb0d
    type: comment
  author: matthayes
  content: I'll go ahead and close this but take note to look into more summarization
    examples in the future.
  created_at: 2023-04-17 18:51:53+00:00
  edited: false
  hidden: false
  id: 643da35946c2cebe83baeb0d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
      fullname: Matthew Hayes
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: matthayes
      type: user
    createdAt: '2023-04-17T19:51:53.000Z'
    data:
      status: closed
    id: 643da35946c2cebe83baeb0e
    type: status-change
  author: matthayes
  created_at: 2023-04-17 18:51:53+00:00
  id: 643da35946c2cebe83baeb0e
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1637750401588-noauth.jpeg?w=200&h=200&f=face
      fullname: Daniele Giofre'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dgiofre
      type: user
    createdAt: '2023-05-04T14:20:19.000Z'
    data:
      edited: false
      editors:
      - dgiofre
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1637750401588-noauth.jpeg?w=200&h=200&f=face
          fullname: Daniele Giofre'
          isHf: false
          isPro: false
          name: dgiofre
          type: user
        html: '<blockquote>

          <p>Hey thanks for reporting this. I can try some experiments. Can you also
          try formatting the prompt like this?</p>

          <pre><code>instruction


          Input:

          &lt;context goes here&gt;

          </code></pre>

          <p>This is how the model was trained when there was context usually.</p>

          </blockquote>

          <p>From my experiments, it is even worst.<br>The model response is just
          a continuation of the context text, and the initial part of the output is
          again a copy of the original context tail.</p>

          '
        raw: "> Hey thanks for reporting this. I can try some experiments. Can you\
          \ also try formatting the prompt like this?\n> \n> ```\n> instruction\n\
          > \n> Input:\n> <context goes here>\n> ```\n> \n> This is how the model\
          \ was trained when there was context usually.\n\nFrom my experiments, it\
          \ is even worst. \nThe model response is just a continuation of the context\
          \ text, and the initial part of the output is again a copy of the original\
          \ context tail."
        updatedAt: '2023-05-04T14:20:19.608Z'
      numEdits: 0
      reactions: []
    id: 6453bf2372d331dec8985a29
    type: comment
  author: dgiofre
  content: "> Hey thanks for reporting this. I can try some experiments. Can you also\
    \ try formatting the prompt like this?\n> \n> ```\n> instruction\n> \n> Input:\n\
    > <context goes here>\n> ```\n> \n> This is how the model was trained when there\
    \ was context usually.\n\nFrom my experiments, it is even worst. \nThe model response\
    \ is just a continuation of the context text, and the initial part of the output\
    \ is again a copy of the original context tail."
  created_at: 2023-05-04 13:20:19+00:00
  edited: false
  hidden: false
  id: 6453bf2372d331dec8985a29
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: databricks/dolly-v2-7b
repo_type: model
status: closed
target_branch: null
title: Model copy-pasting input
