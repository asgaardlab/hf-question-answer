!!python/object:huggingface_hub.community.DiscussionWithDetails
author: durapensa
conflicting_files: null
created_at: 2023-04-19 20:16:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/0_3Gtw7AETNrMPPLRKhdk.png?w=200&h=200&f=face
      fullname: durapensa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: durapensa
      type: user
    createdAt: '2023-04-19T21:16:05.000Z'
    data:
      edited: true
      editors:
      - durapensa
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/0_3Gtw7AETNrMPPLRKhdk.png?w=200&h=200&f=face
          fullname: durapensa
          isHf: false
          isPro: false
          name: durapensa
          type: user
        html: '<p>I chose <code>dolly-v2-7b</code> because it should be tuneable using
          a midrange VM w/GPU on GCE, Azure, etc.</p>

          <p>I believe that the example code for fine-tuning the base model <code>Pythia-6.9B</code>
          with <code>databricks_dolly_15k</code> to create <code>dolly-v2-7b</code>
          has not yet been published but I''m experimenting anyway, first with tokenizing
          <code>databricks_dolly_15k</code> before attempting to tokenize my own dataset,
          and likely just need some pointers to the correct tutorial or other resource.</p>

          <p>A snippet of my first experiment:</p>

          <pre><code class="language-python"><span class="hljs-keyword">from</span>
          datasets <span class="hljs-keyword">import</span> load_dataset

          <span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span>
          AutoTokenizer


          dataset = load_dataset(<span class="hljs-string">"HuggingFaceH4/databricks_dolly_15k"</span>,
          split=<span class="hljs-string">"train"</span>)

          tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">"databricks/dolly-v2-7b"</span>)


          dataset[<span class="hljs-number">0</span>][<span class="hljs-string">"instruction"</span>]


          <span class="hljs-string">''When did Virgin Australia start operating?''</span>


          tokenizer(dataset[<span class="hljs-number">0</span>][<span class="hljs-string">"instruction"</span>])


          {<span class="hljs-string">''input_ids''</span>: [<span class="hljs-number">3039</span>,
          <span class="hljs-number">858</span>, <span class="hljs-number">8237</span>,
          <span class="hljs-number">6976</span>, <span class="hljs-number">1265</span>,
          <span class="hljs-number">6498</span>, <span class="hljs-number">32</span>],
          <span class="hljs-string">''attention_mask''</span>: [<span class="hljs-number">1</span>,
          <span class="hljs-number">1</span>, <span class="hljs-number">1</span>,
          <span class="hljs-number">1</span>, <span class="hljs-number">1</span>,
          <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}

          </code></pre>

          <p>What I do not know how to do is tokenize all of the features ''category'',
          ''instruction'', ''input'', ''output'', stitching them together before converting
          to pt format for ingestion by the PyTorch Trainer a la <a href="https://huggingface.co/docs/transformers/training">https://huggingface.co/docs/transformers/training</a></p>

          '
        raw: 'I chose `dolly-v2-7b` because it should be tuneable using a midrange
          VM w/GPU on GCE, Azure, etc.


          I believe that the example code for fine-tuning the base model `Pythia-6.9B`
          with `databricks_dolly_15k` to create `dolly-v2-7b` has not yet been published
          but I''m experimenting anyway, first with tokenizing `databricks_dolly_15k`
          before attempting to tokenize my own dataset, and likely just need some
          pointers to the correct tutorial or other resource.


          A snippet of my first experiment:


          ```python

          from datasets import load_dataset

          from transformers import AutoTokenizer


          dataset = load_dataset("HuggingFaceH4/databricks_dolly_15k", split="train")

          tokenizer = AutoTokenizer.from_pretrained("databricks/dolly-v2-7b")


          dataset[0]["instruction"]


          ''When did Virgin Australia start operating?''


          tokenizer(dataset[0]["instruction"])


          {''input_ids'': [3039, 858, 8237, 6976, 1265, 6498, 32], ''attention_mask'':
          [1, 1, 1, 1, 1, 1, 1]}

          ```


          What I do not know how to do is tokenize all of the features ''category'',
          ''instruction'', ''input'', ''output'', stitching them together before converting
          to pt format for ingestion by the PyTorch Trainer a la https://huggingface.co/docs/transformers/training'
        updatedAt: '2023-04-19T22:07:47.413Z'
      numEdits: 4
      reactions: []
    id: 64405a157c481ee3ea4e901d
    type: comment
  author: durapensa
  content: 'I chose `dolly-v2-7b` because it should be tuneable using a midrange VM
    w/GPU on GCE, Azure, etc.


    I believe that the example code for fine-tuning the base model `Pythia-6.9B` with
    `databricks_dolly_15k` to create `dolly-v2-7b` has not yet been published but
    I''m experimenting anyway, first with tokenizing `databricks_dolly_15k` before
    attempting to tokenize my own dataset, and likely just need some pointers to the
    correct tutorial or other resource.


    A snippet of my first experiment:


    ```python

    from datasets import load_dataset

    from transformers import AutoTokenizer


    dataset = load_dataset("HuggingFaceH4/databricks_dolly_15k", split="train")

    tokenizer = AutoTokenizer.from_pretrained("databricks/dolly-v2-7b")


    dataset[0]["instruction"]


    ''When did Virgin Australia start operating?''


    tokenizer(dataset[0]["instruction"])


    {''input_ids'': [3039, 858, 8237, 6976, 1265, 6498, 32], ''attention_mask'': [1,
    1, 1, 1, 1, 1, 1]}

    ```


    What I do not know how to do is tokenize all of the features ''category'', ''instruction'',
    ''input'', ''output'', stitching them together before converting to pt format
    for ingestion by the PyTorch Trainer a la https://huggingface.co/docs/transformers/training'
  created_at: 2023-04-19 20:16:05+00:00
  edited: true
  hidden: false
  id: 64405a157c481ee3ea4e901d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-19T21:23:39.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>No, the code is here, and the dataset: <a rel="nofollow" href="https://github.com/databrickslabs/dolly">https://github.com/databrickslabs/dolly</a><br>Just
          use the existing training script, and plug in your data instead.</p>

          '
        raw: 'No, the code is here, and the dataset: https://github.com/databrickslabs/dolly

          Just use the existing training script, and plug in your data instead.'
        updatedAt: '2023-04-19T21:23:39.973Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - durapensa
    id: 64405bdb194b02fd30955d9b
    type: comment
  author: srowen
  content: 'No, the code is here, and the dataset: https://github.com/databrickslabs/dolly

    Just use the existing training script, and plug in your data instead.'
  created_at: 2023-04-19 20:23:39+00:00
  edited: false
  hidden: false
  id: 64405bdb194b02fd30955d9b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/0_3Gtw7AETNrMPPLRKhdk.png?w=200&h=200&f=face
      fullname: durapensa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: durapensa
      type: user
    createdAt: '2023-04-19T22:11:59.000Z'
    data:
      edited: false
      editors:
      - durapensa
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/0_3Gtw7AETNrMPPLRKhdk.png?w=200&h=200&f=face
          fullname: durapensa
          isHf: false
          isPro: false
          name: durapensa
          type: user
        html: '<p>Thanks for that pointer - I did not look closely enough at <code>dolly/training/trainer.py</code>!</p>

          '
        raw: Thanks for that pointer - I did not look closely enough at `dolly/training/trainer.py`!
        updatedAt: '2023-04-19T22:11:59.234Z'
      numEdits: 0
      reactions: []
    id: 6440672f194b02fd3096519e
    type: comment
  author: durapensa
  content: Thanks for that pointer - I did not look closely enough at `dolly/training/trainer.py`!
  created_at: 2023-04-19 21:11:59+00:00
  edited: false
  hidden: false
  id: 6440672f194b02fd3096519e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-22T14:03:33.000Z'
    data:
      status: closed
    id: 6443e935c63001ae63500721
    type: status-change
  author: srowen
  created_at: 2023-04-22 13:03:33+00:00
  id: 6443e935c63001ae63500721
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
      fullname: Abhilash Sanap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhi24
      type: user
    createdAt: '2023-05-11T21:44:58.000Z'
    data:
      edited: false
      editors:
      - abhi24
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
          fullname: Abhilash Sanap
          isHf: false
          isPro: false
          name: abhi24
          type: user
        html: '<p>Hello Sean!<br>Is the model available through github is already
          trained on the OG 15k training instances?<br>I plan to fine tune it but
          I''m not sure if I have to append my training dataset to the standard 15k
          data or only train on my dataset.<br>Please advise.</p>

          '
        raw: "Hello Sean!\nIs the model available through github is already trained\
          \ on the OG 15k training instances?\nI plan to fine tune it but I'm not\
          \ sure if I have to append my training dataset to the standard 15k data\
          \ or only train on my dataset. \nPlease advise."
        updatedAt: '2023-05-11T21:44:58.101Z'
      numEdits: 0
      reactions: []
    id: 645d61da4435a8ae3fc91b30
    type: comment
  author: abhi24
  content: "Hello Sean!\nIs the model available through github is already trained\
    \ on the OG 15k training instances?\nI plan to fine tune it but I'm not sure if\
    \ I have to append my training dataset to the standard 15k data or only train\
    \ on my dataset. \nPlease advise."
  created_at: 2023-05-11 20:44:58+00:00
  edited: false
  hidden: false
  id: 645d61da4435a8ae3fc91b30
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-11T22:01:56.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>The dolly 15k dataset? Yes, you can see on the model card and in
          the script. What to do depends on your intentions. Do you want an instruction
          following model? Then start from dolly and do not use the 15k dataset to
          further tune</p>

          '
        raw: The dolly 15k dataset? Yes, you can see on the model card and in the
          script. What to do depends on your intentions. Do you want an instruction
          following model? Then start from dolly and do not use the 15k dataset to
          further tune
        updatedAt: '2023-05-11T22:01:56.091Z'
      numEdits: 0
      reactions: []
    id: 645d65d44e2cf468917e180a
    type: comment
  author: srowen
  content: The dolly 15k dataset? Yes, you can see on the model card and in the script.
    What to do depends on your intentions. Do you want an instruction following model?
    Then start from dolly and do not use the 15k dataset to further tune
  created_at: 2023-05-11 21:01:56+00:00
  edited: false
  hidden: false
  id: 645d65d44e2cf468917e180a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
      fullname: Abhilash Sanap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhi24
      type: user
    createdAt: '2023-05-12T19:22:00.000Z'
    data:
      edited: true
      editors:
      - abhi24
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
          fullname: Abhilash Sanap
          isHf: false
          isPro: false
          name: abhi24
          type: user
        html: '<p>Thank you Sean.</p>

          <p>I want to do summarization/extraction. So my prompts look like this -</p>

          <p> &lt;   meeting notes        &gt;<br>Can you extract information about  from
          the meeting notes?</p>

          <p>Is this task an instruction following task? Or is it a very specific
          task so much so that I train dolly directly on the summarization training
          data?</p>

          <p>Thank you for your continued patience and help.</p>

          '
        raw: "Thank you Sean.\n\nI want to do summarization/extraction. So my prompts\
          \ look like this -\n\n <   meeting notes        >\nCan you extract information\
          \ about <company> from the meeting notes?\n\nIs this task an instruction\
          \ following task? Or is it a very specific task so much so that I train\
          \ dolly directly on the summarization training data?\n\nThank you for your\
          \ continued patience and help."
        updatedAt: '2023-05-12T19:23:10.086Z'
      numEdits: 2
      reactions: []
    id: 645e91d86d343f4bb613c0a2
    type: comment
  author: abhi24
  content: "Thank you Sean.\n\nI want to do summarization/extraction. So my prompts\
    \ look like this -\n\n <   meeting notes        >\nCan you extract information\
    \ about <company> from the meeting notes?\n\nIs this task an instruction following\
    \ task? Or is it a very specific task so much so that I train dolly directly on\
    \ the summarization training data?\n\nThank you for your continued patience and\
    \ help."
  created_at: 2023-05-12 18:22:00+00:00
  edited: true
  hidden: false
  id: 645e91d86d343f4bb613c0a2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-12T20:31:48.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>That''s instruction following. You should probably phrase it more
          specifically. Do you want a summary? Because that''s how training instructions
          would have been phrased.</p>

          '
        raw: That's instruction following. You should probably phrase it more specifically.
          Do you want a summary? Because that's how training instructions would have
          been phrased.
        updatedAt: '2023-05-12T20:31:48.415Z'
      numEdits: 0
      reactions: []
    id: 645ea2346d343f4bb6144502
    type: comment
  author: srowen
  content: That's instruction following. You should probably phrase it more specifically.
    Do you want a summary? Because that's how training instructions would have been
    phrased.
  created_at: 2023-05-12 19:31:48+00:00
  edited: false
  hidden: false
  id: 645ea2346d343f4bb6144502
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
      fullname: Abhilash Sanap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhi24
      type: user
    createdAt: '2023-05-12T20:39:33.000Z'
    data:
      edited: false
      editors:
      - abhi24
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
          fullname: Abhilash Sanap
          isHf: false
          isPro: false
          name: abhi24
          type: user
        html: '<p>Thanks.<br>In a meeting, multiple companies/products  are discussed.
          The aim is to extract information about a specific company or product from
          the meeting notes.<br>In the last post, I misformatted the prompt. Pls check
          the correct one below. </p>

          <p>&lt; meeting notes &gt;<br>Can you extract information about &lt;  company  &gt;
          from the meeting notes?</p>

          '
        raw: "Thanks. \nIn a meeting, multiple companies/products  are discussed.\
          \ The aim is to extract information about a specific company or product\
          \ from the meeting notes.\nIn the last post, I misformatted the prompt.\
          \ Pls check the correct one below. \n\n< meeting notes >\nCan you extract\
          \ information about <  company  > from the meeting notes?"
        updatedAt: '2023-05-12T20:39:33.211Z'
      numEdits: 0
      reactions: []
    id: 645ea405144c62420f2b909c
    type: comment
  author: abhi24
  content: "Thanks. \nIn a meeting, multiple companies/products  are discussed. The\
    \ aim is to extract information about a specific company or product from the meeting\
    \ notes.\nIn the last post, I misformatted the prompt. Pls check the correct one\
    \ below. \n\n< meeting notes >\nCan you extract information about <  company \
    \ > from the meeting notes?"
  created_at: 2023-05-12 19:39:33+00:00
  edited: false
  hidden: false
  id: 645ea405144c62420f2b909c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: databricks/dolly-v2-7b
repo_type: model
status: closed
target_branch: null
title: Creating & tokenizing a dataset for fine-tuning dolly-v2-7b
