!!python/object:huggingface_hub.community.DiscussionWithDetails
author: zaqintosh
conflicting_files: null
created_at: 2023-07-10 23:03:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b8ef4abcac2fcdee3c5dae3fb114d6ce.svg
      fullname: Etan Lightstone
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zaqintosh
      type: user
    createdAt: '2023-07-11T00:03:38.000Z'
    data:
      edited: false
      editors:
      - zaqintosh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9702264666557312
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b8ef4abcac2fcdee3c5dae3fb114d6ce.svg
          fullname: Etan Lightstone
          isHf: false
          isPro: false
          name: zaqintosh
          type: user
        html: '<p>If someone were to use this model for generating responses based
          on a locally provided context (which seems to be very much compatible with
          the training data used for fine tuning with this model), it would be nice
          to know exactly how the text was formatted during fine tuning. Based on
          the pipeline.py script I found it''s clear that it was close to this format:<br>INSTRUCTION_KEY
          = "### Instruction:"<br>RESPONSE_KEY = "### Response:"<br>END_KEY = "###
          End"</p>

          <p>But the databricks-dolly-15k dataset used frequently adds a context,
          how exactly is that incorporated into the chunk of text when you fine tuned
          this model ?</p>

          '
        raw: "If someone were to use this model for generating responses based on\
          \ a locally provided context (which seems to be very much compatible with\
          \ the training data used for fine tuning with this model), it would be nice\
          \ to know exactly how the text was formatted during fine tuning. Based on\
          \ the pipeline.py script I found it's clear that it was close to this format:\r\
          \nINSTRUCTION_KEY = \"### Instruction:\"\r\nRESPONSE_KEY = \"### Response:\"\
          \r\nEND_KEY = \"### End\"\r\n\r\nBut the databricks-dolly-15k dataset used\
          \ frequently adds a context, how exactly is that incorporated into the chunk\
          \ of text when you fine tuned this model ?"
        updatedAt: '2023-07-11T00:03:38.772Z'
      numEdits: 0
      reactions: []
    id: 64ac9c5a2d29d3bdcd3b6e88
    type: comment
  author: zaqintosh
  content: "If someone were to use this model for generating responses based on a\
    \ locally provided context (which seems to be very much compatible with the training\
    \ data used for fine tuning with this model), it would be nice to know exactly\
    \ how the text was formatted during fine tuning. Based on the pipeline.py script\
    \ I found it's clear that it was close to this format:\r\nINSTRUCTION_KEY = \"\
    ### Instruction:\"\r\nRESPONSE_KEY = \"### Response:\"\r\nEND_KEY = \"### End\"\
    \r\n\r\nBut the databricks-dolly-15k dataset used frequently adds a context, how\
    \ exactly is that incorporated into the chunk of text when you fine tuned this\
    \ model ?"
  created_at: 2023-07-10 23:03:38+00:00
  edited: false
  hidden: false
  id: 64ac9c5a2d29d3bdcd3b6e88
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-07-11T00:10:46.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8916928172111511
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>You can see how the training input was formed with context or without
          here: <a rel="nofollow" href="https://github.com/databrickslabs/dolly/blob/master/training/trainer.py#L109">https://github.com/databrickslabs/dolly/blob/master/training/trainer.py#L109</a></p>

          '
        raw: 'You can see how the training input was formed with context or without
          here: https://github.com/databrickslabs/dolly/blob/master/training/trainer.py#L109

          '
        updatedAt: '2023-07-11T00:10:46.733Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - zaqintosh
    id: 64ac9e064b6cefa3a8504b84
    type: comment
  author: srowen
  content: 'You can see how the training input was formed with context or without
    here: https://github.com/databrickslabs/dolly/blob/master/training/trainer.py#L109

    '
  created_at: 2023-07-10 23:10:46+00:00
  edited: false
  hidden: false
  id: 64ac9e064b6cefa3a8504b84
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b8ef4abcac2fcdee3c5dae3fb114d6ce.svg
      fullname: Etan Lightstone
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zaqintosh
      type: user
    createdAt: '2023-07-11T01:50:12.000Z'
    data:
      edited: true
      editors:
      - zaqintosh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.923129141330719
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b8ef4abcac2fcdee3c5dae3fb114d6ce.svg
          fullname: Etan Lightstone
          isHf: false
          isPro: false
          name: zaqintosh
          type: user
        html: '<p>Thanks! I still had to dig into this file to verify exactly how
          the formatting worked in plaintext: <a rel="nofollow" href="https://github.com/databrickslabs/dolly/blob/master/training/consts.py">https://github.com/databrickslabs/dolly/blob/master/training/consts.py</a></p>

          <p>PROMPT_WITH_INPUT_FORMAT and how its constructed</p>

          '
        raw: 'Thanks! I still had to dig into this file to verify exactly how the
          formatting worked in plaintext: https://github.com/databrickslabs/dolly/blob/master/training/consts.py


          PROMPT_WITH_INPUT_FORMAT and how its constructed'
        updatedAt: '2023-07-11T01:51:11.028Z'
      numEdits: 1
      reactions: []
    id: 64acb5542d29d3bdcd3e3705
    type: comment
  author: zaqintosh
  content: 'Thanks! I still had to dig into this file to verify exactly how the formatting
    worked in plaintext: https://github.com/databrickslabs/dolly/blob/master/training/consts.py


    PROMPT_WITH_INPUT_FORMAT and how its constructed'
  created_at: 2023-07-11 00:50:12+00:00
  edited: true
  hidden: false
  id: 64acb5542d29d3bdcd3e3705
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-07-15T16:00:54.000Z'
    data:
      status: closed
    id: 64b2c2b6f460afaefc259fb5
    type: status-change
  author: srowen
  created_at: 2023-07-15 15:00:54+00:00
  id: 64b2c2b6f460afaefc259fb5
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: databricks/dolly-v2-7b
repo_type: model
status: closed
target_branch: null
title: Exact prompt used to fine tune this model that will help when someone uses
  it for inference?
