!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TheBloke
conflicting_files: null
created_at: 2023-11-01 15:39:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-01T16:39:47.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.359960675239563
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p>Trying to load your tokenizer using the provided example code gives\
          \ this error: <code>AttributeError: 'BlueLMTokenizer' object has no attribute\
          \ 'sp_model'</code></p>\n<p>Tested with: <code>transformers==4.34.1</code></p>\n\
          <p>Full log:</p>\n<pre><code>In [1]: from transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\n\nIn [2]: tokenizer = AutoTokenizer.from_pretrained(\"\
          vivo-ai/BlueLM-7B-Chat-32K\", trust_remote_code=True, use_fast=False)\n\
          A new version of the following files was downloaded from https://huggingface.co/vivo-ai/BlueLM-7B-Chat-32K:\n\
          - tokenization_bluelm.py\n. Make sure to double-check they do not contain\
          \ any added malicious code. To avoid downloading new versions of the code\
          \ file, you can pin a revision.\n---------------------------------------------------------------------------\n\
          AttributeError                            Traceback (most recent call last)\n\
          Cell In[2], line 1\n----&gt; 1 tokenizer = AutoTokenizer.from_pretrained(\"\
          vivo-ai/BlueLM-7B-Chat-32K\", trust_remote_code=True, use_fast=False)\n\n\
          File /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:738,\
          \ in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs,\
          \ **kwargs)\n    736     if os.path.isdir(pretrained_model_name_or_path):\n\
          \    737         tokenizer_class.register_for_auto_class()\n--&gt; 738 \
          \    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\n    739 elif config_tokenizer_class is not None:\n\
          \    740     tokenizer_class = None\n\nFile /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2017,\
          \ in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,\
          \ cache_dir, force_download, local_files_only, token, revision, *init_inputs,\
          \ **kwargs)\n   2014     else:\n   2015         logger.info(f\"loading file\
          \ {file_path} from cache at {resolved_vocab_files[file_id]}\")\n-&gt; 2017\
          \ return cls._from_pretrained(\n   2018     resolved_vocab_files,\n   2019\
          \     pretrained_model_name_or_path,\n   2020     init_configuration,\n\
          \   2021     *init_inputs,\n   2022     token=token,\n   2023     cache_dir=cache_dir,\n\
          \   2024     local_files_only=local_files_only,\n   2025     _commit_hash=commit_hash,\n\
          \   2026     _is_local=is_local,\n   2027     **kwargs,\n   2028 )\n\nFile\
          \ /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2249,\
          \ in PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files,\
          \ pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only,\
          \ _commit_hash, _is_local, *init_inputs, **kwargs)\n   2247 # Instantiate\
          \ the tokenizer.\n   2248 try:\n-&gt; 2249     tokenizer = cls(*init_inputs,\
          \ **init_kwargs)\n   2250 except OSError:\n   2251     raise OSError(\n\
          \   2252         \"Unable to load vocabulary from file. \"\n   2253    \
          \     \"Please check that the provided vocabulary is accessible and not\
          \ corrupted.\"\n   2254     )\n\nFile /workspace/huggingface/modules/transformers_modules/vivo-ai/BlueLM-7B-Chat-32K/1b474dbc96f42f94289eafd42d7a582a436f87ba/tokenization_bluelm.py:76,\
          \ in BlueLMTokenizer.__init__(self, vocab_file, unk_token, bos_token, eos_token,\
          \ pad_token, sp_model_kwargs, add_bos_token, add_eos_token, clean_up_tokenization_spaces,\
          \ **kwargs)\n     74 unk_token = AddedToken(unk_token, lstrip=False, rstrip=False)\
          \ if isinstance(unk_token, str) else unk_token\n     75 pad_token = AddedToken(pad_token,\
          \ lstrip=False, rstrip=False) if isinstance(pad_token, str) else pad_token\n\
          ---&gt; 76 super().__init__(\n     77     bos_token=bos_token,\n     78\
          \     eos_token=eos_token,\n     79     unk_token=unk_token,\n     80  \
          \   pad_token=pad_token,\n     81     add_bos_token=add_bos_token,\n   \
          \  82     add_eos_token=add_eos_token,\n     83     sp_model_kwargs=self.sp_model_kwargs,\n\
          \     84     clean_up_tokenization_spaces=clean_up_tokenization_spaces,\n\
          \     85     **kwargs,\n     86 )\n     87 self.vocab_file = vocab_file\n\
          \     88 self.add_bos_token = add_bos_token\n\nFile /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils.py:367,\
          \ in PreTrainedTokenizer.__init__(self, **kwargs)\n    363 super().__init__(**kwargs)\n\
          \    365 # 4. If some of the special tokens are not part of the vocab, we\
          \ add them, at the end.\n    366 # the order of addition is the same as\
          \ self.SPECIAL_TOKENS_ATTRIBUTES following `tokenizers`\n--&gt; 367 self._add_tokens(\n\
          \    368     [token for token in self.all_special_tokens_extended if token\
          \ not in self._added_tokens_encoder],\n    369     special_tokens=True,\n\
          \    370 )\n    372 self._decode_use_source_tokenizer = False\n\nFile /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils.py:467,\
          \ in PreTrainedTokenizer._add_tokens(self, new_tokens, special_tokens)\n\
          \    465     return added_tokens\n    466 # TODO this is fairly slow to\
          \ improve!\n--&gt; 467 current_vocab = self.get_vocab().copy()\n    468\
          \ new_idx = len(current_vocab)  # only call this once, len gives the last\
          \ index + 1\n    469 for token in new_tokens:\n\nFile /workspace/huggingface/modules/transformers_modules/vivo-ai/BlueLM-7B-Chat-32K/1b474dbc96f42f94289eafd42d7a582a436f87ba/tokenization_bluelm.py:110,\
          \ in BlueLMTokenizer.get_vocab(self)\n    108 def get_vocab(self):\n   \
          \ 109     \"\"\"Returns vocab as a dict\"\"\"\n--&gt; 110     vocab = {self.convert_ids_to_tokens(i):\
          \ i for i in range(self.vocab_size)}\n    111     vocab.update(self.added_tokens_encoder)\n\
          \    112     return vocab\n\nFile /workspace/huggingface/modules/transformers_modules/vivo-ai/BlueLM-7B-Chat-32K/1b474dbc96f42f94289eafd42d7a582a436f87ba/tokenization_bluelm.py:106,\
          \ in BlueLMTokenizer.vocab_size(self)\n    103 @property\n    104 def vocab_size(self):\n\
          \    105     \"\"\"Returns vocab size\"\"\"\n--&gt; 106     return self.sp_model.get_piece_size()\n\
          \nAttributeError: 'BlueLMTokenizer' object has no attribute 'sp_model'\n\
          </code></pre>\n"
        raw: "Trying to load your tokenizer using the provided example code gives\
          \ this error: `AttributeError: 'BlueLMTokenizer' object has no attribute\
          \ 'sp_model'`\n\nTested with: `transformers==4.34.1`\n\nFull log:\n\n```\n\
          In [1]: from transformers import AutoModelForCausalLM, AutoTokenizer\n\n\
          In [2]: tokenizer = AutoTokenizer.from_pretrained(\"vivo-ai/BlueLM-7B-Chat-32K\"\
          , trust_remote_code=True, use_fast=False)\nA new version of the following\
          \ files was downloaded from https://huggingface.co/vivo-ai/BlueLM-7B-Chat-32K:\n\
          - tokenization_bluelm.py\n. Make sure to double-check they do not contain\
          \ any added malicious code. To avoid downloading new versions of the code\
          \ file, you can pin a revision.\n---------------------------------------------------------------------------\n\
          AttributeError                            Traceback (most recent call last)\n\
          Cell In[2], line 1\n----> 1 tokenizer = AutoTokenizer.from_pretrained(\"\
          vivo-ai/BlueLM-7B-Chat-32K\", trust_remote_code=True, use_fast=False)\n\n\
          File /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:738,\
          \ in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs,\
          \ **kwargs)\n    736     if os.path.isdir(pretrained_model_name_or_path):\n\
          \    737         tokenizer_class.register_for_auto_class()\n--> 738    \
          \ return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\n    739 elif config_tokenizer_class is not None:\n\
          \    740     tokenizer_class = None\n\nFile /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2017,\
          \ in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,\
          \ cache_dir, force_download, local_files_only, token, revision, *init_inputs,\
          \ **kwargs)\n   2014     else:\n   2015         logger.info(f\"loading file\
          \ {file_path} from cache at {resolved_vocab_files[file_id]}\")\n-> 2017\
          \ return cls._from_pretrained(\n   2018     resolved_vocab_files,\n   2019\
          \     pretrained_model_name_or_path,\n   2020     init_configuration,\n\
          \   2021     *init_inputs,\n   2022     token=token,\n   2023     cache_dir=cache_dir,\n\
          \   2024     local_files_only=local_files_only,\n   2025     _commit_hash=commit_hash,\n\
          \   2026     _is_local=is_local,\n   2027     **kwargs,\n   2028 )\n\nFile\
          \ /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2249,\
          \ in PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files,\
          \ pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only,\
          \ _commit_hash, _is_local, *init_inputs, **kwargs)\n   2247 # Instantiate\
          \ the tokenizer.\n   2248 try:\n-> 2249     tokenizer = cls(*init_inputs,\
          \ **init_kwargs)\n   2250 except OSError:\n   2251     raise OSError(\n\
          \   2252         \"Unable to load vocabulary from file. \"\n   2253    \
          \     \"Please check that the provided vocabulary is accessible and not\
          \ corrupted.\"\n   2254     )\n\nFile /workspace/huggingface/modules/transformers_modules/vivo-ai/BlueLM-7B-Chat-32K/1b474dbc96f42f94289eafd42d7a582a436f87ba/tokenization_bluelm.py:76,\
          \ in BlueLMTokenizer.__init__(self, vocab_file, unk_token, bos_token, eos_token,\
          \ pad_token, sp_model_kwargs, add_bos_token, add_eos_token, clean_up_tokenization_spaces,\
          \ **kwargs)\n     74 unk_token = AddedToken(unk_token, lstrip=False, rstrip=False)\
          \ if isinstance(unk_token, str) else unk_token\n     75 pad_token = AddedToken(pad_token,\
          \ lstrip=False, rstrip=False) if isinstance(pad_token, str) else pad_token\n\
          ---> 76 super().__init__(\n     77     bos_token=bos_token,\n     78   \
          \  eos_token=eos_token,\n     79     unk_token=unk_token,\n     80     pad_token=pad_token,\n\
          \     81     add_bos_token=add_bos_token,\n     82     add_eos_token=add_eos_token,\n\
          \     83     sp_model_kwargs=self.sp_model_kwargs,\n     84     clean_up_tokenization_spaces=clean_up_tokenization_spaces,\n\
          \     85     **kwargs,\n     86 )\n     87 self.vocab_file = vocab_file\n\
          \     88 self.add_bos_token = add_bos_token\n\nFile /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils.py:367,\
          \ in PreTrainedTokenizer.__init__(self, **kwargs)\n    363 super().__init__(**kwargs)\n\
          \    365 # 4. If some of the special tokens are not part of the vocab, we\
          \ add them, at the end.\n    366 # the order of addition is the same as\
          \ self.SPECIAL_TOKENS_ATTRIBUTES following `tokenizers`\n--> 367 self._add_tokens(\n\
          \    368     [token for token in self.all_special_tokens_extended if token\
          \ not in self._added_tokens_encoder],\n    369     special_tokens=True,\n\
          \    370 )\n    372 self._decode_use_source_tokenizer = False\n\nFile /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils.py:467,\
          \ in PreTrainedTokenizer._add_tokens(self, new_tokens, special_tokens)\n\
          \    465     return added_tokens\n    466 # TODO this is fairly slow to\
          \ improve!\n--> 467 current_vocab = self.get_vocab().copy()\n    468 new_idx\
          \ = len(current_vocab)  # only call this once, len gives the last index\
          \ + 1\n    469 for token in new_tokens:\n\nFile /workspace/huggingface/modules/transformers_modules/vivo-ai/BlueLM-7B-Chat-32K/1b474dbc96f42f94289eafd42d7a582a436f87ba/tokenization_bluelm.py:110,\
          \ in BlueLMTokenizer.get_vocab(self)\n    108 def get_vocab(self):\n   \
          \ 109     \"\"\"Returns vocab as a dict\"\"\"\n--> 110     vocab = {self.convert_ids_to_tokens(i):\
          \ i for i in range(self.vocab_size)}\n    111     vocab.update(self.added_tokens_encoder)\n\
          \    112     return vocab\n\nFile /workspace/huggingface/modules/transformers_modules/vivo-ai/BlueLM-7B-Chat-32K/1b474dbc96f42f94289eafd42d7a582a436f87ba/tokenization_bluelm.py:106,\
          \ in BlueLMTokenizer.vocab_size(self)\n    103 @property\n    104 def vocab_size(self):\n\
          \    105     \"\"\"Returns vocab size\"\"\"\n--> 106     return self.sp_model.get_piece_size()\n\
          \nAttributeError: 'BlueLMTokenizer' object has no attribute 'sp_model'\n\
          \n```"
        updatedAt: '2023-11-01T16:40:28.128Z'
      numEdits: 1
      reactions: []
    id: 65427f532855468b37ee36eb
    type: comment
  author: TheBloke
  content: "Trying to load your tokenizer using the provided example code gives this\
    \ error: `AttributeError: 'BlueLMTokenizer' object has no attribute 'sp_model'`\n\
    \nTested with: `transformers==4.34.1`\n\nFull log:\n\n```\nIn [1]: from transformers\
    \ import AutoModelForCausalLM, AutoTokenizer\n\nIn [2]: tokenizer = AutoTokenizer.from_pretrained(\"\
    vivo-ai/BlueLM-7B-Chat-32K\", trust_remote_code=True, use_fast=False)\nA new version\
    \ of the following files was downloaded from https://huggingface.co/vivo-ai/BlueLM-7B-Chat-32K:\n\
    - tokenization_bluelm.py\n. Make sure to double-check they do not contain any\
    \ added malicious code. To avoid downloading new versions of the code file, you\
    \ can pin a revision.\n---------------------------------------------------------------------------\n\
    AttributeError                            Traceback (most recent call last)\n\
    Cell In[2], line 1\n----> 1 tokenizer = AutoTokenizer.from_pretrained(\"vivo-ai/BlueLM-7B-Chat-32K\"\
    , trust_remote_code=True, use_fast=False)\n\nFile /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:738,\
    \ in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs,\
    \ **kwargs)\n    736     if os.path.isdir(pretrained_model_name_or_path):\n  \
    \  737         tokenizer_class.register_for_auto_class()\n--> 738     return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
    \ *inputs, **kwargs)\n    739 elif config_tokenizer_class is not None:\n    740\
    \     tokenizer_class = None\n\nFile /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2017,\
    \ in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,\
    \ cache_dir, force_download, local_files_only, token, revision, *init_inputs,\
    \ **kwargs)\n   2014     else:\n   2015         logger.info(f\"loading file {file_path}\
    \ from cache at {resolved_vocab_files[file_id]}\")\n-> 2017 return cls._from_pretrained(\n\
    \   2018     resolved_vocab_files,\n   2019     pretrained_model_name_or_path,\n\
    \   2020     init_configuration,\n   2021     *init_inputs,\n   2022     token=token,\n\
    \   2023     cache_dir=cache_dir,\n   2024     local_files_only=local_files_only,\n\
    \   2025     _commit_hash=commit_hash,\n   2026     _is_local=is_local,\n   2027\
    \     **kwargs,\n   2028 )\n\nFile /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2249,\
    \ in PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path,\
    \ init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local,\
    \ *init_inputs, **kwargs)\n   2247 # Instantiate the tokenizer.\n   2248 try:\n\
    -> 2249     tokenizer = cls(*init_inputs, **init_kwargs)\n   2250 except OSError:\n\
    \   2251     raise OSError(\n   2252         \"Unable to load vocabulary from\
    \ file. \"\n   2253         \"Please check that the provided vocabulary is accessible\
    \ and not corrupted.\"\n   2254     )\n\nFile /workspace/huggingface/modules/transformers_modules/vivo-ai/BlueLM-7B-Chat-32K/1b474dbc96f42f94289eafd42d7a582a436f87ba/tokenization_bluelm.py:76,\
    \ in BlueLMTokenizer.__init__(self, vocab_file, unk_token, bos_token, eos_token,\
    \ pad_token, sp_model_kwargs, add_bos_token, add_eos_token, clean_up_tokenization_spaces,\
    \ **kwargs)\n     74 unk_token = AddedToken(unk_token, lstrip=False, rstrip=False)\
    \ if isinstance(unk_token, str) else unk_token\n     75 pad_token = AddedToken(pad_token,\
    \ lstrip=False, rstrip=False) if isinstance(pad_token, str) else pad_token\n--->\
    \ 76 super().__init__(\n     77     bos_token=bos_token,\n     78     eos_token=eos_token,\n\
    \     79     unk_token=unk_token,\n     80     pad_token=pad_token,\n     81 \
    \    add_bos_token=add_bos_token,\n     82     add_eos_token=add_eos_token,\n\
    \     83     sp_model_kwargs=self.sp_model_kwargs,\n     84     clean_up_tokenization_spaces=clean_up_tokenization_spaces,\n\
    \     85     **kwargs,\n     86 )\n     87 self.vocab_file = vocab_file\n    \
    \ 88 self.add_bos_token = add_bos_token\n\nFile /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils.py:367,\
    \ in PreTrainedTokenizer.__init__(self, **kwargs)\n    363 super().__init__(**kwargs)\n\
    \    365 # 4. If some of the special tokens are not part of the vocab, we add\
    \ them, at the end.\n    366 # the order of addition is the same as self.SPECIAL_TOKENS_ATTRIBUTES\
    \ following `tokenizers`\n--> 367 self._add_tokens(\n    368     [token for token\
    \ in self.all_special_tokens_extended if token not in self._added_tokens_encoder],\n\
    \    369     special_tokens=True,\n    370 )\n    372 self._decode_use_source_tokenizer\
    \ = False\n\nFile /workspace/venv/pytorch2/lib/python3.10/site-packages/transformers/tokenization_utils.py:467,\
    \ in PreTrainedTokenizer._add_tokens(self, new_tokens, special_tokens)\n    465\
    \     return added_tokens\n    466 # TODO this is fairly slow to improve!\n-->\
    \ 467 current_vocab = self.get_vocab().copy()\n    468 new_idx = len(current_vocab)\
    \  # only call this once, len gives the last index + 1\n    469 for token in new_tokens:\n\
    \nFile /workspace/huggingface/modules/transformers_modules/vivo-ai/BlueLM-7B-Chat-32K/1b474dbc96f42f94289eafd42d7a582a436f87ba/tokenization_bluelm.py:110,\
    \ in BlueLMTokenizer.get_vocab(self)\n    108 def get_vocab(self):\n    109  \
    \   \"\"\"Returns vocab as a dict\"\"\"\n--> 110     vocab = {self.convert_ids_to_tokens(i):\
    \ i for i in range(self.vocab_size)}\n    111     vocab.update(self.added_tokens_encoder)\n\
    \    112     return vocab\n\nFile /workspace/huggingface/modules/transformers_modules/vivo-ai/BlueLM-7B-Chat-32K/1b474dbc96f42f94289eafd42d7a582a436f87ba/tokenization_bluelm.py:106,\
    \ in BlueLMTokenizer.vocab_size(self)\n    103 @property\n    104 def vocab_size(self):\n\
    \    105     \"\"\"Returns vocab size\"\"\"\n--> 106     return self.sp_model.get_piece_size()\n\
    \nAttributeError: 'BlueLMTokenizer' object has no attribute 'sp_model'\n\n```"
  created_at: 2023-11-01 15:39:47+00:00
  edited: true
  hidden: false
  id: 65427f532855468b37ee36eb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/870724e20dc1c221fbe9c6656720ab9b.svg
      fullname: Pororo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jeffreygao
      type: user
    createdAt: '2023-11-02T02:02:27.000Z'
    data:
      edited: false
      editors:
      - jeffreygao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8104820251464844
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/870724e20dc1c221fbe9c6656720ab9b.svg
          fullname: Pororo
          isHf: false
          isPro: false
          name: jeffreygao
          type: user
        html: '<p>You can try transformers==4.33.1.</p>

          '
        raw: You can try transformers==4.33.1.
        updatedAt: '2023-11-02T02:02:27.938Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - derekhsu
    id: 6543033302409f0994034d37
    type: comment
  author: jeffreygao
  content: You can try transformers==4.33.1.
  created_at: 2023-11-02 01:02:27+00:00
  edited: false
  hidden: false
  id: 6543033302409f0994034d37
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5996c7758185c7dae8be55d874eed408.svg
      fullname: Derek
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: derekhsu
      type: user
    createdAt: '2023-11-02T07:10:04.000Z'
    data:
      edited: false
      editors:
      - derekhsu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9011083841323853
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5996c7758185c7dae8be55d874eed408.svg
          fullname: Derek
          isHf: false
          isPro: false
          name: derekhsu
          type: user
        html: '<blockquote>

          <p>You can try transformers==4.33.1.</p>

          </blockquote>

          <p>Done. I successed. </p>

          '
        raw: '> You can try transformers==4.33.1.


          Done. I successed. '
        updatedAt: '2023-11-02T07:10:04.732Z'
      numEdits: 0
      reactions: []
    id: 65434b4c2997b38f4fa6ed35
    type: comment
  author: derekhsu
  content: '> You can try transformers==4.33.1.


    Done. I successed. '
  created_at: 2023-11-02 06:10:04+00:00
  edited: false
  hidden: false
  id: 65434b4c2997b38f4fa6ed35
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-02T09:26:23.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9382560849189758
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Are you planning to fix it for 4.34.1 ?  Otherwise this is very
          limiting for users - most people want to be on the latest Transformers.
          And this will keep getting more important as new Transformers releases coming
          out (there''s going to be another Transformers release in the next day or
          two)</p>

          '
        raw: Are you planning to fix it for 4.34.1 ?  Otherwise this is very limiting
          for users - most people want to be on the latest Transformers. And this
          will keep getting more important as new Transformers releases coming out
          (there's going to be another Transformers release in the next day or two)
        updatedAt: '2023-11-02T09:26:23.535Z'
      numEdits: 0
      reactions: []
    id: 65436b3f2cfe8660a39e34f5
    type: comment
  author: TheBloke
  content: Are you planning to fix it for 4.34.1 ?  Otherwise this is very limiting
    for users - most people want to be on the latest Transformers. And this will keep
    getting more important as new Transformers releases coming out (there's going
    to be another Transformers release in the next day or two)
  created_at: 2023-11-02 08:26:23+00:00
  edited: false
  hidden: false
  id: 65436b3f2cfe8660a39e34f5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4b4312d553a59ad5246b2b88c43847d9.svg
      fullname: LiHongbin
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JoeyHeisenberg
      type: user
    createdAt: '2023-11-02T12:56:45.000Z'
    data:
      edited: false
      editors:
      - JoeyHeisenberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8486483693122864
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4b4312d553a59ad5246b2b88c43847d9.svg
          fullname: LiHongbin
          isHf: false
          isPro: false
          name: JoeyHeisenberg
          type: user
        html: '<p>Moving the call to super().<strong>init</strong>() to a line after
          the creation of self.sp_model in tokenization_bluelm.py could resolve the
          issue. </p>

          '
        raw: 'Moving the call to super().__init__() to a line after the creation of
          self.sp_model in tokenization_bluelm.py could resolve the issue. '
        updatedAt: '2023-11-02T12:56:45.888Z'
      numEdits: 0
      reactions: []
    id: 65439c8d9ce0fa3dfa4f9194
    type: comment
  author: JoeyHeisenberg
  content: 'Moving the call to super().__init__() to a line after the creation of
    self.sp_model in tokenization_bluelm.py could resolve the issue. '
  created_at: 2023-11-02 11:56:45+00:00
  edited: false
  hidden: false
  id: 65439c8d9ce0fa3dfa4f9194
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/4b4312d553a59ad5246b2b88c43847d9.svg
      fullname: LiHongbin
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JoeyHeisenberg
      type: user
    createdAt: '2023-11-06T01:52:32.000Z'
    data:
      status: closed
    id: 654846e051c10a6f8b37475b
    type: status-change
  author: JoeyHeisenberg
  created_at: 2023-11-06 01:52:32+00:00
  id: 654846e051c10a6f8b37475b
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: vivo-ai/BlueLM-7B-Chat-32K
repo_type: model
status: closed
target_branch: null
title: 'Tokenizer code not working? `AttributeError: ''BlueLMTokenizer'' object has
  no attribute ''sp_model''`'
