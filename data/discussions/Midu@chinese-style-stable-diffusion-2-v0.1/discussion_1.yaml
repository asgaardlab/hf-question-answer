!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nipi
conflicting_files: null
created_at: 2022-12-27 01:47:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1494031fa331cf6f61b5a59294a4e696.svg
      fullname: pengwang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nipi
      type: user
    createdAt: '2022-12-27T01:47:16.000Z'
    data:
      edited: true
      editors:
      - nipi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1494031fa331cf6f61b5a59294a4e696.svg
          fullname: pengwang
          isHf: false
          isPro: false
          name: nipi
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;Midu&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Midu\">@<span class=\"\
          underline\">Midu</span></a></span>\n\n\t</span></span>\uFF0CThank you for\
          \ your sharing. Is the finetune Chinese-style script based on the \"<a rel=\"\
          nofollow\" href=\"https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py\"\
          >diffusers</a>\" script? Is it possible to share training skills or training\
          \ parameters?</p>\n"
        raw: "Hello @Midu\uFF0CThank you for your sharing. Is the finetune Chinese-style\
          \ script based on the \"[diffusers](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)\"\
          \ script? Is it possible to share training skills or training parameters?"
        updatedAt: '2022-12-27T01:49:00.384Z'
      numEdits: 2
      reactions: []
    id: 63aa4ea4769a10efc403a582
    type: comment
  author: nipi
  content: "Hello @Midu\uFF0CThank you for your sharing. Is the finetune Chinese-style\
    \ script based on the \"[diffusers](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)\"\
    \ script? Is it possible to share training skills or training parameters?"
  created_at: 2022-12-27 01:47:16+00:00
  edited: true
  hidden: false
  id: 63aa4ea4769a10efc403a582
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cc6ccd0b4b6f074f1e920858197f3c2d.svg
      fullname: tenghui.li
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tenpha
      type: user
    createdAt: '2022-12-27T03:15:46.000Z'
    data:
      edited: false
      editors:
      - tenpha
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cc6ccd0b4b6f074f1e920858197f3c2d.svg
          fullname: tenghui.li
          isHf: false
          isPro: false
          name: tenpha
          type: user
        html: "<blockquote>\n<p>Hello <span data-props=\"{&quot;user&quot;:&quot;Midu&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Midu\"\
          >@<span class=\"underline\">Midu</span></a></span>\n\n\t</span></span>\uFF0C\
          Thank you for your sharing. Is the finetune Chinese-style script based on\
          \ the \"<a rel=\"nofollow\" href=\"https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py\"\
          >diffusers</a>\" script? Is it possible to share training skills or training\
          \ parameters?</p>\n</blockquote>\n<p>+1</p>\n"
        raw: "> Hello @Midu\uFF0CThank you for your sharing. Is the finetune Chinese-style\
          \ script based on the \"[diffusers](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)\"\
          \ script? Is it possible to share training skills or training parameters?\n\
          \n+1"
        updatedAt: '2022-12-27T03:15:46.609Z'
      numEdits: 0
      reactions: []
    id: 63aa636257ca9193a67edf50
    type: comment
  author: tenpha
  content: "> Hello @Midu\uFF0CThank you for your sharing. Is the finetune Chinese-style\
    \ script based on the \"[diffusers](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)\"\
    \ script? Is it possible to share training skills or training parameters?\n\n\
    +1"
  created_at: 2022-12-27 03:15:46+00:00
  edited: false
  hidden: false
  id: 63aa636257ca9193a67edf50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2914bdf3d344b0e34da456814bfcc6dd.svg
      fullname: LiuYidong
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Midu
      type: user
    createdAt: '2022-12-28T09:56:14.000Z'
    data:
      edited: false
      editors:
      - Midu
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2914bdf3d344b0e34da456814bfcc6dd.svg
          fullname: LiuYidong
          isHf: false
          isPro: false
          name: Midu
          type: user
        html: "<blockquote>\n<p>Hello <span data-props=\"{&quot;user&quot;:&quot;Midu&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Midu\"\
          >@<span class=\"underline\">Midu</span></a></span>\n\n\t</span></span>\uFF0C\
          Thank you for your sharing. Is the finetune Chinese-style script based on\
          \ the \"<a rel=\"nofollow\" href=\"https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py\"\
          >diffusers</a>\" script? Is it possible to share training skills or training\
          \ parameters?</p>\n</blockquote>\n<p>Hi <span data-props=\"{&quot;user&quot;:&quot;nipi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/nipi\"\
          >@<span class=\"underline\">nipi</span></a></span>\n\n\t</span></span> ,<br>Yes,\
          \ my script is based on diffusers for a good Deepspeed support. I did not\
          \ tune the hyperparameters a lot but only use a low learning rate (6e-5\
          \ for 256 batch size).</p>\n"
        raw: "> Hello @Midu\uFF0CThank you for your sharing. Is the finetune Chinese-style\
          \ script based on the \"[diffusers](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)\"\
          \ script? Is it possible to share training skills or training parameters?\n\
          \nHi @nipi ,\nYes, my script is based on diffusers for a good Deepspeed\
          \ support. I did not tune the hyperparameters a lot but only use a low learning\
          \ rate (6e-5 for 256 batch size)."
        updatedAt: '2022-12-28T09:56:14.286Z'
      numEdits: 0
      reactions: []
    id: 63ac12beddc14eb44b0aeeab
    type: comment
  author: Midu
  content: "> Hello @Midu\uFF0CThank you for your sharing. Is the finetune Chinese-style\
    \ script based on the \"[diffusers](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)\"\
    \ script? Is it possible to share training skills or training parameters?\n\n\
    Hi @nipi ,\nYes, my script is based on diffusers for a good Deepspeed support.\
    \ I did not tune the hyperparameters a lot but only use a low learning rate (6e-5\
    \ for 256 batch size)."
  created_at: 2022-12-28 09:56:14+00:00
  edited: false
  hidden: false
  id: 63ac12beddc14eb44b0aeeab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1494031fa331cf6f61b5a59294a4e696.svg
      fullname: pengwang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nipi
      type: user
    createdAt: '2022-12-29T05:45:57.000Z'
    data:
      edited: false
      editors:
      - nipi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1494031fa331cf6f61b5a59294a4e696.svg
          fullname: pengwang
          isHf: false
          isPro: false
          name: nipi
          type: user
        html: "<blockquote>\n<blockquote>\n<p>Hello <span data-props=\"{&quot;user&quot;:&quot;Midu&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Midu\"\
          >@<span class=\"underline\">Midu</span></a></span>\n\n\t</span></span>\uFF0C\
          Thank you for your sharing. Is the finetune Chinese-style script based on\
          \ the \"<a rel=\"nofollow\" href=\"https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py\"\
          >diffusers</a>\" script? Is it possible to share training skills or training\
          \ parameters?</p>\n</blockquote>\n<p>Hi <span data-props=\"{&quot;user&quot;:&quot;nipi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/nipi\"\
          >@<span class=\"underline\">nipi</span></a></span>\n\n\t</span></span> ,<br>Yes,\
          \ my script is based on diffusers for a good Deepspeed support. I did not\
          \ tune the hyperparameters a lot but only use a low learning rate (6e-5\
          \ for 256 batch size).</p>\n</blockquote>\n<p>Hello <span data-props=\"\
          {&quot;user&quot;:&quot;Midu&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/Midu\">@<span class=\"underline\">Midu</span></a></span>\n\
          \n\t</span></span>,<br>Thank you for responding. The scheduler in the model's\
          \ scheduler config.json uses EulerDiscreteScheduler, and the prediction\
          \ type is v _prediction, but the diffuser's EulerDiscreteScheduler does\
          \ not implement the get_velocity method. Do you make use of DDPMScheduler\
          \ finetune? Furthermore, do you freeze the gradients of text encoder and\
          \ vae during the training process, only finetuning the unet model?</p>\n"
        raw: "> > Hello @Midu\uFF0CThank you for your sharing. Is the finetune Chinese-style\
          \ script based on the \"[diffusers](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)\"\
          \ script? Is it possible to share training skills or training parameters?\n\
          > \n> Hi @nipi ,\n> Yes, my script is based on diffusers for a good Deepspeed\
          \ support. I did not tune the hyperparameters a lot but only use a low learning\
          \ rate (6e-5 for 256 batch size).\n\nHello @Midu,\nThank you for responding.\
          \ The scheduler in the model's scheduler config.json uses EulerDiscreteScheduler,\
          \ and the prediction type is v _prediction, but the diffuser's EulerDiscreteScheduler\
          \ does not implement the get_velocity method. Do you make use of DDPMScheduler\
          \ finetune? Furthermore, do you freeze the gradients of text encoder and\
          \ vae during the training process, only finetuning the unet model?"
        updatedAt: '2022-12-29T05:45:57.937Z'
      numEdits: 0
      reactions: []
    id: 63ad299523f39d70bddb01a3
    type: comment
  author: nipi
  content: "> > Hello @Midu\uFF0CThank you for your sharing. Is the finetune Chinese-style\
    \ script based on the \"[diffusers](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)\"\
    \ script? Is it possible to share training skills or training parameters?\n> \n\
    > Hi @nipi ,\n> Yes, my script is based on diffusers for a good Deepspeed support.\
    \ I did not tune the hyperparameters a lot but only use a low learning rate (6e-5\
    \ for 256 batch size).\n\nHello @Midu,\nThank you for responding. The scheduler\
    \ in the model's scheduler config.json uses EulerDiscreteScheduler, and the prediction\
    \ type is v _prediction, but the diffuser's EulerDiscreteScheduler does not implement\
    \ the get_velocity method. Do you make use of DDPMScheduler finetune? Furthermore,\
    \ do you freeze the gradients of text encoder and vae during the training process,\
    \ only finetuning the unet model?"
  created_at: 2022-12-29 05:45:57+00:00
  edited: false
  hidden: false
  id: 63ad299523f39d70bddb01a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1494031fa331cf6f61b5a59294a4e696.svg
      fullname: pengwang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nipi
      type: user
    createdAt: '2022-12-29T09:40:50.000Z'
    data:
      edited: false
      editors:
      - nipi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1494031fa331cf6f61b5a59294a4e696.svg
          fullname: pengwang
          isHf: false
          isPro: false
          name: nipi
          type: user
        html: "<blockquote>\n<blockquote>\n<blockquote>\n<p>Hello <span data-props=\"\
          {&quot;user&quot;:&quot;Midu&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/Midu\">@<span class=\"underline\">Midu</span></a></span>\n\
          \n\t</span></span>\uFF0CThank you for your sharing. Is the finetune Chinese-style\
          \ script based on the \"<a rel=\"nofollow\" href=\"https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py\"\
          >diffusers</a>\" script? Is it possible to share training skills or training\
          \ parameters?</p>\n</blockquote>\n<p>Hi <span data-props=\"{&quot;user&quot;:&quot;nipi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/nipi\"\
          >@<span class=\"underline\">nipi</span></a></span>\n\n\t</span></span> ,<br>Yes,\
          \ my script is based on diffusers for a good Deepspeed support. I did not\
          \ tune the hyperparameters a lot but only use a low learning rate (6e-5\
          \ for 256 batch size).</p>\n</blockquote>\n<p>Hello <span data-props=\"\
          {&quot;user&quot;:&quot;Midu&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/Midu\">@<span class=\"underline\">Midu</span></a></span>\n\
          \n\t</span></span>,<br>Thank you for responding. The scheduler in the model's\
          \ scheduler config.json uses EulerDiscreteScheduler, and the prediction\
          \ type is v _prediction, but the diffuser's EulerDiscreteScheduler does\
          \ not implement the get_velocity method. Do you make use of DDPMScheduler\
          \ finetune? Furthermore, do you freeze the gradients of text encoder and\
          \ vae during the training process, only finetuning the unet model?</p>\n\
          </blockquote>\n<p>Hi <span data-props=\"{&quot;user&quot;:&quot;Midu&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Midu\"\
          >@<span class=\"underline\">Midu</span></a></span>\n\n\t</span></span> ,<br>I\
          \ can normally execute scripts with a batch size of 256 using the zero stage\
          \ 3&amp;pytorch lightning package, but I'm not sure how pytorch lightning\
          \ uses the ema strategy under multiple gpus, and there's a dimension issue\
          \ when directly modifying the diffusers text_to_image script. Could you\
          \ please share the finetune code? If that is not possible, please send me\
          \ a private message (my email address is <a rel=\"nofollow\" href=\"mailto:by_nipi@163.com\"\
          >by_nipi@163.com</a>).</p>\n"
        raw: "> > > Hello @Midu\uFF0CThank you for your sharing. Is the finetune Chinese-style\
          \ script based on the \"[diffusers](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)\"\
          \ script? Is it possible to share training skills or training parameters?\n\
          > > \n> > Hi @nipi ,\n> > Yes, my script is based on diffusers for a good\
          \ Deepspeed support. I did not tune the hyperparameters a lot but only use\
          \ a low learning rate (6e-5 for 256 batch size).\n> \n> Hello @Midu,\n>\
          \ Thank you for responding. The scheduler in the model's scheduler config.json\
          \ uses EulerDiscreteScheduler, and the prediction type is v _prediction,\
          \ but the diffuser's EulerDiscreteScheduler does not implement the get_velocity\
          \ method. Do you make use of DDPMScheduler finetune? Furthermore, do you\
          \ freeze the gradients of text encoder and vae during the training process,\
          \ only finetuning the unet model?\n\nHi @Midu ,\nI can normally execute\
          \ scripts with a batch size of 256 using the zero stage 3&pytorch lightning\
          \ package, but I'm not sure how pytorch lightning uses the ema strategy\
          \ under multiple gpus, and there's a dimension issue when directly modifying\
          \ the diffusers text_to_image script. Could you please share the finetune\
          \ code? If that is not possible, please send me a private message (my email\
          \ address is by_nipi@163.com)."
        updatedAt: '2022-12-29T09:40:50.500Z'
      numEdits: 0
      reactions: []
    id: 63ad60a256a3b69537830ed7
    type: comment
  author: nipi
  content: "> > > Hello @Midu\uFF0CThank you for your sharing. Is the finetune Chinese-style\
    \ script based on the \"[diffusers](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)\"\
    \ script? Is it possible to share training skills or training parameters?\n> >\
    \ \n> > Hi @nipi ,\n> > Yes, my script is based on diffusers for a good Deepspeed\
    \ support. I did not tune the hyperparameters a lot but only use a low learning\
    \ rate (6e-5 for 256 batch size).\n> \n> Hello @Midu,\n> Thank you for responding.\
    \ The scheduler in the model's scheduler config.json uses EulerDiscreteScheduler,\
    \ and the prediction type is v _prediction, but the diffuser's EulerDiscreteScheduler\
    \ does not implement the get_velocity method. Do you make use of DDPMScheduler\
    \ finetune? Furthermore, do you freeze the gradients of text encoder and vae during\
    \ the training process, only finetuning the unet model?\n\nHi @Midu ,\nI can normally\
    \ execute scripts with a batch size of 256 using the zero stage 3&pytorch lightning\
    \ package, but I'm not sure how pytorch lightning uses the ema strategy under\
    \ multiple gpus, and there's a dimension issue when directly modifying the diffusers\
    \ text_to_image script. Could you please share the finetune code? If that is not\
    \ possible, please send me a private message (my email address is by_nipi@163.com)."
  created_at: 2022-12-29 09:40:50+00:00
  edited: false
  hidden: false
  id: 63ad60a256a3b69537830ed7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2914bdf3d344b0e34da456814bfcc6dd.svg
      fullname: LiuYidong
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Midu
      type: user
    createdAt: '2023-01-03T06:08:44.000Z'
    data:
      edited: false
      editors:
      - Midu
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2914bdf3d344b0e34da456814bfcc6dd.svg
          fullname: LiuYidong
          isHf: false
          isPro: false
          name: Midu
          type: user
        html: "<blockquote>\n<blockquote>\n<blockquote>\n<p>Hello <span data-props=\"\
          {&quot;user&quot;:&quot;Midu&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/Midu\">@<span class=\"underline\">Midu</span></a></span>\n\
          \n\t</span></span>\uFF0CThank you for your sharing. Is the finetune Chinese-style\
          \ script based on the \"<a rel=\"nofollow\" href=\"https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py\"\
          >diffusers</a>\" script? Is it possible to share training skills or training\
          \ parameters?</p>\n</blockquote>\n<p>Hi <span data-props=\"{&quot;user&quot;:&quot;nipi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/nipi\"\
          >@<span class=\"underline\">nipi</span></a></span>\n\n\t</span></span> ,<br>Yes,\
          \ my script is based on diffusers for a good Deepspeed support. I did not\
          \ tune the hyperparameters a lot but only use a low learning rate (6e-5\
          \ for 256 batch size).</p>\n</blockquote>\n<p>Hello <span data-props=\"\
          {&quot;user&quot;:&quot;Midu&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/Midu\">@<span class=\"underline\">Midu</span></a></span>\n\
          \n\t</span></span>,<br>Thank you for responding. The scheduler in the model's\
          \ scheduler config.json uses EulerDiscreteScheduler, and the prediction\
          \ type is v _prediction, but the diffuser's EulerDiscreteScheduler does\
          \ not implement the get_velocity method. Do you make use of DDPMScheduler\
          \ finetune? Furthermore, do you freeze the gradients of text encoder and\
          \ vae during the training process, only finetuning the unet model?</p>\n\
          </blockquote>\n<p>When finetuning, use DDPMScheduler to schedule noise and\
          \ use get_velocity function, and use EulerDiscreteScheduler for sampling.</p>\n"
        raw: "> > > Hello @Midu\uFF0CThank you for your sharing. Is the finetune Chinese-style\
          \ script based on the \"[diffusers](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)\"\
          \ script? Is it possible to share training skills or training parameters?\n\
          > > \n> > Hi @nipi ,\n> > Yes, my script is based on diffusers for a good\
          \ Deepspeed support. I did not tune the hyperparameters a lot but only use\
          \ a low learning rate (6e-5 for 256 batch size).\n> \n> Hello @Midu,\n>\
          \ Thank you for responding. The scheduler in the model's scheduler config.json\
          \ uses EulerDiscreteScheduler, and the prediction type is v _prediction,\
          \ but the diffuser's EulerDiscreteScheduler does not implement the get_velocity\
          \ method. Do you make use of DDPMScheduler finetune? Furthermore, do you\
          \ freeze the gradients of text encoder and vae during the training process,\
          \ only finetuning the unet model?\n\nWhen finetuning, use DDPMScheduler\
          \ to schedule noise and use get_velocity function, and use EulerDiscreteScheduler\
          \ for sampling."
        updatedAt: '2023-01-03T06:08:44.749Z'
      numEdits: 0
      reactions: []
    id: 63b3c66c0dddc8f717fe562d
    type: comment
  author: Midu
  content: "> > > Hello @Midu\uFF0CThank you for your sharing. Is the finetune Chinese-style\
    \ script based on the \"[diffusers](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)\"\
    \ script? Is it possible to share training skills or training parameters?\n> >\
    \ \n> > Hi @nipi ,\n> > Yes, my script is based on diffusers for a good Deepspeed\
    \ support. I did not tune the hyperparameters a lot but only use a low learning\
    \ rate (6e-5 for 256 batch size).\n> \n> Hello @Midu,\n> Thank you for responding.\
    \ The scheduler in the model's scheduler config.json uses EulerDiscreteScheduler,\
    \ and the prediction type is v _prediction, but the diffuser's EulerDiscreteScheduler\
    \ does not implement the get_velocity method. Do you make use of DDPMScheduler\
    \ finetune? Furthermore, do you freeze the gradients of text encoder and vae during\
    \ the training process, only finetuning the unet model?\n\nWhen finetuning, use\
    \ DDPMScheduler to schedule noise and use get_velocity function, and use EulerDiscreteScheduler\
    \ for sampling."
  created_at: 2023-01-03 06:08:44+00:00
  edited: false
  hidden: false
  id: 63b3c66c0dddc8f717fe562d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/1494031fa331cf6f61b5a59294a4e696.svg
      fullname: pengwang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nipi
      type: user
    createdAt: '2023-01-28T03:25:01.000Z'
    data:
      status: closed
    id: 63d4958d85118edc044c9308
    type: status-change
  author: nipi
  created_at: 2023-01-28 03:25:01+00:00
  id: 63d4958d85118edc044c9308
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Midu/chinese-style-stable-diffusion-2-v0.1
repo_type: model
status: closed
target_branch: null
title: ' Is it possible to share training skills or training parameters?'
