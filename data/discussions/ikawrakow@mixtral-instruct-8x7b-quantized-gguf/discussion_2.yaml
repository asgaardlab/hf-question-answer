!!python/object:huggingface_hub.community.DiscussionWithDetails
author: cmh
conflicting_files: null
created_at: 2024-01-09 13:37:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/631f1e015ba8c02634093d59/AIJwL4LEsMely6FvzdSSV.png?w=200&h=200&f=face
      fullname: cmh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cmh
      type: user
    createdAt: '2024-01-09T13:37:49.000Z'
    data:
      edited: true
      editors:
      - cmh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.26098814606666565
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/631f1e015ba8c02634093d59/AIJwL4LEsMely6FvzdSSV.png?w=200&h=200&f=face
          fullname: cmh
          isHf: false
          isPro: false
          name: cmh
          type: user
        html: "<p>There seems to be an issue with mixtral-instruct-8x7b-q3k-medium.gguf.\
          \ It will give the first token then output garbage. The other quants are\
          \ fine tho.<br>Exemple:<br>PS C:\\Users\\Windows\\AI&gt; C:\\Users\\Windows\\\
          AI\\main.exe -m C:\\Users\\Windows\\AI\\models\\mixtral-instruct-8x7b-q3k-medium.gguf\
          \ -ngl 15 -t 7 --repeat_penalty 1 --no-penalize-nl --color --temp 0 --top-k\
          \ 50 --top-p 1 -c 8192 -n -1 --seed 1 -p \" [INST] You are an LLM trained\
          \ to follow instructions. Here's an instruction: explain the incompleteness\
          \ theorems [/INST]  \"<br>[...]<br>\"The\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585<br>PS C:\\\
          Users\\Windows\\AI&gt; </p>\n"
        raw: "There seems to be an issue with mixtral-instruct-8x7b-q3k-medium.gguf.\
          \ It will give the first token then output garbage. The other quants are\
          \ fine tho.\nExemple:\nPS C:\\Users\\Windows\\AI> C:\\Users\\Windows\\AI\\\
          main.exe -m C:\\Users\\Windows\\AI\\models\\mixtral-instruct-8x7b-q3k-medium.gguf\
          \ -ngl 15 -t 7 --repeat_penalty 1 --no-penalize-nl --color --temp 0 --top-k\
          \ 50 --top-p 1 -c 8192 -n -1 --seed 1 -p \" [INST] You are an LLM trained\
          \ to follow instructions. Here's an instruction: explain the incompleteness\
          \ theorems [/INST]  \"\n[...]\n\"The\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
          \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\nPS C:\\Users\\\
          Windows\\AI> "
        updatedAt: '2024-01-09T13:38:10.152Z'
      numEdits: 1
      reactions: []
    id: 659d4c2de520cf08924e44f8
    type: comment
  author: cmh
  content: "There seems to be an issue with mixtral-instruct-8x7b-q3k-medium.gguf.\
    \ It will give the first token then output garbage. The other quants are fine\
    \ tho.\nExemple:\nPS C:\\Users\\Windows\\AI> C:\\Users\\Windows\\AI\\main.exe\
    \ -m C:\\Users\\Windows\\AI\\models\\mixtral-instruct-8x7b-q3k-medium.gguf -ngl\
    \ 15 -t 7 --repeat_penalty 1 --no-penalize-nl --color --temp 0 --top-k 50 --top-p\
    \ 1 -c 8192 -n -1 --seed 1 -p \" [INST] You are an LLM trained to follow instructions.\
    \ Here's an instruction: explain the incompleteness theorems [/INST]  \"\n[...]\n\
    \"The\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\
    \u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\nPS C:\\\
    Users\\Windows\\AI> "
  created_at: 2024-01-09 13:37:49+00:00
  edited: true
  hidden: false
  id: 659d4c2de520cf08924e44f8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/afd23461306f89bb80c5c43674438756.svg
      fullname: "\u72E9\u884C\u6642\u7D75"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tokie
      type: user
    createdAt: '2024-01-10T11:12:41.000Z'
    data:
      edited: false
      editors:
      - Tokie
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7137433290481567
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/afd23461306f89bb80c5c43674438756.svg
          fullname: "\u72E9\u884C\u6642\u7D75"
          isHf: false
          isPro: false
          name: Tokie
          type: user
        html: "<p>I observe similar behavior with <code>mixtral-instruct-8x7b-q4k-medium.gguf</code>,\
          \ except I can\u02BCt even get it to output a single good token. With <code>--temp\
          \ 0</code> it only outputs <code>\u2585</code>, and with higher temperatures\
          \ only nonsense.</p>\n"
        raw: "I observe similar behavior with `mixtral-instruct-8x7b-q4k-medium.gguf`,\
          \ except I can\u02BCt even get it to output a single good token. With `--temp\
          \ 0` it only outputs `\u2585`, and with higher temperatures only nonsense."
        updatedAt: '2024-01-10T11:12:41.692Z'
      numEdits: 0
      reactions: []
    id: 659e7ba9ef09971a71a563f3
    type: comment
  author: Tokie
  content: "I observe similar behavior with `mixtral-instruct-8x7b-q4k-medium.gguf`,\
    \ except I can\u02BCt even get it to output a single good token. With `--temp\
    \ 0` it only outputs `\u2585`, and with higher temperatures only nonsense."
  created_at: 2024-01-10 11:12:41+00:00
  edited: false
  hidden: false
  id: 659e7ba9ef09971a71a563f3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/98d7cbc7bf4cbf4f2810cbc0a1a34d64.svg
      fullname: Iwan Kawrakow
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ikawrakow
      type: user
    createdAt: '2024-01-10T12:40:22.000Z'
    data:
      edited: false
      editors:
      - ikawrakow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.943093478679657
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/98d7cbc7bf4cbf4f2810cbc0a1a34d64.svg
          fullname: Iwan Kawrakow
          isHf: false
          isPro: false
          name: ikawrakow
          type: user
        html: "<p>Not sure. With the above I get</p>\n<pre><code>The Incompleteness\
          \ Theorems are two of the most famous theorems in mathematical logic, both\
          \ proven by Kurt G\xF6del in 1931.\nThe first theorem, known as G\xF6del's\
          \ First Incompleteness Theorem, states that no consistent, recursive axiomatic\
          \ system can prove\nall true statements about the natural numbers. This\
          \ theorem implies that there are true statements that cannot be proven within\
          \ any\ngiven axiomatic system, demonstrating that mathematics is inherently\
          \ incomplete.\n\nThe second theorem, G\xF6del's Second Incompleteness Theorem,\
          \ states that within any consistent, recursive axiomatic system, the\nconsistency\
          \ of the system cannot be proven. This theorem highlights the limitations\
          \ of formal systems and shows that mathematics\ncannot be reduced to a set\
          \ of axioms that can be proven to be consistent.\n\nThese theorems have\
          \ profound implications for the foundations of mathematics and have been\
          \ the subject of much debate and\ndiscussion in the philosophical and mathematical\
          \ communities. They demonstrate that there are limits to what can be proven\
          \ within\nformal systems and that mathematics is not just a matter of deduction\
          \ from axioms, but also involves creativity and intuition. [end of text]\n\
          </code></pre>\n"
        raw: "Not sure. With the above I get\n```\nThe Incompleteness Theorems are\
          \ two of the most famous theorems in mathematical logic, both proven by\
          \ Kurt G\xF6del in 1931.\nThe first theorem, known as G\xF6del's First Incompleteness\
          \ Theorem, states that no consistent, recursive axiomatic system can prove\n\
          all true statements about the natural numbers. This theorem implies that\
          \ there are true statements that cannot be proven within any\ngiven axiomatic\
          \ system, demonstrating that mathematics is inherently incomplete.\n\nThe\
          \ second theorem, G\xF6del's Second Incompleteness Theorem, states that\
          \ within any consistent, recursive axiomatic system, the\nconsistency of\
          \ the system cannot be proven. This theorem highlights the limitations of\
          \ formal systems and shows that mathematics\ncannot be reduced to a set\
          \ of axioms that can be proven to be consistent.\n\nThese theorems have\
          \ profound implications for the foundations of mathematics and have been\
          \ the subject of much debate and\ndiscussion in the philosophical and mathematical\
          \ communities. They demonstrate that there are limits to what can be proven\
          \ within\nformal systems and that mathematics is not just a matter of deduction\
          \ from axioms, but also involves creativity and intuition. [end of text]\n\
          ```"
        updatedAt: '2024-01-10T12:40:22.272Z'
      numEdits: 0
      reactions: []
    id: 659e90361b45843689ba276d
    type: comment
  author: ikawrakow
  content: "Not sure. With the above I get\n```\nThe Incompleteness Theorems are two\
    \ of the most famous theorems in mathematical logic, both proven by Kurt G\xF6\
    del in 1931.\nThe first theorem, known as G\xF6del's First Incompleteness Theorem,\
    \ states that no consistent, recursive axiomatic system can prove\nall true statements\
    \ about the natural numbers. This theorem implies that there are true statements\
    \ that cannot be proven within any\ngiven axiomatic system, demonstrating that\
    \ mathematics is inherently incomplete.\n\nThe second theorem, G\xF6del's Second\
    \ Incompleteness Theorem, states that within any consistent, recursive axiomatic\
    \ system, the\nconsistency of the system cannot be proven. This theorem highlights\
    \ the limitations of formal systems and shows that mathematics\ncannot be reduced\
    \ to a set of axioms that can be proven to be consistent.\n\nThese theorems have\
    \ profound implications for the foundations of mathematics and have been the subject\
    \ of much debate and\ndiscussion in the philosophical and mathematical communities.\
    \ They demonstrate that there are limits to what can be proven within\nformal\
    \ systems and that mathematics is not just a matter of deduction from axioms,\
    \ but also involves creativity and intuition. [end of text]\n```"
  created_at: 2024-01-10 12:40:22+00:00
  edited: false
  hidden: false
  id: 659e90361b45843689ba276d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/631f1e015ba8c02634093d59/AIJwL4LEsMely6FvzdSSV.png?w=200&h=200&f=face
      fullname: cmh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cmh
      type: user
    createdAt: '2024-01-11T01:35:10.000Z'
    data:
      edited: true
      editors:
      - cmh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9506186246871948
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/631f1e015ba8c02634093d59/AIJwL4LEsMely6FvzdSSV.png?w=200&h=200&f=face
          fullname: cmh
          isHf: false
          isPro: false
          name: cmh
          type: user
        html: '<p>Yeah, mixtral-instruct-8x7b-q4k-medium.gguf is also borked here.<br>Llama.cpp
          was compiled with -DLLAMA_CUBLAS=ON -DLLAMA_CUDA_F16=ON so I recompiled
          without F16 but it has the same behavior.<br>I don''t have those issues
          with the files that TheBloke have made available (but some didn''t work
          in the past and they removed them).<br>IDK. Just to be thorough, I''m using
          CUDA 12.1, llama.cpp''s master branch (latest commit cd108e6) on Windows
          11 with an RTX 3060 12GB.</p>

          <p>edit:<br>mixtral-instruct-8x7b-2.10bpw.gguf works fine<br>mixtral-instruct-8x7b-2.34bpw.gguf
          do not. </p>

          <p>The file is 12,7&nbsp;gb, the model size reported is wrong:<br>llm_load_print_meta:
          model ftype      = unknown, may not work<br>llm_load_print_meta: model params     =
          46.70 B<br>llm_load_print_meta: model size       = 42.15 GiB (7.75 BPW)</p>

          <p>Llama.cpp crashes with<br>GGML_ASSERT: C:\Users\Windows\AI\llama.cpp\ggml-cuda.cu:7899:
          false</p>

          '
        raw: "Yeah, mixtral-instruct-8x7b-q4k-medium.gguf is also borked here.\nLlama.cpp\
          \ was compiled with -DLLAMA_CUBLAS=ON -DLLAMA_CUDA_F16=ON so I recompiled\
          \ without F16 but it has the same behavior. \nI don't have those issues\
          \ with the files that TheBloke have made available (but some didn't work\
          \ in the past and they removed them).\nIDK. Just to be thorough, I'm using\
          \ CUDA 12.1, llama.cpp's master branch (latest commit cd108e6) on Windows\
          \ 11 with an RTX 3060 12GB.\n\nedit: \nmixtral-instruct-8x7b-2.10bpw.gguf\
          \ works fine\nmixtral-instruct-8x7b-2.34bpw.gguf do not. \n\nThe file is\
          \ 12,7\_gb, the model size reported is wrong:\nllm_load_print_meta: model\
          \ ftype      = unknown, may not work\nllm_load_print_meta: model params\
          \     = 46.70 B\nllm_load_print_meta: model size       = 42.15 GiB (7.75\
          \ BPW)\n\nLlama.cpp crashes with\nGGML_ASSERT: C:\\Users\\Windows\\AI\\\
          llama.cpp\\ggml-cuda.cu:7899: false"
        updatedAt: '2024-01-11T11:39:55.873Z'
      numEdits: 6
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - KeyboardMasher
        - RachidAR
    id: 659f45ce96cd935fab78274b
    type: comment
  author: cmh
  content: "Yeah, mixtral-instruct-8x7b-q4k-medium.gguf is also borked here.\nLlama.cpp\
    \ was compiled with -DLLAMA_CUBLAS=ON -DLLAMA_CUDA_F16=ON so I recompiled without\
    \ F16 but it has the same behavior. \nI don't have those issues with the files\
    \ that TheBloke have made available (but some didn't work in the past and they\
    \ removed them).\nIDK. Just to be thorough, I'm using CUDA 12.1, llama.cpp's master\
    \ branch (latest commit cd108e6) on Windows 11 with an RTX 3060 12GB.\n\nedit:\
    \ \nmixtral-instruct-8x7b-2.10bpw.gguf works fine\nmixtral-instruct-8x7b-2.34bpw.gguf\
    \ do not. \n\nThe file is 12,7\_gb, the model size reported is wrong:\nllm_load_print_meta:\
    \ model ftype      = unknown, may not work\nllm_load_print_meta: model params\
    \     = 46.70 B\nllm_load_print_meta: model size       = 42.15 GiB (7.75 BPW)\n\
    \nLlama.cpp crashes with\nGGML_ASSERT: C:\\Users\\Windows\\AI\\llama.cpp\\ggml-cuda.cu:7899:\
    \ false"
  created_at: 2024-01-11 01:35:10+00:00
  edited: true
  hidden: false
  id: 659f45ce96cd935fab78274b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: ikawrakow/mixtral-instruct-8x7b-quantized-gguf
repo_type: model
status: open
target_branch: null
title: mixtral-instruct-8x7b-q3k-medium.gguf
