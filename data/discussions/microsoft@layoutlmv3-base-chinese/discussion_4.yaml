!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Viking714
conflicting_files: null
created_at: 2023-06-03 08:26:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5774a69421ba933e406863bfcba946d8.svg
      fullname: VikingZ
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Viking714
      type: user
    createdAt: '2023-06-03T09:26:01.000Z'
    data:
      edited: false
      editors:
      - Viking714
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.685505211353302
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5774a69421ba933e406863bfcba946d8.svg
          fullname: VikingZ
          isHf: false
          isPro: false
          name: Viking714
          type: user
        html: "<p>Hello, I recently use this model to do Chinese image OCR, but I\
          \ got the wrong words output, the code I use is below:</p>\n<p>from PIL\
          \ import Image<br>img_pil = Image.open('/kaggle/input/timuimage/timu.jpg')<br>image\
          \ = img_pil.convert(\"RGB\")</p>\n<p>from transformers import LayoutXLMProcessor<br>processor\
          \ = LayoutXLMProcessor.from_pretrained(\"Microsoft/layoutlmv3-base-chinese\"\
          )<br>feature_extractor =  processor.feature_extractor</p>\n<h1 id=\"preprocess-image-to-text\"\
          >preprocess image to text</h1>\n<p>encoded_inputs = feature_extractor(image)<br>words\
          \ = encoded_inputs.words</p>\n<h1 id=\"just-output-the-words-in-a-format\"\
          >Just output the words in a format</h1>\n<p>text = \"\"<br>for word in words[0]:<br>\
          \    text = text + word<br>print(text)</p>\n<p>The output is as below:<br>re\\\
          1AlltTTiani|iete44si)ii\"eahi|WAiL\u201C4HNHHAilKtintteersNaaiftyUeawliditieeaHuseuay1he\u2018\
          4LrLHauiiiasiliatififiaigMtiiarecuaEtaaii!t~BCpecaaOaeeiyfnaeipiesaoriyeae4raBiia4aiaei{thiulEiuaadlfh,aeaatteateeileweypakPotHsae</p>\n\
          <p>The Image I use is from <a rel=\"nofollow\" href=\"https://www.kaggle.com/datasets/viking714/timuimage\"\
          >https://www.kaggle.com/datasets/viking714/timuimage</a>, everyone can see\
          \ the image, it's public.<br>I use the same method to OCR English images\
          \ to words by LayoutXLM and LayoutLMV2 models, they are both ok.<br>Thank\
          \ you very much.</p>\n"
        raw: "Hello, I recently use this model to do Chinese image OCR, but I got\
          \ the wrong words output, the code I use is below:\r\n\r\nfrom PIL import\
          \ Image\r\nimg_pil = Image.open('/kaggle/input/timuimage/timu.jpg') \r\n\
          image = img_pil.convert(\"RGB\")\r\n\r\nfrom transformers import LayoutXLMProcessor\r\
          \nprocessor = LayoutXLMProcessor.from_pretrained(\"Microsoft/layoutlmv3-base-chinese\"\
          )\r\nfeature_extractor =  processor.feature_extractor\r\n\r\n# preprocess\
          \ image to text\r\nencoded_inputs = feature_extractor(image)\r\nwords =\
          \ encoded_inputs.words\r\n\r\n# Just output the words in a format\r\ntext\
          \ = \"\"\r\nfor word in words[0]:\r\n    text = text + word\r\nprint(text)\r\
          \n\r\nThe output is as below:\r\nre\\1AlltTTiani|iete44si)ii\"eahi|WAiL\u201C\
          4HNHHAilKtintteersNaaiftyUeawliditieeaHuseuay1he\u20184LrLHauiiiasiliatififiaigMtiiarecuaEtaaii!t~BCpecaaOaeeiyfnaeipiesaoriyeae4raBiia4aiaei{thiulEiuaadlfh,aeaatteateeileweypakPotHsae\r\
          \n\r\nThe Image I use is from https://www.kaggle.com/datasets/viking714/timuimage,\
          \ everyone can see the image, it's public.\r\nI use the same method to OCR\
          \ English images to words by LayoutXLM and LayoutLMV2 models, they are both\
          \ ok. \r\nThank you very much."
        updatedAt: '2023-06-03T09:26:01.354Z'
      numEdits: 0
      reactions: []
    id: 647b072901025ddbd98ffe24
    type: comment
  author: Viking714
  content: "Hello, I recently use this model to do Chinese image OCR, but I got the\
    \ wrong words output, the code I use is below:\r\n\r\nfrom PIL import Image\r\n\
    img_pil = Image.open('/kaggle/input/timuimage/timu.jpg') \r\nimage = img_pil.convert(\"\
    RGB\")\r\n\r\nfrom transformers import LayoutXLMProcessor\r\nprocessor = LayoutXLMProcessor.from_pretrained(\"\
    Microsoft/layoutlmv3-base-chinese\")\r\nfeature_extractor =  processor.feature_extractor\r\
    \n\r\n# preprocess image to text\r\nencoded_inputs = feature_extractor(image)\r\
    \nwords = encoded_inputs.words\r\n\r\n# Just output the words in a format\r\n\
    text = \"\"\r\nfor word in words[0]:\r\n    text = text + word\r\nprint(text)\r\
    \n\r\nThe output is as below:\r\nre\\1AlltTTiani|iete44si)ii\"eahi|WAiL\u201C\
    4HNHHAilKtintteersNaaiftyUeawliditieeaHuseuay1he\u20184LrLHauiiiasiliatififiaigMtiiarecuaEtaaii!t~BCpecaaOaeeiyfnaeipiesaoriyeae4raBiia4aiaei{thiulEiuaadlfh,aeaatteateeileweypakPotHsae\r\
    \n\r\nThe Image I use is from https://www.kaggle.com/datasets/viking714/timuimage,\
    \ everyone can see the image, it's public.\r\nI use the same method to OCR English\
    \ images to words by LayoutXLM and LayoutLMV2 models, they are both ok. \r\nThank\
    \ you very much."
  created_at: 2023-06-03 08:26:01+00:00
  edited: false
  hidden: false
  id: 647b072901025ddbd98ffe24
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6374c494958cd71fa7ea0a9d/2YCKv6tXCZXtsIOFIIXjs.png?w=200&h=200&f=face
      fullname: yuyijiong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yuyijiong
      type: user
    createdAt: '2023-08-27T02:44:45.000Z'
    data:
      edited: false
      editors:
      - yuyijiong
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4060031473636627
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6374c494958cd71fa7ea0a9d/2YCKv6tXCZXtsIOFIIXjs.png?w=200&h=200&f=face
          fullname: yuyijiong
          isHf: false
          isPro: false
          name: yuyijiong
          type: user
        html: "<p>\u4F60\u9700\u8981\u8BBE\u7F6Eocr\u8BED\u8A00\u4E3A\u4E2D\u6587\
          +\u82F1\u6587\uFF0C\u4E5F\u5C31\u662F'chi_sim+eng'</p>\n<pre><code>model_name=\"\
          microsoft/layoutlmv3-base-chinese\"\nimage_processor = LayoutLMv3ImageProcessor.from_pretrained(model_name,ocr_lang='chi_sim+eng')\n\
          tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\nprocessor =\
          \ LayoutLMv3Processor(image_processor=image_processor,tokenizer=tokenizer,apply_ocr=True)\n\
          </code></pre>\n"
        raw: "\u4F60\u9700\u8981\u8BBE\u7F6Eocr\u8BED\u8A00\u4E3A\u4E2D\u6587+\u82F1\
          \u6587\uFF0C\u4E5F\u5C31\u662F'chi_sim+eng'\n```\nmodel_name=\"microsoft/layoutlmv3-base-chinese\"\
          \nimage_processor = LayoutLMv3ImageProcessor.from_pretrained(model_name,ocr_lang='chi_sim+eng')\n\
          tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\nprocessor =\
          \ LayoutLMv3Processor(image_processor=image_processor,tokenizer=tokenizer,apply_ocr=True)\n\
          ```"
        updatedAt: '2023-08-27T02:44:45.149Z'
      numEdits: 0
      reactions: []
    id: 64eab89de574e31915aa9e79
    type: comment
  author: yuyijiong
  content: "\u4F60\u9700\u8981\u8BBE\u7F6Eocr\u8BED\u8A00\u4E3A\u4E2D\u6587+\u82F1\
    \u6587\uFF0C\u4E5F\u5C31\u662F'chi_sim+eng'\n```\nmodel_name=\"microsoft/layoutlmv3-base-chinese\"\
    \nimage_processor = LayoutLMv3ImageProcessor.from_pretrained(model_name,ocr_lang='chi_sim+eng')\n\
    tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\nprocessor = LayoutLMv3Processor(image_processor=image_processor,tokenizer=tokenizer,apply_ocr=True)\n\
    ```"
  created_at: 2023-08-27 01:44:45+00:00
  edited: false
  hidden: false
  id: 64eab89de574e31915aa9e79
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a5b52003cf2a4e9df04ac5ec3983e6f5.svg
      fullname: Resul Mamiyev
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: resulmamiyev
      type: user
    createdAt: '2023-09-15T03:51:27.000Z'
    data:
      edited: false
      editors:
      - resulmamiyev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.704600989818573
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a5b52003cf2a4e9df04ac5ec3983e6f5.svg
          fullname: Resul Mamiyev
          isHf: false
          isPro: false
          name: resulmamiyev
          type: user
        html: '<p>Hello, I was trying to use it in the same way. But I got this error:</p>

          <hr>

          <p>ValueError                                Traceback (most recent call
          last)<br> in &lt;cell line: 4&gt;()<br>      2 image_processor = LayoutLMv3ImageProcessor.from_pretrained(model_name,ocr_lang=''chi_sim+eng'')<br>      3
          tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)<br>----&gt;
          4 processor = LayoutLMv3Processor(image_processor=image_processor,tokenizer=tokenizer,apply_ocr=True)</p>

          <p>ValueError: Received XLMRobertaTokenizer for argument tokenizer, but
          a (''LayoutLMv3Tokenizer'', ''LayoutLMv3TokenizerFast'') was expected.</p>

          <p>What can be wrong? Thanks</p>

          '
        raw: "Hello, I was trying to use it in the same way. But I got this error:\n\
          \n---------------------------------------------------------------------------\n\
          ValueError                                Traceback (most recent call last)\n\
          <ipython-input-17-84adec118009> in <cell line: 4>()\n      2 image_processor\
          \ = LayoutLMv3ImageProcessor.from_pretrained(model_name,ocr_lang='chi_sim+eng')\n\
          \      3 tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n---->\
          \ 4 processor = LayoutLMv3Processor(image_processor=image_processor,tokenizer=tokenizer,apply_ocr=True)\n\
          \nValueError: Received XLMRobertaTokenizer for argument tokenizer, but a\
          \ ('LayoutLMv3Tokenizer', 'LayoutLMv3TokenizerFast') was expected.\n\nWhat\
          \ can be wrong? Thanks"
        updatedAt: '2023-09-15T03:51:27.830Z'
      numEdits: 0
      reactions: []
    id: 6503d4bf93574a897180e127
    type: comment
  author: resulmamiyev
  content: "Hello, I was trying to use it in the same way. But I got this error:\n\
    \n---------------------------------------------------------------------------\n\
    ValueError                                Traceback (most recent call last)\n\
    <ipython-input-17-84adec118009> in <cell line: 4>()\n      2 image_processor =\
    \ LayoutLMv3ImageProcessor.from_pretrained(model_name,ocr_lang='chi_sim+eng')\n\
    \      3 tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n----> 4\
    \ processor = LayoutLMv3Processor(image_processor=image_processor,tokenizer=tokenizer,apply_ocr=True)\n\
    \nValueError: Received XLMRobertaTokenizer for argument tokenizer, but a ('LayoutLMv3Tokenizer',\
    \ 'LayoutLMv3TokenizerFast') was expected.\n\nWhat can be wrong? Thanks"
  created_at: 2023-09-15 02:51:27+00:00
  edited: false
  hidden: false
  id: 6503d4bf93574a897180e127
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6374c494958cd71fa7ea0a9d/2YCKv6tXCZXtsIOFIIXjs.png?w=200&h=200&f=face
      fullname: yuyijiong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yuyijiong
      type: user
    createdAt: '2023-09-15T05:44:32.000Z'
    data:
      edited: false
      editors:
      - yuyijiong
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2960895001888275
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6374c494958cd71fa7ea0a9d/2YCKv6tXCZXtsIOFIIXjs.png?w=200&h=200&f=face
          fullname: yuyijiong
          isHf: false
          isPro: false
          name: yuyijiong
          type: user
        html: "<p>\u627E\u5230LayoutLMv3Processor\u7684\u6E90\u7801\uFF0C\u628A<br>\
          \   <code> tokenizer_class = (\"LayoutLMv3Tokenizer\", \"LayoutLMv3TokenizerFast\"\
          )</code><br>\u6539\u6210<br>    <code>tokenizer_class = (\"LayoutLMv3Tokenizer\"\
          , \"LayoutLMv3TokenizerFast\",'XLMRobertaTokenizer','XLMRobertaTokenizerFast','LayoutXLMTokenizer')</code></p>\n"
        raw: "\u627E\u5230LayoutLMv3Processor\u7684\u6E90\u7801\uFF0C\u628A\n   ```\
          \ tokenizer_class = (\"LayoutLMv3Tokenizer\", \"LayoutLMv3TokenizerFast\"\
          )```\n\u6539\u6210\n    ```tokenizer_class = (\"LayoutLMv3Tokenizer\", \"\
          LayoutLMv3TokenizerFast\",'XLMRobertaTokenizer','XLMRobertaTokenizerFast','LayoutXLMTokenizer')```\n"
        updatedAt: '2023-09-15T05:44:32.313Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - nql
    id: 6503ef40dcfe8fd06a77b1a2
    type: comment
  author: yuyijiong
  content: "\u627E\u5230LayoutLMv3Processor\u7684\u6E90\u7801\uFF0C\u628A\n   ```\
    \ tokenizer_class = (\"LayoutLMv3Tokenizer\", \"LayoutLMv3TokenizerFast\")```\n\
    \u6539\u6210\n    ```tokenizer_class = (\"LayoutLMv3Tokenizer\", \"LayoutLMv3TokenizerFast\"\
    ,'XLMRobertaTokenizer','XLMRobertaTokenizerFast','LayoutXLMTokenizer')```\n"
  created_at: 2023-09-15 04:44:32+00:00
  edited: false
  hidden: false
  id: 6503ef40dcfe8fd06a77b1a2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/3DuqCX3TZmBD6GhBSmXu0.jpeg?w=200&h=200&f=face
      fullname: Xuchen Fan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fandl
      type: user
    createdAt: '2023-11-02T03:59:19.000Z'
    data:
      edited: false
      editors:
      - fandl
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9767407178878784
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/3DuqCX3TZmBD6GhBSmXu0.jpeg?w=200&h=200&f=face
          fullname: Xuchen Fan
          isHf: false
          isPro: false
          name: fandl
          type: user
        html: "<p>\u60A8\u597D\uFF0C\u8BF7\u95EE\u89E3\u51B3\u4E86\u5417\uFF0C\u6211\
          \u53C2\u8003\u4E0A\u9762\u7684\u65B9\u6CD5\u6700\u540E\u663E\u793A\u51FA\
          \u6765\u7684\u8FD8\u662F\u53EA\u6709\u82F1\u6587</p>\n"
        raw: "\u60A8\u597D\uFF0C\u8BF7\u95EE\u89E3\u51B3\u4E86\u5417\uFF0C\u6211\u53C2\
          \u8003\u4E0A\u9762\u7684\u65B9\u6CD5\u6700\u540E\u663E\u793A\u51FA\u6765\
          \u7684\u8FD8\u662F\u53EA\u6709\u82F1\u6587"
        updatedAt: '2023-11-02T03:59:19.237Z'
      numEdits: 0
      reactions: []
    id: 65431e97bcc444d7ce311c50
    type: comment
  author: fandl
  content: "\u60A8\u597D\uFF0C\u8BF7\u95EE\u89E3\u51B3\u4E86\u5417\uFF0C\u6211\u53C2\
    \u8003\u4E0A\u9762\u7684\u65B9\u6CD5\u6700\u540E\u663E\u793A\u51FA\u6765\u7684\
    \u8FD8\u662F\u53EA\u6709\u82F1\u6587"
  created_at: 2023-11-02 02:59:19+00:00
  edited: false
  hidden: false
  id: 65431e97bcc444d7ce311c50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/65aeb0b346ec01a6a2cc1a580765024d.svg
      fullname: z
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alex1qaz
      type: user
    createdAt: '2023-12-01T08:15:51.000Z'
    data:
      edited: false
      editors:
      - alex1qaz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.40455010533332825
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/65aeb0b346ec01a6a2cc1a580765024d.svg
          fullname: z
          isHf: false
          isPro: false
          name: alex1qaz
          type: user
        html: "<p>\u53C2\u8003\u4E4B\u524D\u7684\u56DE\u7B54\uFF0C\u6309\u7167\u4EE5\
          \u4E0B\u65B9\u5F0F\u53EF\u4EE5\u7684\u5230\u4E2D\u6587\u7ED3\u679C\u3002\
          \u5982\u679C\u4E0D\u884C\u7684\u8BDD\u53EF\u4EE5\u770B\u4E00\u4E0B\u4F60\
          \u7684tesseract-ocr\u662F\u4E0D\u662F\u7F3A\u5C11chi_sim.traineddata\u6587\
          \u4EF6\uFF0C\u4E00\u822C\u4F1A\u4FDD\u5B58\u5728/usr/share/tesseract-ocr/4.00/tessdata/</p>\n\
          <p>from transformers import XLMRobertaTokenizer, AutoModel, AutoProcessor,\
          \ LayoutLMv3ImageProcessor, LayoutLMv3Processor<br>model_name = \"Microsoft/layoutlmv3-base-chinese\"\
          <br>image_processor = LayoutLMv3ImageProcessor.from_pretrained(model_name,\
          \ ocr_lang='chi_sim+eng')<br>tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)<br>processor\
          \ = LayoutLMv3Processor(image_processor=image_processor,tokenizer=tokenizer,apply_ocr=True)<br>feature_extractor\
          \ = processor.feature_extractor<br>inputs = feature_extractor(image)<br>inputs['words']</p>\n"
        raw: "\u53C2\u8003\u4E4B\u524D\u7684\u56DE\u7B54\uFF0C\u6309\u7167\u4EE5\u4E0B\
          \u65B9\u5F0F\u53EF\u4EE5\u7684\u5230\u4E2D\u6587\u7ED3\u679C\u3002\u5982\
          \u679C\u4E0D\u884C\u7684\u8BDD\u53EF\u4EE5\u770B\u4E00\u4E0B\u4F60\u7684\
          tesseract-ocr\u662F\u4E0D\u662F\u7F3A\u5C11chi_sim.traineddata\u6587\u4EF6\
          \uFF0C\u4E00\u822C\u4F1A\u4FDD\u5B58\u5728/usr/share/tesseract-ocr/4.00/tessdata/\n\
          \nfrom transformers import XLMRobertaTokenizer, AutoModel, AutoProcessor,\
          \ LayoutLMv3ImageProcessor, LayoutLMv3Processor\nmodel_name = \"Microsoft/layoutlmv3-base-chinese\"\
          \nimage_processor = LayoutLMv3ImageProcessor.from_pretrained(model_name,\
          \ ocr_lang='chi_sim+eng')\ntokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n\
          processor = LayoutLMv3Processor(image_processor=image_processor,tokenizer=tokenizer,apply_ocr=True)\n\
          feature_extractor = processor.feature_extractor\ninputs = feature_extractor(image)\n\
          inputs['words']"
        updatedAt: '2023-12-01T08:15:51.639Z'
      numEdits: 0
      reactions: []
    id: 656996375958c68e3183a709
    type: comment
  author: alex1qaz
  content: "\u53C2\u8003\u4E4B\u524D\u7684\u56DE\u7B54\uFF0C\u6309\u7167\u4EE5\u4E0B\
    \u65B9\u5F0F\u53EF\u4EE5\u7684\u5230\u4E2D\u6587\u7ED3\u679C\u3002\u5982\u679C\
    \u4E0D\u884C\u7684\u8BDD\u53EF\u4EE5\u770B\u4E00\u4E0B\u4F60\u7684tesseract-ocr\u662F\
    \u4E0D\u662F\u7F3A\u5C11chi_sim.traineddata\u6587\u4EF6\uFF0C\u4E00\u822C\u4F1A\
    \u4FDD\u5B58\u5728/usr/share/tesseract-ocr/4.00/tessdata/\n\nfrom transformers\
    \ import XLMRobertaTokenizer, AutoModel, AutoProcessor, LayoutLMv3ImageProcessor,\
    \ LayoutLMv3Processor\nmodel_name = \"Microsoft/layoutlmv3-base-chinese\"\nimage_processor\
    \ = LayoutLMv3ImageProcessor.from_pretrained(model_name, ocr_lang='chi_sim+eng')\n\
    tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\nprocessor = LayoutLMv3Processor(image_processor=image_processor,tokenizer=tokenizer,apply_ocr=True)\n\
    feature_extractor = processor.feature_extractor\ninputs = feature_extractor(image)\n\
    inputs['words']"
  created_at: 2023-12-01 08:15:51+00:00
  edited: false
  hidden: false
  id: 656996375958c68e3183a709
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: microsoft/layoutlmv3-base-chinese
repo_type: model
status: open
target_branch: null
title: why chinese image ocr error ocde
