!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bobsled
conflicting_files: null
created_at: 2022-12-06 20:14:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/69af6a4614e9902ac94a5fa250395ac5.svg
      fullname: Mike Boyer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bobsled
      type: user
    createdAt: '2022-12-06T20:14:38.000Z'
    data:
      edited: false
      editors:
      - bobsled
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/69af6a4614e9902ac94a5fa250395ac5.svg
          fullname: Mike Boyer
          isHf: false
          isPro: false
          name: bobsled
          type: user
        html: '<p>Having the absolute reverse problem. I can get tolerable results
          on SD2 with the 512 model, but get very "crude" or pixelated/lowres results
          when invoking with the 768model at either 768x768 or 512x512 resolutions.
          I have the appropriate yaml files. I got the poor results on a in-place
          upgrade before so have built an entirely new conda environment and getting
          the same poor results. (file examples for same prompt and seed attached).
          Using cuda 11.7, pytorch 1.13.0; have nvidia3090 24gb so no constraints.
          xformers not installed</p>

          <p>Curious if anyone has any insight as to what I might have missed or be
          doing/configure wrong. Grateful for any insights! Any help appreciated!</p>

          <p>prompt "a jack russell dog wearing sunglass smoking a cigar and holding
          a martini" </p>

          <p>-- 768 model cruddy output --<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1670357376552-6362e0f92c0bb59ecc1b8d64.png"><img
          alt="grid-0002.png" src="https://cdn-uploads.huggingface.co/production/uploads/1670357376552-6362e0f92c0bb59ecc1b8d64.png"></a></p>

          <p>-- 512 model much better, but still likely way worse than 768 when I
          figure this out --<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1670357364439-6362e0f92c0bb59ecc1b8d64.png"><img
          alt="grid-0001.png" src="https://cdn-uploads.huggingface.co/production/uploads/1670357364439-6362e0f92c0bb59ecc1b8d64.png"></a></p>

          '
        raw: "Having the absolute reverse problem. I can get tolerable results on\
          \ SD2 with the 512 model, but get very \"crude\" or pixelated/lowres results\
          \ when invoking with the 768model at either 768x768 or 512x512 resolutions.\
          \ I have the appropriate yaml files. I got the poor results on a in-place\
          \ upgrade before so have built an entirely new conda environment and getting\
          \ the same poor results. (file examples for same prompt and seed attached).\
          \ Using cuda 11.7, pytorch 1.13.0; have nvidia3090 24gb so no constraints.\
          \ xformers not installed\r\n\r\nCurious if anyone has any insight as to\
          \ what I might have missed or be doing/configure wrong. Grateful for any\
          \ insights! Any help appreciated!\r\n\r\nprompt \"a jack russell dog wearing\
          \ sunglass smoking a cigar and holding a martini\" \r\n\r\n-- 768 model\
          \ cruddy output --\r\n![grid-0002.png](https://cdn-uploads.huggingface.co/production/uploads/1670357376552-6362e0f92c0bb59ecc1b8d64.png)\r\
          \n\r\n-- 512 model much better, but still likely way worse than 768 when\
          \ I figure this out --\r\n![grid-0001.png](https://cdn-uploads.huggingface.co/production/uploads/1670357364439-6362e0f92c0bb59ecc1b8d64.png)\r\
          \n\r\n"
        updatedAt: '2022-12-06T20:14:38.258Z'
      numEdits: 0
      reactions: []
    id: 638fa2ae073cdaa89611146a
    type: comment
  author: bobsled
  content: "Having the absolute reverse problem. I can get tolerable results on SD2\
    \ with the 512 model, but get very \"crude\" or pixelated/lowres results when\
    \ invoking with the 768model at either 768x768 or 512x512 resolutions. I have\
    \ the appropriate yaml files. I got the poor results on a in-place upgrade before\
    \ so have built an entirely new conda environment and getting the same poor results.\
    \ (file examples for same prompt and seed attached). Using cuda 11.7, pytorch\
    \ 1.13.0; have nvidia3090 24gb so no constraints. xformers not installed\r\n\r\
    \nCurious if anyone has any insight as to what I might have missed or be doing/configure\
    \ wrong. Grateful for any insights! Any help appreciated!\r\n\r\nprompt \"a jack\
    \ russell dog wearing sunglass smoking a cigar and holding a martini\" \r\n\r\n\
    -- 768 model cruddy output --\r\n![grid-0002.png](https://cdn-uploads.huggingface.co/production/uploads/1670357376552-6362e0f92c0bb59ecc1b8d64.png)\r\
    \n\r\n-- 512 model much better, but still likely way worse than 768 when I figure\
    \ this out --\r\n![grid-0001.png](https://cdn-uploads.huggingface.co/production/uploads/1670357364439-6362e0f92c0bb59ecc1b8d64.png)\r\
    \n\r\n"
  created_at: 2022-12-06 20:14:38+00:00
  edited: false
  hidden: false
  id: 638fa2ae073cdaa89611146a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/69af6a4614e9902ac94a5fa250395ac5.svg
      fullname: Mike Boyer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bobsled
      type: user
    createdAt: '2022-12-06T22:20:37.000Z'
    data:
      edited: false
      editors:
      - bobsled
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/69af6a4614e9902ac94a5fa250395ac5.svg
          fullname: Mike Boyer
          isHf: false
          isPro: false
          name: bobsled
          type: user
        html: '<p>Additional information:</p>

          <p>I was able to get good output with DPM sampler, but using PLMS is what
          produces the garbage. Unclear if something whacky on my install(s) related
          to PLMS sampler or a bug.</p>

          '
        raw: 'Additional information:


          I was able to get good output with DPM sampler, but using PLMS is what produces
          the garbage. Unclear if something whacky on my install(s) related to PLMS
          sampler or a bug.'
        updatedAt: '2022-12-06T22:20:37.034Z'
      numEdits: 0
      reactions: []
    id: 638fc0352ddd69e70b8adfbe
    type: comment
  author: bobsled
  content: 'Additional information:


    I was able to get good output with DPM sampler, but using PLMS is what produces
    the garbage. Unclear if something whacky on my install(s) related to PLMS sampler
    or a bug.'
  created_at: 2022-12-06 22:20:37+00:00
  edited: false
  hidden: false
  id: 638fc0352ddd69e70b8adfbe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/45a59de69ef750333ca67a3b12f5e828.svg
      fullname: julian orzel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Dupity123
      type: user
    createdAt: '2022-12-23T19:44:50.000Z'
    data:
      edited: false
      editors:
      - Dupity123
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/45a59de69ef750333ca67a3b12f5e828.svg
          fullname: julian orzel
          isHf: false
          isPro: false
          name: Dupity123
          type: user
        html: '<p>Hey, so I had the same issue. For me, I was using the common v1.4
          deforum on collab. What you need to do is find the stable_diffusion_v2_webui_colab.ipynb
          because it has Automatic1111, deforum and 768 pre installed. The mess has
          to do with the config, model and some command line prompt im too dumb to
          know how to do. Just search google for that exact name above, all the other
          ones are definitely not worth your time or computing power.</p>

          '
        raw: Hey, so I had the same issue. For me, I was using the common v1.4 deforum
          on collab. What you need to do is find the stable_diffusion_v2_webui_colab.ipynb
          because it has Automatic1111, deforum and 768 pre installed. The mess has
          to do with the config, model and some command line prompt im too dumb to
          know how to do. Just search google for that exact name above, all the other
          ones are definitely not worth your time or computing power.
        updatedAt: '2022-12-23T19:44:50.824Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - immx2
    id: 63a60532c1a26c19c80d4c51
    type: comment
  author: Dupity123
  content: Hey, so I had the same issue. For me, I was using the common v1.4 deforum
    on collab. What you need to do is find the stable_diffusion_v2_webui_colab.ipynb
    because it has Automatic1111, deforum and 768 pre installed. The mess has to do
    with the config, model and some command line prompt im too dumb to know how to
    do. Just search google for that exact name above, all the other ones are definitely
    not worth your time or computing power.
  created_at: 2022-12-23 19:44:50+00:00
  edited: false
  hidden: false
  id: 63a60532c1a26c19c80d4c51
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 30
repo_id: stabilityai/stable-diffusion-2
repo_type: model
status: open
target_branch: null
title: Suggestions?  poor quality low/res pixel output with 768 model much better
  with 512model
