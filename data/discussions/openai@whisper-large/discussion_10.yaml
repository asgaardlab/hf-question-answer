!!python/object:huggingface_hub.community.DiscussionWithDetails
author: minseong-ringle
conflicting_files: null
created_at: 2022-11-09 15:52:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/23aa6ef61302bd46cbaf42bb2dd81555.svg
      fullname: MinseongHwang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: minseong-ringle
      type: user
    createdAt: '2022-11-09T15:52:31.000Z'
    data:
      edited: false
      editors:
      - minseong-ringle
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/23aa6ef61302bd46cbaf42bb2dd81555.svg
          fullname: MinseongHwang
          isHf: false
          isPro: false
          name: minseong-ringle
          type: user
        html: "<pre><code>input_features = processor(input, return_tensors=\"pt\"\
          ).input_features\nforced_decoder_ids = processor.get_decoder_prompt_ids(language\
          \ = \"en\", task = \"transcribe\", no_timestamps=False)\n\npredicted_ids\
          \ = model.generate(input_features, forced_decoder_ids = forced_decoder_ids)\n\
          transcription = processor.batch_decode(predicted_ids)\n\n#  This results\
          \ in \n# tensor([[50258, 50259, 50359, 50363\n# -&gt; \"&lt;|startoftranscript|&gt;&lt;|en|&gt;&lt;|transcribe|&gt;&lt;|notimestamps|&gt;\n\
          # for transcription\n\nmodel.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language\
          \ = \"en\", task = \"transcribe\", no_timestamps=False)\n# also using this\
          \ cause the same result.\n</code></pre>\n<p>Here are some code snippets\
          \ I've tried so far.<br>I cannot remove notimestamps token as a decoder\
          \ input.<br>Any rescues?</p>\n<p>Thank you for your help in advance.</p>\n"
        raw: "```\r\ninput_features = processor(input, return_tensors=\"pt\").input_features\r\
          \nforced_decoder_ids = processor.get_decoder_prompt_ids(language = \"en\"\
          , task = \"transcribe\", no_timestamps=False)\r\n\r\npredicted_ids = model.generate(input_features,\
          \ forced_decoder_ids = forced_decoder_ids)\r\ntranscription = processor.batch_decode(predicted_ids)\r\
          \n\r\n#  This results in \r\n# tensor([[50258, 50259, 50359, 50363\r\n#\
          \ -> \"<|startoftranscript|><|en|><|transcribe|><|notimestamps|>\r\n# for\
          \ transcription\r\n\r\nmodel.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language\
          \ = \"en\", task = \"transcribe\", no_timestamps=False)\r\n# also using\
          \ this cause the same result.\r\n```\r\nHere are some code snippets I've\
          \ tried so far.\r\nI cannot remove notimestamps token as a decoder input.\r\
          \nAny rescues?\r\n\r\nThank you for your help in advance.\r\n"
        updatedAt: '2022-11-09T15:52:31.718Z'
      numEdits: 0
      reactions: []
    id: 636bccbf6890dd5a45024b82
    type: comment
  author: minseong-ringle
  content: "```\r\ninput_features = processor(input, return_tensors=\"pt\").input_features\r\
    \nforced_decoder_ids = processor.get_decoder_prompt_ids(language = \"en\", task\
    \ = \"transcribe\", no_timestamps=False)\r\n\r\npredicted_ids = model.generate(input_features,\
    \ forced_decoder_ids = forced_decoder_ids)\r\ntranscription = processor.batch_decode(predicted_ids)\r\
    \n\r\n#  This results in \r\n# tensor([[50258, 50259, 50359, 50363\r\n# -> \"\
    <|startoftranscript|><|en|><|transcribe|><|notimestamps|>\r\n# for transcription\r\
    \n\r\nmodel.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language\
    \ = \"en\", task = \"transcribe\", no_timestamps=False)\r\n# also using this cause\
    \ the same result.\r\n```\r\nHere are some code snippets I've tried so far.\r\n\
    I cannot remove notimestamps token as a decoder input.\r\nAny rescues?\r\n\r\n\
    Thank you for your help in advance.\r\n"
  created_at: 2022-11-09 15:52:31+00:00
  edited: false
  hidden: false
  id: 636bccbf6890dd5a45024b82
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2022-11-10T13:26:52.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>Hey! So this might be related to the fact that the <code>"&lt;|notimestamps|&gt;"</code>  token
          is not in the list of suppress tokens! This means that the model is just
          predicting this token.<br>We should probably add it to the list of the <code>suppress_tokens</code></p>

          '
        raw: "Hey! So this might be related to the fact that the `\"<|notimestamps|>\"\
          `  token is not in the list of suppress tokens! This means that the model\
          \ is just predicting this token. \nWe should probably add it to the list\
          \ of the `suppress_tokens`"
        updatedAt: '2022-11-10T13:26:52.617Z'
      numEdits: 0
      reactions: []
    id: 636cfc1c96cd7bc4b1fc9c5e
    type: comment
  author: ArthurZ
  content: "Hey! So this might be related to the fact that the `\"<|notimestamps|>\"\
    `  token is not in the list of suppress tokens! This means that the model is just\
    \ predicting this token. \nWe should probably add it to the list of the `suppress_tokens`"
  created_at: 2022-11-10 13:26:52+00:00
  edited: false
  hidden: false
  id: 636cfc1c96cd7bc4b1fc9c5e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: openai/whisper-large
repo_type: model
status: open
target_branch: null
title: forced_decoder_ids not applied properly when generation
