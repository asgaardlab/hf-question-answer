!!python/object:huggingface_hub.community.DiscussionWithDetails
author: polaris16
conflicting_files: null
created_at: 2023-10-10 12:01:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/642e6959e5cc5ddea69def253fbb4e80.svg
      fullname: polaris
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: polaris16
      type: user
    createdAt: '2023-10-10T13:01:31.000Z'
    data:
      edited: false
      editors:
      - polaris16
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5602525472640991
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/642e6959e5cc5ddea69def253fbb4e80.svg
          fullname: polaris
          isHf: false
          isPro: false
          name: polaris16
          type: user
        html: '<p>In the example of Long-Form Transcription,  pipe does not return
          the language type. How can return the language type?</p>

          <p>import torch<br>from transformers import pipeline<br>from datasets import
          load_dataset</p>

          <p>device = "cuda:0" if torch.cuda.is_available() else "cpu"</p>

          <p>pipe = pipeline(<br>  "automatic-speech-recognition",<br>  model="openai/whisper-large-v2",<br>  chunk_length_s=30,<br>  device=device,<br>)</p>

          <p>ds = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean",
          split="validation")<br>sample = ds[0]["audio"]</p>

          <p>prediction = pipe(sample.copy(), batch_size=8)</p>

          <p>for k in prediction:<br>    print(k)</p>

          <p>---- output ----<br>text</p>

          '
        raw: "In the example of Long-Form Transcription,  pipe does not return the\
          \ language type. How can return the language type?\r\n\r\n\r\nimport torch\r\
          \nfrom transformers import pipeline\r\nfrom datasets import load_dataset\r\
          \n\r\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\r\n\r\
          \npipe = pipeline(\r\n  \"automatic-speech-recognition\",\r\n  model=\"\
          openai/whisper-large-v2\",\r\n  chunk_length_s=30,\r\n  device=device,\r\
          \n)\r\n\r\nds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\"\
          , \"clean\", split=\"validation\")\r\nsample = ds[0][\"audio\"]\r\n\r\n\
          prediction = pipe(sample.copy(), batch_size=8)\r\n\r\nfor k in prediction:\r\
          \n    print(k)\r\n\r\n\r\n---- output ---- \r\ntext"
        updatedAt: '2023-10-10T13:01:31.161Z'
      numEdits: 0
      reactions: []
    id: 65254b2b2eff981222c87c45
    type: comment
  author: polaris16
  content: "In the example of Long-Form Transcription,  pipe does not return the language\
    \ type. How can return the language type?\r\n\r\n\r\nimport torch\r\nfrom transformers\
    \ import pipeline\r\nfrom datasets import load_dataset\r\n\r\ndevice = \"cuda:0\"\
    \ if torch.cuda.is_available() else \"cpu\"\r\n\r\npipe = pipeline(\r\n  \"automatic-speech-recognition\"\
    ,\r\n  model=\"openai/whisper-large-v2\",\r\n  chunk_length_s=30,\r\n  device=device,\r\
    \n)\r\n\r\nds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"\
    clean\", split=\"validation\")\r\nsample = ds[0][\"audio\"]\r\n\r\nprediction\
    \ = pipe(sample.copy(), batch_size=8)\r\n\r\nfor k in prediction:\r\n    print(k)\r\
    \n\r\n\r\n---- output ---- \r\ntext"
  created_at: 2023-10-10 12:01:31+00:00
  edited: false
  hidden: false
  id: 65254b2b2eff981222c87c45
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-10-10T16:32:23.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6406095623970032
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>You can pass the <code>return_language</code> argument to the pipeline\
          \ to get the language detected for each chunk:</p>\n<pre><code class=\"\
          language-python\"><span class=\"hljs-keyword\">import</span> torch\n<span\
          \ class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\"\
          >import</span> pipeline\n<span class=\"hljs-keyword\">from</span> datasets\
          \ <span class=\"hljs-keyword\">import</span> load_dataset\n\ndevice = <span\
          \ class=\"hljs-string\">\"cuda:0\"</span> <span class=\"hljs-keyword\">if</span>\
          \ torch.cuda.is_available() <span class=\"hljs-keyword\">else</span> <span\
          \ class=\"hljs-string\">\"cpu\"</span>\n\npipe = pipeline(\n<span class=\"\
          hljs-string\">\"automatic-speech-recognition\"</span>,\nmodel=<span class=\"\
          hljs-string\">\"openai/whisper-large-v2\"</span>,\nchunk_length_s=<span\
          \ class=\"hljs-number\">30</span>,\ndevice=device,\n)\n\nds = load_dataset(<span\
          \ class=\"hljs-string\">\"hf-internal-testing/librispeech_asr_dummy\"</span>,\
          \ <span class=\"hljs-string\">\"clean\"</span>, split=<span class=\"hljs-string\"\
          >\"validation\"</span>)\nsample = ds[<span class=\"hljs-number\">0</span>][<span\
          \ class=\"hljs-string\">\"audio\"</span>]\n\nprediction = pipe(sample),\
          \ batch_size=<span class=\"hljs-number\">8</span>, return_language=<span\
          \ class=\"hljs-literal\">True</span>)\n\n<span class=\"hljs-built_in\">print</span>(prediction)\n\
          </code></pre>\n<p><strong>Print Output:</strong></p>\n<pre><code>{'text':\
          \ ' Mr. Quilter is the apostle of the middle classes and we are glad to\
          \ welcome his gospel.',\n 'chunks': [{'language': 'english',\n   'text':\
          \ ' Mr. Quilter is the apostle of the middle classes and we are glad to\
          \ welcome his gospel.'}]}\n</code></pre>\n"
        raw: "You can pass the `return_language` argument to the pipeline to get the\
          \ language detected for each chunk:\n```python\nimport torch\nfrom transformers\
          \ import pipeline\nfrom datasets import load_dataset\n\ndevice = \"cuda:0\"\
          \ if torch.cuda.is_available() else \"cpu\"\n\npipe = pipeline(\n\"automatic-speech-recognition\"\
          ,\nmodel=\"openai/whisper-large-v2\",\nchunk_length_s=30,\ndevice=device,\n\
          )\n\nds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"\
          clean\", split=\"validation\")\nsample = ds[0][\"audio\"]\n\nprediction\
          \ = pipe(sample), batch_size=8, return_language=True)\n\nprint(prediction)\n\
          ```\n**Print Output:**\n```\n{'text': ' Mr. Quilter is the apostle of the\
          \ middle classes and we are glad to welcome his gospel.',\n 'chunks': [{'language':\
          \ 'english',\n   'text': ' Mr. Quilter is the apostle of the middle classes\
          \ and we are glad to welcome his gospel.'}]}\n```"
        updatedAt: '2023-10-10T16:32:23.751Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - unk1911
    id: 65257c97f8db96cffc971b65
    type: comment
  author: sanchit-gandhi
  content: "You can pass the `return_language` argument to the pipeline to get the\
    \ language detected for each chunk:\n```python\nimport torch\nfrom transformers\
    \ import pipeline\nfrom datasets import load_dataset\n\ndevice = \"cuda:0\" if\
    \ torch.cuda.is_available() else \"cpu\"\n\npipe = pipeline(\n\"automatic-speech-recognition\"\
    ,\nmodel=\"openai/whisper-large-v2\",\nchunk_length_s=30,\ndevice=device,\n)\n\
    \nds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\",\
    \ split=\"validation\")\nsample = ds[0][\"audio\"]\n\nprediction = pipe(sample),\
    \ batch_size=8, return_language=True)\n\nprint(prediction)\n```\n**Print Output:**\n\
    ```\n{'text': ' Mr. Quilter is the apostle of the middle classes and we are glad\
    \ to welcome his gospel.',\n 'chunks': [{'language': 'english',\n   'text': '\
    \ Mr. Quilter is the apostle of the middle classes and we are glad to welcome\
    \ his gospel.'}]}\n```"
  created_at: 2023-10-10 15:32:23+00:00
  edited: false
  hidden: false
  id: 65257c97f8db96cffc971b65
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1ecfed2642cd245da6f2dc5c686bab68.svg
      fullname: mike melamed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: unk1911
      type: user
    createdAt: '2023-12-19T06:57:44.000Z'
    data:
      edited: false
      editors:
      - unk1911
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5934706330299377
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1ecfed2642cd245da6f2dc5c686bab68.svg
          fullname: mike melamed
          isHf: false
          isPro: false
          name: unk1911
          type: user
        html: '<p>should be:</p>

          <p>prediction = pipe(sample,  batch_size=8, return_language=True)</p>

          <p>(minor syntax error)</p>

          '
        raw: 'should be:


          prediction = pipe(sample,  batch_size=8, return_language=True)


          (minor syntax error)'
        updatedAt: '2023-12-19T06:57:44.195Z'
      numEdits: 0
      reactions: []
    id: 65813ee8133ca7da45e4bc4b
    type: comment
  author: unk1911
  content: 'should be:


    prediction = pipe(sample,  batch_size=8, return_language=True)


    (minor syntax error)'
  created_at: 2023-12-19 06:57:44+00:00
  edited: false
  hidden: false
  id: 65813ee8133ca7da45e4bc4b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 41
repo_id: openai/whisper-large
repo_type: model
status: open
target_branch: null
title: How can whisper return the language type?
