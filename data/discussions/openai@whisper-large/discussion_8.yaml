!!python/object:huggingface_hub.community.DiscussionWithDetails
author: joeyontour
conflicting_files: null
created_at: 2022-10-24 15:04:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4960d2c1bb65bc1045de1ca1c9948dd0.svg
      fullname: Joey Alexus
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joeyontour
      type: user
    createdAt: '2022-10-24T16:04:55.000Z'
    data:
      edited: false
      editors:
      - joeyontour
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4960d2c1bb65bc1045de1ca1c9948dd0.svg
          fullname: Joey Alexus
          isHf: false
          isPro: false
          name: joeyontour
          type: user
        html: "<p>In the sample code from the model card, only the logits for the\
          \ language token are returned and not the logits of the actual audio. I\
          \ cannot use the generate function as I need the logits to compute the word\
          \ level timestamps and to use it with a language model. Is there a way to\
          \ obtain the logits?</p>\n<pre><code class=\"language-python\"><span class=\"\
          hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-comment\"># Generate\
          \ logits</span>\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>logits =\
          \ model(input_features, decoder_input_ids = torch.tensor([[<span class=\"\
          hljs-number\">50258</span>]])).logits \n<span class=\"hljs-meta\">&gt;&gt;&gt;\
          \ </span><span class=\"hljs-comment\"># take argmax and decode</span>\n\
          <span class=\"hljs-meta\">&gt;&gt;&gt; </span>predicted_ids = torch.argmax(logits,\
          \ dim=-<span class=\"hljs-number\">1</span>)\n<span class=\"hljs-meta\"\
          >&gt;&gt;&gt; </span>transcription = processor.batch_decode(predicted_ids)\n\
          [<span class=\"hljs-string\">'&lt;|en|&gt;'</span>]\n</code></pre>\n"
        raw: "In the sample code from the model card, only the logits for the language\
          \ token are returned and not the logits of the actual audio. I cannot use\
          \ the generate function as I need the logits to compute the word level timestamps\
          \ and to use it with a language model. Is there a way to obtain the logits?\r\
          \n```python\r\n>>> # Generate logits\r\n>>> logits = model(input_features,\
          \ decoder_input_ids = torch.tensor([[50258]])).logits \r\n>>> # take argmax\
          \ and decode\r\n>>> predicted_ids = torch.argmax(logits, dim=-1)\r\n>>>\
          \ transcription = processor.batch_decode(predicted_ids)\r\n['<|en|>']\r\n\
          ```"
        updatedAt: '2022-10-24T16:04:55.212Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - pbo
    id: 6356b7a73c32f2c90f4d5aef
    type: comment
  author: joeyontour
  content: "In the sample code from the model card, only the logits for the language\
    \ token are returned and not the logits of the actual audio. I cannot use the\
    \ generate function as I need the logits to compute the word level timestamps\
    \ and to use it with a language model. Is there a way to obtain the logits?\r\n\
    ```python\r\n>>> # Generate logits\r\n>>> logits = model(input_features, decoder_input_ids\
    \ = torch.tensor([[50258]])).logits \r\n>>> # take argmax and decode\r\n>>> predicted_ids\
    \ = torch.argmax(logits, dim=-1)\r\n>>> transcription = processor.batch_decode(predicted_ids)\r\
    \n['<|en|>']\r\n```"
  created_at: 2022-10-24 15:04:55+00:00
  edited: false
  hidden: false
  id: 6356b7a73c32f2c90f4d5aef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/aa907eb7fd3c839e7ef9d65e33f9c31e.svg
      fullname: Mark Van Aken
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vanakema
      type: user
    createdAt: '2022-10-26T02:24:06.000Z'
    data:
      edited: false
      editors:
      - vanakema
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/aa907eb7fd3c839e7ef9d65e33f9c31e.svg
          fullname: Mark Van Aken
          isHf: false
          isPro: false
          name: vanakema
          type: user
        html: '<p>You have to run model.generate(...) to get more than the first token</p>

          '
        raw: You have to run model.generate(...) to get more than the first token
        updatedAt: '2022-10-26T02:24:06.123Z'
      numEdits: 0
      reactions: []
    id: 63589a46aff68f72ac0539b2
    type: comment
  author: vanakema
  content: You have to run model.generate(...) to get more than the first token
  created_at: 2022-10-26 01:24:06+00:00
  edited: false
  hidden: false
  id: 63589a46aff68f72ac0539b2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4960d2c1bb65bc1045de1ca1c9948dd0.svg
      fullname: Joey Alexus
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joeyontour
      type: user
    createdAt: '2022-10-26T08:05:55.000Z'
    data:
      edited: false
      editors:
      - joeyontour
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4960d2c1bb65bc1045de1ca1c9948dd0.svg
          fullname: Joey Alexus
          isHf: false
          isPro: false
          name: joeyontour
          type: user
        html: '<p>In this case, I don''t understand how the evaluation was performed.
          Here the logits are extracted and the ids are decoded. When I run this locally,
          I indeed only get an empty transcription after normalization, so I''m wondering
          how it was evaluated.</p>

          <pre><code class="language-python"><span class="hljs-meta">&gt;&gt;&gt;
          </span>librispeech_eval = load_dataset(<span class="hljs-string">"librispeech_asr"</span>,
          <span class="hljs-string">"clean"</span>, split=<span class="hljs-string">"test"</span>)

          <span class="hljs-meta">&gt;&gt;&gt; </span>model = WhisperForConditionalGeneration.from_pretrained(<span
          class="hljs-string">"openai/whisper-large"</span>).to(<span class="hljs-string">"cuda"</span>)

          <span class="hljs-meta">&gt;&gt;&gt; </span>processor = WhisperProcessor.from_pretrained(<span
          class="hljs-string">"openai/whisper-large"</span>)

          <span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span>
          <span class="hljs-title function_">map_to_pred</span>(<span class="hljs-params">batch</span>):

          <span class="hljs-meta">&gt;&gt;&gt; </span>    input_features = processor(batch[<span
          class="hljs-string">"audio"</span>][<span class="hljs-string">"array"</span>],
          return_tensors=<span class="hljs-string">"pt"</span>).input_features

          <span class="hljs-meta">&gt;&gt;&gt; </span>    <span class="hljs-keyword">with</span>
          torch.no_grad():

          <span class="hljs-meta">&gt;&gt;&gt; </span>        logits = model(input_features.to(<span
          class="hljs-string">"cuda"</span>)).logits

          <span class="hljs-meta">&gt;&gt;&gt; </span>    predicted_ids = torch.argmax(logits,
          dim=-<span class="hljs-number">1</span>)

          <span class="hljs-meta">&gt;&gt;&gt; </span>    transcription = processor.batch_decode(predicted_ids,
          normalize = <span class="hljs-literal">True</span>)

          <span class="hljs-meta">&gt;&gt;&gt; </span>    batch[<span class="hljs-string">''text''</span>]
          = processor.tokenizer._normalize(batch[<span class="hljs-string">''text''</span>])

          <span class="hljs-meta">&gt;&gt;&gt; </span>    batch[<span class="hljs-string">"transcription"</span>]
          = transcription

          <span class="hljs-meta">&gt;&gt;&gt; </span>    <span class="hljs-keyword">return</span>
          batch

          <span class="hljs-meta">&gt;&gt;&gt; </span>result = librispeech_eval.<span
          class="hljs-built_in">map</span>(map_to_pred, batched=<span class="hljs-literal">True</span>,
          batch_size=<span class="hljs-number">1</span>, remove_columns=[<span class="hljs-string">"speech"</span>])

          <span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span
          class="hljs-string">"WER:"</span>, wer(result[<span class="hljs-string">"text"</span>],
          result[<span class="hljs-string">"transcription"</span>]))

          <span class="hljs-number">0.030003583080317572</span>

          </code></pre>

          '
        raw: 'In this case, I don''t understand how the evaluation was performed.
          Here the logits are extracted and the ids are decoded. When I run this locally,
          I indeed only get an empty transcription after normalization, so I''m wondering
          how it was evaluated.

          ```python

          >>> librispeech_eval = load_dataset("librispeech_asr", "clean", split="test")

          >>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-large").to("cuda")

          >>> processor = WhisperProcessor.from_pretrained("openai/whisper-large")

          >>> def map_to_pred(batch):

          >>>     input_features = processor(batch["audio"]["array"], return_tensors="pt").input_features

          >>>     with torch.no_grad():

          >>>         logits = model(input_features.to("cuda")).logits

          >>>     predicted_ids = torch.argmax(logits, dim=-1)

          >>>     transcription = processor.batch_decode(predicted_ids, normalize
          = True)

          >>>     batch[''text''] = processor.tokenizer._normalize(batch[''text''])

          >>>     batch["transcription"] = transcription

          >>>     return batch

          >>> result = librispeech_eval.map(map_to_pred, batched=True, batch_size=1,
          remove_columns=["speech"])

          >>> print("WER:", wer(result["text"], result["transcription"]))

          0.030003583080317572

          ```'
        updatedAt: '2022-10-26T08:05:55.344Z'
      numEdits: 0
      reactions: []
    id: 6358ea63b8c1e60283cfd2f7
    type: comment
  author: joeyontour
  content: 'In this case, I don''t understand how the evaluation was performed. Here
    the logits are extracted and the ids are decoded. When I run this locally, I indeed
    only get an empty transcription after normalization, so I''m wondering how it
    was evaluated.

    ```python

    >>> librispeech_eval = load_dataset("librispeech_asr", "clean", split="test")

    >>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-large").to("cuda")

    >>> processor = WhisperProcessor.from_pretrained("openai/whisper-large")

    >>> def map_to_pred(batch):

    >>>     input_features = processor(batch["audio"]["array"], return_tensors="pt").input_features

    >>>     with torch.no_grad():

    >>>         logits = model(input_features.to("cuda")).logits

    >>>     predicted_ids = torch.argmax(logits, dim=-1)

    >>>     transcription = processor.batch_decode(predicted_ids, normalize = True)

    >>>     batch[''text''] = processor.tokenizer._normalize(batch[''text''])

    >>>     batch["transcription"] = transcription

    >>>     return batch

    >>> result = librispeech_eval.map(map_to_pred, batched=True, batch_size=1, remove_columns=["speech"])

    >>> print("WER:", wer(result["text"], result["transcription"]))

    0.030003583080317572

    ```'
  created_at: 2022-10-26 07:05:55+00:00
  edited: false
  hidden: false
  id: 6358ea63b8c1e60283cfd2f7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2022-11-12T09:10:23.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>Hey ! You are correct, the snippet is wrong, we indeed used generate!
          Will fix the evaluation code . Thanks for the catch</p>

          '
        raw: Hey ! You are correct, the snippet is wrong, we indeed used generate!
          Will fix the evaluation code . Thanks for the catch
        updatedAt: '2022-11-12T09:10:23.403Z'
      numEdits: 0
      reactions: []
    id: 636f62ff5af6ffb65636002a
    type: comment
  author: ArthurZ
  content: Hey ! You are correct, the snippet is wrong, we indeed used generate! Will
    fix the evaluation code . Thanks for the catch
  created_at: 2022-11-12 09:10:23+00:00
  edited: false
  hidden: false
  id: 636f62ff5af6ffb65636002a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2022-11-12T14:32:45.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: '<p>For reference, a corrected code-snippet exists here (just swap base
          model for large): <a rel="nofollow" href="https://github.com/openai/whisper/blob/a40c75e35cd62b7779774e636b3d081d9cbff82f/README.md#use-in--transformers">https://github.com/openai/whisper/blob/a40c75e35cd62b7779774e636b3d081d9cbff82f/README.md#use-in--transformers</a></p>

          '
        raw: 'For reference, a corrected code-snippet exists here (just swap base
          model for large): https://github.com/openai/whisper/blob/a40c75e35cd62b7779774e636b3d081d9cbff82f/README.md#use-in--transformers'
        updatedAt: '2022-11-12T14:32:45.258Z'
      numEdits: 0
      reactions: []
    id: 636fae8d6cd69d9a3602e210
    type: comment
  author: sanchit-gandhi
  content: 'For reference, a corrected code-snippet exists here (just swap base model
    for large): https://github.com/openai/whisper/blob/a40c75e35cd62b7779774e636b3d081d9cbff82f/README.md#use-in--transformers'
  created_at: 2022-11-12 14:32:45+00:00
  edited: false
  hidden: false
  id: 636fae8d6cd69d9a3602e210
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: openai/whisper-large
repo_type: model
status: open
target_branch: null
title: Only the logits for the decoder_input_ids are returned, not for the actual
  input_features
