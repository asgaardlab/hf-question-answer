!!python/object:huggingface_hub.community.DiscussionWithDetails
author: AlbelTec
conflicting_files: null
created_at: 2023-10-07 16:10:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62614f960568e418d6908ea3/eJF-2Qxh4Hln5bEu5InoM.png?w=200&h=200&f=face
      fullname: Albel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AlbelTec
      type: user
    createdAt: '2023-10-07T17:10:16.000Z'
    data:
      edited: false
      editors:
      - AlbelTec
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8981178998947144
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62614f960568e418d6908ea3/eJF-2Qxh4Hln5bEu5InoM.png?w=200&h=200&f=face
          fullname: Albel
          isHf: false
          isPro: false
          name: AlbelTec
          type: user
        html: '<p>Hello,</p>

          <p>I fine-tuned phi-1.5 but  when trying to infer a question I''m getting
          the answer and the model keep generating tokens until it reach max_lenght
          tokens. As a newbie, I wonder how to prevent such behavior. any insights
          ?</p>

          <p>kr,</p>

          '
        raw: "Hello,\r\n\r\nI fine-tuned phi-1.5 but  when trying to infer a question\
          \ I'm getting the answer and the model keep generating tokens until it reach\
          \ max_lenght tokens. As a newbie, I wonder how to prevent such behavior.\
          \ any insights ?\r\n\r\nkr,"
        updatedAt: '2023-10-07T17:10:16.545Z'
      numEdits: 0
      reactions: []
    id: 652190f834420556f4d826b3
    type: comment
  author: AlbelTec
  content: "Hello,\r\n\r\nI fine-tuned phi-1.5 but  when trying to infer a question\
    \ I'm getting the answer and the model keep generating tokens until it reach max_lenght\
    \ tokens. As a newbie, I wonder how to prevent such behavior. any insights ?\r\
    \n\r\nkr,"
  created_at: 2023-10-07 16:10:16+00:00
  edited: false
  hidden: false
  id: 652190f834420556f4d826b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/645cdd5c03fc86c46b3d7d66/426ZbgQ62X0s2uXZ52cs2.jpeg?w=200&h=200&f=face
      fullname: Vicente Rivera
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Vicenterivera
      type: user
    createdAt: '2023-10-07T17:30:49.000Z'
    data:
      edited: false
      editors:
      - Vicenterivera
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7745480537414551
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/645cdd5c03fc86c46b3d7d66/426ZbgQ62X0s2uXZ52cs2.jpeg?w=200&h=200&f=face
          fullname: Vicente Rivera
          isHf: false
          isPro: false
          name: Vicenterivera
          type: user
        html: '<p>Are you setting the EOS token? What template did you use on your
          finetune data?</p>

          '
        raw: Are you setting the EOS token? What template did you use on your finetune
          data?
        updatedAt: '2023-10-07T17:30:49.072Z'
      numEdits: 0
      reactions: []
    id: 652195c9c709aaca9a994283
    type: comment
  author: Vicenterivera
  content: Are you setting the EOS token? What template did you use on your finetune
    data?
  created_at: 2023-10-07 16:30:49+00:00
  edited: false
  hidden: false
  id: 652195c9c709aaca9a994283
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/650d42549e898eb6d21cc5dc/ndmXshML3If8pHRHJGNct.jpeg?w=200&h=200&f=face
      fullname: Mohamed Jihed Riahi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nulltella
      type: user
    createdAt: '2023-10-07T19:04:28.000Z'
    data:
      edited: false
      editors:
      - nulltella
      hidden: false
      identifiedLanguage:
        language: fr
        probability: 0.27723589539527893
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/650d42549e898eb6d21cc5dc/ndmXshML3If8pHRHJGNct.jpeg?w=200&h=200&f=face
          fullname: Mohamed Jihed Riahi
          isHf: false
          isPro: false
          name: nulltella
          type: user
        html: '<p>Idem.</p>

          '
        raw: Idem.
        updatedAt: '2023-10-07T19:04:28.045Z'
      numEdits: 0
      reactions: []
    id: 6521abbc0415e1b734c99de6
    type: comment
  author: nulltella
  content: Idem.
  created_at: 2023-10-07 18:04:28+00:00
  edited: false
  hidden: false
  id: 6521abbc0415e1b734c99de6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62614f960568e418d6908ea3/eJF-2Qxh4Hln5bEu5InoM.png?w=200&h=200&f=face
      fullname: Albel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AlbelTec
      type: user
    createdAt: '2023-10-07T19:49:33.000Z'
    data:
      edited: true
      editors:
      - AlbelTec
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8029950261116028
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62614f960568e418d6908ea3/eJF-2Qxh4Hln5bEu5InoM.png?w=200&h=200&f=face
          fullname: Albel
          isHf: false
          isPro: false
          name: AlbelTec
          type: user
        html: '<p>Actually, I used a subset of openorca dataset and my template is
          based on :<br>system_prompt:<br>question:<br>answer:</p>

          '
        raw: 'Actually, I used a subset of openorca dataset and my template is based
          on :

          system_prompt:

          question:

          answer:'
        updatedAt: '2023-10-07T19:50:11.150Z'
      numEdits: 1
      reactions: []
    id: 6521b64d706c7551488f2d07
    type: comment
  author: AlbelTec
  content: 'Actually, I used a subset of openorca dataset and my template is based
    on :

    system_prompt:

    question:

    answer:'
  created_at: 2023-10-07 18:49:33+00:00
  edited: true
  hidden: false
  id: 6521b64d706c7551488f2d07
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62614f960568e418d6908ea3/eJF-2Qxh4Hln5bEu5InoM.png?w=200&h=200&f=face
      fullname: Albel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AlbelTec
      type: user
    createdAt: '2023-10-14T17:36:38.000Z'
    data:
      status: closed
    id: 652ad1a6ff2202020e97051c
    type: status-change
  author: AlbelTec
  created_at: 2023-10-14 16:36:38+00:00
  id: 652ad1a6ff2202020e97051c
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dcc9140ace304cfcf6a832bac908fad8.svg
      fullname: Ilya  Raykhel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iraykhel
      type: user
    createdAt: '2023-12-29T17:06:27.000Z'
    data:
      edited: false
      editors:
      - iraykhel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9602348208427429
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dcc9140ace304cfcf6a832bac908fad8.svg
          fullname: Ilya  Raykhel
          isHf: false
          isPro: false
          name: iraykhel
          type: user
        html: '<p>You ever find an answer to this question?</p>

          '
        raw: You ever find an answer to this question?
        updatedAt: '2023-12-29T17:06:27.108Z'
      numEdits: 0
      reactions: []
    id: 658efc93a6567cb93c2d0c51
    type: comment
  author: iraykhel
  content: You ever find an answer to this question?
  created_at: 2023-12-29 17:06:27+00:00
  edited: false
  hidden: false
  id: 658efc93a6567cb93c2d0c51
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 45
repo_id: microsoft/phi-1_5
repo_type: model
status: closed
target_branch: null
title: stop the fine-tuned model to keep generating tokens
