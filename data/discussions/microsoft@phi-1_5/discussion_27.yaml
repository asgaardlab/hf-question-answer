!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sudhir2016
conflicting_files: null
created_at: 2023-09-22 08:58:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9c3b817a7b558e0667652ead31747967.svg
      fullname: Sudhir Gupta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sudhir2016
      type: user
    createdAt: '2023-09-22T09:58:12.000Z'
    data:
      edited: false
      editors:
      - sudhir2016
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8434329032897949
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9c3b817a7b558e0667652ead31747967.svg
          fullname: Sudhir Gupta
          isHf: false
          isPro: false
          name: sudhir2016
          type: user
        html: '<p>When do you plan to integrate in transformers lib as a pipeline
          function ?</p>

          '
        raw: When do you plan to integrate in transformers lib as a pipeline function
          ?
        updatedAt: '2023-09-22T09:58:12.130Z'
      numEdits: 0
      reactions:
      - count: 6
        reaction: "\U0001F917"
        users:
        - lysandre
        - ArthurZ
        - apurvagup
        - shikhar-srivastava
        - oscaramos
        - osanseviero
      - count: 1
        reaction: "\U0001F44D"
        users:
        - shaktisd
    id: 650d653403ce54bd11bbe44d
    type: comment
  author: sudhir2016
  content: When do you plan to integrate in transformers lib as a pipeline function
    ?
  created_at: 2023-09-22 08:58:12+00:00
  edited: false
  hidden: false
  id: 650d653403ce54bd11bbe44d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
      fullname: Lysandre
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lysandre
      type: user
    createdAt: '2023-09-22T14:21:06.000Z'
    data:
      edited: true
      editors:
      - lysandre
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9163889288902283
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
          fullname: Lysandre
          isHf: true
          isPro: false
          name: lysandre
          type: user
        html: "<p>On behalf of the <code>transformers</code> team, we'd be happy to\
          \ help with the integration within the library if there is desire from <span\
          \ data-props=\"{&quot;user&quot;:&quot;gugarosa&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/gugarosa\">@<span class=\"\
          underline\">gugarosa</span></a></span>\n\n\t</span></span> or <span data-props=\"\
          {&quot;user&quot;:&quot;suriyagunasekar&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/suriyagunasekar\">@<span class=\"underline\"\
          >suriyagunasekar</span></a></span>\n\n\t</span></span> \U0001F917</p>\n"
        raw: "On behalf of the `transformers` team, we'd be happy to help with the\
          \ integration within the library if there is desire from @gugarosa or @suriyagunasekar\
          \ \U0001F917"
        updatedAt: '2023-09-22T16:04:42.999Z'
      numEdits: 1
      reactions: []
    id: 650da2d2a8a707150c2f0414
    type: comment
  author: lysandre
  content: "On behalf of the `transformers` team, we'd be happy to help with the integration\
    \ within the library if there is desire from @gugarosa or @suriyagunasekar \U0001F917"
  created_at: 2023-09-22 13:21:06+00:00
  edited: true
  hidden: false
  id: 650da2d2a8a707150c2f0414
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
      fullname: Susnato Dhar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: susnato
      type: user
    createdAt: '2023-09-24T16:57:04.000Z'
    data:
      edited: false
      editors:
      - susnato
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8850417137145996
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
          fullname: Susnato Dhar
          isHf: false
          isPro: false
          name: susnato
          type: user
        html: '<p>Hi,  I am currently working on this integration, <a rel="nofollow"
          href="https://github.com/huggingface/transformers/pull/26170">PR</a>. :)</p>

          '
        raw: Hi,  I am currently working on this integration, [PR](https://github.com/huggingface/transformers/pull/26170).
          :)
        updatedAt: '2023-09-24T16:57:04.512Z'
      numEdits: 0
      reactions: []
    id: 65106a60b63668f4483b8060
    type: comment
  author: susnato
  content: Hi,  I am currently working on this integration, [PR](https://github.com/huggingface/transformers/pull/26170).
    :)
  created_at: 2023-09-24 15:57:04+00:00
  edited: false
  hidden: false
  id: 65106a60b63668f4483b8060
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9c3b817a7b558e0667652ead31747967.svg
      fullname: Sudhir Gupta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sudhir2016
      type: user
    createdAt: '2023-09-25T01:56:36.000Z'
    data:
      edited: false
      editors:
      - sudhir2016
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6409125328063965
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9c3b817a7b558e0667652ead31747967.svg
          fullname: Sudhir Gupta
          isHf: false
          isPro: false
          name: sudhir2016
          type: user
        html: '<p>Thank you  !!</p>

          '
        raw: Thank you  !!
        updatedAt: '2023-09-25T01:56:36.039Z'
      numEdits: 0
      reactions: []
    id: 6510e8d48d01590937f9680c
    type: comment
  author: sudhir2016
  content: Thank you  !!
  created_at: 2023-09-25 00:56:36+00:00
  edited: false
  hidden: false
  id: 6510e8d48d01590937f9680c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86090d2d8c7dd596cf9f7e640e8e5951.svg
      fullname: Zengzhi Wang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SinclairWang
      type: user
    createdAt: '2023-10-13T05:11:13.000Z'
    data:
      edited: false
      editors:
      - SinclairWang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9008011817932129
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/86090d2d8c7dd596cf9f7e640e8e5951.svg
          fullname: Zengzhi Wang
          isHf: false
          isPro: false
          name: SinclairWang
          type: user
        html: "<p>Will it support fine-tuning these models, such as phi-1 and phi-1.5?</p>\n\
          <p>Currently, during my finetuning, I encountered this warning</p>\n<pre><code>`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          {'loss': 1.3228, 'learning_rate': 1.999875577156579e-05, 'epoch': 0.02}\n\
          \  1%|\u258D                                                           \
          \                                  | 300/59745 [06:19&lt;20:47:29,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 301/59745 [06:20&lt;20:48:14,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 302/59745 [06:22&lt;20:48:01,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 303/59745 [06:23&lt;20:47:31,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 304/59745 [06:24&lt;20:48:13,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 305/59745 [06:25&lt;20:49:27,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 306/59745 [06:27&lt;20:48:52,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 307/59745 [06:28&lt;20:48:29,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 308/59745 [06:29&lt;20:49:14,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 309/59745 [06:30&lt;20:49:49,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          {'loss': 1.5263, 'learning_rate': 1.9998671442394832e-05, 'epoch': 0.02}\n\
          </code></pre>\n"
        raw: "Will it support fine-tuning these models, such as phi-1 and phi-1.5?\n\
          \nCurrently, during my finetuning, I encountered this warning\n\n```\n`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          {'loss': 1.3228, 'learning_rate': 1.999875577156579e-05, 'epoch': 0.02}\n\
          \  1%|\u258D                                                           \
          \                                  | 300/59745 [06:19<20:47:29,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 301/59745 [06:20<20:48:14,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 302/59745 [06:22<20:48:01,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 303/59745 [06:23<20:47:31,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 304/59745 [06:24<20:48:13,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 305/59745 [06:25<20:49:27,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 306/59745 [06:27<20:48:52,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 307/59745 [06:28<20:48:29,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 308/59745 [06:29<20:49:14,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          \  1%|\u258D                                                           \
          \                                  | 309/59745 [06:30<20:49:49,  1.26s/it]`attention_mask`\
          \ is not supported during training. Using it might lead to unexpected results.\n\
          {'loss': 1.5263, 'learning_rate': 1.9998671442394832e-05, 'epoch': 0.02}\n\
          \n```"
        updatedAt: '2023-10-13T05:11:13.888Z'
      numEdits: 0
      reactions: []
    id: 6528d1711ddb701dc2d8c536
    type: comment
  author: SinclairWang
  content: "Will it support fine-tuning these models, such as phi-1 and phi-1.5?\n\
    \nCurrently, during my finetuning, I encountered this warning\n\n```\n`attention_mask`\
    \ is not supported during training. Using it might lead to unexpected results.\n\
    {'loss': 1.3228, 'learning_rate': 1.999875577156579e-05, 'epoch': 0.02}\n  1%|\u258D\
    \                                                                            \
    \                 | 300/59745 [06:19<20:47:29,  1.26s/it]`attention_mask` is not\
    \ supported during training. Using it might lead to unexpected results.\n  1%|\u258D\
    \                                                                            \
    \                 | 301/59745 [06:20<20:48:14,  1.26s/it]`attention_mask` is not\
    \ supported during training. Using it might lead to unexpected results.\n  1%|\u258D\
    \                                                                            \
    \                 | 302/59745 [06:22<20:48:01,  1.26s/it]`attention_mask` is not\
    \ supported during training. Using it might lead to unexpected results.\n  1%|\u258D\
    \                                                                            \
    \                 | 303/59745 [06:23<20:47:31,  1.26s/it]`attention_mask` is not\
    \ supported during training. Using it might lead to unexpected results.\n  1%|\u258D\
    \                                                                            \
    \                 | 304/59745 [06:24<20:48:13,  1.26s/it]`attention_mask` is not\
    \ supported during training. Using it might lead to unexpected results.\n  1%|\u258D\
    \                                                                            \
    \                 | 305/59745 [06:25<20:49:27,  1.26s/it]`attention_mask` is not\
    \ supported during training. Using it might lead to unexpected results.\n  1%|\u258D\
    \                                                                            \
    \                 | 306/59745 [06:27<20:48:52,  1.26s/it]`attention_mask` is not\
    \ supported during training. Using it might lead to unexpected results.\n  1%|\u258D\
    \                                                                            \
    \                 | 307/59745 [06:28<20:48:29,  1.26s/it]`attention_mask` is not\
    \ supported during training. Using it might lead to unexpected results.\n  1%|\u258D\
    \                                                                            \
    \                 | 308/59745 [06:29<20:49:14,  1.26s/it]`attention_mask` is not\
    \ supported during training. Using it might lead to unexpected results.\n  1%|\u258D\
    \                                                                            \
    \                 | 309/59745 [06:30<20:49:49,  1.26s/it]`attention_mask` is not\
    \ supported during training. Using it might lead to unexpected results.\n{'loss':\
    \ 1.5263, 'learning_rate': 1.9998671442394832e-05, 'epoch': 0.02}\n\n```"
  created_at: 2023-10-13 04:11:13+00:00
  edited: false
  hidden: false
  id: 6528d1711ddb701dc2d8c536
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
      fullname: Susnato Dhar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: susnato
      type: user
    createdAt: '2023-10-13T06:36:18.000Z'
    data:
      edited: false
      editors:
      - susnato
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8415988087654114
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
          fullname: Susnato Dhar
          isHf: false
          isPro: false
          name: susnato
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;SinclairWang&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/SinclairWang\"\
          >@<span class=\"underline\">SinclairWang</span></a></span>\n\n\t</span></span>,\
          \ yes it will support <code>attention_mask</code>, so you won't get this\
          \ warning.</p>\n"
        raw: Hi @SinclairWang, yes it will support `attention_mask`, so you won't
          get this warning.
        updatedAt: '2023-10-13T06:36:18.421Z'
      numEdits: 0
      reactions: []
    id: 6528e562f0042c8301dad96d
    type: comment
  author: susnato
  content: Hi @SinclairWang, yes it will support `attention_mask`, so you won't get
    this warning.
  created_at: 2023-10-13 05:36:18+00:00
  edited: false
  hidden: false
  id: 6528e562f0042c8301dad96d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2023-10-30T17:03:29.000Z'
    data:
      edited: false
      editors:
      - gugarosa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9170374274253845
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
          fullname: Gustavo de Rosa
          isHf: false
          isPro: false
          name: gugarosa
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;SinclairWang&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/SinclairWang\"\
          >@<span class=\"underline\">SinclairWang</span></a></span>\n\n\t</span></span>!\
          \ Until phi is fully integrated in <code>transformers</code>, we added support\
          \ for training/fine-tuning with attention mask in the files located in this\
          \ repository.</p>\n<p>You should not get the warning anymore if using the\
          \ latest revision.</p>\n"
        raw: 'Hello @SinclairWang! Until phi is fully integrated in `transformers`,
          we added support for training/fine-tuning with attention mask in the files
          located in this repository.


          You should not get the warning anymore if using the latest revision.'
        updatedAt: '2023-10-30T17:03:29.066Z'
      numEdits: 0
      reactions: []
    id: 653fe1e166c716609b188944
    type: comment
  author: gugarosa
  content: 'Hello @SinclairWang! Until phi is fully integrated in `transformers`,
    we added support for training/fine-tuning with attention mask in the files located
    in this repository.


    You should not get the warning anymore if using the latest revision.'
  created_at: 2023-10-30 16:03:29+00:00
  edited: false
  hidden: false
  id: 653fe1e166c716609b188944
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2023-11-20T18:13:26.000Z'
    data:
      status: closed
    id: 655ba1c676e4fad552a51163
    type: status-change
  author: gugarosa
  created_at: 2023-11-20 18:13:26+00:00
  id: 655ba1c676e4fad552a51163
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 27
repo_id: microsoft/phi-1_5
repo_type: model
status: closed
target_branch: null
title: Integration in transformers lib.
