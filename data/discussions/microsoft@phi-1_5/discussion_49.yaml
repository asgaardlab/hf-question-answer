!!python/object:huggingface_hub.community.DiscussionWithDetails
author: codegood
conflicting_files: null
created_at: 2023-10-13 23:13:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/14c0faec86334a15d040ef3219f7a63f.svg
      fullname: Stephan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: codegood
      type: user
    createdAt: '2023-10-14T00:13:09.000Z'
    data:
      edited: false
      editors:
      - codegood
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9774338603019714
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/14c0faec86334a15d040ef3219f7a63f.svg
          fullname: Stephan
          isHf: false
          isPro: false
          name: codegood
          type: user
        html: '<p>Hello,</p>

          <p>I want to know if this model is able for Question Answering and what
          is the format I should give to it?<br>Does it also require context?</p>

          <p>Thanks</p>

          '
        raw: "Hello,\r\n\r\nI want to know if this model is able for Question Answering\
          \ and what is the format I should give to it?\r\nDoes it also require context?\r\
          \n\r\nThanks"
        updatedAt: '2023-10-14T00:13:09.704Z'
      numEdits: 0
      reactions: []
    id: 6529dd153a416e1f2185744b
    type: comment
  author: codegood
  content: "Hello,\r\n\r\nI want to know if this model is able for Question Answering\
    \ and what is the format I should give to it?\r\nDoes it also require context?\r\
    \n\r\nThanks"
  created_at: 2023-10-13 23:13:09+00:00
  edited: false
  hidden: false
  id: 6529dd153a416e1f2185744b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/236c771e6c5a25ef6ed5e1bc061e30b8.svg
      fullname: Krishna Kaasyap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KrishnaKaasyap
      type: user
    createdAt: '2023-10-15T09:09:52.000Z'
    data:
      edited: false
      editors:
      - KrishnaKaasyap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9322519898414612
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/236c771e6c5a25ef6ed5e1bc061e30b8.svg
          fullname: Krishna Kaasyap
          isHf: false
          isPro: false
          name: KrishnaKaasyap
          type: user
        html: '<p>No, it is not trained for Q&amp;A format. It is not a instruct or
          chat fine tuned version, It is a base model. But still  you can ask questions.</p>

          <p>You can use this format -</p>

          <p>What is the capital of Germany - Berlin<br>What is the capital of India
          - New Delhi<br>What is the capital of Egypt -</p>

          <p>The it''ll answer Cairo.</p>

          <p>And it needs context for most of the questions. Since it is trained on
          30B tokens data, it doesn''t know everything. If you ask what is the capital
          of France - it might say Paris and some other same level questions, but
          if you ask it complex questions, which you usually ask GPT 4 or Google Bard
          or Bing chat or Chat GPT (GPT 3.5) - it might not be able to answer them.</p>

          <p>Moreover it has only 2048 context length, so you cannot ask long questions
          and expect lengthy answers.</p>

          '
        raw: 'No, it is not trained for Q&A format. It is not a instruct or chat fine
          tuned version, It is a base model. But still  you can ask questions.


          You can use this format -


          What is the capital of Germany - Berlin

          What is the capital of India - New Delhi

          What is the capital of Egypt -


          The it''ll answer Cairo.


          And it needs context for most of the questions. Since it is trained on 30B
          tokens data, it doesn''t know everything. If you ask what is the capital
          of France - it might say Paris and some other same level questions, but
          if you ask it complex questions, which you usually ask GPT 4 or Google Bard
          or Bing chat or Chat GPT (GPT 3.5) - it might not be able to answer them.


          Moreover it has only 2048 context length, so you cannot ask long questions
          and expect lengthy answers.'
        updatedAt: '2023-10-15T09:09:52.863Z'
      numEdits: 0
      reactions: []
    id: 652bac60be6f4e2fbba7e2b2
    type: comment
  author: KrishnaKaasyap
  content: 'No, it is not trained for Q&A format. It is not a instruct or chat fine
    tuned version, It is a base model. But still  you can ask questions.


    You can use this format -


    What is the capital of Germany - Berlin

    What is the capital of India - New Delhi

    What is the capital of Egypt -


    The it''ll answer Cairo.


    And it needs context for most of the questions. Since it is trained on 30B tokens
    data, it doesn''t know everything. If you ask what is the capital of France -
    it might say Paris and some other same level questions, but if you ask it complex
    questions, which you usually ask GPT 4 or Google Bard or Bing chat or Chat GPT
    (GPT 3.5) - it might not be able to answer them.


    Moreover it has only 2048 context length, so you cannot ask long questions and
    expect lengthy answers.'
  created_at: 2023-10-15 08:09:52+00:00
  edited: false
  hidden: false
  id: 652bac60be6f4e2fbba7e2b2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/14c0faec86334a15d040ef3219f7a63f.svg
      fullname: Stephan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: codegood
      type: user
    createdAt: '2023-10-19T02:13:11.000Z'
    data:
      edited: false
      editors:
      - codegood
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9218183755874634
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/14c0faec86334a15d040ef3219f7a63f.svg
          fullname: Stephan
          isHf: false
          isPro: false
          name: codegood
          type: user
        html: '<p>I''m running it on Google Colab.<br>Can we get list of libraries
          being used?</p>

          '
        raw: 'I''m running it on Google Colab.

          Can we get list of libraries being used?'
        updatedAt: '2023-10-19T02:13:11.282Z'
      numEdits: 0
      reactions: []
    id: 653090b7020159ddf4bb857e
    type: comment
  author: codegood
  content: 'I''m running it on Google Colab.

    Can we get list of libraries being used?'
  created_at: 2023-10-19 01:13:11+00:00
  edited: false
  hidden: false
  id: 653090b7020159ddf4bb857e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ccfc51d2a9397bc4f54af1f1b8ebf537.svg
      fullname: Vicente Rivera
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vriveras
      type: user
    createdAt: '2023-10-19T02:19:30.000Z'
    data:
      edited: false
      editors:
      - vriveras
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8986819386482239
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ccfc51d2a9397bc4f54af1f1b8ebf537.svg
          fullname: Vicente Rivera
          isHf: false
          isPro: false
          name: vriveras
          type: user
        html: '<p>What do you mean? If you are just using the model PyTorch and Transformers
          should let you run inference. </p>

          '
        raw: 'What do you mean? If you are just using the model PyTorch and Transformers
          should let you run inference. '
        updatedAt: '2023-10-19T02:19:30.203Z'
      numEdits: 0
      reactions: []
    id: 65309232020159ddf4bbaef6
    type: comment
  author: vriveras
  content: 'What do you mean? If you are just using the model PyTorch and Transformers
    should let you run inference. '
  created_at: 2023-10-19 01:19:30+00:00
  edited: false
  hidden: false
  id: 65309232020159ddf4bbaef6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2023-10-30T17:14:05.000Z'
    data:
      edited: false
      editors:
      - gugarosa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9509148597717285
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
          fullname: Gustavo de Rosa
          isHf: false
          isPro: false
          name: gugarosa
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;codegood&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/codegood\"\
          >@<span class=\"underline\">codegood</span></a></span>\n\n\t</span></span>!\
          \ As vriveras previously mentioned, this model has not been instructed fine-tuned\
          \ or reinforced with human feedback. Thus, it is more useful to generate\
          \ completions than chatting, although it can produce some reasonable chat\
          \ depending on the prompt you are using.</p>\n<p>The libraries used to load\
          \ the model are <code>torch</code>, <code>transformers</code> and <code>einops</code>.\
          \ As long as you have them, you should be able to load and infer with the\
          \ model.</p>\n"
        raw: 'Hello @codegood! As vriveras previously mentioned, this model has not
          been instructed fine-tuned or reinforced with human feedback. Thus, it is
          more useful to generate completions than chatting, although it can produce
          some reasonable chat depending on the prompt you are using.


          The libraries used to load the model are `torch`, `transformers` and `einops`.
          As long as you have them, you should be able to load and infer with the
          model.'
        updatedAt: '2023-10-30T17:14:05.894Z'
      numEdits: 0
      reactions: []
    id: 653fe45df6991d528c655992
    type: comment
  author: gugarosa
  content: 'Hello @codegood! As vriveras previously mentioned, this model has not
    been instructed fine-tuned or reinforced with human feedback. Thus, it is more
    useful to generate completions than chatting, although it can produce some reasonable
    chat depending on the prompt you are using.


    The libraries used to load the model are `torch`, `transformers` and `einops`.
    As long as you have them, you should be able to load and infer with the model.'
  created_at: 2023-10-30 16:14:05+00:00
  edited: false
  hidden: false
  id: 653fe45df6991d528c655992
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2023-11-13T18:48:05.000Z'
    data:
      status: closed
    id: 65526f659e144c06dd09389a
    type: status-change
  author: gugarosa
  created_at: 2023-11-13 18:48:05+00:00
  id: 65526f659e144c06dd09389a
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 49
repo_id: microsoft/phi-1_5
repo_type: model
status: closed
target_branch: null
title: Question answering format
