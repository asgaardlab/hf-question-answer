!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jamesbraza
conflicting_files: null
created_at: 2024-01-11 09:49:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b83ceb49bde5d94813ce2e/PYf6nXBVGQPIgTk_NzudC.png?w=200&h=200&f=face
      fullname: James Braza
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jamesbraza
      type: user
    createdAt: '2024-01-11T09:49:00.000Z'
    data:
      edited: false
      editors:
      - jamesbraza
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6547617316246033
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b83ceb49bde5d94813ce2e/PYf6nXBVGQPIgTk_NzudC.png?w=200&h=200&f=face
          fullname: James Braza
          isHf: false
          isPro: false
          name: jamesbraza
          type: user
        html: "<p>The current README (<a href=\"https://huggingface.co/microsoft/phi-1_5/blob/914c8fb3c681ebe3cacbe3c748858a572283ddde/README.md\"\
          >https://huggingface.co/microsoft/phi-1_5/blob/914c8fb3c681ebe3cacbe3c748858a572283ddde/README.md</a>)\
          \ poses the QA format.</p>\n<p>Trying to reproduce the response, I get nowhere\
          \ close to what the <code>README</code> says (see output below).  What am\
          \ I missing?</p>\n<pre><code class=\"language-python\"><span class=\"hljs-comment\"\
          ># With transformers==4.36.2 and tokenizers==0.15.0</span>\n<span class=\"\
          hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span>\
          \ AutoModelForCausalLM, AutoTokenizer\n\nMODEL_NAME = <span class=\"hljs-string\"\
          >\"microsoft/phi-1_5\"</span>\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\
          model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\ngeneration = model.generate(\n\
          \    **tokenizer(\n        <span class=\"hljs-string\">\"Write a detailed\
          \ analogy between mathematics and a lighthouse.\\n\\nAnswer:\"</span>,\n\
          \        return_tensors=<span class=\"hljs-string\">\"pt\"</span>,\n   \
          \ ),\n    max_length=<span class=\"hljs-number\">30</span>,\n    do_sample=<span\
          \ class=\"hljs-literal\">True</span>,\n)\n<span class=\"hljs-built_in\"\
          >print</span>(tokenizer.batch_decode(generation, skip_special_tokens=<span\
          \ class=\"hljs-literal\">True</span>))\n</code></pre>\n<p>Running this prints:</p>\n\
          <pre><code>['Write a detailed analogy between mathematics and a lighthouse.\\\
          n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n</code></pre>\n"
        raw: "The current README (https://huggingface.co/microsoft/phi-1_5/blob/914c8fb3c681ebe3cacbe3c748858a572283ddde/README.md)\
          \ poses the QA format.\r\n\r\nTrying to reproduce the response, I get nowhere\
          \ close to what the `README` says (see output below).  What am I missing?\r\
          \n\r\n```python\r\n# With transformers==4.36.2 and tokenizers==0.15.0\r\n\
          from transformers import AutoModelForCausalLM, AutoTokenizer\r\n\r\nMODEL_NAME\
          \ = \"microsoft/phi-1_5\"\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\r\
          \nmodel = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\r\ngeneration\
          \ = model.generate(\r\n    **tokenizer(\r\n        \"Write a detailed analogy\
          \ between mathematics and a lighthouse.\\n\\nAnswer:\",\r\n        return_tensors=\"\
          pt\",\r\n    ),\r\n    max_length=30,\r\n    do_sample=True,\r\n)\r\nprint(tokenizer.batch_decode(generation,\
          \ skip_special_tokens=True))\r\n```\r\n\r\nRunning this prints:\r\n\r\n\
          ```\r\n['Write a detailed analogy between mathematics and a lighthouse.\\\
          n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\r\n```"
        updatedAt: '2024-01-11T09:49:00.166Z'
      numEdits: 0
      reactions: []
    id: 659fb98c419de2ea6058ac3f
    type: comment
  author: jamesbraza
  content: "The current README (https://huggingface.co/microsoft/phi-1_5/blob/914c8fb3c681ebe3cacbe3c748858a572283ddde/README.md)\
    \ poses the QA format.\r\n\r\nTrying to reproduce the response, I get nowhere\
    \ close to what the `README` says (see output below).  What am I missing?\r\n\r\
    \n```python\r\n# With transformers==4.36.2 and tokenizers==0.15.0\r\nfrom transformers\
    \ import AutoModelForCausalLM, AutoTokenizer\r\n\r\nMODEL_NAME = \"microsoft/phi-1_5\"\
    \r\n\r\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\r\nmodel = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\r\
    \ngeneration = model.generate(\r\n    **tokenizer(\r\n        \"Write a detailed\
    \ analogy between mathematics and a lighthouse.\\n\\nAnswer:\",\r\n        return_tensors=\"\
    pt\",\r\n    ),\r\n    max_length=30,\r\n    do_sample=True,\r\n)\r\nprint(tokenizer.batch_decode(generation,\
    \ skip_special_tokens=True))\r\n```\r\n\r\nRunning this prints:\r\n\r\n```\r\n\
    ['Write a detailed analogy between mathematics and a lighthouse.\\n\\nAnswer:\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\r\n```"
  created_at: 2024-01-11 09:49:00+00:00
  edited: false
  hidden: false
  id: 659fb98c419de2ea6058ac3f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a3c6507abdaa25a81ce659/Z7e4xiH7sjQYt2Qga4W8o.png?w=200&h=200&f=face
      fullname: M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Maykeye
      type: user
    createdAt: '2024-01-11T10:15:04.000Z'
    data:
      edited: true
      editors:
      - Maykeye
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8875551819801331
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a3c6507abdaa25a81ce659/Z7e4xiH7sjQYt2Qga4W8o.png?w=200&h=200&f=face
          fullname: M
          isHf: false
          isPro: false
          name: Maykeye
          type: user
        html: '<blockquote>

          <p>model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)</p>

          </blockquote>

          <p>At this point <code>transformers</code> 4.36.2 should print tons of warnings
          about keys mismatch: you are using built-in version of phi from 4.36.2 which
          is not compatible with weights in this phi-1.5 repo.</p>

          <p>Either force transformers to load the code from this repo, or use repo
          with compatible version (see <a rel="nofollow" href="https://github.com/huggingface/transformers/issues/28416">https://github.com/huggingface/transformers/issues/28416</a>
          for example) or do torch.load to load weights manually and poke them with
          a pointy stick until they become suitable to be loaded with <code>load_state_dict</code></p>

          '
        raw: '> model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)


          At this point `transformers` 4.36.2 should print tons of warnings about
          keys mismatch: you are using built-in version of phi from 4.36.2 which is
          not compatible with weights in this phi-1.5 repo.


          Either force transformers to load the code from this repo, or use repo with
          compatible version (see https://github.com/huggingface/transformers/issues/28416
          for example) or do torch.load to load weights manually and poke them with
          a pointy stick until they become suitable to be loaded with `load_state_dict`'
        updatedAt: '2024-01-11T10:15:40.750Z'
      numEdits: 1
      reactions: []
    id: 659fbfa80183046e16bced81
    type: comment
  author: Maykeye
  content: '> model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)


    At this point `transformers` 4.36.2 should print tons of warnings about keys mismatch:
    you are using built-in version of phi from 4.36.2 which is not compatible with
    weights in this phi-1.5 repo.


    Either force transformers to load the code from this repo, or use repo with compatible
    version (see https://github.com/huggingface/transformers/issues/28416 for example)
    or do torch.load to load weights manually and poke them with a pointy stick until
    they become suitable to be loaded with `load_state_dict`'
  created_at: 2024-01-11 10:15:04+00:00
  edited: true
  hidden: false
  id: 659fbfa80183046e16bced81
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-11T11:25:00.000Z'
    data:
      edited: false
      editors:
      - gugarosa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8869861364364624
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
          fullname: Gustavo de Rosa
          isHf: false
          isPro: false
          name: gugarosa
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;jamesbraza&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/jamesbraza\"\
          >@<span class=\"underline\">jamesbraza</span></a></span>\n\n\t</span></span>!</p>\n\
          <p>We just pushed a fix to the <code>config.json</code> and it should work\
          \ now. However, as per the remark on the model card:</p>\n<pre><code>If\
          \ you are using transformers&lt;4.37.0, always load the model with trust_remote_code=True\
          \ to prevent side-effects.\n</code></pre>\n<p>Best regards,<br>Gustavo.</p>\n"
        raw: 'Hello @jamesbraza!


          We just pushed a fix to the `config.json` and it should work now. However,
          as per the remark on the model card:


          ```

          If you are using transformers<4.37.0, always load the model with trust_remote_code=True
          to prevent side-effects.

          ```


          Best regards,

          Gustavo.'
        updatedAt: '2024-01-11T11:25:00.876Z'
      numEdits: 0
      reactions: []
      relatedEventId: 659fd00de06dc8fc0e598c43
    id: 659fd00ce06dc8fc0e598c39
    type: comment
  author: gugarosa
  content: 'Hello @jamesbraza!


    We just pushed a fix to the `config.json` and it should work now. However, as
    per the remark on the model card:


    ```

    If you are using transformers<4.37.0, always load the model with trust_remote_code=True
    to prevent side-effects.

    ```


    Best regards,

    Gustavo.'
  created_at: 2024-01-11 11:25:00+00:00
  edited: false
  hidden: false
  id: 659fd00ce06dc8fc0e598c39
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-11T11:25:01.000Z'
    data:
      status: closed
    id: 659fd00de06dc8fc0e598c43
    type: status-change
  author: gugarosa
  created_at: 2024-01-11 11:25:01+00:00
  id: 659fd00de06dc8fc0e598c43
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 71
repo_id: microsoft/phi-1_5
repo_type: model
status: closed
target_branch: null
title: Failure to reproduce QA Format response from the README
