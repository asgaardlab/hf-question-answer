!!python/object:huggingface_hub.community.DiscussionWithDetails
author: GhostlyBox
conflicting_files: null
created_at: 2023-08-09 16:19:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f515b1cb7c87f945c31b2dbe1d11d3b7.svg
      fullname: Rob Reeves
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: GhostlyBox
      type: user
    createdAt: '2023-08-09T17:19:56.000Z'
    data:
      edited: false
      editors:
      - GhostlyBox
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4550532400608063
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f515b1cb7c87f945c31b2dbe1d11d3b7.svg
          fullname: Rob Reeves
          isHf: false
          isPro: false
          name: GhostlyBox
          type: user
        html: "<p>Would someone be able to tell me what I might be doing wrong with\
          \ the <code>GPTQ_gptq-8bit-128g-actorder_False</code> model?  I seem to\
          \ get the following error output when asking a question in text-generation-webui:</p>\n\
          <pre><code>Traceback (most recent call last):\n  File \"C:\\Users\\User\\\
          Desktop\\oobabooga_windows\\text-generation-webui\\modules\\callbacks.py\"\
          , line 55, in gentask\n    ret = self.mfunc(callback=_callback, *args, **self.kwargs)\n\
          \  File \"C:\\Users\\User\\Desktop\\oobabooga_windows\\text-generation-webui\\\
          modules\\text_generation.py\", line 307, in generate_with_callback\n   \
          \ shared.model.generate(**kwargs)\n  File \"C:\\Users\\User\\Desktop\\oobabooga_windows\\\
          installer_files\\env\\lib\\site-packages\\auto_gptq\\modeling\\_base.py\"\
          , line 443, in generate\n    return self.model.generate(**kwargs)\n  File\
          \ \"C:\\Users\\User\\Desktop\\oobabooga_windows\\installer_files\\env\\\
          lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n\
          \    return func(*args, **kwargs)\n  File \"C:\\Users\\User\\Desktop\\oobabooga_windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\generation\\utils.py\"\
          , line 1430, in generate\n    and torch.sum(inputs_tensor[:, -1] == generation_config.pad_token_id)\
          \ &gt; 0\nIndexError: index -1 is out of bounds for dimension 1 with size\
          \ 0\n</code></pre>\n"
        raw: "Would someone be able to tell me what I might be doing wrong with the\
          \ `GPTQ_gptq-8bit-128g-actorder_False` model?  I seem to get the following\
          \ error output when asking a question in text-generation-webui:\r\n\r\n\
          ```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\User\\\
          Desktop\\oobabooga_windows\\text-generation-webui\\modules\\callbacks.py\"\
          , line 55, in gentask\r\n    ret = self.mfunc(callback=_callback, *args,\
          \ **self.kwargs)\r\n  File \"C:\\Users\\User\\Desktop\\oobabooga_windows\\\
          text-generation-webui\\modules\\text_generation.py\", line 307, in generate_with_callback\r\
          \n    shared.model.generate(**kwargs)\r\n  File \"C:\\Users\\User\\Desktop\\\
          oobabooga_windows\\installer_files\\env\\lib\\site-packages\\auto_gptq\\\
          modeling\\_base.py\", line 443, in generate\r\n    return self.model.generate(**kwargs)\r\
          \n  File \"C:\\Users\\User\\Desktop\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\r\
          \n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\User\\Desktop\\\
          oobabooga_windows\\installer_files\\env\\lib\\site-packages\\transformers\\\
          generation\\utils.py\", line 1430, in generate\r\n    and torch.sum(inputs_tensor[:,\
          \ -1] == generation_config.pad_token_id) > 0\r\nIndexError: index -1 is\
          \ out of bounds for dimension 1 with size 0\r\n```"
        updatedAt: '2023-08-09T17:19:56.940Z'
      numEdits: 0
      reactions: []
    id: 64d3cabcffc45aae26b867d6
    type: comment
  author: GhostlyBox
  content: "Would someone be able to tell me what I might be doing wrong with the\
    \ `GPTQ_gptq-8bit-128g-actorder_False` model?  I seem to get the following error\
    \ output when asking a question in text-generation-webui:\r\n\r\n```\r\nTraceback\
    \ (most recent call last):\r\n  File \"C:\\Users\\User\\Desktop\\oobabooga_windows\\\
    text-generation-webui\\modules\\callbacks.py\", line 55, in gentask\r\n    ret\
    \ = self.mfunc(callback=_callback, *args, **self.kwargs)\r\n  File \"C:\\Users\\\
    User\\Desktop\\oobabooga_windows\\text-generation-webui\\modules\\text_generation.py\"\
    , line 307, in generate_with_callback\r\n    shared.model.generate(**kwargs)\r\
    \n  File \"C:\\Users\\User\\Desktop\\oobabooga_windows\\installer_files\\env\\\
    lib\\site-packages\\auto_gptq\\modeling\\_base.py\", line 443, in generate\r\n\
    \    return self.model.generate(**kwargs)\r\n  File \"C:\\Users\\User\\Desktop\\\
    oobabooga_windows\\installer_files\\env\\lib\\site-packages\\torch\\utils\\_contextlib.py\"\
    , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File\
    \ \"C:\\Users\\User\\Desktop\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\generation\\utils.py\", line 1430, in generate\r\n    and torch.sum(inputs_tensor[:,\
    \ -1] == generation_config.pad_token_id) > 0\r\nIndexError: index -1 is out of\
    \ bounds for dimension 1 with size 0\r\n```"
  created_at: 2023-08-09 16:19:56+00:00
  edited: false
  hidden: false
  id: 64d3cabcffc45aae26b867d6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TheBloke/WizardCoder-Guanaco-15B-V1.1-GPTQ
repo_type: model
status: open
target_branch: null
title: text-generation-webui error with auto_gptq?
