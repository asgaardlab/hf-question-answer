!!python/object:huggingface_hub.community.DiscussionWithDetails
author: eshamanideep
conflicting_files: null
created_at: 2023-07-12 10:11:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8814cfd4eabbe0347da89249a2ccacb2.svg
      fullname: Esha Manideep
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eshamanideep
      type: user
    createdAt: '2023-07-12T11:11:09.000Z'
    data:
      edited: false
      editors:
      - eshamanideep
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9230493307113647
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8814cfd4eabbe0347da89249a2ccacb2.svg
          fullname: Esha Manideep
          isHf: false
          isPro: false
          name: eshamanideep
          type: user
        html: '<p>Why did you guys choose TPU v4 over GPU A100 80 Gb or H100 any specific
          reason is it more quick or more economical ? I want to know this to decide
          GPU or TPU for fine tuning this model thanks </p>

          '
        raw: 'Why did you guys choose TPU v4 over GPU A100 80 Gb or H100 any specific
          reason is it more quick or more economical ? I want to know this to decide
          GPU or TPU for fine tuning this model thanks '
        updatedAt: '2023-07-12T11:11:09.909Z'
      numEdits: 0
      reactions: []
    id: 64ae8a4d51ab462d3b1e65ee
    type: comment
  author: eshamanideep
  content: 'Why did you guys choose TPU v4 over GPU A100 80 Gb or H100 any specific
    reason is it more quick or more economical ? I want to know this to decide GPU
    or TPU for fine tuning this model thanks '
  created_at: 2023-07-12 10:11:09+00:00
  edited: false
  hidden: false
  id: 64ae8a4d51ab462d3b1e65ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/24574113bfe000250196e935e4f7cde2.svg
      fullname: Tian Xie
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: tianxie-sf
      type: user
    createdAt: '2023-07-18T00:44:21.000Z'
    data:
      edited: false
      editors:
      - tianxie-sf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9036194682121277
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/24574113bfe000250196e935e4f7cde2.svg
          fullname: Tian Xie
          isHf: false
          isPro: false
          name: tianxie-sf
          type: user
        html: '<p>Because we don''t have good enough inter-node bandwidth for distributed
          training using GPUs on GCP, so we chose TPUs.  </p>

          '
        raw: 'Because we don''t have good enough inter-node bandwidth for distributed
          training using GPUs on GCP, so we chose TPUs.  '
        updatedAt: '2023-07-18T00:44:21.587Z'
      numEdits: 0
      reactions: []
    id: 64b5e065cf312e54881457ba
    type: comment
  author: tianxie-sf
  content: 'Because we don''t have good enough inter-node bandwidth for distributed
    training using GPUs on GCP, so we chose TPUs.  '
  created_at: 2023-07-17 23:44:21+00:00
  edited: false
  hidden: false
  id: 64b5e065cf312e54881457ba
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 23
repo_id: Salesforce/xgen-7b-8k-base
repo_type: model
status: open
target_branch: null
title: 'Regarding Choosing TPU over GPU for training '
