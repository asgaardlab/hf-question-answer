!!python/object:huggingface_hub.community.DiscussionWithDetails
author: psurya1994
conflicting_files: null
created_at: 2023-10-28 10:43:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/50fddef7fbc77bcda86a982d1cd11f80.svg
      fullname: Surya Penmetsa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: psurya1994
      type: user
    createdAt: '2023-10-28T11:43:34.000Z'
    data:
      edited: false
      editors:
      - psurya1994
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5452653169631958
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/50fddef7fbc77bcda86a982d1cd11f80.svg
          fullname: Surya Penmetsa
          isHf: false
          isPro: false
          name: psurya1994
          type: user
        html: "<p>I get the following error on a H100. This happens sometimes, but\
          \ not always. Happens for sentences close to 200 characters with lots of\
          \ fullstops like <code>The sun rose. Birds sang. Cats meowed. Dogs barked.\
          \ Cars honked. Children played. Trees swayed. Flowers bloomed. Bees buzzed.\
          \ Rain fell. The day began. Everyone smiled. Life was good.</code> Has anyone\
          \ faced this issue before? </p>\n<pre><code>../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [119,0,0] Assertion `srcIndex\
          \ &lt; srcSelectDimSize` failed.\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [120,0,0] Assertion `srcIndex\
          \ &lt; srcSelectDimSize` failed.\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [121,0,0] Assertion `srcIndex\
          \ &lt; srcSelectDimSize` failed.\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [122,0,0] Assertion `srcIndex\
          \ &lt; srcSelectDimSize` failed.\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [123,0,0] Assertion `srcIndex\
          \ &lt; srcSelectDimSize` failed.\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [124,0,0] Assertion `srcIndex\
          \ &lt; srcSelectDimSize` failed.\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [125,0,0] Assertion `srcIndex\
          \ &lt; srcSelectDimSize` failed.\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [126,0,0] Assertion `srcIndex\
          \ &lt; srcSelectDimSize` failed.\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [127,0,0] Assertion `srcIndex\
          \ &lt; srcSelectDimSize` failed.\nTraceback (most recent call last):\n \
          \ File \"/home/surya/code/tts_experiments/test.py\", line 12, in &lt;module&gt;\n\
          \    \n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/models/xtts.py\"\
          , line 428, in synthesize\n    return self.inference_with_config(text, config,\
          \ ref_audio_path=speaker_wav, language=language, **kwargs)\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/models/xtts.py\"\
          , line 450, in inference_with_config\n    return self.inference(text, ref_audio_path,\
          \ language, **settings)\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/models/xtts.py\"\
          , line 550, in inference\n    gpt_codes = gpt.generate(\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/layers/xtts/gpt.py\"\
          , line 535, in generate\n    gen = self.gpt_inference.generate(\n  File\
          \ \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 1648, in generate\n    return self.sample(\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 2730, in sample\n    outputs = self(\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/layers/xtts/gpt_inference.py\"\
          , line 97, in forward\n    transformer_outputs = self.transformer(\n  File\
          \ \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\"\
          , line 900, in forward\n    outputs = block(\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\"\
          , line 390, in forward\n    attn_outputs = self.attn(\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\"\
          , line 331, in forward\n    attn_output, attn_weights = self._attn(query,\
          \ key, value, attention_mask, head_mask)\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\"\
          , line 201, in _attn\n    mask_value = torch.full([], mask_value, dtype=attn_weights.dtype).to(attn_weights.device)\n\
          RuntimeError: CUDA error: device-side assert triggered\nCUDA kernel errors\
          \ might be asynchronously reported at some other API call, so the stacktrace\
          \ below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n\
          Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n</code></pre>\n"
        raw: "I get the following error on a H100. This happens sometimes, but not\
          \ always. Happens for sentences close to 200 characters with lots of fullstops\
          \ like `The sun rose. Birds sang. Cats meowed. Dogs barked. Cars honked.\
          \ Children played. Trees swayed. Flowers bloomed. Bees buzzed. Rain fell.\
          \ The day began. Everyone smiled. Life was good.` Has anyone faced this\
          \ issue before? \r\n\r\n```\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [119,0,0] Assertion `srcIndex\
          \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [120,0,0] Assertion `srcIndex\
          \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [121,0,0] Assertion `srcIndex\
          \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [122,0,0] Assertion `srcIndex\
          \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [123,0,0] Assertion `srcIndex\
          \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [124,0,0] Assertion `srcIndex\
          \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [125,0,0] Assertion `srcIndex\
          \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [126,0,0] Assertion `srcIndex\
          \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
          \ indexSelectSmallIndex: block: [6,0,0], thread: [127,0,0] Assertion `srcIndex\
          \ < srcSelectDimSize` failed.\r\nTraceback (most recent call last):\r\n\
          \  File \"/home/surya/code/tts_experiments/test.py\", line 12, in <module>\r\
          \n    \r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/models/xtts.py\"\
          , line 428, in synthesize\r\n    return self.inference_with_config(text,\
          \ config, ref_audio_path=speaker_wav, language=language, **kwargs)\r\n \
          \ File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/models/xtts.py\"\
          , line 450, in inference_with_config\r\n    return self.inference(text,\
          \ ref_audio_path, language, **settings)\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n\
          \  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/models/xtts.py\"\
          , line 550, in inference\r\n    gpt_codes = gpt.generate(\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/layers/xtts/gpt.py\"\
          , line 535, in generate\r\n    gen = self.gpt_inference.generate(\r\n  File\
          \ \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n\
          \  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 1648, in generate\r\n    return self.sample(\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 2730, in sample\r\n    outputs = self(\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/layers/xtts/gpt_inference.py\"\
          , line 97, in forward\r\n    transformer_outputs = self.transformer(\r\n\
          \  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\"\
          , line 900, in forward\r\n    outputs = block(\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\"\
          , line 390, in forward\r\n    attn_outputs = self.attn(\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\"\
          , line 331, in forward\r\n    attn_output, attn_weights = self._attn(query,\
          \ key, value, attention_mask, head_mask)\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\"\
          , line 201, in _attn\r\n    mask_value = torch.full([], mask_value, dtype=attn_weights.dtype).to(attn_weights.device)\r\
          \nRuntimeError: CUDA error: device-side assert triggered\r\nCUDA kernel\
          \ errors might be asynchronously reported at some other API call, so the\
          \ stacktrace below might be incorrect.\r\nFor debugging consider passing\
          \ CUDA_LAUNCH_BLOCKING=1.\r\nCompile with `TORCH_USE_CUDA_DSA` to enable\
          \ device-side assertions.\r\n```"
        updatedAt: '2023-10-28T11:43:34.955Z'
      numEdits: 0
      reactions: []
    id: 653cf3e6c2307cc44865c9b3
    type: comment
  author: psurya1994
  content: "I get the following error on a H100. This happens sometimes, but not always.\
    \ Happens for sentences close to 200 characters with lots of fullstops like `The\
    \ sun rose. Birds sang. Cats meowed. Dogs barked. Cars honked. Children played.\
    \ Trees swayed. Flowers bloomed. Bees buzzed. Rain fell. The day began. Everyone\
    \ smiled. Life was good.` Has anyone faced this issue before? \r\n\r\n```\r\n\
    ../aten/src/ATen/native/cuda/Indexing.cu:1093: indexSelectSmallIndex: block: [6,0,0],\
    \ thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
    \ indexSelectSmallIndex: block: [6,0,0], thread: [120,0,0] Assertion `srcIndex\
    \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
    \ indexSelectSmallIndex: block: [6,0,0], thread: [121,0,0] Assertion `srcIndex\
    \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
    \ indexSelectSmallIndex: block: [6,0,0], thread: [122,0,0] Assertion `srcIndex\
    \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
    \ indexSelectSmallIndex: block: [6,0,0], thread: [123,0,0] Assertion `srcIndex\
    \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
    \ indexSelectSmallIndex: block: [6,0,0], thread: [124,0,0] Assertion `srcIndex\
    \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
    \ indexSelectSmallIndex: block: [6,0,0], thread: [125,0,0] Assertion `srcIndex\
    \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
    \ indexSelectSmallIndex: block: [6,0,0], thread: [126,0,0] Assertion `srcIndex\
    \ < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:1093:\
    \ indexSelectSmallIndex: block: [6,0,0], thread: [127,0,0] Assertion `srcIndex\
    \ < srcSelectDimSize` failed.\r\nTraceback (most recent call last):\r\n  File\
    \ \"/home/surya/code/tts_experiments/test.py\", line 12, in <module>\r\n    \r\
    \n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/models/xtts.py\"\
    , line 428, in synthesize\r\n    return self.inference_with_config(text, config,\
    \ ref_audio_path=speaker_wav, language=language, **kwargs)\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/models/xtts.py\"\
    , line 450, in inference_with_config\r\n    return self.inference(text, ref_audio_path,\
    \ language, **settings)\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File\
    \ \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/models/xtts.py\"\
    , line 550, in inference\r\n    gpt_codes = gpt.generate(\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/layers/xtts/gpt.py\"\
    , line 535, in generate\r\n    gen = self.gpt_inference.generate(\r\n  File \"\
    /home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File\
    \ \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 1648, in generate\r\n    return self.sample(\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 2730, in sample\r\n    outputs = self(\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/TTS/tts/layers/xtts/gpt_inference.py\"\
    , line 97, in forward\r\n    transformer_outputs = self.transformer(\r\n  File\
    \ \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\"\
    , line 900, in forward\r\n    outputs = block(\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\"\
    , line 390, in forward\r\n    attn_outputs = self.attn(\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\"\
    , line 331, in forward\r\n    attn_output, attn_weights = self._attn(query, key,\
    \ value, attention_mask, head_mask)\r\n  File \"/home/surya/miniconda3/envs/tts/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\"\
    , line 201, in _attn\r\n    mask_value = torch.full([], mask_value, dtype=attn_weights.dtype).to(attn_weights.device)\r\
    \nRuntimeError: CUDA error: device-side assert triggered\r\nCUDA kernel errors\
    \ might be asynchronously reported at some other API call, so the stacktrace below\
    \ might be incorrect.\r\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\r\
    \nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\r\n```"
  created_at: 2023-10-28 10:43:34+00:00
  edited: false
  hidden: false
  id: 653cf3e6c2307cc44865c9b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e30fb3453a8777f7d40ed311b613f03a.svg
      fullname: Gorkem Goknar
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gorkemgoknar
      type: user
    createdAt: '2023-11-12T09:26:15.000Z'
    data:
      edited: false
      editors:
      - gorkemgoknar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7716010808944702
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e30fb3453a8777f7d40ed311b613f03a.svg
          fullname: Gorkem Goknar
          isHf: false
          isPro: false
          name: gorkemgoknar
          type: user
        html: '<p>On V2 model here these problems are minimized <a href="https://huggingface.co/coqui/XTTS-v2">https://huggingface.co/coqui/XTTS-v2</a></p>

          '
        raw: On V2 model here these problems are minimized https://huggingface.co/coqui/XTTS-v2
        updatedAt: '2023-11-12T09:26:15.190Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65509a378d8c3bf4dded9c9a
    id: 65509a378d8c3bf4dded9c96
    type: comment
  author: gorkemgoknar
  content: On V2 model here these problems are minimized https://huggingface.co/coqui/XTTS-v2
  created_at: 2023-11-12 09:26:15+00:00
  edited: false
  hidden: false
  id: 65509a378d8c3bf4dded9c96
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/e30fb3453a8777f7d40ed311b613f03a.svg
      fullname: Gorkem Goknar
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gorkemgoknar
      type: user
    createdAt: '2023-11-12T09:26:15.000Z'
    data:
      status: closed
    id: 65509a378d8c3bf4dded9c9a
    type: status-change
  author: gorkemgoknar
  created_at: 2023-11-12 09:26:15+00:00
  id: 65509a378d8c3bf4dded9c9a
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: coqui/XTTS-v1
repo_type: model
status: closed
target_branch: null
title: 'RuntimeError: CUDA error: device-side assert triggered'
