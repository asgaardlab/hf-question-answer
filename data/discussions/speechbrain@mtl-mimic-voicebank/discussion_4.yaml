!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SemanticLeopard
conflicting_files: null
created_at: 2022-07-20 00:54:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/459647888dbb5275ece9ce784101f569.svg
      fullname: .
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SemanticLeopard
      type: user
    createdAt: '2022-07-20T01:54:17.000Z'
    data:
      edited: true
      editors:
      - SemanticLeopard
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/459647888dbb5275ece9ce784101f569.svg
          fullname: .
          isHf: false
          isPro: false
          name: SemanticLeopard
          type: user
        html: '<p>Hi,</p>

          <p>I''ve managed to fine-tune the ASR model, the last step in this recipe,
          however I''m struggling to understand how I can easily use an inference
          class to transcribe enhanced audio files with the model. It seems like the
          pretrained ASR model may use a encoder decoder interface, but the modules
          produced in the hyperparameters final output are different from what is
          expected by that interface.</p>

          <p>Clearly based on the ''test_stats'' a model is produced that can perform
          ASR, but what interface to use for inference is a bit unclear - whether
          this needs to be something custom, or if it''s simpler than that. If you
          could provide some clarity regarding this, that would be helpful. </p>

          <p>Thanks.</p>

          '
        raw: "Hi,\n\nI've managed to fine-tune the ASR model, the last step in this\
          \ recipe, however I'm struggling to understand how I can easily use an inference\
          \ class to transcribe enhanced audio files with the model. It seems like\
          \ the pretrained ASR model may use a encoder decoder interface, but the\
          \ modules produced in the hyperparameters final output are different from\
          \ what is expected by that interface.\n\nClearly based on the 'test_stats'\
          \ a model is produced that can perform ASR, but what interface to use for\
          \ inference is a bit unclear - whether this needs to be something custom,\
          \ or if it's simpler than that. If you could provide some clarity regarding\
          \ this, that would be helpful. \n\nThanks."
        updatedAt: '2022-07-20T02:02:14.396Z'
      numEdits: 4
      reactions: []
    id: 62d760494fe7c96c5ff6a20f
    type: comment
  author: SemanticLeopard
  content: "Hi,\n\nI've managed to fine-tune the ASR model, the last step in this\
    \ recipe, however I'm struggling to understand how I can easily use an inference\
    \ class to transcribe enhanced audio files with the model. It seems like the pretrained\
    \ ASR model may use a encoder decoder interface, but the modules produced in the\
    \ hyperparameters final output are different from what is expected by that interface.\n\
    \nClearly based on the 'test_stats' a model is produced that can perform ASR,\
    \ but what interface to use for inference is a bit unclear - whether this needs\
    \ to be something custom, or if it's simpler than that. If you could provide some\
    \ clarity regarding this, that would be helpful. \n\nThanks."
  created_at: 2022-07-20 00:54:17+00:00
  edited: true
  hidden: false
  id: 62d760494fe7c96c5ff6a20f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615209203744-noauth.jpeg?w=200&h=200&f=face
      fullname: Peter Plantinga
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: pplantinga
      type: user
    createdAt: '2022-07-21T15:26:55.000Z'
    data:
      edited: false
      editors:
      - pplantinga
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615209203744-noauth.jpeg?w=200&h=200&f=face
          fullname: Peter Plantinga
          isHf: false
          isPro: false
          name: pplantinga
          type: user
        html: '<p>Hi, thanks for your interest!</p>

          <p>Unfortunately, we haven''t gotten around to writing an inference class
          for the robust-ASR model. You can do it yourself, however with code similar
          to this (untested):</p>

          <pre><code class="language-python">noisy_wavs, wav_lens = batch.noisy_sig

          cleaned_wavs, _ = self.modules.enhance_model(noisy_wavs)

          asr_feats = self.hparams.fbank(cleaned_wavs)

          asr_feats = self.hparams.normalizer(asr_feats, wav_lens)

          embed = self.modules.src_embedding(asr_feats)

          hypotheses, _ = self.hparams.beam_searcher(embed.detach(), wav_lens)

          pred_words = [self.token_encoder.decode_ids(token_seq) <span class="hljs-keyword">for</span>
          token_seq <span class="hljs-keyword">in</span> hypotheses]

          </code></pre>

          <p>Hope this helps!</p>

          '
        raw: 'Hi, thanks for your interest!


          Unfortunately, we haven''t gotten around to writing an inference class for
          the robust-ASR model. You can do it yourself, however with code similar
          to this (untested):


          ```python

          noisy_wavs, wav_lens = batch.noisy_sig

          cleaned_wavs, _ = self.modules.enhance_model(noisy_wavs)

          asr_feats = self.hparams.fbank(cleaned_wavs)

          asr_feats = self.hparams.normalizer(asr_feats, wav_lens)

          embed = self.modules.src_embedding(asr_feats)

          hypotheses, _ = self.hparams.beam_searcher(embed.detach(), wav_lens)

          pred_words = [self.token_encoder.decode_ids(token_seq) for token_seq in
          hypotheses]

          ```

          Hope this helps!'
        updatedAt: '2022-07-21T15:26:55.457Z'
      numEdits: 0
      reactions: []
    id: 62d9703f5e39f0dc96c3786b
    type: comment
  author: pplantinga
  content: 'Hi, thanks for your interest!


    Unfortunately, we haven''t gotten around to writing an inference class for the
    robust-ASR model. You can do it yourself, however with code similar to this (untested):


    ```python

    noisy_wavs, wav_lens = batch.noisy_sig

    cleaned_wavs, _ = self.modules.enhance_model(noisy_wavs)

    asr_feats = self.hparams.fbank(cleaned_wavs)

    asr_feats = self.hparams.normalizer(asr_feats, wav_lens)

    embed = self.modules.src_embedding(asr_feats)

    hypotheses, _ = self.hparams.beam_searcher(embed.detach(), wav_lens)

    pred_words = [self.token_encoder.decode_ids(token_seq) for token_seq in hypotheses]

    ```

    Hope this helps!'
  created_at: 2022-07-21 14:26:55+00:00
  edited: false
  hidden: false
  id: 62d9703f5e39f0dc96c3786b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615209203744-noauth.jpeg?w=200&h=200&f=face
      fullname: Peter Plantinga
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: pplantinga
      type: user
    createdAt: '2022-07-21T16:22:08.000Z'
    data:
      edited: true
      editors:
      - pplantinga
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615209203744-noauth.jpeg?w=200&h=200&f=face
          fullname: Peter Plantinga
          isHf: false
          isPro: false
          name: pplantinga
          type: user
        html: "<p>I suppose it might also work to use <code>EncoderDecoderASR</code>\
          \ inference class with a custom YAML file. Try to copy the <a href=\"https://huggingface.co/speechbrain/asr-crdnn-rnnlm-librispeech/blob/main/hyperparams.yaml\"\
          >https://huggingface.co/speechbrain/asr-crdnn-rnnlm-librispeech/blob/main/hyperparams.yaml</a></p>\n\
          <p>And add the enhance model in 2 places:</p>\n<pre><code>+ enhance_model:\
          \ # ... copy from the file in this repo\n  ...\n  # We compose the inference\
          \ (encoder) pipeline.\n  encoder: !new:speechbrain.nnet.containers.LengthsCapableSequential\n\
          \      input_shape: [null, null]\n+     enhance_features: !ref &lt;enhance_model&gt;\n\
          \      compute_features: !ref &lt;compute_features&gt;\n      normalize:\
          \ !ref &lt;normalizer&gt;\n      model: !ref &lt;enc&gt;\n</code></pre>\n"
        raw: "I suppose it might also work to use `EncoderDecoderASR` inference class\
          \ with a custom YAML file. Try to copy the https://huggingface.co/speechbrain/asr-crdnn-rnnlm-librispeech/blob/main/hyperparams.yaml\n\
          \nAnd add the enhance model in 2 places:\n\n```\n+ enhance_model: # ...\
          \ copy from the file in this repo\n  ...\n  # We compose the inference (encoder)\
          \ pipeline.\n  encoder: !new:speechbrain.nnet.containers.LengthsCapableSequential\n\
          \      input_shape: [null, null]\n+     enhance_features: !ref <enhance_model>\n\
          \      compute_features: !ref <compute_features>\n      normalize: !ref\
          \ <normalizer>\n      model: !ref <enc>\n```"
        updatedAt: '2022-07-21T16:22:46.354Z'
      numEdits: 1
      reactions: []
    id: 62d97d3051e8289052c0e16d
    type: comment
  author: pplantinga
  content: "I suppose it might also work to use `EncoderDecoderASR` inference class\
    \ with a custom YAML file. Try to copy the https://huggingface.co/speechbrain/asr-crdnn-rnnlm-librispeech/blob/main/hyperparams.yaml\n\
    \nAnd add the enhance model in 2 places:\n\n```\n+ enhance_model: # ... copy from\
    \ the file in this repo\n  ...\n  # We compose the inference (encoder) pipeline.\n\
    \  encoder: !new:speechbrain.nnet.containers.LengthsCapableSequential\n      input_shape:\
    \ [null, null]\n+     enhance_features: !ref <enhance_model>\n      compute_features:\
    \ !ref <compute_features>\n      normalize: !ref <normalizer>\n      model: !ref\
    \ <enc>\n```"
  created_at: 2022-07-21 15:22:08+00:00
  edited: true
  hidden: false
  id: 62d97d3051e8289052c0e16d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/459647888dbb5275ece9ce784101f569.svg
      fullname: .
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SemanticLeopard
      type: user
    createdAt: '2022-07-22T00:28:01.000Z'
    data:
      edited: true
      editors:
      - SemanticLeopard
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/459647888dbb5275ece9ce784101f569.svg
          fullname: .
          isHf: false
          isPro: false
          name: SemanticLeopard
          type: user
        html: '<p>First bit of code worked without issues. Thanks for that one! </p>

          '
        raw: 'First bit of code worked without issues. Thanks for that one! '
        updatedAt: '2022-07-22T05:42:39.829Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - pplantinga
    id: 62d9ef11c43067695ddb8b64
    type: comment
  author: SemanticLeopard
  content: 'First bit of code worked without issues. Thanks for that one! '
  created_at: 2022-07-21 23:28:01+00:00
  edited: true
  hidden: false
  id: 62d9ef11c43067695ddb8b64
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: speechbrain/mtl-mimic-voicebank
repo_type: model
status: open
target_branch: null
title: ASR Inference
