!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tristanchambers-bids
conflicting_files: null
created_at: 2023-04-10 16:27:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c40cef65c16508dafe9fdbf1146c8153.svg
      fullname: Tristan Chambers
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: tristanchambers-bids
      type: user
    createdAt: '2023-04-10T17:27:34.000Z'
    data:
      edited: false
      editors:
      - tristanchambers-bids
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c40cef65c16508dafe9fdbf1146c8153.svg
          fullname: Tristan Chambers
          isHf: false
          isPro: true
          name: tristanchambers-bids
          type: user
        html: '<p>I''m experimenting with using Flan-T5 for question answering from
          a given chunk of text. It is pretty reliable about giving decent answers
          but I would like to it cite the text from which it got its answer in an
          exact quote, so that I can highlight the text in a user interface, and also
          because LLMs can lie. I tried prepping the model with some few shot examples
          quoting the text in the answer but this did not change the behavior at all.
          I''ve had some limited success with this by adding "How do you know that?"
          or "Where did you learn that?" or "Where does it say that?" to the end of
          my question. I get slightly different results with each approach, and unfortunately
          sometimes adding this term reduces the accuracy of the response, or also
          sometimes it quotes text that is nearby the answer but that''s not correct.
          I''m wondering if I''m confusing it or using the wrong approach. Is there
          a best practice for getting Flan-T5 to produce a quote or quotes of the
          text from the given source? Is there a better place for me to ask this question,
          that''s more general to FLAN?</p>

          <p>I''m using this for mining a large dataset of transcribed interviews
          and narratives for evidence of people doing certain things. LLMs seems to
          work well for this task because there can be a lot of linguistic nuance,
          which traditional NLP methods can''t cope with to the same degree.</p>

          <p>Thanks!</p>

          '
        raw: "I'm experimenting with using Flan-T5 for question answering from a given\
          \ chunk of text. It is pretty reliable about giving decent answers but I\
          \ would like to it cite the text from which it got its answer in an exact\
          \ quote, so that I can highlight the text in a user interface, and also\
          \ because LLMs can lie. I tried prepping the model with some few shot examples\
          \ quoting the text in the answer but this did not change the behavior at\
          \ all. I've had some limited success with this by adding \"How do you know\
          \ that?\" or \"Where did you learn that?\" or \"Where does it say that?\"\
          \ to the end of my question. I get slightly different results with each\
          \ approach, and unfortunately sometimes adding this term reduces the accuracy\
          \ of the response, or also sometimes it quotes text that is nearby the answer\
          \ but that's not correct. I'm wondering if I'm confusing it or using the\
          \ wrong approach. Is there a best practice for getting Flan-T5 to produce\
          \ a quote or quotes of the text from the given source? Is there a better\
          \ place for me to ask this question, that's more general to FLAN?\r\n\r\n\
          I'm using this for mining a large dataset of transcribed interviews and\
          \ narratives for evidence of people doing certain things. LLMs seems to\
          \ work well for this task because there can be a lot of linguistic nuance,\
          \ which traditional NLP methods can't cope with to the same degree.\r\n\r\
          \nThanks!"
        updatedAt: '2023-04-10T17:27:34.494Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - ryderwishart
        - samarthagarwal23
    id: 64344706546e16f17a145d19
    type: comment
  author: tristanchambers-bids
  content: "I'm experimenting with using Flan-T5 for question answering from a given\
    \ chunk of text. It is pretty reliable about giving decent answers but I would\
    \ like to it cite the text from which it got its answer in an exact quote, so\
    \ that I can highlight the text in a user interface, and also because LLMs can\
    \ lie. I tried prepping the model with some few shot examples quoting the text\
    \ in the answer but this did not change the behavior at all. I've had some limited\
    \ success with this by adding \"How do you know that?\" or \"Where did you learn\
    \ that?\" or \"Where does it say that?\" to the end of my question. I get slightly\
    \ different results with each approach, and unfortunately sometimes adding this\
    \ term reduces the accuracy of the response, or also sometimes it quotes text\
    \ that is nearby the answer but that's not correct. I'm wondering if I'm confusing\
    \ it or using the wrong approach. Is there a best practice for getting Flan-T5\
    \ to produce a quote or quotes of the text from the given source? Is there a better\
    \ place for me to ask this question, that's more general to FLAN?\r\n\r\nI'm using\
    \ this for mining a large dataset of transcribed interviews and narratives for\
    \ evidence of people doing certain things. LLMs seems to work well for this task\
    \ because there can be a lot of linguistic nuance, which traditional NLP methods\
    \ can't cope with to the same degree.\r\n\r\nThanks!"
  created_at: 2023-04-10 16:27:34+00:00
  edited: false
  hidden: false
  id: 64344706546e16f17a145d19
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/501655ae6c2368f656ccc9064da10a39.svg
      fullname: SUN
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SUNM
      type: user
    createdAt: '2023-07-23T10:14:26.000Z'
    data:
      edited: false
      editors:
      - SUNM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9287552237510681
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/501655ae6c2368f656ccc9064da10a39.svg
          fullname: SUN
          isHf: false
          isPro: false
          name: SUNM
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;tristanchambers-bids&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/tristanchambers-bids\"\
          >@<span class=\"underline\">tristanchambers-bids</span></a></span>\n\n\t\
          </span></span> ,</p>\n<p>sorry, I want to use flan_t5 for questions and\
          \ answers. I have challenges and for each challenge the related solution\
          \ and no more contex. would you please guide me that how I can create an\
          \ appropriate prompt for that? Should be in one column and include both\
          \ question and answer or 2 different columns? I generate two different columns\
          \ like \"answer the following question: what is the solution for ...., another\
          \ column as the solution is.....<br>can I use seq2seq or T5conditionalgeneration\
          \ and Causal type? many thanks</p>\n"
        raw: "Hi @tristanchambers-bids ,\n\nsorry, I want to use flan_t5 for questions\
          \ and answers. I have challenges and for each challenge the related solution\
          \ and no more contex. would you please guide me that how I can create an\
          \ appropriate prompt for that? Should be in one column and include both\
          \ question and answer or 2 different columns? I generate two different columns\
          \ like \"answer the following question: what is the solution for ...., another\
          \ column as the solution is..... \ncan I use seq2seq or T5conditionalgeneration\
          \ and Causal type? many thanks"
        updatedAt: '2023-07-23T10:14:26.256Z'
      numEdits: 0
      reactions: []
    id: 64bcfd822e66dc7b8bb99eac
    type: comment
  author: SUNM
  content: "Hi @tristanchambers-bids ,\n\nsorry, I want to use flan_t5 for questions\
    \ and answers. I have challenges and for each challenge the related solution and\
    \ no more contex. would you please guide me that how I can create an appropriate\
    \ prompt for that? Should be in one column and include both question and answer\
    \ or 2 different columns? I generate two different columns like \"answer the following\
    \ question: what is the solution for ...., another column as the solution is.....\
    \ \ncan I use seq2seq or T5conditionalgeneration and Causal type? many thanks"
  created_at: 2023-07-23 09:14:26+00:00
  edited: false
  hidden: false
  id: 64bcfd822e66dc7b8bb99eac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c40cef65c16508dafe9fdbf1146c8153.svg
      fullname: Tristan Chambers
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: tristanchambers-bids
      type: user
    createdAt: '2023-07-24T12:21:48.000Z'
    data:
      edited: false
      editors:
      - tristanchambers-bids
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.969998836517334
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c40cef65c16508dafe9fdbf1146c8153.svg
          fullname: Tristan Chambers
          isHf: false
          isPro: true
          name: tristanchambers-bids
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;SUNM&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/SUNM\">@<span class=\"\
          underline\">SUNM</span></a></span>\n\n\t</span></span> your question seems\
          \ different from the topic of this thread, which is about quoting text from\
          \ the given context. Please start a new thread for your specific question\
          \ so that other people can see it and reply to it without confusing this\
          \ one. Thanks!</p>\n"
        raw: Hi @SUNM your question seems different from the topic of this thread,
          which is about quoting text from the given context. Please start a new thread
          for your specific question so that other people can see it and reply to
          it without confusing this one. Thanks!
        updatedAt: '2023-07-24T12:21:48.416Z'
      numEdits: 0
      reactions: []
    id: 64be6cdc8496ee0fb61a9d4f
    type: comment
  author: tristanchambers-bids
  content: Hi @SUNM your question seems different from the topic of this thread, which
    is about quoting text from the given context. Please start a new thread for your
    specific question so that other people can see it and reply to it without confusing
    this one. Thanks!
  created_at: 2023-07-24 11:21:48+00:00
  edited: false
  hidden: false
  id: 64be6cdc8496ee0fb61a9d4f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c40cef65c16508dafe9fdbf1146c8153.svg
      fullname: Tristan Chambers
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: tristanchambers-bids
      type: user
    createdAt: '2023-07-24T12:28:14.000Z'
    data:
      edited: false
      editors:
      - tristanchambers-bids
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9774264097213745
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c40cef65c16508dafe9fdbf1146c8153.svg
          fullname: Tristan Chambers
          isHf: false
          isPro: true
          name: tristanchambers-bids
          type: user
        html: '<p>Since this conversation has been quiet, I''ll share what else I
          have learned on my own about this. Lately I''ve been having success using
          the phrase "quote the text that proves it". This has been working pretty
          reliably for me. However, when compounded with other directives in a single
          prompt the model can get confused. E.g. "Was someone at the store at 3pm?
          Quote the text that proves it. Say unknown if you don''t know." Just overwhelms
          the model and the quality of the responses is very poor, especially when
          an answer can''t actually be found in the given text. I have resorted to
          a multistep sequence of prompts, first with the bare question "Was someone
          at the store at 3pm? Say unknown if you don''t know.", then if I get a good
          quality answer I reprompt including the clause "Quote the text that proves
          it." This seems to work pretty well for my situation, but it''s far from
          ideal.</p>

          '
        raw: Since this conversation has been quiet, I'll share what else I have learned
          on my own about this. Lately I've been having success using the phrase "quote
          the text that proves it". This has been working pretty reliably for me.
          However, when compounded with other directives in a single prompt the model
          can get confused. E.g. "Was someone at the store at 3pm? Quote the text
          that proves it. Say unknown if you don't know." Just overwhelms the model
          and the quality of the responses is very poor, especially when an answer
          can't actually be found in the given text. I have resorted to a multistep
          sequence of prompts, first with the bare question "Was someone at the store
          at 3pm? Say unknown if you don't know.", then if I get a good quality answer
          I reprompt including the clause "Quote the text that proves it." This seems
          to work pretty well for my situation, but it's far from ideal.
        updatedAt: '2023-07-24T12:28:14.861Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - rjtmehta99
    id: 64be6e5ee38420aabaefa6a8
    type: comment
  author: tristanchambers-bids
  content: Since this conversation has been quiet, I'll share what else I have learned
    on my own about this. Lately I've been having success using the phrase "quote
    the text that proves it". This has been working pretty reliably for me. However,
    when compounded with other directives in a single prompt the model can get confused.
    E.g. "Was someone at the store at 3pm? Quote the text that proves it. Say unknown
    if you don't know." Just overwhelms the model and the quality of the responses
    is very poor, especially when an answer can't actually be found in the given text.
    I have resorted to a multistep sequence of prompts, first with the bare question
    "Was someone at the store at 3pm? Say unknown if you don't know.", then if I get
    a good quality answer I reprompt including the clause "Quote the text that proves
    it." This seems to work pretty well for my situation, but it's far from ideal.
  created_at: 2023-07-24 11:28:14+00:00
  edited: false
  hidden: false
  id: 64be6e5ee38420aabaefa6a8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 42
repo_id: google/flan-t5-xxl
repo_type: model
status: open
target_branch: null
title: Quoting source from given text for Q&A prompt
