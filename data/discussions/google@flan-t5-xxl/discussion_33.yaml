!!python/object:huggingface_hub.community.DiscussionWithDetails
author: michaelroyzen
conflicting_files: null
created_at: 2023-02-23 22:04:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624223414317-noauth.jpeg?w=200&h=200&f=face
      fullname: Michael Royzen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: michaelroyzen
      type: user
    createdAt: '2023-02-23T22:04:08.000Z'
    data:
      edited: true
      editors:
      - michaelroyzen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624223414317-noauth.jpeg?w=200&h=200&f=face
          fullname: Michael Royzen
          isHf: false
          isPro: true
          name: michaelroyzen
          type: user
        html: "<p>It seems that the Flan-T5 tokenizer can't handle Chinese (despite\
          \ being advertised as such on the model card) as well as many programming-related\
          \ tokens such as \"{\" or \"\\n\" or \"\\t\". How is this the case if Flan-T5\
          \ was truly fine-tuned on coding datasets as described in the paper? Is\
          \ the publicly-available tokenizer flawed, or was the entire fine-tuning\
          \ procedure flawed?</p>\n<p><span data-props=\"{&quot;user&quot;:&quot;ybelkada&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ybelkada\"\
          >@<span class=\"underline\">ybelkada</span></a></span>\n\n\t</span></span></p>\n"
        raw: 'It seems that the Flan-T5 tokenizer can''t handle Chinese (despite being
          advertised as such on the model card) as well as many programming-related
          tokens such as "{" or "\n" or "\t". How is this the case if Flan-T5 was
          truly fine-tuned on coding datasets as described in the paper? Is the publicly-available
          tokenizer flawed, or was the entire fine-tuning procedure flawed?


          @ybelkada'
        updatedAt: '2023-02-23T22:04:24.374Z'
      numEdits: 1
      reactions:
      - count: 9
        reaction: "\U0001F44D"
        users:
        - wunein
        - blazing
        - mrtan
        - xin1111
        - XXXMMMBBB
        - semindan
        - HuaJuan
        - noobmldude
        - ysdede
    id: 63f7e2d849569335b6780bef
    type: comment
  author: michaelroyzen
  content: 'It seems that the Flan-T5 tokenizer can''t handle Chinese (despite being
    advertised as such on the model card) as well as many programming-related tokens
    such as "{" or "\n" or "\t". How is this the case if Flan-T5 was truly fine-tuned
    on coding datasets as described in the paper? Is the publicly-available tokenizer
    flawed, or was the entire fine-tuning procedure flawed?


    @ybelkada'
  created_at: 2023-02-23 22:04:08+00:00
  edited: true
  hidden: false
  id: 63f7e2d849569335b6780bef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a1cf1ef1fd442c36ed65c68e51919fed.svg
      fullname: Shayne Longpre
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Shayne
      type: user
    createdAt: '2023-04-05T18:12:23.000Z'
    data:
      edited: false
      editors:
      - Shayne
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a1cf1ef1fd442c36ed65c68e51919fed.svg
          fullname: Shayne Longpre
          isHf: false
          isPro: false
          name: Shayne
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;michaelroyzen&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/michaelroyzen\"\
          >@<span class=\"underline\">michaelroyzen</span></a></span>\n\n\t</span></span>\
          \ Flan-T5 uses the T5 tokenizer, which is English-only and not well suited\
          \ to coding tasks. We do include multilingual and coding tasks in the Flan\
          \ Collection, which plays well with multilingual models and appropriate\
          \ tokenizers, but of course may not overcome the limitations of the T5 tokenizer.\
          \ With limited experiments we did not see any evidence that including coding\
          \ or multilingual tasks hurt Flan-T5 for English held-in and held-out evaluation\
          \ tasks (not including program synthesis eval), but may even have helped\
          \ by adding task diversity.</p>\n<p>If you'd like to do multilingual or\
          \ coding tasks we do recommend applying FLAN tuning on top of a more appropriate\
          \ model/tokenizer, and even up-sample the data sources you're targeting.</p>\n"
        raw: '@michaelroyzen Flan-T5 uses the T5 tokenizer, which is English-only
          and not well suited to coding tasks. We do include multilingual and coding
          tasks in the Flan Collection, which plays well with multilingual models
          and appropriate tokenizers, but of course may not overcome the limitations
          of the T5 tokenizer. With limited experiments we did not see any evidence
          that including coding or multilingual tasks hurt Flan-T5 for English held-in
          and held-out evaluation tasks (not including program synthesis eval), but
          may even have helped by adding task diversity.


          If you''d like to do multilingual or coding tasks we do recommend applying
          FLAN tuning on top of a more appropriate model/tokenizer, and even up-sample
          the data sources you''re targeting.'
        updatedAt: '2023-04-05T18:12:23.207Z'
      numEdits: 0
      reactions: []
    id: 642dba07baf943d5db44cbe6
    type: comment
  author: Shayne
  content: '@michaelroyzen Flan-T5 uses the T5 tokenizer, which is English-only and
    not well suited to coding tasks. We do include multilingual and coding tasks in
    the Flan Collection, which plays well with multilingual models and appropriate
    tokenizers, but of course may not overcome the limitations of the T5 tokenizer.
    With limited experiments we did not see any evidence that including coding or
    multilingual tasks hurt Flan-T5 for English held-in and held-out evaluation tasks
    (not including program synthesis eval), but may even have helped by adding task
    diversity.


    If you''d like to do multilingual or coding tasks we do recommend applying FLAN
    tuning on top of a more appropriate model/tokenizer, and even up-sample the data
    sources you''re targeting.'
  created_at: 2023-04-05 17:12:23+00:00
  edited: false
  hidden: false
  id: 642dba07baf943d5db44cbe6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 33
repo_id: google/flan-t5-xxl
repo_type: model
status: open
target_branch: null
title: Flan-T5 tokenizer supports neither Chinese nor many code-related tokens despite
  being advertised as such
