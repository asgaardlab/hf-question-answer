!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kabalanresearch
conflicting_files: null
created_at: 2022-10-23 11:56:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e1c2179aee86675afea981a22b45c29d.svg
      fullname: Fede
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kabalanresearch
      type: user
    createdAt: '2022-10-23T12:56:11.000Z'
    data:
      edited: false
      editors:
      - kabalanresearch
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e1c2179aee86675afea981a22b45c29d.svg
          fullname: Fede
          isHf: false
          isPro: false
          name: kabalanresearch
          type: user
        html: '<p>Im trying to run the model using the 8 bit library</p>

          <p>model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-xxl",
          device_map="auto",torch_dtype=torch.bfloat16, load_in_8bit=True)</p>

          <p>the model gets loaded and returns output, but the return value is some
          kind of gibberish,<br>did some one have success with the 8 bit library ?</p>

          '
        raw: "Im trying to run the model using the 8 bit library\r\n\r\nmodel = T5ForConditionalGeneration.from_pretrained(\"\
          google/flan-t5-xxl\", device_map=\"auto\",torch_dtype=torch.bfloat16, load_in_8bit=True)\r\
          \n\r\nthe model gets loaded and returns output, but the return value is\
          \ some kind of gibberish, \r\ndid some one have success with the 8 bit library\
          \ ?\r\n\r\n"
        updatedAt: '2022-10-23T12:56:11.545Z'
      numEdits: 0
      reactions: []
    id: 635539eb70babb7a4a5614d5
    type: comment
  author: kabalanresearch
  content: "Im trying to run the model using the 8 bit library\r\n\r\nmodel = T5ForConditionalGeneration.from_pretrained(\"\
    google/flan-t5-xxl\", device_map=\"auto\",torch_dtype=torch.bfloat16, load_in_8bit=True)\r\
    \n\r\nthe model gets loaded and returns output, but the return value is some kind\
    \ of gibberish, \r\ndid some one have success with the 8 bit library ?\r\n\r\n"
  created_at: 2022-10-23 11:56:11+00:00
  edited: false
  hidden: false
  id: 635539eb70babb7a4a5614d5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2022-10-24T08:33:20.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>This is expected as <code>float16</code> does not work either on
          this model. We are investigating this!</p>

          '
        raw: This is expected as `float16` does not work either on this model. We
          are investigating this!
        updatedAt: '2022-10-24T08:33:20.914Z'
      numEdits: 0
      reactions: []
    id: 63564dd0cf7c58d844b318c1
    type: comment
  author: ArthurZ
  content: This is expected as `float16` does not work either on this model. We are
    investigating this!
  created_at: 2022-10-24 07:33:20+00:00
  edited: false
  hidden: false
  id: 63564dd0cf7c58d844b318c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2022-10-24T08:34:31.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: '<p>Also, note that this happens only for <code>xxl</code> model, for
          other models the <code>int8</code> quantization works as expected</p>

          '
        raw: Also, note that this happens only for `xxl` model, for other models the
          `int8` quantization works as expected
        updatedAt: '2022-10-24T08:34:31.712Z'
      numEdits: 0
      reactions: []
    id: 63564e171c93c1ef4e9f79f0
    type: comment
  author: ybelkada
  content: Also, note that this happens only for `xxl` model, for other models the
    `int8` quantization works as expected
  created_at: 2022-10-24 07:34:31+00:00
  edited: false
  hidden: false
  id: 63564e171c93c1ef4e9f79f0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1639773384591-5f353bb37e58354338621655.jpeg?w=200&h=200&f=face
      fullname: Nicholas Broad
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: true
      name: nbroad
      type: user
    createdAt: '2022-10-24T13:06:42.000Z'
    data:
      edited: false
      editors:
      - nbroad
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1639773384591-5f353bb37e58354338621655.jpeg?w=200&h=200&f=face
          fullname: Nicholas Broad
          isHf: true
          isPro: true
          name: nbroad
          type: user
        html: '<p>Probably related to this <a rel="nofollow" href="https://discuss.huggingface.co/t/mixed-precision-for-bfloat16-pretrained-models/5315">https://discuss.huggingface.co/t/mixed-precision-for-bfloat16-pretrained-models/5315</a></p>

          '
        raw: Probably related to this https://discuss.huggingface.co/t/mixed-precision-for-bfloat16-pretrained-models/5315
        updatedAt: '2022-10-24T13:06:42.662Z'
      numEdits: 0
      reactions: []
    id: 63568de2f31dac014b5eaa7b
    type: comment
  author: nbroad
  content: Probably related to this https://discuss.huggingface.co/t/mixed-precision-for-bfloat16-pretrained-models/5315
  created_at: 2022-10-24 12:06:42+00:00
  edited: false
  hidden: false
  id: 63568de2f31dac014b5eaa7b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5e4318d616b09a31220980d6/24rMJ_vPh3gW9ZEmj64xr.png?w=200&h=200&f=face
      fullname: Manuel Romero
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: mrm8488
      type: user
    createdAt: '2022-10-25T12:30:02.000Z'
    data:
      edited: false
      editors:
      - mrm8488
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5e4318d616b09a31220980d6/24rMJ_vPh3gW9ZEmj64xr.png?w=200&h=200&f=face
          fullname: Manuel Romero
          isHf: false
          isPro: true
          name: mrm8488
          type: user
        html: '<p>I tested the <code>xl</code> one using <code>float16</code>and <code>int8</code>and
          it does not work as expected (gibberish). However, it works like a charm
          in <code>fp32 </code></p>

          '
        raw: I tested the `xl` one using `float16`and `int8`and it does not work as
          expected (gibberish). However, it works like a charm in `fp32 `
        updatedAt: '2022-10-25T12:30:02.906Z'
      numEdits: 0
      reactions: []
    id: 6357d6cab8e7a95943841e44
    type: comment
  author: mrm8488
  content: I tested the `xl` one using `float16`and `int8`and it does not work as
    expected (gibberish). However, it works like a charm in `fp32 `
  created_at: 2022-10-25 11:30:02+00:00
  edited: false
  hidden: false
  id: 6357d6cab8e7a95943841e44
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e1c2179aee86675afea981a22b45c29d.svg
      fullname: Fede
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kabalanresearch
      type: user
    createdAt: '2022-10-25T19:03:35.000Z'
    data:
      edited: false
      editors:
      - kabalanresearch
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e1c2179aee86675afea981a22b45c29d.svg
          fullname: Fede
          isHf: false
          isPro: false
          name: kabalanresearch
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mrm8488&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mrm8488\">@<span class=\"\
          underline\">mrm8488</span></a></span>\n\n\t</span></span>  can you pls post\
          \ your model config</p>\n"
        raw: '@mrm8488  can you pls post your model config'
        updatedAt: '2022-10-25T19:03:35.903Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - ParkerBurchett
    id: 635833070bdd366489ba8668
    type: comment
  author: kabalanresearch
  content: '@mrm8488  can you pls post your model config'
  created_at: 2022-10-25 18:03:35+00:00
  edited: false
  hidden: false
  id: 635833070bdd366489ba8668
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5e4318d616b09a31220980d6/24rMJ_vPh3gW9ZEmj64xr.png?w=200&h=200&f=face
      fullname: Manuel Romero
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: mrm8488
      type: user
    createdAt: '2022-11-03T15:21:09.000Z'
    data:
      edited: false
      editors:
      - mrm8488
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5e4318d616b09a31220980d6/24rMJ_vPh3gW9ZEmj64xr.png?w=200&h=200&f=face
          fullname: Manuel Romero
          isHf: false
          isPro: true
          name: mrm8488
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;mrm8488&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/mrm8488\"\
          >@<span class=\"underline\">mrm8488</span></a></span>\n\n\t</span></span>\
          \  can you pls post your model config</p>\n</blockquote>\n<p>It is the config\
          \ you can find in the repo: <a href=\"https://huggingface.co/google/flan-t5-xl/blob/main/config.json\"\
          >https://huggingface.co/google/flan-t5-xl/blob/main/config.json</a></p>\n"
        raw: '> @mrm8488  can you pls post your model config


          It is the config you can find in the repo: https://huggingface.co/google/flan-t5-xl/blob/main/config.json'
        updatedAt: '2022-11-03T15:21:09.342Z'
      numEdits: 0
      reactions: []
    id: 6363dc652bf7a2c9eb5483dc
    type: comment
  author: mrm8488
  content: '> @mrm8488  can you pls post your model config


    It is the config you can find in the repo: https://huggingface.co/google/flan-t5-xl/blob/main/config.json'
  created_at: 2022-11-03 14:21:09+00:00
  edited: false
  hidden: false
  id: 6363dc652bf7a2c9eb5483dc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fd3301e6209288bfdb82ee12e37fba05.svg
      fullname: neo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: i-am-neo
      type: user
    createdAt: '2023-04-18T18:52:51.000Z'
    data:
      edited: false
      editors:
      - i-am-neo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fd3301e6209288bfdb82ee12e37fba05.svg
          fullname: neo
          isHf: false
          isPro: false
          name: i-am-neo
          type: user
        html: '<p>Anyone here able to run Flan-T5-XL on colab?  I tried 8bit and got
          junk results.</p>

          '
        raw: Anyone here able to run Flan-T5-XL on colab?  I tried 8bit and got junk
          results.
        updatedAt: '2023-04-18T18:52:51.790Z'
      numEdits: 0
      reactions: []
    id: 643ee703f2ed3bc5c06347d1
    type: comment
  author: i-am-neo
  content: Anyone here able to run Flan-T5-XL on colab?  I tried 8bit and got junk
    results.
  created_at: 2023-04-18 17:52:51+00:00
  edited: false
  hidden: false
  id: 643ee703f2ed3bc5c06347d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-10-11T09:29:13.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7320282459259033
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: '<p>can you try with the recent release of transformers <code>pip install
          -U transformers</code> + use 4bit instead (just pass <code>load_in_4bit=True</code>)</p>

          '
        raw: can you try with the recent release of transformers `pip install -U transformers`
          + use 4bit instead (just pass `load_in_4bit=True`)
        updatedAt: '2023-10-11T09:29:13.190Z'
      numEdits: 0
      reactions: []
    id: 65266ae95567b6fa61599c72
    type: comment
  author: ybelkada
  content: can you try with the recent release of transformers `pip install -U transformers`
    + use 4bit instead (just pass `load_in_4bit=True`)
  created_at: 2023-10-11 08:29:13+00:00
  edited: false
  hidden: false
  id: 65266ae95567b6fa61599c72
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: google/flan-t5-xxl
repo_type: model
status: open
target_branch: null
title: 'run model in colab using 8 bit '
