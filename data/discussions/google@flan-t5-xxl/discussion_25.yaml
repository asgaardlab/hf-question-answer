!!python/object:huggingface_hub.community.DiscussionWithDetails
author: pradeepmohans
conflicting_files: null
created_at: 2023-02-01 22:38:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4f374c6d747cfc3a1d6eda8b9247fb64.svg
      fullname: Pradeep Mohan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: pradeepmohans
      type: user
    createdAt: '2023-02-01T22:38:33.000Z'
    data:
      edited: false
      editors:
      - pradeepmohans
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4f374c6d747cfc3a1d6eda8b9247fb64.svg
          fullname: Pradeep Mohan
          isHf: false
          isPro: true
          name: pradeepmohans
          type: user
        html: '<p>when I run this:</p>

          <p>from transformers import T5Tokenizer, T5ForConditionalGeneration</p>

          <p>tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-xxl")<br>model
          = T5ForConditionalGeneration.from_pretrained("google/flan-t5-xxl")</p>

          <p>input_text = "translate English to German: How old are you?"<br>input_ids
          = tokenizer(input_text, return_tensors="pt").input_ids</p>

          <p>outputs = model.generate(input_ids)<br>print(tokenizer.decode(outputs[0]))</p>

          <p>I get the following error: </p>

          <hr>

          <p>EntryNotFoundError                        Traceback (most recent call
          last)<br>/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py
          in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)<br>   1357                 #
          Load from URL or cache if already cached<br>-&gt; 1358                 resolved_archive_file
          = cached_path(<br>   1359                     archive_file,</p>

          <p>4 frames<br>EntryNotFoundError: 404 Client Error: Entry Not Found for
          url: <a href="https://huggingface.co/google/flan-t5-xxl/resolve/main/pytorch_model.bin">https://huggingface.co/google/flan-t5-xxl/resolve/main/pytorch_model.bin</a></p>

          <p>During handling of the above exception, another exception occurred:</p>

          <p>OSError                                   Traceback (most recent call
          last)<br>/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py
          in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)<br>   1401                         )<br>   1402                     else:<br>-&gt;
          1403                         raise EnvironmentError(<br>   1404                             f"{pretrained_model_name_or_path}
          does not appear to have a file named {WEIGHTS_NAME}, "<br>   1405                             f"{TF2_WEIGHTS_NAME},
          {TF_WEIGHTS_NAME} or {FLAX_WEIGHTS_NAME}."</p>

          <p>OSError: google/flan-t5-xxl does not appear to have a file named pytorch_model.bin,
          tf_model.h5, model.ckpt or flax_model.msgpack.</p>

          '
        raw: "when I run this:\r\n\r\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\r\
          \n\r\ntokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xxl\")\r\n\
          model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xxl\"\
          )\r\n\r\ninput_text = \"translate English to German: How old are you?\"\r\
          \ninput_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\r\n\
          \r\noutputs = model.generate(input_ids)\r\nprint(tokenizer.decode(outputs[0]))\r\
          \n\r\nI get the following error: \r\n\r\n---------------------------------------------------------------------------\r\
          \nEntryNotFoundError                        Traceback (most recent call\
          \ last)\r\n/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)\r\
          \n   1357                 # Load from URL or cache if already cached\r\n\
          -> 1358                 resolved_archive_file = cached_path(\r\n   1359\
          \                     archive_file,\r\n\r\n4 frames\r\nEntryNotFoundError:\
          \ 404 Client Error: Entry Not Found for url: https://huggingface.co/google/flan-t5-xxl/resolve/main/pytorch_model.bin\r\
          \n\r\nDuring handling of the above exception, another exception occurred:\r\
          \n\r\nOSError                                   Traceback (most recent call\
          \ last)\r\n/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)\r\
          \n   1401                         )\r\n   1402                     else:\r\
          \n-> 1403                         raise EnvironmentError(\r\n   1404   \
          \                          f\"{pretrained_model_name_or_path} does not appear\
          \ to have a file named {WEIGHTS_NAME}, \"\r\n   1405                   \
          \          f\"{TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME} or {FLAX_WEIGHTS_NAME}.\"\
          \r\n\r\nOSError: google/flan-t5-xxl does not appear to have a file named\
          \ pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack."
        updatedAt: '2023-02-01T22:38:33.254Z'
      numEdits: 0
      reactions: []
    id: 63dae9e90cc3bc12bc098667
    type: comment
  author: pradeepmohans
  content: "when I run this:\r\n\r\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\r\
    \n\r\ntokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xxl\")\r\nmodel\
    \ = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xxl\")\r\n\r\n\
    input_text = \"translate English to German: How old are you?\"\r\ninput_ids =\
    \ tokenizer(input_text, return_tensors=\"pt\").input_ids\r\n\r\noutputs = model.generate(input_ids)\r\
    \nprint(tokenizer.decode(outputs[0]))\r\n\r\nI get the following error: \r\n\r\
    \n---------------------------------------------------------------------------\r\
    \nEntryNotFoundError                        Traceback (most recent call last)\r\
    \n/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py in from_pretrained(cls,\
    \ pretrained_model_name_or_path, *model_args, **kwargs)\r\n   1357           \
    \      # Load from URL or cache if already cached\r\n-> 1358                 resolved_archive_file\
    \ = cached_path(\r\n   1359                     archive_file,\r\n\r\n4 frames\r\
    \nEntryNotFoundError: 404 Client Error: Entry Not Found for url: https://huggingface.co/google/flan-t5-xxl/resolve/main/pytorch_model.bin\r\
    \n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\
    \nOSError                                   Traceback (most recent call last)\r\
    \n/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py in from_pretrained(cls,\
    \ pretrained_model_name_or_path, *model_args, **kwargs)\r\n   1401           \
    \              )\r\n   1402                     else:\r\n-> 1403             \
    \            raise EnvironmentError(\r\n   1404                             f\"\
    {pretrained_model_name_or_path} does not appear to have a file named {WEIGHTS_NAME},\
    \ \"\r\n   1405                             f\"{TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME}\
    \ or {FLAX_WEIGHTS_NAME}.\"\r\n\r\nOSError: google/flan-t5-xxl does not appear\
    \ to have a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack."
  created_at: 2023-02-01 22:38:33+00:00
  edited: false
  hidden: false
  id: 63dae9e90cc3bc12bc098667
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-02-02T08:20:24.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;pradeepmohans&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/pradeepmohans\"\
          >@<span class=\"underline\">pradeepmohans</span></a></span>\n\n\t</span></span><br>Thanks\
          \ for the issue,<br>please use <code>transformers&gt;=4.18.0</code> in order\
          \ to load large models that saves sharded checkpoints<br>Thanks!</p>\n"
        raw: "Hi @pradeepmohans \nThanks for the issue, \nplease use `transformers>=4.18.0`\
          \ in order to load large models that saves sharded checkpoints\nThanks!"
        updatedAt: '2023-02-02T08:20:24.260Z'
      numEdits: 0
      reactions: []
    id: 63db7248ef6ecf800ebb2d11
    type: comment
  author: ybelkada
  content: "Hi @pradeepmohans \nThanks for the issue, \nplease use `transformers>=4.18.0`\
    \ in order to load large models that saves sharded checkpoints\nThanks!"
  created_at: 2023-02-02 08:20:24+00:00
  edited: false
  hidden: false
  id: 63db7248ef6ecf800ebb2d11
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 25
repo_id: google/flan-t5-xxl
repo_type: model
status: open
target_branch: null
title: file not found error
