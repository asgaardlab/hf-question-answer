!!python/object:huggingface_hub.community.DiscussionWithDetails
author: haizamir
conflicting_files: null
created_at: 2023-10-02 18:41:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d37a88b15043181b276d919506c4315b.svg
      fullname: Hai Zamir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: haizamir
      type: user
    createdAt: '2023-10-02T19:41:09.000Z'
    data:
      edited: false
      editors:
      - haizamir
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6427028775215149
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d37a88b15043181b276d919506c4315b.svg
          fullname: Hai Zamir
          isHf: false
          isPro: false
          name: haizamir
          type: user
        html: '<p>Hi Huggingface community,</p>

          <h2 id="i-deploy-googleflan-t5-xxl-inference-in-aws-sagemaker-exactly-as-the-deploy-instructions-for-sagemaker-in-the-model-page">I
          deploy google/flan-t5-xxl inference in AWS Sagemaker exactly as the Deploy
          Instructions for Sagemaker in the model page.</h2>

          <h1 id="hub-model-configuration-httpshuggingfacecomodels">Hub Model configuration.
          <a href="https://huggingface.co/models">https://huggingface.co/models</a></h1>

          <p>hub = {<br>    ''HF_MODEL_ID'':''google/flan-t5-xxl'',<br>    ''SM_NUM_GPUS'':
          json.dumps(4)<br>}</p>

          <h1 id="create-hugging-face-model-class">create Hugging Face Model Class</h1>

          <p>huggingface_model = HuggingFaceModel(<br>    image_uri=get_huggingface_llm_image_uri("huggingface",version="1.0.3"),<br>    env=hub,<br>    role=role,<br>)</p>

          <h1 id="deploy-model-to-sagemaker-inference">deploy model to SageMaker Inference</h1>

          <p>predictor = huggingface_model.deploy(<br>    initial_instance_count=1,<br>    instance_type="ml.g5.12xlarge",<br>    container_startup_health_check_timeout=300,<br>)</p>

          <hr>

          <p>In parallel, I deploy the AWS Jumpstart flan-t5-xxl and compare the answers.<br>All
          the answers from huggingface ''google/flan-t5-xxl'' were truncated compared
          to the AWS jumpstart flan-t5-xxl, even when setting the hyperparameter max_length
          to 300.<br>Same behavior for ''google/flan-t5-large/XL''.</p>

          <p>Please advise what I miss here?</p>

          <p>Thanks,<br>Hai</p>

          '
        raw: "Hi Huggingface community,\r\n\r\nI deploy google/flan-t5-xxl inference\
          \ in AWS Sagemaker exactly as the Deploy Instructions for Sagemaker in the\
          \ model page.\r\n-------------------------------------------------------------------------------------\r\
          \n# Hub Model configuration. https://huggingface.co/models\r\nhub = {\r\n\
          \    'HF_MODEL_ID':'google/flan-t5-xxl',\r\n    'SM_NUM_GPUS': json.dumps(4)\r\
          \n}\r\n# create Hugging Face Model Class\r\nhuggingface_model = HuggingFaceModel(\r\
          \n    image_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"\
          1.0.3\"),\r\n    env=hub,\r\n    role=role,\r\n)\r\n# deploy model to SageMaker\
          \ Inference\r\npredictor = huggingface_model.deploy(\r\n    initial_instance_count=1,\r\
          \n    instance_type=\"ml.g5.12xlarge\",\r\n    container_startup_health_check_timeout=300,\r\
          \n)\r\n-------------------------------------------------------------------------------------\r\
          \nIn parallel, I deploy the AWS Jumpstart flan-t5-xxl and compare the answers.\r\
          \nAll the answers from huggingface 'google/flan-t5-xxl' were truncated compared\
          \ to the AWS jumpstart flan-t5-xxl, even when setting the hyperparameter\
          \ max_length to 300.\r\nSame behavior for 'google/flan-t5-large/XL'.\r\n\
          \r\nPlease advise what I miss here?\r\n\r\nThanks,\r\nHai\r\n\r\n"
        updatedAt: '2023-10-02T19:41:09.859Z'
      numEdits: 0
      reactions: []
    id: 651b1cd57e69df7dc3c902dd
    type: comment
  author: haizamir
  content: "Hi Huggingface community,\r\n\r\nI deploy google/flan-t5-xxl inference\
    \ in AWS Sagemaker exactly as the Deploy Instructions for Sagemaker in the model\
    \ page.\r\n-------------------------------------------------------------------------------------\r\
    \n# Hub Model configuration. https://huggingface.co/models\r\nhub = {\r\n    'HF_MODEL_ID':'google/flan-t5-xxl',\r\
    \n    'SM_NUM_GPUS': json.dumps(4)\r\n}\r\n# create Hugging Face Model Class\r\
    \nhuggingface_model = HuggingFaceModel(\r\n    image_uri=get_huggingface_llm_image_uri(\"\
    huggingface\",version=\"1.0.3\"),\r\n    env=hub,\r\n    role=role,\r\n)\r\n#\
    \ deploy model to SageMaker Inference\r\npredictor = huggingface_model.deploy(\r\
    \n    initial_instance_count=1,\r\n    instance_type=\"ml.g5.12xlarge\",\r\n \
    \   container_startup_health_check_timeout=300,\r\n)\r\n-------------------------------------------------------------------------------------\r\
    \nIn parallel, I deploy the AWS Jumpstart flan-t5-xxl and compare the answers.\r\
    \nAll the answers from huggingface 'google/flan-t5-xxl' were truncated compared\
    \ to the AWS jumpstart flan-t5-xxl, even when setting the hyperparameter max_length\
    \ to 300.\r\nSame behavior for 'google/flan-t5-large/XL'.\r\n\r\nPlease advise\
    \ what I miss here?\r\n\r\nThanks,\r\nHai\r\n\r\n"
  created_at: 2023-10-02 18:41:09+00:00
  edited: false
  hidden: false
  id: 651b1cd57e69df7dc3c902dd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
      fullname: Lysandre
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lysandre
      type: user
    createdAt: '2023-10-03T09:13:27.000Z'
    data:
      edited: false
      editors:
      - lysandre
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8682617545127869
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
          fullname: Lysandre
          isHf: true
          isPro: false
          name: lysandre
          type: user
        html: "<p>Maybe of interest to <span data-props=\"{&quot;user&quot;:&quot;philschmid&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/philschmid\"\
          >@<span class=\"underline\">philschmid</span></a></span>\n\n\t</span></span></p>\n"
        raw: Maybe of interest to @philschmid
        updatedAt: '2023-10-03T09:13:27.203Z'
      numEdits: 0
      reactions: []
    id: 651bdb373fa6c4e1828d119a
    type: comment
  author: lysandre
  content: Maybe of interest to @philschmid
  created_at: 2023-10-03 08:13:27+00:00
  edited: false
  hidden: false
  id: 651bdb373fa6c4e1828d119a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png?w=200&h=200&f=face
      fullname: Philipp Schmid
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: philschmid
      type: user
    createdAt: '2023-10-04T08:18:21.000Z'
    data:
      edited: false
      editors:
      - philschmid
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6380513906478882
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png?w=200&h=200&f=face
          fullname: Philipp Schmid
          isHf: true
          isPro: false
          name: philschmid
          type: user
        html: '<p>You can customize the lenght by adding parameters in the request,
          see: <a href="https://huggingface.co/blog/sagemaker-huggingface-llm#4-run-inference-and-chat-with-our-model">https://huggingface.co/blog/sagemaker-huggingface-llm#4-run-inference-and-chat-with-our-model</a></p>

          '
        raw: 'You can customize the lenght by adding parameters in the request, see:
          https://huggingface.co/blog/sagemaker-huggingface-llm#4-run-inference-and-chat-with-our-model'
        updatedAt: '2023-10-04T08:18:21.208Z'
      numEdits: 0
      reactions: []
    id: 651d1fcd89f39456c53ec63b
    type: comment
  author: philschmid
  content: 'You can customize the lenght by adding parameters in the request, see:
    https://huggingface.co/blog/sagemaker-huggingface-llm#4-run-inference-and-chat-with-our-model'
  created_at: 2023-10-04 07:18:21+00:00
  edited: false
  hidden: false
  id: 651d1fcd89f39456c53ec63b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d37a88b15043181b276d919506c4315b.svg
      fullname: Hai Zamir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: haizamir
      type: user
    createdAt: '2023-10-04T08:51:58.000Z'
    data:
      edited: false
      editors:
      - haizamir
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9297232031822205
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d37a88b15043181b276d919506c4315b.svg
          fullname: Hai Zamir
          isHf: false
          isPro: false
          name: haizamir
          type: user
        html: "<p>Thank you very much <span data-props=\"{&quot;user&quot;:&quot;philschmid&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/philschmid\"\
          >@<span class=\"underline\">philschmid</span></a></span>\n\n\t</span></span>\
          \ and <span data-props=\"{&quot;user&quot;:&quot;lysandre&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/lysandre\">@<span class=\"\
          underline\">lysandre</span></a></span>\n\n\t</span></span><br>We will try\
          \ to set the max_new_tokens and test it.</p>\n<p>Thanks!!!!</p>\n"
        raw: 'Thank you very much @philschmid and @lysandre

          We will try to set the max_new_tokens and test it.


          Thanks!!!!'
        updatedAt: '2023-10-04T08:51:58.701Z'
      numEdits: 0
      reactions: []
    id: 651d27ae1e6a7ff79f9f17c2
    type: comment
  author: haizamir
  content: 'Thank you very much @philschmid and @lysandre

    We will try to set the max_new_tokens and test it.


    Thanks!!!!'
  created_at: 2023-10-04 07:51:58+00:00
  edited: false
  hidden: false
  id: 651d27ae1e6a7ff79f9f17c2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 62
repo_id: google/flan-t5-xxl
repo_type: model
status: open
target_branch: null
title: While try to using google/flan-t5-xxl inference deploy in AWS sagemaker. Answers
  is truncated.
