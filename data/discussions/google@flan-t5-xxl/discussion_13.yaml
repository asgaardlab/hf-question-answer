!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Stromal
conflicting_files: null
created_at: 2022-12-09 12:20:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1643413963271-noauth.jpeg?w=200&h=200&f=face
      fullname: Peter Simon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Stromal
      type: user
    createdAt: '2022-12-09T12:20:08.000Z'
    data:
      edited: false
      editors:
      - Stromal
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1643413963271-noauth.jpeg?w=200&h=200&f=face
          fullname: Peter Simon
          isHf: false
          isPro: false
          name: Stromal
          type: user
        html: '<p>I have domain specific articles on my website for example.: superhero
          movies (non generalist text).</p>

          <p>I do not want to fully retrain FLAN-T5, but I want to do is rather adding
          my articles in to the knowledgebase of the model.</p>

          <p>Maybe in a way like smartphone keyboards federated learning to recommend
          next words or do spelling corrections personalized for each user (I am open
          to any solutions if ther are anything).</p>

          <p>In my case I would like to feed the model with my article about super
          heroes so it can answer questions about the whole website that not normally
          searchable with traditional techniques like.:</p>

          <ul>

          <li>In Batman VS Superman who wins the final battle and how?</li>

          <li>What is the main plot in Avengers: Infinity War?</li>

          </ul>

          <p>The goal would be to not to spend 10-20M USD on training the whole model.
          But maybe a few 1000 USD.</p>

          '
        raw: "I have domain specific articles on my website for example.: superhero\
          \ movies (non generalist text).\r\n\r\nI do not want to fully retrain FLAN-T5,\
          \ but I want to do is rather adding my articles in to the knowledgebase\
          \ of the model.\r\n\r\nMaybe in a way like smartphone keyboards federated\
          \ learning to recommend next words or do spelling corrections personalized\
          \ for each user (I am open to any solutions if ther are anything).\r\n\r\
          \nIn my case I would like to feed the model with my article about super\
          \ heroes so it can answer questions about the whole website that not normally\
          \ searchable with traditional techniques like.:\r\n- In Batman VS Superman\
          \ who wins the final battle and how?\r\n- What is the main plot in Avengers:\
          \ Infinity War?\r\n\r\nThe goal would be to not to spend 10-20M USD on training\
          \ the whole model. But maybe a few 1000 USD."
        updatedAt: '2022-12-09T12:20:08.942Z'
      numEdits: 0
      reactions: []
    id: 639327f80f9530c55f2af617
    type: comment
  author: Stromal
  content: "I have domain specific articles on my website for example.: superhero\
    \ movies (non generalist text).\r\n\r\nI do not want to fully retrain FLAN-T5,\
    \ but I want to do is rather adding my articles in to the knowledgebase of the\
    \ model.\r\n\r\nMaybe in a way like smartphone keyboards federated learning to\
    \ recommend next words or do spelling corrections personalized for each user (I\
    \ am open to any solutions if ther are anything).\r\n\r\nIn my case I would like\
    \ to feed the model with my article about super heroes so it can answer questions\
    \ about the whole website that not normally searchable with traditional techniques\
    \ like.:\r\n- In Batman VS Superman who wins the final battle and how?\r\n- What\
    \ is the main plot in Avengers: Infinity War?\r\n\r\nThe goal would be to not\
    \ to spend 10-20M USD on training the whole model. But maybe a few 1000 USD."
  created_at: 2022-12-09 12:20:08+00:00
  edited: false
  hidden: false
  id: 639327f80f9530c55f2af617
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/444c50d8d9e5bcb64a80d5aebb1f73cc.svg
      fullname: R
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: y-ray
      type: user
    createdAt: '2023-04-07T13:43:11.000Z'
    data:
      edited: false
      editors:
      - y-ray
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/444c50d8d9e5bcb64a80d5aebb1f73cc.svg
          fullname: R
          isHf: false
          isPro: false
          name: y-ray
          type: user
        html: '<p>Hi Stromal,<br>Hope you are doing well!</p>

          <p>I would say that you don''t need to do a fine-tuning but only an in-context
          semantic search using tools such as LangChain or Llama-index.<br>With this,
          the software will add a context to the prompt by doing a similarity search
          on embedding and ask the model a question like "based on the following text:
          {text}. {Question}".</p>

          '
        raw: 'Hi Stromal,

          Hope you are doing well!


          I would say that you don''t need to do a fine-tuning but only an in-context
          semantic search using tools such as LangChain or Llama-index.

          With this, the software will add a context to the prompt by doing a similarity
          search on embedding and ask the model a question like "based on the following
          text: {text}. {Question}".'
        updatedAt: '2023-04-07T13:43:11.598Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Stromal
    id: 64301def12c9cad0dc0595eb
    type: comment
  author: y-ray
  content: 'Hi Stromal,

    Hope you are doing well!


    I would say that you don''t need to do a fine-tuning but only an in-context semantic
    search using tools such as LangChain or Llama-index.

    With this, the software will add a context to the prompt by doing a similarity
    search on embedding and ask the model a question like "based on the following
    text: {text}. {Question}".'
  created_at: 2023-04-07 12:43:11+00:00
  edited: false
  hidden: false
  id: 64301def12c9cad0dc0595eb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2427886248c9e0d2787535fa83b1a41e.svg
      fullname: 'Naman '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: naman-trilogy
      type: user
    createdAt: '2023-05-18T10:41:38.000Z'
    data:
      edited: false
      editors:
      - naman-trilogy
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2427886248c9e0d2787535fa83b1a41e.svg
          fullname: 'Naman '
          isHf: false
          isPro: false
          name: naman-trilogy
          type: user
        html: '<p>But say if I were to fine-tune Flan-T5 using local data, how would
          I go about it?</p>

          <p>Note: I''ve already tried the semantic search approach using langchain
          and really not satisfied with the results</p>

          '
        raw: 'But say if I were to fine-tune Flan-T5 using local data, how would I
          go about it?


          Note: I''ve already tried the semantic search approach using langchain and
          really not satisfied with the results'
        updatedAt: '2023-05-18T10:41:38.169Z'
      numEdits: 0
      reactions: []
    id: 646600e23b99ed9970f68849
    type: comment
  author: naman-trilogy
  content: 'But say if I were to fine-tune Flan-T5 using local data, how would I go
    about it?


    Note: I''ve already tried the semantic search approach using langchain and really
    not satisfied with the results'
  created_at: 2023-05-18 09:41:38+00:00
  edited: false
  hidden: false
  id: 646600e23b99ed9970f68849
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7326e101d21911792d36122cf0d3e2d7.svg
      fullname: Pramod M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: modemz
      type: user
    createdAt: '2023-06-07T21:55:50.000Z'
    data:
      edited: false
      editors:
      - modemz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9606389999389648
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7326e101d21911792d36122cf0d3e2d7.svg
          fullname: Pramod M
          isHf: false
          isPro: false
          name: modemz
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;naman-trilogy&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/naman-trilogy\"\
          >@<span class=\"underline\">naman-trilogy</span></a></span>\n\n\t</span></span>\
          \ can you share why you were not satisfied with the results (just curious\
          \ as I'm interested in the same question - do we need to fine tune, or can\
          \ we just use LangChain to be able to effectively query custom data sources).</p>\n"
        raw: '@naman-trilogy can you share why you were not satisfied with the results
          (just curious as I''m interested in the same question - do we need to fine
          tune, or can we just use LangChain to be able to effectively query custom
          data sources).'
        updatedAt: '2023-06-07T21:55:50.225Z'
      numEdits: 0
      reactions: []
    id: 6480fce69aafd41918b08bfd
    type: comment
  author: modemz
  content: '@naman-trilogy can you share why you were not satisfied with the results
    (just curious as I''m interested in the same question - do we need to fine tune,
    or can we just use LangChain to be able to effectively query custom data sources).'
  created_at: 2023-06-07 20:55:50+00:00
  edited: false
  hidden: false
  id: 6480fce69aafd41918b08bfd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: google/flan-t5-xxl
repo_type: model
status: open
target_branch: null
title: Is there a way to add to the feed my domain specific articles to current trained
  model?
