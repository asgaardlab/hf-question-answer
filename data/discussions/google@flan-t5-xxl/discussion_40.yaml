!!python/object:huggingface_hub.community.DiscussionWithDetails
author: skrishna
conflicting_files: null
created_at: 2023-04-02 15:27:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6186fef1b1085ab638324e7f/BL6_WJCkxB-BatBUBilT8.jpeg?w=200&h=200&f=face
      fullname: Satya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: skrishna
      type: user
    createdAt: '2023-04-02T16:27:11.000Z'
    data:
      edited: false
      editors:
      - skrishna
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6186fef1b1085ab638324e7f/BL6_WJCkxB-BatBUBilT8.jpeg?w=200&h=200&f=face
          fullname: Satya
          isHf: false
          isPro: false
          name: skrishna
          type: user
        html: "<p>I get this 422 response error when I use hugging face inference\
          \ engine for the model using the code below. </p>\n<pre><code>API_URL =\
          \ \"https://api-inference.huggingface.co/models/google/flan-t5-xxl\"\nheaders\
          \ = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\ndef query(payload):\n\
          \    response = requests.post(API_URL, headers=headers, json=payload)\n\
          \    return response.json()\n    \noutput = query({\n    \"inputs\": \"\
          The answer to the universe is\",\n})\n</code></pre>\n"
        raw: "I get this 422 response error when I use hugging face inference engine\
          \ for the model using the code below. \r\n\r\n```\r\nAPI_URL = \"https://api-inference.huggingface.co/models/google/flan-t5-xxl\"\
          \r\nheaders = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\r\ndef query(payload):\r\
          \n\tresponse = requests.post(API_URL, headers=headers, json=payload)\r\n\
          \treturn response.json()\r\n\t\r\noutput = query({\r\n\t\"inputs\": \"The\
          \ answer to the universe is\",\r\n})\r\n```"
        updatedAt: '2023-04-02T16:27:11.041Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Mosh
    id: 6429acdf75bcc24c5e565dc9
    type: comment
  author: skrishna
  content: "I get this 422 response error when I use hugging face inference engine\
    \ for the model using the code below. \r\n\r\n```\r\nAPI_URL = \"https://api-inference.huggingface.co/models/google/flan-t5-xxl\"\
    \r\nheaders = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\r\ndef query(payload):\r\
    \n\tresponse = requests.post(API_URL, headers=headers, json=payload)\r\n\treturn\
    \ response.json()\r\n\t\r\noutput = query({\r\n\t\"inputs\": \"The answer to the\
    \ universe is\",\r\n})\r\n```"
  created_at: 2023-04-02 15:27:11+00:00
  edited: false
  hidden: false
  id: 6429acdf75bcc24c5e565dc9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 40
repo_id: google/flan-t5-xxl
repo_type: model
status: open
target_branch: null
title: '<Response [422]> '
