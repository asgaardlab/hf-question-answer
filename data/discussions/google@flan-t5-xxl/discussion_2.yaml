!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kosukekurimoto
conflicting_files: null
created_at: 2022-10-22 10:57:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5856ce4d28d969da827f83b8aaa9e289.svg
      fullname: kosuke kurimoto
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kosukekurimoto
      type: user
    createdAt: '2022-10-22T11:57:52.000Z'
    data:
      edited: false
      editors:
      - kosukekurimoto
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5856ce4d28d969da827f83b8aaa9e289.svg
          fullname: kosuke kurimoto
          isHf: false
          isPro: false
          name: kosukekurimoto
          type: user
        html: "<p>from transformers import T5Tokenizer, T5ForConditionalGeneration</p>\n\
          <p>tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xxl\")<br>model\
          \ = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xxl\", device_map=\"\
          auto\")<br>input_ids = tokenizer(\"summarize: studies have shown that owning\
          \ a dog is good for you \", return_tensors=\"pt\").input_ids  # Batch size\
          \ 1<br>outputs = model.generate(input_ids)<br>print(tokenizer.decode(outputs[0]))</p>\n\
          <p>\u2193\u2193\u2193\u2193\u2193</p>\n<pre><code>---------------------------------------------------------------------------\n\
          ValueError                                Traceback (most recent call last)\n\
          &lt;ipython-input-11-c7dcdc6785c6&gt; in &lt;module&gt;()\n      1 input_ids\
          \ = tokenizer(\"summarize: studies have shown that owning a dog is good\
          \ for you \", return_tensors=\"pt\").input_ids  # Batch size 1\n----&gt;\
          \ 2 outputs = model.generate(input_ids)\n      3 print(tokenizer.decode(outputs[0]))\n\
          \n3 frames\n/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\
          \ in _get_decoder_start_token_id(self, decoder_start_token_id, bos_token_id)\n\
          \    569             return self.config.decoder.bos_token_id\n    570  \
          \       raise ValueError(\n--&gt; 571             \"`decoder_start_token_id`\
          \ or `bos_token_id` has to be defined for encoder-decoder generation.\"\n\
          \    572         )\n    573 \n\nValueError: `decoder_start_token_id` or\
          \ `bos_token_id` has to be defined for encoder-decoder generation.\n</code></pre>\n"
        raw: "from transformers import T5Tokenizer, T5ForConditionalGeneration\r\n\
          \r\ntokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xxl\")\r\n\
          model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xxl\"\
          , device_map=\"auto\")\r\ninput_ids = tokenizer(\"summarize: studies have\
          \ shown that owning a dog is good for you \", return_tensors=\"pt\").input_ids\
          \  # Batch size 1\r\noutputs = model.generate(input_ids)\r\nprint(tokenizer.decode(outputs[0]))\r\
          \n\r\n\u2193\u2193\u2193\u2193\u2193\r\n\r\n```\r\n---------------------------------------------------------------------------\r\
          \nValueError                                Traceback (most recent call\
          \ last)\r\n<ipython-input-11-c7dcdc6785c6> in <module>()\r\n      1 input_ids\
          \ = tokenizer(\"summarize: studies have shown that owning a dog is good\
          \ for you \", return_tensors=\"pt\").input_ids  # Batch size 1\r\n---->\
          \ 2 outputs = model.generate(input_ids)\r\n      3 print(tokenizer.decode(outputs[0]))\r\
          \n\r\n3 frames\r\n/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\
          \ in _get_decoder_start_token_id(self, decoder_start_token_id, bos_token_id)\r\
          \n    569             return self.config.decoder.bos_token_id\r\n    570\
          \         raise ValueError(\r\n--> 571             \"`decoder_start_token_id`\
          \ or `bos_token_id` has to be defined for encoder-decoder generation.\"\r\
          \n    572         )\r\n    573 \r\n\r\nValueError: `decoder_start_token_id`\
          \ or `bos_token_id` has to be defined for encoder-decoder generation.\r\n\
          ```"
        updatedAt: '2022-10-22T11:57:52.043Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Tonic
    id: 6353dac0c5609a6c001e3969
    type: comment
  author: kosukekurimoto
  content: "from transformers import T5Tokenizer, T5ForConditionalGeneration\r\n\r\
    \ntokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xxl\")\r\nmodel = T5ForConditionalGeneration.from_pretrained(\"\
    google/flan-t5-xxl\", device_map=\"auto\")\r\ninput_ids = tokenizer(\"summarize:\
    \ studies have shown that owning a dog is good for you \", return_tensors=\"pt\"\
    ).input_ids  # Batch size 1\r\noutputs = model.generate(input_ids)\r\nprint(tokenizer.decode(outputs[0]))\r\
    \n\r\n\u2193\u2193\u2193\u2193\u2193\r\n\r\n```\r\n---------------------------------------------------------------------------\r\
    \nValueError                                Traceback (most recent call last)\r\
    \n<ipython-input-11-c7dcdc6785c6> in <module>()\r\n      1 input_ids = tokenizer(\"\
    summarize: studies have shown that owning a dog is good for you \", return_tensors=\"\
    pt\").input_ids  # Batch size 1\r\n----> 2 outputs = model.generate(input_ids)\r\
    \n      3 print(tokenizer.decode(outputs[0]))\r\n\r\n3 frames\r\n/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\
    \ in _get_decoder_start_token_id(self, decoder_start_token_id, bos_token_id)\r\
    \n    569             return self.config.decoder.bos_token_id\r\n    570     \
    \    raise ValueError(\r\n--> 571             \"`decoder_start_token_id` or `bos_token_id`\
    \ has to be defined for encoder-decoder generation.\"\r\n    572         )\r\n\
    \    573 \r\n\r\nValueError: `decoder_start_token_id` or `bos_token_id` has to\
    \ be defined for encoder-decoder generation.\r\n```"
  created_at: 2022-10-22 10:57:52+00:00
  edited: false
  hidden: false
  id: 6353dac0c5609a6c001e3969
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2022-10-22T19:53:21.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;kosukekurimoto&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/kosukekurimoto\"\
          >@<span class=\"underline\">kosukekurimoto</span></a></span>\n\n\t</span></span>\
          \ !<br>With <a href=\"https://huggingface.co/google/flan-t5-xxl/discussions/3\"\
          >https://huggingface.co/google/flan-t5-xxl/discussions/3</a> being merged,\
          \ I believe that the snippet should work now - could you give it another\
          \ try and let us know here? Thanks!</p>\n"
        raw: 'Hey @kosukekurimoto !

          With https://huggingface.co/google/flan-t5-xxl/discussions/3 being merged,
          I believe that the snippet should work now - could you give it another try
          and let us know here? Thanks!'
        updatedAt: '2022-10-22T19:53:21.116Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - kosukekurimoto
    id: 63544a315eac2d2efa788b37
    type: comment
  author: ybelkada
  content: 'Hey @kosukekurimoto !

    With https://huggingface.co/google/flan-t5-xxl/discussions/3 being merged, I believe
    that the snippet should work now - could you give it another try and let us know
    here? Thanks!'
  created_at: 2022-10-22 18:53:21+00:00
  edited: false
  hidden: false
  id: 63544a315eac2d2efa788b37
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a3bb1cd0d8c2c2169f0b88/eT2TS0IlQbZtz-F_zHLz9.jpeg?w=200&h=200&f=face
      fullname: Joseph Pollack
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tonic
      type: user
    createdAt: '2023-10-18T09:08:31.000Z'
    data:
      edited: false
      editors:
      - Tonic
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9928913116455078
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a3bb1cd0d8c2c2169f0b88/eT2TS0IlQbZtz-F_zHLz9.jpeg?w=200&h=200&f=face
          fullname: Joseph Pollack
          isHf: false
          isPro: false
          name: Tonic
          type: user
        html: "<p>i know it's closed, but thanks for sharing that code snippet, it\
          \ was indeed very useful to me \U0001F64F\U0001F3FB</p>\n"
        raw: "i know it's closed, but thanks for sharing that code snippet, it was\
          \ indeed very useful to me \U0001F64F\U0001F3FB"
        updatedAt: '2023-10-18T09:08:31.029Z'
      numEdits: 0
      reactions: []
    id: 652fa08f902fe76a6d2d7c4b
    type: comment
  author: Tonic
  content: "i know it's closed, but thanks for sharing that code snippet, it was indeed\
    \ very useful to me \U0001F64F\U0001F3FB"
  created_at: 2023-10-18 08:08:31+00:00
  edited: false
  hidden: false
  id: 652fa08f902fe76a6d2d7c4b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: google/flan-t5-xxl
repo_type: model
status: open
target_branch: null
title: 'ValueError: `decoder_start_token_id` or `bos_token_id` has to be defined for
  encoder-decoder generation'
