!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nbroad
conflicting_files: null
created_at: 2023-12-11 09:35:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1639773384591-5f353bb37e58354338621655.jpeg?w=200&h=200&f=face
      fullname: Nicholas Broad
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: true
      name: nbroad
      type: user
    createdAt: '2023-12-11T09:35:37.000Z'
    data:
      edited: false
      editors:
      - nbroad
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8385484218597412
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1639773384591-5f353bb37e58354338621655.jpeg?w=200&h=200&f=face
          fullname: Nicholas Broad
          isHf: true
          isPro: true
          name: nbroad
          type: user
        html: '<p>Hi there,</p>

          <p><a rel="nofollow" href="https://github.com/huggingface/transformers/pull/27700">A
          recent fix</a> improved the perpelexity of models like mistral at long context
          lengths. <a rel="nofollow" href="https://github.com/huggingface/transformers/pull/27907#issuecomment-1847303660">Here
          is a figure</a> showing the before-and-after.</p>

          <p>I''m wondering if this would impact the figure on your model card.  This
          only happens in fp16, afaik.</p>

          '
        raw: "Hi there,\r\n\r\n[A recent fix](https://github.com/huggingface/transformers/pull/27700)\
          \ improved the perpelexity of models like mistral at long context lengths.\
          \ [Here is a figure](https://github.com/huggingface/transformers/pull/27907#issuecomment-1847303660)\
          \ showing the before-and-after.\r\n\r\nI'm wondering if this would impact\
          \ the figure on your model card.  This only happens in fp16, afaik."
        updatedAt: '2023-12-11T09:35:37.731Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Sciumo
    id: 6576d7e9177b3b4663a15355
    type: comment
  author: nbroad
  content: "Hi there,\r\n\r\n[A recent fix](https://github.com/huggingface/transformers/pull/27700)\
    \ improved the perpelexity of models like mistral at long context lengths. [Here\
    \ is a figure](https://github.com/huggingface/transformers/pull/27907#issuecomment-1847303660)\
    \ showing the before-and-after.\r\n\r\nI'm wondering if this would impact the\
    \ figure on your model card.  This only happens in fp16, afaik."
  created_at: 2023-12-11 09:35:37+00:00
  edited: false
  hidden: false
  id: 6576d7e9177b3b4663a15355
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1639773384591-5f353bb37e58354338621655.jpeg?w=200&h=200&f=face
      fullname: Nicholas Broad
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: true
      name: nbroad
      type: user
    createdAt: '2023-12-12T01:21:43.000Z'
    data:
      edited: false
      editors:
      - nbroad
      hidden: false
      identifiedLanguage:
        language: et
        probability: 0.10166307538747787
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1639773384591-5f353bb37e58354338621655.jpeg?w=200&h=200&f=face
          fullname: Nicholas Broad
          isHf: true
          isPro: true
          name: nbroad
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;teknium&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/teknium\">@<span class=\"\
          underline\">teknium</span></a></span>\n\n\t</span></span> <span data-props=\"\
          {&quot;user&quot;:&quot;emozilla&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/emozilla\">@<span class=\"underline\">emozilla</span></a></span>\n\
          \n\t</span></span>  <span data-props=\"{&quot;user&quot;:&quot;bloc97&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/bloc97\"\
          >@<span class=\"underline\">bloc97</span></a></span>\n\n\t</span></span>\
          \ </p>\n"
        raw: '@teknium @emozilla  @bloc97 '
        updatedAt: '2023-12-12T01:21:43.962Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Sciumo
    id: 6577b5a78628ec00e9d540de
    type: comment
  author: nbroad
  content: '@teknium @emozilla  @bloc97 '
  created_at: 2023-12-12 01:21:43+00:00
  edited: false
  hidden: false
  id: 6577b5a78628ec00e9d540de
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: NousResearch/Yarn-Mistral-7b-128k
repo_type: model
status: open
target_branch: null
title: Transformers fix to mixed precision at long context lengths
