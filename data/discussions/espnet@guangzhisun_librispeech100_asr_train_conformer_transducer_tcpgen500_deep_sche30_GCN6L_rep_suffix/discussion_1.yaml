!!python/object:huggingface_hub.community.DiscussionWithDetails
author: woshinibaba
conflicting_files: null
created_at: 2023-10-17 05:56:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e8cd225cac80fb91583d1a59da58aea.svg
      fullname: aaa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: woshinibaba
      type: user
    createdAt: '2023-10-17T06:56:50.000Z'
    data:
      edited: false
      editors:
      - woshinibaba
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9445850849151611
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e8cd225cac80fb91583d1a59da58aea.svg
          fullname: aaa
          isHf: false
          isPro: false
          name: woshinibaba
          type: user
        html: '<p>Hi, thanks for your nice work and the pretrained model !</p>

          <p>I found the link (<a rel="nofollow" href="https://github.com/the-anonymous-bs/LibriSpeechBiasingLists">https://github.com/the-anonymous-bs/LibriSpeechBiasingLists</a>)
          to the bias word list is down. Could you please provide another link for
          this file? I would like to try your method on my tasks. Thanks!</p>

          '
        raw: "Hi, thanks for your nice work and the pretrained model !\r\n\r\nI found\
          \ the link (https://github.com/the-anonymous-bs/LibriSpeechBiasingLists)\
          \ to the bias word list is down. Could you please provide another link for\
          \ this file? I would like to try your method on my tasks. Thanks!"
        updatedAt: '2023-10-17T06:56:50.983Z'
      numEdits: 0
      reactions: []
    id: 652e30325a13506b080b4c3c
    type: comment
  author: woshinibaba
  content: "Hi, thanks for your nice work and the pretrained model !\r\n\r\nI found\
    \ the link (https://github.com/the-anonymous-bs/LibriSpeechBiasingLists) to the\
    \ bias word list is down. Could you please provide another link for this file?\
    \ I would like to try your method on my tasks. Thanks!"
  created_at: 2023-10-17 05:56:50+00:00
  edited: false
  hidden: false
  id: 652e30325a13506b080b4c3c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f1a9def3afbec2f8b89ef4450770d67e.svg
      fullname: Guangzhi Sun
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: BrianatCambridge
      type: user
    createdAt: '2023-10-17T07:13:14.000Z'
    data:
      edited: false
      editors:
      - BrianatCambridge
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8850118517875671
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f1a9def3afbec2f8b89ef4450770d67e.svg
          fullname: Guangzhi Sun
          isHf: false
          isPro: false
          name: BrianatCambridge
          type: user
        html: '<p>Hi. Thanks for the message. Please check here: <a rel="nofollow"
          href="https://github.com/BriansIDP/espnet/tree/TCPGendev/egs2/librispeech_100/asr1_biasing/local">https://github.com/BriansIDP/espnet/tree/TCPGendev/egs2/librispeech_100/asr1_biasing/local</a>
          for the biasing lists. <code>all_rare_words.txt</code> is the full rare
          word list which contains ~200k words. <code>rareword_f15.txt</code> is the
          list used to train this model. During inference we always use <code>all_rare_words.txt</code>
          by selecting target biasing words in an utterance and adding 1000 distractors.
          </p>

          '
        raw: 'Hi. Thanks for the message. Please check here: https://github.com/BriansIDP/espnet/tree/TCPGendev/egs2/librispeech_100/asr1_biasing/local
          for the biasing lists. `all_rare_words.txt` is the full rare word list which
          contains ~200k words. `rareword_f15.txt` is the list used to train this
          model. During inference we always use `all_rare_words.txt` by selecting
          target biasing words in an utterance and adding 1000 distractors. '
        updatedAt: '2023-10-17T07:13:14.774Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - woshinibaba
    id: 652e340a2c5f2e2fcf53b653
    type: comment
  author: BrianatCambridge
  content: 'Hi. Thanks for the message. Please check here: https://github.com/BriansIDP/espnet/tree/TCPGendev/egs2/librispeech_100/asr1_biasing/local
    for the biasing lists. `all_rare_words.txt` is the full rare word list which contains
    ~200k words. `rareword_f15.txt` is the list used to train this model. During inference
    we always use `all_rare_words.txt` by selecting target biasing words in an utterance
    and adding 1000 distractors. '
  created_at: 2023-10-17 06:13:14+00:00
  edited: false
  hidden: false
  id: 652e340a2c5f2e2fcf53b653
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: espnet/guangzhisun_librispeech100_asr_train_conformer_transducer_tcpgen500_deep_sche30_GCN6L_rep_suffix
repo_type: model
status: open
target_branch: null
title: About the bias word list
