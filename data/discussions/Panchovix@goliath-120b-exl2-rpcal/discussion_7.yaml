!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bwzimpel
conflicting_files: null
created_at: 2024-01-08 15:14:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3037e58a1dc19152522333a48d121ead.svg
      fullname: Baiwu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bwzimpel
      type: user
    createdAt: '2024-01-08T15:14:24.000Z'
    data:
      edited: false
      editors:
      - bwzimpel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9679149985313416
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3037e58a1dc19152522333a48d121ead.svg
          fullname: Baiwu
          isHf: false
          isPro: false
          name: bwzimpel
          type: user
        html: '<p>Hi, do you have example code on running the model? I''d love to
          have some pointers. Thanks.</p>

          '
        raw: Hi, do you have example code on running the model? I'd love to have some
          pointers. Thanks.
        updatedAt: '2024-01-08T15:14:24.378Z'
      numEdits: 0
      reactions: []
    id: 659c11506b8d5d1940b47b2e
    type: comment
  author: bwzimpel
  content: Hi, do you have example code on running the model? I'd love to have some
    pointers. Thanks.
  created_at: 2024-01-08 15:14:24+00:00
  edited: false
  hidden: false
  id: 659c11506b8d5d1940b47b2e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f52a8d866ed36aba5000ac8d0ef5bc96.svg
      fullname: Francisco
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Panchovix
      type: user
    createdAt: '2024-01-08T20:00:49.000Z'
    data:
      edited: false
      editors:
      - Panchovix
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7790206670761108
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f52a8d866ed36aba5000ac8d0ef5bc96.svg
          fullname: Francisco
          isHf: false
          isPro: false
          name: Panchovix
          type: user
        html: '<p>This model type has to be run on exllamav2 (<a rel="nofollow" href="https://github.com/turboderp/exllamav2">https://github.com/turboderp/exllamav2</a>)</p>

          <p>And there it shows an small example how to run it in the README with
          code.</p>

          <p>The another option is using a UI, like oobabooga/text-generation-webui
          (<a rel="nofollow" href="https://github.com/oobabooga/text-generation-webui">https://github.com/oobabooga/text-generation-webui</a>),
          install it, place a model in the text-generation-webui folder and then on
          the moder loader select exllamav2_hf (though, it should detect it automatically)
          and then load the model there.</p>

          '
        raw: 'This model type has to be run on exllamav2 (https://github.com/turboderp/exllamav2)


          And there it shows an small example how to run it in the README with code.


          The another option is using a UI, like oobabooga/text-generation-webui (https://github.com/oobabooga/text-generation-webui),
          install it, place a model in the text-generation-webui folder and then on
          the moder loader select exllamav2_hf (though, it should detect it automatically)
          and then load the model there.'
        updatedAt: '2024-01-08T20:00:49.660Z'
      numEdits: 0
      reactions: []
    id: 659c547118ad5521980e1e9f
    type: comment
  author: Panchovix
  content: 'This model type has to be run on exllamav2 (https://github.com/turboderp/exllamav2)


    And there it shows an small example how to run it in the README with code.


    The another option is using a UI, like oobabooga/text-generation-webui (https://github.com/oobabooga/text-generation-webui),
    install it, place a model in the text-generation-webui folder and then on the
    moder loader select exllamav2_hf (though, it should detect it automatically) and
    then load the model there.'
  created_at: 2024-01-08 20:00:49+00:00
  edited: false
  hidden: false
  id: 659c547118ad5521980e1e9f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3037e58a1dc19152522333a48d121ead.svg
      fullname: Baiwu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bwzimpel
      type: user
    createdAt: '2024-01-09T02:02:55.000Z'
    data:
      edited: false
      editors:
      - bwzimpel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9390986561775208
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3037e58a1dc19152522333a48d121ead.svg
          fullname: Baiwu
          isHf: false
          isPro: false
          name: bwzimpel
          type: user
        html: '<p>Thanks for the pointer. I was able to get the model running with
          exllamav2. But it seems it never outputs stop token. It will just generate
          until the max token. How to properly instruct it for stop token?</p>

          '
        raw: Thanks for the pointer. I was able to get the model running with exllamav2.
          But it seems it never outputs stop token. It will just generate until the
          max token. How to properly instruct it for stop token?
        updatedAt: '2024-01-09T02:02:55.077Z'
      numEdits: 0
      reactions: []
    id: 659ca94fad9aec418594ad7b
    type: comment
  author: bwzimpel
  content: Thanks for the pointer. I was able to get the model running with exllamav2.
    But it seems it never outputs stop token. It will just generate until the max
    token. How to properly instruct it for stop token?
  created_at: 2024-01-09 02:02:55+00:00
  edited: false
  hidden: false
  id: 659ca94fad9aec418594ad7b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: Panchovix/goliath-120b-exl2-rpcal
repo_type: model
status: open
target_branch: null
title: Example code on running the model?
