!!python/object:huggingface_hub.community.DiscussionWithDetails
author: AlonCohen
conflicting_files: null
created_at: 2024-01-24 14:35:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/94bdd764735a096bd94c6878a60eab27.svg
      fullname: Alon Cohen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AlonCohen
      type: user
    createdAt: '2024-01-24T14:35:02.000Z'
    data:
      edited: false
      editors:
      - AlonCohen
      hidden: false
      identifiedLanguage:
        language: he
        probability: 0.4554276466369629
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/94bdd764735a096bd94c6878a60eab27.svg
          fullname: Alon Cohen
          isHf: false
          isPro: false
          name: AlonCohen
          type: user
        html: "<p>Hi, is anyone else experiencing the same behavior when using pipline?</p>\n\
          <pre><code>from transformers import pipeline\n\npipe = pipeline(\"feature-extraction\"\
          , model=\"dicta-il/dictabert-tiny-joint\", trust_remote_code=True)\npipe(\"\
          \u05D1\u05E9\u05E0\u05EA 1948 \u05D4\u05E9\u05DC\u05D9\u05DD \u05D0\u05E4\
          \u05E8\u05D9\u05DD \u05E7\u05D9\u05E9\u05D5\u05DF \u05D0\u05EA \u05DC\u05D9\
          \u05DE\u05D5\u05D3\u05D9\u05D5 \u05D1\u05E4\u05D9\u05E1\u05D5\u05DC \u05DE\
          \u05EA\u05DB\u05EA \u05D5\u05D1\u05EA\u05D5\u05DC\u05D3\u05D5\u05EA \u05D4\
          \u05D0\u05DE\u05E0\u05D5\u05EA \u05D5\u05D4\u05D7\u05DC \u05DC\u05E4\u05E8\
          \u05E1\u05DD \u05DE\u05D0\u05DE\u05E8\u05D9\u05DD \u05D4\u05D5\u05DE\u05D5\
          \u05E8\u05D9\u05E1\u05D8\u05D9\u05D9\u05DD\")\n</code></pre>\n<p>Error:</p>\n\
          <pre><code>TypeError                                 Traceback (most recent\
          \ call last)\n&lt;ipython-input-57-38fb8274e7c7&gt; in &lt;cell line: 5&gt;()\n\
          \      3 \n      4 pipe = pipeline(\"feature-extraction\", model=\"dicta-il/dictabert-tiny-joint\"\
          , trust_remote_code=True)\n----&gt; 5 pipe(\"\u05D1\u05E9\u05E0\u05EA 1948\
          \ \u05D4\u05E9\u05DC\u05D9\u05DD \u05D0\u05E4\u05E8\u05D9\u05DD \u05E7\u05D9\
          \u05E9\u05D5\u05DF \u05D0\u05EA \u05DC\u05D9\u05DE\u05D5\u05D3\u05D9\u05D5\
          \ \u05D1\u05E4\u05D9\u05E1\u05D5\u05DC \u05DE\u05EA\u05DB\u05EA \u05D5\u05D1\
          \u05EA\u05D5\u05DC\u05D3\u05D5\u05EA \u05D4\u05D0\u05DE\u05E0\u05D5\u05EA\
          \ \u05D5\u05D4\u05D7\u05DC \u05DC\u05E4\u05E8\u05E1\u05DD \u05DE\u05D0\u05DE\
          \u05E8\u05D9\u05DD \u05D4\u05D5\u05DE\u05D5\u05E8\u05D9\u05E1\u05D8\u05D9\
          \u05D9\u05DD\")\n\n14 frames\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\
          \ in embedding(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq,\
          \ sparse)\n   2231         # remove once script supports set_grad_enabled\n\
          \   2232         _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)\n\
          -&gt; 2233     return torch.embedding(weight, input, padding_idx, scale_grad_by_freq,\
          \ sparse)\n   2234 \n   2235 \n\nTypeError: embedding(): argument 'indices'\
          \ (position 2) must be Tensor, not NoneType\n</code></pre>\n"
        raw: "Hi, is anyone else experiencing the same behavior when using pipline?\r\
          \n```\r\nfrom transformers import pipeline\r\n\r\npipe = pipeline(\"feature-extraction\"\
          , model=\"dicta-il/dictabert-tiny-joint\", trust_remote_code=True)\r\npipe(\"\
          \u05D1\u05E9\u05E0\u05EA 1948 \u05D4\u05E9\u05DC\u05D9\u05DD \u05D0\u05E4\
          \u05E8\u05D9\u05DD \u05E7\u05D9\u05E9\u05D5\u05DF \u05D0\u05EA \u05DC\u05D9\
          \u05DE\u05D5\u05D3\u05D9\u05D5 \u05D1\u05E4\u05D9\u05E1\u05D5\u05DC \u05DE\
          \u05EA\u05DB\u05EA \u05D5\u05D1\u05EA\u05D5\u05DC\u05D3\u05D5\u05EA \u05D4\
          \u05D0\u05DE\u05E0\u05D5\u05EA \u05D5\u05D4\u05D7\u05DC \u05DC\u05E4\u05E8\
          \u05E1\u05DD \u05DE\u05D0\u05DE\u05E8\u05D9\u05DD \u05D4\u05D5\u05DE\u05D5\
          \u05E8\u05D9\u05E1\u05D8\u05D9\u05D9\u05DD\")\r\n```\r\n\r\nError:\r\n```\r\
          \nTypeError                                 Traceback (most recent call\
          \ last)\r\n<ipython-input-57-38fb8274e7c7> in <cell line: 5>()\r\n     \
          \ 3 \r\n      4 pipe = pipeline(\"feature-extraction\", model=\"dicta-il/dictabert-tiny-joint\"\
          , trust_remote_code=True)\r\n----> 5 pipe(\"\u05D1\u05E9\u05E0\u05EA 1948\
          \ \u05D4\u05E9\u05DC\u05D9\u05DD \u05D0\u05E4\u05E8\u05D9\u05DD \u05E7\u05D9\
          \u05E9\u05D5\u05DF \u05D0\u05EA \u05DC\u05D9\u05DE\u05D5\u05D3\u05D9\u05D5\
          \ \u05D1\u05E4\u05D9\u05E1\u05D5\u05DC \u05DE\u05EA\u05DB\u05EA \u05D5\u05D1\
          \u05EA\u05D5\u05DC\u05D3\u05D5\u05EA \u05D4\u05D0\u05DE\u05E0\u05D5\u05EA\
          \ \u05D5\u05D4\u05D7\u05DC \u05DC\u05E4\u05E8\u05E1\u05DD \u05DE\u05D0\u05DE\
          \u05E8\u05D9\u05DD \u05D4\u05D5\u05DE\u05D5\u05E8\u05D9\u05E1\u05D8\u05D9\
          \u05D9\u05DD\")\r\n\r\n14 frames\r\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\
          \ in embedding(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq,\
          \ sparse)\r\n   2231         # remove once script supports set_grad_enabled\r\
          \n   2232         _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)\r\
          \n-> 2233     return torch.embedding(weight, input, padding_idx, scale_grad_by_freq,\
          \ sparse)\r\n   2234 \r\n   2235 \r\n\r\nTypeError: embedding(): argument\
          \ 'indices' (position 2) must be Tensor, not NoneType\r\n```\r\n\r\n"
        updatedAt: '2024-01-24T14:35:02.875Z'
      numEdits: 0
      reactions: []
    id: 65b1201654fa188a2f756f0b
    type: comment
  author: AlonCohen
  content: "Hi, is anyone else experiencing the same behavior when using pipline?\r\
    \n```\r\nfrom transformers import pipeline\r\n\r\npipe = pipeline(\"feature-extraction\"\
    , model=\"dicta-il/dictabert-tiny-joint\", trust_remote_code=True)\r\npipe(\"\u05D1\
    \u05E9\u05E0\u05EA 1948 \u05D4\u05E9\u05DC\u05D9\u05DD \u05D0\u05E4\u05E8\u05D9\
    \u05DD \u05E7\u05D9\u05E9\u05D5\u05DF \u05D0\u05EA \u05DC\u05D9\u05DE\u05D5\u05D3\
    \u05D9\u05D5 \u05D1\u05E4\u05D9\u05E1\u05D5\u05DC \u05DE\u05EA\u05DB\u05EA \u05D5\
    \u05D1\u05EA\u05D5\u05DC\u05D3\u05D5\u05EA \u05D4\u05D0\u05DE\u05E0\u05D5\u05EA\
    \ \u05D5\u05D4\u05D7\u05DC \u05DC\u05E4\u05E8\u05E1\u05DD \u05DE\u05D0\u05DE\u05E8\
    \u05D9\u05DD \u05D4\u05D5\u05DE\u05D5\u05E8\u05D9\u05E1\u05D8\u05D9\u05D9\u05DD\
    \")\r\n```\r\n\r\nError:\r\n```\r\nTypeError                                 Traceback\
    \ (most recent call last)\r\n<ipython-input-57-38fb8274e7c7> in <cell line: 5>()\r\
    \n      3 \r\n      4 pipe = pipeline(\"feature-extraction\", model=\"dicta-il/dictabert-tiny-joint\"\
    , trust_remote_code=True)\r\n----> 5 pipe(\"\u05D1\u05E9\u05E0\u05EA 1948 \u05D4\
    \u05E9\u05DC\u05D9\u05DD \u05D0\u05E4\u05E8\u05D9\u05DD \u05E7\u05D9\u05E9\u05D5\
    \u05DF \u05D0\u05EA \u05DC\u05D9\u05DE\u05D5\u05D3\u05D9\u05D5 \u05D1\u05E4\u05D9\
    \u05E1\u05D5\u05DC \u05DE\u05EA\u05DB\u05EA \u05D5\u05D1\u05EA\u05D5\u05DC\u05D3\
    \u05D5\u05EA \u05D4\u05D0\u05DE\u05E0\u05D5\u05EA \u05D5\u05D4\u05D7\u05DC \u05DC\
    \u05E4\u05E8\u05E1\u05DD \u05DE\u05D0\u05DE\u05E8\u05D9\u05DD \u05D4\u05D5\u05DE\
    \u05D5\u05E8\u05D9\u05E1\u05D8\u05D9\u05D9\u05DD\")\r\n\r\n14 frames\r\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\
    \ in embedding(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq,\
    \ sparse)\r\n   2231         # remove once script supports set_grad_enabled\r\n\
    \   2232         _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)\r\
    \n-> 2233     return torch.embedding(weight, input, padding_idx, scale_grad_by_freq,\
    \ sparse)\r\n   2234 \r\n   2235 \r\n\r\nTypeError: embedding(): argument 'indices'\
    \ (position 2) must be Tensor, not NoneType\r\n```\r\n\r\n"
  created_at: 2024-01-24 14:35:02+00:00
  edited: false
  hidden: false
  id: 65b1201654fa188a2f756f0b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/668dfce780e1681234f9116822592119.svg
      fullname: Shmidman
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Shaltiel
      type: user
    createdAt: '2024-01-24T14:37:06.000Z'
    data:
      edited: false
      editors:
      - Shaltiel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9524447321891785
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/668dfce780e1681234f9116822592119.svg
          fullname: Shmidman
          isHf: false
          isPro: false
          name: Shaltiel
          type: user
        html: '<p>The model isn''t designed for any of the generic pipelines since
          the output is tailored for the Hebrew language tasks.</p>

          <p>Please try using the example on the model card.</p>

          '
        raw: 'The model isn''t designed for any of the generic pipelines since the
          output is tailored for the Hebrew language tasks.


          Please try using the example on the model card.'
        updatedAt: '2024-01-24T14:37:06.196Z'
      numEdits: 0
      reactions: []
    id: 65b1209286731ad483a4f25e
    type: comment
  author: Shaltiel
  content: 'The model isn''t designed for any of the generic pipelines since the output
    is tailored for the Hebrew language tasks.


    Please try using the example on the model card.'
  created_at: 2024-01-24 14:37:06+00:00
  edited: false
  hidden: false
  id: 65b1209286731ad483a4f25e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: dicta-il/dictabert-tiny-joint
repo_type: model
status: open
target_branch: null
title: Unable to use pipeline
