!!python/object:huggingface_hub.community.DiscussionWithDetails
author: RobFrans
conflicting_files: null
created_at: 2024-01-20 21:22:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b7af0e8ad40131a1fd28837a53ad2707.svg
      fullname: Mount NLP
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RobFrans
      type: user
    createdAt: '2024-01-20T21:22:12.000Z'
    data:
      edited: false
      editors:
      - RobFrans
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3954453468322754
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b7af0e8ad40131a1fd28837a53ad2707.svg
          fullname: Mount NLP
          isHf: false
          isPro: false
          name: RobFrans
          type: user
        html: '<p>my code:<br>from transformers import AutoModelForMaskedLM<br>model
          = AutoModelForMaskedLM.from_pretrained(<br>  "togethercomputer/m2-bert-80M-8k-retrieval",<br>  trust_remote_code=True<br>)</p>

          <p>and I get this error:<br>You are using a model of type m2_bert to instantiate
          a model of type bert. This is not supported for all configurations of models
          and can yield errors.<br>ValueError: Unrecognized configuration class &lt;class
          ''transformers_modules.togethercomputer.m2-bert-80M-8k-retrieval.90e0b28f3382c289cc6c1e92ef53d7dc5a3ec14b.configuration_bert.BertConfig''&gt;
          for this kind of AutoModel: AutoModelForMaskedLM.<br>Model type should be
          one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, CamembertConfig,
          ConvBertConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig,
          ElectraConfig, ErnieConfig, EsmConfig, FlaubertConfig, FNetConfig, FunnelConfig,
          IBertConfig, LayoutLMConfig, LongformerConfig, LukeConfig, MBartConfig,
          MegaConfig, MegatronBertConfig, MobileBertConfig, MPNetConfig, MvpConfig,
          NezhaConfig, NystromformerConfig, PerceiverConfig, QDQBertConfig, ReformerConfig,
          RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig,
          RoFormerConfig, SqueezeBertConfig, TapasConfig, Wav2Vec2Config, XLMConfig,
          XLMRobertaConfig, XLMRobertaXLConfig, XmodConfig, YosoConfig.</p>

          '
        raw: "my code:\r\nfrom transformers import AutoModelForMaskedLM\r\nmodel =\
          \ AutoModelForMaskedLM.from_pretrained(\r\n  \"togethercomputer/m2-bert-80M-8k-retrieval\"\
          ,\r\n  trust_remote_code=True\r\n)\r\n\r\nand I get this error:\r\nYou are\
          \ using a model of type m2_bert to instantiate a model of type bert. This\
          \ is not supported for all configurations of models and can yield errors.\r\
          \nValueError: Unrecognized configuration class <class 'transformers_modules.togethercomputer.m2-bert-80M-8k-retrieval.90e0b28f3382c289cc6c1e92ef53d7dc5a3ec14b.configuration_bert.BertConfig'>\
          \ for this kind of AutoModel: AutoModelForMaskedLM.\r\nModel type should\
          \ be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, CamembertConfig,\
          \ ConvBertConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig,\
          \ ElectraConfig, ErnieConfig, EsmConfig, FlaubertConfig, FNetConfig, FunnelConfig,\
          \ IBertConfig, LayoutLMConfig, LongformerConfig, LukeConfig, MBartConfig,\
          \ MegaConfig, MegatronBertConfig, MobileBertConfig, MPNetConfig, MvpConfig,\
          \ NezhaConfig, NystromformerConfig, PerceiverConfig, QDQBertConfig, ReformerConfig,\
          \ RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig,\
          \ RoFormerConfig, SqueezeBertConfig, TapasConfig, Wav2Vec2Config, XLMConfig,\
          \ XLMRobertaConfig, XLMRobertaXLConfig, XmodConfig, YosoConfig.\r\n"
        updatedAt: '2024-01-20T21:22:12.023Z'
      numEdits: 0
      reactions: []
    id: 65ac398427f7d6995af1d46b
    type: comment
  author: RobFrans
  content: "my code:\r\nfrom transformers import AutoModelForMaskedLM\r\nmodel = AutoModelForMaskedLM.from_pretrained(\r\
    \n  \"togethercomputer/m2-bert-80M-8k-retrieval\",\r\n  trust_remote_code=True\r\
    \n)\r\n\r\nand I get this error:\r\nYou are using a model of type m2_bert to instantiate\
    \ a model of type bert. This is not supported for all configurations of models\
    \ and can yield errors.\r\nValueError: Unrecognized configuration class <class\
    \ 'transformers_modules.togethercomputer.m2-bert-80M-8k-retrieval.90e0b28f3382c289cc6c1e92ef53d7dc5a3ec14b.configuration_bert.BertConfig'>\
    \ for this kind of AutoModel: AutoModelForMaskedLM.\r\nModel type should be one\
    \ of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, CamembertConfig, ConvBertConfig,\
    \ Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig, ElectraConfig,\
    \ ErnieConfig, EsmConfig, FlaubertConfig, FNetConfig, FunnelConfig, IBertConfig,\
    \ LayoutLMConfig, LongformerConfig, LukeConfig, MBartConfig, MegaConfig, MegatronBertConfig,\
    \ MobileBertConfig, MPNetConfig, MvpConfig, NezhaConfig, NystromformerConfig,\
    \ PerceiverConfig, QDQBertConfig, ReformerConfig, RemBertConfig, RobertaConfig,\
    \ RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig,\
    \ TapasConfig, Wav2Vec2Config, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig,\
    \ XmodConfig, YosoConfig.\r\n"
  created_at: 2024-01-20 21:22:12+00:00
  edited: false
  hidden: false
  id: 65ac398427f7d6995af1d46b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: togethercomputer/m2-bert-80M-8k
repo_type: model
status: open
target_branch: null
title: Error
