!!python/object:huggingface_hub.community.DiscussionWithDetails
author: AIdinner
conflicting_files: null
created_at: 2023-09-02 07:03:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/39fb655746b9f52f289f4cf2a7b0c0e3.svg
      fullname: Pony Donkey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AIdinner
      type: user
    createdAt: '2023-09-02T08:03:48.000Z'
    data:
      edited: false
      editors:
      - AIdinner
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9597949981689453
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/39fb655746b9f52f289f4cf2a7b0c0e3.svg
          fullname: Pony Donkey
          isHf: false
          isPro: false
          name: AIdinner
          type: user
        html: '<p>Hey bro, I am a big fan of you. I wonder the cause of the dramatic
          drop of your model on the Open LLM Leaderboard. Could you please provide
          more information? I would really appreciate it!</p>

          '
        raw: Hey bro, I am a big fan of you. I wonder the cause of the dramatic drop
          of your model on the Open LLM Leaderboard. Could you please provide more
          information? I would really appreciate it!
        updatedAt: '2023-09-02T08:03:48.780Z'
      numEdits: 0
      reactions: []
    id: 64f2ec643e9d80250d162bce
    type: comment
  author: AIdinner
  content: Hey bro, I am a big fan of you. I wonder the cause of the dramatic drop
    of your model on the Open LLM Leaderboard. Could you please provide more information?
    I would really appreciate it!
  created_at: 2023-09-02 07:03:48+00:00
  edited: false
  hidden: false
  id: 64f2ec643e9d80250d162bce
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/39fb655746b9f52f289f4cf2a7b0c0e3.svg
      fullname: Pony Donkey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AIdinner
      type: user
    createdAt: '2023-09-02T08:21:24.000Z'
    data:
      edited: false
      editors:
      - AIdinner
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.934110701084137
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/39fb655746b9f52f289f4cf2a7b0c0e3.svg
          fullname: Pony Donkey
          isHf: false
          isPro: false
          name: AIdinner
          type: user
        html: '<p>I tried to reproduce your results on LLM Leaderboard (TruthfulQA
          score 70) with your QLoRA python scripts and shell scripts to train Airobors-l2-70B-gpt4-1.4.1-qlora
          from <a rel="nofollow" href="https://gist.github.com/jondurbin/87fc040b92a3073125ed516b04bc6e19">https://gist.github.com/jondurbin/87fc040b92a3073125ed516b04bc6e19</a>.
          However, the score of TruthfulQA of my reproduced model is about 55, far
          from 70. I learnt from your model card that you have excluded some de-censoring
          data and did not publish them. I have no idea where the difference comes
          from:  from the de-censoring data ? or the TruthfulQA score 70 is erroneous
          and score about 55 is correct? </p>

          '
        raw: 'I tried to reproduce your results on LLM Leaderboard (TruthfulQA score
          70) with your QLoRA python scripts and shell scripts to train Airobors-l2-70B-gpt4-1.4.1-qlora
          from https://gist.github.com/jondurbin/87fc040b92a3073125ed516b04bc6e19.
          However, the score of TruthfulQA of my reproduced model is about 55, far
          from 70. I learnt from your model card that you have excluded some de-censoring
          data and did not publish them. I have no idea where the difference comes
          from:  from the de-censoring data ? or the TruthfulQA score 70 is erroneous
          and score about 55 is correct? '
        updatedAt: '2023-09-02T08:21:24.870Z'
      numEdits: 0
      reactions: []
    id: 64f2f084594d3120bda3bdc3
    type: comment
  author: AIdinner
  content: 'I tried to reproduce your results on LLM Leaderboard (TruthfulQA score
    70) with your QLoRA python scripts and shell scripts to train Airobors-l2-70B-gpt4-1.4.1-qlora
    from https://gist.github.com/jondurbin/87fc040b92a3073125ed516b04bc6e19. However,
    the score of TruthfulQA of my reproduced model is about 55, far from 70. I learnt
    from your model card that you have excluded some de-censoring data and did not
    publish them. I have no idea where the difference comes from:  from the de-censoring
    data ? or the TruthfulQA score 70 is erroneous and score about 55 is correct? '
  created_at: 2023-09-02 07:21:24+00:00
  edited: false
  hidden: false
  id: 64f2f084594d3120bda3bdc3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6453dafca647b92069ac541a/QkUleoJtHHdTkqtW54QIG.jpeg?w=200&h=200&f=face
      fullname: Jon Durbin
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: jondurbin
      type: user
    createdAt: '2023-09-02T11:20:24.000Z'
    data:
      edited: false
      editors:
      - jondurbin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9529867768287659
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6453dafca647b92069ac541a/QkUleoJtHHdTkqtW54QIG.jpeg?w=200&h=200&f=face
          fullname: Jon Durbin
          isHf: false
          isPro: true
          name: jondurbin
          type: user
        html: '<p>I discovered contamination in an earlier version so I purged anything
          I could find in the datasets via similarity score and recreated the model,
          55 or thereabouts is accurate,</p>

          '
        raw: I discovered contamination in an earlier version so I purged anything
          I could find in the datasets via similarity score and recreated the model,
          55 or thereabouts is accurate,
        updatedAt: '2023-09-02T11:20:24.321Z'
      numEdits: 0
      reactions: []
    id: 64f31a781cb6a62d8444179d
    type: comment
  author: jondurbin
  content: I discovered contamination in an earlier version so I purged anything I
    could find in the datasets via similarity score and recreated the model, 55 or
    thereabouts is accurate,
  created_at: 2023-09-02 10:20:24+00:00
  edited: false
  hidden: false
  id: 64f31a781cb6a62d8444179d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6453dafca647b92069ac541a/QkUleoJtHHdTkqtW54QIG.jpeg?w=200&h=200&f=face
      fullname: Jon Durbin
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: jondurbin
      type: user
    createdAt: '2023-09-02T12:08:46.000Z'
    data:
      edited: false
      editors:
      - jondurbin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9817026257514954
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6453dafca647b92069ac541a/QkUleoJtHHdTkqtW54QIG.jpeg?w=200&h=200&f=face
          fullname: Jon Durbin
          isHf: false
          isPro: true
          name: jondurbin
          type: user
        html: '<p>It you want very specific details, here''s what happened, as far
          as I can tell:</p>

          <ol>

          <li>I included a new misconceptions generator, which was based on: <a rel="nofollow"
          href="https://en.m.wikipedia.org/wiki/List_of_common_misconceptions">https://en.m.wikipedia.org/wiki/List_of_common_misconceptions</a>
          and naturally has some overlap with truthfulqa</li>

          <li>Many of the character cards used for stylized responses are of an AI
          assistant, and when you use gpt4 to generate a response as that character,
          the answers will be very aligned.</li>

          <li>I always have a number of jsonl files for the various categories, and
          merge/format them into a combined dataset before training, including the
          unpublished dealignment stuff.  I''m guessing the "cat *.jsonl &gt; instructions.jsonl"
          was slopppy and grabbed benchmark data, but I always delete pods when done
          so I don''t pay for storage so I can''t say for sure, and I didn''t publish
          the combined file because it had the dealignment rows.</li>

          </ol>

          <p>I requested HF remove the scores as soon as they came through on 08/24,
          which they did, but there was some caching issues after the fixed version
          was retested so it took a few days and a couple PRs to address.</p>

          <p>I like reproducability though - I think what I can do, to avoid the possibility
          of the published training data not matching in the future, is to do my dealignment
          first on the base model without any of the other data, then use it as a
          base for fine-tuning rather than the default llama-2 base.</p>

          '
        raw: 'It you want very specific details, here''s what happened, as far as
          I can tell:

          1. I included a new misconceptions generator, which was based on: https://en.m.wikipedia.org/wiki/List_of_common_misconceptions
          and naturally has some overlap with truthfulqa

          2. Many of the character cards used for stylized responses are of an AI
          assistant, and when you use gpt4 to generate a response as that character,
          the answers will be very aligned.

          3. I always have a number of jsonl files for the various categories, and
          merge/format them into a combined dataset before training, including the
          unpublished dealignment stuff.  I''m guessing the "cat *.jsonl > instructions.jsonl"
          was slopppy and grabbed benchmark data, but I always delete pods when done
          so I don''t pay for storage so I can''t say for sure, and I didn''t publish
          the combined file because it had the dealignment rows.


          I requested HF remove the scores as soon as they came through on 08/24,
          which they did, but there was some caching issues after the fixed version
          was retested so it took a few days and a couple PRs to address.


          I like reproducability though - I think what I can do, to avoid the possibility
          of the published training data not matching in the future, is to do my dealignment
          first on the base model without any of the other data, then use it as a
          base for fine-tuning rather than the default llama-2 base.

          '
        updatedAt: '2023-09-02T12:08:46.104Z'
      numEdits: 0
      reactions: []
    id: 64f325ce352152814d1f796a
    type: comment
  author: jondurbin
  content: 'It you want very specific details, here''s what happened, as far as I
    can tell:

    1. I included a new misconceptions generator, which was based on: https://en.m.wikipedia.org/wiki/List_of_common_misconceptions
    and naturally has some overlap with truthfulqa

    2. Many of the character cards used for stylized responses are of an AI assistant,
    and when you use gpt4 to generate a response as that character, the answers will
    be very aligned.

    3. I always have a number of jsonl files for the various categories, and merge/format
    them into a combined dataset before training, including the unpublished dealignment
    stuff.  I''m guessing the "cat *.jsonl > instructions.jsonl" was slopppy and grabbed
    benchmark data, but I always delete pods when done so I don''t pay for storage
    so I can''t say for sure, and I didn''t publish the combined file because it had
    the dealignment rows.


    I requested HF remove the scores as soon as they came through on 08/24, which
    they did, but there was some caching issues after the fixed version was retested
    so it took a few days and a couple PRs to address.


    I like reproducability though - I think what I can do, to avoid the possibility
    of the published training data not matching in the future, is to do my dealignment
    first on the base model without any of the other data, then use it as a base for
    fine-tuning rather than the default llama-2 base.

    '
  created_at: 2023-09-02 11:08:46+00:00
  edited: false
  hidden: false
  id: 64f325ce352152814d1f796a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/39fb655746b9f52f289f4cf2a7b0c0e3.svg
      fullname: Pony Donkey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AIdinner
      type: user
    createdAt: '2023-09-02T12:34:43.000Z'
    data:
      edited: true
      editors:
      - AIdinner
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9807620644569397
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/39fb655746b9f52f289f4cf2a7b0c0e3.svg
          fullname: Pony Donkey
          isHf: false
          isPro: false
          name: AIdinner
          type: user
        html: '<p>Thank you, Sir! </p>

          '
        raw: 'Thank you, Sir! '
        updatedAt: '2023-09-02T12:35:32.560Z'
      numEdits: 1
      reactions: []
      relatedEventId: 64f32be4ad8b2fb77408ca0a
    id: 64f32be3ad8b2fb77408ca01
    type: comment
  author: AIdinner
  content: 'Thank you, Sir! '
  created_at: 2023-09-02 11:34:43+00:00
  edited: true
  hidden: false
  id: 64f32be3ad8b2fb77408ca01
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/39fb655746b9f52f289f4cf2a7b0c0e3.svg
      fullname: Pony Donkey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AIdinner
      type: user
    createdAt: '2023-09-02T12:34:44.000Z'
    data:
      status: closed
    id: 64f32be4ad8b2fb77408ca0a
    type: status-change
  author: AIdinner
  created_at: 2023-09-02 11:34:44+00:00
  id: 64f32be4ad8b2fb77408ca0a
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: jondurbin/airoboros-l2-70b-2.1
repo_type: model
status: closed
target_branch: null
title: Why there is a dramatic drop on model performance?
