!!python/object:huggingface_hub.community.DiscussionWithDetails
author: arimakana
conflicting_files: null
created_at: 2023-08-19 23:36:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64867bb01bf85dc6a61382f1/g-dZZFnHEoaFo6pxsmbNg.png?w=200&h=200&f=face
      fullname: Ogiso Setsuna
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: arimakana
      type: user
    createdAt: '2023-08-20T00:36:11.000Z'
    data:
      edited: false
      editors:
      - arimakana
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9723482131958008
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64867bb01bf85dc6a61382f1/g-dZZFnHEoaFo6pxsmbNg.png?w=200&h=200&f=face
          fullname: Ogiso Setsuna
          isHf: false
          isPro: false
          name: arimakana
          type: user
        html: '<p>Just curious, does the training dataset includes the MMLU dataset
          which is used during evaluation? If so, is it still fair to use MMLU as
          a metric to evaluate this model? Because compared with other 13B(or maybe
          30B) models, the MMLU metric is very high.</p>

          '
        raw: Just curious, does the training dataset includes the MMLU dataset which
          is used during evaluation? If so, is it still fair to use MMLU as a metric
          to evaluate this model? Because compared with other 13B(or maybe 30B) models,
          the MMLU metric is very high.
        updatedAt: '2023-08-20T00:36:11.531Z'
      numEdits: 0
      reactions: []
    id: 64e15ffb97757ec0576d7e47
    type: comment
  author: arimakana
  content: Just curious, does the training dataset includes the MMLU dataset which
    is used during evaluation? If so, is it still fair to use MMLU as a metric to
    evaluate this model? Because compared with other 13B(or maybe 30B) models, the
    MMLU metric is very high.
  created_at: 2023-08-19 23:36:11+00:00
  edited: false
  hidden: false
  id: 64e15ffb97757ec0576d7e47
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64867bb01bf85dc6a61382f1/g-dZZFnHEoaFo6pxsmbNg.png?w=200&h=200&f=face
      fullname: Ogiso Setsuna
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: arimakana
      type: user
    createdAt: '2023-08-20T00:54:41.000Z'
    data:
      edited: false
      editors:
      - arimakana
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7418226599693298
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64867bb01bf85dc6a61382f1/g-dZZFnHEoaFo6pxsmbNg.png?w=200&h=200&f=face
          fullname: Ogiso Setsuna
          isHf: false
          isPro: false
          name: arimakana
          type: user
        html: '<p>btw, if you rank all the models using MMLU, trurl-2-13b is the highest
          one now... Even higher than the best 70B models by 8%. What tricks did you
          use?<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64867bb01bf85dc6a61382f1/jAyOd1AACJ4KYDzfn-Ql7.png"><img
          alt="Screenshot 2023-08-19 at 5.53.57 PM.png" src="https://cdn-uploads.huggingface.co/production/uploads/64867bb01bf85dc6a61382f1/jAyOd1AACJ4KYDzfn-Ql7.png"></a></p>

          '
        raw: 'btw, if you rank all the models using MMLU, trurl-2-13b is the highest
          one now... Even higher than the best 70B models by 8%. What tricks did you
          use?

          ![Screenshot 2023-08-19 at 5.53.57 PM.png](https://cdn-uploads.huggingface.co/production/uploads/64867bb01bf85dc6a61382f1/jAyOd1AACJ4KYDzfn-Ql7.png)

          '
        updatedAt: '2023-08-20T00:54:41.193Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - radm
    id: 64e16451debaa902f6d192b8
    type: comment
  author: arimakana
  content: 'btw, if you rank all the models using MMLU, trurl-2-13b is the highest
    one now... Even higher than the best 70B models by 8%. What tricks did you use?

    ![Screenshot 2023-08-19 at 5.53.57 PM.png](https://cdn-uploads.huggingface.co/production/uploads/64867bb01bf85dc6a61382f1/jAyOd1AACJ4KYDzfn-Ql7.png)

    '
  created_at: 2023-08-19 23:54:41+00:00
  edited: false
  hidden: false
  id: 64e16451debaa902f6d192b8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646919026796-6229fb48b8c5f583fa931cdd.jpeg?w=200&h=200&f=face
      fullname: "Agnieszka Miko\u0142ajczyk-Bare\u0142a"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: AgaMiko
      type: user
    createdAt: '2023-08-20T08:29:39.000Z'
    data:
      edited: true
      editors:
      - AgaMiko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9858099818229675
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646919026796-6229fb48b8c5f583fa931cdd.jpeg?w=200&h=200&f=face
          fullname: "Agnieszka Miko\u0142ajczyk-Bare\u0142a"
          isHf: false
          isPro: false
          name: AgaMiko
          type: user
        html: '<p>Hi,<br>Yes, our model was trained on MMLU* as we stated in the readme
          description and results table we provided. This model was supposed to be
          our private one, however, it was decided by the company to release it too.
          Our main goal was an improvement of the model in Polish, and our private
          evaluation didn''t include any of the leaderboard datasets, as we focused
          on testing the model in Polish. Originally, we planned to release the model
          trained without the MMLU, but the training is still in progress. We will
          release it as soon as it ends, but it will take another few weeks. Our 7b
          model shows results without MMLU.<br>We didn''t have any plans of evaluating
          trurl-13b on MMLU in the leaderboard, unfortunately, anyone can send the
          model for evaluation.<br>Since it is already in the leaderboard we will
          send on Monday the request to the HF leaderboard to remove our 13b model
          from the MMLU leaderboard.<br>I hope this answers your question.</p>

          <p>*It was only a part of MMLU, modified to only text (no ABCD answers)
          but still MMLU was in the training set.</p>

          '
        raw: "Hi, \nYes, our model was trained on MMLU* as we stated in the readme\
          \ description and results table we provided. This model was supposed to\
          \ be our private one, however, it was decided by the company to release\
          \ it too. Our main goal was an improvement of the model in Polish, and our\
          \ private evaluation didn't include any of the leaderboard datasets, as\
          \ we focused on testing the model in Polish. Originally, we planned to release\
          \ the model trained without the MMLU, but the training is still in progress.\
          \ We will release it as soon as it ends, but it will take another few weeks.\
          \ Our 7b model shows results without MMLU.\nWe didn't have any plans of\
          \ evaluating trurl-13b on MMLU in the leaderboard, unfortunately, anyone\
          \ can send the model for evaluation. \nSince it is already in the leaderboard\
          \ we will send on Monday the request to the HF leaderboard to remove our\
          \ 13b model from the MMLU leaderboard. \nI hope this answers your question.\n\
          \n*It was only a part of MMLU, modified to only text (no ABCD answers) but\
          \ still MMLU was in the training set."
        updatedAt: '2023-08-20T17:11:03.406Z'
      numEdits: 1
      reactions: []
    id: 64e1cef3ee2904562283afec
    type: comment
  author: AgaMiko
  content: "Hi, \nYes, our model was trained on MMLU* as we stated in the readme description\
    \ and results table we provided. This model was supposed to be our private one,\
    \ however, it was decided by the company to release it too. Our main goal was\
    \ an improvement of the model in Polish, and our private evaluation didn't include\
    \ any of the leaderboard datasets, as we focused on testing the model in Polish.\
    \ Originally, we planned to release the model trained without the MMLU, but the\
    \ training is still in progress. We will release it as soon as it ends, but it\
    \ will take another few weeks. Our 7b model shows results without MMLU.\nWe didn't\
    \ have any plans of evaluating trurl-13b on MMLU in the leaderboard, unfortunately,\
    \ anyone can send the model for evaluation. \nSince it is already in the leaderboard\
    \ we will send on Monday the request to the HF leaderboard to remove our 13b model\
    \ from the MMLU leaderboard. \nI hope this answers your question.\n\n*It was only\
    \ a part of MMLU, modified to only text (no ABCD answers) but still MMLU was in\
    \ the training set."
  created_at: 2023-08-20 07:29:39+00:00
  edited: true
  hidden: false
  id: 64e1cef3ee2904562283afec
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646919026796-6229fb48b8c5f583fa931cdd.jpeg?w=200&h=200&f=face
      fullname: "Agnieszka Miko\u0142ajczyk-Bare\u0142a"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: AgaMiko
      type: user
    createdAt: '2023-08-23T07:13:27.000Z'
    data:
      edited: false
      editors:
      - AgaMiko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9757360816001892
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646919026796-6229fb48b8c5f583fa931cdd.jpeg?w=200&h=200&f=face
          fullname: "Agnieszka Miko\u0142ajczyk-Bare\u0142a"
          isHf: false
          isPro: false
          name: AgaMiko
          type: user
        html: '<p>Hello,<br>Just a quick update. Our model have been excluded from
          the leaderboard and we asked if it''s possible to add a new parameter to
          the model card that would block submitting the model to the leaderboard
          so similar situation won''t happen (third party submitting it again).<br>We
          will release the model trained without MMLU when the training will end,
          and this one will be submitted to the leaderboard by us. However, we guess
          that results will not be much higher than Llama 2 (if not slightly lower)
          as the model was trained to work better <strong>on Polish</strong>, especially
          on business-related tasks, and no effort was made towards beating other
          models on HF benchmarks.<br>Cheers</p>

          '
        raw: "Hello,\nJust a quick update. Our model have been excluded from the leaderboard\
          \ and we asked if it's possible to add a new parameter to the model card\
          \ that would block submitting the model to the leaderboard so similar situation\
          \ won't happen (third party submitting it again). \nWe will release the\
          \ model trained without MMLU when the training will end, and this one will\
          \ be submitted to the leaderboard by us. However, we guess that results\
          \ will not be much higher than Llama 2 (if not slightly lower) as the model\
          \ was trained to work better **on Polish**, especially on business-related\
          \ tasks, and no effort was made towards beating other models on HF benchmarks.\n\
          Cheers\n\n"
        updatedAt: '2023-08-23T07:13:27.336Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64e5b19763a071d9b8bddf01
    id: 64e5b19763a071d9b8bddf00
    type: comment
  author: AgaMiko
  content: "Hello,\nJust a quick update. Our model have been excluded from the leaderboard\
    \ and we asked if it's possible to add a new parameter to the model card that\
    \ would block submitting the model to the leaderboard so similar situation won't\
    \ happen (third party submitting it again). \nWe will release the model trained\
    \ without MMLU when the training will end, and this one will be submitted to the\
    \ leaderboard by us. However, we guess that results will not be much higher than\
    \ Llama 2 (if not slightly lower) as the model was trained to work better **on\
    \ Polish**, especially on business-related tasks, and no effort was made towards\
    \ beating other models on HF benchmarks.\nCheers\n\n"
  created_at: 2023-08-23 06:13:27+00:00
  edited: false
  hidden: false
  id: 64e5b19763a071d9b8bddf00
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646919026796-6229fb48b8c5f583fa931cdd.jpeg?w=200&h=200&f=face
      fullname: "Agnieszka Miko\u0142ajczyk-Bare\u0142a"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: AgaMiko
      type: user
    createdAt: '2023-08-23T07:13:27.000Z'
    data:
      status: closed
    id: 64e5b19763a071d9b8bddf01
    type: status-change
  author: AgaMiko
  created_at: 2023-08-23 06:13:27+00:00
  id: 64e5b19763a071d9b8bddf01
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646919026796-6229fb48b8c5f583fa931cdd.jpeg?w=200&h=200&f=face
      fullname: "Agnieszka Miko\u0142ajczyk-Bare\u0142a"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: AgaMiko
      type: user
    createdAt: '2023-09-19T07:14:15.000Z'
    data:
      edited: false
      editors:
      - AgaMiko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5455737709999084
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646919026796-6229fb48b8c5f583fa931cdd.jpeg?w=200&h=200&f=face
          fullname: "Agnieszka Miko\u0142ajczyk-Bare\u0142a"
          isHf: false
          isPro: false
          name: AgaMiko
          type: user
        html: '<p>Just a quick update. The new Trurl is available here: <a href="https://huggingface.co/Voicelab/trurl-2-13b-academic">https://huggingface.co/Voicelab/trurl-2-13b-academic</a></p>

          '
        raw: 'Just a quick update. The new Trurl is available here: https://huggingface.co/Voicelab/trurl-2-13b-academic'
        updatedAt: '2023-09-19T07:14:15.308Z'
      numEdits: 0
      reactions: []
    id: 65094a47a0f81fbc0a6d93e6
    type: comment
  author: AgaMiko
  content: 'Just a quick update. The new Trurl is available here: https://huggingface.co/Voicelab/trurl-2-13b-academic'
  created_at: 2023-09-19 06:14:15+00:00
  edited: false
  hidden: false
  id: 65094a47a0f81fbc0a6d93e6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Voicelab/trurl-2-13b
repo_type: model
status: closed
target_branch: null
title: MMLU
