!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Vladislav951
conflicting_files: null
created_at: 2022-08-03 12:13:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/75c5f4a520b7a9e2a8912db94e1bb0cc.svg
      fullname: Vladislav
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vladislav951
      type: user
    createdAt: '2022-08-03T13:13:01.000Z'
    data:
      edited: false
      editors:
      - Vladislav951
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/75c5f4a520b7a9e2a8912db94e1bb0cc.svg
          fullname: Vladislav
          isHf: false
          isPro: false
          name: Vladislav951
          type: user
        html: '<p>I need to translate large text &gt;10000 characters</p>

          <p>I split the text into sentences and pass this list of sentences into
          pipeline:</p>

          <p>sentences = # list of splitted text into sentences </p>

          <p>from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline<br>pipe
          = pipeline(''translation'', model="facebook/nllb-200-distilled-1.3B", src_lang=''rus_Cyrl'',
          tgt_lang=''eng_Latn'', device=0)<br>result = pipe(sentences, max_length=400,
          batch_size=64)</p>

          <p>Does the model take into account the context from neighboring sentences?
          If not, is it possible to make it?</p>

          '
        raw: "I need to translate large text >10000 characters\r\n\r\nI split the\
          \ text into sentences and pass this list of sentences into pipeline:\r\n\
          \r\nsentences = # list of splitted text into sentences \r\n\r\nfrom transformers\
          \ import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\r\npipe = pipeline('translation',\
          \ model=\"facebook/nllb-200-distilled-1.3B\", src_lang='rus_Cyrl', tgt_lang='eng_Latn',\
          \ device=0)\r\nresult = pipe(sentences, max_length=400, batch_size=64)\r\
          \n\r\n\r\nDoes the model take into account the context from neighboring\
          \ sentences? If not, is it possible to make it?"
        updatedAt: '2022-08-03T13:13:01.427Z'
      numEdits: 0
      reactions: []
    id: 62ea745da9496e43522aa1aa
    type: comment
  author: Vladislav951
  content: "I need to translate large text >10000 characters\r\n\r\nI split the text\
    \ into sentences and pass this list of sentences into pipeline:\r\n\r\nsentences\
    \ = # list of splitted text into sentences \r\n\r\nfrom transformers import AutoModelForSeq2SeqLM,\
    \ AutoTokenizer, pipeline\r\npipe = pipeline('translation', model=\"facebook/nllb-200-distilled-1.3B\"\
    , src_lang='rus_Cyrl', tgt_lang='eng_Latn', device=0)\r\nresult = pipe(sentences,\
    \ max_length=400, batch_size=64)\r\n\r\n\r\nDoes the model take into account the\
    \ context from neighboring sentences? If not, is it possible to make it?"
  created_at: 2022-08-03 12:13:01+00:00
  edited: false
  hidden: false
  id: 62ea745da9496e43522aa1aa
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: facebook/nllb-200-1.3B
repo_type: model
status: open
target_branch: null
title: Does nllb-200 take context into account when splitting into sentences?
