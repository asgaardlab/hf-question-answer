!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MazenSiraj
conflicting_files: null
created_at: 2023-09-16 17:07:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/10e7e9f611efdc47904c5bdb82ceba03.svg
      fullname: Mazen Siraj
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MazenSiraj
      type: user
    createdAt: '2023-09-16T18:07:09.000Z'
    data:
      edited: false
      editors:
      - MazenSiraj
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9282824397087097
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/10e7e9f611efdc47904c5bdb82ceba03.svg
          fullname: Mazen Siraj
          isHf: false
          isPro: false
          name: MazenSiraj
          type: user
        html: '<p>Hello all, I tried downloading the model locally and after the download
          finished i tried to run the sample code and it showed an error related to
          offload folder path and I did not manage to solve it, actually I don''t
          know what is that..<br>So, I''m trying to deploy the model on a virtual
          machine to have the suitable specs.. am using runpod<br>and i have this
          error on the 6th model download<br>ERROR text_generation launcher: An error
          occurred while downloading using <code>hf_transfer</code>. Consider disabling
          HF_HUB_ENABLE_HF_TRANSFER for better error handling.</p>

          <p>can any one help with any of the issues with how to use it locally, step-by-step
          guide for the regular level laptops or the steps to deploy on cloud and
          use it with apis</p>

          <p>thanks</p>

          '
        raw: "Hello all, I tried downloading the model locally and after the download\
          \ finished i tried to run the sample code and it showed an error related\
          \ to offload folder path and I did not manage to solve it, actually I don't\
          \ know what is that.. \r\nSo, I'm trying to deploy the model on a virtual\
          \ machine to have the suitable specs.. am using runpod\r\nand i have this\
          \ error on the 6th model download\r\nERROR text_generation launcher: An\
          \ error occurred while downloading using `hf_transfer`. Consider disabling\
          \ HF_HUB_ENABLE_HF_TRANSFER for better error handling.\r\n\r\ncan any one\
          \ help with any of the issues with how to use it locally, step-by-step guide\
          \ for the regular level laptops or the steps to deploy on cloud and use\
          \ it with apis\r\n\r\nthanks"
        updatedAt: '2023-09-16T18:07:09.935Z'
      numEdits: 0
      reactions: []
    id: 6505eecd1ae953ff2f41bfb5
    type: comment
  author: MazenSiraj
  content: "Hello all, I tried downloading the model locally and after the download\
    \ finished i tried to run the sample code and it showed an error related to offload\
    \ folder path and I did not manage to solve it, actually I don't know what is\
    \ that.. \r\nSo, I'm trying to deploy the model on a virtual machine to have the\
    \ suitable specs.. am using runpod\r\nand i have this error on the 6th model download\r\
    \nERROR text_generation launcher: An error occurred while downloading using `hf_transfer`.\
    \ Consider disabling HF_HUB_ENABLE_HF_TRANSFER for better error handling.\r\n\r\
    \ncan any one help with any of the issues with how to use it locally, step-by-step\
    \ guide for the regular level laptops or the steps to deploy on cloud and use\
    \ it with apis\r\n\r\nthanks"
  created_at: 2023-09-16 17:07:09+00:00
  edited: false
  hidden: false
  id: 6505eecd1ae953ff2f41bfb5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8397a6538ca0423b6a58178a50f9cd77.svg
      fullname: jl
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: poiccard
      type: user
    createdAt: '2023-09-22T19:23:05.000Z'
    data:
      edited: true
      editors:
      - poiccard
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8820655345916748
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8397a6538ca0423b6a58178a50f9cd77.svg
          fullname: jl
          isHf: false
          isPro: false
          name: poiccard
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;MazenSiraj&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/MazenSiraj\"\
          >@<span class=\"underline\">MazenSiraj</span></a></span>\n\n\t</span></span>\
          \ ,<br>The issue with offload folder can be solved by adding <code>offload_folder='offload'</code><br><code>self.model\
          \ = AutoModelForCausalLM.from_pretrained(path, device_map=\"auto\", offload_folder='offload',\
          \ trust_remote_code=True)</code><br>i have submitted a pull request so that\
          \ the model can be deployed on hface inference endpoint<br><a href=\"https://huggingface.co/inception-mbzuai/jais-13b-chat/discussions/12\"\
          >https://huggingface.co/inception-mbzuai/jais-13b-chat/discussions/12</a></p>\n\
          <p>while PR is being reviewed you can check out my copy of this model which\
          \ already has those changes - see button deploy in top right corner<br>please\
          \ note that you will need a beefy machine to run it, i was able to run it\
          \ on GPU [large] \xB7 4x Nvidia Tesla T4 which is $ 4.50 per h, small and\
          \ medium size machines were not able to run it<br><a href=\"https://huggingface.co/poiccard/jais-13b-chat-adn\"\
          >https://huggingface.co/poiccard/jais-13b-chat-adn</a></p>\n"
        raw: "Hi @MazenSiraj , \nThe issue with offload folder can be solved by adding\
          \ `offload_folder='offload'`\n`self.model = AutoModelForCausalLM.from_pretrained(path,\
          \ device_map=\"auto\", offload_folder='offload', trust_remote_code=True)`\n\
          i have submitted a pull request so that the model can be deployed on hface\
          \ inference endpoint\nhttps://huggingface.co/inception-mbzuai/jais-13b-chat/discussions/12\n\
          \nwhile PR is being reviewed you can check out my copy of this model which\
          \ already has those changes - see button deploy in top right corner\nplease\
          \ note that you will need a beefy machine to run it, i was able to run it\
          \ on GPU [large] \xB7 4x Nvidia Tesla T4 which is $ 4.50 per h, small and\
          \ medium size machines were not able to run it\nhttps://huggingface.co/poiccard/jais-13b-chat-adn"
        updatedAt: '2023-09-22T19:27:40.757Z'
      numEdits: 1
      reactions: []
    id: 650de99953b1e2d59eefddfc
    type: comment
  author: poiccard
  content: "Hi @MazenSiraj , \nThe issue with offload folder can be solved by adding\
    \ `offload_folder='offload'`\n`self.model = AutoModelForCausalLM.from_pretrained(path,\
    \ device_map=\"auto\", offload_folder='offload', trust_remote_code=True)`\ni have\
    \ submitted a pull request so that the model can be deployed on hface inference\
    \ endpoint\nhttps://huggingface.co/inception-mbzuai/jais-13b-chat/discussions/12\n\
    \nwhile PR is being reviewed you can check out my copy of this model which already\
    \ has those changes - see button deploy in top right corner\nplease note that\
    \ you will need a beefy machine to run it, i was able to run it on GPU [large]\
    \ \xB7 4x Nvidia Tesla T4 which is $ 4.50 per h, small and medium size machines\
    \ were not able to run it\nhttps://huggingface.co/poiccard/jais-13b-chat-adn"
  created_at: 2023-09-22 18:23:05+00:00
  edited: true
  hidden: false
  id: 650de99953b1e2d59eefddfc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/10e7e9f611efdc47904c5bdb82ceba03.svg
      fullname: Mazen Siraj
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MazenSiraj
      type: user
    createdAt: '2023-09-25T06:31:41.000Z'
    data:
      edited: false
      editors:
      - MazenSiraj
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9500271081924438
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/10e7e9f611efdc47904c5bdb82ceba03.svg
          fullname: Mazen Siraj
          isHf: false
          isPro: false
          name: MazenSiraj
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;poiccard&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/poiccard\"\
          >@<span class=\"underline\">poiccard</span></a></span>\n\n\t</span></span>\
          \ ,<br>Thank u so much, I will check it. may I ask u, I tried to run it\
          \ on my machine, it ran but every time I run the sample code it downloads\
          \ again?<br>if you could support with the steps to run the model and use\
          \ it, will be helpful.</p>\n<p>thanks</p>\n"
        raw: 'Hi @poiccard ,

          Thank u so much, I will check it. may I ask u, I tried to run it on my machine,
          it ran but every time I run the sample code it downloads again?

          if you could support with the steps to run the model and use it, will be
          helpful.


          thanks'
        updatedAt: '2023-09-25T06:31:41.954Z'
      numEdits: 0
      reactions: []
    id: 6511294da0f2ffbecab82d57
    type: comment
  author: MazenSiraj
  content: 'Hi @poiccard ,

    Thank u so much, I will check it. may I ask u, I tried to run it on my machine,
    it ran but every time I run the sample code it downloads again?

    if you could support with the steps to run the model and use it, will be helpful.


    thanks'
  created_at: 2023-09-25 05:31:41+00:00
  edited: false
  hidden: false
  id: 6511294da0f2ffbecab82d57
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/10e7e9f611efdc47904c5bdb82ceba03.svg
      fullname: Mazen Siraj
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MazenSiraj
      type: user
    createdAt: '2023-09-25T06:40:50.000Z'
    data:
      edited: false
      editors:
      - MazenSiraj
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7814875245094299
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/10e7e9f611efdc47904c5bdb82ceba03.svg
          fullname: Mazen Siraj
          isHf: false
          isPro: false
          name: MazenSiraj
          type: user
        html: "<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/650022eaaf1e402143761f57/p0x-xdlTjoxpl5cOPjymm.png\"\
          ><img alt=\"Jais.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/650022eaaf1e402143761f57/p0x-xdlTjoxpl5cOPjymm.png\"\
          ></a><br><span data-props=\"{&quot;user&quot;:&quot;poiccard&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/poiccard\">@<span class=\"\
          underline\">poiccard</span></a></span>\n\n\t</span></span> this is what\
          \ i get every time I run the sample code and it starts downloading all over\
          \ again, I don't think this is how it should go, correct?</p>\n"
        raw: '

          ![Jais.png](https://cdn-uploads.huggingface.co/production/uploads/650022eaaf1e402143761f57/p0x-xdlTjoxpl5cOPjymm.png)

          @poiccard this is what i get every time I run the sample code and it starts
          downloading all over again, I don''t think this is how it should go, correct?

          '
        updatedAt: '2023-09-25T06:40:50.947Z'
      numEdits: 0
      reactions: []
    id: 65112b7299fe56caa8434c84
    type: comment
  author: MazenSiraj
  content: '

    ![Jais.png](https://cdn-uploads.huggingface.co/production/uploads/650022eaaf1e402143761f57/p0x-xdlTjoxpl5cOPjymm.png)

    @poiccard this is what i get every time I run the sample code and it starts downloading
    all over again, I don''t think this is how it should go, correct?

    '
  created_at: 2023-09-25 05:40:50+00:00
  edited: false
  hidden: false
  id: 65112b7299fe56caa8434c84
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8397a6538ca0423b6a58178a50f9cd77.svg
      fullname: jl
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: poiccard
      type: user
    createdAt: '2023-09-25T17:28:47.000Z'
    data:
      edited: true
      editors:
      - poiccard
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9413741230964661
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8397a6538ca0423b6a58178a50f9cd77.svg
          fullname: jl
          isHf: false
          isPro: false
          name: poiccard
          type: user
        html: '<p>Hi,<br>how did you clone it, make you have actually downloaded the
          bin files not just reference<br><code>git lfs install git clone https://huggingface.co/inception-mbzuai/jais-13b-chat
          </code><br>this model is big and is divided into pieces (shards) - what
          it tries to do next, is to load those shards into memory (so it is not downloading,
          but loading)</p>

          <p>you can check more here<br><a href="https://huggingface.co/docs/accelerate/v0.19.0/en/usage_guides/big_modeling">https://huggingface.co/docs/accelerate/v0.19.0/en/usage_guides/big_modeling</a></p>

          <p>i was not able to launch this model on my machine, but i got in contact
          with model creators, and inshallah we will be working on improvements</p>

          <p>in meantime as i mentioned previously, you can deploy my version of the
          model on huggingface inference endpoint (4.5 usd per hour - you can put
          it to sleep when you don''t need it)</p>

          '
        raw: "Hi, \nhow did you clone it, make you have actually downloaded the bin\
          \ files not just reference\n`git lfs install\ngit clone https://huggingface.co/inception-mbzuai/jais-13b-chat\n\
          `\nthis model is big and is divided into pieces (shards) - what it tries\
          \ to do next, is to load those shards into memory (so it is not downloading,\
          \ but loading)\n\nyou can check more here\nhttps://huggingface.co/docs/accelerate/v0.19.0/en/usage_guides/big_modeling\n\
          \ni was not able to launch this model on my machine, but i got in contact\
          \ with model creators, and inshallah we will be working on improvements\n\
          \nin meantime as i mentioned previously, you can deploy my version of the\
          \ model on huggingface inference endpoint (4.5 usd per hour - you can put\
          \ it to sleep when you don't need it)\n"
        updatedAt: '2023-09-25T17:29:45.659Z'
      numEdits: 1
      reactions: []
    id: 6511c34f5b7e52b0251a1cb5
    type: comment
  author: poiccard
  content: "Hi, \nhow did you clone it, make you have actually downloaded the bin\
    \ files not just reference\n`git lfs install\ngit clone https://huggingface.co/inception-mbzuai/jais-13b-chat\n\
    `\nthis model is big and is divided into pieces (shards) - what it tries to do\
    \ next, is to load those shards into memory (so it is not downloading, but loading)\n\
    \nyou can check more here\nhttps://huggingface.co/docs/accelerate/v0.19.0/en/usage_guides/big_modeling\n\
    \ni was not able to launch this model on my machine, but i got in contact with\
    \ model creators, and inshallah we will be working on improvements\n\nin meantime\
    \ as i mentioned previously, you can deploy my version of the model on huggingface\
    \ inference endpoint (4.5 usd per hour - you can put it to sleep when you don't\
    \ need it)\n"
  created_at: 2023-09-25 16:28:47+00:00
  edited: true
  hidden: false
  id: 6511c34f5b7e52b0251a1cb5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 11
repo_id: core42/jais-13b-chat
repo_type: model
status: open
target_branch: null
title: deploy the model on cloud machine
