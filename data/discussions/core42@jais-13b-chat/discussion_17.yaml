!!python/object:huggingface_hub.community.DiscussionWithDetails
author: faris98
conflicting_files: null
created_at: 2023-11-23 17:39:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/246abaaa9c6a18b7859d320d99229933.svg
      fullname: mohammad faris
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: faris98
      type: user
    createdAt: '2023-11-23T17:39:43.000Z'
    data:
      edited: false
      editors:
      - faris98
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7513203024864197
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/246abaaa9c6a18b7859d320d99229933.svg
          fullname: mohammad faris
          isHf: false
          isPro: false
          name: faris98
          type: user
        html: '<p>I attempted to load my checkpoint model using AutoModelForCausalLM.from_pretrained.
          I then merged and unloaded it. However, when I tried to save it using model.save_pretrained(output_merged_dir,
          safe_serialization=True), an error occurred.</p>

          <p>Here is my code snippet:</p>

          <p>from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training,
          AutoPeftModelForCausalLM, PeftModel<br>import torch<br>model = AutoPeftModelForCausalLM.from_pretrained("./final_checkpoint",
          device_map="auto", torch_dtype=torch.bfloat16, trust_remote_code=True)<br>model
          = model.merge_and_unload()</p>

          <p>import os<br>output_merged_dir = "./final_merged_checkpoint"<br>os.makedirs(output_merged_dir,
          exist_ok=True)<br>model.save_pretrained(output_merged_dir, safe_serialization=True)
          </p>

          <p>It shows this error<br>ValueError: You are trying to save a non contiguous
          tensor: <code>transformer.h.0.attn.c_attn.weight</code> which is not allowed.
          It either means you are trying to save tensors which are reference of each
          other in which case it''s recommended to save only the full tensors, and
          reslice at load time, or simply call <code>.contiguous()</code> on your
          tensor to pack it before saving.</p>

          '
        raw: "I attempted to load my checkpoint model using AutoModelForCausalLM.from_pretrained.\
          \ I then merged and unloaded it. However, when I tried to save it using\
          \ model.save_pretrained(output_merged_dir, safe_serialization=True), an\
          \ error occurred.\r\n\r\nHere is my code snippet:\r\n\r\nfrom peft import\
          \ LoraConfig, get_peft_model, prepare_model_for_kbit_training, AutoPeftModelForCausalLM,\
          \ PeftModel\r\nimport torch\r\nmodel = AutoPeftModelForCausalLM.from_pretrained(\"\
          ./final_checkpoint\", device_map=\"auto\", torch_dtype=torch.bfloat16, trust_remote_code=True)\r\
          \nmodel = model.merge_and_unload()\r\n\r\nimport os\r\noutput_merged_dir\
          \ = \"./final_merged_checkpoint\"\r\nos.makedirs(output_merged_dir, exist_ok=True)\r\
          \nmodel.save_pretrained(output_merged_dir, safe_serialization=True) \r\n\
          \r\nIt shows this error\r\nValueError: You are trying to save a non contiguous\
          \ tensor: `transformer.h.0.attn.c_attn.weight` which is not allowed. It\
          \ either means you are trying to save tensors which are reference of each\
          \ other in which case it's recommended to save only the full tensors, and\
          \ reslice at load time, or simply call `.contiguous()` on your tensor to\
          \ pack it before saving.\r\n\r\n\r\n"
        updatedAt: '2023-11-23T17:39:43.574Z'
      numEdits: 0
      reactions: []
    id: 655f8e5f12fb73960c0cfb40
    type: comment
  author: faris98
  content: "I attempted to load my checkpoint model using AutoModelForCausalLM.from_pretrained.\
    \ I then merged and unloaded it. However, when I tried to save it using model.save_pretrained(output_merged_dir,\
    \ safe_serialization=True), an error occurred.\r\n\r\nHere is my code snippet:\r\
    \n\r\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training,\
    \ AutoPeftModelForCausalLM, PeftModel\r\nimport torch\r\nmodel = AutoPeftModelForCausalLM.from_pretrained(\"\
    ./final_checkpoint\", device_map=\"auto\", torch_dtype=torch.bfloat16, trust_remote_code=True)\r\
    \nmodel = model.merge_and_unload()\r\n\r\nimport os\r\noutput_merged_dir = \"\
    ./final_merged_checkpoint\"\r\nos.makedirs(output_merged_dir, exist_ok=True)\r\
    \nmodel.save_pretrained(output_merged_dir, safe_serialization=True) \r\n\r\nIt\
    \ shows this error\r\nValueError: You are trying to save a non contiguous tensor:\
    \ `transformer.h.0.attn.c_attn.weight` which is not allowed. It either means you\
    \ are trying to save tensors which are reference of each other in which case it's\
    \ recommended to save only the full tensors, and reslice at load time, or simply\
    \ call `.contiguous()` on your tensor to pack it before saving.\r\n\r\n\r\n"
  created_at: 2023-11-23 17:39:43+00:00
  edited: false
  hidden: false
  id: 655f8e5f12fb73960c0cfb40
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 17
repo_id: core42/jais-13b-chat
repo_type: model
status: open
target_branch: null
title: error when using `.save_pretrained` due to the non-contiguous tensor
