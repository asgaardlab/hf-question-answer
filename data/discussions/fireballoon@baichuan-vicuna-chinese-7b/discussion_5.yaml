!!python/object:huggingface_hub.community.DiscussionWithDetails
author: deerluffy
conflicting_files: null
created_at: 2023-06-30 05:30:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/36735e11b6baab38d7eba22a0bd5fb8e.svg
      fullname: lu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: deerluffy
      type: user
    createdAt: '2023-06-30T06:30:55.000Z'
    data:
      edited: false
      editors:
      - deerluffy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2733409106731415
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/36735e11b6baab38d7eba22a0bd5fb8e.svg
          fullname: lu
          isHf: false
          isPro: false
          name: deerluffy
          type: user
        html: "<h1 id=\"fastchat-v025\">fastchat v0.2.5</h1>\n<h1 id=\"\u8FD0\u884C\
          \u547D\u4EE4\uFF1A\">\u8FD0\u884C\u547D\u4EE4\uFF1A</h1>\n<p>deepspeed \
          \ fastchat/train/train.py         --num_train_epochs 3     --per_device_train_batch_size\
          \ 1     --per_device_eval_batch_size 1    --gradient_accumulation_steps\
          \ 1     --evaluation_strategy \"no\"     --save_strategy \"steps\"     --save_steps\
          \ 1000     --save_total_limit 2     --learning_rate 2e-5     --weight_decay\
          \ 0.     --warmup_ratio 0.03     --lr_scheduler_type \"cosine\"     --logging_steps\
          \ 1     --tf32 False     --fp16 True     --model_max_length 2048     --gradient_checkpointing\
          \ True     --lazy_preprocess True     --deepspeed /data/xxx/Llama-X/src/configs/deepspeed_config.json\
          \ </p>\n<h1 id=\"log\">log</h1>\n<p>[bjrw-platform-kube-node-di-gpu055:44105:44977\
          \ [0] NCCL INFO Launch mode Parallel<br>{'loss': 0.0, 'learning_rate': 1.5037593984962406e-07,\
          \ 'epoch': 0.0}<br>  0%|                                               \
          \                                                                      |\
          \ 1/4410 [00:30&lt;37:29:28, 30.61s/it]WARNING: tokenization mismatch: 422\
          \ vs. 430. (ignored)<br>{'loss': 0.0, 'learning_rate': 3.007518796992481e-07,\
          \ 'epoch': 0.0}<br>  0%|                                               \
          \                                                                      |\
          \ 2/4410 [00:56&lt;33:55:30, 27.71s/it]WARNING: tokenization mismatch: 312\
          \ vs. 319. (ignored)<br>{'loss': 0.0, 'learning_rate': 4.511278195488722e-07,\
          \ 'epoch': 0.0}<br>  0%|                                               \
          \                                                                      |\
          \ 3/4410 [01:21&lt;32:39:38, 26.68s/it]WARNING: tokenization mismatch: 386\
          \ vs. 394. (ignored)<br>{'loss': 0.0, 'learning_rate': 6.015037593984962e-07,\
          \ 'epoch': 0.0}<br>  0%|                                               \
          \                                                                      |\
          \ 4/4410 [01:46&lt;31:54:57, 26.08s/it]WARNING: tokenization mismatch: 357\
          \ vs. 362. (ignored)<br>{'loss': 0.0, 'learning_rate': 7.518796992481203e-07,\
          \ 'epoch': 0.0}<br>  0%|\u258F                                         \
          \                                                                      \
          \     | 5/4410 [02:13&lt;32:09:14, 26.28s/it]WARNING: tokenization mismatch:\
          \ 218 vs. 220. (ignored)<br>{'loss': 0.0, 'learning_rate': 9.022556390977444e-07,\
          \ 'epoch': 0.0}<br>  0%|\u258F                                         \
          \                                                                      \
          \     | 6/4410 [02:39&lt;32:00:17, 26.16s/it]WARNING: tokenization mismatch:\
          \ 137 vs. 139. (ignored)](WARNING: tokenization mismatch: 279 vs. 286. (ignored)<br>{'loss':\
          \ 0.0, 'learning_rate': 3.7593984962406014e-06, 'epoch': 0.02}<br>  1%|\u258B\
          \                                                                      \
          \                                             | 25/4410 [10:29&lt;28:45:22,\
          \ 23.61s/it]WARNING: tokenization mismatch: 282 vs. 285. (ignored)<br>{'loss':\
          \ 0.0, 'learning_rate': 3.909774436090225e-06, 'epoch': 0.02}<br>  1%|\u258B\
          \                                                                      \
          \                                             | 26/4410 [10:52&lt;28:28:15,\
          \ 23.38s/it]WARNING: tokenization mismatch: 426 vs. 434. (ignored))</p>\n\
          <p>\u662F\u56E0\u4E3A\u8BCD\u8868\u7684\u95EE\u9898\u5BFC\u81F4\u6570\u636E\
          \u90FD\u88AB\u5FFD\u7565\u4E86\u5417\uFF1F</p>\n"
        raw: "# fastchat v0.2.5 \r\n# \u8FD0\u884C\u547D\u4EE4\uFF1A\r\ndeepspeed\
          \  fastchat/train/train.py         --num_train_epochs 3     --per_device_train_batch_size\
          \ 1     --per_device_eval_batch_size 1    --gradient_accumulation_steps\
          \ 1     --evaluation_strategy \"no\"     --save_strategy \"steps\"     --save_steps\
          \ 1000     --save_total_limit 2     --learning_rate 2e-5     --weight_decay\
          \ 0.     --warmup_ratio 0.03     --lr_scheduler_type \"cosine\"     --logging_steps\
          \ 1     --tf32 False     --fp16 True     --model_max_length 2048     --gradient_checkpointing\
          \ True     --lazy_preprocess True     --deepspeed /data/xxx/Llama-X/src/configs/deepspeed_config.json\
          \ \r\n\r\n# log\r\n[bjrw-platform-kube-node-di-gpu055:44105:44977 [0] NCCL\
          \ INFO Launch mode Parallel\r\n{'loss': 0.0, 'learning_rate': 1.5037593984962406e-07,\
          \ 'epoch': 0.0}\r\n  0%|                                               \
          \                                                                      |\
          \ 1/4410 [00:30<37:29:28, 30.61s/it]WARNING: tokenization mismatch: 422\
          \ vs. 430. (ignored)\r\n{'loss': 0.0, 'learning_rate': 3.007518796992481e-07,\
          \ 'epoch': 0.0}\r\n  0%|                                               \
          \                                                                      |\
          \ 2/4410 [00:56<33:55:30, 27.71s/it]WARNING: tokenization mismatch: 312\
          \ vs. 319. (ignored)\r\n{'loss': 0.0, 'learning_rate': 4.511278195488722e-07,\
          \ 'epoch': 0.0}\r\n  0%|                                               \
          \                                                                      |\
          \ 3/4410 [01:21<32:39:38, 26.68s/it]WARNING: tokenization mismatch: 386\
          \ vs. 394. (ignored)\r\n{'loss': 0.0, 'learning_rate': 6.015037593984962e-07,\
          \ 'epoch': 0.0}\r\n  0%|                                               \
          \                                                                      |\
          \ 4/4410 [01:46<31:54:57, 26.08s/it]WARNING: tokenization mismatch: 357\
          \ vs. 362. (ignored)\r\n{'loss': 0.0, 'learning_rate': 7.518796992481203e-07,\
          \ 'epoch': 0.0}\r\n  0%|\u258F                                         \
          \                                                                      \
          \     | 5/4410 [02:13<32:09:14, 26.28s/it]WARNING: tokenization mismatch:\
          \ 218 vs. 220. (ignored)\r\n{'loss': 0.0, 'learning_rate': 9.022556390977444e-07,\
          \ 'epoch': 0.0}\r\n  0%|\u258F                                         \
          \                                                                      \
          \     | 6/4410 [02:39<32:00:17, 26.16s/it]WARNING: tokenization mismatch:\
          \ 137 vs. 139. (ignored)](WARNING: tokenization mismatch: 279 vs. 286. (ignored)\r\
          \n{'loss': 0.0, 'learning_rate': 3.7593984962406014e-06, 'epoch': 0.02}\r\
          \n  1%|\u258B                                                          \
          \                                                         | 25/4410 [10:29<28:45:22,\
          \ 23.61s/it]WARNING: tokenization mismatch: 282 vs. 285. (ignored)\r\n{'loss':\
          \ 0.0, 'learning_rate': 3.909774436090225e-06, 'epoch': 0.02}\r\n  1%|\u258B\
          \                                                                      \
          \                                             | 26/4410 [10:52<28:28:15,\
          \ 23.38s/it]WARNING: tokenization mismatch: 426 vs. 434. (ignored))\r\n\r\
          \n\u662F\u56E0\u4E3A\u8BCD\u8868\u7684\u95EE\u9898\u5BFC\u81F4\u6570\u636E\
          \u90FD\u88AB\u5FFD\u7565\u4E86\u5417\uFF1F"
        updatedAt: '2023-06-30T06:30:55.606Z'
      numEdits: 0
      reactions: []
    id: 649e769fed3107c9bd269b0b
    type: comment
  author: deerluffy
  content: "# fastchat v0.2.5 \r\n# \u8FD0\u884C\u547D\u4EE4\uFF1A\r\ndeepspeed  fastchat/train/train.py\
    \         --num_train_epochs 3     --per_device_train_batch_size 1     --per_device_eval_batch_size\
    \ 1    --gradient_accumulation_steps 1     --evaluation_strategy \"no\"     --save_strategy\
    \ \"steps\"     --save_steps 1000     --save_total_limit 2     --learning_rate\
    \ 2e-5     --weight_decay 0.     --warmup_ratio 0.03     --lr_scheduler_type \"\
    cosine\"     --logging_steps 1     --tf32 False     --fp16 True     --model_max_length\
    \ 2048     --gradient_checkpointing True     --lazy_preprocess True     --deepspeed\
    \ /data/xxx/Llama-X/src/configs/deepspeed_config.json \r\n\r\n# log\r\n[bjrw-platform-kube-node-di-gpu055:44105:44977\
    \ [0] NCCL INFO Launch mode Parallel\r\n{'loss': 0.0, 'learning_rate': 1.5037593984962406e-07,\
    \ 'epoch': 0.0}\r\n  0%|                                                     \
    \                                                                | 1/4410 [00:30<37:29:28,\
    \ 30.61s/it]WARNING: tokenization mismatch: 422 vs. 430. (ignored)\r\n{'loss':\
    \ 0.0, 'learning_rate': 3.007518796992481e-07, 'epoch': 0.0}\r\n  0%|        \
    \                                                                            \
    \                                 | 2/4410 [00:56<33:55:30, 27.71s/it]WARNING:\
    \ tokenization mismatch: 312 vs. 319. (ignored)\r\n{'loss': 0.0, 'learning_rate':\
    \ 4.511278195488722e-07, 'epoch': 0.0}\r\n  0%|                              \
    \                                                                            \
    \           | 3/4410 [01:21<32:39:38, 26.68s/it]WARNING: tokenization mismatch:\
    \ 386 vs. 394. (ignored)\r\n{'loss': 0.0, 'learning_rate': 6.015037593984962e-07,\
    \ 'epoch': 0.0}\r\n  0%|                                                     \
    \                                                                | 4/4410 [01:46<31:54:57,\
    \ 26.08s/it]WARNING: tokenization mismatch: 357 vs. 362. (ignored)\r\n{'loss':\
    \ 0.0, 'learning_rate': 7.518796992481203e-07, 'epoch': 0.0}\r\n  0%|\u258F  \
    \                                                                            \
    \                                      | 5/4410 [02:13<32:09:14, 26.28s/it]WARNING:\
    \ tokenization mismatch: 218 vs. 220. (ignored)\r\n{'loss': 0.0, 'learning_rate':\
    \ 9.022556390977444e-07, 'epoch': 0.0}\r\n  0%|\u258F                        \
    \                                                                            \
    \                | 6/4410 [02:39<32:00:17, 26.16s/it]WARNING: tokenization mismatch:\
    \ 137 vs. 139. (ignored)](WARNING: tokenization mismatch: 279 vs. 286. (ignored)\r\
    \n{'loss': 0.0, 'learning_rate': 3.7593984962406014e-06, 'epoch': 0.02}\r\n  1%|\u258B\
    \                                                                            \
    \                                       | 25/4410 [10:29<28:45:22, 23.61s/it]WARNING:\
    \ tokenization mismatch: 282 vs. 285. (ignored)\r\n{'loss': 0.0, 'learning_rate':\
    \ 3.909774436090225e-06, 'epoch': 0.02}\r\n  1%|\u258B                       \
    \                                                                            \
    \                | 26/4410 [10:52<28:28:15, 23.38s/it]WARNING: tokenization mismatch:\
    \ 426 vs. 434. (ignored))\r\n\r\n\u662F\u56E0\u4E3A\u8BCD\u8868\u7684\u95EE\u9898\
    \u5BFC\u81F4\u6570\u636E\u90FD\u88AB\u5FFD\u7565\u4E86\u5417\uFF1F"
  created_at: 2023-06-30 05:30:55+00:00
  edited: false
  hidden: false
  id: 649e769fed3107c9bd269b0b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/648b7223355113a5fba3cba7/jDetKunlde-KPUv_YOToD.png?w=200&h=200&f=face
      fullname: fireballoon
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: fireballoon
      type: user
    createdAt: '2023-06-30T06:59:24.000Z'
    data:
      edited: false
      editors:
      - fireballoon
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.7835658192634583
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/648b7223355113a5fba3cba7/jDetKunlde-KPUv_YOToD.png?w=200&h=200&f=face
          fullname: fireballoon
          isHf: false
          isPro: false
          name: fireballoon
          type: user
        html: "<p>\u8FD9\u4E2A\u95EE\u9898\u662F\u7531\u4E8Etokenizer\u7F16\u7801\u9519\
          \u8BEF\uFF0C\u5BFC\u81F4\u6570\u636E\u90FD\u88AB\u8DF3\u8FC7\u4E86\u3002\
          \u6211\u4E5F\u9047\u5230\u4E86\u8FD9\u4E2A\u95EE\u9898\uFF0C\u5E76\u91CD\
          \u5199\u4E86tokenize\u7684\u51FD\u6570\u4EE5\u907F\u514D\u7F16\u7801\u9519\
          \u8BEF\uFF08\u53EF\u4EE5\u53C2\u8003<a href=\"https://huggingface.co/fireballoon/baichuan-vicuna-7b/blob/main/train_vicuna.py\"\
          >https://huggingface.co/fireballoon/baichuan-vicuna-7b/blob/main/train_vicuna.py</a>\
          \ \u4E2D\u7684<code>tokenize</code>\u51FD\u6570\uFF0C\u5BF9\u5E94fastchat\
          \ train\u4E2D\u7684<code>preprocess</code>\u51FD\u6570\uFF09</p>\n"
        raw: "\u8FD9\u4E2A\u95EE\u9898\u662F\u7531\u4E8Etokenizer\u7F16\u7801\u9519\
          \u8BEF\uFF0C\u5BFC\u81F4\u6570\u636E\u90FD\u88AB\u8DF3\u8FC7\u4E86\u3002\
          \u6211\u4E5F\u9047\u5230\u4E86\u8FD9\u4E2A\u95EE\u9898\uFF0C\u5E76\u91CD\
          \u5199\u4E86tokenize\u7684\u51FD\u6570\u4EE5\u907F\u514D\u7F16\u7801\u9519\
          \u8BEF\uFF08\u53EF\u4EE5\u53C2\u8003https://huggingface.co/fireballoon/baichuan-vicuna-7b/blob/main/train_vicuna.py\
          \ \u4E2D\u7684`tokenize`\u51FD\u6570\uFF0C\u5BF9\u5E94fastchat train\u4E2D\
          \u7684`preprocess`\u51FD\u6570\uFF09"
        updatedAt: '2023-06-30T06:59:24.235Z'
      numEdits: 0
      reactions: []
    id: 649e7d4c40d0ed8a50e86607
    type: comment
  author: fireballoon
  content: "\u8FD9\u4E2A\u95EE\u9898\u662F\u7531\u4E8Etokenizer\u7F16\u7801\u9519\u8BEF\
    \uFF0C\u5BFC\u81F4\u6570\u636E\u90FD\u88AB\u8DF3\u8FC7\u4E86\u3002\u6211\u4E5F\
    \u9047\u5230\u4E86\u8FD9\u4E2A\u95EE\u9898\uFF0C\u5E76\u91CD\u5199\u4E86tokenize\u7684\
    \u51FD\u6570\u4EE5\u907F\u514D\u7F16\u7801\u9519\u8BEF\uFF08\u53EF\u4EE5\u53C2\
    \u8003https://huggingface.co/fireballoon/baichuan-vicuna-7b/blob/main/train_vicuna.py\
    \ \u4E2D\u7684`tokenize`\u51FD\u6570\uFF0C\u5BF9\u5E94fastchat train\u4E2D\u7684\
    `preprocess`\u51FD\u6570\uFF09"
  created_at: 2023-06-30 05:59:24+00:00
  edited: false
  hidden: false
  id: 649e7d4c40d0ed8a50e86607
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/648b7223355113a5fba3cba7/jDetKunlde-KPUv_YOToD.png?w=200&h=200&f=face
      fullname: fireballoon
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: fireballoon
      type: user
    createdAt: '2023-07-21T10:44:34.000Z'
    data:
      status: closed
    id: 64ba619277dd483716aca0ec
    type: status-change
  author: fireballoon
  created_at: 2023-07-21 09:44:34+00:00
  id: 64ba619277dd483716aca0ec
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: fireballoon/baichuan-vicuna-chinese-7b
repo_type: model
status: closed
target_branch: null
title: "\u8BAD\u7EC3\u7684\u65F6\u5019loss\u4E3A0"
