!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Dipankar1415
conflicting_files: null
created_at: 2023-05-29 06:37:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cb1a128ab1b01cfa874566a39a1dea77.svg
      fullname: Bhattacharya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Dipankar1415
      type: user
    createdAt: '2023-05-29T07:37:01.000Z'
    data:
      edited: false
      editors:
      - Dipankar1415
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cb1a128ab1b01cfa874566a39a1dea77.svg
          fullname: Bhattacharya
          isHf: false
          isPro: false
          name: Dipankar1415
          type: user
        html: "<p>Getting out of space for bigscience/bloom deployment on sagemaker\
          \ even with 1 TB space and instance ml.m5.24xlarge at the following step<br>model\
          \ = AutoModelForCausalLM.from_pretrained(<br>    \"bigscience/bloom\",<br>\
          \    device_map=\"auto\",<br>    torch_dtype=\"auto\"<br>)</p>\n<p>Error:</p>\n\
          <h2 id=\"downloading-lvemainconfigjson---0-----------000573-0000-bs\">Downloading\
          \ (\u2026)lve/main/config.json:   0%|          | 0.00/573 [00:00&lt;?, ?B/s]</h2>\n\
          <hr>\n<p>OSError                                   Traceback (most recent\
          \ call last)<br>Cell In[5], line 1<br>----&gt; 1 model = AutoModelForCausalLM.from_pretrained(<br>\
          \      2     \"bigscience/bloom\",<br>      3     device_map=\"auto\",<br>\
          \      4     torch_dtype=\"auto\"<br>      5 )</p>\n<p>File ~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:467,\
          \ in _BaseAutoModelClass.from_pretrained(cls, pretrained_model_name_or_path,\
          \ *model_args, **kwargs)<br>    465 elif type(config) in cls._model_mapping.keys():<br>\
          \    466     model_class = _get_model_class(config, cls._model_mapping)<br>--&gt;\
          \ 467     return model_class.from_pretrained(<br>    468         pretrained_model_name_or_path,\
          \ *model_args, config=config, **hub_kwargs, **kwargs<br>    469     )<br>\
          \    470 raise ValueError(<br>    471     f\"Unrecognized configuration\
          \ class {config.<strong>class</strong>} for this kind of AutoModel: {cls.<strong>name</strong>}.\\\
          n\"<br>    472     f\"Model type should be one of {', '.join(c.<strong>name</strong>\
          \ for c in cls._model_mapping.keys())}.\"<br>    473 )</p>\n<p>File ~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/modeling_utils.py:2523,\
          \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path,\
          \ *model_args, **kwargs)<br>   2520 # We'll need to download and cache each\
          \ checkpoint shard if the checkpoint is sharded.<br>   2521 if is_sharded:<br>\
          \   2522     # rsolved_archive_file becomes a list of files that point to\
          \ the different checkpoint shards in this case.<br>-&gt; 2523     resolved_archive_file,\
          \ sharded_metadata = get_checkpoint_shard_files(<br>   2524         pretrained_model_name_or_path,<br>\
          \   2525         resolved_archive_file,<br>   2526         cache_dir=cache_dir,<br>\
          \   2527         force_download=force_download,<br>   2528         proxies=proxies,<br>\
          \   2529         resume_download=resume_download,<br>   2530         local_files_only=local_files_only,<br>\
          \   2531         use_auth_token=use_auth_token,<br>   2532         user_agent=user_agent,<br>\
          \   2533         revision=revision,<br>   2534         subfolder=subfolder,<br>\
          \   2535         _commit_hash=commit_hash,<br>   2536     )<br>   2538 #\
          \ load pt weights early so that we know which dtype to init the model under<br>\
          \   2539 if from_pt:</p>\n<p>File ~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/utils/hub.py:934,\
          \ in get_checkpoint_shard_files(pretrained_model_name_or_path, index_filename,\
          \ cache_dir, force_download, proxies, resume_download, local_files_only,\
          \ use_auth_token, user_agent, revision, subfolder, _commit_hash)<br>   \
          \ 931 for shard_filename in tqdm(shard_filenames, desc=\"Downloading shards\"\
          , disable=not show_progress_bar):<br>    932     try:<br>    933       \
          \  # Load from URL<br>--&gt; 934         cached_filename = cached_file(<br>\
          \    935             pretrained_model_name_or_path,<br>    936         \
          \    shard_filename,<br>    937             cache_dir=cache_dir,<br>   \
          \ 938             force_download=force_download,<br>    939            \
          \ proxies=proxies,<br>    940             resume_download=resume_download,<br>\
          \    941             local_files_only=local_files_only,<br>    942     \
          \        use_auth_token=use_auth_token,<br>    943             user_agent=user_agent,<br>\
          \    944             revision=revision,<br>    945             subfolder=subfolder,<br>\
          \    946             _commit_hash=_commit_hash,<br>    947         )<br>\
          \    948     # We have already dealt with RepositoryNotFoundError and RevisionNotFoundError\
          \ when getting the index, so<br>    949     # we don't have to catch them\
          \ here.<br>    950     except EntryNotFoundError:</p>\n<p>File ~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/utils/hub.py:417,\
          \ in cached_file(path_or_repo_id, filename, cache_dir, force_download, resume_download,\
          \ proxies, use_auth_token, revision, local_files_only, subfolder, repo_type,\
          \ user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors,\
          \ _commit_hash)<br>    414 user_agent = http_user_agent(user_agent)<br>\
          \    415 try:<br>    416     # Load from URL or cache if already cached<br>--&gt;\
          \ 417     resolved_file = hf_hub_download(<br>    418         path_or_repo_id,<br>\
          \    419         filename,<br>    420         subfolder=None if len(subfolder)\
          \ == 0 else subfolder,<br>    421         repo_type=repo_type,<br>    422\
          \         revision=revision,<br>    423         cache_dir=cache_dir,<br>\
          \    424         user_agent=user_agent,<br>    425         force_download=force_download,<br>\
          \    426         proxies=proxies,<br>    427         resume_download=resume_download,<br>\
          \    428         use_auth_token=use_auth_token,<br>    429         local_files_only=local_files_only,<br>\
          \    430     )<br>    432 except RepositoryNotFoundError:<br>    433   \
          \  raise EnvironmentError(<br>    434         f\"{path_or_repo_id} is not\
          \ a local folder and is not a valid model identifier \"<br>    435     \
          \    \"listed on '<a href=\"https://huggingface.co/models'%5CnIf\">https://huggingface.co/models'\\\
          nIf</a> this is a private repository, make sure to \"<br>    436       \
          \  \"pass a token having permission to this repo with <code>use_auth_token</code>\
          \ or log in with \"<br>    437         \"<code>huggingface-cli login</code>\
          \ and pass <code>use_auth_token=True</code>.\"<br>    438     )</p>\n<p>File\
          \ ~/anaconda3/envs/python3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:120,\
          \ in validate_hf_hub_args.._inner_fn(*args, **kwargs)<br>    117 if check_use_auth_token:<br>\
          \    118     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.<strong>name</strong>,\
          \ has_token=has_token, kwargs=kwargs)<br>--&gt; 120 return fn(*args, **kwargs)</p>\n\
          <p>File ~/anaconda3/envs/python3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1364,\
          \ in hf_hub_download(repo_id, filename, subfolder, repo_type, revision,\
          \ library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks,\
          \ user_agent, force_download, force_filename, proxies, etag_timeout, resume_download,\
          \ token, local_files_only, legacy_cache_layout)<br>   1361 with temp_file_manager()\
          \ as temp_file:<br>   1362     logger.info(\"downloading %s to %s\", url,\
          \ temp_file.name)<br>-&gt; 1364     http_get(<br>   1365         url_to_download,<br>\
          \   1366         temp_file,<br>   1367         proxies=proxies,<br>   1368\
          \         resume_size=resume_size,<br>   1369         headers=headers,<br>\
          \   1370         expected_size=expected_size,<br>   1371     )<br>   1373\
          \ if local_dir is None:<br>   1374     logger.info(f\"Storing {url} in cache\
          \ at {blob_path}\")</p>\n<p>File ~/anaconda3/envs/python3/lib/python3.10/site-packages/huggingface_hub/file_download.py:544,\
          \ in http_get(url, temp_file, proxies, resume_size, headers, timeout, max_retries,\
          \ expected_size)<br>    542     if chunk:  # filter out keep-alive new chunks<br>\
          \    543         progress.update(len(chunk))<br>--&gt; 544         temp_file.write(chunk)<br>\
          \    546 if expected_size is not None and expected_size != temp_file.tell():<br>\
          \    547     raise EnvironmentError(<br>    548         f\"Consistency check\
          \ failed: file should be of size {expected_size} but has size\"<br>    549\
          \         f\" {temp_file.tell()} ({displayed_name}).\\nWe are sorry for\
          \ the inconvenience. Please retry download and\"<br>    550         \" pass\
          \ <code>force_download=True, resume_download=False</code> as argument.\\\
          nIf the issue persists, please let us\"<br>    551         \" know by opening\
          \ an issue on <a rel=\"nofollow\" href=\"https://github.com/huggingface/huggingface_hub.&quot;\"\
          >https://github.com/huggingface/huggingface_hub.\"</a><br>    552     )</p>\n\
          <p>File ~/anaconda3/envs/python3/lib/python3.10/tempfile.py:483, in _TemporaryFileWrapper.<strong>getattr</strong>..func_wrapper(*args,\
          \ **kwargs)<br>    481 @_functools.wraps(func)<br>    482 def func_wrapper(*args,\
          \ **kwargs):<br>--&gt; 483     return func(*args, **kwargs)</p>\n<p>OSError:\
          \ [Errno 28] No space left on device</p>\n"
        raw: "Getting out of space for bigscience/bloom deployment on sagemaker even\
          \ with 1 TB space and instance ml.m5.24xlarge at the following step\r\n\
          model = AutoModelForCausalLM.from_pretrained(\r\n    \"bigscience/bloom\"\
          ,\r\n    device_map=\"auto\",\r\n    torch_dtype=\"auto\"\r\n)\r\n\r\nError:\r\
          \nDownloading (\u2026)lve/main/config.json:   0%|          | 0.00/573 [00:00<?,\
          \ ?B/s]\r\n----\r\n---------------------------------------------------------------------------\r\
          \nOSError                                   Traceback (most recent call\
          \ last)\r\nCell In[5], line 1\r\n----> 1 model = AutoModelForCausalLM.from_pretrained(\r\
          \n      2     \"bigscience/bloom\",\r\n      3     device_map=\"auto\",\r\
          \n      4     torch_dtype=\"auto\"\r\n      5 )\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:467,\
          \ in _BaseAutoModelClass.from_pretrained(cls, pretrained_model_name_or_path,\
          \ *model_args, **kwargs)\r\n    465 elif type(config) in cls._model_mapping.keys():\r\
          \n    466     model_class = _get_model_class(config, cls._model_mapping)\r\
          \n--> 467     return model_class.from_pretrained(\r\n    468         pretrained_model_name_or_path,\
          \ *model_args, config=config, **hub_kwargs, **kwargs\r\n    469     )\r\n\
          \    470 raise ValueError(\r\n    471     f\"Unrecognized configuration\
          \ class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\\
          n\"\r\n    472     f\"Model type should be one of {', '.join(c.__name__\
          \ for c in cls._model_mapping.keys())}.\"\r\n    473 )\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/modeling_utils.py:2523,\
          \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path,\
          \ *model_args, **kwargs)\r\n   2520 # We'll need to download and cache each\
          \ checkpoint shard if the checkpoint is sharded.\r\n   2521 if is_sharded:\r\
          \n   2522     # rsolved_archive_file becomes a list of files that point\
          \ to the different checkpoint shards in this case.\r\n-> 2523     resolved_archive_file,\
          \ sharded_metadata = get_checkpoint_shard_files(\r\n   2524         pretrained_model_name_or_path,\r\
          \n   2525         resolved_archive_file,\r\n   2526         cache_dir=cache_dir,\r\
          \n   2527         force_download=force_download,\r\n   2528         proxies=proxies,\r\
          \n   2529         resume_download=resume_download,\r\n   2530         local_files_only=local_files_only,\r\
          \n   2531         use_auth_token=use_auth_token,\r\n   2532         user_agent=user_agent,\r\
          \n   2533         revision=revision,\r\n   2534         subfolder=subfolder,\r\
          \n   2535         _commit_hash=commit_hash,\r\n   2536     )\r\n   2538\
          \ # load pt weights early so that we know which dtype to init the model\
          \ under\r\n   2539 if from_pt:\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/utils/hub.py:934,\
          \ in get_checkpoint_shard_files(pretrained_model_name_or_path, index_filename,\
          \ cache_dir, force_download, proxies, resume_download, local_files_only,\
          \ use_auth_token, user_agent, revision, subfolder, _commit_hash)\r\n   \
          \ 931 for shard_filename in tqdm(shard_filenames, desc=\"Downloading shards\"\
          , disable=not show_progress_bar):\r\n    932     try:\r\n    933       \
          \  # Load from URL\r\n--> 934         cached_filename = cached_file(\r\n\
          \    935             pretrained_model_name_or_path,\r\n    936         \
          \    shard_filename,\r\n    937             cache_dir=cache_dir,\r\n   \
          \ 938             force_download=force_download,\r\n    939            \
          \ proxies=proxies,\r\n    940             resume_download=resume_download,\r\
          \n    941             local_files_only=local_files_only,\r\n    942    \
          \         use_auth_token=use_auth_token,\r\n    943             user_agent=user_agent,\r\
          \n    944             revision=revision,\r\n    945             subfolder=subfolder,\r\
          \n    946             _commit_hash=_commit_hash,\r\n    947         )\r\n\
          \    948     # We have already dealt with RepositoryNotFoundError and RevisionNotFoundError\
          \ when getting the index, so\r\n    949     # we don't have to catch them\
          \ here.\r\n    950     except EntryNotFoundError:\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/utils/hub.py:417,\
          \ in cached_file(path_or_repo_id, filename, cache_dir, force_download, resume_download,\
          \ proxies, use_auth_token, revision, local_files_only, subfolder, repo_type,\
          \ user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors,\
          \ _commit_hash)\r\n    414 user_agent = http_user_agent(user_agent)\r\n\
          \    415 try:\r\n    416     # Load from URL or cache if already cached\r\
          \n--> 417     resolved_file = hf_hub_download(\r\n    418         path_or_repo_id,\r\
          \n    419         filename,\r\n    420         subfolder=None if len(subfolder)\
          \ == 0 else subfolder,\r\n    421         repo_type=repo_type,\r\n    422\
          \         revision=revision,\r\n    423         cache_dir=cache_dir,\r\n\
          \    424         user_agent=user_agent,\r\n    425         force_download=force_download,\r\
          \n    426         proxies=proxies,\r\n    427         resume_download=resume_download,\r\
          \n    428         use_auth_token=use_auth_token,\r\n    429         local_files_only=local_files_only,\r\
          \n    430     )\r\n    432 except RepositoryNotFoundError:\r\n    433  \
          \   raise EnvironmentError(\r\n    434         f\"{path_or_repo_id} is not\
          \ a local folder and is not a valid model identifier \"\r\n    435     \
          \    \"listed on 'https://huggingface.co/models'\\nIf this is a private\
          \ repository, make sure to \"\r\n    436         \"pass a token having permission\
          \ to this repo with `use_auth_token` or log in with \"\r\n    437      \
          \   \"`huggingface-cli login` and pass `use_auth_token=True`.\"\r\n    438\
          \     )\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:120,\
          \ in validate_hf_hub_args.<locals>._inner_fn(*args, **kwargs)\r\n    117\
          \ if check_use_auth_token:\r\n    118     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.__name__,\
          \ has_token=has_token, kwargs=kwargs)\r\n--> 120 return fn(*args, **kwargs)\r\
          \n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1364,\
          \ in hf_hub_download(repo_id, filename, subfolder, repo_type, revision,\
          \ library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks,\
          \ user_agent, force_download, force_filename, proxies, etag_timeout, resume_download,\
          \ token, local_files_only, legacy_cache_layout)\r\n   1361 with temp_file_manager()\
          \ as temp_file:\r\n   1362     logger.info(\"downloading %s to %s\", url,\
          \ temp_file.name)\r\n-> 1364     http_get(\r\n   1365         url_to_download,\r\
          \n   1366         temp_file,\r\n   1367         proxies=proxies,\r\n   1368\
          \         resume_size=resume_size,\r\n   1369         headers=headers,\r\
          \n   1370         expected_size=expected_size,\r\n   1371     )\r\n   1373\
          \ if local_dir is None:\r\n   1374     logger.info(f\"Storing {url} in cache\
          \ at {blob_path}\")\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/huggingface_hub/file_download.py:544,\
          \ in http_get(url, temp_file, proxies, resume_size, headers, timeout, max_retries,\
          \ expected_size)\r\n    542     if chunk:  # filter out keep-alive new chunks\r\
          \n    543         progress.update(len(chunk))\r\n--> 544         temp_file.write(chunk)\r\
          \n    546 if expected_size is not None and expected_size != temp_file.tell():\r\
          \n    547     raise EnvironmentError(\r\n    548         f\"Consistency\
          \ check failed: file should be of size {expected_size} but has size\"\r\n\
          \    549         f\" {temp_file.tell()} ({displayed_name}).\\nWe are sorry\
          \ for the inconvenience. Please retry download and\"\r\n    550        \
          \ \" pass `force_download=True, resume_download=False` as argument.\\nIf\
          \ the issue persists, please let us\"\r\n    551         \" know by opening\
          \ an issue on https://github.com/huggingface/huggingface_hub.\"\r\n    552\
          \     )\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/tempfile.py:483,\
          \ in _TemporaryFileWrapper.__getattr__.<locals>.func_wrapper(*args, **kwargs)\r\
          \n    481 @_functools.wraps(func)\r\n    482 def func_wrapper(*args, **kwargs):\r\
          \n--> 483     return func(*args, **kwargs)\r\n\r\nOSError: [Errno 28] No\
          \ space left on device"
        updatedAt: '2023-05-29T07:37:01.654Z'
      numEdits: 0
      reactions: []
    id: 6474561dd815855e4ef37e52
    type: comment
  author: Dipankar1415
  content: "Getting out of space for bigscience/bloom deployment on sagemaker even\
    \ with 1 TB space and instance ml.m5.24xlarge at the following step\r\nmodel =\
    \ AutoModelForCausalLM.from_pretrained(\r\n    \"bigscience/bloom\",\r\n    device_map=\"\
    auto\",\r\n    torch_dtype=\"auto\"\r\n)\r\n\r\nError:\r\nDownloading (\u2026\
    )lve/main/config.json:   0%|          | 0.00/573 [00:00<?, ?B/s]\r\n----\r\n---------------------------------------------------------------------------\r\
    \nOSError                                   Traceback (most recent call last)\r\
    \nCell In[5], line 1\r\n----> 1 model = AutoModelForCausalLM.from_pretrained(\r\
    \n      2     \"bigscience/bloom\",\r\n      3     device_map=\"auto\",\r\n  \
    \    4     torch_dtype=\"auto\"\r\n      5 )\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:467,\
    \ in _BaseAutoModelClass.from_pretrained(cls, pretrained_model_name_or_path, *model_args,\
    \ **kwargs)\r\n    465 elif type(config) in cls._model_mapping.keys():\r\n   \
    \ 466     model_class = _get_model_class(config, cls._model_mapping)\r\n--> 467\
    \     return model_class.from_pretrained(\r\n    468         pretrained_model_name_or_path,\
    \ *model_args, config=config, **hub_kwargs, **kwargs\r\n    469     )\r\n    470\
    \ raise ValueError(\r\n    471     f\"Unrecognized configuration class {config.__class__}\
    \ for this kind of AutoModel: {cls.__name__}.\\n\"\r\n    472     f\"Model type\
    \ should be one of {', '.join(c.__name__ for c in cls._model_mapping.keys())}.\"\
    \r\n    473 )\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/modeling_utils.py:2523,\
    \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path, *model_args,\
    \ **kwargs)\r\n   2520 # We'll need to download and cache each checkpoint shard\
    \ if the checkpoint is sharded.\r\n   2521 if is_sharded:\r\n   2522     # rsolved_archive_file\
    \ becomes a list of files that point to the different checkpoint shards in this\
    \ case.\r\n-> 2523     resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\r\
    \n   2524         pretrained_model_name_or_path,\r\n   2525         resolved_archive_file,\r\
    \n   2526         cache_dir=cache_dir,\r\n   2527         force_download=force_download,\r\
    \n   2528         proxies=proxies,\r\n   2529         resume_download=resume_download,\r\
    \n   2530         local_files_only=local_files_only,\r\n   2531         use_auth_token=use_auth_token,\r\
    \n   2532         user_agent=user_agent,\r\n   2533         revision=revision,\r\
    \n   2534         subfolder=subfolder,\r\n   2535         _commit_hash=commit_hash,\r\
    \n   2536     )\r\n   2538 # load pt weights early so that we know which dtype\
    \ to init the model under\r\n   2539 if from_pt:\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/utils/hub.py:934,\
    \ in get_checkpoint_shard_files(pretrained_model_name_or_path, index_filename,\
    \ cache_dir, force_download, proxies, resume_download, local_files_only, use_auth_token,\
    \ user_agent, revision, subfolder, _commit_hash)\r\n    931 for shard_filename\
    \ in tqdm(shard_filenames, desc=\"Downloading shards\", disable=not show_progress_bar):\r\
    \n    932     try:\r\n    933         # Load from URL\r\n--> 934         cached_filename\
    \ = cached_file(\r\n    935             pretrained_model_name_or_path,\r\n   \
    \ 936             shard_filename,\r\n    937             cache_dir=cache_dir,\r\
    \n    938             force_download=force_download,\r\n    939             proxies=proxies,\r\
    \n    940             resume_download=resume_download,\r\n    941            \
    \ local_files_only=local_files_only,\r\n    942             use_auth_token=use_auth_token,\r\
    \n    943             user_agent=user_agent,\r\n    944             revision=revision,\r\
    \n    945             subfolder=subfolder,\r\n    946             _commit_hash=_commit_hash,\r\
    \n    947         )\r\n    948     # We have already dealt with RepositoryNotFoundError\
    \ and RevisionNotFoundError when getting the index, so\r\n    949     # we don't\
    \ have to catch them here.\r\n    950     except EntryNotFoundError:\r\n\r\nFile\
    \ ~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/utils/hub.py:417,\
    \ in cached_file(path_or_repo_id, filename, cache_dir, force_download, resume_download,\
    \ proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent,\
    \ _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors,\
    \ _commit_hash)\r\n    414 user_agent = http_user_agent(user_agent)\r\n    415\
    \ try:\r\n    416     # Load from URL or cache if already cached\r\n--> 417  \
    \   resolved_file = hf_hub_download(\r\n    418         path_or_repo_id,\r\n \
    \   419         filename,\r\n    420         subfolder=None if len(subfolder)\
    \ == 0 else subfolder,\r\n    421         repo_type=repo_type,\r\n    422    \
    \     revision=revision,\r\n    423         cache_dir=cache_dir,\r\n    424  \
    \       user_agent=user_agent,\r\n    425         force_download=force_download,\r\
    \n    426         proxies=proxies,\r\n    427         resume_download=resume_download,\r\
    \n    428         use_auth_token=use_auth_token,\r\n    429         local_files_only=local_files_only,\r\
    \n    430     )\r\n    432 except RepositoryNotFoundError:\r\n    433     raise\
    \ EnvironmentError(\r\n    434         f\"{path_or_repo_id} is not a local folder\
    \ and is not a valid model identifier \"\r\n    435         \"listed on 'https://huggingface.co/models'\\\
    nIf this is a private repository, make sure to \"\r\n    436         \"pass a\
    \ token having permission to this repo with `use_auth_token` or log in with \"\
    \r\n    437         \"`huggingface-cli login` and pass `use_auth_token=True`.\"\
    \r\n    438     )\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:120,\
    \ in validate_hf_hub_args.<locals>._inner_fn(*args, **kwargs)\r\n    117 if check_use_auth_token:\r\
    \n    118     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.__name__,\
    \ has_token=has_token, kwargs=kwargs)\r\n--> 120 return fn(*args, **kwargs)\r\n\
    \r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1364,\
    \ in hf_hub_download(repo_id, filename, subfolder, repo_type, revision, library_name,\
    \ library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download,\
    \ force_filename, proxies, etag_timeout, resume_download, token, local_files_only,\
    \ legacy_cache_layout)\r\n   1361 with temp_file_manager() as temp_file:\r\n \
    \  1362     logger.info(\"downloading %s to %s\", url, temp_file.name)\r\n-> 1364\
    \     http_get(\r\n   1365         url_to_download,\r\n   1366         temp_file,\r\
    \n   1367         proxies=proxies,\r\n   1368         resume_size=resume_size,\r\
    \n   1369         headers=headers,\r\n   1370         expected_size=expected_size,\r\
    \n   1371     )\r\n   1373 if local_dir is None:\r\n   1374     logger.info(f\"\
    Storing {url} in cache at {blob_path}\")\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/huggingface_hub/file_download.py:544,\
    \ in http_get(url, temp_file, proxies, resume_size, headers, timeout, max_retries,\
    \ expected_size)\r\n    542     if chunk:  # filter out keep-alive new chunks\r\
    \n    543         progress.update(len(chunk))\r\n--> 544         temp_file.write(chunk)\r\
    \n    546 if expected_size is not None and expected_size != temp_file.tell():\r\
    \n    547     raise EnvironmentError(\r\n    548         f\"Consistency check\
    \ failed: file should be of size {expected_size} but has size\"\r\n    549   \
    \      f\" {temp_file.tell()} ({displayed_name}).\\nWe are sorry for the inconvenience.\
    \ Please retry download and\"\r\n    550         \" pass `force_download=True,\
    \ resume_download=False` as argument.\\nIf the issue persists, please let us\"\
    \r\n    551         \" know by opening an issue on https://github.com/huggingface/huggingface_hub.\"\
    \r\n    552     )\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/tempfile.py:483,\
    \ in _TemporaryFileWrapper.__getattr__.<locals>.func_wrapper(*args, **kwargs)\r\
    \n    481 @_functools.wraps(func)\r\n    482 def func_wrapper(*args, **kwargs):\r\
    \n--> 483     return func(*args, **kwargs)\r\n\r\nOSError: [Errno 28] No space\
    \ left on device"
  created_at: 2023-05-29 06:37:01+00:00
  edited: false
  hidden: false
  id: 6474561dd815855e4ef37e52
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 251
repo_id: bigscience/bloom
repo_type: model
status: open
target_branch: null
title: Getting out of space for bigscience/bloom deployment on sagemaker
