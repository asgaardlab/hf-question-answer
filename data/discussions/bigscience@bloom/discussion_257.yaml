!!python/object:huggingface_hub.community.DiscussionWithDetails
author: smcg1579
conflicting_files: null
created_at: 2023-07-05 17:32:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12ea860b1616c7d72955a8453782452e.svg
      fullname: 'Shannon '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: smcg1579
      type: user
    createdAt: '2023-07-05T18:32:41.000Z'
    data:
      edited: false
      editors:
      - smcg1579
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9749902486801147
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12ea860b1616c7d72955a8453782452e.svg
          fullname: 'Shannon '
          isHf: false
          isPro: false
          name: smcg1579
          type: user
        html: '<p>For an experiment I''m working on, we''ve been looking into the
          usage of Bloom as a large language model, but I''m not sure if it is feasible
          for it to work on the computer we have available to us. I''m still fairly
          new to LLMs, so I''m not sure how I can measure the capabilities against
          our computer. For the purposes of the experiment we don''t need anything
          high-speed, and figure if we can get the model working to return query results
          after one or two days that works for us. We are working with a Nvidia RTX
          A5000 GPU and 128GB RAM, so I was just wondering if bloom would be at all
          feasible or if we should consider other options. Thanks!</p>

          '
        raw: For an experiment I'm working on, we've been looking into the usage of
          Bloom as a large language model, but I'm not sure if it is feasible for
          it to work on the computer we have available to us. I'm still fairly new
          to LLMs, so I'm not sure how I can measure the capabilities against our
          computer. For the purposes of the experiment we don't need anything high-speed,
          and figure if we can get the model working to return query results after
          one or two days that works for us. We are working with a Nvidia RTX A5000
          GPU and 128GB RAM, so I was just wondering if bloom would be at all feasible
          or if we should consider other options. Thanks!
        updatedAt: '2023-07-05T18:32:41.486Z'
      numEdits: 0
      reactions: []
    id: 64a5b749f8e6f96ca6b839b2
    type: comment
  author: smcg1579
  content: For an experiment I'm working on, we've been looking into the usage of
    Bloom as a large language model, but I'm not sure if it is feasible for it to
    work on the computer we have available to us. I'm still fairly new to LLMs, so
    I'm not sure how I can measure the capabilities against our computer. For the
    purposes of the experiment we don't need anything high-speed, and figure if we
    can get the model working to return query results after one or two days that works
    for us. We are working with a Nvidia RTX A5000 GPU and 128GB RAM, so I was just
    wondering if bloom would be at all feasible or if we should consider other options.
    Thanks!
  created_at: 2023-07-05 17:32:41+00:00
  edited: false
  hidden: false
  id: 64a5b749f8e6f96ca6b839b2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/12ea860b1616c7d72955a8453782452e.svg
      fullname: 'Shannon '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: smcg1579
      type: user
    createdAt: '2023-07-07T15:12:59.000Z'
    data:
      from: Bloom GPU Requirements
      to: Can I use Bloom on an a5000 GPU?
    id: 64a82b7b3e6b928e11531bcc
    type: title-change
  author: smcg1579
  created_at: 2023-07-07 14:12:59+00:00
  id: 64a82b7b3e6b928e11531bcc
  new_title: Can I use Bloom on an a5000 GPU?
  old_title: Bloom GPU Requirements
  type: title-change
is_pull_request: false
merge_commit_oid: null
num: 257
repo_id: bigscience/bloom
repo_type: model
status: open
target_branch: null
title: Can I use Bloom on an a5000 GPU?
