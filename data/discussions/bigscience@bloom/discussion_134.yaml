!!python/object:huggingface_hub.community.DiscussionWithDetails
author: XiangD-OSU
conflicting_files: null
created_at: 2022-11-04 13:40:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1dbc89402c7e38eb131d43dbc28022ab.svg
      fullname: Xiang Deng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: XiangD-OSU
      type: user
    createdAt: '2022-11-04T14:40:16.000Z'
    data:
      edited: false
      editors:
      - XiangD-OSU
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1dbc89402c7e38eb131d43dbc28022ab.svg
          fullname: Xiang Deng
          isHf: false
          isPro: false
          name: XiangD-OSU
          type: user
        html: '<p>The hosted inference API mentions "The model is loaded and running
          on Intel Xeon Ice Lake CPU." and seems the latency is surprisingly low.
          Does anyone has pointers to where I could find more information about deploying
          to CPU only environment, or actually the service is still hosted with GPUs?</p>

          '
        raw: The hosted inference API mentions "The model is loaded and running on
          Intel Xeon Ice Lake CPU." and seems the latency is surprisingly low. Does
          anyone has pointers to where I could find more information about deploying
          to CPU only environment, or actually the service is still hosted with GPUs?
        updatedAt: '2022-11-04T14:40:16.334Z'
      numEdits: 0
      reactions: []
    id: 6365245025aa3bd177cf509b
    type: comment
  author: XiangD-OSU
  content: The hosted inference API mentions "The model is loaded and running on Intel
    Xeon Ice Lake CPU." and seems the latency is surprisingly low. Does anyone has
    pointers to where I could find more information about deploying to CPU only environment,
    or actually the service is still hosted with GPUs?
  created_at: 2022-11-04 13:40:16+00:00
  edited: false
  hidden: false
  id: 6365245025aa3bd177cf509b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
      fullname: Thomas Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: TimeRobber
      type: user
    createdAt: '2022-11-04T18:11:44.000Z'
    data:
      edited: false
      editors:
      - TimeRobber
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
          fullname: Thomas Wang
          isHf: false
          isPro: false
          name: TimeRobber
          type: user
        html: "<p>This service is hosted on GPUs. I don't think you'll be able to\
          \ run inference at that scale on CPUs. <span data-props=\"{&quot;user&quot;:&quot;Narsil&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Narsil\"\
          >@<span class=\"underline\">Narsil</span></a></span>\n\n\t</span></span>\
          \ wrote a great blog on how we deployed it <a href=\"https://huggingface.co/blog/bloom-inference-optimization\"\
          >https://huggingface.co/blog/bloom-inference-optimization</a></p>\n"
        raw: This service is hosted on GPUs. I don't think you'll be able to run inference
          at that scale on CPUs. @Narsil wrote a great blog on how we deployed it
          https://huggingface.co/blog/bloom-inference-optimization
        updatedAt: '2022-11-04T18:11:44.640Z'
      numEdits: 0
      reactions: []
    id: 636555e0daa65e06f90d3c41
    type: comment
  author: TimeRobber
  content: This service is hosted on GPUs. I don't think you'll be able to run inference
    at that scale on CPUs. @Narsil wrote a great blog on how we deployed it https://huggingface.co/blog/bloom-inference-optimization
  created_at: 2022-11-04 17:11:44+00:00
  edited: false
  hidden: false
  id: 636555e0daa65e06f90d3c41
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
      fullname: Christopher Akiki
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: cakiki
      type: user
    createdAt: '2022-11-05T09:48:23.000Z'
    data:
      edited: false
      editors:
      - cakiki
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
          fullname: Christopher Akiki
          isHf: false
          isPro: false
          name: cakiki
          type: user
        html: '<p>Also, thank you for noticing the GUI bug! It''s being taken care
          of: <a rel="nofollow" href="https://github.com/huggingface/hub-docs/pull/477">https://github.com/huggingface/hub-docs/pull/477</a></p>

          '
        raw: 'Also, thank you for noticing the GUI bug! It''s being taken care of:
          https://github.com/huggingface/hub-docs/pull/477'
        updatedAt: '2022-11-05T09:48:23.329Z'
      numEdits: 0
      reactions: []
      relatedEventId: 63663167575c93cedaff889e
    id: 63663167575c93cedaff889d
    type: comment
  author: cakiki
  content: 'Also, thank you for noticing the GUI bug! It''s being taken care of: https://github.com/huggingface/hub-docs/pull/477'
  created_at: 2022-11-05 08:48:23+00:00
  edited: false
  hidden: false
  id: 63663167575c93cedaff889d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
      fullname: Christopher Akiki
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: cakiki
      type: user
    createdAt: '2022-11-05T09:48:23.000Z'
    data:
      status: closed
    id: 63663167575c93cedaff889e
    type: status-change
  author: cakiki
  created_at: 2022-11-05 08:48:23+00:00
  id: 63663167575c93cedaff889e
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 134
repo_id: bigscience/bloom
repo_type: model
status: closed
target_branch: null
title: Question about inference on CPU
