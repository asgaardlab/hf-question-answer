!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bicx
conflicting_files: null
created_at: 2023-01-30 02:53:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0da8fc3032cebdada3c9dc5158b1ac7d.svg
      fullname: Brian Bowden
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bicx
      type: user
    createdAt: '2023-01-30T02:53:36.000Z'
    data:
      edited: true
      editors:
      - bicx
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0da8fc3032cebdada3c9dc5158b1ac7d.svg
          fullname: Brian Bowden
          isHf: false
          isPro: false
          name: bicx
          type: user
        html: '<p>I have been receiving the error "Model is overloaded, please wait
          for a bit" every time I''ve tried using the bloom Inference API in the last
          16 hours. I''m a new user (Pro plan, if that makes any difference) trying
          to get started, and I haven''t yet made a successful API call. Is there
          anything that commonly triggers this error, or is this a true overload?</p>

          '
        raw: I have been receiving the error "Model is overloaded, please wait for
          a bit" every time I've tried using the bloom Inference API in the last 16
          hours. I'm a new user (Pro plan, if that makes any difference) trying to
          get started, and I haven't yet made a successful API call. Is there anything
          that commonly triggers this error, or is this a true overload?
        updatedAt: '2023-01-30T02:53:50.819Z'
      numEdits: 1
      reactions: []
    id: 63d731302e397d9f8e2e2c23
    type: comment
  author: bicx
  content: I have been receiving the error "Model is overloaded, please wait for a
    bit" every time I've tried using the bloom Inference API in the last 16 hours.
    I'm a new user (Pro plan, if that makes any difference) trying to get started,
    and I haven't yet made a successful API call. Is there anything that commonly
    triggers this error, or is this a true overload?
  created_at: 2023-01-30 02:53:36+00:00
  edited: true
  hidden: false
  id: 63d731302e397d9f8e2e2c23
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
      fullname: Thomas Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: TimeRobber
      type: user
    createdAt: '2023-01-30T07:33:12.000Z'
    data:
      edited: false
      editors:
      - TimeRobber
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
          fullname: Thomas Wang
          isHf: false
          isPro: false
          name: TimeRobber
          type: user
        html: '<p>I just tried it and it seems fine</p>

          '
        raw: I just tried it and it seems fine
        updatedAt: '2023-01-30T07:33:12.307Z'
      numEdits: 0
      reactions: []
    id: 63d772b803f2eb32f47d8367
    type: comment
  author: TimeRobber
  content: I just tried it and it seems fine
  created_at: 2023-01-30 07:33:12+00:00
  edited: false
  hidden: false
  id: 63d772b803f2eb32f47d8367
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 179
repo_id: bigscience/bloom
repo_type: model
status: open
target_branch: null
title: Bloom Inference API has been reporting as overloaded all day (1/29/23)
