!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Eloop
conflicting_files: null
created_at: 2022-08-15 07:01:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660506037713-noauth.jpeg?w=200&h=200&f=face
      fullname: Mads Voigt Hingelberg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Eloop
      type: user
    createdAt: '2022-08-15T08:01:48.000Z'
    data:
      edited: false
      editors:
      - Eloop
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660506037713-noauth.jpeg?w=200&h=200&f=face
          fullname: Mads Voigt Hingelberg
          isHf: false
          isPro: false
          name: Eloop
          type: user
        html: '<p>Hi Guys.<br>I have looked everywhere but cannot seem to resolve
          this.</p>

          <p>My code is:</p>

          <hr>

          <p>from transformers import AutoTokenizer, AutoModel<br>from transformers
          import BloomForTokenClassification<br>from transformers import BloomForTokenClassification<br>from
          transformers import BloomTokenizerFast</p>

          <p>tokenizer = AutoTokenizer.from_pretrained("bigscience/bloom-560m")<br>model
          = AutoModel.from_pretrained("bigscience/bloom-560m")</p>

          <p>prompt = "It was a dark and stormy night"<br>result_length = 50<br>inputs
          = tokenizer(prompt, return_tensors="pt")</p>

          <p>tokenout = model.generate(inputs["input_ids"], max_length=result_length)[0]</p>

          <hr>

          <p>I get the below error in the line:  tokenout = model.generate(inputs["input_ids"],
          max_length=result_length)[0]</p>

          <p>Exception has occurred: AttributeError<br>''BaseModelOutputWithPastAndCrossAttentions''
          object has no attribute ''logits''<br>  File "C:\TF_Test\BLOOM\brewstory.py",
          line 13, in <br>    tokenout = model.generate(inputs["input_ids"], max_length=result_length)[0]</p>

          <p>Any suggestions are welcome. It seems to work if I use the GPT-2 model,
          just fine so it must be some additional parameters I''m not setting properly?</p>

          '
        raw: "Hi Guys. \r\nI have looked everywhere but cannot seem to resolve this.\r\
          \n\r\nMy code is:\r\n_______________________________________________\r\n\
          from transformers import AutoTokenizer, AutoModel\r\nfrom transformers import\
          \ BloomForTokenClassification\r\nfrom transformers import BloomForTokenClassification\r\
          \nfrom transformers import BloomTokenizerFast\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
          bigscience/bloom-560m\")\r\nmodel = AutoModel.from_pretrained(\"bigscience/bloom-560m\"\
          )\r\n\r\nprompt = \"It was a dark and stormy night\"\r\nresult_length =\
          \ 50\r\ninputs = tokenizer(prompt, return_tensors=\"pt\")\r\n\r\ntokenout\
          \ = model.generate(inputs[\"input_ids\"], max_length=result_length)[0]\r\
          \n\r\n___________________________________________________________________________________\r\
          \nI get the below error in the line:  tokenout = model.generate(inputs[\"\
          input_ids\"], max_length=result_length)[0]\r\n\r\nException has occurred:\
          \ AttributeError\r\n'BaseModelOutputWithPastAndCrossAttentions' object has\
          \ no attribute 'logits'\r\n  File \"C:\\TF_Test\\BLOOM\\brewstory.py\",\
          \ line 13, in <module>\r\n    tokenout = model.generate(inputs[\"input_ids\"\
          ], max_length=result_length)[0]\r\n\r\nAny suggestions are welcome. It seems\
          \ to work if I use the GPT-2 model, just fine so it must be some additional\
          \ parameters I'm not setting properly?\r\n\r\n\r\n\t"
        updatedAt: '2022-08-15T08:01:48.902Z'
      numEdits: 0
      reactions: []
    id: 62f9fd6c15e8b4d65a3409ad
    type: comment
  author: Eloop
  content: "Hi Guys. \r\nI have looked everywhere but cannot seem to resolve this.\r\
    \n\r\nMy code is:\r\n_______________________________________________\r\nfrom transformers\
    \ import AutoTokenizer, AutoModel\r\nfrom transformers import BloomForTokenClassification\r\
    \nfrom transformers import BloomForTokenClassification\r\nfrom transformers import\
    \ BloomTokenizerFast\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-560m\"\
    )\r\nmodel = AutoModel.from_pretrained(\"bigscience/bloom-560m\")\r\n\r\nprompt\
    \ = \"It was a dark and stormy night\"\r\nresult_length = 50\r\ninputs = tokenizer(prompt,\
    \ return_tensors=\"pt\")\r\n\r\ntokenout = model.generate(inputs[\"input_ids\"\
    ], max_length=result_length)[0]\r\n\r\n___________________________________________________________________________________\r\
    \nI get the below error in the line:  tokenout = model.generate(inputs[\"input_ids\"\
    ], max_length=result_length)[0]\r\n\r\nException has occurred: AttributeError\r\
    \n'BaseModelOutputWithPastAndCrossAttentions' object has no attribute 'logits'\r\
    \n  File \"C:\\TF_Test\\BLOOM\\brewstory.py\", line 13, in <module>\r\n    tokenout\
    \ = model.generate(inputs[\"input_ids\"], max_length=result_length)[0]\r\n\r\n\
    Any suggestions are welcome. It seems to work if I use the GPT-2 model, just fine\
    \ so it must be some additional parameters I'm not setting properly?\r\n\r\n\r\
    \n\t"
  created_at: 2022-08-15 07:01:48+00:00
  edited: false
  hidden: false
  id: 62f9fd6c15e8b4d65a3409ad
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2022-08-15T09:51:01.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: "<p>For generation, you want to use the model with the language modelling\
          \ head \U0001F607</p>\n<pre><code class=\"language-python\"><span class=\"\
          hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span>\
          \ AutoTokenizer, AutoModelForCausalLM\n<span class=\"hljs-keyword\">from</span>\
          \ transformers <span class=\"hljs-keyword\">import</span> BloomForTokenClassification\n\
          <span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\"\
          >import</span> BloomForTokenClassification\n<span class=\"hljs-keyword\"\
          >from</span> transformers <span class=\"hljs-keyword\">import</span> BloomTokenizerFast\n\
          \ntokenizer = AutoTokenizer.from_pretrained(<span class=\"hljs-string\"\
          >\"bigscience/bloom-560m\"</span>)\nmodel = AutoModelForCausalLM.from_pretrained(<span\
          \ class=\"hljs-string\">\"bigscience/bloom-560m\"</span>)\n\nprompt = <span\
          \ class=\"hljs-string\">\"It was a dark and stormy night\"</span>\nresult_length\
          \ = <span class=\"hljs-number\">50</span>\ninputs = tokenizer(prompt, return_tensors=<span\
          \ class=\"hljs-string\">\"pt\"</span>)\n\ntokenout = model.generate(inputs[<span\
          \ class=\"hljs-string\">\"input_ids\"</span>], max_length=result_length)\n\
          </code></pre>\n"
        raw: "For generation, you want to use the model with the language modelling\
          \ head \U0001F607\n\n```python\nfrom transformers import AutoTokenizer,\
          \ AutoModelForCausalLM\nfrom transformers import BloomForTokenClassification\n\
          from transformers import BloomForTokenClassification\nfrom transformers\
          \ import BloomTokenizerFast\n\ntokenizer = AutoTokenizer.from_pretrained(\"\
          bigscience/bloom-560m\")\nmodel = AutoModelForCausalLM.from_pretrained(\"\
          bigscience/bloom-560m\")\n\nprompt = \"It was a dark and stormy night\"\n\
          result_length = 50\ninputs = tokenizer(prompt, return_tensors=\"pt\")\n\n\
          tokenout = model.generate(inputs[\"input_ids\"], max_length=result_length)\n\
          ```"
        updatedAt: '2022-08-15T09:51:01.473Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\U0001F91D"
        users:
        - ybelkada
        - DaGoodDoctor
        - staracc
        - Walker
      - count: 1
        reaction: "\U0001F614"
        users:
        - mathxh
    id: 62fa1705363251ee40a18247
    type: comment
  author: Muennighoff
  content: "For generation, you want to use the model with the language modelling\
    \ head \U0001F607\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\
    from transformers import BloomForTokenClassification\nfrom transformers import\
    \ BloomForTokenClassification\nfrom transformers import BloomTokenizerFast\n\n\
    tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-560m\")\nmodel =\
    \ AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n\nprompt =\
    \ \"It was a dark and stormy night\"\nresult_length = 50\ninputs = tokenizer(prompt,\
    \ return_tensors=\"pt\")\n\ntokenout = model.generate(inputs[\"input_ids\"], max_length=result_length)\n\
    ```"
  created_at: 2022-08-15 08:51:01+00:00
  edited: false
  hidden: false
  id: 62fa1705363251ee40a18247
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
      fullname: Thomas Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: TimeRobber
      type: user
    createdAt: '2023-01-27T07:47:52.000Z'
    data:
      status: closed
    id: 63d381a85507ec44cd9e6ca4
    type: status-change
  author: TimeRobber
  created_at: 2023-01-27 07:47:52+00:00
  id: 63d381a85507ec44cd9e6ca4
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 83
repo_id: bigscience/bloom
repo_type: model
status: closed
target_branch: null
title: Error while running simple example PLEASE help
