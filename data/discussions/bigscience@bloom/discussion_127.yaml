!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mishavee
conflicting_files: null
created_at: 2022-10-22 17:14:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
      fullname: Mike Vinitsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mishavee
      type: user
    createdAt: '2022-10-22T18:14:08.000Z'
    data:
      edited: false
      editors:
      - mishavee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
          fullname: Mike Vinitsky
          isHf: false
          isPro: false
          name: mishavee
          type: user
        html: '<ol>

          <li><p>How large is Bloom exactly to load all the checkpoints into gpu ram?
          </p>

          </li>

          <li><p>How large of gpu ram would be needed to load all the checkpoints
          and fine tune it?</p>

          </li>

          </ol>

          '
        raw: "1. How large is Bloom exactly to load all the checkpoints into gpu ram?\
          \ \r\n\r\n2. How large of gpu ram would be needed to load all the checkpoints\
          \ and fine tune it? "
        updatedAt: '2022-10-22T18:14:08.092Z'
      numEdits: 0
      reactions: []
    id: 635432f0b8aa3b0b3ebcd42a
    type: comment
  author: mishavee
  content: "1. How large is Bloom exactly to load all the checkpoints into gpu ram?\
    \ \r\n\r\n2. How large of gpu ram would be needed to load all the checkpoints\
    \ and fine tune it? "
  created_at: 2022-10-22 17:14:08+00:00
  edited: false
  hidden: false
  id: 635432f0b8aa3b0b3ebcd42a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
      fullname: Thomas Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: TimeRobber
      type: user
    createdAt: '2022-10-23T09:16:26.000Z'
    data:
      edited: false
      editors:
      - TimeRobber
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
          fullname: Thomas Wang
          isHf: false
          isPro: false
          name: TimeRobber
          type: user
        html: "<blockquote>\n<p>How large is Bloom exactly to load all the checkpoints\
          \ into gpu ram?</p>\n</blockquote>\n<p>You need 352G of GPU ram to load\
          \ the weights in bfloat16 in GPUs.</p>\n<blockquote>\n<p>How large of gpu\
          \ ram would be needed to load all the checkpoints and fine tune it?</p>\n\
          </blockquote>\n<p>You never need to load all the checkpoints at once ...\
          \ if you want to finetune you have to take in account optimizer states.\
          \ Luckily you can try using DeepSpeed zero offload, it essentially moves\
          \ the memory footprint to other spaces (either CPU RAM or Disk). <span data-props=\"\
          {&quot;user&quot;:&quot;stas&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/stas\">@<span class=\"underline\">stas</span></a></span>\n\
          \n\t</span></span> has written a great documentation about how to use it\
          \ in transformers <a href=\"https://huggingface.co/docs/transformers/main_classes/deepspeed\"\
          >https://huggingface.co/docs/transformers/main_classes/deepspeed</a></p>\n"
        raw: '> How large is Bloom exactly to load all the checkpoints into gpu ram?


          You need 352G of GPU ram to load the weights in bfloat16 in GPUs.


          > How large of gpu ram would be needed to load all the checkpoints and fine
          tune it?


          You never need to load all the checkpoints at once ... if you want to finetune
          you have to take in account optimizer states. Luckily you can try using
          DeepSpeed zero offload, it essentially moves the memory footprint to other
          spaces (either CPU RAM or Disk). @stas has written a great documentation
          about how to use it in transformers https://huggingface.co/docs/transformers/main_classes/deepspeed'
        updatedAt: '2022-10-23T09:16:26.188Z'
      numEdits: 0
      reactions: []
    id: 6355066a70babb7a4a54cec1
    type: comment
  author: TimeRobber
  content: '> How large is Bloom exactly to load all the checkpoints into gpu ram?


    You need 352G of GPU ram to load the weights in bfloat16 in GPUs.


    > How large of gpu ram would be needed to load all the checkpoints and fine tune
    it?


    You never need to load all the checkpoints at once ... if you want to finetune
    you have to take in account optimizer states. Luckily you can try using DeepSpeed
    zero offload, it essentially moves the memory footprint to other spaces (either
    CPU RAM or Disk). @stas has written a great documentation about how to use it
    in transformers https://huggingface.co/docs/transformers/main_classes/deepspeed'
  created_at: 2022-10-23 08:16:26+00:00
  edited: false
  hidden: false
  id: 6355066a70babb7a4a54cec1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
      fullname: Mike Vinitsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mishavee
      type: user
    createdAt: '2022-10-23T22:24:12.000Z'
    data:
      edited: true
      editors:
      - mishavee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
          fullname: Mike Vinitsky
          isHf: false
          isPro: false
          name: mishavee
          type: user
        html: '<p>so what is the least amount of A100 80gb gpus I need if I use deepspeed
          zero offload?</p>

          '
        raw: so what is the least amount of A100 80gb gpus I need if I use deepspeed
          zero offload?
        updatedAt: '2022-10-23T22:24:42.460Z'
      numEdits: 1
      reactions: []
    id: 6355bf0c70babb7a4a59d583
    type: comment
  author: mishavee
  content: so what is the least amount of A100 80gb gpus I need if I use deepspeed
    zero offload?
  created_at: 2022-10-23 21:24:12+00:00
  edited: true
  hidden: false
  id: 6355bf0c70babb7a4a59d583
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
      fullname: Thomas Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: TimeRobber
      type: user
    createdAt: '2022-10-23T22:59:24.000Z'
    data:
      edited: false
      editors:
      - TimeRobber
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
          fullname: Thomas Wang
          isHf: false
          isPro: false
          name: TimeRobber
          type: user
        html: '<blockquote>

          <p>so what is the least amount of A100 80gb gpus I need if I use deepspeed
          zero offload?</p>

          </blockquote>

          <p>The very minimum is probably going to be 1 A100. It''s going to be very
          slow, but it''s going to run. Offloading just means that it''s going to
          use the CPU memory / disk space as additional memory so that you''re not
          going to go out of memory.</p>

          '
        raw: '> so what is the least amount of A100 80gb gpus I need if I use deepspeed
          zero offload?


          The very minimum is probably going to be 1 A100. It''s going to be very
          slow, but it''s going to run. Offloading just means that it''s going to
          use the CPU memory / disk space as additional memory so that you''re not
          going to go out of memory.'
        updatedAt: '2022-10-23T22:59:24.589Z'
      numEdits: 0
      reactions: []
    id: 6355c74c9c72a7e742f3ec99
    type: comment
  author: TimeRobber
  content: '> so what is the least amount of A100 80gb gpus I need if I use deepspeed
    zero offload?


    The very minimum is probably going to be 1 A100. It''s going to be very slow,
    but it''s going to run. Offloading just means that it''s going to use the CPU
    memory / disk space as additional memory so that you''re not going to go out of
    memory.'
  created_at: 2022-10-23 21:59:24+00:00
  edited: false
  hidden: false
  id: 6355c74c9c72a7e742f3ec99
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 127
repo_id: bigscience/bloom
repo_type: model
status: open
target_branch: null
title: 'How large is Bloom exactly to load all the checkpoints into gpu ram? '
