!!python/object:huggingface_hub.community.DiscussionWithDetails
author: vickyzhang
conflicting_files: null
created_at: 2022-07-18 17:17:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a827dba11510d538ad0590c5fd112f1a.svg
      fullname: Vicky Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vickyzhang
      type: user
    createdAt: '2022-07-18T18:17:06.000Z'
    data:
      edited: false
      editors:
      - vickyzhang
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a827dba11510d538ad0590c5fd112f1a.svg
          fullname: Vicky Zhang
          isHf: false
          isPro: false
          name: vickyzhang
          type: user
        html: "<p>I copy pasted the sample code for token classification for aws and\
          \ used it in sagemaker notebook, but got an error.<br>Sample code used:</p>\n\
          <pre><code>from sagemaker.huggingface import HuggingFaceModel\nimport sagemaker\n\
          \nrole = sagemaker.get_execution_role()\n# Hub Model configuration. https://huggingface.co/models\n\
          hub = {\n    'HF_MODEL_ID':'bigscience/bloom',\n    'HF_TASK':'token-classification'\n\
          }\n\n# create Hugging Face Model Class\nhuggingface_model = HuggingFaceModel(\n\
          \    transformers_version='4.17.0',\n    pytorch_version='1.10.2',\n   \
          \ py_version='py38',\n    env=hub,\n    role=role, \n)\n\n# deploy model\
          \ to SageMaker Inference\npredictor = huggingface_model.deploy(\n    initial_instance_count=1,\
          \ # number of instances\n    instance_type='ml.m5.xlarge' # ec2 instance\
          \ type\n)\n\npredictor.predict({\n    'inputs': \"Can you please let us\
          \ know more details about your \"\n})\n</code></pre>\n<p>Error:</p>\n<pre><code>ModelError:\
          \ An error occurred (ModelError) when calling the InvokeEndpoint operation:\
          \ Received client error (400) from primary with message \"{\n  \"code\"\
          : 400,\n  \"type\": \"InternalServerException\",\n  \"message\": \"\\u0027bloom\\\
          u0027\"\n}\n</code></pre>\n<p>Code 400 is invalid request. But it's an exact\
          \ copy paste of the sample code. What could have gone wrong here? Thanks.</p>\n"
        raw: "I copy pasted the sample code for token classification for aws and used\
          \ it in sagemaker notebook, but got an error.\r\nSample code used:\r\n```\r\
          \nfrom sagemaker.huggingface import HuggingFaceModel\r\nimport sagemaker\r\
          \n\r\nrole = sagemaker.get_execution_role()\r\n# Hub Model configuration.\
          \ https://huggingface.co/models\r\nhub = {\r\n\t'HF_MODEL_ID':'bigscience/bloom',\r\
          \n\t'HF_TASK':'token-classification'\r\n}\r\n\r\n# create Hugging Face Model\
          \ Class\r\nhuggingface_model = HuggingFaceModel(\r\n\ttransformers_version='4.17.0',\r\
          \n\tpytorch_version='1.10.2',\r\n\tpy_version='py38',\r\n\tenv=hub,\r\n\t\
          role=role, \r\n)\r\n\r\n# deploy model to SageMaker Inference\r\npredictor\
          \ = huggingface_model.deploy(\r\n\tinitial_instance_count=1, # number of\
          \ instances\r\n\tinstance_type='ml.m5.xlarge' # ec2 instance type\r\n)\r\
          \n\r\npredictor.predict({\r\n\t'inputs': \"Can you please let us know more\
          \ details about your \"\r\n})\r\n```\r\n\r\nError:\r\n```\r\nModelError:\
          \ An error occurred (ModelError) when calling the InvokeEndpoint operation:\
          \ Received client error (400) from primary with message \"{\r\n  \"code\"\
          : 400,\r\n  \"type\": \"InternalServerException\",\r\n  \"message\": \"\\\
          u0027bloom\\u0027\"\r\n}\r\n```\r\n\r\nCode 400 is invalid request. But\
          \ it's an exact copy paste of the sample code. What could have gone wrong\
          \ here? Thanks."
        updatedAt: '2022-07-18T18:17:06.540Z'
      numEdits: 0
      reactions: []
    id: 62d5a3a223656463bdf4ce22
    type: comment
  author: vickyzhang
  content: "I copy pasted the sample code for token classification for aws and used\
    \ it in sagemaker notebook, but got an error.\r\nSample code used:\r\n```\r\n\
    from sagemaker.huggingface import HuggingFaceModel\r\nimport sagemaker\r\n\r\n\
    role = sagemaker.get_execution_role()\r\n# Hub Model configuration. https://huggingface.co/models\r\
    \nhub = {\r\n\t'HF_MODEL_ID':'bigscience/bloom',\r\n\t'HF_TASK':'token-classification'\r\
    \n}\r\n\r\n# create Hugging Face Model Class\r\nhuggingface_model = HuggingFaceModel(\r\
    \n\ttransformers_version='4.17.0',\r\n\tpytorch_version='1.10.2',\r\n\tpy_version='py38',\r\
    \n\tenv=hub,\r\n\trole=role, \r\n)\r\n\r\n# deploy model to SageMaker Inference\r\
    \npredictor = huggingface_model.deploy(\r\n\tinitial_instance_count=1, # number\
    \ of instances\r\n\tinstance_type='ml.m5.xlarge' # ec2 instance type\r\n)\r\n\r\
    \npredictor.predict({\r\n\t'inputs': \"Can you please let us know more details\
    \ about your \"\r\n})\r\n```\r\n\r\nError:\r\n```\r\nModelError: An error occurred\
    \ (ModelError) when calling the InvokeEndpoint operation: Received client error\
    \ (400) from primary with message \"{\r\n  \"code\": 400,\r\n  \"type\": \"InternalServerException\"\
    ,\r\n  \"message\": \"\\u0027bloom\\u0027\"\r\n}\r\n```\r\n\r\nCode 400 is invalid\
    \ request. But it's an exact copy paste of the sample code. What could have gone\
    \ wrong here? Thanks."
  created_at: 2022-07-18 17:17:06+00:00
  edited: false
  hidden: false
  id: 62d5a3a223656463bdf4ce22
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png?w=200&h=200&f=face
      fullname: Philipp Schmid
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: philschmid
      type: user
    createdAt: '2022-07-19T05:17:50.000Z'
    data:
      edited: false
      editors:
      - philschmid
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png?w=200&h=200&f=face
          fullname: Philipp Schmid
          isHf: true
          isPro: false
          name: philschmid
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;vickyzhang&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/vickyzhang\"\
          >@<span class=\"underline\">vickyzhang</span></a></span>\n\n\t</span></span>,</p>\n\
          <p><code>BLOOM</code> got added to transformers in version <code>4.20.0</code>\
          \ and you are using <code>4.17.0</code>. Sadly there is currently not a\
          \ newer DLC yet available. </p>\n<p>Additionally, even if there were a version\
          \ for <code>4.20.0</code> the instance type with <code>ml.m5.xlarge</code>\
          \ would probably be way to small to load the model.</p>\n"
        raw: "Hello @vickyzhang,\n\n`BLOOM` got added to transformers in version `4.20.0`\
          \ and you are using `4.17.0`. Sadly there is currently not a newer DLC yet\
          \ available. \n\nAdditionally, even if there were a version for `4.20.0`\
          \ the instance type with `ml.m5.xlarge` would probably be way to small to\
          \ load the model."
        updatedAt: '2022-07-19T05:17:50.259Z'
      numEdits: 0
      reactions: []
    id: 62d63e7e4d766e27a4735226
    type: comment
  author: philschmid
  content: "Hello @vickyzhang,\n\n`BLOOM` got added to transformers in version `4.20.0`\
    \ and you are using `4.17.0`. Sadly there is currently not a newer DLC yet available.\
    \ \n\nAdditionally, even if there were a version for `4.20.0` the instance type\
    \ with `ml.m5.xlarge` would probably be way to small to load the model."
  created_at: 2022-07-19 04:17:50+00:00
  edited: false
  hidden: false
  id: 62d63e7e4d766e27a4735226
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a827dba11510d538ad0590c5fd112f1a.svg
      fullname: Vicky Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vickyzhang
      type: user
    createdAt: '2022-07-19T17:13:10.000Z'
    data:
      edited: false
      editors:
      - vickyzhang
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a827dba11510d538ad0590c5fd112f1a.svg
          fullname: Vicky Zhang
          isHf: false
          isPro: false
          name: vickyzhang
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;philschmid&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/philschmid\"\
          >@<span class=\"underline\">philschmid</span></a></span>\n\n\t</span></span>\
          \ , I think 4.17.0 was in the sample code. Is there any way to use bloom\
          \ (or smaller versions of it) for token classification task / NER then?\
          \ Through inferences API or other means?<br>Also maybe consider taking down\
          \ the sample code if it's not possible to run. Thanks!</p>\n"
        raw: 'Thanks @philschmid , I think 4.17.0 was in the sample code. Is there
          any way to use bloom (or smaller versions of it) for token classification
          task / NER then? Through inferences API or other means?

          Also maybe consider taking down the sample code if it''s not possible to
          run. Thanks!'
        updatedAt: '2022-07-19T17:13:10.432Z'
      numEdits: 0
      reactions: []
    id: 62d6e626acc7c69fbea38767
    type: comment
  author: vickyzhang
  content: 'Thanks @philschmid , I think 4.17.0 was in the sample code. Is there any
    way to use bloom (or smaller versions of it) for token classification task / NER
    then? Through inferences API or other means?

    Also maybe consider taking down the sample code if it''s not possible to run.
    Thanks!'
  created_at: 2022-07-19 16:13:10+00:00
  edited: false
  hidden: false
  id: 62d6e626acc7c69fbea38767
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 52
repo_id: bigscience/bloom
repo_type: model
status: open
target_branch: null
title: Invalid request from sample code
