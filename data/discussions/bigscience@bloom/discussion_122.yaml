!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mishavee
conflicting_files: null
created_at: 2022-10-19 20:17:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
      fullname: Mike Vinitsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mishavee
      type: user
    createdAt: '2022-10-19T21:17:22.000Z'
    data:
      edited: false
      editors:
      - mishavee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
          fullname: Mike Vinitsky
          isHf: false
          isPro: false
          name: mishavee
          type: user
        html: '<p>Does Bloom summarize text. If not can I fine tune it to summarize
          and what are prospects for a good result? Will it be as good as gpt3? Is
          Abstractive summarization possible? Is bloom as good as gpt3 in general?
          </p>

          '
        raw: 'Does Bloom summarize text. If not can I fine tune it to summarize and
          what are prospects for a good result? Will it be as good as gpt3? Is Abstractive
          summarization possible? Is bloom as good as gpt3 in general? '
        updatedAt: '2022-10-19T21:17:22.465Z'
      numEdits: 0
      reactions: []
    id: 63506962535d2b371b261e2a
    type: comment
  author: mishavee
  content: 'Does Bloom summarize text. If not can I fine tune it to summarize and
    what are prospects for a good result? Will it be as good as gpt3? Is Abstractive
    summarization possible? Is bloom as good as gpt3 in general? '
  created_at: 2022-10-19 20:17:22+00:00
  edited: false
  hidden: false
  id: 63506962535d2b371b261e2a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
      fullname: Thomas Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: TimeRobber
      type: user
    createdAt: '2022-10-19T21:52:10.000Z'
    data:
      edited: false
      editors:
      - TimeRobber
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
          fullname: Thomas Wang
          isHf: false
          isPro: false
          name: TimeRobber
          type: user
        html: '<blockquote>

          <p>Does Bloom summarize text</p>

          </blockquote>

          <p>It was not pretrained for, but it''s capable of text generation. One
          setup that people have had a bit of success in is try to run in one shot
          setting.</p>

          <blockquote>

          <p>If not can I fine tune it to summarize and what are prospects for a good
          result?</p>

          </blockquote>

          <p>There''s a good chance it will be quite good at it.</p>

          <blockquote>

          <p>Will it be as good as gpt3?</p>

          </blockquote>

          <p>Probably not. BLOOM is multilingual and thus sacrifices performances
          in english to enable performance in other languages.</p>

          <blockquote>

          <p>Is Abstractive summarization possible? </p>

          </blockquote>

          <p>Yes, see first answer.</p>

          <blockquote>

          <p>Is bloom as good as gpt3 in general?</p>

          </blockquote>

          <p>It depends on the metric you''re trying to optimize</p>

          '
        raw: "> Does Bloom summarize text\n\nIt was not pretrained for, but it's capable\
          \ of text generation. One setup that people have had a bit of success in\
          \ is try to run in one shot setting.\n\n> If not can I fine tune it to summarize\
          \ and what are prospects for a good result?\n\nThere's a good chance it\
          \ will be quite good at it.\n\n> Will it be as good as gpt3?\n\nProbably\
          \ not. BLOOM is multilingual and thus sacrifices performances in english\
          \ to enable performance in other languages.\n\n> Is Abstractive summarization\
          \ possible? \n\nYes, see first answer.\n\n> Is bloom as good as gpt3 in\
          \ general?\n\nIt depends on the metric you're trying to optimize"
        updatedAt: '2022-10-19T21:52:10.890Z'
      numEdits: 0
      reactions: []
    id: 6350718a18a4f616c9df6a76
    type: comment
  author: TimeRobber
  content: "> Does Bloom summarize text\n\nIt was not pretrained for, but it's capable\
    \ of text generation. One setup that people have had a bit of success in is try\
    \ to run in one shot setting.\n\n> If not can I fine tune it to summarize and\
    \ what are prospects for a good result?\n\nThere's a good chance it will be quite\
    \ good at it.\n\n> Will it be as good as gpt3?\n\nProbably not. BLOOM is multilingual\
    \ and thus sacrifices performances in english to enable performance in other languages.\n\
    \n> Is Abstractive summarization possible? \n\nYes, see first answer.\n\n> Is\
    \ bloom as good as gpt3 in general?\n\nIt depends on the metric you're trying\
    \ to optimize"
  created_at: 2022-10-19 20:52:10+00:00
  edited: false
  hidden: false
  id: 6350718a18a4f616c9df6a76
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
      fullname: Mike Vinitsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mishavee
      type: user
    createdAt: '2022-10-19T22:25:31.000Z'
    data:
      edited: false
      editors:
      - mishavee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
          fullname: Mike Vinitsky
          isHf: false
          isPro: false
          name: mishavee
          type: user
        html: '<p>ty</p>

          <p>As far as one shot summarization do I give it one example and then put
          what I need summarized and see the output? </p>

          <p>How many examples do I need to fine tune it for summarization? How many
          epochs? </p>

          <p>Can I train Bloom for gap sentences? </p>

          <p>what level of hardware do I need to fine tune Bloom reasonably? Where
          is best to go to aws, lambda?</p>

          '
        raw: "ty\n\nAs far as one shot summarization do I give it one example and\
          \ then put what I need summarized and see the output? \n\nHow many examples\
          \ do I need to fine tune it for summarization? How many epochs? \n\nCan\
          \ I train Bloom for gap sentences? \n\nwhat level of hardware do I need\
          \ to fine tune Bloom reasonably? Where is best to go to aws, lambda?"
        updatedAt: '2022-10-19T22:25:31.841Z'
      numEdits: 0
      reactions: []
    id: 6350795b1edb9d240f666c9b
    type: comment
  author: mishavee
  content: "ty\n\nAs far as one shot summarization do I give it one example and then\
    \ put what I need summarized and see the output? \n\nHow many examples do I need\
    \ to fine tune it for summarization? How many epochs? \n\nCan I train Bloom for\
    \ gap sentences? \n\nwhat level of hardware do I need to fine tune Bloom reasonably?\
    \ Where is best to go to aws, lambda?"
  created_at: 2022-10-19 21:25:31+00:00
  edited: false
  hidden: false
  id: 6350795b1edb9d240f666c9b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
      fullname: Thomas Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: TimeRobber
      type: user
    createdAt: '2022-10-20T13:52:55.000Z'
    data:
      edited: false
      editors:
      - TimeRobber
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
          fullname: Thomas Wang
          isHf: false
          isPro: false
          name: TimeRobber
          type: user
        html: '<blockquote>

          <p>As far as one shot summarization do I give it one example and then put
          what I need summarized and see the output?</p>

          </blockquote>

          <p>One shot is going to be something like:</p>

          <pre><code>Article: {ARTICLE_1}

          Summary: {SUMMARY_1}


          Activate: {ARTICLE_2}

          Summary:

          </code></pre>

          <blockquote>

          <p>How many examples do I need to fine tune it for summarization? How many
          epochs?</p>

          </blockquote>

          <p>Depends on the size of your fine tuning dataset. We haven''t played too
          much with finetuning yet. Feel free to test it out yourself and share your
          result here.</p>

          <blockquote>

          <p>Can I train Bloom for gap sentences?</p>

          </blockquote>

          <p>No sure what you mean here. If you mean filling the gap in the middle
          of the sentence, then I''d guess yes, you just need to format your problem
          as a language modeling one.</p>

          <blockquote>

          <p>what level of hardware do I need to fine tune Bloom reasonably? Where
          is best to go to aws, lambda?</p>

          </blockquote>

          <p>Hum you need something like 1-2T of GPU memory, depending on if you finetune
          all the layers and a subset of the layers.</p>

          '
        raw: '> As far as one shot summarization do I give it one example and then
          put what I need summarized and see the output?


          One shot is going to be something like:


          ```

          Article: {ARTICLE_1}

          Summary: {SUMMARY_1}


          Activate: {ARTICLE_2}

          Summary:

          ```


          > How many examples do I need to fine tune it for summarization? How many
          epochs?


          Depends on the size of your fine tuning dataset. We haven''t played too
          much with finetuning yet. Feel free to test it out yourself and share your
          result here.


          > Can I train Bloom for gap sentences?


          No sure what you mean here. If you mean filling the gap in the middle of
          the sentence, then I''d guess yes, you just need to format your problem
          as a language modeling one.


          > what level of hardware do I need to fine tune Bloom reasonably? Where
          is best to go to aws, lambda?


          Hum you need something like 1-2T of GPU memory, depending on if you finetune
          all the layers and a subset of the layers.'
        updatedAt: '2022-10-20T13:52:55.043Z'
      numEdits: 0
      reactions: []
    id: 635152b7cba4ff2e81cce4a6
    type: comment
  author: TimeRobber
  content: '> As far as one shot summarization do I give it one example and then put
    what I need summarized and see the output?


    One shot is going to be something like:


    ```

    Article: {ARTICLE_1}

    Summary: {SUMMARY_1}


    Activate: {ARTICLE_2}

    Summary:

    ```


    > How many examples do I need to fine tune it for summarization? How many epochs?


    Depends on the size of your fine tuning dataset. We haven''t played too much with
    finetuning yet. Feel free to test it out yourself and share your result here.


    > Can I train Bloom for gap sentences?


    No sure what you mean here. If you mean filling the gap in the middle of the sentence,
    then I''d guess yes, you just need to format your problem as a language modeling
    one.


    > what level of hardware do I need to fine tune Bloom reasonably? Where is best
    to go to aws, lambda?


    Hum you need something like 1-2T of GPU memory, depending on if you finetune all
    the layers and a subset of the layers.'
  created_at: 2022-10-20 12:52:55+00:00
  edited: false
  hidden: false
  id: 635152b7cba4ff2e81cce4a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
      fullname: Mike Vinitsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mishavee
      type: user
    createdAt: '2022-10-20T17:23:10.000Z'
    data:
      edited: false
      editors:
      - mishavee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
          fullname: Mike Vinitsky
          isHf: false
          isPro: false
          name: mishavee
          type: user
        html: '<p>ty</p>

          <p>how long does it take approximately to do one epoch for all layers with
          2T memory? </p>

          <p>Gap sentences is when they remove a sentence in between sentences and
          the model has to guess all the words of the missing sentence. Google Pegasus
          was trained like this. Can you train Bloom like this? </p>

          <p>if I were to train Bloom for summarization would I feed many of these
          to it?<br>Article: {ARTICLE_1}<br>Summary: {SUMMARY_1}</p>

          <p>How long would it take for a dataset of 311k like daily mail/cnn for
          one epoch with 2T memory of gpus? And how many epochs do you recommend for
          a good result?</p>

          '
        raw: "ty\n\nhow long does it take approximately to do one epoch for all layers\
          \ with 2T memory? \n\nGap sentences is when they remove a sentence in between\
          \ sentences and the model has to guess all the words of the missing sentence.\
          \ Google Pegasus was trained like this. Can you train Bloom like this? \n\
          \nif I were to train Bloom for summarization would I feed many of these\
          \ to it? \nArticle: {ARTICLE_1}\nSummary: {SUMMARY_1}\n\nHow long would\
          \ it take for a dataset of 311k like daily mail/cnn for one epoch with 2T\
          \ memory of gpus? And how many epochs do you recommend for a good result?"
        updatedAt: '2022-10-20T17:23:10.507Z'
      numEdits: 0
      reactions: []
    id: 635183feced5ba57d22dc602
    type: comment
  author: mishavee
  content: "ty\n\nhow long does it take approximately to do one epoch for all layers\
    \ with 2T memory? \n\nGap sentences is when they remove a sentence in between\
    \ sentences and the model has to guess all the words of the missing sentence.\
    \ Google Pegasus was trained like this. Can you train Bloom like this? \n\nif\
    \ I were to train Bloom for summarization would I feed many of these to it? \n\
    Article: {ARTICLE_1}\nSummary: {SUMMARY_1}\n\nHow long would it take for a dataset\
    \ of 311k like daily mail/cnn for one epoch with 2T memory of gpus? And how many\
    \ epochs do you recommend for a good result?"
  created_at: 2022-10-20 16:23:10+00:00
  edited: false
  hidden: false
  id: 635183feced5ba57d22dc602
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2022-11-04T08:21:24.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: "<p>You'll probably get much better summarization with <a href=\"https://huggingface.co/bigscience/bloomz\"\
          >BLOOMZ</a> by prompting it e.g. with</p>\n<pre><code>A neural network is\
          \ a network or circuit of biological neurons, or, in a modern sense, an\
          \ artificial neural network, composed of artificial neurons or nodes.[1]\
          \ Thus, a neural network is either a biological neural network, made up\
          \ of biological neurons, or an artificial neural network, used for solving\
          \ artificial intelligence (AI) problems. The connections of the biological\
          \ neuron are modeled in artificial neural networks as weights between nodes.\
          \ A positive weight reflects an excitatory connection, while negative values\
          \ mean inhibitory connections. All inputs are modified by a weight and summed.\
          \ This activity is referred to as a linear combination. Finally, an activation\
          \ function controls the amplitude of the output. For example, an acceptable\
          \ range of output is usually between 0 and 1, or it could be \u22121 and\
          \ 1. Summarize the previous text in one sentence:\n</code></pre>\n"
        raw: "You'll probably get much better summarization with [BLOOMZ](https://huggingface.co/bigscience/bloomz)\
          \ by prompting it e.g. with\n\n```\nA neural network is a network or circuit\
          \ of biological neurons, or, in a modern sense, an artificial neural network,\
          \ composed of artificial neurons or nodes.[1] Thus, a neural network is\
          \ either a biological neural network, made up of biological neurons, or\
          \ an artificial neural network, used for solving artificial intelligence\
          \ (AI) problems. The connections of the biological neuron are modeled in\
          \ artificial neural networks as weights between nodes. A positive weight\
          \ reflects an excitatory connection, while negative values mean inhibitory\
          \ connections. All inputs are modified by a weight and summed. This activity\
          \ is referred to as a linear combination. Finally, an activation function\
          \ controls the amplitude of the output. For example, an acceptable range\
          \ of output is usually between 0 and 1, or it could be \u22121 and 1. Summarize\
          \ the previous text in one sentence:\n```"
        updatedAt: '2022-11-04T08:21:24.464Z'
      numEdits: 0
      reactions: []
    id: 6364cb84a7a1324ccd52577b
    type: comment
  author: Muennighoff
  content: "You'll probably get much better summarization with [BLOOMZ](https://huggingface.co/bigscience/bloomz)\
    \ by prompting it e.g. with\n\n```\nA neural network is a network or circuit of\
    \ biological neurons, or, in a modern sense, an artificial neural network, composed\
    \ of artificial neurons or nodes.[1] Thus, a neural network is either a biological\
    \ neural network, made up of biological neurons, or an artificial neural network,\
    \ used for solving artificial intelligence (AI) problems. The connections of the\
    \ biological neuron are modeled in artificial neural networks as weights between\
    \ nodes. A positive weight reflects an excitatory connection, while negative values\
    \ mean inhibitory connections. All inputs are modified by a weight and summed.\
    \ This activity is referred to as a linear combination. Finally, an activation\
    \ function controls the amplitude of the output. For example, an acceptable range\
    \ of output is usually between 0 and 1, or it could be \u22121 and 1. Summarize\
    \ the previous text in one sentence:\n```"
  created_at: 2022-11-04 07:21:24+00:00
  edited: false
  hidden: false
  id: 6364cb84a7a1324ccd52577b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
      fullname: Mike Vinitsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mishavee
      type: user
    createdAt: '2022-11-04T22:47:57.000Z'
    data:
      edited: false
      editors:
      - mishavee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
          fullname: Mike Vinitsky
          isHf: false
          isPro: false
          name: mishavee
          type: user
        html: '<p>Thanks, is it possible to do this in a foreign language as well?</p>

          '
        raw: Thanks, is it possible to do this in a foreign language as well?
        updatedAt: '2022-11-04T22:47:57.753Z'
      numEdits: 0
      reactions: []
    id: 6365969de7a78348d8222892
    type: comment
  author: mishavee
  content: Thanks, is it possible to do this in a foreign language as well?
  created_at: 2022-11-04 21:47:57+00:00
  edited: false
  hidden: false
  id: 6365969de7a78348d8222892
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2022-11-05T07:22:34.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: '<p>Yes of course! You can try out the inference widget for  <a href="https://huggingface.co/bigscience/bloomz">BLOOMZ</a>  &amp;
          it should understand all BLOOM languages and many more.</p>

          '
        raw: Yes of course! You can try out the inference widget for  [BLOOMZ](https://huggingface.co/bigscience/bloomz)  &
          it should understand all BLOOM languages and many more.
        updatedAt: '2022-11-05T07:22:34.304Z'
      numEdits: 0
      reactions: []
    id: 63660f3aa2abcdf2fd610ed4
    type: comment
  author: Muennighoff
  content: Yes of course! You can try out the inference widget for  [BLOOMZ](https://huggingface.co/bigscience/bloomz)  &
    it should understand all BLOOM languages and many more.
  created_at: 2022-11-05 06:22:34+00:00
  edited: false
  hidden: false
  id: 63660f3aa2abcdf2fd610ed4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
      fullname: Mike Vinitsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mishavee
      type: user
    createdAt: '2022-11-05T07:38:21.000Z'
    data:
      edited: false
      editors:
      - mishavee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
          fullname: Mike Vinitsky
          isHf: false
          isPro: false
          name: mishavee
          type: user
        html: '<p>I have tried it on English with many different paragraphs. Sometimes
          it does a good job but not always. Is there an ideal length of text to summarize?
          </p>

          <p>when summarizing other languages do I still write summarize previous
          text in one sentence in English or the language of the text?</p>

          '
        raw: "I have tried it on English with many different paragraphs. Sometimes\
          \ it does a good job but not always. Is there an ideal length of text to\
          \ summarize? \n\nwhen summarizing other languages do I still write summarize\
          \ previous text in one sentence in English or the language of the text?"
        updatedAt: '2022-11-05T07:38:21.522Z'
      numEdits: 0
      reactions: []
    id: 636612edd0ee6e2662b11d30
    type: comment
  author: mishavee
  content: "I have tried it on English with many different paragraphs. Sometimes it\
    \ does a good job but not always. Is there an ideal length of text to summarize?\
    \ \n\nwhen summarizing other languages do I still write summarize previous text\
    \ in one sentence in English or the language of the text?"
  created_at: 2022-11-05 06:38:21+00:00
  edited: false
  hidden: false
  id: 636612edd0ee6e2662b11d30
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2022-11-05T07:55:41.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: '<blockquote>

          <p>I have tried it on English with many different paragraphs. Sometimes
          it does a good job but not always. Is there an ideal length of text to summarize?</p>

          </blockquote>

          <p>Any text length less than 2048 tokens should be fine. Note that there
          is a limit on the tokens you can generate in the widget, so you may have
          to press "Compute" multiple times.</p>

          <blockquote>

          <p>when summarizing other languages do I still write summarize previous
          text in one sentence in English or the language of the text?</p>

          </blockquote>

          <p>It will probably be better when asking it in English, but it should also
          work in other languages. Specifying the summarization language should also
          work. E.g. "Summarize the previous text in French.".</p>

          '
        raw: '> I have tried it on English with many different paragraphs. Sometimes
          it does a good job but not always. Is there an ideal length of text to summarize?


          Any text length less than 2048 tokens should be fine. Note that there is
          a limit on the tokens you can generate in the widget, so you may have to
          press "Compute" multiple times.


          > when summarizing other languages do I still write summarize previous text
          in one sentence in English or the language of the text?


          It will probably be better when asking it in English, but it should also
          work in other languages. Specifying the summarization language should also
          work. E.g. "Summarize the previous text in French.".'
        updatedAt: '2022-11-05T07:55:41.695Z'
      numEdits: 0
      reactions: []
    id: 636616fd6604a4fee84f82b6
    type: comment
  author: Muennighoff
  content: '> I have tried it on English with many different paragraphs. Sometimes
    it does a good job but not always. Is there an ideal length of text to summarize?


    Any text length less than 2048 tokens should be fine. Note that there is a limit
    on the tokens you can generate in the widget, so you may have to press "Compute"
    multiple times.


    > when summarizing other languages do I still write summarize previous text in
    one sentence in English or the language of the text?


    It will probably be better when asking it in English, but it should also work
    in other languages. Specifying the summarization language should also work. E.g.
    "Summarize the previous text in French.".'
  created_at: 2022-11-05 06:55:41+00:00
  edited: false
  hidden: false
  id: 636616fd6604a4fee84f82b6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e6470332ebc447f8a4ba32a339a0c01c.svg
      fullname: Nimja
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nimja
      type: user
    createdAt: '2023-06-01T12:54:13.000Z'
    data:
      edited: false
      editors:
      - Nimja
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e6470332ebc447f8a4ba32a339a0c01c.svg
          fullname: Nimja
          isHf: false
          isPro: false
          name: Nimja
          type: user
        html: '<p>This is the code I used and for long texts, the summary is completely
          useless.</p>

          <p>Chat-GPT gave me VERY good answers;</p>

          <pre><code>summary_instruction = f"\n\nSummarize the previous text in three
          sentences:\n\n"


          total_prompt = prompt + summary_instruction


          input_ids = tokenizer(prompt + f"\n\n" + summary_instruction, return_tensors="pt").to(0)

          sample = model.generate(**input_ids, max_length=5000,  top_k=1, temperature=0.9,
          repetition_penalty = 2.0)


          result_string = tokenizer.decode(sample[0], truncate_before_pattern=[r"\n\n^#",
          "^''", "\n\n\n"])


          print(result_string[len(total_prompt)::])

          </code></pre>

          '
        raw: 'This is the code I used and for long texts, the summary is completely
          useless.


          Chat-GPT gave me VERY good answers;


          ```

          summary_instruction = f"\n\nSummarize the previous text in three sentences:\n\n"


          total_prompt = prompt + summary_instruction


          input_ids = tokenizer(prompt + f"\n\n" + summary_instruction, return_tensors="pt").to(0)

          sample = model.generate(**input_ids, max_length=5000,  top_k=1, temperature=0.9,
          repetition_penalty = 2.0)


          result_string = tokenizer.decode(sample[0], truncate_before_pattern=[r"\n\n^#",
          "^''", "\n\n\n"])


          print(result_string[len(total_prompt)::])

          ```'
        updatedAt: '2023-06-01T12:54:13.032Z'
      numEdits: 0
      reactions: []
    id: 647894f51f9756aa89d1cadf
    type: comment
  author: Nimja
  content: 'This is the code I used and for long texts, the summary is completely
    useless.


    Chat-GPT gave me VERY good answers;


    ```

    summary_instruction = f"\n\nSummarize the previous text in three sentences:\n\n"


    total_prompt = prompt + summary_instruction


    input_ids = tokenizer(prompt + f"\n\n" + summary_instruction, return_tensors="pt").to(0)

    sample = model.generate(**input_ids, max_length=5000,  top_k=1, temperature=0.9,
    repetition_penalty = 2.0)


    result_string = tokenizer.decode(sample[0], truncate_before_pattern=[r"\n\n^#",
    "^''", "\n\n\n"])


    print(result_string[len(total_prompt)::])

    ```'
  created_at: 2023-06-01 11:54:13+00:00
  edited: false
  hidden: false
  id: 647894f51f9756aa89d1cadf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
      fullname: Mike Vinitsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mishavee
      type: user
    createdAt: '2023-06-01T16:49:46.000Z'
    data:
      edited: false
      editors:
      - mishavee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
          fullname: Mike Vinitsky
          isHf: false
          isPro: false
          name: mishavee
          type: user
        html: '<p>are you saying bloom doesn''t summarize well?</p>

          '
        raw: are you saying bloom doesn't summarize well?
        updatedAt: '2023-06-01T16:49:46.870Z'
      numEdits: 0
      reactions: []
    id: 6478cc2a25e06d2ffe8941a6
    type: comment
  author: mishavee
  content: are you saying bloom doesn't summarize well?
  created_at: 2023-06-01 15:49:46+00:00
  edited: false
  hidden: false
  id: 6478cc2a25e06d2ffe8941a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e6470332ebc447f8a4ba32a339a0c01c.svg
      fullname: Nimja
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nimja
      type: user
    createdAt: '2023-06-01T17:45:50.000Z'
    data:
      edited: false
      editors:
      - Nimja
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e6470332ebc447f8a4ba32a339a0c01c.svg
          fullname: Nimja
          isHf: false
          isPro: false
          name: Nimja
          type: user
        html: '<p>I''m not getting good results with this setup, no. Neither with
          bloom or bloomz. </p>

          <p>However, I''d appreciate if anyone can tell me what I could improve.</p>

          '
        raw: "I'm not getting good results with this setup, no. Neither with bloom\
          \ or bloomz. \n\nHowever, I'd appreciate if anyone can tell me what I could\
          \ improve."
        updatedAt: '2023-06-01T17:45:50.036Z'
      numEdits: 0
      reactions: []
    id: 6478d94ec68a021fbba17943
    type: comment
  author: Nimja
  content: "I'm not getting good results with this setup, no. Neither with bloom or\
    \ bloomz. \n\nHowever, I'd appreciate if anyone can tell me what I could improve."
  created_at: 2023-06-01 16:45:50+00:00
  edited: false
  hidden: false
  id: 6478d94ec68a021fbba17943
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
      fullname: Mike Vinitsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mishavee
      type: user
    createdAt: '2023-06-01T17:48:42.000Z'
    data:
      edited: true
      editors:
      - mishavee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
          fullname: Mike Vinitsky
          isHf: false
          isPro: false
          name: mishavee
          type: user
        html: '<p>they have to train bloom for text summarization. Otherwise it won''t
          work. I would like them to do it.</p>

          '
        raw: they have to train bloom for text summarization. Otherwise it won't work.
          I would like them to do it.
        updatedAt: '2023-06-01T17:49:14.180Z'
      numEdits: 1
      reactions: []
    id: 6478d9fa25e06d2ffe8a58a0
    type: comment
  author: mishavee
  content: they have to train bloom for text summarization. Otherwise it won't work.
    I would like them to do it.
  created_at: 2023-06-01 16:48:42+00:00
  edited: true
  hidden: false
  id: 6478d9fa25e06d2ffe8a58a0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 122
repo_id: bigscience/bloom
repo_type: model
status: open
target_branch: null
title: Text summarization with Bloom
