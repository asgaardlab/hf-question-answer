!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mzattera
conflicting_files: null
created_at: 2023-05-29 07:11:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/0-hE8SBo86gKVEHPvtaSQ.jpeg?w=200&h=200&f=face
      fullname: Massimiliano Zattera
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mzattera
      type: user
    createdAt: '2023-05-29T08:11:05.000Z'
    data:
      edited: true
      editors:
      - mzattera
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/0-hE8SBo86gKVEHPvtaSQ.jpeg?w=200&h=200&f=face
          fullname: Massimiliano Zattera
          isHf: false
          isPro: false
          name: mzattera
          type: user
        html: "<p>I am trying to use <code>bigscience/bloom</code> through Inference\
          \ API, but I keep receiving HTTP Error Code: 422 (unfortunately, no more\
          \ informative messages).</p>\n<p>If I use the very same request for <code>gpt2</code>\
          \ (just changing the model), it works, therefore I assume it is not a badly\
          \ formed request.</p>\n<p>The request is shown below:</p>\n<pre><code>{\n\
          \  \"inputs\" : [ \"How high is Mt. Everest?\" ],\n  \"options\" : { },\n\
          \  \"parameters\" : {\n    \"max_new_tokens\" : 15,\n    \"return_full_text\"\
          \ : false\n  }\n}\n</code></pre>\n<p>Am I doing something wrong? Thanks.</p>\n"
        raw: "I am trying to use `bigscience/bloom` through Inference API, but I keep\
          \ receiving HTTP Error Code: 422 (unfortunately, no more informative messages).\n\
          \nIf I use the very same request for `gpt2` (just changing the model), it\
          \ works, therefore I assume it is not a badly formed request.\n\nThe request\
          \ is shown below:\n\n```\n{\n  \"inputs\" : [ \"How high is Mt. Everest?\"\
          \ ],\n  \"options\" : { },\n  \"parameters\" : {\n    \"max_new_tokens\"\
          \ : 15,\n    \"return_full_text\" : false\n  }\n}\n```\n\nAm I doing something\
          \ wrong? Thanks."
        updatedAt: '2023-05-29T09:46:28.674Z'
      numEdits: 2
      reactions: []
    id: 64745e195aba8edfb2ed5339
    type: comment
  author: mzattera
  content: "I am trying to use `bigscience/bloom` through Inference API, but I keep\
    \ receiving HTTP Error Code: 422 (unfortunately, no more informative messages).\n\
    \nIf I use the very same request for `gpt2` (just changing the model), it works,\
    \ therefore I assume it is not a badly formed request.\n\nThe request is shown\
    \ below:\n\n```\n{\n  \"inputs\" : [ \"How high is Mt. Everest?\" ],\n  \"options\"\
    \ : { },\n  \"parameters\" : {\n    \"max_new_tokens\" : 15,\n    \"return_full_text\"\
    \ : false\n  }\n}\n```\n\nAm I doing something wrong? Thanks."
  created_at: 2023-05-29 07:11:05+00:00
  edited: true
  hidden: false
  id: 64745e195aba8edfb2ed5339
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8d295bf17a1728321cecd18e93210e6a.svg
      fullname: Lester Reynolds
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lesterpaintstheworld
      type: user
    createdAt: '2023-07-05T13:57:36.000Z'
    data:
      edited: true
      editors:
      - Lesterpaintstheworld
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.44238418340682983
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8d295bf17a1728321cecd18e93210e6a.svg
          fullname: Lester Reynolds
          isHf: false
          isPro: false
          name: Lesterpaintstheworld
          type: user
        html: '<p>+1, I get this all the time</p>

          '
        raw: +1, I get this all the time
        updatedAt: '2023-07-05T13:57:45.492Z'
      numEdits: 1
      reactions: []
    id: 64a576d071e569993cc0b049
    type: comment
  author: Lesterpaintstheworld
  content: +1, I get this all the time
  created_at: 2023-07-05 12:57:36+00:00
  edited: true
  hidden: false
  id: 64a576d071e569993cc0b049
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/648a66c628e95179adc68d49/WXTipJgemlrxXouBOGl96.png?w=200&h=200&f=face
      fullname: Vatsa Pandey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: VatsaDev
      type: user
    createdAt: '2023-07-16T03:40:57.000Z'
    data:
      edited: false
      editors:
      - VatsaDev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9610403776168823
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/648a66c628e95179adc68d49/WXTipJgemlrxXouBOGl96.png?w=200&h=200&f=face
          fullname: Vatsa Pandey
          isHf: false
          isPro: false
          name: VatsaDev
          type: user
        html: '<p>Same, Does anyone know a fix for this?</p>

          '
        raw: Same, Does anyone know a fix for this?
        updatedAt: '2023-07-16T03:40:57.952Z'
      numEdits: 0
      reactions: []
    id: 64b366c9f460afaefc342e97
    type: comment
  author: VatsaDev
  content: Same, Does anyone know a fix for this?
  created_at: 2023-07-16 02:40:57+00:00
  edited: false
  hidden: false
  id: 64b366c9f460afaefc342e97
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/97be409c91b2557646394dab844f1f47.svg
      fullname: Karim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: karim1104
      type: user
    createdAt: '2023-08-02T11:06:34.000Z'
    data:
      edited: true
      editors:
      - karim1104
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.627862811088562
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/97be409c91b2557646394dab844f1f47.svg
          fullname: Karim
          isHf: false
          isPro: false
          name: karim1104
          type: user
        html: '<p>I use this code and it works for me (albeit for Bloomz-3b):</p>

          <p>import json<br>import requests as r</p>

          <p>ENDPOINT_URL=""# url of your endpoint<br>HF_TOKEN=""</p>

          <h1 id="payload-samples">payload samples</h1>

          <p>regular_payload = { "inputs": "translate English to German: The weather
          is nice today." }<br>parameter_payload = {<br>    "inputs": "translate English
          to French: Hello my name is Philipp and I am a Technical Leader at Hugging
          Face",<br>  "parameters" : {<br>    "max_length": 40,<br>  }<br>}</p>

          <h1 id="http-headers-for-authorization">HTTP headers for authorization</h1>

          <p>headers= {<br>    "Authorization": f"Bearer {HF_TOKEN}",<br>    "Content-Type":
          "application/json"<br>}</p>

          <h1 id="send-request">send request</h1>

          <p>response = r.post(ENDPOINT_URL, headers=headers, json=parameter_payload)<br>generated_text
          = response.json()</p>

          <p>print(generated_text)</p>

          '
        raw: "I use this code and it works for me (albeit for Bloomz-3b):\n\nimport\
          \ json\nimport requests as r\n\nENDPOINT_URL=\"\"# url of your endpoint\n\
          HF_TOKEN=\"\"\n\n# payload samples\nregular_payload = { \"inputs\": \"translate\
          \ English to German: The weather is nice today.\" }\nparameter_payload =\
          \ {\n\t\"inputs\": \"translate English to French: Hello my name is Philipp\
          \ and I am a Technical Leader at Hugging Face\",\n  \"parameters\" : {\n\
          \    \"max_length\": 40,\n  }\n}\n\n# HTTP headers for authorization\nheaders=\
          \ {\n    \"Authorization\": f\"Bearer {HF_TOKEN}\",\n    \"Content-Type\"\
          : \"application/json\"\n}\n\n# send request\nresponse = r.post(ENDPOINT_URL,\
          \ headers=headers, json=parameter_payload)\ngenerated_text = response.json()\n\
          \nprint(generated_text)"
        updatedAt: '2023-08-02T11:17:23.734Z'
      numEdits: 1
      reactions: []
    id: 64ca38ba7846f146bd1f2f78
    type: comment
  author: karim1104
  content: "I use this code and it works for me (albeit for Bloomz-3b):\n\nimport\
    \ json\nimport requests as r\n\nENDPOINT_URL=\"\"# url of your endpoint\nHF_TOKEN=\"\
    \"\n\n# payload samples\nregular_payload = { \"inputs\": \"translate English to\
    \ German: The weather is nice today.\" }\nparameter_payload = {\n\t\"inputs\"\
    : \"translate English to French: Hello my name is Philipp and I am a Technical\
    \ Leader at Hugging Face\",\n  \"parameters\" : {\n    \"max_length\": 40,\n \
    \ }\n}\n\n# HTTP headers for authorization\nheaders= {\n    \"Authorization\"\
    : f\"Bearer {HF_TOKEN}\",\n    \"Content-Type\": \"application/json\"\n}\n\n#\
    \ send request\nresponse = r.post(ENDPOINT_URL, headers=headers, json=parameter_payload)\n\
    generated_text = response.json()\n\nprint(generated_text)"
  created_at: 2023-08-02 10:06:34+00:00
  edited: true
  hidden: false
  id: 64ca38ba7846f146bd1f2f78
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0195993fb9da7c25baab583d7acbb46.svg
      fullname: Augustin Athane
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Augustin1
      type: user
    createdAt: '2024-01-08T13:59:03.000Z'
    data:
      edited: false
      editors:
      - Augustin1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9718896746635437
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0195993fb9da7c25baab583d7acbb46.svg
          fullname: Augustin Athane
          isHf: false
          isPro: false
          name: Augustin1
          type: user
        html: '<p>For those who have the same problem, on my side it came from a change
          in the API, the output format had changed so the max_new_token had to be
          decreased. Most of the time, a 422 error comes from a problem in the parameters.</p>

          '
        raw: For those who have the same problem, on my side it came from a change
          in the API, the output format had changed so the max_new_token had to be
          decreased. Most of the time, a 422 error comes from a problem in the parameters.
        updatedAt: '2024-01-08T13:59:03.847Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - cakiki
        - VatsaDev
    id: 659bffa73454f79d543169f5
    type: comment
  author: Augustin1
  content: For those who have the same problem, on my side it came from a change in
    the API, the output format had changed so the max_new_token had to be decreased.
    Most of the time, a 422 error comes from a problem in the parameters.
  created_at: 2024-01-08 13:59:03+00:00
  edited: false
  hidden: false
  id: 659bffa73454f79d543169f5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
      fullname: Christopher Akiki
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: cakiki
      type: user
    createdAt: '2024-01-10T17:57:32.000Z'
    data:
      status: closed
    id: 659eda8c16d53757286352d9
    type: status-change
  author: cakiki
  created_at: 2024-01-10 17:57:32+00:00
  id: 659eda8c16d53757286352d9
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 252
repo_id: bigscience/bloom
repo_type: model
status: closed
target_branch: null
title: 'Getting HTTP Error Code: 422 when using Inference API'
