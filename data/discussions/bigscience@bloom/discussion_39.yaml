!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ricwo
conflicting_files: null
created_at: 2022-07-13 12:06:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f2d9f64ef34535d2e8277a3676969c1d.svg
      fullname: RW
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ricwo
      type: user
    createdAt: '2022-07-13T13:06:09.000Z'
    data:
      edited: true
      editors:
      - ricwo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f2d9f64ef34535d2e8277a3676969c1d.svg
          fullname: RW
          isHf: false
          isPro: false
          name: ricwo
          type: user
        html: "<p>Hi all, I'm trying to load Bloom onto eight A40 GPUs (48 GB of GPU\
          \ RAM each) using</p>\n<pre><code class=\"language-python\"><span class=\"\
          hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span>\
          \ AutoModelForCausalLM\nmodel = AutoModelForCausalLM.from_pretrained(model_name,\
          \ device_map=<span class=\"hljs-string\">\"auto\"</span>, torch_dtype=<span\
          \ class=\"hljs-string\">\"auto\"</span>)\n</code></pre>\n<p>which fails\
          \ with</p>\n<pre><code class=\"language-text\">Traceback (most recent call\
          \ last):\n\n  File \"/home/me/bloom/lib/python3.8/site-packages/torch/serialization.py\"\
          , line 308, in _check_seekable\n    f.seek(f.tell())\n\nAttributeError:\
          \ 'list' object has no attribute 'seek'\n</code></pre>\n<p><a rel=\"nofollow\"\
          \ href=\"https://elmah.io/tools/stack-trace-formatter/43ff9dd42c4f45bb9735a3f1c068e9d0/\"\
          >Here's</a> the full stack trace.</p>\n<p>Here's my system setup:</p>\n\
          <pre><code class=\"language-text\">$ nvcc --version\nnvcc: NVIDIA (R) Cuda\
          \ compiler driver\nCopyright (c) 2005-2022 NVIDIA Corporation\nBuilt on\
          \ Tue_Mar__8_18:18:20_PST_2022\nCuda compilation tools, release 11.6, V11.6.124\n\
          Build cuda_11.6.r11.6/compiler.31057947_0\n\n$ pip show torch\nName: torch\n\
          Version: 1.12.0+cu116\n\n$ pip show transformers\nName: transformers\nVersion:\
          \ 4.20.1\n\n$ pip show accelerate\nName: accelerate\nVersion: 0.10.0\n</code></pre>\n\
          <p>Has anyone encountered this and found a solution?</p>\n"
        raw: "Hi all, I'm trying to load Bloom onto eight A40 GPUs (48 GB of GPU RAM\
          \ each) using\n\n```python\nfrom transformers import AutoModelForCausalLM\n\
          model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\"\
          , torch_dtype=\"auto\")\n```\n\nwhich fails with\n```text\nTraceback (most\
          \ recent call last):\n\n  File \"/home/me/bloom/lib/python3.8/site-packages/torch/serialization.py\"\
          , line 308, in _check_seekable\n    f.seek(f.tell())\n\nAttributeError:\
          \ 'list' object has no attribute 'seek'\n```\n\n[Here's](https://elmah.io/tools/stack-trace-formatter/43ff9dd42c4f45bb9735a3f1c068e9d0/)\
          \ the full stack trace.\n\nHere's my system setup:\n\n```text\n$ nvcc --version\n\
          nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2022 NVIDIA Corporation\n\
          Built on Tue_Mar__8_18:18:20_PST_2022\nCuda compilation tools, release 11.6,\
          \ V11.6.124\nBuild cuda_11.6.r11.6/compiler.31057947_0\n\n$ pip show torch\n\
          Name: torch\nVersion: 1.12.0+cu116\n\n$ pip show transformers\nName: transformers\n\
          Version: 4.20.1\n\n$ pip show accelerate\nName: accelerate\nVersion: 0.10.0\n\
          ```\n\nHas anyone encountered this and found a solution?"
        updatedAt: '2022-07-13T13:09:33.408Z'
      numEdits: 3
      reactions: []
    id: 62cec3415802fa8dc071ed5c
    type: comment
  author: ricwo
  content: "Hi all, I'm trying to load Bloom onto eight A40 GPUs (48 GB of GPU RAM\
    \ each) using\n\n```python\nfrom transformers import AutoModelForCausalLM\nmodel\
    \ = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"\
    auto\")\n```\n\nwhich fails with\n```text\nTraceback (most recent call last):\n\
    \n  File \"/home/me/bloom/lib/python3.8/site-packages/torch/serialization.py\"\
    , line 308, in _check_seekable\n    f.seek(f.tell())\n\nAttributeError: 'list'\
    \ object has no attribute 'seek'\n```\n\n[Here's](https://elmah.io/tools/stack-trace-formatter/43ff9dd42c4f45bb9735a3f1c068e9d0/)\
    \ the full stack trace.\n\nHere's my system setup:\n\n```text\n$ nvcc --version\n\
    nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2022 NVIDIA Corporation\n\
    Built on Tue_Mar__8_18:18:20_PST_2022\nCuda compilation tools, release 11.6, V11.6.124\n\
    Build cuda_11.6.r11.6/compiler.31057947_0\n\n$ pip show torch\nName: torch\nVersion:\
    \ 1.12.0+cu116\n\n$ pip show transformers\nName: transformers\nVersion: 4.20.1\n\
    \n$ pip show accelerate\nName: accelerate\nVersion: 0.10.0\n```\n\nHas anyone\
    \ encountered this and found a solution?"
  created_at: 2022-07-13 12:06:09+00:00
  edited: true
  hidden: false
  id: 62cec3415802fa8dc071ed5c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2022-07-13T13:12:09.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: '<p>Hi, </p>

          <p>Thanks for your question ! THis issue is related to that PR: <a rel="nofollow"
          href="https://github.com/huggingface/transformers/pull/18061">https://github.com/huggingface/transformers/pull/18061</a><br>Could
          you try with this command while the PR gets merged:</p>

          <pre><code>from transformers import AutoModelForCausalLM

          import torch

          model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto",
          torch_dtype=torch.bfloat16)

          </code></pre>

          '
        raw: "Hi, \n\nThanks for your question ! THis issue is related to that PR:\
          \ https://github.com/huggingface/transformers/pull/18061\nCould you try\
          \ with this command while the PR gets merged:\n```\nfrom transformers import\
          \ AutoModelForCausalLM\nimport torch\nmodel = AutoModelForCausalLM.from_pretrained(model_name,\
          \ device_map=\"auto\", torch_dtype=torch.bfloat16)\n```"
        updatedAt: '2022-07-13T13:12:09.683Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - ricwo
    id: 62cec4a9e1d5ee194e6009fe
    type: comment
  author: ybelkada
  content: "Hi, \n\nThanks for your question ! THis issue is related to that PR: https://github.com/huggingface/transformers/pull/18061\n\
    Could you try with this command while the PR gets merged:\n```\nfrom transformers\
    \ import AutoModelForCausalLM\nimport torch\nmodel = AutoModelForCausalLM.from_pretrained(model_name,\
    \ device_map=\"auto\", torch_dtype=torch.bfloat16)\n```"
  created_at: 2022-07-13 12:12:09+00:00
  edited: false
  hidden: false
  id: 62cec4a9e1d5ee194e6009fe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f2d9f64ef34535d2e8277a3676969c1d.svg
      fullname: RW
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ricwo
      type: user
    createdAt: '2022-07-15T07:22:43.000Z'
    data:
      edited: false
      editors:
      - ricwo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f2d9f64ef34535d2e8277a3676969c1d.svg
          fullname: RW
          isHf: false
          isPro: false
          name: ricwo
          type: user
        html: "<p>Thanks so much <span data-props=\"{&quot;user&quot;:&quot;ybelkada&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ybelkada\"\
          >@<span class=\"underline\">ybelkada</span></a></span>\n\n\t</span></span>,\
          \ it now works as expected</p>\n"
        raw: Thanks so much @ybelkada, it now works as expected
        updatedAt: '2022-07-15T07:22:43.828Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - ybelkada
    id: 62d115c3eaedad8270698da0
    type: comment
  author: ricwo
  content: Thanks so much @ybelkada, it now works as expected
  created_at: 2022-07-15 06:22:43+00:00
  edited: false
  hidden: false
  id: 62d115c3eaedad8270698da0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/f2d9f64ef34535d2e8277a3676969c1d.svg
      fullname: RW
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ricwo
      type: user
    createdAt: '2022-07-15T07:22:43.000Z'
    data:
      status: closed
    id: 62d115c3eaedad8270698da1
    type: status-change
  author: ricwo
  created_at: 2022-07-15 06:22:43+00:00
  id: 62d115c3eaedad8270698da1
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 39
repo_id: bigscience/bloom
repo_type: model
status: closed
target_branch: null
title: Unable to load model using `accelerate`
