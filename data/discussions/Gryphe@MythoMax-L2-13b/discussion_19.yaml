!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Samvanity
conflicting_files: null
created_at: 2023-11-28 19:58:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/41f136dd7933e710bea90eba83fb38d4.svg
      fullname: Sam Vance
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Samvanity
      type: user
    createdAt: '2023-11-28T19:58:32.000Z'
    data:
      edited: false
      editors:
      - Samvanity
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8258545994758606
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/41f136dd7933e710bea90eba83fb38d4.svg
          fullname: Sam Vance
          isHf: false
          isPro: false
          name: Samvanity
          type: user
        html: '<p>I want to use this with lmstudio and memgpt, and memgpt wants the
          context length set to the max:<br><a rel="nofollow" href="https://memgpt.readthedocs.io/en/latest/lmstudio/#memgpt-lm-studio">https://memgpt.readthedocs.io/en/latest/lmstudio/#memgpt-lm-studio</a><br>it
          says: Make sure that "context length" is set (inside LM Studio''s "Model
          Configuration" panel) to the max context length of the model you''re using
          (e.g. 8000 for Mistral 7B variants).</p>

          <p>Thanks!</p>

          '
        raw: "I want to use this with lmstudio and memgpt, and memgpt wants the context\
          \ length set to the max:\r\nhttps://memgpt.readthedocs.io/en/latest/lmstudio/#memgpt-lm-studio\r\
          \nit says: Make sure that \"context length\" is set (inside LM Studio's\
          \ \"Model Configuration\" panel) to the max context length of the model\
          \ you're using (e.g. 8000 for Mistral 7B variants).\r\n\r\nThanks!"
        updatedAt: '2023-11-28T19:58:32.006Z'
      numEdits: 0
      reactions: []
    id: 65664668d4c272e7a904d06e
    type: comment
  author: Samvanity
  content: "I want to use this with lmstudio and memgpt, and memgpt wants the context\
    \ length set to the max:\r\nhttps://memgpt.readthedocs.io/en/latest/lmstudio/#memgpt-lm-studio\r\
    \nit says: Make sure that \"context length\" is set (inside LM Studio's \"Model\
    \ Configuration\" panel) to the max context length of the model you're using (e.g.\
    \ 8000 for Mistral 7B variants).\r\n\r\nThanks!"
  created_at: 2023-11-28 19:58:32+00:00
  edited: false
  hidden: false
  id: 65664668d4c272e7a904d06e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b55879f2858e648d5460fb/ZrkS_BmET_WIXZCS_q6Bv.png?w=200&h=200&f=face
      fullname: OlO
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 010O11
      type: user
    createdAt: '2024-01-10T06:01:07.000Z'
    data:
      edited: false
      editors:
      - 010O11
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8019189238548279
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b55879f2858e648d5460fb/ZrkS_BmET_WIXZCS_q6Bv.png?w=200&h=200&f=face
          fullname: OlO
          isHf: false
          isPro: false
          name: 010O11
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Samvanity&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Samvanity\">@<span class=\"\
          underline\">Samvanity</span></a></span>\n\n\t</span></span> &gt; you ca\
          \ check this for almost each model here on HF  -  go to the Files and versions\
          \ tab up there &gt; search for the config.json , click on it &gt; look for\
          \ the line \"max_position_embeddings\"</p>\n"
        raw: '@Samvanity > you ca check this for almost each model here on HF  -  go
          to the Files and versions tab up there > search for the config.json , click
          on it > look for the line "max_position_embeddings"'
        updatedAt: '2024-01-10T06:01:07.887Z'
      numEdits: 0
      reactions: []
    id: 659e32a3e5bc942b4b2161d2
    type: comment
  author: 010O11
  content: '@Samvanity > you ca check this for almost each model here on HF  -  go
    to the Files and versions tab up there > search for the config.json , click on
    it > look for the line "max_position_embeddings"'
  created_at: 2024-01-10 06:01:07+00:00
  edited: false
  hidden: false
  id: 659e32a3e5bc942b4b2161d2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 19
repo_id: Gryphe/MythoMax-L2-13b
repo_type: model
status: open
target_branch: null
title: Whats the maximum context length for this model?
