!!python/object:huggingface_hub.community.DiscussionWithDetails
author: cmp-nct
conflicting_files: null
created_at: 2024-01-18 00:24:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/70bfddcf585e2f191ba24f47274c9e94.svg
      fullname: John
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cmp-nct
      type: user
    createdAt: '2024-01-18T00:24:57.000Z'
    data:
      edited: false
      editors:
      - cmp-nct
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9543200731277466
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/70bfddcf585e2f191ba24f47274c9e94.svg
          fullname: John
          isHf: false
          isPro: false
          name: cmp-nct
          type: user
        html: '<p>I really like your work, it''s a clean approach on translation and
          it''s possibly the best open approach for translation we have.<br>However,
          the comparison to GPT-4(preview) level is not correct yet.</p>

          <p>I''ve been struggling with en-&gt;german translations for a while, tried
          a ton of approaches.<br>This new LORA appears slightly better than the previous
          one in my comparisons but it still makes grammatical errors where GPT-4
          is flawless.</p>

          <p>I''m getting very good results when giving the model only small sentences,
          compareable to GPT4 in those cases.<br>But when you give it a paragraph
          the grammar starts to degrade.<br>When comparing this to GPT4, the quality
          improves further with larger sentences.</p>

          <p>Switching to separate short sentences is not an option as translation
          needs context when one words meaning depends on a previous sentence.</p>

          <p>Maybe there is additional tuning possible for paragraphs ?</p>

          '
        raw: "I really like your work, it's a clean approach on translation and it's\
          \ possibly the best open approach for translation we have.\r\nHowever, the\
          \ comparison to GPT-4(preview) level is not correct yet.\r\n\r\nI've been\
          \ struggling with en->german translations for a while, tried a ton of approaches.\r\
          \nThis new LORA appears slightly better than the previous one in my comparisons\
          \ but it still makes grammatical errors where GPT-4 is flawless.\r\n\r\n\
          I'm getting very good results when giving the model only small sentences,\
          \ compareable to GPT4 in those cases.\r\nBut when you give it a paragraph\
          \ the grammar starts to degrade.\r\nWhen comparing this to GPT4, the quality\
          \ improves further with larger sentences.\r\n\r\nSwitching to separate short\
          \ sentences is not an option as translation needs context when one words\
          \ meaning depends on a previous sentence.\r\n\r\n\r\nMaybe there is additional\
          \ tuning possible for paragraphs ?"
        updatedAt: '2024-01-18T00:24:57.969Z'
      numEdits: 0
      reactions: []
    id: 65a86fd90237119dc5ffcfbb
    type: comment
  author: cmp-nct
  content: "I really like your work, it's a clean approach on translation and it's\
    \ possibly the best open approach for translation we have.\r\nHowever, the comparison\
    \ to GPT-4(preview) level is not correct yet.\r\n\r\nI've been struggling with\
    \ en->german translations for a while, tried a ton of approaches.\r\nThis new\
    \ LORA appears slightly better than the previous one in my comparisons but it\
    \ still makes grammatical errors where GPT-4 is flawless.\r\n\r\nI'm getting very\
    \ good results when giving the model only small sentences, compareable to GPT4\
    \ in those cases.\r\nBut when you give it a paragraph the grammar starts to degrade.\r\
    \nWhen comparing this to GPT4, the quality improves further with larger sentences.\r\
    \n\r\nSwitching to separate short sentences is not an option as translation needs\
    \ context when one words meaning depends on a previous sentence.\r\n\r\n\r\nMaybe\
    \ there is additional tuning possible for paragraphs ?"
  created_at: 2024-01-18 00:24:57+00:00
  edited: false
  hidden: false
  id: 65a86fd90237119dc5ffcfbb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1631080954171-61384b860317b0a5c10877d3.jpeg?w=200&h=200&f=face
      fullname: Haoran Xu
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: haoranxu
      type: user
    createdAt: '2024-01-18T04:52:53.000Z'
    data:
      edited: false
      editors:
      - haoranxu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9427565336227417
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1631080954171-61384b860317b0a5c10877d3.jpeg?w=200&h=200&f=face
          fullname: Haoran Xu
          isHf: false
          isPro: false
          name: haoranxu
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;cmp-nct&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/cmp-nct\">@<span class=\"\
          underline\">cmp-nct</span></a></span>\n\n\t</span></span>! Thank you for\
          \ your interest in our work and for testing our model so quickly! Your feedback\
          \ provides valuable insights for our future work in exploring better methods\
          \ for translating from English to German.</p>\n<p>In our comparison with\
          \ GPT-4-1106-preview, we considered not only translation into German but\
          \ also other language pairs and directions, such as Chinese and Icelandic.\
          \ The performance we reported is an average across 10 different language\
          \ directions three differenet metrics. However, it's true that specifically\
          \ for English to German translation, GPT-4 still performs slightly better.\
          \ (Refer to Table 2: GPT-4 <strong>84.91</strong> KIWI-XXL vs. ALMA-13B-R\
          \ <strong>84.25</strong>).</p>\n"
        raw: 'Hi @cmp-nct! Thank you for your interest in our work and for testing
          our model so quickly! Your feedback provides valuable insights for our future
          work in exploring better methods for translating from English to German.


          In our comparison with GPT-4-1106-preview, we considered not only translation
          into German but also other language pairs and directions, such as Chinese
          and Icelandic. The performance we reported is an average across 10 different
          language directions three differenet metrics. However, it''s true that specifically
          for English to German translation, GPT-4 still performs slightly better.
          (Refer to Table 2: GPT-4 **84.91** KIWI-XXL vs. ALMA-13B-R **84.25**).

          '
        updatedAt: '2024-01-18T04:52:53.077Z'
      numEdits: 0
      reactions: []
    id: 65a8aea5ef14f9e60380bd73
    type: comment
  author: haoranxu
  content: 'Hi @cmp-nct! Thank you for your interest in our work and for testing our
    model so quickly! Your feedback provides valuable insights for our future work
    in exploring better methods for translating from English to German.


    In our comparison with GPT-4-1106-preview, we considered not only translation
    into German but also other language pairs and directions, such as Chinese and
    Icelandic. The performance we reported is an average across 10 different language
    directions three differenet metrics. However, it''s true that specifically for
    English to German translation, GPT-4 still performs slightly better. (Refer to
    Table 2: GPT-4 **84.91** KIWI-XXL vs. ALMA-13B-R **84.25**).

    '
  created_at: 2024-01-18 04:52:53+00:00
  edited: false
  hidden: false
  id: 65a8aea5ef14f9e60380bd73
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6495b47a74ce69cc4eab61f0/2eg17fMXjshpfQfSq5jyP.png?w=200&h=200&f=face
      fullname: VincentN
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vince62s
      type: user
    createdAt: '2024-01-19T13:04:33.000Z'
    data:
      edited: false
      editors:
      - vince62s
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9220549464225769
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6495b47a74ce69cc4eab61f0/2eg17fMXjshpfQfSq5jyP.png?w=200&h=200&f=face
          fullname: VincentN
          isHf: false
          isPro: false
          name: vince62s
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;haoranxu&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/haoranxu\"\
          >@<span class=\"underline\">haoranxu</span></a></span>\n\n\t</span></span><br>I\
          \ enjoyed your paper too. Not being a criticism, because I think the methodology\
          \ is good, I posted this here a couple of days ago: <a rel=\"nofollow\"\
          \ href=\"https://www.linkedin.com/posts/vincentnguyenngoc_microsoft-released-a-new-paper-with-llm-as-activity-7153391325722152960-HeCJ?utm_source=share&amp;utm_medium=member_desktop\"\
          >https://www.linkedin.com/posts/vincentnguyenngoc_microsoft-released-a-new-paper-with-llm-as-activity-7153391325722152960-HeCJ?utm_source=share&amp;utm_medium=member_desktop</a><br>Feel\
          \ free to comment but my main question is 1) how do you explain the -10\
          \ BLEU for EN-DE vs Sota systems (I still played a lot with EN-DE) and 2)\
          \ did you do human eval of your work ?<br>lastly did you try to apply CPO\
          \ with an encoder-decoder architecture ?</p>\n"
        raw: "Hi @haoranxu \nI enjoyed your paper too. Not being a criticism, because\
          \ I think the methodology is good, I posted this here a couple of days ago:\
          \ https://www.linkedin.com/posts/vincentnguyenngoc_microsoft-released-a-new-paper-with-llm-as-activity-7153391325722152960-HeCJ?utm_source=share&utm_medium=member_desktop\n\
          Feel free to comment but my main question is 1) how do you explain the -10\
          \ BLEU for EN-DE vs Sota systems (I still played a lot with EN-DE) and 2)\
          \ did you do human eval of your work ?\nlastly did you try to apply CPO\
          \ with an encoder-decoder architecture ?"
        updatedAt: '2024-01-19T13:04:33.897Z'
      numEdits: 0
      reactions: []
    id: 65aa736148c718a574077c63
    type: comment
  author: vince62s
  content: "Hi @haoranxu \nI enjoyed your paper too. Not being a criticism, because\
    \ I think the methodology is good, I posted this here a couple of days ago: https://www.linkedin.com/posts/vincentnguyenngoc_microsoft-released-a-new-paper-with-llm-as-activity-7153391325722152960-HeCJ?utm_source=share&utm_medium=member_desktop\n\
    Feel free to comment but my main question is 1) how do you explain the -10 BLEU\
    \ for EN-DE vs Sota systems (I still played a lot with EN-DE) and 2) did you do\
    \ human eval of your work ?\nlastly did you try to apply CPO with an encoder-decoder\
    \ architecture ?"
  created_at: 2024-01-19 13:04:33+00:00
  edited: false
  hidden: false
  id: 65aa736148c718a574077c63
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1631080954171-61384b860317b0a5c10877d3.jpeg?w=200&h=200&f=face
      fullname: Haoran Xu
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: haoranxu
      type: user
    createdAt: '2024-01-19T18:01:16.000Z'
    data:
      edited: false
      editors:
      - haoranxu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9367488622665405
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1631080954171-61384b860317b0a5c10877d3.jpeg?w=200&h=200&f=face
          fullname: Haoran Xu
          isHf: false
          isPro: false
          name: haoranxu
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;vince62s&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/vince62s\"\
          >@<span class=\"underline\">vince62s</span></a></span>\n\n\t</span></span>\
          \  I just replied to your post before I saw this message! </p>\n<blockquote>\n\
          <p>how do you explain the -10 BLEU for EN-DE vs Sota systems</p>\n</blockquote>\n\
          <p>For the first question, I have replied under the post. But copied here:\
          \ I also noticed the BLEU drop but improvements in the other metrics. As\
          \ a Chinese speaker, I examined the test set for en-&gt;zh and found that\
          \ ALMA-R provides more fluent and natural translations. I assume that the\
          \ BLEU drop is due to domain mismatch with the WMT topics.</p>\n<p>A good\
          \ example from WMT\u201922 for en-&gt;zh:<br>src: I'm sorry that your order\
          \ is running late.<br>tgt: \u5F88\u62B1\u6B49\uFF0C\u60A8\u70B9\u7684\u9910\
          \u53EF\u80FD\u4F1A\u665A\u5230\u4E00\u4F1A\u3002<br>ALMA-R: \u5BF9\u4E0D\
          \u8D77\uFF0C\u60A8\u7684\u8BA2\u5355\u5EF6\u8BEF\u4E86\u3002</p>\n<p>The\
          \ BLEU is very low because the lexical overlapping is almost 0. But I feel\
          \ ALMA-R is slightly better (because \"\u8BA2\u5355\" here is more suitable\
          \ for \"order\") and they are the basically same meaning. I often find that\
          \ WMT winners have nonsensically high BLEU scores, like over 64.2 for cs-&gt;en.\
          \ So, I guess this is because the WMT winner for cs-&gt;en just learned\
          \ very well in the domain of WMT\u201922.</p>\n<blockquote>\n<p>did you\
          \ do human eval of your work ?</p>\n</blockquote>\n<p>Regarding the human\
          \ evaluation, we are doing our best to implement it in the next step.</p>\n\
          <blockquote>\n<p>lastly did you try to apply CPO with an encoder-decoder\
          \ architecture ?</p>\n</blockquote>\n<p>No, we haven't done so yet, but\
          \ it will be interesting to explore this :)!</p>\n"
        raw: "Hi @vince62s  I just replied to your post before I saw this message!\
          \ \n>how do you explain the -10 BLEU for EN-DE vs Sota systems\n\nFor the\
          \ first question, I have replied under the post. But copied here: I also\
          \ noticed the BLEU drop but improvements in the other metrics. As a Chinese\
          \ speaker, I examined the test set for en->zh and found that ALMA-R provides\
          \ more fluent and natural translations. I assume that the BLEU drop is due\
          \ to domain mismatch with the WMT topics.\n\nA good example from WMT\u2019\
          22 for en->zh:\nsrc: I'm sorry that your order is running late.\ntgt: \u5F88\
          \u62B1\u6B49\uFF0C\u60A8\u70B9\u7684\u9910\u53EF\u80FD\u4F1A\u665A\u5230\
          \u4E00\u4F1A\u3002\nALMA-R: \u5BF9\u4E0D\u8D77\uFF0C\u60A8\u7684\u8BA2\u5355\
          \u5EF6\u8BEF\u4E86\u3002\n\nThe BLEU is very low because the lexical overlapping\
          \ is almost 0. But I feel ALMA-R is slightly better (because \"\u8BA2\u5355\
          \" here is more suitable for \"order\") and they are the basically same\
          \ meaning. I often find that WMT winners have nonsensically high BLEU scores,\
          \ like over 64.2 for cs->en. So, I guess this is because the WMT winner\
          \ for cs->en just learned very well in the domain of WMT\u201922.\n\n\n\
          >did you do human eval of your work ?\n\nRegarding the human evaluation,\
          \ we are doing our best to implement it in the next step.\n\n>lastly did\
          \ you try to apply CPO with an encoder-decoder architecture ?\n\nNo, we\
          \ haven't done so yet, but it will be interesting to explore this :)!"
        updatedAt: '2024-01-19T18:01:16.009Z'
      numEdits: 0
      reactions: []
    id: 65aab8ec23a4f1b4ecc372a3
    type: comment
  author: haoranxu
  content: "Hi @vince62s  I just replied to your post before I saw this message! \n\
    >how do you explain the -10 BLEU for EN-DE vs Sota systems\n\nFor the first question,\
    \ I have replied under the post. But copied here: I also noticed the BLEU drop\
    \ but improvements in the other metrics. As a Chinese speaker, I examined the\
    \ test set for en->zh and found that ALMA-R provides more fluent and natural translations.\
    \ I assume that the BLEU drop is due to domain mismatch with the WMT topics.\n\
    \nA good example from WMT\u201922 for en->zh:\nsrc: I'm sorry that your order\
    \ is running late.\ntgt: \u5F88\u62B1\u6B49\uFF0C\u60A8\u70B9\u7684\u9910\u53EF\
    \u80FD\u4F1A\u665A\u5230\u4E00\u4F1A\u3002\nALMA-R: \u5BF9\u4E0D\u8D77\uFF0C\u60A8\
    \u7684\u8BA2\u5355\u5EF6\u8BEF\u4E86\u3002\n\nThe BLEU is very low because the\
    \ lexical overlapping is almost 0. But I feel ALMA-R is slightly better (because\
    \ \"\u8BA2\u5355\" here is more suitable for \"order\") and they are the basically\
    \ same meaning. I often find that WMT winners have nonsensically high BLEU scores,\
    \ like over 64.2 for cs->en. So, I guess this is because the WMT winner for cs->en\
    \ just learned very well in the domain of WMT\u201922.\n\n\n>did you do human\
    \ eval of your work ?\n\nRegarding the human evaluation, we are doing our best\
    \ to implement it in the next step.\n\n>lastly did you try to apply CPO with an\
    \ encoder-decoder architecture ?\n\nNo, we haven't done so yet, but it will be\
    \ interesting to explore this :)!"
  created_at: 2024-01-19 18:01:16+00:00
  edited: false
  hidden: false
  id: 65aab8ec23a4f1b4ecc372a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6495b47a74ce69cc4eab61f0/2eg17fMXjshpfQfSq5jyP.png?w=200&h=200&f=face
      fullname: VincentN
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vince62s
      type: user
    createdAt: '2024-01-19T18:08:40.000Z'
    data:
      edited: false
      editors:
      - vince62s
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9796455502510071
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6495b47a74ce69cc4eab61f0/2eg17fMXjshpfQfSq5jyP.png?w=200&h=200&f=face
          fullname: VincentN
          isHf: false
          isPro: false
          name: vince62s
          type: user
        html: '<p>FYI I am one of the maintainer of OpenNMT-py and have been working
          on NMT for a long long time.<br>I was about to implement DPO in the repo
          when I saw your paper, so it seems easier to implement CPO and will do it.<br>Now
          for the results, maybe it worked fine for EN-ZH but honestly I think for
          EN-DE it overfitted the metric (comet). -10 Bleu is HUGE at a system level.
          I can understand that a sentence level this can happen but for a system
          I don''t think so. I will be very interested to look at the human eval.
          Anyhow nice paper, congrats.</p>

          '
        raw: 'FYI I am one of the maintainer of OpenNMT-py and have been working on
          NMT for a long long time.

          I was about to implement DPO in the repo when I saw your paper, so it seems
          easier to implement CPO and will do it.

          Now for the results, maybe it worked fine for EN-ZH but honestly I think
          for EN-DE it overfitted the metric (comet). -10 Bleu is HUGE at a system
          level. I can understand that a sentence level this can happen but for a
          system I don''t think so. I will be very interested to look at the human
          eval. Anyhow nice paper, congrats.'
        updatedAt: '2024-01-19T18:08:40.826Z'
      numEdits: 0
      reactions: []
    id: 65aabaa82bf3e0cbbf2c663f
    type: comment
  author: vince62s
  content: 'FYI I am one of the maintainer of OpenNMT-py and have been working on
    NMT for a long long time.

    I was about to implement DPO in the repo when I saw your paper, so it seems easier
    to implement CPO and will do it.

    Now for the results, maybe it worked fine for EN-ZH but honestly I think for EN-DE
    it overfitted the metric (comet). -10 Bleu is HUGE at a system level. I can understand
    that a sentence level this can happen but for a system I don''t think so. I will
    be very interested to look at the human eval. Anyhow nice paper, congrats.'
  created_at: 2024-01-19 18:08:40+00:00
  edited: false
  hidden: false
  id: 65aabaa82bf3e0cbbf2c663f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: haoranxu/ALMA-13B-R
repo_type: model
status: open
target_branch: null
title: The GPT-4 comparison is a bit too early (yet?)
