!!python/object:huggingface_hub.community.DiscussionWithDetails
author: iamrobotbear
conflicting_files: null
created_at: 2023-08-07 14:02:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9af57ddd73fc94d02499d54478d0cfeb.svg
      fullname: Brian King
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iamrobotbear
      type: user
    createdAt: '2023-08-07T15:02:53.000Z'
    data:
      edited: false
      editors:
      - iamrobotbear
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7719109058380127
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9af57ddd73fc94d02499d54478d0cfeb.svg
          fullname: Brian King
          isHf: false
          isPro: false
          name: iamrobotbear
          type: user
        html: "<p>Thank you for this. Can you share your process for getting this\
          \ running in 8bit mode?</p>\n<p>I'd love to have this done for InstructBlip\
          \ Flan-t5xl and xxl. </p>\n<p>How does this impact your vram requirements\
          \ and inference speed/accuracy?</p>\n<ul>\n<li><a href=\"https://huggingface.co/Salesforce/instructblip-flan-t5-xl\"\
          >Salesforce Huggingface Model Page for InstructBlip Flan-T5xl</a></li>\n\
          <li><a href=\"https://huggingface.co/Salesforce/instructblip-flan-t5-xxl\"\
          >Salesforce Huggingface Model Page for InstructBlip Flan-T5xxl</a></li>\n\
          </ul>\n<p>Thanks again, <span data-props=\"{&quot;user&quot;:&quot;Mediocreatmybest&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Mediocreatmybest\"\
          >@<span class=\"underline\">Mediocreatmybest</span></a></span>\n\n\t</span></span>\
          \ </p>\n"
        raw: "Thank you for this. Can you share your process for getting this running\
          \ in 8bit mode?\r\n\r\nI'd love to have this done for InstructBlip Flan-t5xl\
          \ and xxl. \r\n\r\nHow does this impact your vram requirements and inference\
          \ speed/accuracy?\r\n\r\n* [Salesforce Huggingface Model Page for InstructBlip\
          \ Flan-T5xl](https://huggingface.co/Salesforce/instructblip-flan-t5-xl)\r\
          \n* [Salesforce Huggingface Model Page for InstructBlip Flan-T5xxl](https://huggingface.co/Salesforce/instructblip-flan-t5-xxl)\r\
          \n\r\nThanks again, @Mediocreatmybest "
        updatedAt: '2023-08-07T15:02:53.167Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Mediocreatmybest
    id: 64d1079d01931c60163b350a
    type: comment
  author: iamrobotbear
  content: "Thank you for this. Can you share your process for getting this running\
    \ in 8bit mode?\r\n\r\nI'd love to have this done for InstructBlip Flan-t5xl and\
    \ xxl. \r\n\r\nHow does this impact your vram requirements and inference speed/accuracy?\r\
    \n\r\n* [Salesforce Huggingface Model Page for InstructBlip Flan-T5xl](https://huggingface.co/Salesforce/instructblip-flan-t5-xl)\r\
    \n* [Salesforce Huggingface Model Page for InstructBlip Flan-T5xxl](https://huggingface.co/Salesforce/instructblip-flan-t5-xxl)\r\
    \n\r\nThanks again, @Mediocreatmybest "
  created_at: 2023-08-07 14:02:53+00:00
  edited: false
  hidden: false
  id: 64d1079d01931c60163b350a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676512038653-63074ea3cb09c0a90429ce3b.png?w=200&h=200&f=face
      fullname: Sir Mediocre Jr, Esq.
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Mediocreatmybest
      type: user
    createdAt: '2023-08-08T02:17:35.000Z'
    data:
      edited: false
      editors:
      - Mediocreatmybest
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6991875767707825
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676512038653-63074ea3cb09c0a90429ce3b.png?w=200&h=200&f=face
          fullname: Sir Mediocre Jr, Esq.
          isHf: false
          isPro: false
          name: Mediocreatmybest
          type: user
        html: '<p>I just modified the example on the InstructBlip model page:  --&gt;
          <a href="https://huggingface.co/Salesforce/instructblip-vicuna-7b">https://huggingface.co/Salesforce/instructblip-vicuna-7b</a></p>

          <p>Adding in the 8bit options, I''ve found dropping it down to 4bit can
          lead to slightly different output that is less descriptive, 8bit seems to
          be a good compromise.<br>I haven''t been able to check it against the full
          precision weights as all the InstructBlip models are huge it either "Out
          of Memory error" or crashes due to consuming all the CPU RAM.<br>They are
          30GB to 50GB + or so in size, so not very consumer hardware friendly.</p>

          <p>This is the example I''ve ran with (using bitsandbytes / accelerate)</p>

          <p>from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration<br>import
          torch<br>from PIL import Image<br>import requests</p>

          <p>device = "cuda" if torch.cuda.is_available() else "cpu"</p>

          <p>processor = InstructBlipProcessor.from_pretrained("Mediocreatmybest/instructblip-vicuna-7b_8bit")<br>model
          = InstructBlipForConditionalGeneration.from_pretrained("Mediocreatmybest/instructblip-vicuna-7b_8bit",<br>                                                             load_in_8bit=True,<br>                                                             device_map="auto",<br>                                                             llm_int8_enable_fp32_cpu_offload=False)</p>

          <p>url = "<a href="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&quot;">https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"</a><br>image
          = Image.open(requests.get(url, stream=True).raw).convert("RGB")<br>prompt
          = "Please provide a concise description of the image''s art style and subject
          matter"<br>inputs = processor(images=image, text=prompt, return_tensors="pt").to("cuda",
          torch.float16)</p>

          <p>outputs = model.generate(<br>    **inputs,<br>    do_sample=False,<br>    num_beams=5,<br>    max_length=150,<br>    min_length=1,<br>    top_p=0.9,<br>    repetition_penalty=1.5,<br>    length_penalty=1.5,<br>    temperature=1,<br>)<br>generated_text
          = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()<br>print(generated_text)</p>

          <p>I''m happy to try convert the xxl and xl model when I get the chance.
          </p>

          '
        raw: "I just modified the example on the InstructBlip model page:  --> https://huggingface.co/Salesforce/instructblip-vicuna-7b\n\
          \nAdding in the 8bit options, I've found dropping it down to 4bit can lead\
          \ to slightly different output that is less descriptive, 8bit seems to be\
          \ a good compromise. \nI haven't been able to check it against the full\
          \ precision weights as all the InstructBlip models are huge it either \"\
          Out of Memory error\" or crashes due to consuming all the CPU RAM. \nThey\
          \ are 30GB to 50GB + or so in size, so not very consumer hardware friendly.\n\
          \nThis is the example I've ran with (using bitsandbytes / accelerate)\n\n\
          from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n\
          import torch\nfrom PIL import Image\nimport requests\n\ndevice = \"cuda\"\
          \ if torch.cuda.is_available() else \"cpu\"\n\nprocessor = InstructBlipProcessor.from_pretrained(\"\
          Mediocreatmybest/instructblip-vicuna-7b_8bit\")\nmodel = InstructBlipForConditionalGeneration.from_pretrained(\"\
          Mediocreatmybest/instructblip-vicuna-7b_8bit\",\n                      \
          \                                       load_in_8bit=True,\n           \
          \                                                  device_map=\"auto\",\n\
          \                                                             llm_int8_enable_fp32_cpu_offload=False)\n\
          \n\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\
          \nimage = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\"\
          )\nprompt = \"Please provide a concise description of the image's art style\
          \ and subject matter\"\ninputs = processor(images=image, text=prompt, return_tensors=\"\
          pt\").to(\"cuda\", torch.float16)\n\noutputs = model.generate(\n    **inputs,\n\
          \    do_sample=False,\n    num_beams=5,\n    max_length=150,\n    min_length=1,\n\
          \    top_p=0.9,\n    repetition_penalty=1.5,\n    length_penalty=1.5,\n\
          \    temperature=1,\n)\ngenerated_text = processor.batch_decode(outputs,\
          \ skip_special_tokens=True)[0].strip()\nprint(generated_text)\n\nI'm happy\
          \ to try convert the xxl and xl model when I get the chance. \n"
        updatedAt: '2023-08-08T02:17:35.332Z'
      numEdits: 0
      reactions: []
    id: 64d1a5bf0b71aea8bea1a5e4
    type: comment
  author: Mediocreatmybest
  content: "I just modified the example on the InstructBlip model page:  --> https://huggingface.co/Salesforce/instructblip-vicuna-7b\n\
    \nAdding in the 8bit options, I've found dropping it down to 4bit can lead to\
    \ slightly different output that is less descriptive, 8bit seems to be a good\
    \ compromise. \nI haven't been able to check it against the full precision weights\
    \ as all the InstructBlip models are huge it either \"Out of Memory error\" or\
    \ crashes due to consuming all the CPU RAM. \nThey are 30GB to 50GB + or so in\
    \ size, so not very consumer hardware friendly.\n\nThis is the example I've ran\
    \ with (using bitsandbytes / accelerate)\n\nfrom transformers import InstructBlipProcessor,\
    \ InstructBlipForConditionalGeneration\nimport torch\nfrom PIL import Image\n\
    import requests\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\
    \n\nprocessor = InstructBlipProcessor.from_pretrained(\"Mediocreatmybest/instructblip-vicuna-7b_8bit\"\
    )\nmodel = InstructBlipForConditionalGeneration.from_pretrained(\"Mediocreatmybest/instructblip-vicuna-7b_8bit\"\
    ,\n                                                             load_in_8bit=True,\n\
    \                                                             device_map=\"auto\"\
    ,\n                                                             llm_int8_enable_fp32_cpu_offload=False)\n\
    \n\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\
    \nimage = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\nprompt\
    \ = \"Please provide a concise description of the image's art style and subject\
    \ matter\"\ninputs = processor(images=image, text=prompt, return_tensors=\"pt\"\
    ).to(\"cuda\", torch.float16)\n\noutputs = model.generate(\n    **inputs,\n  \
    \  do_sample=False,\n    num_beams=5,\n    max_length=150,\n    min_length=1,\n\
    \    top_p=0.9,\n    repetition_penalty=1.5,\n    length_penalty=1.5,\n    temperature=1,\n\
    )\ngenerated_text = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n\
    print(generated_text)\n\nI'm happy to try convert the xxl and xl model when I\
    \ get the chance. \n"
  created_at: 2023-08-08 01:17:35+00:00
  edited: false
  hidden: false
  id: 64d1a5bf0b71aea8bea1a5e4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676512038653-63074ea3cb09c0a90429ce3b.png?w=200&h=200&f=face
      fullname: Sir Mediocre Jr, Esq.
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Mediocreatmybest
      type: user
    createdAt: '2023-08-08T04:15:57.000Z'
    data:
      edited: false
      editors:
      - Mediocreatmybest
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8739550709724426
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676512038653-63074ea3cb09c0a90429ce3b.png?w=200&h=200&f=face
          fullname: Sir Mediocre Jr, Esq.
          isHf: false
          isPro: false
          name: Mediocreatmybest
          type: user
        html: '<p>I can''t access a large enough GPU for the XXL, (And I haven''t
          tested it, but it should work) --&gt; <a href="https://huggingface.co/Mediocreatmybest/instructblip-flan-t5-xl_8bit">https://huggingface.co/Mediocreatmybest/instructblip-flan-t5-xl_8bit</a></p>

          '
        raw: I can't access a large enough GPU for the XXL, (And I haven't tested
          it, but it should work) --> https://huggingface.co/Mediocreatmybest/instructblip-flan-t5-xl_8bit
        updatedAt: '2023-08-08T04:15:57.204Z'
      numEdits: 0
      reactions: []
    id: 64d1c17d86e19d5db1bf3093
    type: comment
  author: Mediocreatmybest
  content: I can't access a large enough GPU for the XXL, (And I haven't tested it,
    but it should work) --> https://huggingface.co/Mediocreatmybest/instructblip-flan-t5-xl_8bit
  created_at: 2023-08-08 03:15:57+00:00
  edited: false
  hidden: false
  id: 64d1c17d86e19d5db1bf3093
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676512038653-63074ea3cb09c0a90429ce3b.png?w=200&h=200&f=face
      fullname: Sir Mediocre Jr, Esq.
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Mediocreatmybest
      type: user
    createdAt: '2023-08-08T06:15:24.000Z'
    data:
      edited: false
      editors:
      - Mediocreatmybest
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6885208487510681
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676512038653-63074ea3cb09c0a90429ce3b.png?w=200&h=200&f=face
          fullname: Sir Mediocre Jr, Esq.
          isHf: false
          isPro: false
          name: Mediocreatmybest
          type: user
        html: '<p>Was able to jump into the queue and spin it up --&gt; <a href="https://huggingface.co/Mediocreatmybest/instructblip-flan-t5-xxl_8bit">https://huggingface.co/Mediocreatmybest/instructblip-flan-t5-xxl_8bit</a></p>

          '
        raw: Was able to jump into the queue and spin it up --> https://huggingface.co/Mediocreatmybest/instructblip-flan-t5-xxl_8bit
        updatedAt: '2023-08-08T06:15:24.358Z'
      numEdits: 0
      reactions: []
    id: 64d1dd7cd8d092737200f037
    type: comment
  author: Mediocreatmybest
  content: Was able to jump into the queue and spin it up --> https://huggingface.co/Mediocreatmybest/instructblip-flan-t5-xxl_8bit
  created_at: 2023-08-08 05:15:24+00:00
  edited: false
  hidden: false
  id: 64d1dd7cd8d092737200f037
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676512038653-63074ea3cb09c0a90429ce3b.png?w=200&h=200&f=face
      fullname: Sir Mediocre Jr, Esq.
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Mediocreatmybest
      type: user
    createdAt: '2023-08-10T22:32:14.000Z'
    data:
      status: closed
    id: 64d5656e6db135cfc88b9cb0
    type: status-change
  author: Mediocreatmybest
  created_at: 2023-08-10 21:32:14+00:00
  id: 64d5656e6db135cfc88b9cb0
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9af57ddd73fc94d02499d54478d0cfeb.svg
      fullname: Brian King
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iamrobotbear
      type: user
    createdAt: '2023-08-10T22:49:21.000Z'
    data:
      edited: false
      editors:
      - iamrobotbear
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.46368739008903503
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9af57ddd73fc94d02499d54478d0cfeb.svg
          fullname: Brian King
          isHf: false
          isPro: false
          name: iamrobotbear
          type: user
        html: '<p>Thank you!</p>

          '
        raw: Thank you!
        updatedAt: '2023-08-10T22:49:21.515Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Mediocreatmybest
    id: 64d56971505306fcd297b271
    type: comment
  author: iamrobotbear
  content: Thank you!
  created_at: 2023-08-10 21:49:21+00:00
  edited: false
  hidden: false
  id: 64d56971505306fcd297b271
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676512038653-63074ea3cb09c0a90429ce3b.png?w=200&h=200&f=face
      fullname: Sir Mediocre Jr, Esq.
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Mediocreatmybest
      type: user
    createdAt: '2023-08-11T04:07:40.000Z'
    data:
      edited: false
      editors:
      - Mediocreatmybest
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.959597647190094
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676512038653-63074ea3cb09c0a90429ce3b.png?w=200&h=200&f=face
          fullname: Sir Mediocre Jr, Esq.
          isHf: false
          isPro: false
          name: Mediocreatmybest
          type: user
        html: "<p>\U0001F44D hopefully works well :)<br>I\u2019ve tested and seemed\
          \ ok. </p>\n"
        raw: "\U0001F44D hopefully works well :) \nI\u2019ve tested and seemed ok. "
        updatedAt: '2023-08-11T04:07:40.030Z'
      numEdits: 0
      reactions: []
    id: 64d5b40c79d99b87001fdcad
    type: comment
  author: Mediocreatmybest
  content: "\U0001F44D hopefully works well :) \nI\u2019ve tested and seemed ok. "
  created_at: 2023-08-11 03:07:40+00:00
  edited: false
  hidden: false
  id: 64d5b40c79d99b87001fdcad
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Mediocreatmybest/instructblip-vicuna-7b_8bit
repo_type: model
status: closed
target_branch: null
title: Question & thank you
