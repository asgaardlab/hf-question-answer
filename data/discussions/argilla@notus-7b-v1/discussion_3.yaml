!!python/object:huggingface_hub.community.DiscussionWithDetails
author: LaferriereJC
conflicting_files: null
created_at: 2023-12-03 14:33:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7e8da869c47dbc3f9052f1cbd4cc5ae6.svg
      fullname: Joshua Laferriere
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LaferriereJC
      type: user
    createdAt: '2023-12-03T14:33:51.000Z'
    data:
      edited: false
      editors:
      - LaferriereJC
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8164224624633789
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7e8da869c47dbc3f9052f1cbd4cc5ae6.svg
          fullname: Joshua Laferriere
          isHf: false
          isPro: false
          name: LaferriereJC
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span><br>Can you gguf'izer\
          \ these?</p>\n"
        raw: "@TheBloke \r\nCan you gguf'izer these?"
        updatedAt: '2023-12-03T14:33:51.296Z'
      numEdits: 0
      reactions: []
    id: 656c91cf02a56b531aa48664
    type: comment
  author: LaferriereJC
  content: "@TheBloke \r\nCan you gguf'izer these?"
  created_at: 2023-12-03 14:33:51+00:00
  edited: false
  hidden: false
  id: 656c91cf02a56b531aa48664
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c6f1579ade6ce37610f3a07aaab83e4b.svg
      fullname: YAKOV BRL
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YAKOVNUKJHJ
      type: user
    createdAt: '2023-12-03T14:34:48.000Z'
    data:
      edited: false
      editors:
      - YAKOVNUKJHJ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9625282883644104
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c6f1579ade6ce37610f3a07aaab83e4b.svg
          fullname: YAKOV BRL
          isHf: false
          isPro: false
          name: YAKOVNUKJHJ
          type: user
        html: '<p>I''m waiting for it too, it''s the best model I''ve met so far</p>

          '
        raw: I'm waiting for it too, it's the best model I've met so far
        updatedAt: '2023-12-03T14:34:48.405Z'
      numEdits: 0
      reactions: []
    id: 656c9208c56388a985fa0447
    type: comment
  author: YAKOVNUKJHJ
  content: I'm waiting for it too, it's the best model I've met so far
  created_at: 2023-12-03 14:34:48+00:00
  edited: false
  hidden: false
  id: 656c9208c56388a985fa0447
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-03T20:36:53.000Z'
    data:
      edited: true
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9902963042259216
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>The Bloke just released it.</p>

          <p>Edit: I''m getting the newline character typed vs applied, such as &lt;0x0A&gt;&lt;0x0A&gt;
          rather than new paragraphs. Is this just the case for the GGUF version,
          the GPT4ALL app I''m using... or does it also happen with this unquantized
          version?</p>

          '
        raw: 'The Bloke just released it.


          Edit: I''m getting the newline character typed vs applied, such as <0x0A><0x0A>
          rather than new paragraphs. Is this just the case for the GGUF version,
          the GPT4ALL app I''m using... or does it also happen with this unquantized
          version?'
        updatedAt: '2023-12-03T20:49:08.275Z'
      numEdits: 1
      reactions: []
    id: 656ce6e5665d15428aaf8385
    type: comment
  author: Phil337
  content: 'The Bloke just released it.


    Edit: I''m getting the newline character typed vs applied, such as <0x0A><0x0A>
    rather than new paragraphs. Is this just the case for the GGUF version, the GPT4ALL
    app I''m using... or does it also happen with this unquantized version?'
  created_at: 2023-12-03 20:36:53+00:00
  edited: true
  hidden: false
  id: 656ce6e5665d15428aaf8385
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60f0608166e5701b80ed3f02/ZSIRRZgthYnTinV1wGE1N.jpeg?w=200&h=200&f=face
      fullname: Alvaro Bartolome
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: alvarobartt
      type: user
    createdAt: '2023-12-04T08:15:17.000Z'
    data:
      edited: false
      editors:
      - alvarobartt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8450084328651428
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60f0608166e5701b80ed3f02/ZSIRRZgthYnTinV1wGE1N.jpeg?w=200&h=200&f=face
          fullname: Alvaro Bartolome
          isHf: false
          isPro: false
          name: alvarobartt
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;LaferriereJC&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/LaferriereJC\"\
          >@<span class=\"underline\">LaferriereJC</span></a></span>\n\n\t</span></span>\
          \ <span data-props=\"{&quot;user&quot;:&quot;YAKOVNUKJHJ&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/YAKOVNUKJHJ\">@<span\
          \ class=\"underline\">YAKOVNUKJHJ</span></a></span>\n\n\t</span></span>,\
          \ good news \u2728 The awesome <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ has already quantized those (announced recently at <a rel=\"nofollow\"\
          \ href=\"https://twitter.com/alvarobartt/status/1731587062522929520\">https://twitter.com/alvarobartt/status/1731587062522929520</a>)\
          \ so you should already be able to use those, either GGUF or AWQ.</p>\n"
        raw: "Hi @LaferriereJC @YAKOVNUKJHJ, good news \u2728 The awesome @TheBloke\
          \ has already quantized those (announced recently at https://twitter.com/alvarobartt/status/1731587062522929520)\
          \ so you should already be able to use those, either GGUF or AWQ."
        updatedAt: '2023-12-04T08:15:17.057Z'
      numEdits: 0
      reactions: []
    id: 656d8a95b9fa60e33d1d08f9
    type: comment
  author: alvarobartt
  content: "Hi @LaferriereJC @YAKOVNUKJHJ, good news \u2728 The awesome @TheBloke\
    \ has already quantized those (announced recently at https://twitter.com/alvarobartt/status/1731587062522929520)\
    \ so you should already be able to use those, either GGUF or AWQ."
  created_at: 2023-12-04 08:15:17+00:00
  edited: false
  hidden: false
  id: 656d8a95b9fa60e33d1d08f9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60f0608166e5701b80ed3f02/ZSIRRZgthYnTinV1wGE1N.jpeg?w=200&h=200&f=face
      fullname: Alvaro Bartolome
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: alvarobartt
      type: user
    createdAt: '2023-12-04T08:16:11.000Z'
    data:
      edited: false
      editors:
      - alvarobartt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.946406900882721
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60f0608166e5701b80ed3f02/ZSIRRZgthYnTinV1wGE1N.jpeg?w=200&h=200&f=face
          fullname: Alvaro Bartolome
          isHf: false
          isPro: false
          name: alvarobartt
          type: user
        html: "<blockquote>\n<p>Edit: I'm getting the newline character typed vs applied,\
          \ such as &lt;0x0A&gt;&lt;0x0A&gt; rather than new paragraphs. Is this just\
          \ the case for the GGUF version, the GPT4ALL app I'm using... or does it\
          \ also happen with this unquantized version?</p>\n</blockquote>\n<p>Hi here\
          \ <span data-props=\"{&quot;user&quot;:&quot;Phil337&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Phil337\">@<span class=\"\
          underline\">Phil337</span></a></span>\n\n\t</span></span> could you elaborate\
          \ a bit on this? Is it related to the GGUF quantized weights, or just to\
          \ prompting within the Notus model?</p>\n"
        raw: '> Edit: I''m getting the newline character typed vs applied, such as
          <0x0A><0x0A> rather than new paragraphs. Is this just the case for the GGUF
          version, the GPT4ALL app I''m using... or does it also happen with this
          unquantized version?


          Hi here @Phil337 could you elaborate a bit on this? Is it related to the
          GGUF quantized weights, or just to prompting within the Notus model?'
        updatedAt: '2023-12-04T08:16:11.029Z'
      numEdits: 0
      reactions: []
    id: 656d8acb02a56b531ad2aacf
    type: comment
  author: alvarobartt
  content: '> Edit: I''m getting the newline character typed vs applied, such as <0x0A><0x0A>
    rather than new paragraphs. Is this just the case for the GGUF version, the GPT4ALL
    app I''m using... or does it also happen with this unquantized version?


    Hi here @Phil337 could you elaborate a bit on this? Is it related to the GGUF
    quantized weights, or just to prompting within the Notus model?'
  created_at: 2023-12-04 08:16:11+00:00
  edited: false
  hidden: false
  id: 656d8acb02a56b531ad2aacf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-04T08:33:37.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9602953195571899
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;alvarobartt&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/alvarobartt\"\
          >@<span class=\"underline\">alvarobartt</span></a></span>\n\n\t</span></span>\
          \ It must be due to the GGUF version (I'm using Q4_0) or how it mixes with\
          \ GPT4All because it's EVERY newline and paragraph regardless of prompt.\
          \ There's a known token issue with GPT4All and the latest GGUF implementation\
          \ that they say on the Github page is going to be fixed with the next update,\
          \ so maybe that's it. Other than this Lotus performed very well. </p>\n"
        raw: '@alvarobartt It must be due to the GGUF version (I''m using Q4_0) or
          how it mixes with GPT4All because it''s EVERY newline and paragraph regardless
          of prompt. There''s a known token issue with GPT4All and the latest GGUF
          implementation that they say on the Github page is going to be fixed with
          the next update, so maybe that''s it. Other than this Lotus performed very
          well. '
        updatedAt: '2023-12-04T08:33:37.926Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - alvarobartt
    id: 656d8ee17825b31010406d30
    type: comment
  author: Phil337
  content: '@alvarobartt It must be due to the GGUF version (I''m using Q4_0) or how
    it mixes with GPT4All because it''s EVERY newline and paragraph regardless of
    prompt. There''s a known token issue with GPT4All and the latest GGUF implementation
    that they say on the Github page is going to be fixed with the next update, so
    maybe that''s it. Other than this Lotus performed very well. '
  created_at: 2023-12-04 08:33:37+00:00
  edited: false
  hidden: false
  id: 656d8ee17825b31010406d30
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60f0608166e5701b80ed3f02/ZSIRRZgthYnTinV1wGE1N.jpeg?w=200&h=200&f=face
      fullname: Alvaro Bartolome
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: alvarobartt
      type: user
    createdAt: '2023-12-04T08:36:48.000Z'
    data:
      edited: false
      editors:
      - alvarobartt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9865918159484863
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60f0608166e5701b80ed3f02/ZSIRRZgthYnTinV1wGE1N.jpeg?w=200&h=200&f=face
          fullname: Alvaro Bartolome
          isHf: false
          isPro: false
          name: alvarobartt
          type: user
        html: "<p>Happy to hear that <span data-props=\"{&quot;user&quot;:&quot;Phil337&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Phil337\"\
          >@<span class=\"underline\">Phil337</span></a></span>\n\n\t</span></span>,\
          \ we'll also play around a bit with the quantized versions this week! </p>\n"
        raw: 'Happy to hear that @Phil337, we''ll also play around a bit with the
          quantized versions this week! '
        updatedAt: '2023-12-04T08:36:48.575Z'
      numEdits: 0
      reactions: []
    id: 656d8fa002a56b531ad39183
    type: comment
  author: alvarobartt
  content: 'Happy to hear that @Phil337, we''ll also play around a bit with the quantized
    versions this week! '
  created_at: 2023-12-04 08:36:48+00:00
  edited: false
  hidden: false
  id: 656d8fa002a56b531ad39183
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60f0608166e5701b80ed3f02/ZSIRRZgthYnTinV1wGE1N.jpeg?w=200&h=200&f=face
      fullname: Alvaro Bartolome
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: alvarobartt
      type: user
    createdAt: '2023-12-04T08:36:51.000Z'
    data:
      status: closed
    id: 656d8fa34ab7bc884dcc6afe
    type: status-change
  author: alvarobartt
  created_at: 2023-12-04 08:36:51+00:00
  id: 656d8fa34ab7bc884dcc6afe
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60f0608166e5701b80ed3f02/ZSIRRZgthYnTinV1wGE1N.jpeg?w=200&h=200&f=face
      fullname: Alvaro Bartolome
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: alvarobartt
      type: user
    createdAt: '2023-12-04T12:45:12.000Z'
    data:
      edited: false
      editors:
      - alvarobartt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.953028678894043
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60f0608166e5701b80ed3f02/ZSIRRZgthYnTinV1wGE1N.jpeg?w=200&h=200&f=face
          fullname: Alvaro Bartolome
          isHf: false
          isPro: false
          name: alvarobartt
          type: user
        html: "<p>Hi again <span data-props=\"{&quot;user&quot;:&quot;Phil337&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Phil337\"\
          >@<span class=\"underline\">Phil337</span></a></span>\n\n\t</span></span>\
          \ after reading a bit more it seems that the issue of the <code>&lt;0x0A&gt;</code>\
          \ tokens was because the file <code>tokenizer.model</code> (SetencePiece\
          \ based tokenizer, slow tokenizer) was missing and the GGUF quantized version\
          \ had to build the tokenizer from the existing vocab file and that was leading\
          \ to some errors, I saw that also being reported at <a href=\"https://huggingface.co/TheBloke/Starling-LM-7B-alpha-GGUF/discussions/1\"\
          >https://huggingface.co/TheBloke/Starling-LM-7B-alpha-GGUF/discussions/1</a>,\
          \ and finally decided to port it from <a href=\"https://huggingface.co/HuggingFaceH4/zephyr-7b-beta/blob/main/tokenizer.model\"\
          >https://huggingface.co/HuggingFaceH4/zephyr-7b-beta/blob/main/tokenizer.model</a>,\
          \ as we're using the same tokenizer. Also thanks to <span data-props=\"\
          {&quot;user&quot;:&quot;plaguss&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/plaguss\">@<span class=\"underline\">plaguss</span></a></span>\n\
          \n\t</span></span> for internally reporting it!</p>\n"
        raw: Hi again @Phil337 after reading a bit more it seems that the issue of
          the `<0x0A>` tokens was because the file `tokenizer.model` (SetencePiece
          based tokenizer, slow tokenizer) was missing and the GGUF quantized version
          had to build the tokenizer from the existing vocab file and that was leading
          to some errors, I saw that also being reported at https://huggingface.co/TheBloke/Starling-LM-7B-alpha-GGUF/discussions/1,
          and finally decided to port it from https://huggingface.co/HuggingFaceH4/zephyr-7b-beta/blob/main/tokenizer.model,
          as we're using the same tokenizer. Also thanks to @plaguss for internally
          reporting it!
        updatedAt: '2023-12-04T12:45:12.237Z'
      numEdits: 0
      reactions: []
    id: 656dc9d802a56b531ade7f73
    type: comment
  author: alvarobartt
  content: Hi again @Phil337 after reading a bit more it seems that the issue of the
    `<0x0A>` tokens was because the file `tokenizer.model` (SetencePiece based tokenizer,
    slow tokenizer) was missing and the GGUF quantized version had to build the tokenizer
    from the existing vocab file and that was leading to some errors, I saw that also
    being reported at https://huggingface.co/TheBloke/Starling-LM-7B-alpha-GGUF/discussions/1,
    and finally decided to port it from https://huggingface.co/HuggingFaceH4/zephyr-7b-beta/blob/main/tokenizer.model,
    as we're using the same tokenizer. Also thanks to @plaguss for internally reporting
    it!
  created_at: 2023-12-04 12:45:12+00:00
  edited: false
  hidden: false
  id: 656dc9d802a56b531ade7f73
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-04T14:45:26.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9140474200248718
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;alvarobartt&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/alvarobartt\"\
          >@<span class=\"underline\">alvarobartt</span></a></span>\n\n\t</span></span>\
          \ Thanks for looking into it and finding the cause. </p>\n"
        raw: '@alvarobartt Thanks for looking into it and finding the cause. '
        updatedAt: '2023-12-04T14:45:26.774Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - alvarobartt
    id: 656de60672c19de723b696b5
    type: comment
  author: Phil337
  content: '@alvarobartt Thanks for looking into it and finding the cause. '
  created_at: 2023-12-04 14:45:26+00:00
  edited: false
  hidden: false
  id: 656de60672c19de723b696b5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: argilla/notus-7b-v1
repo_type: model
status: closed
target_branch: null
title: gguf?
