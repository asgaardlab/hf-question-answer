!!python/object:huggingface_hub.community.DiscussionWithDetails
author: oMateos2020
conflicting_files: null
created_at: 2023-09-13 08:49:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9f930d343daee1f4c00104e46aabffb7.svg
      fullname: "\xD3scar Mateos L\xF3pez"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: oMateos2020
      type: user
    createdAt: '2023-09-13T09:49:17.000Z'
    data:
      edited: true
      editors:
      - oMateos2020
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5324602127075195
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9f930d343daee1f4c00104e46aabffb7.svg
          fullname: "\xD3scar Mateos L\xF3pez"
          isHf: false
          isPro: false
          name: oMateos2020
          type: user
        html: '<p>Hi everyone,<br>I am trying to use flair/ner-spanish-large model
          for extracting several entities from spanish sentences. I tested it in the
          Hosted inference API and liked the results, so I did a notebook to test
          it locally, but I get the next error:</p>

          <p>RuntimeError                              Traceback (most recent call
          last)<br>Cell In[4], line 2<br>      1 # load tagger<br>----&gt; 2 tagger
          = SequenceTagger.load("flair/ner-spanish-large")<br>      4 # make example
          sentence<br>      5 sentence = Sentence("George Washington fue a Washington.
          ")</p>

          <p>File ~.conda\envs\flair_0_12_2\lib\site-packages\flair\models\sequence_tagger_model.py:1035,
          in SequenceTagger.load(cls, model_path)<br>   1031 @classmethod<br>   1032
          def load(cls, model_path: Union[str, Path, Dict[str, Any]]) -&gt; "SequenceTagger":<br>   1033     from
          typing import cast<br>-&gt; 1035     return cast("SequenceTagger", super().load(model_path=model_path))</p>

          <p>File ~.conda\envs\flair_0_12_2\lib\site-packages\flair\nn\model.py:559,
          in Classifier.load(cls, model_path)<br>    555 @classmethod<br>    556 def
          load(cls, model_path: Union[str, Path, Dict[str, Any]]) -&gt; "Classifier":<br>    557     from
          typing import cast<br>--&gt; 559     return cast("Classifier", super().load(model_path=model_path))</p>

          <p>File ~.conda\envs\flair_0_12_2\lib\site-packages\flair\nn\model.py:191,
          in Model.load(cls, model_path)<br>    189 if not isinstance(model_path,
          dict):<br>    190     model_file = cls._fetch_model(str(model_path))<br>--&gt;
          191     state = load_torch_state(model_file)<br>    192 else:<br>    193     state
          = model_path</p>

          <p>File ~.conda\envs\flair_0_12_2\lib\site-packages\flair\file_utils.py:359,
          in load_torch_state(model_file)<br>    355 # load_big_file is a workaround
          by<a rel="nofollow" href="https://github.com/highway11git">https://github.com/highway11git</a><br>    356
          # to load models on some Mac/Windows setups<br>    357 # see <a rel="nofollow"
          href="https://github.com/zalandoresearch/flair/issues/351">https://github.com/zalandoresearch/flair/issues/351</a><br>    358
          f = load_big_file(model_file)<br>--&gt; 359 return torch.load(f, map_location="cpu")</p>

          <p>File ~.conda\envs\flair_0_12_2\lib\site-packages\torch\serialization.py:809,
          in load(f, map_location, pickle_module, weights_only, **pickle_load_args)<br>    807             except
          RuntimeError as e:<br>    808                 raise pickle.UnpicklingError(UNSAFE_MESSAGE
          + str(e)) from None<br>--&gt; 809         return _load(opened_zipfile, map_location,
          pickle_module, **pickle_load_args)<br>    810 if weights_only:<br>    811     try:</p>

          <p>File ~.conda\envs\flair_0_12_2\lib\site-packages\torch\serialization.py:1172,
          in _load(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)<br>   1170
          unpickler = UnpicklerWrapper(data_file, **pickle_load_args)<br>   1171 unpickler.persistent_load
          = persistent_load<br>-&gt; 1172 result = unpickler.load()<br>   1174 torch._utils._validate_loaded_sparse_tensors()<br>   1176
          return result</p>

          <p>File ~.conda\envs\flair_0_12_2\lib\site-packages\flair\embeddings\transformer.py:1169,
          in TransformerEmbeddings.<strong>setstate</strong>(self, state)<br>   1166     self.<strong>dict</strong>[key]
          = embedding.<strong>dict</strong>[key]<br>   1168 if model_state_dict:<br>-&gt;
          1169     self.model.load_state_dict(model_state_dict)</p>

          <p>File ~.conda\envs\flair_0_12_2\lib\site-packages\torch\nn\modules\module.py:2041,
          in Module.load_state_dict(self, state_dict, strict)<br>   2036         error_msgs.insert(<br>   2037             0,
          ''Missing key(s) in state_dict: {}. ''.format(<br>   2038                 '',
          ''.join(''"{}"''.format(k) for k in missing_keys)))<br>   2040 if len(error_msgs)
          &gt; 0:<br>-&gt; 2041     raise RuntimeError(''Error(s) in loading state_dict
          for {}:\n\t{}''.format(<br>   2042                        self.<strong>class</strong>.<strong>name</strong>,
          "\n\t".join(error_msgs)))<br>   2043 return _IncompatibleKeys(missing_keys,
          unexpected_keys)</p>

          <p>RuntimeError: Error(s) in loading state_dict for XLMRobertaModel:<br>    Unexpected
          key(s) in state_dict: "embeddings.position_ids". </p>

          <p>My code is the same from the demo:</p>

          <p>from flair.data import Sentence<br>from flair.models import SequenceTagger</p>

          <h1 id="load-tagger">load tagger</h1>

          <p>tagger = SequenceTagger.load("flair/ner-spanish-large")</p>

          <h1 id="make-example-sentence">make example sentence</h1>

          <p>sentence = Sentence("George Washington fue a Washington")</p>

          <h1 id="predict-ner-tags">predict NER tags</h1>

          <p>tagger.predict(sentence)</p>

          <h1 id="print-sentence">print sentence</h1>

          <p>print(sentence)</p>

          <p>And finally I tried to force to reinstall the dependecies as per the
          requirements file from the github repo which are as follows, but the RuntimeError
          from  the keys from state_dict for XLMRobertaModel persist the same as above,
          here the lines from the requirements file:</p>

          <p>boto3&gt;=1.20.27<br>bpemb&gt;=0.3.2<br>conllu&gt;=4.0<br>deprecated&gt;=1.2.13<br>ftfy&gt;=6.1.0<br>gdown&gt;=4.4.0<br>gensim&gt;=4.2.0<br>huggingface-hub&gt;=0.10.0<br>janome&gt;=0.4.2<br>langdetect&gt;=1.0.9<br>lxml&gt;=4.8.0<br>matplotlib&gt;=2.2.3<br>more-itertools&gt;=8.13.0<br>mpld3&gt;=0.3<br>pptree&gt;=3.1<br>python-dateutil&gt;=2.8.2<br>pytorch_revgrad&gt;=0.2.0<br>regex&gt;=2022.1.18<br>scikit-learn&gt;=1.0.2<br>segtok&gt;=1.5.11<br>sqlitedict&gt;=2.0.0<br>tabulate&gt;=0.8.10<br>torch&gt;=1.5.0,!=1.8<br>tqdm&gt;=4.63.0<br>transformer-smaller-training-vocab&gt;=0.2.3<br>transformers[sentencepiece]&gt;=4.18.0,&lt;5.0.0<br>urllib3&lt;2.0.0,&gt;=1.0.0  #
          pin below 2 to make dependency resolution faster.<br>wikipedia-api&gt;=0.5.7<br>semver&lt;4.0.0,&gt;=3.0.0</p>

          <p>Do you have any idea on why am I getting this error and if there is a
          way to make this working? I am under Windows 10 for job requirements, but
          I have tried also to run it in Google Colab getting the same error. ( <a
          rel="nofollow" href="https://colab.research.google.com/drive/1gEXkxDvK2MAY1ztGrN5z9uE0pzi6BAcs?usp=sharing">https://colab.research.google.com/drive/1gEXkxDvK2MAY1ztGrN5z9uE0pzi6BAcs?usp=sharing</a>
          ).</p>

          <p>Any help would be highly appreciated. Thanks in advance.</p>

          '
        raw: "Hi everyone, \nI am trying to use flair/ner-spanish-large model for\
          \ extracting several entities from spanish sentences. I tested it in the\
          \ Hosted inference API and liked the results, so I did a notebook to test\
          \ it locally, but I get the next error:\n\nRuntimeError                \
          \              Traceback (most recent call last)\nCell In[4], line 2\n \
          \     1 # load tagger\n----> 2 tagger = SequenceTagger.load(\"flair/ner-spanish-large\"\
          )\n      4 # make example sentence\n      5 sentence = Sentence(\"George\
          \ Washington fue a Washington. \")\n\nFile ~\\.conda\\envs\\flair_0_12_2\\\
          lib\\site-packages\\flair\\models\\sequence_tagger_model.py:1035, in SequenceTagger.load(cls,\
          \ model_path)\n   1031 @classmethod\n   1032 def load(cls, model_path: Union[str,\
          \ Path, Dict[str, Any]]) -> \"SequenceTagger\":\n   1033     from typing\
          \ import cast\n-> 1035     return cast(\"SequenceTagger\", super().load(model_path=model_path))\n\
          \nFile ~\\.conda\\envs\\flair_0_12_2\\lib\\site-packages\\flair\\nn\\model.py:559,\
          \ in Classifier.load(cls, model_path)\n    555 @classmethod\n    556 def\
          \ load(cls, model_path: Union[str, Path, Dict[str, Any]]) -> \"Classifier\"\
          :\n    557     from typing import cast\n--> 559     return cast(\"Classifier\"\
          , super().load(model_path=model_path))\n\nFile ~\\.conda\\envs\\flair_0_12_2\\\
          lib\\site-packages\\flair\\nn\\model.py:191, in Model.load(cls, model_path)\n\
          \    189 if not isinstance(model_path, dict):\n    190     model_file =\
          \ cls._fetch_model(str(model_path))\n--> 191     state = load_torch_state(model_file)\n\
          \    192 else:\n    193     state = model_path\n\nFile ~\\.conda\\envs\\\
          flair_0_12_2\\lib\\site-packages\\flair\\file_utils.py:359, in load_torch_state(model_file)\n\
          \    355 # load_big_file is a workaround byhttps://github.com/highway11git\n\
          \    356 # to load models on some Mac/Windows setups\n    357 # see https://github.com/zalandoresearch/flair/issues/351\n\
          \    358 f = load_big_file(model_file)\n--> 359 return torch.load(f, map_location=\"\
          cpu\")\n\nFile ~\\.conda\\envs\\flair_0_12_2\\lib\\site-packages\\torch\\\
          serialization.py:809, in load(f, map_location, pickle_module, weights_only,\
          \ **pickle_load_args)\n    807             except RuntimeError as e:\n \
          \   808                 raise pickle.UnpicklingError(UNSAFE_MESSAGE + str(e))\
          \ from None\n--> 809         return _load(opened_zipfile, map_location,\
          \ pickle_module, **pickle_load_args)\n    810 if weights_only:\n    811\
          \     try:\n\nFile ~\\.conda\\envs\\flair_0_12_2\\lib\\site-packages\\torch\\\
          serialization.py:1172, in _load(zip_file, map_location, pickle_module, pickle_file,\
          \ **pickle_load_args)\n   1170 unpickler = UnpicklerWrapper(data_file, **pickle_load_args)\n\
          \   1171 unpickler.persistent_load = persistent_load\n-> 1172 result = unpickler.load()\n\
          \   1174 torch._utils._validate_loaded_sparse_tensors()\n   1176 return\
          \ result\n\nFile ~\\.conda\\envs\\flair_0_12_2\\lib\\site-packages\\flair\\\
          embeddings\\transformer.py:1169, in TransformerEmbeddings.__setstate__(self,\
          \ state)\n   1166     self.__dict__[key] = embedding.__dict__[key]\n   1168\
          \ if model_state_dict:\n-> 1169     self.model.load_state_dict(model_state_dict)\n\
          \nFile ~\\.conda\\envs\\flair_0_12_2\\lib\\site-packages\\torch\\nn\\modules\\\
          module.py:2041, in Module.load_state_dict(self, state_dict, strict)\n  \
          \ 2036         error_msgs.insert(\n   2037             0, 'Missing key(s)\
          \ in state_dict: {}. '.format(\n   2038                 ', '.join('\"{}\"\
          '.format(k) for k in missing_keys)))\n   2040 if len(error_msgs) > 0:\n\
          -> 2041     raise RuntimeError('Error(s) in loading state_dict for {}:\\\
          n\\t{}'.format(\n   2042                        self.__class__.__name__,\
          \ \"\\n\\t\".join(error_msgs)))\n   2043 return _IncompatibleKeys(missing_keys,\
          \ unexpected_keys)\n\nRuntimeError: Error(s) in loading state_dict for XLMRobertaModel:\n\
          \tUnexpected key(s) in state_dict: \"embeddings.position_ids\". \n\nMy code\
          \ is the same from the demo:\n\nfrom flair.data import Sentence\nfrom flair.models\
          \ import SequenceTagger\n\n# load tagger\ntagger = SequenceTagger.load(\"\
          flair/ner-spanish-large\")\n\n# make example sentence\nsentence = Sentence(\"\
          George Washington fue a Washington\")\n\n# predict NER tags\ntagger.predict(sentence)\n\
          \n# print sentence\nprint(sentence)\n\nAnd finally I tried to force to reinstall\
          \ the dependecies as per the requirements file from the github repo which\
          \ are as follows, but the RuntimeError from  the keys from state_dict for\
          \ XLMRobertaModel persist the same as above, here the lines from the requirements\
          \ file:\n\nboto3>=1.20.27\nbpemb>=0.3.2\nconllu>=4.0\ndeprecated>=1.2.13\n\
          ftfy>=6.1.0\ngdown>=4.4.0\ngensim>=4.2.0\nhuggingface-hub>=0.10.0\njanome>=0.4.2\n\
          langdetect>=1.0.9\nlxml>=4.8.0\nmatplotlib>=2.2.3\nmore-itertools>=8.13.0\n\
          mpld3>=0.3\npptree>=3.1\npython-dateutil>=2.8.2\npytorch_revgrad>=0.2.0\n\
          regex>=2022.1.18\nscikit-learn>=1.0.2\nsegtok>=1.5.11\nsqlitedict>=2.0.0\n\
          tabulate>=0.8.10\ntorch>=1.5.0,!=1.8\ntqdm>=4.63.0\ntransformer-smaller-training-vocab>=0.2.3\n\
          transformers[sentencepiece]>=4.18.0,<5.0.0\nurllib3<2.0.0,>=1.0.0  # pin\
          \ below 2 to make dependency resolution faster.\nwikipedia-api>=0.5.7\n\
          semver<4.0.0,>=3.0.0\n\nDo you have any idea on why am I getting this error\
          \ and if there is a way to make this working? I am under Windows 10 for\
          \ job requirements, but I have tried also to run it in Google Colab getting\
          \ the same error. ( https://colab.research.google.com/drive/1gEXkxDvK2MAY1ztGrN5z9uE0pzi6BAcs?usp=sharing\
          \ ).\n\nAny help would be highly appreciated. Thanks in advance.\n\n"
        updatedAt: '2023-09-14T14:25:41.347Z'
      numEdits: 1
      reactions: []
    id: 6501859dff08101b32f0acfe
    type: comment
  author: oMateos2020
  content: "Hi everyone, \nI am trying to use flair/ner-spanish-large model for extracting\
    \ several entities from spanish sentences. I tested it in the Hosted inference\
    \ API and liked the results, so I did a notebook to test it locally, but I get\
    \ the next error:\n\nRuntimeError                              Traceback (most\
    \ recent call last)\nCell In[4], line 2\n      1 # load tagger\n----> 2 tagger\
    \ = SequenceTagger.load(\"flair/ner-spanish-large\")\n      4 # make example sentence\n\
    \      5 sentence = Sentence(\"George Washington fue a Washington. \")\n\nFile\
    \ ~\\.conda\\envs\\flair_0_12_2\\lib\\site-packages\\flair\\models\\sequence_tagger_model.py:1035,\
    \ in SequenceTagger.load(cls, model_path)\n   1031 @classmethod\n   1032 def load(cls,\
    \ model_path: Union[str, Path, Dict[str, Any]]) -> \"SequenceTagger\":\n   1033\
    \     from typing import cast\n-> 1035     return cast(\"SequenceTagger\", super().load(model_path=model_path))\n\
    \nFile ~\\.conda\\envs\\flair_0_12_2\\lib\\site-packages\\flair\\nn\\model.py:559,\
    \ in Classifier.load(cls, model_path)\n    555 @classmethod\n    556 def load(cls,\
    \ model_path: Union[str, Path, Dict[str, Any]]) -> \"Classifier\":\n    557  \
    \   from typing import cast\n--> 559     return cast(\"Classifier\", super().load(model_path=model_path))\n\
    \nFile ~\\.conda\\envs\\flair_0_12_2\\lib\\site-packages\\flair\\nn\\model.py:191,\
    \ in Model.load(cls, model_path)\n    189 if not isinstance(model_path, dict):\n\
    \    190     model_file = cls._fetch_model(str(model_path))\n--> 191     state\
    \ = load_torch_state(model_file)\n    192 else:\n    193     state = model_path\n\
    \nFile ~\\.conda\\envs\\flair_0_12_2\\lib\\site-packages\\flair\\file_utils.py:359,\
    \ in load_torch_state(model_file)\n    355 # load_big_file is a workaround byhttps://github.com/highway11git\n\
    \    356 # to load models on some Mac/Windows setups\n    357 # see https://github.com/zalandoresearch/flair/issues/351\n\
    \    358 f = load_big_file(model_file)\n--> 359 return torch.load(f, map_location=\"\
    cpu\")\n\nFile ~\\.conda\\envs\\flair_0_12_2\\lib\\site-packages\\torch\\serialization.py:809,\
    \ in load(f, map_location, pickle_module, weights_only, **pickle_load_args)\n\
    \    807             except RuntimeError as e:\n    808                 raise\
    \ pickle.UnpicklingError(UNSAFE_MESSAGE + str(e)) from None\n--> 809         return\
    \ _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n   \
    \ 810 if weights_only:\n    811     try:\n\nFile ~\\.conda\\envs\\flair_0_12_2\\\
    lib\\site-packages\\torch\\serialization.py:1172, in _load(zip_file, map_location,\
    \ pickle_module, pickle_file, **pickle_load_args)\n   1170 unpickler = UnpicklerWrapper(data_file,\
    \ **pickle_load_args)\n   1171 unpickler.persistent_load = persistent_load\n->\
    \ 1172 result = unpickler.load()\n   1174 torch._utils._validate_loaded_sparse_tensors()\n\
    \   1176 return result\n\nFile ~\\.conda\\envs\\flair_0_12_2\\lib\\site-packages\\\
    flair\\embeddings\\transformer.py:1169, in TransformerEmbeddings.__setstate__(self,\
    \ state)\n   1166     self.__dict__[key] = embedding.__dict__[key]\n   1168 if\
    \ model_state_dict:\n-> 1169     self.model.load_state_dict(model_state_dict)\n\
    \nFile ~\\.conda\\envs\\flair_0_12_2\\lib\\site-packages\\torch\\nn\\modules\\\
    module.py:2041, in Module.load_state_dict(self, state_dict, strict)\n   2036 \
    \        error_msgs.insert(\n   2037             0, 'Missing key(s) in state_dict:\
    \ {}. '.format(\n   2038                 ', '.join('\"{}\"'.format(k) for k in\
    \ missing_keys)))\n   2040 if len(error_msgs) > 0:\n-> 2041     raise RuntimeError('Error(s)\
    \ in loading state_dict for {}:\\n\\t{}'.format(\n   2042                    \
    \    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n   2043 return _IncompatibleKeys(missing_keys,\
    \ unexpected_keys)\n\nRuntimeError: Error(s) in loading state_dict for XLMRobertaModel:\n\
    \tUnexpected key(s) in state_dict: \"embeddings.position_ids\". \n\nMy code is\
    \ the same from the demo:\n\nfrom flair.data import Sentence\nfrom flair.models\
    \ import SequenceTagger\n\n# load tagger\ntagger = SequenceTagger.load(\"flair/ner-spanish-large\"\
    )\n\n# make example sentence\nsentence = Sentence(\"George Washington fue a Washington\"\
    )\n\n# predict NER tags\ntagger.predict(sentence)\n\n# print sentence\nprint(sentence)\n\
    \nAnd finally I tried to force to reinstall the dependecies as per the requirements\
    \ file from the github repo which are as follows, but the RuntimeError from  the\
    \ keys from state_dict for XLMRobertaModel persist the same as above, here the\
    \ lines from the requirements file:\n\nboto3>=1.20.27\nbpemb>=0.3.2\nconllu>=4.0\n\
    deprecated>=1.2.13\nftfy>=6.1.0\ngdown>=4.4.0\ngensim>=4.2.0\nhuggingface-hub>=0.10.0\n\
    janome>=0.4.2\nlangdetect>=1.0.9\nlxml>=4.8.0\nmatplotlib>=2.2.3\nmore-itertools>=8.13.0\n\
    mpld3>=0.3\npptree>=3.1\npython-dateutil>=2.8.2\npytorch_revgrad>=0.2.0\nregex>=2022.1.18\n\
    scikit-learn>=1.0.2\nsegtok>=1.5.11\nsqlitedict>=2.0.0\ntabulate>=0.8.10\ntorch>=1.5.0,!=1.8\n\
    tqdm>=4.63.0\ntransformer-smaller-training-vocab>=0.2.3\ntransformers[sentencepiece]>=4.18.0,<5.0.0\n\
    urllib3<2.0.0,>=1.0.0  # pin below 2 to make dependency resolution faster.\nwikipedia-api>=0.5.7\n\
    semver<4.0.0,>=3.0.0\n\nDo you have any idea on why am I getting this error and\
    \ if there is a way to make this working? I am under Windows 10 for job requirements,\
    \ but I have tried also to run it in Google Colab getting the same error. ( https://colab.research.google.com/drive/1gEXkxDvK2MAY1ztGrN5z9uE0pzi6BAcs?usp=sharing\
    \ ).\n\nAny help would be highly appreciated. Thanks in advance.\n\n"
  created_at: 2023-09-13 08:49:17+00:00
  edited: true
  hidden: false
  id: 6501859dff08101b32f0acfe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584020801691-noauth.jpeg?w=200&h=200&f=face
      fullname: Stefan
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: stefan-it
      type: user
    createdAt: '2023-09-14T11:38:51.000Z'
    data:
      edited: true
      editors:
      - stefan-it
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6102216839790344
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584020801691-noauth.jpeg?w=200&h=200&f=face
          fullname: Stefan
          isHf: false
          isPro: true
          name: stefan-it
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;oMateos2020&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/oMateos2020\"\
          >@<span class=\"underline\">oMateos2020</span></a></span>\n\n\t</span></span>\
          \ ,</p>\n<p>the \"trick\" is to use latest master version of Flair:</p>\n\
          <p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/5e6a3d4ea9afd5125d9ec064/MjlzB2aBYeMcd8mkCyFhL.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/5e6a3d4ea9afd5125d9ec064/MjlzB2aBYeMcd8mkCyFhL.png\"\
          ></a></p>\n<p>So just use <code>!pip install git+https://github.com/flairNLP/flair.git</code>\
          \ to get it from GitHub :)</p>\n"
        raw: 'Hi @oMateos2020 ,


          the "trick" is to use latest master version of Flair:


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/5e6a3d4ea9afd5125d9ec064/MjlzB2aBYeMcd8mkCyFhL.png)


          So just use `!pip install git+https://github.com/flairNLP/flair.git` to
          get it from GitHub :)'
        updatedAt: '2023-09-14T11:39:02.702Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - oMateos2020
    id: 6502f0cbadf89caf5f19d71a
    type: comment
  author: stefan-it
  content: 'Hi @oMateos2020 ,


    the "trick" is to use latest master version of Flair:


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/5e6a3d4ea9afd5125d9ec064/MjlzB2aBYeMcd8mkCyFhL.png)


    So just use `!pip install git+https://github.com/flairNLP/flair.git` to get it
    from GitHub :)'
  created_at: 2023-09-14 10:38:51+00:00
  edited: true
  hidden: false
  id: 6502f0cbadf89caf5f19d71a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9f930d343daee1f4c00104e46aabffb7.svg
      fullname: "\xD3scar Mateos L\xF3pez"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: oMateos2020
      type: user
    createdAt: '2023-09-14T14:11:10.000Z'
    data:
      edited: false
      editors:
      - oMateos2020
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9192185997962952
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9f930d343daee1f4c00104e46aabffb7.svg
          fullname: "\xD3scar Mateos L\xF3pez"
          isHf: false
          isPro: false
          name: oMateos2020
          type: user
        html: '<p>Thank you for your time Stefan. </p>

          <p>Your help is greatly appreciated!</p>

          '
        raw: "Thank you for your time Stefan. \n\nYour help is greatly appreciated!"
        updatedAt: '2023-09-14T14:11:10.887Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6503147ecccc7b28a3877240
    id: 6503147ecccc7b28a387723e
    type: comment
  author: oMateos2020
  content: "Thank you for your time Stefan. \n\nYour help is greatly appreciated!"
  created_at: 2023-09-14 13:11:10+00:00
  edited: false
  hidden: false
  id: 6503147ecccc7b28a387723e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9f930d343daee1f4c00104e46aabffb7.svg
      fullname: "\xD3scar Mateos L\xF3pez"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: oMateos2020
      type: user
    createdAt: '2023-09-14T14:11:10.000Z'
    data:
      status: closed
    id: 6503147ecccc7b28a3877240
    type: status-change
  author: oMateos2020
  created_at: 2023-09-14 13:11:10+00:00
  id: 6503147ecccc7b28a3877240
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1607338667029-noauth.jpeg?w=200&h=200&f=face
      fullname: Alan Akbik
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: alanakbik
      type: user
    createdAt: '2023-11-04T06:29:15.000Z'
    data:
      edited: false
      editors:
      - alanakbik
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8767130970954895
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1607338667029-noauth.jpeg?w=200&h=200&f=face
          fullname: Alan Akbik
          isHf: false
          isPro: false
          name: alanakbik
          type: user
        html: '<p>We released the new version of Flair (0.13.0) with this bugfix,
          so you can install again directly from pip!</p>

          '
        raw: We released the new version of Flair (0.13.0) with this bugfix, so you
          can install again directly from pip!
        updatedAt: '2023-11-04T06:29:15.672Z'
      numEdits: 0
      reactions: []
    id: 6545e4bb08568852402a9b1b
    type: comment
  author: alanakbik
  content: We released the new version of Flair (0.13.0) with this bugfix, so you
    can install again directly from pip!
  created_at: 2023-11-04 05:29:15+00:00
  edited: false
  hidden: false
  id: 6545e4bb08568852402a9b1b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: flair/ner-spanish-large
repo_type: model
status: closed
target_branch: null
title: RuntimeError while trying to use ner-spanish-large
