!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ultraleow
conflicting_files: null
created_at: 2022-11-13 17:24:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8fa1187bea7fe7304da85a99c11186e7.svg
      fullname: Leow Jun Shou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ultraleow
      type: user
    createdAt: '2022-11-13T17:24:43.000Z'
    data:
      edited: false
      editors:
      - ultraleow
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8fa1187bea7fe7304da85a99c11186e7.svg
          fullname: Leow Jun Shou
          isHf: false
          isPro: false
          name: ultraleow
          type: user
        html: "<p>Distilbert aims to optimize the training by reducing the size of\
          \ BERT and increase the speed of BERT \u2014 all while trying to retain\
          \ as much performance as possible. Specifically, Distilbert is 40% smaller\
          \ than the original BERT-base model, is 60% faster than it, and retains\
          \ 97% of its functionality.</p>\n<p>Thus, is it appropriate? </p>\n"
        raw: "Distilbert aims to optimize the training by reducing the size of BERT\
          \ and increase the speed of BERT \u2014 all while trying to retain as much\
          \ performance as possible. Specifically, Distilbert is 40% smaller than\
          \ the original BERT-base model, is 60% faster than it, and retains 97% of\
          \ its functionality.\r\n\r\nThus, is it appropriate? "
        updatedAt: '2022-11-13T17:24:43.944Z'
      numEdits: 0
      reactions: []
    id: 6371285b3434f2764ce82cac
    type: comment
  author: ultraleow
  content: "Distilbert aims to optimize the training by reducing the size of BERT\
    \ and increase the speed of BERT \u2014 all while trying to retain as much performance\
    \ as possible. Specifically, Distilbert is 40% smaller than the original BERT-base\
    \ model, is 60% faster than it, and retains 97% of its functionality.\r\n\r\n\
    Thus, is it appropriate? "
  created_at: 2022-11-13 17:24:43+00:00
  edited: false
  hidden: false
  id: 6371285b3434f2764ce82cac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bc7a193af4cbb82d4eff674022644381.svg
      fullname: Christian Siebert
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: siebert
      type: user
    createdAt: '2022-11-13T18:13:42.000Z'
    data:
      edited: false
      editors:
      - siebert
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bc7a193af4cbb82d4eff674022644381.svg
          fullname: Christian Siebert
          isHf: false
          isPro: false
          name: siebert
          type: user
        html: '<p>When we released the model, Distilbert-SST2 was the standard sentiment
          model in Huggingface. Our benchmark shows that our (larger) model is indeed
          more accurate, even if inference is somewhat slower. So when choosing models,
          you may consider this trade-off between our more accurate but slower model,
          or the somewhat faster but less accurate Distilbert model, depending on
          your use case. Since our model is already trained, the higher computation
          cost for training is not relevant anymore for your decision. Hope this helps!</p>

          '
        raw: When we released the model, Distilbert-SST2 was the standard sentiment
          model in Huggingface. Our benchmark shows that our (larger) model is indeed
          more accurate, even if inference is somewhat slower. So when choosing models,
          you may consider this trade-off between our more accurate but slower model,
          or the somewhat faster but less accurate Distilbert model, depending on
          your use case. Since our model is already trained, the higher computation
          cost for training is not relevant anymore for your decision. Hope this helps!
        updatedAt: '2022-11-13T18:13:42.769Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - ultraleow
    id: 637133d667cd0e8815024afe
    type: comment
  author: siebert
  content: When we released the model, Distilbert-SST2 was the standard sentiment
    model in Huggingface. Our benchmark shows that our (larger) model is indeed more
    accurate, even if inference is somewhat slower. So when choosing models, you may
    consider this trade-off between our more accurate but slower model, or the somewhat
    faster but less accurate Distilbert model, depending on your use case. Since our
    model is already trained, the higher computation cost for training is not relevant
    anymore for your decision. Hope this helps!
  created_at: 2022-11-13 18:13:42+00:00
  edited: false
  hidden: false
  id: 637133d667cd0e8815024afe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8fa1187bea7fe7304da85a99c11186e7.svg
      fullname: Leow Jun Shou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ultraleow
      type: user
    createdAt: '2022-11-14T09:58:48.000Z'
    data:
      edited: false
      editors:
      - ultraleow
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8fa1187bea7fe7304da85a99c11186e7.svg
          fullname: Leow Jun Shou
          isHf: false
          isPro: false
          name: ultraleow
          type: user
        html: '<p>Thanks, I''m now able to understand the initiative behind of it</p>

          '
        raw: Thanks, I'm now able to understand the initiative behind of it
        updatedAt: '2022-11-14T09:58:48.133Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6372115814d543d507a98497
    id: 6372115814d543d507a98496
    type: comment
  author: ultraleow
  content: Thanks, I'm now able to understand the initiative behind of it
  created_at: 2022-11-14 09:58:48+00:00
  edited: false
  hidden: false
  id: 6372115814d543d507a98496
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/8fa1187bea7fe7304da85a99c11186e7.svg
      fullname: Leow Jun Shou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ultraleow
      type: user
    createdAt: '2022-11-14T09:58:48.000Z'
    data:
      status: closed
    id: 6372115814d543d507a98497
    type: status-change
  author: ultraleow
  created_at: 2022-11-14 09:58:48+00:00
  id: 6372115814d543d507a98497
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: siebert/sentiment-roberta-large-english
repo_type: model
status: closed
target_branch: null
title: is this model comparing the accuracy of a smaller model?
