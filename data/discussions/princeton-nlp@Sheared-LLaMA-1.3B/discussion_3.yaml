!!python/object:huggingface_hub.community.DiscussionWithDetails
author: doberst
conflicting_files: null
created_at: 2023-10-23 15:08:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e813b3bdc5ab53bcffc5f9d6b3eeb084.svg
      fullname: Darren Oberst
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: doberst
      type: user
    createdAt: '2023-10-23T16:08:55.000Z'
    data:
      edited: false
      editors:
      - doberst
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9263508915901184
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e813b3bdc5ab53bcffc5f9d6b3eeb084.svg
          fullname: Darren Oberst
          isHf: false
          isPro: false
          name: doberst
          type: user
        html: '<p>Very interested in your research on pruning and dynamic batch training  and
          to see where it evolves.  We wanted to share with you that we are seeing
          some of the best RAG instruct fine-tuning (for a small model) built on top
          of the Sheared-LLama-1.3B, in particular, and would welcome you to check
          it out (llmware/bling-sheared-llama-1.3-0.1) - we just posted the RAG finetuned
          model and will be publishing some benchmark "RAG-instruct" test evaluations
          in the next couple of weeks.    Would look forward to chances to collaborate
          in the future.  </p>

          '
        raw: 'Very interested in your research on pruning and dynamic batch training  and
          to see where it evolves.  We wanted to share with you that we are seeing
          some of the best RAG instruct fine-tuning (for a small model) built on top
          of the Sheared-LLama-1.3B, in particular, and would welcome you to check
          it out (llmware/bling-sheared-llama-1.3-0.1) - we just posted the RAG finetuned
          model and will be publishing some benchmark "RAG-instruct" test evaluations
          in the next couple of weeks.    Would look forward to chances to collaborate
          in the future.  '
        updatedAt: '2023-10-23T16:08:55.461Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - Felladrin
        - princeton-nlp
    id: 65369a97bbc02c49b2e0b463
    type: comment
  author: doberst
  content: 'Very interested in your research on pruning and dynamic batch training  and
    to see where it evolves.  We wanted to share with you that we are seeing some
    of the best RAG instruct fine-tuning (for a small model) built on top of the Sheared-LLama-1.3B,
    in particular, and would welcome you to check it out (llmware/bling-sheared-llama-1.3-0.1)
    - we just posted the RAG finetuned model and will be publishing some benchmark
    "RAG-instruct" test evaluations in the next couple of weeks.    Would look forward
    to chances to collaborate in the future.  '
  created_at: 2023-10-23 15:08:55+00:00
  edited: false
  hidden: false
  id: 65369a97bbc02c49b2e0b463
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/e813b3bdc5ab53bcffc5f9d6b3eeb084.svg
      fullname: Darren Oberst
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: doberst
      type: user
    createdAt: '2023-10-23T16:09:16.000Z'
    data:
      status: closed
    id: 65369aac019de942639adf93
    type: status-change
  author: doberst
  created_at: 2023-10-23 15:09:16+00:00
  id: 65369aac019de942639adf93
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/e813b3bdc5ab53bcffc5f9d6b3eeb084.svg
      fullname: Darren Oberst
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: doberst
      type: user
    createdAt: '2023-10-23T16:09:21.000Z'
    data:
      status: open
    id: 65369ab18ee17cfd44efdf2c
    type: status-change
  author: doberst
  created_at: 2023-10-23 15:09:21+00:00
  id: 65369ab18ee17cfd44efdf2c
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618969698200-noauth.png?w=200&h=200&f=face
      fullname: Princeton NLP group
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: princeton-nlp
      type: user
    createdAt: '2023-10-26T03:36:17.000Z'
    data:
      edited: false
      editors:
      - princeton-nlp
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9509222507476807
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618969698200-noauth.png?w=200&h=200&f=face
          fullname: Princeton NLP group
          isHf: false
          isPro: false
          name: princeton-nlp
          type: user
        html: '<p>Thanks for your interest in other work!!!!</p>

          '
        raw: Thanks for your interest in other work!!!!
        updatedAt: '2023-10-26T03:36:17.576Z'
      numEdits: 0
      reactions: []
    id: 6539deb1f84b1361669293c4
    type: comment
  author: princeton-nlp
  content: Thanks for your interest in other work!!!!
  created_at: 2023-10-26 02:36:17+00:00
  edited: false
  hidden: false
  id: 6539deb1f84b1361669293c4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: princeton-nlp/Sheared-LLaMA-1.3B
repo_type: model
status: open
target_branch: null
title: Great work + Excellent model
