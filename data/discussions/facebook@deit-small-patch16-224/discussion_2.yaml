!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mhyatt000
conflicting_files: null
created_at: 2022-09-01 00:25:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658862186149-62b09fe1a14cbd64386c042d.jpeg?w=200&h=200&f=face
      fullname: Matt Hyatt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mhyatt000
      type: user
    createdAt: '2022-09-01T01:25:29.000Z'
    data:
      edited: false
      editors:
      - mhyatt000
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658862186149-62b09fe1a14cbd64386c042d.jpeg?w=200&h=200&f=face
          fullname: Matt Hyatt
          isHf: false
          isPro: false
          name: mhyatt000
          type: user
        html: '<p>I tried to reproduce the results mentioned on this model card. Seems
          like my results do not match the claimed accuracy in the model card. I cannot
          figure out how to get the correct numbers, can you help me find my mistake?</p>

          <ul>

          <li>Claimed accuracy<ul>

          <li>top 1: 75.5</li>

          <li>top 5: 95.0</li>

          </ul>

          </li>

          <li>Received accuracy<ul>

          <li>top 1: 77.0</li>

          <li>top 5: 93.0</li>

          </ul>

          </li>

          </ul>

          <h2 id="here-are-the-details-for-my-validation">Here are the details for
          my validation:</h2>

          <ul>

          <li>I instantiate pre-trained model with <code>transformers.pipeline()</code>
          and use measure top 1 / top 5 accuracy</li>

          <li>Evaluation was performed on CPU.</li>

          <li>Dataset was downloaded from image-net.org</li>

          </ul>

          '
        raw: "I tried to reproduce the results mentioned on this model card. Seems\
          \ like my results do not match the claimed accuracy in the model card. I\
          \ cannot figure out how to get the correct numbers, can you help me find\
          \ my mistake?\r\n\r\n- Claimed accuracy\r\n  - top 1: 75.5\r\n  - top 5:\
          \ 95.0\r\n- Received accuracy\r\n  - top 1: 77.0\r\n  - top 5: 93.0\r\n\r\
          \n## Here are the details for my validation:\r\n\r\n- I instantiate pre-trained\
          \ model with `transformers.pipeline()` and use measure top 1 / top 5 accuracy\r\
          \n- Evaluation was performed on CPU.\r\n- Dataset was downloaded from image-net.org\r\
          \n"
        updatedAt: '2022-09-01T01:25:29.472Z'
      numEdits: 0
      reactions: []
    id: 63100a09dd31b2a8dbe8c76a
    type: comment
  author: mhyatt000
  content: "I tried to reproduce the results mentioned on this model card. Seems like\
    \ my results do not match the claimed accuracy in the model card. I cannot figure\
    \ out how to get the correct numbers, can you help me find my mistake?\r\n\r\n\
    - Claimed accuracy\r\n  - top 1: 75.5\r\n  - top 5: 95.0\r\n- Received accuracy\r\
    \n  - top 1: 77.0\r\n  - top 5: 93.0\r\n\r\n## Here are the details for my validation:\r\
    \n\r\n- I instantiate pre-trained model with `transformers.pipeline()` and use\
    \ measure top 1 / top 5 accuracy\r\n- Evaluation was performed on CPU.\r\n- Dataset\
    \ was downloaded from image-net.org\r\n"
  created_at: 2022-09-01 00:25:29+00:00
  edited: false
  hidden: false
  id: 63100a09dd31b2a8dbe8c76a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: facebook/deit-small-patch16-224
repo_type: model
status: open
target_branch: null
title: Accuracy Drop
