!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BlueNipples
conflicting_files: null
created_at: 2024-01-05 05:18:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
      fullname: Matthew Andrews
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BlueNipples
      type: user
    createdAt: '2024-01-05T05:18:56.000Z'
    data:
      edited: true
      editors:
      - BlueNipples
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9604793190956116
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
          fullname: Matthew Andrews
          isHf: false
          isPro: false
          name: BlueNipples
          type: user
        html: '<p>So I found frostwind (of solar instruct origin) to be pretty darn
          smart (surprisingly so actually probs better than any &lt;20b I''ve tried),
          but with terribly dry prose (worse than gpt). Understood everything but
          as creative as a rock. Nous hermes new solar instruct fine tune is MUCH
          better, but probably a little less coherent than frostwind. But defo better
          prose. </p>

          <p>So here''s the idea - I was hoping there was a way you could mash Noromaid
          7b into some 10.7b frankenmerge (something I''ve never been able to work
          out), maybe with toppy 7b? Or whatever you think would be fun or clever.
          </p>

          <p>And then combine the resulting 10.7b model into the other two in some
          clever way, such that the frankenmerge incoherency gets evened out by the
          normal models, but it inherits some more prose. A fine tune on something
          if you feel inclined. </p>

          <p>I totally lament the smaller local models lagging so far behind the ones
          that need juicier gpu''s rn. I know there''s gold in here somewhere, and
          there might be enough fine tunes now to start to play. </p>

          <p>Or not, and tell me to go eat dirt. As usual! I can''t expect anything
          really you make SO many merges. </p>

          <p>I should mention I partly stole the idea from this model:</p>

          <p><a href="https://huggingface.co/NyxKrage/FrostMaid-10.7B-TESTING-GGUF">https://huggingface.co/NyxKrage/FrostMaid-10.7B-TESTING-GGUF</a></p>

          <p>Which I''ve tried and it is in fact pretty good. Best prose of any solar
          instruct I''ve seen, even if it''s a little lacking in logic/coherency,
          and honestly probably just as good prose wise as some of the mistral small
          finetunes (I tried in the same rp using noromaid 8x7b, and ended up favoring
          this more often, despite it''s frequent confusion it just straight up described
          things better). And probs more coherent than noromaid 20b, even still, tbh.
          </p>

          <p>Having tried this model out now, I''m convinced there is something clever
          in this general direction. Perhaps the slight influence of the medical model
          also help the prose? Not sure, but I think they do sometimes do that.  Suspect
          there''s a merge or finetune in here that can beat anything current 20B
          and under. </p>

          '
        raw: "So I found frostwind (of solar instruct origin) to be pretty darn smart\
          \ (surprisingly so actually probs better than any <20b I've tried), but\
          \ with terribly dry prose (worse than gpt). Understood everything but as\
          \ creative as a rock. Nous hermes new solar instruct fine tune is MUCH better,\
          \ but probably a little less coherent than frostwind. But defo better prose.\
          \ \n\nSo here's the idea - I was hoping there was a way you could mash Noromaid\
          \ 7b into some 10.7b frankenmerge (something I've never been able to work\
          \ out), maybe with toppy 7b? Or whatever you think would be fun or clever.\
          \ \n\nAnd then combine the resulting 10.7b model into the other two in some\
          \ clever way, such that the frankenmerge incoherency gets evened out by\
          \ the normal models, but it inherits some more prose. A fine tune on something\
          \ if you feel inclined. \n\nI totally lament the smaller local models lagging\
          \ so far behind the ones that need juicier gpu's rn. I know there's gold\
          \ in here somewhere, and there might be enough fine tunes now to start to\
          \ play. \n\nOr not, and tell me to go eat dirt. As usual! I can't expect\
          \ anything really you make SO many merges. \n\nI should mention I partly\
          \ stole the idea from this model:\n\nhttps://huggingface.co/NyxKrage/FrostMaid-10.7B-TESTING-GGUF\n\
          \nWhich I've tried and it is in fact pretty good. Best prose of any solar\
          \ instruct I've seen, even if it's a little lacking in logic/coherency,\
          \ and honestly probably just as good prose wise as some of the mistral small\
          \ finetunes (I tried in the same rp using noromaid 8x7b, and ended up favoring\
          \ this more often, despite it's frequent confusion it just straight up described\
          \ things better). And probs more coherent than noromaid 20b, even still,\
          \ tbh. \n\nHaving tried this model out now, I'm convinced there is something\
          \ clever in this general direction. Perhaps the slight influence of the\
          \ medical model also help the prose? Not sure, but I think they do sometimes\
          \ do that.  Suspect there's a merge or finetune in here that can beat anything\
          \ current 20B and under. "
        updatedAt: '2024-01-05T10:55:15.024Z'
      numEdits: 4
      reactions: []
    id: 6597914067b8fc62792f2177
    type: comment
  author: BlueNipples
  content: "So I found frostwind (of solar instruct origin) to be pretty darn smart\
    \ (surprisingly so actually probs better than any <20b I've tried), but with terribly\
    \ dry prose (worse than gpt). Understood everything but as creative as a rock.\
    \ Nous hermes new solar instruct fine tune is MUCH better, but probably a little\
    \ less coherent than frostwind. But defo better prose. \n\nSo here's the idea\
    \ - I was hoping there was a way you could mash Noromaid 7b into some 10.7b frankenmerge\
    \ (something I've never been able to work out), maybe with toppy 7b? Or whatever\
    \ you think would be fun or clever. \n\nAnd then combine the resulting 10.7b model\
    \ into the other two in some clever way, such that the frankenmerge incoherency\
    \ gets evened out by the normal models, but it inherits some more prose. A fine\
    \ tune on something if you feel inclined. \n\nI totally lament the smaller local\
    \ models lagging so far behind the ones that need juicier gpu's rn. I know there's\
    \ gold in here somewhere, and there might be enough fine tunes now to start to\
    \ play. \n\nOr not, and tell me to go eat dirt. As usual! I can't expect anything\
    \ really you make SO many merges. \n\nI should mention I partly stole the idea\
    \ from this model:\n\nhttps://huggingface.co/NyxKrage/FrostMaid-10.7B-TESTING-GGUF\n\
    \nWhich I've tried and it is in fact pretty good. Best prose of any solar instruct\
    \ I've seen, even if it's a little lacking in logic/coherency, and honestly probably\
    \ just as good prose wise as some of the mistral small finetunes (I tried in the\
    \ same rp using noromaid 8x7b, and ended up favoring this more often, despite\
    \ it's frequent confusion it just straight up described things better). And probs\
    \ more coherent than noromaid 20b, even still, tbh. \n\nHaving tried this model\
    \ out now, I'm convinced there is something clever in this general direction.\
    \ Perhaps the slight influence of the medical model also help the prose? Not sure,\
    \ but I think they do sometimes do that.  Suspect there's a merge or finetune\
    \ in here that can beat anything current 20B and under. "
  created_at: 2024-01-05 05:18:56+00:00
  edited: true
  hidden: false
  id: 6597914067b8fc62792f2177
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Undi95/FlatDolphinMaid-8x7B-GGUF
repo_type: model
status: open
target_branch: null
title: I've got another (dumb? genius?) merge request for ya man!
