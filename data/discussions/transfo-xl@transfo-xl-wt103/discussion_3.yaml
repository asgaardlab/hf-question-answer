!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dsplog
conflicting_files: null
created_at: 2023-11-14 02:12:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cdf0b9d35296756caad35e0ac298ebd5.svg
      fullname: Krishna Sankar M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dsplog
      type: user
    createdAt: '2023-11-14T02:12:07.000Z'
    data:
      edited: true
      editors:
      - lysandre
      - dsplog
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4148150086402893
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
          fullname: Lysandre
          isHf: true
          isPro: false
          name: lysandre
          type: user
        html: "<p>kindly see the code snippet below.  could see tokenizer.sym2idx\
          \ defined, but  tokenizer.idx2sym is an empty list. </p>\n<pre><code class=\"\
          language-py\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"\
          hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span>\
          \ TransfoXLTokenizer\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>tokenizer\
          \ = TransfoXLTokenizer.from_pretrained(<span class=\"hljs-string\">\"transfo-xl-wt103\"\
          </span>)\n\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>enc = tokenizer.encode(<span\
          \ class=\"hljs-string\">\"Hello, my dog is cute\"</span>)\n<span class=\"\
          hljs-meta\">&gt;&gt;&gt; </span>enc\n[<span class=\"hljs-number\">14049</span>,\
          \ <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">617</span>,\
          \ <span class=\"hljs-number\">3225</span>, <span class=\"hljs-number\">23</span>,\
          \ <span class=\"hljs-number\">16072</span>]\n\n<span class=\"hljs-meta\"\
          >&gt;&gt;&gt; </span>tokenizer.decode\n&lt;bound method PreTrainedTokenizerBase.decode\
          \ of TransfoXLTokenizer(name_or_path=<span class=\"hljs-string\">'transfo-xl-wt103'</span>,\
          \ vocab_size=<span class=\"hljs-number\">0</span>, model_max_length=<span\
          \ class=\"hljs-number\">1000000000000000019884624838656</span>, is_fast=<span\
          \ class=\"hljs-literal\">False</span>, padding_side=<span class=\"hljs-string\"\
          >'right'</span>, truncation_side=<span class=\"hljs-string\">'right'</span>,\
          \ special_tokens={<span class=\"hljs-string\">'eos_token'</span>: <span\
          \ class=\"hljs-string\">'&lt;eos&gt;'</span>, <span class=\"hljs-string\"\
          >'unk_token'</span>: <span class=\"hljs-string\">'&lt;unk&gt;'</span>, <span\
          \ class=\"hljs-string\">'additional_special_tokens'</span>: [<span class=\"\
          hljs-string\">'&lt;formula&gt;'</span>]}, clean_up_tokenization_spaces=<span\
          \ class=\"hljs-literal\">True</span>),  added_tokens_decoder={\n    <span\
          \ class=\"hljs-number\">0</span>: AddedToken(<span class=\"hljs-string\"\
          >\"&lt;eos&gt;\"</span>, rstrip=<span class=\"hljs-literal\">False</span>,\
          \ lstrip=<span class=\"hljs-literal\">False</span>, single_word=<span class=\"\
          hljs-literal\">False</span>, normalized=<span class=\"hljs-literal\">False</span>,\
          \ special=<span class=\"hljs-literal\">True</span>),\n    <span class=\"\
          hljs-number\">24</span>: AddedToken(<span class=\"hljs-string\">\"&lt;unk&gt;\"\
          </span>, rstrip=<span class=\"hljs-literal\">False</span>, lstrip=<span\
          \ class=\"hljs-literal\">False</span>, single_word=<span class=\"hljs-literal\"\
          >False</span>, normalized=<span class=\"hljs-literal\">False</span>, special=<span\
          \ class=\"hljs-literal\">True</span>),\n    <span class=\"hljs-number\"\
          >3039</span>: AddedToken(<span class=\"hljs-string\">\"&lt;formula&gt;\"\
          </span>, rstrip=<span class=\"hljs-literal\">False</span>, lstrip=<span\
          \ class=\"hljs-literal\">False</span>, single_word=<span class=\"hljs-literal\"\
          >False</span>, normalized=<span class=\"hljs-literal\">False</span>, special=<span\
          \ class=\"hljs-literal\">True</span>),\n}&gt;\n<span class=\"hljs-meta\"\
          >&gt;&gt;&gt; </span>tokenizer.decode(enc)\nTraceback (most recent call\
          \ last):\n  File <span class=\"hljs-string\">\"&lt;stdin&gt;\"</span>, line\
          \ <span class=\"hljs-number\">1</span>, <span class=\"hljs-keyword\">in</span>\
          \ &lt;module&gt;\n  File <span class=\"hljs-string\">\"/home/home/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\"\
          </span>, line <span class=\"hljs-number\">3738</span>, <span class=\"hljs-keyword\"\
          >in</span> decode\n    <span class=\"hljs-keyword\">return</span> self._decode(\n\
          \  File <span class=\"hljs-string\">\"/home/home/.local/lib/python3.8/site-packages/transformers/tokenization_utils.py\"\
          </span>, line <span class=\"hljs-number\">1001</span>, <span class=\"hljs-keyword\"\
          >in</span> _decode\n    filtered_tokens = self.convert_ids_to_tokens(token_ids,\
          \ skip_special_tokens=skip_special_tokens)\n  File <span class=\"hljs-string\"\
          >\"/home/home/.local/lib/python3.8/site-packages/transformers/tokenization_utils.py\"\
          </span>, line <span class=\"hljs-number\">982</span>, <span class=\"hljs-keyword\"\
          >in</span> convert_ids_to_tokens\n    tokens.append(self._convert_id_to_token(index))\n\
          \  File <span class=\"hljs-string\">\"/home/home/.local/lib/python3.8/site-packages/transformers/models/transfo_xl/tokenization_transfo_xl.py\"\
          </span>, line <span class=\"hljs-number\">451</span>, <span class=\"hljs-keyword\"\
          >in</span> _convert_id_to_token\n    <span class=\"hljs-keyword\">return</span>\
          \ self.idx2sym[idx]\nIndexError: <span class=\"hljs-built_in\">list</span>\
          \ index out of <span class=\"hljs-built_in\">range</span>\n</code></pre>\n"
        raw: "kindly see the code snippet below.  could see tokenizer.sym2idx defined,\
          \ but  tokenizer.idx2sym is an empty list. \n\n\n\n```py\n>>> from transformers\
          \ import TransfoXLTokenizer\n>>> tokenizer = TransfoXLTokenizer.from_pretrained(\"\
          transfo-xl-wt103\")\n\n>>> enc = tokenizer.encode(\"Hello, my dog is cute\"\
          )\n>>> enc\n[14049, 2, 617, 3225, 23, 16072]\n\n>>> tokenizer.decode\n<bound\
          \ method PreTrainedTokenizerBase.decode of TransfoXLTokenizer(name_or_path='transfo-xl-wt103',\
          \ vocab_size=0, model_max_length=1000000000000000019884624838656, is_fast=False,\
          \ padding_side='right', truncation_side='right', special_tokens={'eos_token':\
          \ '<eos>', 'unk_token': '<unk>', 'additional_special_tokens': ['<formula>']},\
          \ clean_up_tokenization_spaces=True),  added_tokens_decoder={\n\t0: AddedToken(\"\
          <eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False,\
          \ special=True),\n\t24: AddedToken(\"<unk>\", rstrip=False, lstrip=False,\
          \ single_word=False, normalized=False, special=True),\n\t3039: AddedToken(\"\
          <formula>\", rstrip=False, lstrip=False, single_word=False, normalized=False,\
          \ special=True),\n}>\n>>> tokenizer.decode(enc)\nTraceback (most recent\
          \ call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/home/home/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\"\
          , line 3738, in decode\n    return self._decode(\n  File \"/home/home/.local/lib/python3.8/site-packages/transformers/tokenization_utils.py\"\
          , line 1001, in _decode\n    filtered_tokens = self.convert_ids_to_tokens(token_ids,\
          \ skip_special_tokens=skip_special_tokens)\n  File \"/home/home/.local/lib/python3.8/site-packages/transformers/tokenization_utils.py\"\
          , line 982, in convert_ids_to_tokens\n    tokens.append(self._convert_id_to_token(index))\n\
          \  File \"/home/home/.local/lib/python3.8/site-packages/transformers/models/transfo_xl/tokenization_transfo_xl.py\"\
          , line 451, in _convert_id_to_token\n    return self.idx2sym[idx]\nIndexError:\
          \ list index out of range\n```"
        updatedAt: '2023-11-15T15:29:46.997Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F614"
        users:
        - lysandre
      - count: 1
        reaction: "\U0001F44D"
        users:
        - kwazar90
    id: 6552d77711b34f8854124c19
    type: comment
  author: dsplog
  content: "kindly see the code snippet below.  could see tokenizer.sym2idx defined,\
    \ but  tokenizer.idx2sym is an empty list. \n\n\n\n```py\n>>> from transformers\
    \ import TransfoXLTokenizer\n>>> tokenizer = TransfoXLTokenizer.from_pretrained(\"\
    transfo-xl-wt103\")\n\n>>> enc = tokenizer.encode(\"Hello, my dog is cute\")\n\
    >>> enc\n[14049, 2, 617, 3225, 23, 16072]\n\n>>> tokenizer.decode\n<bound method\
    \ PreTrainedTokenizerBase.decode of TransfoXLTokenizer(name_or_path='transfo-xl-wt103',\
    \ vocab_size=0, model_max_length=1000000000000000019884624838656, is_fast=False,\
    \ padding_side='right', truncation_side='right', special_tokens={'eos_token':\
    \ '<eos>', 'unk_token': '<unk>', 'additional_special_tokens': ['<formula>']},\
    \ clean_up_tokenization_spaces=True),  added_tokens_decoder={\n\t0: AddedToken(\"\
    <eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\
    \t24: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False,\
    \ special=True),\n\t3039: AddedToken(\"<formula>\", rstrip=False, lstrip=False,\
    \ single_word=False, normalized=False, special=True),\n}>\n>>> tokenizer.decode(enc)\n\
    Traceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n\
    \  File \"/home/home/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\"\
    , line 3738, in decode\n    return self._decode(\n  File \"/home/home/.local/lib/python3.8/site-packages/transformers/tokenization_utils.py\"\
    , line 1001, in _decode\n    filtered_tokens = self.convert_ids_to_tokens(token_ids,\
    \ skip_special_tokens=skip_special_tokens)\n  File \"/home/home/.local/lib/python3.8/site-packages/transformers/tokenization_utils.py\"\
    , line 982, in convert_ids_to_tokens\n    tokens.append(self._convert_id_to_token(index))\n\
    \  File \"/home/home/.local/lib/python3.8/site-packages/transformers/models/transfo_xl/tokenization_transfo_xl.py\"\
    , line 451, in _convert_id_to_token\n    return self.idx2sym[idx]\nIndexError:\
    \ list index out of range\n```"
  created_at: 2023-11-14 02:12:07+00:00
  edited: true
  hidden: false
  id: 6552d77711b34f8854124c19
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dac412834c0b07ead395a13955e33c1c.svg
      fullname: Sintayew Gashaw
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sintayew4
      type: user
    createdAt: '2023-11-15T22:01:17.000Z'
    data:
      edited: false
      editors:
      - Sintayew4
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6135322451591492
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dac412834c0b07ead395a13955e33c1c.svg
          fullname: Sintayew Gashaw
          isHf: false
          isPro: false
          name: Sintayew4
          type: user
        html: '<p><a href="/transfo-xl/transfo-xl-wt103/discussions/3">#3</a></p>

          '
        raw: '#3'
        updatedAt: '2023-11-15T22:01:17.005Z'
      numEdits: 0
      reactions: []
    id: 65553fadf96492362e206a4d
    type: comment
  author: Sintayew4
  content: '#3'
  created_at: 2023-11-15 22:01:17+00:00
  edited: false
  hidden: false
  id: 65553fadf96492362e206a4d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cdf0b9d35296756caad35e0ac298ebd5.svg
      fullname: Krishna Sankar M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dsplog
      type: user
    createdAt: '2023-11-19T02:22:57.000Z'
    data:
      edited: false
      editors:
      - dsplog
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.832182765007019
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cdf0b9d35296756caad35e0ac298ebd5.svg
          fullname: Krishna Sankar M
          isHf: false
          isPro: false
          name: dsplog
          type: user
        html: '<p>checked the version history of transformers <a rel="nofollow" href="https://pypi.org/project/transformers/#history">https://pypi.org/project/transformers/#history</a><br>this
          issue is not there till transformer version 4.33.3</p>

          <p>after that, from v4.34.0 till v4.35.2, we have this issue</p>

          '
        raw: 'checked the version history of transformers https://pypi.org/project/transformers/#history

          this issue is not there till transformer version 4.33.3


          after that, from v4.34.0 till v4.35.2, we have this issue'
        updatedAt: '2023-11-19T02:22:57.913Z'
      numEdits: 0
      reactions: []
    id: 65597181b9fcdeff519d0b21
    type: comment
  author: dsplog
  content: 'checked the version history of transformers https://pypi.org/project/transformers/#history

    this issue is not there till transformer version 4.33.3


    after that, from v4.34.0 till v4.35.2, we have this issue'
  created_at: 2023-11-19 02:22:57+00:00
  edited: false
  hidden: false
  id: 65597181b9fcdeff519d0b21
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
      fullname: Lysandre
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lysandre
      type: user
    createdAt: '2023-11-28T09:48:43.000Z'
    data:
      edited: false
      editors:
      - lysandre
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7889890074729919
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
          fullname: Lysandre
          isHf: true
          isPro: false
          name: lysandre
          type: user
        html: '<p>Hello, starting with transformers v4.36, the TransfoXL model and
          tokenizer will be deprecated due to a security issue.</p>

          <p>If version v4.33.3 works for your use-case, we recommend sticking to
          it. Additionally, we recommend explicitly passing the repo ID (<code>transfo-xl-wt103</code>)
          and revision (<code><a href="/transfo-xl/transfo-xl-wt103/commit/40a186da79458c9f9de846edfaea79c412137f97">40a186da79458c9f9de846edfaea79c412137f97</a></code>)
          to ensure you use the correct checkpoint.</p>

          '
        raw: 'Hello, starting with transformers v4.36, the TransfoXL model and tokenizer
          will be deprecated due to a security issue.


          If version v4.33.3 works for your use-case, we recommend sticking to it.
          Additionally, we recommend explicitly passing the repo ID (`transfo-xl-wt103`)
          and revision (`40a186da79458c9f9de846edfaea79c412137f97`) to ensure you
          use the correct checkpoint.'
        updatedAt: '2023-11-28T09:48:43.810Z'
      numEdits: 0
      reactions: []
    id: 6565b77bd4ef4fe85faf46b8
    type: comment
  author: lysandre
  content: 'Hello, starting with transformers v4.36, the TransfoXL model and tokenizer
    will be deprecated due to a security issue.


    If version v4.33.3 works for your use-case, we recommend sticking to it. Additionally,
    we recommend explicitly passing the repo ID (`transfo-xl-wt103`) and revision
    (`40a186da79458c9f9de846edfaea79c412137f97`) to ensure you use the correct checkpoint.'
  created_at: 2023-11-28 09:48:43+00:00
  edited: false
  hidden: false
  id: 6565b77bd4ef4fe85faf46b8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: transfo-xl/transfo-xl-wt103
repo_type: model
status: open
target_branch: null
title: decode throwing error for TransfoXLTokenizer
