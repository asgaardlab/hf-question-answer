!!python/object:huggingface_hub.community.DiscussionWithDetails
author: gsaivinay
conflicting_files: null
created_at: 2023-05-15 18:22:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ad4bb6fe31efe3634e349f59d6d57b79.svg
      fullname: SVG
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gsaivinay
      type: user
    createdAt: '2023-05-15T19:22:41.000Z'
    data:
      edited: false
      editors:
      - gsaivinay
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ad4bb6fe31efe3634e349f59d6d57b79.svg
          fullname: SVG
          isHf: false
          isPro: false
          name: gsaivinay
          type: user
        html: '<p>Hello,</p>

          <p>Thanks for your continuous work to provide these models.</p>

          <p>Could you answer a question for me?</p>

          <p>I''m looking to deploy this model as a backend API with streaming to
          access via UI application. What servers can I use for this GPTQ converted
          models?</p>

          <p>I''m currently using <a rel="nofollow" href="https://github.com/huggingface/text-generation-inference">https://github.com/huggingface/text-generation-inference</a>
          for regular HF models and it works well, but doesn''t support GPTQ yet.</p>

          '
        raw: "Hello,\r\n\r\nThanks for your continuous work to provide these models.\r\
          \n\r\nCould you answer a question for me?\r\n\r\nI'm looking to deploy this\
          \ model as a backend API with streaming to access via UI application. What\
          \ servers can I use for this GPTQ converted models?\r\n\r\nI'm currently\
          \ using https://github.com/huggingface/text-generation-inference for regular\
          \ HF models and it works well, but doesn't support GPTQ yet."
        updatedAt: '2023-05-15T19:22:41.339Z'
      numEdits: 0
      reactions: []
    id: 64628681514ee1645bd14fdf
    type: comment
  author: gsaivinay
  content: "Hello,\r\n\r\nThanks for your continuous work to provide these models.\r\
    \n\r\nCould you answer a question for me?\r\n\r\nI'm looking to deploy this model\
    \ as a backend API with streaming to access via UI application. What servers can\
    \ I use for this GPTQ converted models?\r\n\r\nI'm currently using https://github.com/huggingface/text-generation-inference\
    \ for regular HF models and it works well, but doesn't support GPTQ yet."
  created_at: 2023-05-15 18:22:41+00:00
  edited: false
  hidden: false
  id: 64628681514ee1645bd14fdf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-15T21:53:41.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Check out <a rel="nofollow" href="https://github.com/oobabooga/text-generation-webui">text-generation-webui</a>.
          It can load these GPTQ models, and supports a simple REST API, with support
          for streaming, which you can query from your own Python code.</p>

          <p>Or, if in future you want to implement your own code, keep an eye on
          <a rel="nofollow" href="https://github.com/PanQiWei/AutoGPTQ">AutoGPTQ</a>.
          It''s a simple transformers-like interface to loading GPTQ models. It makes
          it nearly as easy to load a GPTQ quantised model as it is to load a standard
          HF model.</p>

          <p>It should be pretty easy to add support for GPTQ models into whatever
          code you have, including that HF text-generation-inference if you wanted
          to.</p>

          <p>AutoGPTQ is still in active development and has a few bugs and issues.
          But it''s making great progress and in a week or two it should be ready
          for mass adoption.</p>

          '
        raw: 'Check out [text-generation-webui](https://github.com/oobabooga/text-generation-webui).
          It can load these GPTQ models, and supports a simple REST API, with support
          for streaming, which you can query from your own Python code.


          Or, if in future you want to implement your own code, keep an eye on [AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ).
          It''s a simple transformers-like interface to loading GPTQ models. It makes
          it nearly as easy to load a GPTQ quantised model as it is to load a standard
          HF model.


          It should be pretty easy to add support for GPTQ models into whatever code
          you have, including that HF text-generation-inference if you wanted to.


          AutoGPTQ is still in active development and has a few bugs and issues. But
          it''s making great progress and in a week or two it should be ready for
          mass adoption.'
        updatedAt: '2023-05-15T21:53:41.118Z'
      numEdits: 0
      reactions: []
    id: 6462a9e58e12f9ab999903c1
    type: comment
  author: TheBloke
  content: 'Check out [text-generation-webui](https://github.com/oobabooga/text-generation-webui).
    It can load these GPTQ models, and supports a simple REST API, with support for
    streaming, which you can query from your own Python code.


    Or, if in future you want to implement your own code, keep an eye on [AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ).
    It''s a simple transformers-like interface to loading GPTQ models. It makes it
    nearly as easy to load a GPTQ quantised model as it is to load a standard HF model.


    It should be pretty easy to add support for GPTQ models into whatever code you
    have, including that HF text-generation-inference if you wanted to.


    AutoGPTQ is still in active development and has a few bugs and issues. But it''s
    making great progress and in a week or two it should be ready for mass adoption.'
  created_at: 2023-05-15 20:53:41+00:00
  edited: false
  hidden: false
  id: 6462a9e58e12f9ab999903c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ad4bb6fe31efe3634e349f59d6d57b79.svg
      fullname: SVG
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gsaivinay
      type: user
    createdAt: '2023-05-16T07:54:37.000Z'
    data:
      edited: false
      editors:
      - gsaivinay
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ad4bb6fe31efe3634e349f59d6d57b79.svg
          fullname: SVG
          isHf: false
          isPro: false
          name: gsaivinay
          type: user
        html: '<p>That is awesome. Now I got multiple ideas to implement a backend
          API. Thanks for your response.</p>

          '
        raw: That is awesome. Now I got multiple ideas to implement a backend API.
          Thanks for your response.
        updatedAt: '2023-05-16T07:54:37.014Z'
      numEdits: 0
      reactions: []
      relatedEventId: 646336bdab15db2fa565a2e5
    id: 646336bdab15db2fa565a2e4
    type: comment
  author: gsaivinay
  content: That is awesome. Now I got multiple ideas to implement a backend API. Thanks
    for your response.
  created_at: 2023-05-16 06:54:37+00:00
  edited: false
  hidden: false
  id: 646336bdab15db2fa565a2e4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/ad4bb6fe31efe3634e349f59d6d57b79.svg
      fullname: SVG
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gsaivinay
      type: user
    createdAt: '2023-05-16T07:54:37.000Z'
    data:
      status: closed
    id: 646336bdab15db2fa565a2e5
    type: status-change
  author: gsaivinay
  created_at: 2023-05-16 06:54:37+00:00
  id: 646336bdab15db2fa565a2e5
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: TheBloke/OpenAssistant-SFT-7-Llama-30B-GPTQ
repo_type: model
status: closed
target_branch: null
title: Thanks, Help needed!
