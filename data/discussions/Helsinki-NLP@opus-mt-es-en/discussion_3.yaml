!!python/object:huggingface_hub.community.DiscussionWithDetails
author: llyterson
conflicting_files: null
created_at: 2023-03-28 16:58:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1675861960618-noauth.png?w=200&h=200&f=face
      fullname: William Gag
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: llyterson
      type: user
    createdAt: '2023-03-28T17:58:50.000Z'
    data:
      edited: false
      editors:
      - llyterson
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1675861960618-noauth.png?w=200&h=200&f=face
          fullname: William Gag
          isHf: false
          isPro: false
          name: llyterson
          type: user
        html: '<p>I am trying to run the example code, however I am having problems
          with the tokenizer.<br>The specific error is:</p>

          <p>ValueError: This tokenizer cannot be instantiated. Please make sure you
          have <code>sentencepiece</code> installed in order to use this tokenizer.</p>

          <p>The problem is that when I try to install sentencepiece, I realize that
          it is legacy.</p>

          <p>Have you run into this problem? any suggestions?</p>

          '
        raw: "I am trying to run the example code, however I am having problems with\
          \ the tokenizer.\r\nThe specific error is:\r\n\r\nValueError: This tokenizer\
          \ cannot be instantiated. Please make sure you have `sentencepiece` installed\
          \ in order to use this tokenizer.\r\n\r\nThe problem is that when I try\
          \ to install sentencepiece, I realize that it is legacy.\r\n\r\nHave you\
          \ run into this problem? any suggestions?"
        updatedAt: '2023-03-28T17:58:50.112Z'
      numEdits: 0
      reactions: []
    id: 64232ada2d5965e7229c808d
    type: comment
  author: llyterson
  content: "I am trying to run the example code, however I am having problems with\
    \ the tokenizer.\r\nThe specific error is:\r\n\r\nValueError: This tokenizer cannot\
    \ be instantiated. Please make sure you have `sentencepiece` installed in order\
    \ to use this tokenizer.\r\n\r\nThe problem is that when I try to install sentencepiece,\
    \ I realize that it is legacy.\r\n\r\nHave you run into this problem? any suggestions?"
  created_at: 2023-03-28 16:58:50+00:00
  edited: false
  hidden: false
  id: 64232ada2d5965e7229c808d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a5e8084273d867c78dcf15881301f56f.svg
      fullname: Nelson Moncada
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cinnamon17
      type: user
    createdAt: '2023-03-30T10:04:44.000Z'
    data:
      edited: true
      editors:
      - cinnamon17
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a5e8084273d867c78dcf15881301f56f.svg
          fullname: Nelson Moncada
          isHf: false
          isPro: false
          name: cinnamon17
          type: user
        html: "<p>Try to use python 3.9 instead <span data-props=\"{&quot;user&quot;:&quot;llyterson&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/llyterson\"\
          >@<span class=\"underline\">llyterson</span></a></span>\n\n\t</span></span></p>\n"
        raw: Try to use python 3.9 instead @llyterson
        updatedAt: '2023-03-31T07:23:20.771Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - llyterson
    id: 64255ebc3990893f0262fff9
    type: comment
  author: cinnamon17
  content: Try to use python 3.9 instead @llyterson
  created_at: 2023-03-30 09:04:44+00:00
  edited: true
  hidden: false
  id: 64255ebc3990893f0262fff9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Helsinki-NLP/opus-mt-es-en
repo_type: model
status: open
target_branch: null
title: problems with tokenizer because of sentencepiece is legacy
