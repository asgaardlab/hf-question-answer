!!python/object:huggingface_hub.community.DiscussionWithDetails
author: saivineetha
conflicting_files: null
created_at: 2023-12-12 10:37:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9df73264fe5d79bebd9389bc900f01af.svg
      fullname: Baddepudi Venkata Naga Sri Sai Vineetha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: saivineetha
      type: user
    createdAt: '2023-12-12T10:37:48.000Z'
    data:
      edited: false
      editors:
      - saivineetha
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5665883421897888
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9df73264fe5d79bebd9389bc900f01af.svg
          fullname: Baddepudi Venkata Naga Sri Sai Vineetha
          isHf: false
          isPro: false
          name: saivineetha
          type: user
        html: '<p>I have done SFT training on the model with base model as facebook
          opt-350m. Later saved the trained model and trying to deploy on aws sagemaker.
          But I''m getting this error "safetensors_rust.SafetensorError: Error while
          deserializing header: MetadataIncompleteBuffer"</p>

          <p>How can this error be solved in deployment</p>

          <p>import json<br>from sagemaker.huggingface import HuggingFaceModel</p>

          <h1 id="sagemaker-config">sagemaker config</h1>

          <p>instance_type = "ml.g5.4xlarge"<br>number_of_gpu = 1<br>health_check_timeout
          = 300</p>

          <h1 id="define-model-and-endpoint-configuration-parameter">Define Model
          and Endpoint configuration parameter</h1>

          <p>config = {<br>  ''HF_MODEL_ID'': "/opt/ml/model", # path to where sagemaker
          stores the model<br>  ''SM_NUM_GPUS'': json.dumps(number_of_gpu), # Number
          of GPU used per replica<br>  ''MAX_INPUT_LENGTH'': json.dumps(1024), # Max
          length of input text<br>  ''MAX_TOTAL_TOKENS'': json.dumps(2048), # Max
          length of the generation (including input text)</p>

          <h1 id="hf_model_quantize-bitsandbytes-comment-in-to-quantize">''HF_MODEL_QUANTIZE'':
          "bitsandbytes",# Comment in to quantize</h1>

          <p>}</p>

          <h1 id="create-huggingfacemodel-with-the-image-uri">create HuggingFaceModel
          with the image uri</h1>

          <p>llm_model = HuggingFaceModel(<br>  role=role,<br>  image_uri=llm_image,<br>  model_data=s3_model_uri,<br>  env=config<br>)</p>

          <h1 id="deploy-model-to-an-endpoint">Deploy model to an endpoint</h1>

          <h1 id="httpssagemakerreadthedocsioenstableapiinferencemodelhtmlsagemakermodelmodeldeploy"><a
          rel="nofollow" href="https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy">https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy</a></h1>

          <p>llm = llm_model.deploy(<br>  initial_instance_count=1,<br>  instance_type=instance_type,</p>

          <h1 id="volume_size400--if-using-an-instance-with-local-ssd-storage-volume_size-must-be-none-eg-p4-but-not-p3">volume_size=400,
          # If using an instance with local SSD storage, volume_size must be None,
          e.g. p4 but not p3</h1>

          <p>  container_startup_health_check_timeout=health_check_timeout, # 10 minutes
          to be able to load the model<br>)</p>

          <p>I''ve tried this code for deploying. But getting the error "safetensors_rust.SafetensorError:
          Error while deserializing header: MetadataIncompleteBuffer". How can I solve
          it</p>

          '
        raw: "I have done SFT training on the model with base model as facebook opt-350m.\
          \ Later saved the trained model and trying to deploy on aws sagemaker. But\
          \ I'm getting this error \"safetensors_rust.SafetensorError: Error while\
          \ deserializing header: MetadataIncompleteBuffer\"\r\n\r\nHow can this error\
          \ be solved in deployment\r\n\r\nimport json\r\nfrom sagemaker.huggingface\
          \ import HuggingFaceModel\r\n\r\n# sagemaker config\r\ninstance_type = \"\
          ml.g5.4xlarge\"\r\nnumber_of_gpu = 1\r\nhealth_check_timeout = 300\r\n\r\
          \n# Define Model and Endpoint configuration parameter\r\nconfig = {\r\n\
          \  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the\
          \ model\r\n  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used\
          \ per replica\r\n  'MAX_INPUT_LENGTH': json.dumps(1024), # Max length of\
          \ input text\r\n  'MAX_TOTAL_TOKENS': json.dumps(2048), # Max length of\
          \ the generation (including input text)\r\n  # 'HF_MODEL_QUANTIZE': \"bitsandbytes\"\
          ,# Comment in to quantize\r\n}\r\n\r\n# create HuggingFaceModel with the\
          \ image uri\r\nllm_model = HuggingFaceModel(\r\n  role=role,\r\n  image_uri=llm_image,\r\
          \n  model_data=s3_model_uri,\r\n  env=config\r\n)\r\n\r\n# Deploy model\
          \ to an endpoint\r\n# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\r\
          \nllm = llm_model.deploy(\r\n  initial_instance_count=1,\r\n  instance_type=instance_type,\r\
          \n  # volume_size=400, # If using an instance with local SSD storage, volume_size\
          \ must be None, e.g. p4 but not p3\r\n  container_startup_health_check_timeout=health_check_timeout,\
          \ # 10 minutes to be able to load the model\r\n)\r\n\r\nI've tried this\
          \ code for deploying. But getting the error \"safetensors_rust.SafetensorError:\
          \ Error while deserializing header: MetadataIncompleteBuffer\". How can\
          \ I solve it"
        updatedAt: '2023-12-12T10:37:48.539Z'
      numEdits: 0
      reactions: []
    id: 657837fc6cb1dcb957deea38
    type: comment
  author: saivineetha
  content: "I have done SFT training on the model with base model as facebook opt-350m.\
    \ Later saved the trained model and trying to deploy on aws sagemaker. But I'm\
    \ getting this error \"safetensors_rust.SafetensorError: Error while deserializing\
    \ header: MetadataIncompleteBuffer\"\r\n\r\nHow can this error be solved in deployment\r\
    \n\r\nimport json\r\nfrom sagemaker.huggingface import HuggingFaceModel\r\n\r\n\
    # sagemaker config\r\ninstance_type = \"ml.g5.4xlarge\"\r\nnumber_of_gpu = 1\r\
    \nhealth_check_timeout = 300\r\n\r\n# Define Model and Endpoint configuration\
    \ parameter\r\nconfig = {\r\n  'HF_MODEL_ID': \"/opt/ml/model\", # path to where\
    \ sagemaker stores the model\r\n  'SM_NUM_GPUS': json.dumps(number_of_gpu), #\
    \ Number of GPU used per replica\r\n  'MAX_INPUT_LENGTH': json.dumps(1024), #\
    \ Max length of input text\r\n  'MAX_TOTAL_TOKENS': json.dumps(2048), # Max length\
    \ of the generation (including input text)\r\n  # 'HF_MODEL_QUANTIZE': \"bitsandbytes\"\
    ,# Comment in to quantize\r\n}\r\n\r\n# create HuggingFaceModel with the image\
    \ uri\r\nllm_model = HuggingFaceModel(\r\n  role=role,\r\n  image_uri=llm_image,\r\
    \n  model_data=s3_model_uri,\r\n  env=config\r\n)\r\n\r\n# Deploy model to an\
    \ endpoint\r\n# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\r\
    \nllm = llm_model.deploy(\r\n  initial_instance_count=1,\r\n  instance_type=instance_type,\r\
    \n  # volume_size=400, # If using an instance with local SSD storage, volume_size\
    \ must be None, e.g. p4 but not p3\r\n  container_startup_health_check_timeout=health_check_timeout,\
    \ # 10 minutes to be able to load the model\r\n)\r\n\r\nI've tried this code for\
    \ deploying. But getting the error \"safetensors_rust.SafetensorError: Error while\
    \ deserializing header: MetadataIncompleteBuffer\". How can I solve it"
  created_at: 2023-12-12 10:37:48+00:00
  edited: false
  hidden: false
  id: 657837fc6cb1dcb957deea38
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
      fullname: Yih-Dar SHIEH
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ydshieh
      type: user
    createdAt: '2023-12-12T14:38:03.000Z'
    data:
      edited: false
      editors:
      - ydshieh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7268298864364624
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625150194719-6058c8cbcbe9c7542f3501ff.png?w=200&h=200&f=face
          fullname: Yih-Dar SHIEH
          isHf: true
          isPro: false
          name: ydshieh
          type: user
        html: '<p>I am not familiar with the sagemaker deployment, but google gives
          some information, and one is</p>

          <p><a rel="nofollow" href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/10199">https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/10199</a></p>

          '
        raw: 'I am not familiar with the sagemaker deployment, but google gives some
          information, and one is


          https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/10199'
        updatedAt: '2023-12-12T14:38:03.393Z'
      numEdits: 0
      reactions: []
    id: 6578704b197a6182c34e02f0
    type: comment
  author: ydshieh
  content: 'I am not familiar with the sagemaker deployment, but google gives some
    information, and one is


    https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/10199'
  created_at: 2023-12-12 14:38:03+00:00
  edited: false
  hidden: false
  id: 6578704b197a6182c34e02f0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9df73264fe5d79bebd9389bc900f01af.svg
      fullname: Baddepudi Venkata Naga Sri Sai Vineetha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: saivineetha
      type: user
    createdAt: '2023-12-13T06:52:13.000Z'
    data:
      edited: false
      editors:
      - saivineetha
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.883402943611145
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9df73264fe5d79bebd9389bc900f01af.svg
          fullname: Baddepudi Venkata Naga Sri Sai Vineetha
          isHf: false
          isPro: false
          name: saivineetha
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;ydshieh&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ydshieh\"\
          >@<span class=\"underline\">ydshieh</span></a></span>\n\n\t</span></span>\
          \ for the help.</p>\n"
        raw: Thanks @ydshieh for the help.
        updatedAt: '2023-12-13T06:52:13.542Z'
      numEdits: 0
      reactions: []
    id: 6579549d62d3ac18171ca392
    type: comment
  author: saivineetha
  content: Thanks @ydshieh for the help.
  created_at: 2023-12-13 06:52:13+00:00
  edited: false
  hidden: false
  id: 6579549d62d3ac18171ca392
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 35
repo_id: facebook/opt-350m
repo_type: model
status: open
target_branch: null
title: 'safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer'
