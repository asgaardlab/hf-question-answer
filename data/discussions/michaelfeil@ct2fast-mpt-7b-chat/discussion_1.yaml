!!python/object:huggingface_hub.community.DiscussionWithDetails
author: g30rv17ys
conflicting_files: null
created_at: 2023-05-30 16:57:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665920159204-618ccf9219d7d2a706004b98.png?w=200&h=200&f=face
      fullname: g30rv1ty
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: g30rv17ys
      type: user
    createdAt: '2023-05-30T17:57:12.000Z'
    data:
      edited: false
      editors:
      - g30rv17ys
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665920159204-618ccf9219d7d2a706004b98.png?w=200&h=200&f=face
          fullname: g30rv1ty
          isHf: false
          isPro: false
          name: g30rv17ys
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;michaelfeil&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/michaelfeil\"\
          >@<span class=\"underline\">michaelfeil</span></a></span>\n\n\t</span></span>\
          \ .</p>\n<p>thank you for the model that can be loaded in 8bit.<br>when\
          \ I try to run inference, it keeps on generating texts.<br>Whereas , I just\
          \ want an answer to my question.</p>\n<p>Could you edit the inference script\
          \ such that we only get precise answers and not uncontrolled generations.<br>I've\
          \ attached a screenshot below of what output i am getting, hope you can\
          \ suggest a fix for this.<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/618ccf9219d7d2a706004b98/-JZ_I5CPwe5or0EFHDdB-.png\"\
          ><img alt=\"Screenshot from 2023-05-30 23-24-31.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/618ccf9219d7d2a706004b98/-JZ_I5CPwe5or0EFHDdB-.png\"\
          ></a></p>\n"
        raw: "@michaelfeil .\r\n\r\nthank you for the model that can be loaded in\
          \ 8bit.\r\nwhen I try to run inference, it keeps on generating texts.\r\n\
          Whereas , I just want an answer to my question.\r\n\r\nCould you edit the\
          \ inference script such that we only get precise answers and not uncontrolled\
          \ generations.\r\nI've attached a screenshot below of what output i am getting,\
          \ hope you can suggest a fix for this.\r\n![Screenshot from 2023-05-30 23-24-31.png](https://cdn-uploads.huggingface.co/production/uploads/618ccf9219d7d2a706004b98/-JZ_I5CPwe5or0EFHDdB-.png)\r\
          \n"
        updatedAt: '2023-05-30T17:57:12.833Z'
      numEdits: 0
      reactions: []
    id: 647638f8ce774efd373dafb5
    type: comment
  author: g30rv17ys
  content: "@michaelfeil .\r\n\r\nthank you for the model that can be loaded in 8bit.\r\
    \nwhen I try to run inference, it keeps on generating texts.\r\nWhereas , I just\
    \ want an answer to my question.\r\n\r\nCould you edit the inference script such\
    \ that we only get precise answers and not uncontrolled generations.\r\nI've attached\
    \ a screenshot below of what output i am getting, hope you can suggest a fix for\
    \ this.\r\n![Screenshot from 2023-05-30 23-24-31.png](https://cdn-uploads.huggingface.co/production/uploads/618ccf9219d7d2a706004b98/-JZ_I5CPwe5or0EFHDdB-.png)\r\
    \n"
  created_at: 2023-05-30 16:57:12+00:00
  edited: false
  hidden: false
  id: 647638f8ce774efd373dafb5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
      fullname: Michael
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: michaelfeil
      type: user
    createdAt: '2023-05-30T18:11:15.000Z'
    data:
      edited: true
      editors:
      - michaelfeil
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
          fullname: Michael
          isHf: false
          isPro: false
          name: michaelfeil
          type: user
        html: "<p>There is no easy fix for this, a typical problem in any library.<br>As\
          \ in <a rel=\"nofollow\" href=\"https://github.com/michaelfeil/hf-hub-ctranslate2/blob/e236f006593fb00633f9874fe414c87bd9735813/hf_hub_ctranslate2/translate.py#LL309C1-L334C70\"\
          >https://github.com/michaelfeil/hf-hub-ctranslate2/blob/e236f006593fb00633f9874fe414c87bd9735813/hf_hub_ctranslate2/translate.py#LL309C1-L334C70</a><br>You\
          \ might want to set <code>end_token =[\"User\u201C, \u201Euser\u201C]</code>\
          \ or so.</p>\n"
        raw: "There is no easy fix for this, a typical problem in any library.\nAs\
          \ in https://github.com/michaelfeil/hf-hub-ctranslate2/blob/e236f006593fb00633f9874fe414c87bd9735813/hf_hub_ctranslate2/translate.py#LL309C1-L334C70\n\
          You might want to set `end_token =[\"User\u201C, \u201Euser\u201C]` or so."
        updatedAt: '2023-05-30T18:31:00.062Z'
      numEdits: 1
      reactions: []
    id: 64763c43cfe9d995bf3cc029
    type: comment
  author: michaelfeil
  content: "There is no easy fix for this, a typical problem in any library.\nAs in\
    \ https://github.com/michaelfeil/hf-hub-ctranslate2/blob/e236f006593fb00633f9874fe414c87bd9735813/hf_hub_ctranslate2/translate.py#LL309C1-L334C70\n\
    You might want to set `end_token =[\"User\u201C, \u201Euser\u201C]` or so."
  created_at: 2023-05-30 17:11:15+00:00
  edited: true
  hidden: false
  id: 64763c43cfe9d995bf3cc029
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665920159204-618ccf9219d7d2a706004b98.png?w=200&h=200&f=face
      fullname: g30rv1ty
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: g30rv17ys
      type: user
    createdAt: '2023-05-30T18:14:23.000Z'
    data:
      edited: false
      editors:
      - g30rv17ys
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665920159204-618ccf9219d7d2a706004b98.png?w=200&h=200&f=face
          fullname: g30rv1ty
          isHf: false
          isPro: false
          name: g30rv17ys
          type: user
        html: "<p>thanks for the reply <span data-props=\"{&quot;user&quot;:&quot;michaelfeil&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/michaelfeil\"\
          >@<span class=\"underline\">michaelfeil</span></a></span>\n\n\t</span></span>\
          \ .<br>i noticed that you can get perfect answers in the mpt-7b-chat space\
          \ : <a href=\"https://huggingface.co/spaces/mosaicml/mpt-7b-chat\">https://huggingface.co/spaces/mosaicml/mpt-7b-chat</a><br>could\
          \ you have a look at the app.py file.</p>\n<p>maybe it can suggest a fix\
          \ to the issue.</p>\n<p>how would you re-write the inference example you\
          \ mentioned in the readme to sort of resolve the issue even a bit.could\
          \ you paste the updated inference script in your next reply?</p>\n"
        raw: 'thanks for the reply @michaelfeil .

          i noticed that you can get perfect answers in the mpt-7b-chat space : https://huggingface.co/spaces/mosaicml/mpt-7b-chat

          could you have a look at the app.py file.


          maybe it can suggest a fix to the issue.


          how would you re-write the inference example you mentioned in the readme
          to sort of resolve the issue even a bit.could you paste the updated inference
          script in your next reply?'
        updatedAt: '2023-05-30T18:14:23.782Z'
      numEdits: 0
      reactions: []
    id: 64763cff6f0553f1b4f4ae02
    type: comment
  author: g30rv17ys
  content: 'thanks for the reply @michaelfeil .

    i noticed that you can get perfect answers in the mpt-7b-chat space : https://huggingface.co/spaces/mosaicml/mpt-7b-chat

    could you have a look at the app.py file.


    maybe it can suggest a fix to the issue.


    how would you re-write the inference example you mentioned in the readme to sort
    of resolve the issue even a bit.could you paste the updated inference script in
    your next reply?'
  created_at: 2023-05-30 17:14:23+00:00
  edited: false
  hidden: false
  id: 64763cff6f0553f1b4f4ae02
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665920159204-618ccf9219d7d2a706004b98.png?w=200&h=200&f=face
      fullname: g30rv1ty
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: g30rv17ys
      type: user
    createdAt: '2023-05-30T18:17:40.000Z'
    data:
      edited: true
      editors:
      - g30rv17ys
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665920159204-618ccf9219d7d2a706004b98.png?w=200&h=200&f=face
          fullname: g30rv1ty
          isHf: false
          isPro: false
          name: g30rv17ys
          type: user
        html: "<p>say for eg , in the below script</p>\n<p>from hf_hub_ctranslate2\
          \ import TranslatorCT2fromHfHub, GeneratorCT2fromHfHub<br>from transformers\
          \ import AutoTokenizer</p>\n<p>model_name = \"michaelfeil/ct2fast-mpt-7b-chat\"\
          <br>model = GeneratorCT2fromHfHub(<br>        # load in int8 on CUDA<br>\
          \        model_name_or_path=model_name,<br>        device=\"cuda\",<br>\
          \        compute_type=\"int8_float16\",<br>)<br>outputs = model.generate(<br>\
          \    text=[\"User: what is the largest mountain on mars? Bot:\"],<br>  \
          \  max_length=256<br>)<br>print(outputs)</p>\n<p>it would be great if the\
          \ output was :<br>Bot : The largest mountain on mars in Olympus Mons.</p>\n\
          <p>It actually gives the right answer , but it then continues with some\
          \ other text. I want it to stop at Olympus Mons. <span data-props=\"{&quot;user&quot;:&quot;michaelfeil&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/michaelfeil\"\
          >@<span class=\"underline\">michaelfeil</span></a></span>\n\n\t</span></span></p>\n"
        raw: "say for eg , in the below script\n\nfrom hf_hub_ctranslate2 import TranslatorCT2fromHfHub,\
          \ GeneratorCT2fromHfHub\nfrom transformers import AutoTokenizer\n\nmodel_name\
          \ = \"michaelfeil/ct2fast-mpt-7b-chat\"\nmodel = GeneratorCT2fromHfHub(\n\
          \        # load in int8 on CUDA\n        model_name_or_path=model_name,\
          \ \n        device=\"cuda\",\n        compute_type=\"int8_float16\",\n)\n\
          outputs = model.generate(\n    text=[\"User: what is the largest mountain\
          \ on mars? Bot:\"],\n    max_length=256\n)\nprint(outputs)\n\n\nit would\
          \ be great if the output was :\nBot : The largest mountain on mars in Olympus\
          \ Mons.\n\nIt actually gives the right answer , but it then continues with\
          \ some other text. I want it to stop at Olympus Mons. @michaelfeil"
        updatedAt: '2023-05-30T18:17:54.648Z'
      numEdits: 1
      reactions: []
    id: 64763dc4cfe9d995bf3cddde
    type: comment
  author: g30rv17ys
  content: "say for eg , in the below script\n\nfrom hf_hub_ctranslate2 import TranslatorCT2fromHfHub,\
    \ GeneratorCT2fromHfHub\nfrom transformers import AutoTokenizer\n\nmodel_name\
    \ = \"michaelfeil/ct2fast-mpt-7b-chat\"\nmodel = GeneratorCT2fromHfHub(\n    \
    \    # load in int8 on CUDA\n        model_name_or_path=model_name, \n       \
    \ device=\"cuda\",\n        compute_type=\"int8_float16\",\n)\noutputs = model.generate(\n\
    \    text=[\"User: what is the largest mountain on mars? Bot:\"],\n    max_length=256\n\
    )\nprint(outputs)\n\n\nit would be great if the output was :\nBot : The largest\
    \ mountain on mars in Olympus Mons.\n\nIt actually gives the right answer , but\
    \ it then continues with some other text. I want it to stop at Olympus Mons. @michaelfeil"
  created_at: 2023-05-30 17:17:40+00:00
  edited: true
  hidden: false
  id: 64763dc4cfe9d995bf3cddde
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665920159204-618ccf9219d7d2a706004b98.png?w=200&h=200&f=face
      fullname: g30rv1ty
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: g30rv17ys
      type: user
    createdAt: '2023-05-30T18:22:44.000Z'
    data:
      edited: false
      editors:
      - g30rv17ys
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665920159204-618ccf9219d7d2a706004b98.png?w=200&h=200&f=face
          fullname: g30rv1ty
          isHf: false
          isPro: false
          name: g30rv17ys
          type: user
        html: "<p>also you can check this notebook for eg <span data-props=\"{&quot;user&quot;:&quot;michaelfeil&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/michaelfeil\"\
          >@<span class=\"underline\">michaelfeil</span></a></span>\n\n\t</span></span><br><a\
          \ rel=\"nofollow\" href=\"https://colab.research.google.com/drive/1s2beg55SEV8ICHufhwcflYtUNskTX8kO\"\
          >https://colab.research.google.com/drive/1s2beg55SEV8ICHufhwcflYtUNskTX8kO</a></p>\n\
          <p>it ends the sentence perfectly!</p>\n"
        raw: "also you can check this notebook for eg @michaelfeil \nhttps://colab.research.google.com/drive/1s2beg55SEV8ICHufhwcflYtUNskTX8kO\n\
          \nit ends the sentence perfectly!"
        updatedAt: '2023-05-30T18:22:44.996Z'
      numEdits: 0
      reactions: []
    id: 64763ef4cfe9d995bf3cf489
    type: comment
  author: g30rv17ys
  content: "also you can check this notebook for eg @michaelfeil \nhttps://colab.research.google.com/drive/1s2beg55SEV8ICHufhwcflYtUNskTX8kO\n\
    \nit ends the sentence perfectly!"
  created_at: 2023-05-30 17:22:44+00:00
  edited: false
  hidden: false
  id: 64763ef4cfe9d995bf3cf489
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
      fullname: Michael
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: michaelfeil
      type: user
    createdAt: '2023-05-30T18:31:41.000Z'
    data:
      edited: false
      editors:
      - michaelfeil
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
          fullname: Michael
          isHf: false
          isPro: false
          name: michaelfeil
          type: user
        html: "<p>You might set end_token=[\u201EUser\u201C], as keyword to model.generate</p>\n"
        raw: "You might set end_token=[\u201EUser\u201C], as keyword to model.generate"
        updatedAt: '2023-05-30T18:31:41.207Z'
      numEdits: 0
      reactions: []
    id: 6476410d57108da176fc301d
    type: comment
  author: michaelfeil
  content: "You might set end_token=[\u201EUser\u201C], as keyword to model.generate"
  created_at: 2023-05-30 17:31:41+00:00
  edited: false
  hidden: false
  id: 6476410d57108da176fc301d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665920159204-618ccf9219d7d2a706004b98.png?w=200&h=200&f=face
      fullname: g30rv1ty
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: g30rv17ys
      type: user
    createdAt: '2023-05-30T18:35:08.000Z'
    data:
      edited: true
      editors:
      - g30rv17ys
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665920159204-618ccf9219d7d2a706004b98.png?w=200&h=200&f=face
          fullname: g30rv1ty
          isHf: false
          isPro: false
          name: g30rv17ys
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;michaelfeil&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/michaelfeil\"\
          >@<span class=\"underline\">michaelfeil</span></a></span>\n\n\t</span></span>\
          \ , i updated the code as follows </p>\n<p>from hf_hub_ctranslate2 import\
          \ TranslatorCT2fromHfHub, GeneratorCT2fromHfHub<br>from transformers import\
          \ AutoTokenizer</p>\n<p>model_name = \"michaelfeil/ct2fast-mpt-7b-chat\"\
          <br>model = GeneratorCT2fromHfHub(<br>        # load in int8 on CUDA<br>\
          \        model_name_or_path=model_name,<br>        device=\"cuda\",<br>\
          \        compute_type=\"int8_float16\",<br>)<br>outputs = model.generate(<br>\
          \    text=[\"User: what is the largest mountain on mars? Bot:\"],<br>  \
          \  end_token=[\"User\"],<br>    max_length=256<br>)</p>\n<p>print(outputs)</p>\n\
          <p>but i am still getting same continues output :</p>\n<p><a rel=\"nofollow\"\
          \ href=\"https://cdn-uploads.huggingface.co/production/uploads/618ccf9219d7d2a706004b98/VPS1pLmUSlnwdu4lf9A3D.png\"\
          ><img alt=\"Screenshot from 2023-05-31 00-04-50.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/618ccf9219d7d2a706004b98/VPS1pLmUSlnwdu4lf9A3D.png\"\
          ></a></p>\n"
        raw: "@michaelfeil , i updated the code as follows \n\nfrom hf_hub_ctranslate2\
          \ import TranslatorCT2fromHfHub, GeneratorCT2fromHfHub\nfrom transformers\
          \ import AutoTokenizer\n\nmodel_name = \"michaelfeil/ct2fast-mpt-7b-chat\"\
          \nmodel = GeneratorCT2fromHfHub(\n        # load in int8 on CUDA\n     \
          \   model_name_or_path=model_name, \n        device=\"cuda\",\n        compute_type=\"\
          int8_float16\",\n)\noutputs = model.generate(\n    text=[\"User: what is\
          \ the largest mountain on mars? Bot:\"],\n    end_token=[\"User\"],\n  \
          \  max_length=256\n)\n\n\nprint(outputs)\n\n\nbut i am still getting same\
          \ continues output :\n\n![Screenshot from 2023-05-31 00-04-50.png](https://cdn-uploads.huggingface.co/production/uploads/618ccf9219d7d2a706004b98/VPS1pLmUSlnwdu4lf9A3D.png)"
        updatedAt: '2023-05-30T18:35:25.896Z'
      numEdits: 1
      reactions: []
    id: 647641dc6f0553f1b4f509b8
    type: comment
  author: g30rv17ys
  content: "@michaelfeil , i updated the code as follows \n\nfrom hf_hub_ctranslate2\
    \ import TranslatorCT2fromHfHub, GeneratorCT2fromHfHub\nfrom transformers import\
    \ AutoTokenizer\n\nmodel_name = \"michaelfeil/ct2fast-mpt-7b-chat\"\nmodel = GeneratorCT2fromHfHub(\n\
    \        # load in int8 on CUDA\n        model_name_or_path=model_name, \n   \
    \     device=\"cuda\",\n        compute_type=\"int8_float16\",\n)\noutputs = model.generate(\n\
    \    text=[\"User: what is the largest mountain on mars? Bot:\"],\n    end_token=[\"\
    User\"],\n    max_length=256\n)\n\n\nprint(outputs)\n\n\nbut i am still getting\
    \ same continues output :\n\n![Screenshot from 2023-05-31 00-04-50.png](https://cdn-uploads.huggingface.co/production/uploads/618ccf9219d7d2a706004b98/VPS1pLmUSlnwdu4lf9A3D.png)"
  created_at: 2023-05-30 17:35:08+00:00
  edited: true
  hidden: false
  id: 647641dc6f0553f1b4f509b8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
      fullname: Michael
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: michaelfeil
      type: user
    createdAt: '2023-05-30T19:23:43.000Z'
    data:
      edited: false
      editors:
      - michaelfeil
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
          fullname: Michael
          isHf: false
          isPro: false
          name: michaelfeil
          type: user
        html: "<p>User and Bot are also no special tokens, they are just dummies I\
          \ used for a bunch of other models.<br>Not sure why the stop tokens do not\
          \ work in this case. </p>\n<p>Can\u2019t support, if you found a good solution,\
          \ feel free to share it here.</p>\n"
        raw: "User and Bot are also no special tokens, they are just dummies I used\
          \ for a bunch of other models. \nNot sure why the stop tokens do not work\
          \ in this case. \n\nCan\u2019t support, if you found a good solution, feel\
          \ free to share it here."
        updatedAt: '2023-05-30T19:23:43.610Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - g30rv17ys
    id: 64764d3fde6be93fe7aed341
    type: comment
  author: michaelfeil
  content: "User and Bot are also no special tokens, they are just dummies I used\
    \ for a bunch of other models. \nNot sure why the stop tokens do not work in this\
    \ case. \n\nCan\u2019t support, if you found a good solution, feel free to share\
    \ it here."
  created_at: 2023-05-30 18:23:43+00:00
  edited: false
  hidden: false
  id: 64764d3fde6be93fe7aed341
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
      fullname: Michael
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: michaelfeil
      type: user
    createdAt: '2023-05-30T19:28:43.000Z'
    data:
      edited: false
      editors:
      - michaelfeil
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
          fullname: Michael
          isHf: false
          isPro: false
          name: michaelfeil
          type: user
        html: '<p>Okay, stop tokens are ["&lt;|im_end|&gt;", "&lt;|endoftext|&gt;"])<br>And
          messages should be formatted in the style</p>

          <p>f"&lt;|im_start|&gt;user\n{item[0]}&lt;|im_end|&gt;",<br>                    f"&lt;|im_start|&gt;assistant\n{item[1]}&lt;|im_end|&gt;",<br>                ]</p>

          <p>See the app.py in mpt chat space.</p>

          '
        raw: "Okay, stop tokens are [\"<|im_end|>\", \"<|endoftext|>\"])\nAnd messages\
          \ should be formatted in the style\n\nf\"<|im_start|>user\\n{item[0]}<|im_end|>\"\
          ,\n                    f\"<|im_start|>assistant\\n{item[1]}<|im_end|>\"\
          ,\n                ]\n\nSee the app.py in mpt chat space."
        updatedAt: '2023-05-30T19:28:43.475Z'
      numEdits: 0
      reactions: []
    id: 64764e6b57108da176fd349d
    type: comment
  author: michaelfeil
  content: "Okay, stop tokens are [\"<|im_end|>\", \"<|endoftext|>\"])\nAnd messages\
    \ should be formatted in the style\n\nf\"<|im_start|>user\\n{item[0]}<|im_end|>\"\
    ,\n                    f\"<|im_start|>assistant\\n{item[1]}<|im_end|>\",\n   \
    \             ]\n\nSee the app.py in mpt chat space."
  created_at: 2023-05-30 18:28:43+00:00
  edited: false
  hidden: false
  id: 64764e6b57108da176fd349d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665920159204-618ccf9219d7d2a706004b98.png?w=200&h=200&f=face
      fullname: g30rv1ty
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: g30rv17ys
      type: user
    createdAt: '2023-05-31T06:57:53.000Z'
    data:
      edited: false
      editors:
      - g30rv17ys
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665920159204-618ccf9219d7d2a706004b98.png?w=200&h=200&f=face
          fullname: g30rv1ty
          isHf: false
          isPro: false
          name: g30rv17ys
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;michaelfeil&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/michaelfeil\"\
          >@<span class=\"underline\">michaelfeil</span></a></span>\n\n\t</span></span>\
          \ could you paste the whole script here if possible?</p>\n"
        raw: '@michaelfeil could you paste the whole script here if possible?'
        updatedAt: '2023-05-31T06:57:53.631Z'
      numEdits: 0
      reactions: []
    id: 6476eff140c99df876fd75af
    type: comment
  author: g30rv17ys
  content: '@michaelfeil could you paste the whole script here if possible?'
  created_at: 2023-05-31 05:57:53+00:00
  edited: false
  hidden: false
  id: 6476eff140c99df876fd75af
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
      fullname: Michael
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: michaelfeil
      type: user
    createdAt: '2023-05-31T07:17:12.000Z'
    data:
      edited: false
      editors:
      - michaelfeil
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
          fullname: Michael
          isHf: false
          isPro: false
          name: michaelfeil
          type: user
        html: "<p>Sorry, can\u2019t provide further help.</p>\n"
        raw: "Sorry, can\u2019t provide further help."
        updatedAt: '2023-05-31T07:17:12.742Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6476f478242dde3163fca55b
    id: 6476f478242dde3163fca55a
    type: comment
  author: michaelfeil
  content: "Sorry, can\u2019t provide further help."
  created_at: 2023-05-31 06:17:12+00:00
  edited: false
  hidden: false
  id: 6476f478242dde3163fca55a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
      fullname: Michael
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: michaelfeil
      type: user
    createdAt: '2023-05-31T07:17:12.000Z'
    data:
      status: closed
    id: 6476f478242dde3163fca55b
    type: status-change
  author: michaelfeil
  created_at: 2023-05-31 06:17:12+00:00
  id: 6476f478242dde3163fca55b
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: michaelfeil/ct2fast-mpt-7b-chat
repo_type: model
status: closed
target_branch: null
title: request for fixing inference script to get controlled the text output generation
