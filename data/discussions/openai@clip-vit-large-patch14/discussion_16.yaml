!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Abelandadou
conflicting_files: null
created_at: 2023-03-10 01:34:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a14e89fc97345a4dfff161557e459114.svg
      fullname: Abel_adou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Abelandadou
      type: user
    createdAt: '2023-03-10T01:34:20.000Z'
    data:
      edited: false
      editors:
      - Abelandadou
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a14e89fc97345a4dfff161557e459114.svg
          fullname: Abel_adou
          isHf: false
          isPro: false
          name: Abelandadou
          type: user
        html: '<p>from PIL import Image<br>import requests</p>

          <p>from transformers import CLIPProcessor, CLIPModel</p>

          <p>model = CLIPModel.from_pretrained("openai/clip-vit-large-patch14")<br>processor
          = CLIPProcessor.from_pretrained("openai/clip-vit-large-patch14")</p>

          <p>url = "<a rel="nofollow" href="http://images.cocodataset.org/val2017/000000039769.jpg&quot;">http://images.cocodataset.org/val2017/000000039769.jpg"</a><br>image
          = Image.open(requests.get(url, stream=True).raw)</p>

          <p>inputs = processor(text=["a photo of a  girl", "a photo of a woman"],
          images=image, return_tensors="pt", padding=True)</p>

          <p>outputs = model(**inputs)<br>logits_per_image = outputs.logits_per_image
          # this is the image-text similarity score<br>probs = logits_per_image.softmax(dim=1)
          # we can take the softmax to get the label probabilities</p>

          '
        raw: "from PIL import Image\r\nimport requests\r\n\r\nfrom transformers import\
          \ CLIPProcessor, CLIPModel\r\n\r\nmodel = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\"\
          )\r\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\"\
          )\r\n\r\nurl = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\
          \r\nimage = Image.open(requests.get(url, stream=True).raw)\r\n\r\ninputs\
          \ = processor(text=[\"a photo of a  girl\", \"a photo of a woman\"], images=image,\
          \ return_tensors=\"pt\", padding=True)\r\n\r\noutputs = model(**inputs)\r\
          \nlogits_per_image = outputs.logits_per_image # this is the image-text similarity\
          \ score\r\nprobs = logits_per_image.softmax(dim=1) # we can take the softmax\
          \ to get the label probabilities\r\n"
        updatedAt: '2023-03-10T01:34:20.104Z'
      numEdits: 0
      reactions: []
    id: 640a891c9989bcb11729db0c
    type: comment
  author: Abelandadou
  content: "from PIL import Image\r\nimport requests\r\n\r\nfrom transformers import\
    \ CLIPProcessor, CLIPModel\r\n\r\nmodel = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\"\
    )\r\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\"\
    )\r\n\r\nurl = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\r\n\
    image = Image.open(requests.get(url, stream=True).raw)\r\n\r\ninputs = processor(text=[\"\
    a photo of a  girl\", \"a photo of a woman\"], images=image, return_tensors=\"\
    pt\", padding=True)\r\n\r\noutputs = model(**inputs)\r\nlogits_per_image = outputs.logits_per_image\
    \ # this is the image-text similarity score\r\nprobs = logits_per_image.softmax(dim=1)\
    \ # we can take the softmax to get the label probabilities\r\n"
  created_at: 2023-03-10 01:34:20+00:00
  edited: false
  hidden: false
  id: 640a891c9989bcb11729db0c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: openai/clip-vit-large-patch14
repo_type: model
status: open
target_branch: null
title: dreamingAi
