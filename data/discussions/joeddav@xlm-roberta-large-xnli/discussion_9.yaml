!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jianyiyang5
conflicting_files: null
created_at: 2023-04-25 05:13:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e4b6a87932812aae6f145bc394d5acae.svg
      fullname: JianYi Yang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jianyiyang5
      type: user
    createdAt: '2023-04-25T06:13:09.000Z'
    data:
      edited: false
      editors:
      - jianyiyang5
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e4b6a87932812aae6f145bc394d5acae.svg
          fullname: JianYi Yang
          isHf: false
          isPro: false
          name: jianyiyang5
          type: user
        html: "<p>When execute the following command</p>\n<pre><code>import torch\n\
          from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n\
          R_tokenizer = XLMRobertaTokenizer.from_pretrained('joeddav/xlm-roberta-large-xnli')\n\
          </code></pre>\n<p>got the issue</p>\n<pre><code>---------------------------------------------------------------------------\n\
          HTTPError                                 Traceback (most recent call last)\n\
          &lt;ipython-input-20-48b86358d29a&gt; in &lt;module&gt;\n      3 \n    \
          \  4 \n----&gt; 5 R_tokenizer = XLMRobertaTokenizer.from_pretrained('joeddav/xlm-roberta-large-xnli')\n\
          \      6 premise = \"Jupiter's Biggest Moons Started as Tiny Grains of Hail\"\
          \n      7 hypothesis = 'This text is about space &amp; cosmos'\n\n/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\n\
          \   1715                 \"won't be possible anymore in v5. Use a model\
          \ identifier or the path to a directory instead.\",\n   1716           \
          \      FutureWarning,\n-&gt; 1717             )\n   1718             file_id\
          \ = list(cls.vocab_files_names.keys())[0]\n   1719 \n\n/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\n\
          \   1693         user_agent = {\"file_type\": \"tokenizer\", \"from_auto_class\"\
          : from_auto_class, \"is_fast\": \"Fast\" in cls.__name__}\n   1694     \
          \    if from_pipeline is not None:\n-&gt; 1695             user_agent[\"\
          using_pipeline\"] = from_pipeline\n   1696 \n   1697         if is_offline_mode()\
          \ and not local_files_only:\n\n/opt/conda/lib/python3.8/site-packages/transformers/file_utils.py\
          \ in cached_path(url_or_filename, cache_dir, force_download, proxies, resume_download,\
          \ user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\n\
          \n/opt/conda/lib/python3.8/site-packages/transformers/file_utils.py in get_from_cache(url,\
          \ cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent,\
          \ use_auth_token, local_files_only)\n\n/opt/conda/lib/python3.8/site-packages/requests/models.py\
          \ in raise_for_status(self)\n    939 \n    940         if http_error_msg:\n\
          --&gt; 941             raise HTTPError(http_error_msg, response=self)\n\
          \    942 \n    943     def close(self):\n\nHTTPError: 401 Client Error:\
          \ Unauthorized for url: https://huggingface.co/joeddav/xlm-roberta-large-xnli/resolve/main/sentencepiece.bpe.model\n\
          </code></pre>\n<p>I can download the file from webpage, any idea why this\
          \ happened? Thanks!</p>\n"
        raw: "When execute the following command\r\n```\r\nimport torch\r\nfrom transformers\
          \ import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\r\nR_tokenizer\
          \ = XLMRobertaTokenizer.from_pretrained('joeddav/xlm-roberta-large-xnli')\r\
          \n```\r\ngot the issue\r\n```\r\n---------------------------------------------------------------------------\r\
          \nHTTPError                                 Traceback (most recent call\
          \ last)\r\n<ipython-input-20-48b86358d29a> in <module>\r\n      3 \r\n \
          \     4 \r\n----> 5 R_tokenizer = XLMRobertaTokenizer.from_pretrained('joeddav/xlm-roberta-large-xnli')\r\
          \n      6 premise = \"Jupiter's Biggest Moons Started as Tiny Grains of\
          \ Hail\"\r\n      7 hypothesis = 'This text is about space & cosmos'\r\n\
          \r\n/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\r\
          \n   1715                 \"won't be possible anymore in v5. Use a model\
          \ identifier or the path to a directory instead.\",\r\n   1716         \
          \        FutureWarning,\r\n-> 1717             )\r\n   1718            \
          \ file_id = list(cls.vocab_files_names.keys())[0]\r\n   1719 \r\n\r\n/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\r\
          \n   1693         user_agent = {\"file_type\": \"tokenizer\", \"from_auto_class\"\
          : from_auto_class, \"is_fast\": \"Fast\" in cls.__name__}\r\n   1694   \
          \      if from_pipeline is not None:\r\n-> 1695             user_agent[\"\
          using_pipeline\"] = from_pipeline\r\n   1696 \r\n   1697         if is_offline_mode()\
          \ and not local_files_only:\r\n\r\n/opt/conda/lib/python3.8/site-packages/transformers/file_utils.py\
          \ in cached_path(url_or_filename, cache_dir, force_download, proxies, resume_download,\
          \ user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\r\
          \n\r\n/opt/conda/lib/python3.8/site-packages/transformers/file_utils.py\
          \ in get_from_cache(url, cache_dir, force_download, proxies, etag_timeout,\
          \ resume_download, user_agent, use_auth_token, local_files_only)\r\n\r\n\
          /opt/conda/lib/python3.8/site-packages/requests/models.py in raise_for_status(self)\r\
          \n    939 \r\n    940         if http_error_msg:\r\n--> 941            \
          \ raise HTTPError(http_error_msg, response=self)\r\n    942 \r\n    943\
          \     def close(self):\r\n\r\nHTTPError: 401 Client Error: Unauthorized\
          \ for url: https://huggingface.co/joeddav/xlm-roberta-large-xnli/resolve/main/sentencepiece.bpe.model\r\
          \n```\r\n\r\nI can download the file from webpage, any idea why this happened?\
          \ Thanks!"
        updatedAt: '2023-04-25T06:13:09.452Z'
      numEdits: 0
      reactions: []
    id: 64476f7519538c015b24aa4a
    type: comment
  author: jianyiyang5
  content: "When execute the following command\r\n```\r\nimport torch\r\nfrom transformers\
    \ import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\r\nR_tokenizer\
    \ = XLMRobertaTokenizer.from_pretrained('joeddav/xlm-roberta-large-xnli')\r\n\
    ```\r\ngot the issue\r\n```\r\n---------------------------------------------------------------------------\r\
    \nHTTPError                                 Traceback (most recent call last)\r\
    \n<ipython-input-20-48b86358d29a> in <module>\r\n      3 \r\n      4 \r\n---->\
    \ 5 R_tokenizer = XLMRobertaTokenizer.from_pretrained('joeddav/xlm-roberta-large-xnli')\r\
    \n      6 premise = \"Jupiter's Biggest Moons Started as Tiny Grains of Hail\"\
    \r\n      7 hypothesis = 'This text is about space & cosmos'\r\n\r\n/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\
    \ in from_pretrained(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\r\
    \n   1715                 \"won't be possible anymore in v5. Use a model identifier\
    \ or the path to a directory instead.\",\r\n   1716                 FutureWarning,\r\
    \n-> 1717             )\r\n   1718             file_id = list(cls.vocab_files_names.keys())[0]\r\
    \n   1719 \r\n\r\n/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\
    \ in from_pretrained(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\r\
    \n   1693         user_agent = {\"file_type\": \"tokenizer\", \"from_auto_class\"\
    : from_auto_class, \"is_fast\": \"Fast\" in cls.__name__}\r\n   1694         if\
    \ from_pipeline is not None:\r\n-> 1695             user_agent[\"using_pipeline\"\
    ] = from_pipeline\r\n   1696 \r\n   1697         if is_offline_mode() and not\
    \ local_files_only:\r\n\r\n/opt/conda/lib/python3.8/site-packages/transformers/file_utils.py\
    \ in cached_path(url_or_filename, cache_dir, force_download, proxies, resume_download,\
    \ user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\r\
    \n\r\n/opt/conda/lib/python3.8/site-packages/transformers/file_utils.py in get_from_cache(url,\
    \ cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent,\
    \ use_auth_token, local_files_only)\r\n\r\n/opt/conda/lib/python3.8/site-packages/requests/models.py\
    \ in raise_for_status(self)\r\n    939 \r\n    940         if http_error_msg:\r\
    \n--> 941             raise HTTPError(http_error_msg, response=self)\r\n    942\
    \ \r\n    943     def close(self):\r\n\r\nHTTPError: 401 Client Error: Unauthorized\
    \ for url: https://huggingface.co/joeddav/xlm-roberta-large-xnli/resolve/main/sentencepiece.bpe.model\r\
    \n```\r\n\r\nI can download the file from webpage, any idea why this happened?\
    \ Thanks!"
  created_at: 2023-04-25 05:13:09+00:00
  edited: false
  hidden: false
  id: 64476f7519538c015b24aa4a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3fa26d63d5a868bd82a58a891a14e81b.svg
      fullname: Ali-higo Ebo Adou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aliheadou
      type: user
    createdAt: '2023-05-23T13:11:16.000Z'
    data:
      edited: true
      editors:
      - aliheadou
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3fa26d63d5a868bd82a58a891a14e81b.svg
          fullname: Ali-higo Ebo Adou
          isHf: false
          isPro: false
          name: aliheadou
          type: user
        html: '<p>Hi, I am facing the same issue. Have you found any solution to that
          ?<br>Thanks in advance</p>

          '
        raw: 'Hi, I am facing the same issue. Have you found any solution to that
          ?

          Thanks in advance'
        updatedAt: '2023-05-23T13:11:26.372Z'
      numEdits: 1
      reactions:
      - count: 6
        reaction: "\U0001F44D"
        users:
        - Q8NLPResearch
        - liy140
        - choz
        - behouba
        - mokcho
        - Xavier321456
    id: 646cbb74b4eefa7c3695e234
    type: comment
  author: aliheadou
  content: 'Hi, I am facing the same issue. Have you found any solution to that ?

    Thanks in advance'
  created_at: 2023-05-23 12:11:16+00:00
  edited: true
  hidden: false
  id: 646cbb74b4eefa7c3695e234
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: joeddav/xlm-roberta-large-xnli
repo_type: model
status: open
target_branch: null
title: '401 Client Error: Unauthorized for url: https://huggingface.co/joeddav/xlm-roberta-large-xnli/resolve/main/sentencepiece.bpe.model'
