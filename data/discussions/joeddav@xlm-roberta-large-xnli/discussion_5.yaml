!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kai-fidelity
conflicting_files: null
created_at: 2023-03-21 09:20:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d31a5898c0bd5377a64c7231c1204c24.svg
      fullname: Kai Matzutt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kai-fidelity
      type: user
    createdAt: '2023-03-21T10:20:14.000Z'
    data:
      edited: false
      editors:
      - kai-fidelity
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d31a5898c0bd5377a64c7231c1204c24.svg
          fullname: Kai Matzutt
          isHf: false
          isPro: false
          name: kai-fidelity
          type: user
        html: "<p>I am not sure if this is the correct space for this comment/issue,\
          \ but it appears that there is a problem with the hosted inference API for\
          \ this model. Maybe this has something todo with the update to the model\
          \ files 4 days ago?</p>\n<pre><code>Can't load tokenizer using from_pretrained,\
          \ please update its configuration: 400 Client Error: \nBad Request for url:\
          \ \nhttps://s3.us-east-1.amazonaws.com/lfs.huggingface.co/joeddav/xlm-roberta-large-xnli/62c24cdc13d4c9952d63718d6c9fa4c287974249e16b7ade6d5a85e7bbb75626?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;X-Amz-Credential=AKIA4N7VTDGO27GPWFUO%2F20230321%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20230321T100319Z&amp;X-Amz-Expires=259200&amp;X-Amz-Signature=048f5a10b6d098c8ab56426e33ab4afcb243ab50853ca173454b4d41ad2fffea&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=attachment%3B%20filename%2A%3DUTF-8%27%27tokenizer.json%3B%20filename%3D%22tokenizer.json%22%3B&amp;response-content-type=application%2Fjson&amp;x-id=GetObject\n\
          </code></pre>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/1679393804269-62d7fec585364bf2ed02cb02.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/1679393804269-62d7fec585364bf2ed02cb02.png\"\
          ></a></p>\n"
        raw: "I am not sure if this is the correct space for this comment/issue, but\
          \ it appears that there is a problem with the hosted inference API for this\
          \ model. Maybe this has something todo with the update to the model files\
          \ 4 days ago?\r\n```\r\nCan't load tokenizer using from_pretrained, please\
          \ update its configuration: 400 Client Error: \r\nBad Request for url: \r\
          \nhttps://s3.us-east-1.amazonaws.com/lfs.huggingface.co/joeddav/xlm-roberta-large-xnli/62c24cdc13d4c9952d63718d6c9fa4c287974249e16b7ade6d5a85e7bbb75626?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA4N7VTDGO27GPWFUO%2F20230321%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230321T100319Z&X-Amz-Expires=259200&X-Amz-Signature=048f5a10b6d098c8ab56426e33ab4afcb243ab50853ca173454b4d41ad2fffea&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%2A%3DUTF-8%27%27tokenizer.json%3B%20filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&x-id=GetObject\r\
          \n```\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1679393804269-62d7fec585364bf2ed02cb02.png)\r\
          \n"
        updatedAt: '2023-03-21T10:20:14.872Z'
      numEdits: 0
      reactions: []
    id: 641984de8e0baaeed5a050d7
    type: comment
  author: kai-fidelity
  content: "I am not sure if this is the correct space for this comment/issue, but\
    \ it appears that there is a problem with the hosted inference API for this model.\
    \ Maybe this has something todo with the update to the model files 4 days ago?\r\
    \n```\r\nCan't load tokenizer using from_pretrained, please update its configuration:\
    \ 400 Client Error: \r\nBad Request for url: \r\nhttps://s3.us-east-1.amazonaws.com/lfs.huggingface.co/joeddav/xlm-roberta-large-xnli/62c24cdc13d4c9952d63718d6c9fa4c287974249e16b7ade6d5a85e7bbb75626?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA4N7VTDGO27GPWFUO%2F20230321%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230321T100319Z&X-Amz-Expires=259200&X-Amz-Signature=048f5a10b6d098c8ab56426e33ab4afcb243ab50853ca173454b4d41ad2fffea&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%2A%3DUTF-8%27%27tokenizer.json%3B%20filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&x-id=GetObject\r\
    \n```\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1679393804269-62d7fec585364bf2ed02cb02.png)\r\
    \n"
  created_at: 2023-03-21 09:20:14+00:00
  edited: false
  hidden: false
  id: 641984de8e0baaeed5a050d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653638890151-5e67bdfe100906368940747a.jpeg?w=200&h=200&f=face
      fullname: Joe Davison
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: joeddav
      type: user
    createdAt: '2023-03-21T17:56:01.000Z'
    data:
      edited: false
      editors:
      - joeddav
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653638890151-5e67bdfe100906368940747a.jpeg?w=200&h=200&f=face
          fullname: Joe Davison
          isHf: false
          isPro: false
          name: joeddav
          type: user
        html: '<p>I''m actually not sure what the problem is here, but I''m sure it
          has to do with that update. Ideas welcome.</p>

          '
        raw: I'm actually not sure what the problem is here, but I'm sure it has to
          do with that update. Ideas welcome.
        updatedAt: '2023-03-21T17:56:01.997Z'
      numEdits: 0
      reactions: []
    id: 6419efb1e4e6552b05dd2dfd
    type: comment
  author: joeddav
  content: I'm actually not sure what the problem is here, but I'm sure it has to
    do with that update. Ideas welcome.
  created_at: 2023-03-21 16:56:01+00:00
  edited: false
  hidden: false
  id: 6419efb1e4e6552b05dd2dfd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d31a5898c0bd5377a64c7231c1204c24.svg
      fullname: Kai Matzutt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kai-fidelity
      type: user
    createdAt: '2023-03-22T13:25:43.000Z'
    data:
      edited: false
      editors:
      - kai-fidelity
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d31a5898c0bd5377a64c7231c1204c24.svg
          fullname: Kai Matzutt
          isHf: false
          isPro: false
          name: kai-fidelity
          type: user
        html: '<p>I guess that the model files that used for the inference API are
          automatically put to AWS S3 upon new commits. The commit (5 days ag) itself
          appears to be alright, since the model files are accessible through the
          website on the "files and versions" page of the model card. But even loading
          the model directly or via pipeline fails:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/62d7fec585364bf2ed02cb02/Z44wMHBH7_rgbjM6i-izf.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/62d7fec585364bf2ed02cb02/Z44wMHBH7_rgbjM6i-izf.png"></a></p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/62d7fec585364bf2ed02cb02/9hM5G3Dygtj4lRc5CjFHu.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/62d7fec585364bf2ed02cb02/9hM5G3Dygtj4lRc5CjFHu.png"></a></p>

          <p>Maybe some background job that pushes the model files to S3 failed. Maybe
          some new commit (without any relevant new content) would trigger all processes
          again and make the model available.</p>

          '
        raw: 'I guess that the model files that used for the inference API are automatically
          put to AWS S3 upon new commits. The commit (5 days ag) itself appears to
          be alright, since the model files are accessible through the website on
          the "files and versions" page of the model card. But even loading the model
          directly or via pipeline fails:


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62d7fec585364bf2ed02cb02/Z44wMHBH7_rgbjM6i-izf.png)


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62d7fec585364bf2ed02cb02/9hM5G3Dygtj4lRc5CjFHu.png)


          Maybe some background job that pushes the model files to S3 failed. Maybe
          some new commit (without any relevant new content) would trigger all processes
          again and make the model available.'
        updatedAt: '2023-03-22T13:25:43.285Z'
      numEdits: 0
      reactions: []
    id: 641b01d7fc01c26fcaec8a4e
    type: comment
  author: kai-fidelity
  content: 'I guess that the model files that used for the inference API are automatically
    put to AWS S3 upon new commits. The commit (5 days ag) itself appears to be alright,
    since the model files are accessible through the website on the "files and versions"
    page of the model card. But even loading the model directly or via pipeline fails:


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62d7fec585364bf2ed02cb02/Z44wMHBH7_rgbjM6i-izf.png)


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62d7fec585364bf2ed02cb02/9hM5G3Dygtj4lRc5CjFHu.png)


    Maybe some background job that pushes the model files to S3 failed. Maybe some
    new commit (without any relevant new content) would trigger all processes again
    and make the model available.'
  created_at: 2023-03-22 12:25:43+00:00
  edited: false
  hidden: false
  id: 641b01d7fc01c26fcaec8a4e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d31a5898c0bd5377a64c7231c1204c24.svg
      fullname: Kai Matzutt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kai-fidelity
      type: user
    createdAt: '2023-03-27T15:30:17.000Z'
    data:
      edited: false
      editors:
      - kai-fidelity
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d31a5898c0bd5377a64c7231c1204c24.svg
          fullname: Kai Matzutt
          isHf: false
          isPro: false
          name: kai-fidelity
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;joeddav&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/joeddav\">@<span class=\"\
          underline\">joeddav</span></a></span>\n\n\t</span></span> : I do not know\
          \ what you (or huggingFace) did, but the model works again. Thanks!</p>\n"
        raw: '@joeddav : I do not know what you (or huggingFace) did, but the model
          works again. Thanks!'
        updatedAt: '2023-03-27T15:30:17.761Z'
      numEdits: 0
      reactions: []
    id: 6421b6895acad90e6b6eda7a
    type: comment
  author: kai-fidelity
  content: '@joeddav : I do not know what you (or huggingFace) did, but the model
    works again. Thanks!'
  created_at: 2023-03-27 14:30:17+00:00
  edited: false
  hidden: false
  id: 6421b6895acad90e6b6eda7a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: joeddav/xlm-roberta-large-xnli
repo_type: model
status: open
target_branch: null
title: Hosted Inference API Model tokenizer.json file appears to be unavailable
