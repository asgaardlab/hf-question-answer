!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Vreins
conflicting_files: null
created_at: 2023-03-23 14:56:28+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ec490b196334358866cc85104a2dacc1.svg
      fullname: Adah Agaba Augustine
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vreins
      type: user
    createdAt: '2023-03-23T15:56:28.000Z'
    data:
      edited: false
      editors:
      - Vreins
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ec490b196334358866cc85104a2dacc1.svg
          fullname: Adah Agaba Augustine
          isHf: false
          isPro: false
          name: Vreins
          type: user
        html: '<p>In trying to do this:</p>

          <h1 id="pose-sequence-as-a-nli-premise-and-label-as-a-hypothesis">pose sequence
          as a NLI premise and label as a hypothesis</h1>

          <p>from transformers import AutoModelForSequenceClassification, AutoTokenizer<br>nli_model
          = AutoModelForSequenceClassification.from_pretrained("joeddav/xlm-roberta-large-xnli")<br>tokenizer
          = AutoTokenizer.from_pretrained("joeddav/xlm-Roberta-large-xnli")</p>

          <p>I got this error:<br>404 Client Error: Not Found for url: <a href="https://huggingface.co/xlm-roberta-large-xnli/resolve/main/config.json">https://huggingface.co/xlm-roberta-large-xnli/resolve/main/config.json</a><br>HTTPError                                 Traceback
          (most recent call last)<br>/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py
          in get_config_dict(cls, pretrained_model_name_or_path, **kwargs)<br>    465                 use_auth_token=use_auth_token,<br>--&gt;
          466                 user_agent=user_agent,<br>    467             )</p>

          <p>/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py in
          cached_path(url_or_filename, cache_dir, force_download, proxies, resume_download,
          user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)<br>   1172             use_auth_token=use_auth_token,<br>-&gt;
          1173             local_files_only=local_files_only,<br>   1174         )</p>

          <p>/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py in
          get_from_cache(url, cache_dir, force_download, proxies, etag_timeout, resume_download,
          user_agent, use_auth_token, local_files_only)<br>   1335             r =
          requests.head(url, headers=headers, allow_redirects=False, proxies=proxies,
          timeout=etag_timeout)<br>-&gt; 1336             r.raise_for_status()<br>   1337             etag
          = r.headers.get("X-Linked-Etag") or r.headers.get("ETag")</p>

          <p>/opt/conda/lib/python3.7/site-packages/requests/models.py in raise_for_status(self)<br>    942         if
          http_error_msg:<br>--&gt; 943             raise HTTPError(http_error_msg,
          response=self)<br>    944 </p>

          <p>HTTPError: 404 Client Error: Not Found for url: <a href="https://huggingface.co/xlm-roberta-large-xnli/resolve/main/config.json">https://huggingface.co/xlm-roberta-large-xnli/resolve/main/config.json</a></p>

          <p>During handling of the above exception, another exception occurred:</p>

          <p>OSError                                   Traceback (most recent call
          last)<br>/tmp/ipykernel_18/1132170543.py in <br>      7 model_roBerta ="xlm-roberta-large-xnli"<br>      8
          # model_Bert = ''bert-base-multilingual-cased''<br>----&gt; 9 tokenizer
          = AutoTokenizer.from_pretrained(model_roBerta, use_auth_token="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")<br>     10
          model = TFAutoModel.from_pretrained(model_roBerta,use_auth_token="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")</p>

          <p>/opt/conda/lib/python3.7/site-packages/transformers/models/auto/tokenization_auto.py
          in from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs)<br>    388         kwargs["_from_auto"]
          = True<br>    389         if not isinstance(config, PretrainedConfig):<br>--&gt;
          390             config = AutoConfig.from_pretrained(pretrained_model_name_or_path,
          **kwargs)<br>    391<br>    392         use_fast = kwargs.pop("use_fast",
          True)</p>

          <p>/opt/conda/lib/python3.7/site-packages/transformers/models/auto/configuration_auto.py
          in from_pretrained(cls, pretrained_model_name_or_path, **kwargs)<br>    396         """<br>    397         kwargs["_from_auto"]
          = True<br>--&gt; 398         config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path,
          **kwargs)<br>    399         if "model_type" in config_dict:<br>    400             config_class
          = CONFIG_MAPPING[config_dict["model_type"]]</p>

          <p>/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py
          in get_config_dict(cls, pretrained_model_name_or_path, **kwargs)<br>    476                 f"-
          or ''{pretrained_model_name_or_path}'' is the correct path to a directory
          containing a {CONFIG_NAME} file\n\n"<br>    477             )<br>--&gt;
          478             raise EnvironmentError(msg)<br>    479<br>    480         except
          json.JSONDecodeError:</p>

          <p>OSError: Can''t load config for ''xlm-roberta-large-xnli''. Make sure
          that:</p>

          <ul>

          <li><p>''xlm-roberta-large-xnli'' is a correct model identifier listed on
          ''<a href="https://huggingface.co/models''">https://huggingface.co/models''</a></p>

          </li>

          <li><p>or ''xlm-roberta-large-xnli'' is the correct path to a directory
          containing a config.json file</p>

          </li>

          </ul>

          '
        raw: "In trying to do this:\r\n# pose sequence as a NLI premise and label\
          \ as a hypothesis\r\nfrom transformers import AutoModelForSequenceClassification,\
          \ AutoTokenizer\r\nnli_model = AutoModelForSequenceClassification.from_pretrained(\"\
          joeddav/xlm-roberta-large-xnli\")\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
          joeddav/xlm-Roberta-large-xnli\")\r\n\r\nI got this error:\r\n404 Client\
          \ Error: Not Found for url: https://huggingface.co/xlm-roberta-large-xnli/resolve/main/config.json\r\
          \nHTTPError                                 Traceback (most recent call\
          \ last)\r\n/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py\
          \ in get_config_dict(cls, pretrained_model_name_or_path, **kwargs)\r\n \
          \   465                 use_auth_token=use_auth_token,\r\n--> 466      \
          \           user_agent=user_agent,\r\n    467             )\r\n\r\n/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py\
          \ in cached_path(url_or_filename, cache_dir, force_download, proxies, resume_download,\
          \ user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\r\
          \n   1172             use_auth_token=use_auth_token,\r\n-> 1173        \
          \     local_files_only=local_files_only,\r\n   1174         )\r\n\r\n/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py\
          \ in get_from_cache(url, cache_dir, force_download, proxies, etag_timeout,\
          \ resume_download, user_agent, use_auth_token, local_files_only)\r\n   1335\
          \             r = requests.head(url, headers=headers, allow_redirects=False,\
          \ proxies=proxies, timeout=etag_timeout)\r\n-> 1336             r.raise_for_status()\r\
          \n   1337             etag = r.headers.get(\"X-Linked-Etag\") or r.headers.get(\"\
          ETag\")\r\n\r\n/opt/conda/lib/python3.7/site-packages/requests/models.py\
          \ in raise_for_status(self)\r\n    942         if http_error_msg:\r\n-->\
          \ 943             raise HTTPError(http_error_msg, response=self)\r\n   \
          \ 944 \r\n\r\nHTTPError: 404 Client Error: Not Found for url: https://huggingface.co/xlm-roberta-large-xnli/resolve/main/config.json\r\
          \n\r\nDuring handling of the above exception, another exception occurred:\r\
          \n\r\nOSError                                   Traceback (most recent call\
          \ last)\r\n/tmp/ipykernel_18/1132170543.py in <module>\r\n      7 model_roBerta\
          \ =\"xlm-roberta-large-xnli\"\r\n      8 # model_Bert = 'bert-base-multilingual-cased'\r\
          \n----> 9 tokenizer = AutoTokenizer.from_pretrained(model_roBerta, use_auth_token=\"\
          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\")\r\n     10 model = TFAutoModel.from_pretrained(model_roBerta,use_auth_token=\"\
          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\")\r\n\r\n/opt/conda/lib/python3.7/site-packages/transformers/models/auto/tokenization_auto.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs)\r\
          \n    388         kwargs[\"_from_auto\"] = True\r\n    389         if not\
          \ isinstance(config, PretrainedConfig):\r\n--> 390             config =\
          \ AutoConfig.from_pretrained(pretrained_model_name_or_path, **kwargs)\r\n\
          \    391 \r\n    392         use_fast = kwargs.pop(\"use_fast\", True)\r\
          \n\r\n/opt/conda/lib/python3.7/site-packages/transformers/models/auto/configuration_auto.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\r\n \
          \   396         \"\"\"\r\n    397         kwargs[\"_from_auto\"] = True\r\
          \n--> 398         config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path,\
          \ **kwargs)\r\n    399         if \"model_type\" in config_dict:\r\n   \
          \ 400             config_class = CONFIG_MAPPING[config_dict[\"model_type\"\
          ]]\r\n\r\n/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py\
          \ in get_config_dict(cls, pretrained_model_name_or_path, **kwargs)\r\n \
          \   476                 f\"- or '{pretrained_model_name_or_path}' is the\
          \ correct path to a directory containing a {CONFIG_NAME} file\\n\\n\"\r\n\
          \    477             )\r\n--> 478             raise EnvironmentError(msg)\r\
          \n    479 \r\n    480         except json.JSONDecodeError:\r\n\r\nOSError:\
          \ Can't load config for 'xlm-roberta-large-xnli'. Make sure that:\r\n\r\n\
          - 'xlm-roberta-large-xnli' is a correct model identifier listed on 'https://huggingface.co/models'\r\
          \n\r\n- or 'xlm-roberta-large-xnli' is the correct path to a directory containing\
          \ a config.json file"
        updatedAt: '2023-03-23T15:56:28.615Z'
      numEdits: 0
      reactions: []
    id: 641c76acc3983aa9491203a2
    type: comment
  author: Vreins
  content: "In trying to do this:\r\n# pose sequence as a NLI premise and label as\
    \ a hypothesis\r\nfrom transformers import AutoModelForSequenceClassification,\
    \ AutoTokenizer\r\nnli_model = AutoModelForSequenceClassification.from_pretrained(\"\
    joeddav/xlm-roberta-large-xnli\")\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
    joeddav/xlm-Roberta-large-xnli\")\r\n\r\nI got this error:\r\n404 Client Error:\
    \ Not Found for url: https://huggingface.co/xlm-roberta-large-xnli/resolve/main/config.json\r\
    \nHTTPError                                 Traceback (most recent call last)\r\
    \n/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py in\
    \ get_config_dict(cls, pretrained_model_name_or_path, **kwargs)\r\n    465   \
    \              use_auth_token=use_auth_token,\r\n--> 466                 user_agent=user_agent,\r\
    \n    467             )\r\n\r\n/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py\
    \ in cached_path(url_or_filename, cache_dir, force_download, proxies, resume_download,\
    \ user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\r\
    \n   1172             use_auth_token=use_auth_token,\r\n-> 1173             local_files_only=local_files_only,\r\
    \n   1174         )\r\n\r\n/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py\
    \ in get_from_cache(url, cache_dir, force_download, proxies, etag_timeout, resume_download,\
    \ user_agent, use_auth_token, local_files_only)\r\n   1335             r = requests.head(url,\
    \ headers=headers, allow_redirects=False, proxies=proxies, timeout=etag_timeout)\r\
    \n-> 1336             r.raise_for_status()\r\n   1337             etag = r.headers.get(\"\
    X-Linked-Etag\") or r.headers.get(\"ETag\")\r\n\r\n/opt/conda/lib/python3.7/site-packages/requests/models.py\
    \ in raise_for_status(self)\r\n    942         if http_error_msg:\r\n--> 943 \
    \            raise HTTPError(http_error_msg, response=self)\r\n    944 \r\n\r\n\
    HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/xlm-roberta-large-xnli/resolve/main/config.json\r\
    \n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\
    \nOSError                                   Traceback (most recent call last)\r\
    \n/tmp/ipykernel_18/1132170543.py in <module>\r\n      7 model_roBerta =\"xlm-roberta-large-xnli\"\
    \r\n      8 # model_Bert = 'bert-base-multilingual-cased'\r\n----> 9 tokenizer\
    \ = AutoTokenizer.from_pretrained(model_roBerta, use_auth_token=\"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\"\
    )\r\n     10 model = TFAutoModel.from_pretrained(model_roBerta,use_auth_token=\"\
    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\")\r\n\r\n/opt/conda/lib/python3.7/site-packages/transformers/models/auto/tokenization_auto.py\
    \ in from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs)\r\n\
    \    388         kwargs[\"_from_auto\"] = True\r\n    389         if not isinstance(config,\
    \ PretrainedConfig):\r\n--> 390             config = AutoConfig.from_pretrained(pretrained_model_name_or_path,\
    \ **kwargs)\r\n    391 \r\n    392         use_fast = kwargs.pop(\"use_fast\"\
    , True)\r\n\r\n/opt/conda/lib/python3.7/site-packages/transformers/models/auto/configuration_auto.py\
    \ in from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\r\n    396\
    \         \"\"\"\r\n    397         kwargs[\"_from_auto\"] = True\r\n--> 398 \
    \        config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path,\
    \ **kwargs)\r\n    399         if \"model_type\" in config_dict:\r\n    400  \
    \           config_class = CONFIG_MAPPING[config_dict[\"model_type\"]]\r\n\r\n\
    /opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py in\
    \ get_config_dict(cls, pretrained_model_name_or_path, **kwargs)\r\n    476   \
    \              f\"- or '{pretrained_model_name_or_path}' is the correct path to\
    \ a directory containing a {CONFIG_NAME} file\\n\\n\"\r\n    477             )\r\
    \n--> 478             raise EnvironmentError(msg)\r\n    479 \r\n    480     \
    \    except json.JSONDecodeError:\r\n\r\nOSError: Can't load config for 'xlm-roberta-large-xnli'.\
    \ Make sure that:\r\n\r\n- 'xlm-roberta-large-xnli' is a correct model identifier\
    \ listed on 'https://huggingface.co/models'\r\n\r\n- or 'xlm-roberta-large-xnli'\
    \ is the correct path to a directory containing a config.json file"
  created_at: 2023-03-23 14:56:28+00:00
  edited: false
  hidden: false
  id: 641c76acc3983aa9491203a2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: joeddav/xlm-roberta-large-xnli
repo_type: model
status: open
target_branch: null
title: '404 Client Error: Not Found for url: https://huggingface.co/xlm-roberta-large-xnli/resolve/main/config.json'
