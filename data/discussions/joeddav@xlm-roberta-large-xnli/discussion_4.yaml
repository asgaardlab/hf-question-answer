!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ShieldHero
conflicting_files: null
created_at: 2023-02-21 06:16:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1642431328069-noauth.jpeg?w=200&h=200&f=face
      fullname: A Boodhayana S Vishwamithra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShieldHero
      type: user
    createdAt: '2023-02-21T06:16:08.000Z'
    data:
      edited: false
      editors:
      - ShieldHero
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1642431328069-noauth.jpeg?w=200&h=200&f=face
          fullname: A Boodhayana S Vishwamithra
          isHf: false
          isPro: false
          name: ShieldHero
          type: user
        html: "<p>Tokenizer requires both vocab and tokeniser.json files. But theses\
          \ files are not present in the repository. I am not able to initialise the\
          \ tokeniser without these files. Can someone please lend me their aid in\
          \ solving this issue?</p>\n<code>\n File \"run.py\", line 70, in \n    t\
          \ = AutoTokenizer.from_pretrained(model_name)\n  File \"/miniconda/lib/python3.7/site-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 532, in from_pretrained\n    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\n  File \"/miniconda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1780, in from_pretrained\n    **kwargs,\n  File \"/miniconda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1908, in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
          \  File \"/miniconda/lib/python3.7/site-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py\"\
          , line 150, in __init__\n    **kwargs,\n  File \"/miniconda/lib/python3.7/site-packages/transformers/tokenization_utils_fast.py\"\
          , line 118, in __init__\n    \"Couldn't instantiate the backend tokenizer\
          \ from one of: \\n\"\nValueError: Couldn't instantiate the backend tokenizer\
          \ from one of: \n(1) a `tokenizers` library serialization file, \n(2) a\
          \ slow tokenizer instance to convert or \n(3) an equivalent slow tokenizer\
          \ class to instantiate and convert. \nYou need to have sentencepiece installed\
          \ to convert a slow tokenizer to a fast one.\n\n</code>\n![Screenshot 2023-02-21\
          \ at 11.44.08 AM.png](https://cdn-uploads.huggingface.co/production/uploads/1676960156163-61e58371192e9bd83bc96e92.png)\n"
        raw: "Tokenizer requires both vocab and tokeniser.json files. But theses files\
          \ are not present in the repository. I am not able to initialise the tokeniser\
          \ without these files. Can someone please lend me their aid in solving this\
          \ issue?\r\n\r\n<code>\r\n File \"run.py\", line 70, in <module>\r\n   \
          \ t = AutoTokenizer.from_pretrained(model_name)\r\n  File \"/miniconda/lib/python3.7/site-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 532, in from_pretrained\r\n    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\r\n  File \"/miniconda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1780, in from_pretrained\r\n    **kwargs,\r\n  File \"/miniconda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1908, in _from_pretrained\r\n    tokenizer = cls(*init_inputs, **init_kwargs)\r\
          \n  File \"/miniconda/lib/python3.7/site-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py\"\
          , line 150, in __init__\r\n    **kwargs,\r\n  File \"/miniconda/lib/python3.7/site-packages/transformers/tokenization_utils_fast.py\"\
          , line 118, in __init__\r\n    \"Couldn't instantiate the backend tokenizer\
          \ from one of: \\n\"\r\nValueError: Couldn't instantiate the backend tokenizer\
          \ from one of: \r\n(1) a `tokenizers` library serialization file, \r\n(2)\
          \ a slow tokenizer instance to convert or \r\n(3) an equivalent slow tokenizer\
          \ class to instantiate and convert. \r\nYou need to have sentencepiece installed\
          \ to convert a slow tokenizer to a fast one.\r\n\r\n</code>\r\n![Screenshot\
          \ 2023-02-21 at 11.44.08 AM.png](https://cdn-uploads.huggingface.co/production/uploads/1676960156163-61e58371192e9bd83bc96e92.png)\r\
          \n"
        updatedAt: '2023-02-21T06:16:08.379Z'
      numEdits: 0
      reactions: []
    id: 63f461a8a096536aeab68f84
    type: comment
  author: ShieldHero
  content: "Tokenizer requires both vocab and tokeniser.json files. But theses files\
    \ are not present in the repository. I am not able to initialise the tokeniser\
    \ without these files. Can someone please lend me their aid in solving this issue?\r\
    \n\r\n<code>\r\n File \"run.py\", line 70, in <module>\r\n    t = AutoTokenizer.from_pretrained(model_name)\r\
    \n  File \"/miniconda/lib/python3.7/site-packages/transformers/models/auto/tokenization_auto.py\"\
    , line 532, in from_pretrained\r\n    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path,\
    \ *inputs, **kwargs)\r\n  File \"/miniconda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\"\
    , line 1780, in from_pretrained\r\n    **kwargs,\r\n  File \"/miniconda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\"\
    , line 1908, in _from_pretrained\r\n    tokenizer = cls(*init_inputs, **init_kwargs)\r\
    \n  File \"/miniconda/lib/python3.7/site-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py\"\
    , line 150, in __init__\r\n    **kwargs,\r\n  File \"/miniconda/lib/python3.7/site-packages/transformers/tokenization_utils_fast.py\"\
    , line 118, in __init__\r\n    \"Couldn't instantiate the backend tokenizer from\
    \ one of: \\n\"\r\nValueError: Couldn't instantiate the backend tokenizer from\
    \ one of: \r\n(1) a `tokenizers` library serialization file, \r\n(2) a slow tokenizer\
    \ instance to convert or \r\n(3) an equivalent slow tokenizer class to instantiate\
    \ and convert. \r\nYou need to have sentencepiece installed to convert a slow\
    \ tokenizer to a fast one.\r\n\r\n</code>\r\n![Screenshot 2023-02-21 at 11.44.08\
    \ AM.png](https://cdn-uploads.huggingface.co/production/uploads/1676960156163-61e58371192e9bd83bc96e92.png)\r\
    \n"
  created_at: 2023-02-21 06:16:08+00:00
  edited: false
  hidden: false
  id: 63f461a8a096536aeab68f84
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1642431328069-noauth.jpeg?w=200&h=200&f=face
      fullname: A Boodhayana S Vishwamithra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShieldHero
      type: user
    createdAt: '2023-02-21T06:17:04.000Z'
    data:
      from: tokenised.json and vocal files not found
      to: tokeniser.json and vocal files not found
    id: 63f461e0d5f41eb978c41314
    type: title-change
  author: ShieldHero
  created_at: 2023-02-21 06:17:04+00:00
  id: 63f461e0d5f41eb978c41314
  new_title: tokeniser.json and vocal files not found
  old_title: tokenised.json and vocal files not found
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/da3f57d70db9a599876f239e9d04a917.svg
      fullname: Rishi Ghosh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: seigishi
      type: user
    createdAt: '2023-03-14T13:16:11.000Z'
    data:
      edited: false
      editors:
      - seigishi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/da3f57d70db9a599876f239e9d04a917.svg
          fullname: Rishi Ghosh
          isHf: false
          isPro: false
          name: seigishi
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;joeddav&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/joeddav\">@<span class=\"\
          underline\">joeddav</span></a></span>\n\n\t</span></span> any solution to\
          \ this</p>\n"
        raw: '@joeddav any solution to this'
        updatedAt: '2023-03-14T13:16:11.703Z'
      numEdits: 0
      reactions: []
    id: 6410739b7f6bd7278da71634
    type: comment
  author: seigishi
  content: '@joeddav any solution to this'
  created_at: 2023-03-14 12:16:11+00:00
  edited: false
  hidden: false
  id: 6410739b7f6bd7278da71634
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653638890151-5e67bdfe100906368940747a.jpeg?w=200&h=200&f=face
      fullname: Joe Davison
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: joeddav
      type: user
    createdAt: '2023-03-17T18:17:19.000Z'
    data:
      edited: false
      editors:
      - joeddav
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653638890151-5e67bdfe100906368940747a.jpeg?w=200&h=200&f=face
          fullname: Joe Davison
          isHf: false
          isPro: false
          name: joeddav
          type: user
        html: '<p>Fixed via <a href="/joeddav/xlm-roberta-large-xnli/commit/a2a45f84b9f7216de3462a96dc0fa0d65d441f9f">a2a45f84b9f7216de3462a96dc0fa0d65d441f9f</a></p>

          '
        raw: Fixed via a2a45f84b9f7216de3462a96dc0fa0d65d441f9f
        updatedAt: '2023-03-17T18:17:19.594Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6414aeaf1a789360a9730308
    id: 6414aeaf1a789360a9730307
    type: comment
  author: joeddav
  content: Fixed via a2a45f84b9f7216de3462a96dc0fa0d65d441f9f
  created_at: 2023-03-17 17:17:19+00:00
  edited: false
  hidden: false
  id: 6414aeaf1a789360a9730307
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653638890151-5e67bdfe100906368940747a.jpeg?w=200&h=200&f=face
      fullname: Joe Davison
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: joeddav
      type: user
    createdAt: '2023-03-17T18:17:19.000Z'
    data:
      status: closed
    id: 6414aeaf1a789360a9730308
    type: status-change
  author: joeddav
  created_at: 2023-03-17 17:17:19+00:00
  id: 6414aeaf1a789360a9730308
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1642431328069-noauth.jpeg?w=200&h=200&f=face
      fullname: A Boodhayana S Vishwamithra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShieldHero
      type: user
    createdAt: '2023-03-19T16:46:20.000Z'
    data:
      edited: false
      editors:
      - ShieldHero
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1642431328069-noauth.jpeg?w=200&h=200&f=face
          fullname: A Boodhayana S Vishwamithra
          isHf: false
          isPro: false
          name: ShieldHero
          type: user
        html: "<p>Thank you <span data-props=\"{&quot;user&quot;:&quot;joeddav&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/joeddav\"\
          >@<span class=\"underline\">joeddav</span></a></span>\n\n\t</span></span></p>\n"
        raw: Thank you @joeddav
        updatedAt: '2023-03-19T16:46:20.368Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - joeddav
    id: 64173c5c699419b1d371e017
    type: comment
  author: ShieldHero
  content: Thank you @joeddav
  created_at: 2023-03-19 15:46:20+00:00
  edited: false
  hidden: false
  id: 64173c5c699419b1d371e017
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1642431328069-noauth.jpeg?w=200&h=200&f=face
      fullname: A Boodhayana S Vishwamithra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShieldHero
      type: user
    createdAt: '2023-03-19T16:47:19.000Z'
    data:
      from: tokeniser.json and vocal files not found
      to: tokeniser.json and vocab files not found
    id: 64173c97f4d1968f73ea9e99
    type: title-change
  author: ShieldHero
  created_at: 2023-03-19 15:47:19+00:00
  id: 64173c97f4d1968f73ea9e99
  new_title: tokeniser.json and vocab files not found
  old_title: tokeniser.json and vocal files not found
  type: title-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: joeddav/xlm-roberta-large-xnli
repo_type: model
status: closed
target_branch: null
title: tokeniser.json and vocab files not found
