!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ialhabbal
conflicting_files: null
created_at: 2023-10-17 10:32:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/693c652b9ee1df32c9dfb894f68e9207.svg
      fullname: Ibrahim Mohamed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ialhabbal
      type: user
    createdAt: '2023-10-17T11:32:59.000Z'
    data:
      edited: false
      editors:
      - ialhabbal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9622386693954468
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/693c652b9ee1df32c9dfb894f68e9207.svg
          fullname: Ibrahim Mohamed
          isHf: false
          isPro: false
          name: ialhabbal
          type: user
        html: '<p>I tried all model loaders with this model but it failed to load.
          Any ideas how to get it to load? Thanks.</p>

          '
        raw: I tried all model loaders with this model but it failed to load. Any
          ideas how to get it to load? Thanks.
        updatedAt: '2023-10-17T11:32:59.460Z'
      numEdits: 0
      reactions: []
    id: 652e70ebda91a2e19792813f
    type: comment
  author: ialhabbal
  content: I tried all model loaders with this model but it failed to load. Any ideas
    how to get it to load? Thanks.
  created_at: 2023-10-17 10:32:59+00:00
  edited: false
  hidden: false
  id: 652e70ebda91a2e19792813f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a5186befff3a95ba33f4900421ad23b4.svg
      fullname: Adam Filipkowski
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ramzeez88
      type: user
    createdAt: '2023-10-17T17:58:48.000Z'
    data:
      edited: false
      editors:
      - ramzeez88
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5739822387695312
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a5186befff3a95ba33f4900421ad23b4.svg
          fullname: Adam Filipkowski
          isHf: false
          isPro: false
          name: ramzeez88
          type: user
        html: '<p>i run it no problem using the blokes quantized version in gguf file
          format  using llama.cpp loader. I use Q6_k quantized file. i get about 10
          tokens/s </p>

          '
        raw: "i run it no problem using the blokes quantized version in gguf file\
          \ format  using llama.cpp loader. I use Q6_k quantized file. i get about\
          \ 10 tokens/s \n"
        updatedAt: '2023-10-17T17:58:48.488Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - rraulison
        - ialhabbal
    id: 652ecb5867acb68b9f9ddfd9
    type: comment
  author: ramzeez88
  content: "i run it no problem using the blokes quantized version in gguf file format\
    \  using llama.cpp loader. I use Q6_k quantized file. i get about 10 tokens/s\
    \ \n"
  created_at: 2023-10-17 16:58:48+00:00
  edited: false
  hidden: false
  id: 652ecb5867acb68b9f9ddfd9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/432279a6b42c15cec5878ab2a27aa59e.svg
      fullname: Sanjay Chadha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: schadha
      type: user
    createdAt: '2023-10-17T21:57:15.000Z'
    data:
      edited: false
      editors:
      - schadha
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5822346806526184
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/432279a6b42c15cec5878ab2a27aa59e.svg
          fullname: Sanjay Chadha
          isHf: false
          isPro: false
          name: schadha
          type: user
        html: '<p>Try on this Colab: <a rel="nofollow" href="https://colab.research.google.com/drive/18XH8DTbgI4Zrsg-Xat-El3FvL8ZIDXMD">https://colab.research.google.com/drive/18XH8DTbgI4Zrsg-Xat-El3FvL8ZIDXMD</a></p>

          <p>Change<br>llm_chain = LLMChain(prompt=prompt,<br>                     llm=HuggingFaceHub(repo_id="google/flan-t5-xl",<br>                                        model_kwargs={"temperature":0,<br>                                                      "max_length":64}))</p>

          <p>question = " what is capital of France?"<br>print(llm_chain.run(question))</p>

          <p>to</p>

          <p>llm_chain = LLMChain(prompt=prompt,<br>                     llm=HuggingFaceHub(repo_id="HuggingFaceH4/zephyr-7b-alpha",<br>                                        model_kwargs={"temperature":0.7,   #
          NOTE<br>                                                      "max_length":64}))</p>

          <p>question = " what is capital of France?"<br>print(llm_chain.run(question))</p>

          <p>Answers were OK not compared to this online chat <a href="https://huggingface.co/spaces/HuggingFaceH4/zephyr-chat">https://huggingface.co/spaces/HuggingFaceH4/zephyr-chat</a></p>

          '
        raw: "Try on this Colab: https://colab.research.google.com/drive/18XH8DTbgI4Zrsg-Xat-El3FvL8ZIDXMD\n\
          \nChange\nllm_chain = LLMChain(prompt=prompt, \n                     llm=HuggingFaceHub(repo_id=\"\
          google/flan-t5-xl\", \n                                        model_kwargs={\"\
          temperature\":0, \n                                                    \
          \  \"max_length\":64}))\n\nquestion = \" what is capital of France?\"\n\
          print(llm_chain.run(question))\n\nto\n\nllm_chain = LLMChain(prompt=prompt,\
          \ \n                     llm=HuggingFaceHub(repo_id=\"HuggingFaceH4/zephyr-7b-alpha\"\
          , \n                                        model_kwargs={\"temperature\"\
          :0.7,   # NOTE \n                                                      \"\
          max_length\":64}))\n\nquestion = \" what is capital of France?\"\nprint(llm_chain.run(question))\n\
          \nAnswers were OK not compared to this online chat https://huggingface.co/spaces/HuggingFaceH4/zephyr-chat"
        updatedAt: '2023-10-17T21:57:15.465Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - PrimeD
        - ialhabbal
    id: 652f033ba0f516a99de98505
    type: comment
  author: schadha
  content: "Try on this Colab: https://colab.research.google.com/drive/18XH8DTbgI4Zrsg-Xat-El3FvL8ZIDXMD\n\
    \nChange\nllm_chain = LLMChain(prompt=prompt, \n                     llm=HuggingFaceHub(repo_id=\"\
    google/flan-t5-xl\", \n                                        model_kwargs={\"\
    temperature\":0, \n                                                      \"max_length\"\
    :64}))\n\nquestion = \" what is capital of France?\"\nprint(llm_chain.run(question))\n\
    \nto\n\nllm_chain = LLMChain(prompt=prompt, \n                     llm=HuggingFaceHub(repo_id=\"\
    HuggingFaceH4/zephyr-7b-alpha\", \n                                        model_kwargs={\"\
    temperature\":0.7,   # NOTE \n                                               \
    \       \"max_length\":64}))\n\nquestion = \" what is capital of France?\"\nprint(llm_chain.run(question))\n\
    \nAnswers were OK not compared to this online chat https://huggingface.co/spaces/HuggingFaceH4/zephyr-chat"
  created_at: 2023-10-17 20:57:15+00:00
  edited: false
  hidden: false
  id: 652f033ba0f516a99de98505
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 17
repo_id: HuggingFaceH4/zephyr-7b-alpha
repo_type: model
status: open
target_branch: null
title: Not working in Text Generation Web UI
