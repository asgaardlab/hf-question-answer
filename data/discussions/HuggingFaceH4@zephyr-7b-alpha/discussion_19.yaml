!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jamesbraza
conflicting_files: null
created_at: 2023-10-17 22:52:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b83ceb49bde5d94813ce2e/PYf6nXBVGQPIgTk_NzudC.png?w=200&h=200&f=face
      fullname: James Braza
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jamesbraza
      type: user
    createdAt: '2023-10-17T23:52:22.000Z'
    data:
      edited: false
      editors:
      - jamesbraza
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7621540427207947
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b83ceb49bde5d94813ce2e/PYf6nXBVGQPIgTk_NzudC.png?w=200&h=200&f=face
          fullname: James Braza
          isHf: false
          isPro: false
          name: jamesbraza
          type: user
        html: "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span>\
          \ huggingface_hub <span class=\"hljs-keyword\">import</span> InferenceClient\
          \  <span class=\"hljs-comment\"># huggingface-hub[inference]==0.17.3</span>\n\
          \nclient = InferenceClient(model=<span class=\"hljs-string\">\"HuggingFaceH4/zephyr-7b-alpha\"\
          </span>)\nhi = client.text_generation(\n    <span class=\"hljs-string\"\
          >\"Some choices are given below. It is provided in a numbered list (1 to\
          \ 2), where\"</span>\n    <span class=\"hljs-string\">\" each item in the\
          \ list corresponds to a summary.\\n---------------------\\n(1)\"</span>\n\
          \    <span class=\"hljs-string\">\" Provides information on cell lines like\
          \ cell aliases, planes, and trains\\n\\n(2)\"</span>\n    <span class=\"\
          hljs-string\">\" Provides information on abc 123\\n---------------------\\\
          nUsing only the choices above\"</span>\n    <span class=\"hljs-string\"\
          >\" and not prior knowledge, return the choice that is most relevant to\
          \ the question:\"</span>\n    <span class=\"hljs-string\">\" 'What are the\
          \ aliases for MLE12?'\\n\\n\\nThe output should be ONLY JSON formatted\"\
          </span>\n    <span class=\"hljs-string\">\" as a JSON instance.\\n\\nHere\
          \ is an example:\\n[\\n    {{\\n        choice: 1,\\n      \"</span>\n \
          \   <span class=\"hljs-string\">'  reason: \"&lt;insert reason for choice&gt;\"\
          \\n    }},\\n    ...\\n]\\n'</span>\n)\n</code></pre>\n<p>Here is a prompt\
          \ that leads to the model generating 20 <code>\\n</code> newlines. What\
          \ is the issue here, why would it do that?</p>\n"
        raw: "```python\r\nfrom huggingface_hub import InferenceClient  # huggingface-hub[inference]==0.17.3\r\
          \n\r\nclient = InferenceClient(model=\"HuggingFaceH4/zephyr-7b-alpha\")\r\
          \nhi = client.text_generation(\r\n    \"Some choices are given below. It\
          \ is provided in a numbered list (1 to 2), where\"\r\n    \" each item in\
          \ the list corresponds to a summary.\\n---------------------\\n(1)\"\r\n\
          \    \" Provides information on cell lines like cell aliases, planes, and\
          \ trains\\n\\n(2)\"\r\n    \" Provides information on abc 123\\n---------------------\\\
          nUsing only the choices above\"\r\n    \" and not prior knowledge, return\
          \ the choice that is most relevant to the question:\"\r\n    \" 'What are\
          \ the aliases for MLE12?'\\n\\n\\nThe output should be ONLY JSON formatted\"\
          \r\n    \" as a JSON instance.\\n\\nHere is an example:\\n[\\n    {{\\n\
          \        choice: 1,\\n      \"\r\n    '  reason: \"<insert reason for choice>\"\
          \\n    }},\\n    ...\\n]\\n'\r\n)\r\n```\r\n\r\nHere is a prompt that leads\
          \ to the model generating 20 `\\n` newlines. What is the issue here, why\
          \ would it do that?"
        updatedAt: '2023-10-17T23:52:22.193Z'
      numEdits: 0
      reactions: []
    id: 652f1e36aeb9826ab9dc7c55
    type: comment
  author: jamesbraza
  content: "```python\r\nfrom huggingface_hub import InferenceClient  # huggingface-hub[inference]==0.17.3\r\
    \n\r\nclient = InferenceClient(model=\"HuggingFaceH4/zephyr-7b-alpha\")\r\nhi\
    \ = client.text_generation(\r\n    \"Some choices are given below. It is provided\
    \ in a numbered list (1 to 2), where\"\r\n    \" each item in the list corresponds\
    \ to a summary.\\n---------------------\\n(1)\"\r\n    \" Provides information\
    \ on cell lines like cell aliases, planes, and trains\\n\\n(2)\"\r\n    \" Provides\
    \ information on abc 123\\n---------------------\\nUsing only the choices above\"\
    \r\n    \" and not prior knowledge, return the choice that is most relevant to\
    \ the question:\"\r\n    \" 'What are the aliases for MLE12?'\\n\\n\\nThe output\
    \ should be ONLY JSON formatted\"\r\n    \" as a JSON instance.\\n\\nHere is an\
    \ example:\\n[\\n    {{\\n        choice: 1,\\n      \"\r\n    '  reason: \"<insert\
    \ reason for choice>\"\\n    }},\\n    ...\\n]\\n'\r\n)\r\n```\r\n\r\nHere is\
    \ a prompt that leads to the model generating 20 `\\n` newlines. What is the issue\
    \ here, why would it do that?"
  created_at: 2023-10-17 22:52:22+00:00
  edited: false
  hidden: false
  id: 652f1e36aeb9826ab9dc7c55
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1594651707950-noauth.jpeg?w=200&h=200&f=face
      fullname: Lewis Tunstall
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lewtun
      type: user
    createdAt: '2023-10-18T07:25:53.000Z'
    data:
      edited: false
      editors:
      - lewtun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8022570610046387
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1594651707950-noauth.jpeg?w=200&h=200&f=face
          fullname: Lewis Tunstall
          isHf: true
          isPro: false
          name: lewtun
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;jamesbraza&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/jamesbraza\"\
          >@<span class=\"underline\">jamesbraza</span></a></span>\n\n\t</span></span>\
          \ the model was trained with a chat template and you need to format your\
          \ inputs this way to ensure the model terminates generation at the right\
          \ place. See the README for an example on how to format the inputs :)</p>\n"
        raw: Hello @jamesbraza the model was trained with a chat template and you
          need to format your inputs this way to ensure the model terminates generation
          at the right place. See the README for an example on how to format the inputs
          :)
        updatedAt: '2023-10-18T07:25:53.385Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jamesbraza
    id: 652f88818de08dee63fd1f16
    type: comment
  author: lewtun
  content: Hello @jamesbraza the model was trained with a chat template and you need
    to format your inputs this way to ensure the model terminates generation at the
    right place. See the README for an example on how to format the inputs :)
  created_at: 2023-10-18 06:25:53+00:00
  edited: false
  hidden: false
  id: 652f88818de08dee63fd1f16
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b83ceb49bde5d94813ce2e/PYf6nXBVGQPIgTk_NzudC.png?w=200&h=200&f=face
      fullname: James Braza
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jamesbraza
      type: user
    createdAt: '2024-01-11T17:44:56.000Z'
    data:
      edited: false
      editors:
      - jamesbraza
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6233850121498108
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b83ceb49bde5d94813ce2e/PYf6nXBVGQPIgTk_NzudC.png?w=200&h=200&f=face
          fullname: James Braza
          isHf: false
          isPro: false
          name: jamesbraza
          type: user
        html: '<p>Ah gotchu, and thank you!</p>

          '
        raw: Ah gotchu, and thank you!
        updatedAt: '2024-01-11T17:44:56.859Z'
      numEdits: 0
      reactions: []
    id: 65a0291807184d32faf24735
    type: comment
  author: jamesbraza
  content: Ah gotchu, and thank you!
  created_at: 2024-01-11 17:44:56+00:00
  edited: false
  hidden: false
  id: 65a0291807184d32faf24735
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 19
repo_id: HuggingFaceH4/zephyr-7b-alpha
repo_type: model
status: open
target_branch: null
title: Model answering with all newlines?
