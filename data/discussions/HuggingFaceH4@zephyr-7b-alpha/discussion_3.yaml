!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SinanAkkoyun
conflicting_files: null
created_at: 2023-10-11 16:47:28+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63dcff68a8877129a1574f33/O-8C_Wy8nr_zo8TudBF1k.jpeg?w=200&h=200&f=face
      fullname: Sinan Akkoyun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SinanAkkoyun
      type: user
    createdAt: '2023-10-11T17:47:28.000Z'
    data:
      edited: false
      editors:
      - SinanAkkoyun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9405931234359741
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63dcff68a8877129a1574f33/O-8C_Wy8nr_zo8TudBF1k.jpeg?w=200&h=200&f=face
          fullname: Sinan Akkoyun
          isHf: false
          isPro: false
          name: SinanAkkoyun
          type: user
        html: '<p>Hello, I have been wondering what the right prompt format is?<br>The
          chatml variant you present in the model card seems to somewhat work but
          the system prompt seems to be completely disregarded. Also, if I read that
          correctly, your PROMPT_FORMAT in the zephyr-chat space is some sort of Llama
          prompt format?</p>

          <p>Thank you for the help</p>

          '
        raw: "Hello, I have been wondering what the right prompt format is?\r\nThe\
          \ chatml variant you present in the model card seems to somewhat work but\
          \ the system prompt seems to be completely disregarded. Also, if I read\
          \ that correctly, your PROMPT_FORMAT in the zephyr-chat space is some sort\
          \ of Llama prompt format?\r\n\r\nThank you for the help"
        updatedAt: '2023-10-11T17:47:28.912Z'
      numEdits: 0
      reactions: []
    id: 6526dfb0e228bd6794b04529
    type: comment
  author: SinanAkkoyun
  content: "Hello, I have been wondering what the right prompt format is?\r\nThe chatml\
    \ variant you present in the model card seems to somewhat work but the system\
    \ prompt seems to be completely disregarded. Also, if I read that correctly, your\
    \ PROMPT_FORMAT in the zephyr-chat space is some sort of Llama prompt format?\r\
    \n\r\nThank you for the help"
  created_at: 2023-10-11 16:47:28+00:00
  edited: false
  hidden: false
  id: 6526dfb0e228bd6794b04529
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/70931f5e9967e073138162fec4b5b86e.svg
      fullname: Le Khac Phuong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: phuonglk
      type: user
    createdAt: '2023-10-12T02:52:41.000Z'
    data:
      edited: true
      editors:
      - phuonglk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3547866940498352
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/70931f5e9967e073138162fec4b5b86e.svg
          fullname: Le Khac Phuong
          isHf: false
          isPro: false
          name: phuonglk
          type: user
        html: '<p>You can checkout it <a href="https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha/discussions/2/files">here</a>.
          See chat_template<br>You can use: tokenizer.apply_chat_template() to get
          exact prompt for chat.</p>

          '
        raw: 'You can checkout it [here](https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha/discussions/2/files).
          See chat_template

          You can use: tokenizer.apply_chat_template() to get exact prompt for chat.'
        updatedAt: '2023-10-14T14:40:42.662Z'
      numEdits: 1
      reactions: []
    id: 65275f795b3582bcb86fe2a3
    type: comment
  author: phuonglk
  content: 'You can checkout it [here](https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha/discussions/2/files).
    See chat_template

    You can use: tokenizer.apply_chat_template() to get exact prompt for chat.'
  created_at: 2023-10-12 01:52:41+00:00
  edited: true
  hidden: false
  id: 65275f795b3582bcb86fe2a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ab1fba948e86cce23e8ab573f12ff04.svg
      fullname: Nicky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NickyNicky
      type: user
    createdAt: '2023-10-14T23:04:43.000Z'
    data:
      edited: true
      editors:
      - NickyNicky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7625020146369934
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ab1fba948e86cce23e8ab573f12ff04.svg
          fullname: Nicky
          isHf: false
          isPro: false
          name: NickyNicky
          type: user
        html: '<p>format:</p>

          <pre><code class="language-Py"><span class="hljs-comment"># &lt;|system|&gt;</span>

          <span class="hljs-comment"># You are a friendly chatbot who always responds
          in the style of a pirate.&lt;/s&gt;</span>

          <span class="hljs-comment"># &lt;|user|&gt;</span>

          <span class="hljs-comment"># How many helicopters can a human eat in one
          sitting?&lt;/s&gt;</span>

          <span class="hljs-comment"># &lt;|assistant|&gt;</span>

          </code></pre>

          <p>I have some doubts if &lt;|system|&gt;, &lt;|user|&gt;,&lt;|assistant|&gt;
          are added tokens "&lt;|system|&gt;" or is it just pure text to be predicted?</p>

          '
        raw: 'format:


          ```Py

          # <|system|>

          # You are a friendly chatbot who always responds in the style of a pirate.</s>

          # <|user|>

          # How many helicopters can a human eat in one sitting?</s>

          # <|assistant|>

          ```


          I have some doubts if <|system|>, <|user|>,<|assistant|> are added tokens
          "<|system|>" or is it just pure text to be predicted?'
        updatedAt: '2023-10-14T23:06:01.475Z'
      numEdits: 3
      reactions: []
    id: 652b1e8b1ef9983c6d168f84
    type: comment
  author: NickyNicky
  content: 'format:


    ```Py

    # <|system|>

    # You are a friendly chatbot who always responds in the style of a pirate.</s>

    # <|user|>

    # How many helicopters can a human eat in one sitting?</s>

    # <|assistant|>

    ```


    I have some doubts if <|system|>, <|user|>,<|assistant|> are added tokens "<|system|>"
    or is it just pure text to be predicted?'
  created_at: 2023-10-14 22:04:43+00:00
  edited: true
  hidden: false
  id: 652b1e8b1ef9983c6d168f84
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: HuggingFaceH4/zephyr-7b-alpha
repo_type: model
status: open
target_branch: null
title: Prompt format?
