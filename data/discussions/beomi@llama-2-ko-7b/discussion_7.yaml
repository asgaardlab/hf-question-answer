!!python/object:huggingface_hub.community.DiscussionWithDetails
author: wonhosong
conflicting_files: null
created_at: 2023-07-28 12:09:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641e81e75c348064a8259d5d/uPGIDF5NOoVCInxpAscm_.jpeg?w=200&h=200&f=face
      fullname: Wonho Song
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wonhosong
      type: user
    createdAt: '2023-07-28T13:09:51.000Z'
    data:
      edited: false
      editors:
      - wonhosong
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8675073981285095
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641e81e75c348064a8259d5d/uPGIDF5NOoVCInxpAscm_.jpeg?w=200&h=200&f=face
          fullname: Wonho Song
          isHf: false
          isPro: false
          name: wonhosong
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;beomi&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/beomi\">@<span class=\"\
          underline\">beomi</span></a></span>\n\n\t</span></span><br>Thank you for\
          \ sharing these impressive results!<br>This repo is really helpful to develop\
          \ new model.</p>\n<p>I have a couple of questions regarding the tokenizer.</p>\n\
          <ol>\n<li><p>Could you specify which Korean vocabulary or tokenizer you\
          \ are utilizing? I am under the impression that the foundational vocabulary\
          \ might be <code>llama-2</code>. Is the new 'one' derived from the <code>polyglot-ko</code>\
          \ vocabulary or something else?</p>\n</li>\n<li><p>Could you elaborate on\
          \ the process of merging two tokenizers while keeping the original one?</p>\n\
          </li>\n</ol>\n<p>Thanks.</p>\n"
        raw: "@beomi \r\nThank you for sharing these impressive results!\r\nThis repo\
          \ is really helpful to develop new model.\r\n\r\nI have a couple of questions\
          \ regarding the tokenizer.\r\n\r\n1. Could you specify which Korean vocabulary\
          \ or tokenizer you are utilizing? I am under the impression that the foundational\
          \ vocabulary might be `llama-2`. Is the new 'one' derived from the `polyglot-ko`\
          \ vocabulary or something else?\r\n\r\n2. Could you elaborate on the process\
          \ of merging two tokenizers while keeping the original one?\r\n\r\nThanks."
        updatedAt: '2023-07-28T13:09:51.963Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - kesarito
        - yoonniverse
    id: 64c3be1f398c28119f60d66b
    type: comment
  author: wonhosong
  content: "@beomi \r\nThank you for sharing these impressive results!\r\nThis repo\
    \ is really helpful to develop new model.\r\n\r\nI have a couple of questions\
    \ regarding the tokenizer.\r\n\r\n1. Could you specify which Korean vocabulary\
    \ or tokenizer you are utilizing? I am under the impression that the foundational\
    \ vocabulary might be `llama-2`. Is the new 'one' derived from the `polyglot-ko`\
    \ vocabulary or something else?\r\n\r\n2. Could you elaborate on the process of\
    \ merging two tokenizers while keeping the original one?\r\n\r\nThanks."
  created_at: 2023-07-28 12:09:51+00:00
  edited: false
  hidden: false
  id: 64c3be1f398c28119f60d66b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1623302508605-5e56829137cb5b49818287ea.jpeg?w=200&h=200&f=face
      fullname: Lee Junbum
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: beomi
      type: user
    createdAt: '2023-08-01T01:14:21.000Z'
    data:
      edited: false
      editors:
      - beomi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8967784643173218
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1623302508605-5e56829137cb5b49818287ea.jpeg?w=200&h=200&f=face
          fullname: Lee Junbum
          isHf: false
          isPro: false
          name: beomi
          type: user
        html: '<p>Hi, I created new sentencepiece tokenizer using HF tokenizers library,
          trained on Korean+English+Code corpus, which from various sources.<br>(*the
          reason why I used ko/en/code is to limit merges)<br>Using regex, I extracted
          Korean only vocab and merges and append them into original Llama-2 vocab.</p>

          <p>it is totally unrelated with polyglot-ko models :)</p>

          '
        raw: 'Hi, I created new sentencepiece tokenizer using HF tokenizers library,
          trained on Korean+English+Code corpus, which from various sources.

          (*the reason why I used ko/en/code is to limit merges)

          Using regex, I extracted Korean only vocab and merges and append them into
          original Llama-2 vocab.


          it is totally unrelated with polyglot-ko models :)'
        updatedAt: '2023-08-01T01:14:21.041Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - wonhosong
        - yoonniverse
      relatedEventId: 64c85c6d3d5a0dfed5b6465d
    id: 64c85c6d3d5a0dfed5b6464b
    type: comment
  author: beomi
  content: 'Hi, I created new sentencepiece tokenizer using HF tokenizers library,
    trained on Korean+English+Code corpus, which from various sources.

    (*the reason why I used ko/en/code is to limit merges)

    Using regex, I extracted Korean only vocab and merges and append them into original
    Llama-2 vocab.


    it is totally unrelated with polyglot-ko models :)'
  created_at: 2023-08-01 00:14:21+00:00
  edited: false
  hidden: false
  id: 64c85c6d3d5a0dfed5b6464b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1623302508605-5e56829137cb5b49818287ea.jpeg?w=200&h=200&f=face
      fullname: Lee Junbum
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: beomi
      type: user
    createdAt: '2023-08-01T01:14:21.000Z'
    data:
      status: closed
    id: 64c85c6d3d5a0dfed5b6465d
    type: status-change
  author: beomi
  created_at: 2023-08-01 00:14:21+00:00
  id: 64c85c6d3d5a0dfed5b6465d
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: beomi/llama-2-ko-7b
repo_type: model
status: closed
target_branch: null
title: Question about Tokenizer.
