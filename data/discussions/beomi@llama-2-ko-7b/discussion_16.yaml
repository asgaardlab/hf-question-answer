!!python/object:huggingface_hub.community.DiscussionWithDetails
author: taehallm
conflicting_files: null
created_at: 2023-12-04 04:39:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/640dd2d3b03f4cd29f547f29/qK8H-BJPVe6JbkpfWf251.png?w=200&h=200&f=face
      fullname: Taeha Lim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: taehallm
      type: user
    createdAt: '2023-12-04T04:39:52.000Z'
    data:
      edited: false
      editors:
      - taehallm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2695123553276062
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/640dd2d3b03f4cd29f547f29/qK8H-BJPVe6JbkpfWf251.png?w=200&h=200&f=face
          fullname: Taeha Lim
          isHf: false
          isPro: false
          name: taehallm
          type: user
        html: "<pre><code class=\"language-python\"><span class=\"hljs-comment\">#\
          \ Load model directly</span>\n<span class=\"hljs-keyword\">from</span> transformers\
          \ <span class=\"hljs-keyword\">import</span> LlamaTokenizer\n\ntokenizer\
          \ = LlamaTokenizer.from_pretrained(<span class=\"hljs-string\">\"beomi/llama-2-ko-7b\"\
          </span>)\n</code></pre>\n<p>\uC2E4\uD589 \uC2DC \uC544\uB798\uC640 \uAC19\
          \uC740 \uC624\uB958 \uBC1C\uC0DD:</p>\n<pre><code>---------------------------------------------------------------------------\n\
          TypeError                                 Traceback (most recent call last)\n\
          &lt;ipython-input-5-54e21f3e3cc0&gt; in &lt;cell line: 4&gt;()\n      2\
          \ from transformers import LlamaTokenizer\n      3 \n----&gt; 4 tokenizer\
          \ = LlamaTokenizer.from_pretrained(\"beomi/llama-2-ko-7b\")\n\n1 frames\n\
          /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\
          \ in _from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path,\
          \ init_configuration, token, cache_dir, local_files_only, _commit_hash,\
          \ _is_local, *init_inputs, **kwargs)\n   2251             if added_tokens_map\
          \ != {} and init_kwargs[key] is not None:\n   2252                 if key\
          \ != \"additional_special_tokens\":\n-&gt; 2253                     init_kwargs[key]\
          \ = added_tokens_map.get(init_kwargs[key], init_kwargs[key])\n   2254 \n\
          \   2255         init_kwargs[\"added_tokens_decoder\"] = added_tokens_decoder\n\
          \nTypeError: unhashable type: 'dict'\n</code></pre>\n<p>\uC5B4\uB5BB\uAC8C\
          \ \uD574\uACB0\uD558\uB294\uC9C0 \uC54C\uB824\uC8FC\uC2DC\uBA74 \uAC10\uC0AC\
          \uD558\uACA0\uC2B5\uB2C8\uB2E4 &lt;3</p>\n"
        raw: "```python\r\n# Load model directly\r\nfrom transformers import LlamaTokenizer\r\
          \n\r\ntokenizer = LlamaTokenizer.from_pretrained(\"beomi/llama-2-ko-7b\"\
          )\r\n```\r\n\r\n\uC2E4\uD589 \uC2DC \uC544\uB798\uC640 \uAC19\uC740 \uC624\
          \uB958 \uBC1C\uC0DD:\r\n```\r\n---------------------------------------------------------------------------\r\
          \nTypeError                                 Traceback (most recent call\
          \ last)\r\n<ipython-input-5-54e21f3e3cc0> in <cell line: 4>()\r\n      2\
          \ from transformers import LlamaTokenizer\r\n      3 \r\n----> 4 tokenizer\
          \ = LlamaTokenizer.from_pretrained(\"beomi/llama-2-ko-7b\")\r\n\r\n1 frames\r\
          \n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\
          \ in _from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path,\
          \ init_configuration, token, cache_dir, local_files_only, _commit_hash,\
          \ _is_local, *init_inputs, **kwargs)\r\n   2251             if added_tokens_map\
          \ != {} and init_kwargs[key] is not None:\r\n   2252                 if\
          \ key != \"additional_special_tokens\":\r\n-> 2253                     init_kwargs[key]\
          \ = added_tokens_map.get(init_kwargs[key], init_kwargs[key])\r\n   2254\
          \ \r\n   2255         init_kwargs[\"added_tokens_decoder\"] = added_tokens_decoder\r\
          \n\r\nTypeError: unhashable type: 'dict'\r\n```\r\n\r\n\uC5B4\uB5BB\uAC8C\
          \ \uD574\uACB0\uD558\uB294\uC9C0 \uC54C\uB824\uC8FC\uC2DC\uBA74 \uAC10\uC0AC\
          \uD558\uACA0\uC2B5\uB2C8\uB2E4 <3"
        updatedAt: '2023-12-04T04:39:52.458Z'
      numEdits: 0
      reactions: []
    id: 656d5818ede71189ad64bfd6
    type: comment
  author: taehallm
  content: "```python\r\n# Load model directly\r\nfrom transformers import LlamaTokenizer\r\
    \n\r\ntokenizer = LlamaTokenizer.from_pretrained(\"beomi/llama-2-ko-7b\")\r\n\
    ```\r\n\r\n\uC2E4\uD589 \uC2DC \uC544\uB798\uC640 \uAC19\uC740 \uC624\uB958 \uBC1C\
    \uC0DD:\r\n```\r\n---------------------------------------------------------------------------\r\
    \nTypeError                                 Traceback (most recent call last)\r\
    \n<ipython-input-5-54e21f3e3cc0> in <cell line: 4>()\r\n      2 from transformers\
    \ import LlamaTokenizer\r\n      3 \r\n----> 4 tokenizer = LlamaTokenizer.from_pretrained(\"\
    beomi/llama-2-ko-7b\")\r\n\r\n1 frames\r\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\
    \ in _from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path,\
    \ init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local,\
    \ *init_inputs, **kwargs)\r\n   2251             if added_tokens_map != {} and\
    \ init_kwargs[key] is not None:\r\n   2252                 if key != \"additional_special_tokens\"\
    :\r\n-> 2253                     init_kwargs[key] = added_tokens_map.get(init_kwargs[key],\
    \ init_kwargs[key])\r\n   2254 \r\n   2255         init_kwargs[\"added_tokens_decoder\"\
    ] = added_tokens_decoder\r\n\r\nTypeError: unhashable type: 'dict'\r\n```\r\n\r\
    \n\uC5B4\uB5BB\uAC8C \uD574\uACB0\uD558\uB294\uC9C0 \uC54C\uB824\uC8FC\uC2DC\uBA74\
    \ \uAC10\uC0AC\uD558\uACA0\uC2B5\uB2C8\uB2E4 <3"
  created_at: 2023-12-04 04:39:52+00:00
  edited: false
  hidden: false
  id: 656d5818ede71189ad64bfd6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/640dd2d3b03f4cd29f547f29/qK8H-BJPVe6JbkpfWf251.png?w=200&h=200&f=face
      fullname: Taeha Lim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: taehallm
      type: user
    createdAt: '2023-12-04T05:27:16.000Z'
    data:
      edited: false
      editors:
      - taehallm
      hidden: false
      identifiedLanguage:
        language: ko
        probability: 0.999051034450531
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/640dd2d3b03f4cd29f547f29/qK8H-BJPVe6JbkpfWf251.png?w=200&h=200&f=face
          fullname: Taeha Lim
          isHf: false
          isPro: false
          name: taehallm
          type: user
        html: "<p>12\uC6D4 4\uC77C \uD604\uC7AC  Note: this repo is under construction\
          \ \uB77C\uACE0 \uBA85\uC2DC\uB418\uC5B4 \uC788\uB294\uB370 \uADF8\uB798\uC11C\
          \ \uC624\uB958\uAC00 \uBC1C\uC0DD\uD558\uB294 \uAC74\uAC00\uC694? </p>\n"
        raw: "12\uC6D4 4\uC77C \uD604\uC7AC  Note: this repo is under construction\
          \ \uB77C\uACE0 \uBA85\uC2DC\uB418\uC5B4 \uC788\uB294\uB370 \uADF8\uB798\uC11C\
          \ \uC624\uB958\uAC00 \uBC1C\uC0DD\uD558\uB294 \uAC74\uAC00\uC694? "
        updatedAt: '2023-12-04T05:27:16.610Z'
      numEdits: 0
      reactions: []
    id: 656d63348556299698005e74
    type: comment
  author: taehallm
  content: "12\uC6D4 4\uC77C \uD604\uC7AC  Note: this repo is under construction \uB77C\
    \uACE0 \uBA85\uC2DC\uB418\uC5B4 \uC788\uB294\uB370 \uADF8\uB798\uC11C \uC624\uB958\
    \uAC00 \uBC1C\uC0DD\uD558\uB294 \uAC74\uAC00\uC694? "
  created_at: 2023-12-04 05:27:16+00:00
  edited: false
  hidden: false
  id: 656d63348556299698005e74
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1c4b2d0be68f9232e0cd0562ed341331.svg
      fullname: choigh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ghchoi
      type: user
    createdAt: '2023-12-20T07:28:11.000Z'
    data:
      edited: true
      editors:
      - ghchoi
      hidden: false
      identifiedLanguage:
        language: ko
        probability: 0.9637952446937561
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1c4b2d0be68f9232e0cd0562ed341331.svg
          fullname: choigh
          isHf: false
          isPro: false
          name: ghchoi
          type: user
        html: "<p><a href=\"https://huggingface.co/beomi/llama-2-ko-7b/discussions/4\"\
          >https://huggingface.co/beomi/llama-2-ko-7b/discussions/4</a> \uC774 \uC4F0\
          \uB808\uB4DC\uC5D0 \uACF5\uC720\uB41C colab \uB178\uD2B8\uBD81 \uCF54\uB4DC\
          \uB97C \uBCF4\uBA74 \uC0AC\uC6A9\uD558\uC2E0 LlamaTokenizer \uAC00 \uC544\
          \uB2C8\uB77C   AutoTokenizer \uB85C pretrained tokenizer\uB97C \uBD88\uB7EC\
          \uC654\uC2B5\uB2C8\uB2E4. </p>\n"
        raw: "https://huggingface.co/beomi/llama-2-ko-7b/discussions/4 \uC774 \uC4F0\
          \uB808\uB4DC\uC5D0 \uACF5\uC720\uB41C colab \uB178\uD2B8\uBD81 \uCF54\uB4DC\
          \uB97C \uBCF4\uBA74 \uC0AC\uC6A9\uD558\uC2E0 LlamaTokenizer \uAC00 \uC544\
          \uB2C8\uB77C   AutoTokenizer \uB85C pretrained tokenizer\uB97C \uBD88\uB7EC\
          \uC654\uC2B5\uB2C8\uB2E4. "
        updatedAt: '2023-12-20T07:28:46.463Z'
      numEdits: 1
      reactions: []
    id: 6582978b38f102154fdfb25e
    type: comment
  author: ghchoi
  content: "https://huggingface.co/beomi/llama-2-ko-7b/discussions/4 \uC774 \uC4F0\
    \uB808\uB4DC\uC5D0 \uACF5\uC720\uB41C colab \uB178\uD2B8\uBD81 \uCF54\uB4DC\uB97C\
    \ \uBCF4\uBA74 \uC0AC\uC6A9\uD558\uC2E0 LlamaTokenizer \uAC00 \uC544\uB2C8\uB77C\
    \   AutoTokenizer \uB85C pretrained tokenizer\uB97C \uBD88\uB7EC\uC654\uC2B5\uB2C8\
    \uB2E4. "
  created_at: 2023-12-20 07:28:11+00:00
  edited: true
  hidden: false
  id: 6582978b38f102154fdfb25e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1623302508605-5e56829137cb5b49818287ea.jpeg?w=200&h=200&f=face
      fullname: Lee Junbum
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: beomi
      type: user
    createdAt: '2023-12-27T01:57:37.000Z'
    data:
      edited: false
      editors:
      - beomi
      hidden: false
      identifiedLanguage:
        language: ko
        probability: 0.9984002113342285
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1623302508605-5e56829137cb5b49818287ea.jpeg?w=200&h=200&f=face
          fullname: Lee Junbum
          isHf: false
          isPro: false
          name: beomi
          type: user
        html: "<p>\uC548\uB155\uD558\uC138\uC694, \uBCF8 \uB808\uD3EC \uAC00\uC774\
          \uB4DC\uCC98\uB7FC <code> AutoTokenizer</code> \uB97C \uD1B5\uD574 \uBD88\
          \uB7EC\uC624\uC154\uC57C \uD569\uB2C8\uB2E4.</p>\n"
        raw: "\uC548\uB155\uD558\uC138\uC694, \uBCF8 \uB808\uD3EC \uAC00\uC774\uB4DC\
          \uCC98\uB7FC ` AutoTokenizer` \uB97C \uD1B5\uD574 \uBD88\uB7EC\uC624\uC154\
          \uC57C \uD569\uB2C8\uB2E4."
        updatedAt: '2023-12-27T01:57:37.438Z'
      numEdits: 0
      reactions: []
      relatedEventId: 658b8491f366ebe2a3bf3651
    id: 658b8491f366ebe2a3bf364e
    type: comment
  author: beomi
  content: "\uC548\uB155\uD558\uC138\uC694, \uBCF8 \uB808\uD3EC \uAC00\uC774\uB4DC\
    \uCC98\uB7FC ` AutoTokenizer` \uB97C \uD1B5\uD574 \uBD88\uB7EC\uC624\uC154\uC57C\
    \ \uD569\uB2C8\uB2E4."
  created_at: 2023-12-27 01:57:37+00:00
  edited: false
  hidden: false
  id: 658b8491f366ebe2a3bf364e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1623302508605-5e56829137cb5b49818287ea.jpeg?w=200&h=200&f=face
      fullname: Lee Junbum
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: beomi
      type: user
    createdAt: '2023-12-27T01:57:37.000Z'
    data:
      status: closed
    id: 658b8491f366ebe2a3bf3651
    type: status-change
  author: beomi
  created_at: 2023-12-27 01:57:37+00:00
  id: 658b8491f366ebe2a3bf3651
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: beomi/llama-2-ko-7b
repo_type: model
status: closed
target_branch: null
title: "LlamaTokenizer.from_pretrained \uC624\uB958"
