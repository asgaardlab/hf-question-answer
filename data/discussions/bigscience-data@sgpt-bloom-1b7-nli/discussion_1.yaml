!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Mayhem50
conflicting_files: null
created_at: 2023-02-01 17:27:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3274a968e7b739b048518ad9b506804e.svg
      fullname: Benjamin REGNIER
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Mayhem50
      type: user
    createdAt: '2023-02-01T17:27:54.000Z'
    data:
      edited: false
      editors:
      - Mayhem50
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3274a968e7b739b048518ad9b506804e.svg
          fullname: Benjamin REGNIER
          isHf: false
          isPro: false
          name: Mayhem50
          type: user
        html: '<p>Hi, </p>

          <p>I was just trying to replicate your work on the bloom-560M model. I just
          finished the fine-tune and I think my setup was maybe wrong.<br>I had use
          your command <code>CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 accelerate launch
          /content/code/biencoder/nli_msmarco/sentence-transformers/examples/training/nli/training_nli_v2.py
          --model_name bigscience/bloom-560m --freezenonbias --train_batch_size 64
          --lr 32e-5 --pooling weightedmean --wandb --wandbwatchlog gradients --gradcache
          --chunksize 4</code><br>Should I modify something ?</p>

          <p>Another question, can the model be improved on french language by fine-tuning
          it  multilingual like it is described here: <a rel="nofollow" href="https://www.sbert.net/examples/training/multilingual/README.html">https://www.sbert.net/examples/training/multilingual/README.html</a></p>

          <p>Thanks</p>

          '
        raw: "Hi, \r\n\r\nI was just trying to replicate your work on the bloom-560M\
          \ model. I just finished the fine-tune and I think my setup was maybe wrong.\r\
          \nI had use your command `CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 accelerate\
          \ launch /content/code/biencoder/nli_msmarco/sentence-transformers/examples/training/nli/training_nli_v2.py\
          \ --model_name bigscience/bloom-560m --freezenonbias --train_batch_size\
          \ 64 --lr 32e-5 --pooling weightedmean --wandb --wandbwatchlog gradients\
          \ --gradcache --chunksize 4`\r\nShould I modify something ?\r\n\r\nAnother\
          \ question, can the model be improved on french language by fine-tuning\
          \ it  multilingual like it is described here: https://www.sbert.net/examples/training/multilingual/README.html\r\
          \n\r\nThanks\r\n\r\n"
        updatedAt: '2023-02-01T17:27:54.144Z'
      numEdits: 0
      reactions: []
    id: 63daa11a6d061b6c6826cc27
    type: comment
  author: Mayhem50
  content: "Hi, \r\n\r\nI was just trying to replicate your work on the bloom-560M\
    \ model. I just finished the fine-tune and I think my setup was maybe wrong.\r\
    \nI had use your command `CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 accelerate launch\
    \ /content/code/biencoder/nli_msmarco/sentence-transformers/examples/training/nli/training_nli_v2.py\
    \ --model_name bigscience/bloom-560m --freezenonbias --train_batch_size 64 --lr\
    \ 32e-5 --pooling weightedmean --wandb --wandbwatchlog gradients --gradcache --chunksize\
    \ 4`\r\nShould I modify something ?\r\n\r\nAnother question, can the model be\
    \ improved on french language by fine-tuning it  multilingual like it is described\
    \ here: https://www.sbert.net/examples/training/multilingual/README.html\r\n\r\
    \nThanks\r\n\r\n"
  created_at: 2023-02-01 17:27:54+00:00
  edited: false
  hidden: false
  id: 63daa11a6d061b6c6826cc27
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2023-02-01T17:51:11.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: "<p>The command looks fine to me - did training already finish? If not,\
          \ which error did you get?</p>\n<p>Yes, if you have good French data available,\
          \ I would expect slightly better performance by training on it.<br>You can\
          \ try with the French STS datasets from the link you sent \U0001F44D</p>\n\
          <p>Let me know how it goes!</p>\n"
        raw: "The command looks fine to me - did training already finish? If not,\
          \ which error did you get?\n\nYes, if you have good French data available,\
          \ I would expect slightly better performance by training on it.\nYou can\
          \ try with the French STS datasets from the link you sent \U0001F44D\n\n\
          Let me know how it goes!"
        updatedAt: '2023-02-01T17:51:11.848Z'
      numEdits: 0
      reactions: []
    id: 63daa68fca02a16f04fb7c67
    type: comment
  author: Muennighoff
  content: "The command looks fine to me - did training already finish? If not, which\
    \ error did you get?\n\nYes, if you have good French data available, I would expect\
    \ slightly better performance by training on it.\nYou can try with the French\
    \ STS datasets from the link you sent \U0001F44D\n\nLet me know how it goes!"
  created_at: 2023-02-01 17:51:11+00:00
  edited: false
  hidden: false
  id: 63daa68fca02a16f04fb7c67
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3274a968e7b739b048518ad9b506804e.svg
      fullname: Benjamin REGNIER
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Mayhem50
      type: user
    createdAt: '2023-02-01T17:58:58.000Z'
    data:
      edited: false
      editors:
      - Mayhem50
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3274a968e7b739b048518ad9b506804e.svg
          fullname: Benjamin REGNIER
          isHf: false
          isPro: false
          name: Mayhem50
          type: user
        html: '<p>The training has finished: <a href="https://huggingface.co/Mayhem50/sgpt-bloom-560M-nli">https://huggingface.co/Mayhem50/sgpt-bloom-560M-nli</a><br>But
          I was expecting better score on my dataset.</p>

          <p>I will try to fine-tune both and see if improvements are significant</p>

          <p>Thanks a lot.</p>

          '
        raw: 'The training has finished: https://huggingface.co/Mayhem50/sgpt-bloom-560M-nli

          But I was expecting better score on my dataset.


          I will try to fine-tune both and see if improvements are significant


          Thanks a lot.'
        updatedAt: '2023-02-01T17:58:58.308Z'
      numEdits: 0
      reactions: []
    id: 63daa862a175b8d7f25a2aa7
    type: comment
  author: Mayhem50
  content: 'The training has finished: https://huggingface.co/Mayhem50/sgpt-bloom-560M-nli

    But I was expecting better score on my dataset.


    I will try to fine-tune both and see if improvements are significant


    Thanks a lot.'
  created_at: 2023-02-01 17:58:58+00:00
  edited: false
  hidden: false
  id: 63daa862a175b8d7f25a2aa7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2023-02-01T18:11:11.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: '<p>Oh nice!<br>Note that the gap between BitFit &amp; full fine-tuning
          only diminishes as you increase model size. For 560 million parameters you
          are likely better off training without BitFit (i.e. remove the <code>--freezenonbias</code>
          from your command).<br>If you scale up to 1.7B like this model or 7.1B like
          <a href="https://huggingface.co/bigscience/sgpt-bloom-7b1-msmarco">https://huggingface.co/bigscience/sgpt-bloom-7b1-msmarco</a>,
          BitFit should perform just as well as full fine-tuning, so you can keep
          the command as is.</p>

          <p>Also make sure that your downstream task is a symmetric one. If it''s
          search-related, you may be better off training on MSMARCO.</p>

          '
        raw: "Oh nice! \nNote that the gap between BitFit & full fine-tuning only\
          \ diminishes as you increase model size. For 560 million parameters you\
          \ are likely better off training without BitFit (i.e. remove the `--freezenonbias`\
          \ from your command).\nIf you scale up to 1.7B like this model or 7.1B like\
          \ https://huggingface.co/bigscience/sgpt-bloom-7b1-msmarco, BitFit should\
          \ perform just as well as full fine-tuning, so you can keep the command\
          \ as is.\n\nAlso make sure that your downstream task is a symmetric one.\
          \ If it's search-related, you may be better off training on MSMARCO."
        updatedAt: '2023-02-01T18:11:11.014Z'
      numEdits: 0
      reactions: []
    id: 63daab3f26ae589b7639408e
    type: comment
  author: Muennighoff
  content: "Oh nice! \nNote that the gap between BitFit & full fine-tuning only diminishes\
    \ as you increase model size. For 560 million parameters you are likely better\
    \ off training without BitFit (i.e. remove the `--freezenonbias` from your command).\n\
    If you scale up to 1.7B like this model or 7.1B like https://huggingface.co/bigscience/sgpt-bloom-7b1-msmarco,\
    \ BitFit should perform just as well as full fine-tuning, so you can keep the\
    \ command as is.\n\nAlso make sure that your downstream task is a symmetric one.\
    \ If it's search-related, you may be better off training on MSMARCO."
  created_at: 2023-02-01 18:11:11+00:00
  edited: false
  hidden: false
  id: 63daab3f26ae589b7639408e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d2bd0dcab174678772ea34d76764a983.svg
      fullname: fangxu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sunshineLiu
      type: user
    createdAt: '2023-10-25T10:02:05.000Z'
    data:
      edited: false
      editors:
      - sunshineLiu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.45233771204948425
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d2bd0dcab174678772ea34d76764a983.svg
          fullname: fangxu
          isHf: false
          isPro: false
          name: sunshineLiu
          type: user
        html: '<p>I use this command to train,  CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
          accelerate launch /content/code/biencoder/nli_msmarco/sentence-transformers/examples/training/nli/training_nli_v2.py
          --model_name bigscience/bloom-560m --train_batch_size 64 --lr 32e-5 --pooling
          weightedmean --wandb --wandbwatchlog gradients --gradcache --chunksize 4</p>

          <p>But it cannot be parallel. Using multiple GPUs is the same as one GPU.
          What''s the problem?</p>

          '
        raw: 'I use this command to train,  CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 accelerate
          launch /content/code/biencoder/nli_msmarco/sentence-transformers/examples/training/nli/training_nli_v2.py
          --model_name bigscience/bloom-560m --train_batch_size 64 --lr 32e-5 --pooling
          weightedmean --wandb --wandbwatchlog gradients --gradcache --chunksize 4


          But it cannot be parallel. Using multiple GPUs is the same as one GPU. What''s
          the problem?'
        updatedAt: '2023-10-25T10:02:05.440Z'
      numEdits: 0
      reactions: []
    id: 6538e79d2ddab2beff0ba4bd
    type: comment
  author: sunshineLiu
  content: 'I use this command to train,  CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 accelerate
    launch /content/code/biencoder/nli_msmarco/sentence-transformers/examples/training/nli/training_nli_v2.py
    --model_name bigscience/bloom-560m --train_batch_size 64 --lr 32e-5 --pooling
    weightedmean --wandb --wandbwatchlog gradients --gradcache --chunksize 4


    But it cannot be parallel. Using multiple GPUs is the same as one GPU. What''s
    the problem?'
  created_at: 2023-10-25 09:02:05+00:00
  edited: false
  hidden: false
  id: 6538e79d2ddab2beff0ba4bd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2023-10-25T15:14:56.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8661442995071411
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: '<p>Maybe you have to run <code>accelerate config</code> and select
          multiple gpus</p>

          '
        raw: Maybe you have to run `accelerate config` and select multiple gpus
        updatedAt: '2023-10-25T15:14:56.893Z'
      numEdits: 0
      reactions: []
    id: 653930f05c8e4863e19a8ed4
    type: comment
  author: Muennighoff
  content: Maybe you have to run `accelerate config` and select multiple gpus
  created_at: 2023-10-25 14:14:56+00:00
  edited: false
  hidden: false
  id: 653930f05c8e4863e19a8ed4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: bigscience-data/sgpt-bloom-1b7-nli
repo_type: model
status: open
target_branch: null
title: Train Bloom 560M
