!!python/object:huggingface_hub.community.DiscussionWithDetails
author: gospacedev
conflicting_files: null
created_at: 2023-12-19 17:35:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638dd709ca00481637c050d1/uXk3JJyM73EIzkvweVocK.jpeg?w=200&h=200&f=face
      fullname: Grantley Cullar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gospacedev
      type: user
    createdAt: '2023-12-19T17:35:54.000Z'
    data:
      edited: true
      editors:
      - gospacedev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5182924866676331
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638dd709ca00481637c050d1/uXk3JJyM73EIzkvweVocK.jpeg?w=200&h=200&f=face
          fullname: Grantley Cullar
          isHf: false
          isPro: false
          name: gospacedev
          type: user
        html: "<pre><code>from huggingface_hub import InferenceClient\n\nclient =\
          \ InferenceClient(\n    \"ehartford/dolphin-2.5-mixtral-8x7b\"\n)\n</code></pre>\n\
          <p>When I try to use ehartford/dolphin-2.5-mixtral-8x7b in Spaces, I get\
          \ these errors:</p>\n<pre><code>huggingface_hub.utils._errors.HfHubHTTPError:\
          \ 403 Client Error: Forbidden for url: https://api-inference.huggingface.co/models/ehartford/dolphin-2.5-mixtral-8x7b\
          \ (Request ID: bttrYLuVoD5jjxUm9RxFm)\n\nThe model ehartford/dolphin-2.5-mixtral-8x7b\
          \ is too large to be loaded automatically (93GB &gt; 10GB). Please use Spaces\
          \ (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n\
          \nrequests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://api-inference.huggingface.co/models/ehartford/dolphin-2.5-mixtral-8x7b\n\
          </code></pre>\n<p>Is the API access of this model restricted, or its too\
          \ large? But when I tried mistralai/Mixtral-8x7B-Instruct-v0.1 using InferenceClient,\
          \ it works.</p>\n"
        raw: "```\nfrom huggingface_hub import InferenceClient\n\nclient = InferenceClient(\n\
          \    \"ehartford/dolphin-2.5-mixtral-8x7b\"\n)\n```\n\nWhen I try to use\
          \ ehartford/dolphin-2.5-mixtral-8x7b in Spaces, I get these errors:\n```\n\
          huggingface_hub.utils._errors.HfHubHTTPError: 403 Client Error: Forbidden\
          \ for url: https://api-inference.huggingface.co/models/ehartford/dolphin-2.5-mixtral-8x7b\
          \ (Request ID: bttrYLuVoD5jjxUm9RxFm)\n\nThe model ehartford/dolphin-2.5-mixtral-8x7b\
          \ is too large to be loaded automatically (93GB > 10GB). Please use Spaces\
          \ (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n\
          \nrequests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://api-inference.huggingface.co/models/ehartford/dolphin-2.5-mixtral-8x7b\n\
          ```\n\nIs the API access of this model restricted, or its too large? But\
          \ when I tried mistralai/Mixtral-8x7B-Instruct-v0.1 using InferenceClient,\
          \ it works."
        updatedAt: '2023-12-19T17:38:17.433Z'
      numEdits: 1
      reactions: []
    id: 6581d47aafc6b50a2c9667ab
    type: comment
  author: gospacedev
  content: "```\nfrom huggingface_hub import InferenceClient\n\nclient = InferenceClient(\n\
    \    \"ehartford/dolphin-2.5-mixtral-8x7b\"\n)\n```\n\nWhen I try to use ehartford/dolphin-2.5-mixtral-8x7b\
    \ in Spaces, I get these errors:\n```\nhuggingface_hub.utils._errors.HfHubHTTPError:\
    \ 403 Client Error: Forbidden for url: https://api-inference.huggingface.co/models/ehartford/dolphin-2.5-mixtral-8x7b\
    \ (Request ID: bttrYLuVoD5jjxUm9RxFm)\n\nThe model ehartford/dolphin-2.5-mixtral-8x7b\
    \ is too large to be loaded automatically (93GB > 10GB). Please use Spaces (https://huggingface.co/spaces)\
    \ or Inference Endpoints (https://huggingface.co/inference-endpoints).\n\nrequests.exceptions.HTTPError:\
    \ 403 Client Error: Forbidden for url: https://api-inference.huggingface.co/models/ehartford/dolphin-2.5-mixtral-8x7b\n\
    ```\n\nIs the API access of this model restricted, or its too large? But when\
    \ I tried mistralai/Mixtral-8x7B-Instruct-v0.1 using InferenceClient, it works."
  created_at: 2023-12-19 17:35:54+00:00
  edited: true
  hidden: false
  id: 6581d47aafc6b50a2c9667ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638dd709ca00481637c050d1/uXk3JJyM73EIzkvweVocK.jpeg?w=200&h=200&f=face
      fullname: Grantley Cullar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gospacedev
      type: user
    createdAt: '2023-12-19T17:39:33.000Z'
    data:
      from: Errors when using the model in Spaces
      to: Issue with using the model in Spaces
    id: 6581d555117b524ef3d9440a
    type: title-change
  author: gospacedev
  created_at: 2023-12-19 17:39:33+00:00
  id: 6581d555117b524ef3d9440a
  new_title: Issue with using the model in Spaces
  old_title: Errors when using the model in Spaces
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64161701107962562e9b1006/HM8Je8C8ie1aCpdse4SUY.png?w=200&h=200&f=face
      fullname: Forever
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: GreyForever
      type: user
    createdAt: '2023-12-19T19:18:33.000Z'
    data:
      edited: false
      editors:
      - GreyForever
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8808771967887878
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64161701107962562e9b1006/HM8Je8C8ie1aCpdse4SUY.png?w=200&h=200&f=face
          fullname: Forever
          isHf: false
          isPro: false
          name: GreyForever
          type: user
        html: '<p>You may be launching it on spaces, but u are still using the InferenceClient
          that uses the inference api. I guess you must be new around, models that
          require more than 10gb cannot be run with the free inference API, and running
          it on spaces using a free space will not be possible neither hardware speaking.</p>

          <p>If you ever want to REALLY run the model itself, in a space or in your
          computer, you will not be using the inference API and instead be using transformers,
          AKA downloading the model on your computer and running it on your own hardware
          (or space hardware if you run it here)</p>

          <p>I help I managed to be of some help !</p>

          '
        raw: 'You may be launching it on spaces, but u are still using the InferenceClient
          that uses the inference api. I guess you must be new around, models that
          require more than 10gb cannot be run with the free inference API, and running
          it on spaces using a free space will not be possible neither hardware speaking.


          If you ever want to REALLY run the model itself, in a space or in your computer,
          you will not be using the inference API and instead be using transformers,
          AKA downloading the model on your computer and running it on your own hardware
          (or space hardware if you run it here)


          I help I managed to be of some help !'
        updatedAt: '2023-12-19T19:18:33.907Z'
      numEdits: 0
      reactions: []
    id: 6581ec89117b524ef3ddcde7
    type: comment
  author: GreyForever
  content: 'You may be launching it on spaces, but u are still using the InferenceClient
    that uses the inference api. I guess you must be new around, models that require
    more than 10gb cannot be run with the free inference API, and running it on spaces
    using a free space will not be possible neither hardware speaking.


    If you ever want to REALLY run the model itself, in a space or in your computer,
    you will not be using the inference API and instead be using transformers, AKA
    downloading the model on your computer and running it on your own hardware (or
    space hardware if you run it here)


    I help I managed to be of some help !'
  created_at: 2023-12-19 19:18:33+00:00
  edited: false
  hidden: false
  id: 6581ec89117b524ef3ddcde7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64161701107962562e9b1006/HM8Je8C8ie1aCpdse4SUY.png?w=200&h=200&f=face
      fullname: Forever
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: GreyForever
      type: user
    createdAt: '2023-12-19T19:20:40.000Z'
    data:
      edited: false
      editors:
      - GreyForever
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7103583216667175
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64161701107962562e9b1006/HM8Je8C8ie1aCpdse4SUY.png?w=200&h=200&f=face
          fullname: Forever
          isHf: false
          isPro: false
          name: GreyForever
          type: user
        html: "<blockquote>\n<pre><code>from huggingface_hub import InferenceClient\n\
          \nclient = InferenceClient(\n    \"ehartford/dolphin-2.5-mixtral-8x7b\"\n\
          )\n</code></pre>\n<p>When I try to use ehartford/dolphin-2.5-mixtral-8x7b\
          \ in Spaces, I get these errors:</p>\n<pre><code>huggingface_hub.utils._errors.HfHubHTTPError:\
          \ 403 Client Error: Forbidden for url: https://api-inference.huggingface.co/models/ehartford/dolphin-2.5-mixtral-8x7b\
          \ (Request ID: bttrYLuVoD5jjxUm9RxFm)\n\nThe model ehartford/dolphin-2.5-mixtral-8x7b\
          \ is too large to be loaded automatically (93GB &gt; 10GB). Please use Spaces\
          \ (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n\
          \nrequests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://api-inference.huggingface.co/models/ehartford/dolphin-2.5-mixtral-8x7b\n\
          </code></pre>\n<p>Is the API access of this model restricted, or its too\
          \ large? But when I tried mistralai/Mixtral-8x7B-Instruct-v0.1 using InferenceClient,\
          \ it works.</p>\n</blockquote>\n<p>Now about Mixtral I agree that I was\
          \ surprised too, but Mixtral does use originally an architecture quite unique\
          \ that reduces considerably the amount of paremeters required to predict\
          \ tokens for max efficiency, so that may be the reason.</p>\n"
        raw: "> ```\n> from huggingface_hub import InferenceClient\n> \n> client =\
          \ InferenceClient(\n>     \"ehartford/dolphin-2.5-mixtral-8x7b\"\n> )\n\
          > ```\n> \n> When I try to use ehartford/dolphin-2.5-mixtral-8x7b in Spaces,\
          \ I get these errors:\n> ```\n> huggingface_hub.utils._errors.HfHubHTTPError:\
          \ 403 Client Error: Forbidden for url: https://api-inference.huggingface.co/models/ehartford/dolphin-2.5-mixtral-8x7b\
          \ (Request ID: bttrYLuVoD5jjxUm9RxFm)\n> \n> The model ehartford/dolphin-2.5-mixtral-8x7b\
          \ is too large to be loaded automatically (93GB > 10GB). Please use Spaces\
          \ (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n\
          > \n> requests.exceptions.HTTPError: 403 Client Error: Forbidden for url:\
          \ https://api-inference.huggingface.co/models/ehartford/dolphin-2.5-mixtral-8x7b\n\
          > ```\n> \n> Is the API access of this model restricted, or its too large?\
          \ But when I tried mistralai/Mixtral-8x7B-Instruct-v0.1 using InferenceClient,\
          \ it works.\n\nNow about Mixtral I agree that I was surprised too, but Mixtral\
          \ does use originally an architecture quite unique that reduces considerably\
          \ the amount of paremeters required to predict tokens for max efficiency,\
          \ so that may be the reason."
        updatedAt: '2023-12-19T19:20:40.736Z'
      numEdits: 0
      reactions: []
    id: 6581ed084867f8699d2736e7
    type: comment
  author: GreyForever
  content: "> ```\n> from huggingface_hub import InferenceClient\n> \n> client = InferenceClient(\n\
    >     \"ehartford/dolphin-2.5-mixtral-8x7b\"\n> )\n> ```\n> \n> When I try to\
    \ use ehartford/dolphin-2.5-mixtral-8x7b in Spaces, I get these errors:\n> ```\n\
    > huggingface_hub.utils._errors.HfHubHTTPError: 403 Client Error: Forbidden for\
    \ url: https://api-inference.huggingface.co/models/ehartford/dolphin-2.5-mixtral-8x7b\
    \ (Request ID: bttrYLuVoD5jjxUm9RxFm)\n> \n> The model ehartford/dolphin-2.5-mixtral-8x7b\
    \ is too large to be loaded automatically (93GB > 10GB). Please use Spaces (https://huggingface.co/spaces)\
    \ or Inference Endpoints (https://huggingface.co/inference-endpoints).\n> \n>\
    \ requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://api-inference.huggingface.co/models/ehartford/dolphin-2.5-mixtral-8x7b\n\
    > ```\n> \n> Is the API access of this model restricted, or its too large? But\
    \ when I tried mistralai/Mixtral-8x7B-Instruct-v0.1 using InferenceClient, it\
    \ works.\n\nNow about Mixtral I agree that I was surprised too, but Mixtral does\
    \ use originally an architecture quite unique that reduces considerably the amount\
    \ of paremeters required to predict tokens for max efficiency, so that may be\
    \ the reason."
  created_at: 2023-12-19 19:20:40+00:00
  edited: false
  hidden: false
  id: 6581ed084867f8699d2736e7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638dd709ca00481637c050d1/uXk3JJyM73EIzkvweVocK.jpeg?w=200&h=200&f=face
      fullname: Grantley Cullar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gospacedev
      type: user
    createdAt: '2023-12-20T03:35:30.000Z'
    data:
      edited: false
      editors:
      - gospacedev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9367007613182068
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638dd709ca00481637c050d1/uXk3JJyM73EIzkvweVocK.jpeg?w=200&h=200&f=face
          fullname: Grantley Cullar
          isHf: false
          isPro: false
          name: gospacedev
          type: user
        html: '<p>Thank you for helping me!</p>

          '
        raw: Thank you for helping me!
        updatedAt: '2023-12-20T03:35:30.526Z'
      numEdits: 0
      reactions: []
    id: 6582610290aa0254b0a8a5cd
    type: comment
  author: gospacedev
  content: Thank you for helping me!
  created_at: 2023-12-20 03:35:30+00:00
  edited: false
  hidden: false
  id: 6582610290aa0254b0a8a5cd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: cognitivecomputations/dolphin-2.5-mixtral-8x7b
repo_type: model
status: open
target_branch: null
title: Issue with using the model in Spaces
