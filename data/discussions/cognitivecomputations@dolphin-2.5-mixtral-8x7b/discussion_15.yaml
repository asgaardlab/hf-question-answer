!!python/object:huggingface_hub.community.DiscussionWithDetails
author: meadow
conflicting_files: null
created_at: 2023-12-20 18:37:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0d75407a38e7a49ad88077475d76306a.svg
      fullname: Phil N
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: meadow
      type: user
    createdAt: '2023-12-20T18:37:29.000Z'
    data:
      edited: false
      editors:
      - meadow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9036020040512085
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0d75407a38e7a49ad88077475d76306a.svg
          fullname: Phil N
          isHf: false
          isPro: false
          name: meadow
          type: user
        html: "<p>Hi! Thank you for your effort here. Apologies beforehand if this\
          \ is a naive question.</p>\n<p>I'm running this model with ollama via the\
          \ terminal. I edited the manifest (modelfile?) to include my own custom\
          \ paragraph as initial user message and the model responds well to that\
          \ and actually loads pretty fast. </p>\n<p>\"(base) \u279C  ~ ollama run\
          \ dolphin-mixtral:latest</p>\n<blockquote>\n<blockquote>\n<blockquote>\n\
          <p>Hello<br> Title: Comprehensive Guide on How to...[redacted]\"</p>\n</blockquote>\n\
          </blockquote>\n</blockquote>\n<p>However, once that message is completed\
          \ and I send another one then it just ignores the one I sent and starts\
          \ answering the initial user prompt from the modelfile. </p>\n<p>Is this\
          \ simply a memory/hardware related issue or is it worth diving into this\
          \ further?</p>\n<p>Thanks in advance!</p>\n"
        raw: "Hi! Thank you for your effort here. Apologies beforehand if this is\
          \ a naive question.\r\n\r\nI'm running this model with ollama via the terminal.\
          \ I edited the manifest (modelfile?) to include my own custom paragraph\
          \ as initial user message and the model responds well to that and actually\
          \ loads pretty fast. \r\n\r\n\"(base) \u279C  ~ ollama run dolphin-mixtral:latest\r\
          \n>>> Hello\r\n Title: Comprehensive Guide on How to...[redacted]\"\r\n\r\
          \nHowever, once that message is completed and I send another one then it\
          \ just ignores the one I sent and starts answering the initial user prompt\
          \ from the modelfile. \r\n\r\nIs this simply a memory/hardware related issue\
          \ or is it worth diving into this further?\r\n\r\nThanks in advance!"
        updatedAt: '2023-12-20T18:37:29.893Z'
      numEdits: 0
      reactions: []
    id: 65833469948899c453874b17
    type: comment
  author: meadow
  content: "Hi! Thank you for your effort here. Apologies beforehand if this is a\
    \ naive question.\r\n\r\nI'm running this model with ollama via the terminal.\
    \ I edited the manifest (modelfile?) to include my own custom paragraph as initial\
    \ user message and the model responds well to that and actually loads pretty fast.\
    \ \r\n\r\n\"(base) \u279C  ~ ollama run dolphin-mixtral:latest\r\n>>> Hello\r\n\
    \ Title: Comprehensive Guide on How to...[redacted]\"\r\n\r\nHowever, once that\
    \ message is completed and I send another one then it just ignores the one I sent\
    \ and starts answering the initial user prompt from the modelfile. \r\n\r\nIs\
    \ this simply a memory/hardware related issue or is it worth diving into this\
    \ further?\r\n\r\nThanks in advance!"
  created_at: 2023-12-20 18:37:29+00:00
  edited: false
  hidden: false
  id: 65833469948899c453874b17
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/97705f30a63d902ce361bb4ace04d997.svg
      fullname: Helbert Gascon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: muzika38
      type: user
    createdAt: '2023-12-30T02:21:29.000Z'
    data:
      edited: false
      editors:
      - muzika38
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8864365220069885
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/97705f30a63d902ce361bb4ace04d997.svg
          fullname: Helbert Gascon
          isHf: false
          isPro: false
          name: muzika38
          type: user
        html: '<p>Try to increase the context size setting.</p>

          <p>I forgot how to do it on ollama but I believe you either can set it temporarily
          by issuing the "/set" command while chatting or hardcoding it in the modelfile.
          </p>

          '
        raw: 'Try to increase the context size setting.


          I forgot how to do it on ollama but I believe you either can set it temporarily
          by issuing the "/set" command while chatting or hardcoding it in the modelfile. '
        updatedAt: '2023-12-30T02:21:29.754Z'
      numEdits: 0
      reactions: []
    id: 658f7ea9a260709928b8a7f1
    type: comment
  author: muzika38
  content: 'Try to increase the context size setting.


    I forgot how to do it on ollama but I believe you either can set it temporarily
    by issuing the "/set" command while chatting or hardcoding it in the modelfile. '
  created_at: 2023-12-30 02:21:29+00:00
  edited: false
  hidden: false
  id: 658f7ea9a260709928b8a7f1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 15
repo_id: cognitivecomputations/dolphin-2.5-mixtral-8x7b
repo_type: model
status: open
target_branch: null
title: Model working with input file but not when chatting further | Mac M3 Pro 36GB
