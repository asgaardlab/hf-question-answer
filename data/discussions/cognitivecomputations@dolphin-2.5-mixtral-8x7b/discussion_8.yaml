!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mlenno1
conflicting_files: null
created_at: 2023-12-19 02:42:46+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0e89ff214134351ab555d268e2bcbfc.svg
      fullname: Michael
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mlenno1
      type: user
    createdAt: '2023-12-19T02:42:46.000Z'
    data:
      edited: false
      editors:
      - mlenno1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.953908383846283
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0e89ff214134351ab555d268e2bcbfc.svg
          fullname: Michael
          isHf: false
          isPro: false
          name: mlenno1
          type: user
        html: '<p>After a few paragraphs, the text gets very repetitive when asked
          to write a story. I''m using LM Studio with the ChatML preset. Any tips
          to prevent this?</p>

          '
        raw: "After a few paragraphs, the text gets very repetitive when asked to\
          \ write a story. I'm using LM Studio with the ChatML preset. Any tips to\
          \ prevent this?\r\n\r\n"
        updatedAt: '2023-12-19T02:42:46.895Z'
      numEdits: 0
      reactions: []
    id: 658103268ecea67c7d652de5
    type: comment
  author: mlenno1
  content: "After a few paragraphs, the text gets very repetitive when asked to write\
    \ a story. I'm using LM Studio with the ChatML preset. Any tips to prevent this?\r\
    \n\r\n"
  created_at: 2023-12-19 02:42:46+00:00
  edited: false
  hidden: false
  id: 658103268ecea67c7d652de5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-12-19T03:42:03.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9851980209350586
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>I notice the same<br>I think it''s a flaw in the model</p>

          '
        raw: 'I notice the same

          I think it''s a flaw in the model'
        updatedAt: '2023-12-19T03:42:03.482Z'
      numEdits: 0
      reactions: []
    id: 6581110b560c1557cfd3d6a8
    type: comment
  author: ehartford
  content: 'I notice the same

    I think it''s a flaw in the model'
  created_at: 2023-12-19 03:42:03+00:00
  edited: false
  hidden: false
  id: 6581110b560c1557cfd3d6a8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0e89ff214134351ab555d268e2bcbfc.svg
      fullname: Michael
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mlenno1
      type: user
    createdAt: '2023-12-19T04:21:26.000Z'
    data:
      edited: false
      editors:
      - mlenno1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9954128265380859
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0e89ff214134351ab555d268e2bcbfc.svg
          fullname: Michael
          isHf: false
          isPro: false
          name: mlenno1
          type: user
        html: "<p>Glad to know it's not just me. Was going mad trying everything and\
          \ couldn't fix it. \U0001F605</p>\n"
        raw: "Glad to know it's not just me. Was going mad trying everything and couldn't\
          \ fix it. \U0001F605"
        updatedAt: '2023-12-19T04:21:26.786Z'
      numEdits: 0
      reactions: []
    id: 65811a46e77395a0c86107ea
    type: comment
  author: mlenno1
  content: "Glad to know it's not just me. Was going mad trying everything and couldn't\
    \ fix it. \U0001F605"
  created_at: 2023-12-19 04:21:26+00:00
  edited: false
  hidden: false
  id: 65811a46e77395a0c86107ea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63037b895c70c21d0ea80b0e/myu35DuQn9io_HhxNLYR4.png?w=200&h=200&f=face
      fullname: Pooodle Shmith
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: Tom9000
      type: user
    createdAt: '2023-12-19T20:01:06.000Z'
    data:
      edited: false
      editors:
      - Tom9000
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.990558385848999
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63037b895c70c21d0ea80b0e/myu35DuQn9io_HhxNLYR4.png?w=200&h=200&f=face
          fullname: Pooodle Shmith
          isHf: false
          isPro: true
          name: Tom9000
          type: user
        html: '<p>Yes, that''s the reason I went back to Yi based models, after less
          than half hour with mixtral.<br>I just couldn''t get it to stop repeating
          same thing, even by increasing repetition penalty.</p>

          '
        raw: 'Yes, that''s the reason I went back to Yi based models, after less than
          half hour with mixtral.

          I just couldn''t get it to stop repeating same thing, even by increasing
          repetition penalty.'
        updatedAt: '2023-12-19T20:01:06.285Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Velvetflume
    id: 6581f68205c177eea39a48ff
    type: comment
  author: Tom9000
  content: 'Yes, that''s the reason I went back to Yi based models, after less than
    half hour with mixtral.

    I just couldn''t get it to stop repeating same thing, even by increasing repetition
    penalty.'
  created_at: 2023-12-19 20:01:06+00:00
  edited: false
  hidden: false
  id: 6581f68205c177eea39a48ff
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cf33f15c0773ef5abb61a91c26d352da.svg
      fullname: Evgeny Kurnevsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kurnevsky
      type: user
    createdAt: '2023-12-20T13:32:17.000Z'
    data:
      edited: false
      editors:
      - kurnevsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9525453448295593
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cf33f15c0773ef5abb61a91c26d352da.svg
          fullname: Evgeny Kurnevsky
          isHf: false
          isPro: false
          name: kurnevsky
          type: user
        html: '<p>Is it only dolphin or other finetunes too? I had the same, but though
          that dolphin-mixtral might be undertrained on multiturn dialogues. So far
          dolphin-mistral is much better in keeping the track of dialogue for me.</p>

          '
        raw: Is it only dolphin or other finetunes too? I had the same, but though
          that dolphin-mixtral might be undertrained on multiturn dialogues. So far
          dolphin-mistral is much better in keeping the track of dialogue for me.
        updatedAt: '2023-12-20T13:32:17.205Z'
      numEdits: 0
      reactions: []
    id: 6582ece14a130ba7f0f62565
    type: comment
  author: kurnevsky
  content: Is it only dolphin or other finetunes too? I had the same, but though that
    dolphin-mixtral might be undertrained on multiturn dialogues. So far dolphin-mistral
    is much better in keeping the track of dialogue for me.
  created_at: 2023-12-20 13:32:17+00:00
  edited: false
  hidden: false
  id: 6582ece14a130ba7f0f62565
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63037b895c70c21d0ea80b0e/myu35DuQn9io_HhxNLYR4.png?w=200&h=200&f=face
      fullname: Pooodle Shmith
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: Tom9000
      type: user
    createdAt: '2023-12-20T20:44:41.000Z'
    data:
      edited: false
      editors:
      - Tom9000
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9457035660743713
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63037b895c70c21d0ea80b0e/myu35DuQn9io_HhxNLYR4.png?w=200&h=200&f=face
          fullname: Pooodle Shmith
          isHf: false
          isPro: true
          name: Tom9000
          type: user
        html: '<p>Unclear yet, one or another or a bit of both. I''ll decided to let
          all dust to settle, for another month or so, before testing any mixtral
          models again, models and all the tooling just too raw atm.<br>But I suspect
          it will always feel like a group of very knowledgeable but small models,
          rather than one large model, and interesting cognitive signs tend to show
          up at around 30B mark for monoliths, so most likely I won''t be holding
          my breath for this specific type of MOE architecture, despite all the hype.</p>

          '
        raw: "Unclear yet, one or another or a bit of both. I'll decided to let all\
          \ dust to settle, for another month or so, before testing any mixtral models\
          \ again, models and all the tooling just too raw atm. \nBut I suspect it\
          \ will always feel like a group of very knowledgeable but small models,\
          \ rather than one large model, and interesting cognitive signs tend to show\
          \ up at around 30B mark for monoliths, so most likely I won't be holding\
          \ my breath for this specific type of MOE architecture, despite all the\
          \ hype."
        updatedAt: '2023-12-20T20:44:41.377Z'
      numEdits: 0
      reactions: []
    id: 65835239c73f74776bf025c8
    type: comment
  author: Tom9000
  content: "Unclear yet, one or another or a bit of both. I'll decided to let all\
    \ dust to settle, for another month or so, before testing any mixtral models again,\
    \ models and all the tooling just too raw atm. \nBut I suspect it will always\
    \ feel like a group of very knowledgeable but small models, rather than one large\
    \ model, and interesting cognitive signs tend to show up at around 30B mark for\
    \ monoliths, so most likely I won't be holding my breath for this specific type\
    \ of MOE architecture, despite all the hype."
  created_at: 2023-12-20 20:44:41+00:00
  edited: false
  hidden: false
  id: 65835239c73f74776bf025c8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cc3fa400ac9e32fb1799d463c2c0a32a.svg
      fullname: Thomas Broomhall
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AxiomDEV
      type: user
    createdAt: '2023-12-20T23:15:06.000Z'
    data:
      edited: false
      editors:
      - AxiomDEV
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9566500186920166
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cc3fa400ac9e32fb1799d463c2c0a32a.svg
          fullname: Thomas Broomhall
          isHf: false
          isPro: false
          name: AxiomDEV
          type: user
        html: "<p>I found in my few hours of testing that the model repeats itself\
          \ a lot and will get stuck on silly things like a single bracket or when\
          \ giving a example api key in code, it wont say \" {INSERT_API_KEY_HERE}\
          \ \" it will try and create one, a never ending one \U0001F923 and i also\
          \ found that it apologies all the time, esspecally when i just dump my error\
          \ codes for it to help me with issues with no context  \U0001F937\u200D\u2642\
          \uFE0F.  That's my 10p anyway, i don't know enough about this stuff to even\
          \ start contemplating why it dose that as more than likely it's probably\
          \ just me .</p>\n"
        raw: "I found in my few hours of testing that the model repeats itself a lot\
          \ and will get stuck on silly things like a single bracket or when giving\
          \ a example api key in code, it wont say \" {INSERT_API_KEY_HERE} \" it\
          \ will try and create one, a never ending one \U0001F923 and i also found\
          \ that it apologies all the time, esspecally when i just dump my error codes\
          \ for it to help me with issues with no context  \U0001F937\u200D\u2642\uFE0F\
          .  That's my 10p anyway, i don't know enough about this stuff to even start\
          \ contemplating why it dose that as more than likely it's probably just\
          \ me ."
        updatedAt: '2023-12-20T23:15:06.009Z'
      numEdits: 0
      reactions: []
    id: 6583757a1e065c276dc14208
    type: comment
  author: AxiomDEV
  content: "I found in my few hours of testing that the model repeats itself a lot\
    \ and will get stuck on silly things like a single bracket or when giving a example\
    \ api key in code, it wont say \" {INSERT_API_KEY_HERE} \" it will try and create\
    \ one, a never ending one \U0001F923 and i also found that it apologies all the\
    \ time, esspecally when i just dump my error codes for it to help me with issues\
    \ with no context  \U0001F937\u200D\u2642\uFE0F.  That's my 10p anyway, i don't\
    \ know enough about this stuff to even start contemplating why it dose that as\
    \ more than likely it's probably just me ."
  created_at: 2023-12-20 23:15:06+00:00
  edited: false
  hidden: false
  id: 6583757a1e065c276dc14208
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7312c88d6ed65c3f1348a0544f7031df.svg
      fullname: 'hushpiper '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hushpiper
      type: user
    createdAt: '2023-12-21T17:17:34.000Z'
    data:
      edited: false
      editors:
      - hushpiper
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9759183526039124
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7312c88d6ed65c3f1348a0544f7031df.svg
          fullname: 'hushpiper '
          isHf: false
          isPro: false
          name: hushpiper
          type: user
        html: '<p>I''ve been looking into this issue but I''ve had some trouble really
          pinning it down to figure out. Every model I''ve tried on this MoE architecture
          tends to loop, finetunes far moreso than the original, and the commenter
          above is correct that repetition penalty tends to make it worse. I suspect
          it can be addressed, at least partially, with sampler settings. Try raising
          temperature substantially, somewhere between 1 and 1.5, and switch to a
          dynamic sampler. Min P around 0.1 gets pretty consistently good results
          for me, and Mirostat is also very good. (Not quite as good as Min P in terms
          of stability and comprehension, but Min P isn''t available everywhere while
          Mirostat usually is.) Other sampler settings I''ve tried tend to be pretty
          meh.</p>

          <p>Please let me know if these settings help with the issue! As I said,
          I''ve been looking into it, so more data would help.</p>

          '
        raw: 'I''ve been looking into this issue but I''ve had some trouble really
          pinning it down to figure out. Every model I''ve tried on this MoE architecture
          tends to loop, finetunes far moreso than the original, and the commenter
          above is correct that repetition penalty tends to make it worse. I suspect
          it can be addressed, at least partially, with sampler settings. Try raising
          temperature substantially, somewhere between 1 and 1.5, and switch to a
          dynamic sampler. Min P around 0.1 gets pretty consistently good results
          for me, and Mirostat is also very good. (Not quite as good as Min P in terms
          of stability and comprehension, but Min P isn''t available everywhere while
          Mirostat usually is.) Other sampler settings I''ve tried tend to be pretty
          meh.


          Please let me know if these settings help with the issue! As I said, I''ve
          been looking into it, so more data would help.'
        updatedAt: '2023-12-21T17:17:34.496Z'
      numEdits: 0
      reactions: []
    id: 6584732ec2b0d67b5dc9457c
    type: comment
  author: hushpiper
  content: 'I''ve been looking into this issue but I''ve had some trouble really pinning
    it down to figure out. Every model I''ve tried on this MoE architecture tends
    to loop, finetunes far moreso than the original, and the commenter above is correct
    that repetition penalty tends to make it worse. I suspect it can be addressed,
    at least partially, with sampler settings. Try raising temperature substantially,
    somewhere between 1 and 1.5, and switch to a dynamic sampler. Min P around 0.1
    gets pretty consistently good results for me, and Mirostat is also very good.
    (Not quite as good as Min P in terms of stability and comprehension, but Min P
    isn''t available everywhere while Mirostat usually is.) Other sampler settings
    I''ve tried tend to be pretty meh.


    Please let me know if these settings help with the issue! As I said, I''ve been
    looking into it, so more data would help.'
  created_at: 2023-12-21 17:17:34+00:00
  edited: false
  hidden: false
  id: 6584732ec2b0d67b5dc9457c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-12-21T20:31:39.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9936768412590027
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>I would love to get to the bottom of this.</p>

          '
        raw: I would love to get to the bottom of this.
        updatedAt: '2023-12-21T20:31:39.084Z'
      numEdits: 0
      reactions: []
    id: 6584a0abdde0b8de9e7dd620
    type: comment
  author: ehartford
  content: I would love to get to the bottom of this.
  created_at: 2023-12-21 20:31:39+00:00
  edited: false
  hidden: false
  id: 6584a0abdde0b8de9e7dd620
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0e89ff214134351ab555d268e2bcbfc.svg
      fullname: Michael
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mlenno1
      type: user
    createdAt: '2023-12-21T20:36:02.000Z'
    data:
      edited: false
      editors:
      - mlenno1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9696163535118103
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0e89ff214134351ab555d268e2bcbfc.svg
          fullname: Michael
          isHf: false
          isPro: false
          name: mlenno1
          type: user
        html: '<p>It happens with the base Mixtral model as well. I''ve been seeing
          people reporting issues with the K quants, but I tested all q4 and q5 versions
          of the base Mixtral and this fine-tuned model and experience similar results.
          Short answers to direct questions work really well, but asking it to write
          a story or simulate dialogue almost always results in repetition and loss
          of coherence.</p>

          '
        raw: It happens with the base Mixtral model as well. I've been seeing people
          reporting issues with the K quants, but I tested all q4 and q5 versions
          of the base Mixtral and this fine-tuned model and experience similar results.
          Short answers to direct questions work really well, but asking it to write
          a story or simulate dialogue almost always results in repetition and loss
          of coherence.
        updatedAt: '2023-12-21T20:36:02.604Z'
      numEdits: 0
      reactions: []
    id: 6584a1b23c103871648e674e
    type: comment
  author: mlenno1
  content: It happens with the base Mixtral model as well. I've been seeing people
    reporting issues with the K quants, but I tested all q4 and q5 versions of the
    base Mixtral and this fine-tuned model and experience similar results. Short answers
    to direct questions work really well, but asking it to write a story or simulate
    dialogue almost always results in repetition and loss of coherence.
  created_at: 2023-12-21 20:36:02+00:00
  edited: false
  hidden: false
  id: 6584a1b23c103871648e674e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c2378a034649dc92fbaa868e326cebb.svg
      fullname: gghf
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gghfez
      type: user
    createdAt: '2023-12-21T20:37:14.000Z'
    data:
      edited: false
      editors:
      - gghfez
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9611051678657532
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c2378a034649dc92fbaa868e326cebb.svg
          fullname: gghf
          isHf: false
          isPro: false
          name: gghfez
          type: user
        html: "<blockquote>\n<p>I found in my few hours of testing that the model\
          \ repeats itself a lot and will get stuck on silly things like a single\
          \ bracket or when giving a example api key in code, it wont say \" {INSERT_API_KEY_HERE}\
          \ \" it will try and create one, a never ending one \U0001F923 and i also\
          \ found that it apologies all the time, esspecally when i just dump my error\
          \ codes for it to help me with issues with no context  \U0001F937\u200D\u2642\
          \uFE0F.  That's my 10p anyway, i don't know enough about this stuff to even\
          \ start contemplating why it dose that as more than likely it's probably\
          \ just me .</p>\n</blockquote>\n<p>Do you have an example to produce this?\
          \ I'm not having this issue.</p>\n"
        raw: "> I found in my few hours of testing that the model repeats itself a\
          \ lot and will get stuck on silly things like a single bracket or when giving\
          \ a example api key in code, it wont say \" {INSERT_API_KEY_HERE} \" it\
          \ will try and create one, a never ending one \U0001F923 and i also found\
          \ that it apologies all the time, esspecally when i just dump my error codes\
          \ for it to help me with issues with no context  \U0001F937\u200D\u2642\uFE0F\
          .  That's my 10p anyway, i don't know enough about this stuff to even start\
          \ contemplating why it dose that as more than likely it's probably just\
          \ me .\n\nDo you have an example to produce this? I'm not having this issue."
        updatedAt: '2023-12-21T20:37:14.090Z'
      numEdits: 0
      reactions: []
    id: 6584a1facf1596d00284449d
    type: comment
  author: gghfez
  content: "> I found in my few hours of testing that the model repeats itself a lot\
    \ and will get stuck on silly things like a single bracket or when giving a example\
    \ api key in code, it wont say \" {INSERT_API_KEY_HERE} \" it will try and create\
    \ one, a never ending one \U0001F923 and i also found that it apologies all the\
    \ time, esspecally when i just dump my error codes for it to help me with issues\
    \ with no context  \U0001F937\u200D\u2642\uFE0F.  That's my 10p anyway, i don't\
    \ know enough about this stuff to even start contemplating why it dose that as\
    \ more than likely it's probably just me .\n\nDo you have an example to produce\
    \ this? I'm not having this issue."
  created_at: 2023-12-21 20:37:14+00:00
  edited: false
  hidden: false
  id: 6584a1facf1596d00284449d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-12-21T20:41:34.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9682021141052246
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<blockquote>

          <p>It happens with the base Mixtral model as well. I''ve been seeing people
          reporting issues with the K quants, but I tested all q4 and q5 versions
          of the base Mixtral and this fine-tuned model and experience similar results.
          Short answers to direct questions work really well, but asking it to write
          a story or simulate dialogue almost always results in repetition and loss
          of coherence.</p>

          </blockquote>

          <p>Exactly true.  Asking it to generate longer stories is giving terrible
          results even at 16bit so quantization isn''t the problem </p>

          '
        raw: '> It happens with the base Mixtral model as well. I''ve been seeing
          people reporting issues with the K quants, but I tested all q4 and q5 versions
          of the base Mixtral and this fine-tuned model and experience similar results.
          Short answers to direct questions work really well, but asking it to write
          a story or simulate dialogue almost always results in repetition and loss
          of coherence.


          Exactly true.  Asking it to generate longer stories is giving terrible results
          even at 16bit so quantization isn''t the problem '
        updatedAt: '2023-12-21T20:41:34.768Z'
      numEdits: 0
      reactions: []
    id: 6584a2fee07563d421e7c434
    type: comment
  author: ehartford
  content: '> It happens with the base Mixtral model as well. I''ve been seeing people
    reporting issues with the K quants, but I tested all q4 and q5 versions of the
    base Mixtral and this fine-tuned model and experience similar results. Short answers
    to direct questions work really well, but asking it to write a story or simulate
    dialogue almost always results in repetition and loss of coherence.


    Exactly true.  Asking it to generate longer stories is giving terrible results
    even at 16bit so quantization isn''t the problem '
  created_at: 2023-12-21 20:41:34+00:00
  edited: false
  hidden: false
  id: 6584a2fee07563d421e7c434
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6e7a0dde0c9bf3b679360c12210419e5.svg
      fullname: Karl William Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Modeledbehavior
      type: user
    createdAt: '2023-12-21T20:52:44.000Z'
    data:
      edited: false
      editors:
      - Modeledbehavior
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9353877902030945
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6e7a0dde0c9bf3b679360c12210419e5.svg
          fullname: Karl William Smith
          isHf: false
          isPro: false
          name: Modeledbehavior
          type: user
        html: '<p>I wonder if Classifier Free Guidance would help. </p>

          '
        raw: 'I wonder if Classifier Free Guidance would help. '
        updatedAt: '2023-12-21T20:52:44.297Z'
      numEdits: 0
      reactions: []
    id: 6584a59c92a5db7dcc9ace79
    type: comment
  author: Modeledbehavior
  content: 'I wonder if Classifier Free Guidance would help. '
  created_at: 2023-12-21 20:52:44+00:00
  edited: false
  hidden: false
  id: 6584a59c92a5db7dcc9ace79
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63037b895c70c21d0ea80b0e/myu35DuQn9io_HhxNLYR4.png?w=200&h=200&f=face
      fullname: Pooodle Shmith
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: Tom9000
      type: user
    createdAt: '2023-12-22T21:31:20.000Z'
    data:
      edited: false
      editors:
      - Tom9000
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9810901284217834
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63037b895c70c21d0ea80b0e/myu35DuQn9io_HhxNLYR4.png?w=200&h=200&f=face
          fullname: Pooodle Shmith
          isHf: false
          isPro: true
          name: Tom9000
          type: user
        html: '<p>Looks like, at least partially, issue is with the Mixtral MOE architecture.</p>

          '
        raw: Looks like, at least partially, issue is with the Mixtral MOE architecture.
        updatedAt: '2023-12-22T21:31:20.631Z'
      numEdits: 0
      reactions: []
    id: 6586002846ed30388a8b8081
    type: comment
  author: Tom9000
  content: Looks like, at least partially, issue is with the Mixtral MOE architecture.
  created_at: 2023-12-22 21:31:20+00:00
  edited: false
  hidden: false
  id: 6586002846ed30388a8b8081
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: cognitivecomputations/dolphin-2.5-mixtral-8x7b
repo_type: model
status: open
target_branch: null
title: Repetitive Text
