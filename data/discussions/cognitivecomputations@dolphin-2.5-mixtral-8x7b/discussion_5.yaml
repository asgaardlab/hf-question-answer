!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tgaddair
conflicting_files: null
created_at: 2023-12-15 23:04:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2238a639daa567c1e79f4bb51e407145.svg
      fullname: Travis Addair
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tgaddair
      type: user
    createdAt: '2023-12-15T23:04:49.000Z'
    data:
      edited: false
      editors:
      - tgaddair
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9754524230957031
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2238a639daa567c1e79f4bb51e407145.svg
          fullname: Travis Addair
          isHf: false
          isPro: false
          name: tgaddair
          type: user
        html: '<p>Thanks for this project! I noticed that the model was trained with
          QLoRA, but the fine tuned weights are provided as full (merged) weights
          rather than the LoRA weights. Do you happen to have the LoRA weights available
          somewhere to share?</p>

          <p>For context, I''m interested in serving this model using LoRAX (<a rel="nofollow"
          href="https://github.com/predibase/lorax">https://github.com/predibase/lorax</a>)
          so the base model and fine-tuned model can be served at the sam time.</p>

          '
        raw: "Thanks for this project! I noticed that the model was trained with QLoRA,\
          \ but the fine tuned weights are provided as full (merged) weights rather\
          \ than the LoRA weights. Do you happen to have the LoRA weights available\
          \ somewhere to share?\r\n\r\nFor context, I'm interested in serving this\
          \ model using LoRAX (https://github.com/predibase/lorax) so the base model\
          \ and fine-tuned model can be served at the sam time."
        updatedAt: '2023-12-15T23:04:49.620Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jingyibo123
    id: 657cdb916dc01435cd6b25fd
    type: comment
  author: tgaddair
  content: "Thanks for this project! I noticed that the model was trained with QLoRA,\
    \ but the fine tuned weights are provided as full (merged) weights rather than\
    \ the LoRA weights. Do you happen to have the LoRA weights available somewhere\
    \ to share?\r\n\r\nFor context, I'm interested in serving this model using LoRAX\
    \ (https://github.com/predibase/lorax) so the base model and fine-tuned model\
    \ can be served at the sam time."
  created_at: 2023-12-15 23:04:49+00:00
  edited: false
  hidden: false
  id: 657cdb916dc01435cd6b25fd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: cognitivecomputations/dolphin-2.5-mixtral-8x7b
repo_type: model
status: open
target_branch: null
title: Able to provide the LoRA weights?
