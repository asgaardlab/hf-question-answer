!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kopal37
conflicting_files: null
created_at: 2023-11-30 08:32:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e1e58ea1dac6fba786d2b0c22af5775c.svg
      fullname: J W
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kopal37
      type: user
    createdAt: '2023-11-30T08:32:49.000Z'
    data:
      edited: false
      editors:
      - kopal37
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.949883222579956
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e1e58ea1dac6fba786d2b0c22af5775c.svg
          fullname: J W
          isHf: false
          isPro: false
          name: kopal37
          type: user
        html: '<p>How, exactly?</p>

          <p>Thanks for your work on this!</p>

          '
        raw: "How, exactly?\r\n\r\nThanks for your work on this!"
        updatedAt: '2023-11-30T08:32:49.709Z'
      numEdits: 0
      reactions: []
    id: 656848b105fb89fb7e40b917
    type: comment
  author: kopal37
  content: "How, exactly?\r\n\r\nThanks for your work on this!"
  created_at: 2023-11-30 08:32:49+00:00
  edited: false
  hidden: false
  id: 656848b105fb89fb7e40b917
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
      fullname: brucethemoose
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: brucethemoose
      type: user
    createdAt: '2023-11-30T15:04:32.000Z'
    data:
      edited: true
      editors:
      - brucethemoose
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8899680972099304
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
          fullname: brucethemoose
          isHf: false
          isPro: false
          name: brucethemoose
          type: user
        html: '<p>Thank the trainers of the constituent models!</p>

          <p>Exui is a text generation GUI from the exllamav2 dev. Its quite fast:
          <a rel="nofollow" href="https://github.com/turboderp/exui">https://github.com/turboderp/exui</a></p>

          <p>Load the model with 8-bit cache. This applies to ooba as well, if you
          use that instead. Use MinP with other options disabled, except for temperature
          and repetition.</p>

          <p>I use the model in notebook mode, but you may have to manually adjust
          the prompt template for chat mode.</p>

          '
        raw: 'Thank the trainers of the constituent models!


          Exui is a text generation GUI from the exllamav2 dev. Its quite fast: https://github.com/turboderp/exui


          Load the model with 8-bit cache. This applies to ooba as well, if you use
          that instead. Use MinP with other options disabled, except for temperature
          and repetition.


          I use the model in notebook mode, but you may have to manually adjust the
          prompt template for chat mode.'
        updatedAt: '2023-11-30T15:05:04.737Z'
      numEdits: 1
      reactions: []
    id: 6568a4802693fa22e18eff5b
    type: comment
  author: brucethemoose
  content: 'Thank the trainers of the constituent models!


    Exui is a text generation GUI from the exllamav2 dev. Its quite fast: https://github.com/turboderp/exui


    Load the model with 8-bit cache. This applies to ooba as well, if you use that
    instead. Use MinP with other options disabled, except for temperature and repetition.


    I use the model in notebook mode, but you may have to manually adjust the prompt
    template for chat mode.'
  created_at: 2023-11-30 15:04:32+00:00
  edited: true
  hidden: false
  id: 6568a4802693fa22e18eff5b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
      fullname: brucethemoose
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: brucethemoose
      type: user
    createdAt: '2023-12-06T07:15:57.000Z'
    data:
      edited: false
      editors:
      - brucethemoose
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8305184245109558
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
          fullname: brucethemoose
          isHf: false
          isPro: false
          name: brucethemoose
          type: user
        html: '<p>I actually wrote this up on reddit, if you are still interested:
          <a rel="nofollow" href="https://old.reddit.com/r/LocalLLaMA/comments/1896igc/how_i_run_34b_models_at_75k_context_on_24gb_fast/">https://old.reddit.com/r/LocalLLaMA/comments/1896igc/how_i_run_34b_models_at_75k_context_on_24gb_fast/</a></p>

          '
        raw: 'I actually wrote this up on reddit, if you are still interested: https://old.reddit.com/r/LocalLLaMA/comments/1896igc/how_i_run_34b_models_at_75k_context_on_24gb_fast/'
        updatedAt: '2023-12-06T07:15:57.209Z'
      numEdits: 0
      reactions: []
    id: 65701fada60ea28d7eafc579
    type: comment
  author: brucethemoose
  content: 'I actually wrote this up on reddit, if you are still interested: https://old.reddit.com/r/LocalLLaMA/comments/1896igc/how_i_run_34b_models_at_75k_context_on_24gb_fast/'
  created_at: 2023-12-06 07:15:57+00:00
  edited: false
  hidden: false
  id: 65701fada60ea28d7eafc579
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: brucethemoose/CapyTessBorosYi-34B-200K-DARE-Ties-exl2-4bpw-fiction
repo_type: model
status: open
target_branch: null
title: '"running in exui for speed at long context" in text-generation-webui'
